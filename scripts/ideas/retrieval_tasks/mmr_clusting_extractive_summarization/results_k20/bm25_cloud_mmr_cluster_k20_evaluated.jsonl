{"task_id":"1be66272113492407e814eaf21a761d4<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11192-0-1195","score":22.4649058385,"text":"\n\n\n\n\n\n\n  Exploring scorecards \n\nYou can use different approaches to add data to your metrics cube.\n\nScorecards reflect the strategic goals of an organization. Using scorecards, you can identify how well objectives are being met by comparing targets to actual results. Visual status indicators such as traffic lights, trend icons, and colors are used to help you to quickly evaluate performance.\n\nIn Planning Analytics with Watson, you can add existing scorecards to your books, and analyze data by selecting different time periods, metrics, and dimensions. You can also create visualizations from scorecards, such as impact diagrams and strategy maps.\n\nYou can explore scorecards in Planning Analytics with Watson with the GO_Scorecards sample.\n\n\n\n*  [Scorecards](https:\/\/www.ibm.com\/docs\/planning-analytics\/2.0.0?topic=es-scorecards)\n\n\n\nA scorecard is a collection of performance metrics that are designed to reflect the strategic goals of your business unit or organization.\n\n\n\n*  [Metrics cubes](https:\/\/www.ibm.com\/docs\/planning-analytics\/2.0.0?topic=es-metrics-cubes)\n\n\n\nA metrics cube is a special type of cube that provides the basis for scorecard solutions and scorecard diagrams.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/planning-analytics?topic=planning-analytics-exploring-scorecards"},{"document_id":"ibmcld_09615-10623-12269","score":20.2249512157,"text":"\n\"containers-kubernetes\"\n]\n},\n{\n\"operand\": \"location\",\n\"operator\": \"in\",\n\"values\":\n\"us-south\",\n\"eu-de\"\n]\n}\n]\n}]\nShow more\n\nWhere:\n\naction\n: Action defines whether IBM Cloud\u00ae Metrics Routing includes or excludes metrics on the route. Two actions are supported: send and drop. If not specified, the default action is to send the metrics.\n\nsend\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalues\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, values must include a single string. When the inoperator is used, values can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-metrics-router-cli"},{"document_id":"ibmcld_09615-4729-6393","score":20.174480511,"text":"\n{\n\"operand\": \"location\",\n\"operator\": \"in\",\n\"values\":\n\"us-south\",\n\"eu-de\"\n]\n}\n]\n}]\nShow more\n\nWhere:\n\naction\n: Action defines whether IBM Cloud\u00ae Metrics Routing includes or excludes metrics on the route. Two actions are supported: send and drop. If not specified, the default action is to send the metrics.\n\nsend\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalues\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, values must include a single string. When the inoperator is used, values can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-metrics-router-cli"},{"document_id":"ibmcld_09615-2350-4116","score":20.0861290048,"text":"\n: Action defines whether IBM Cloud\u00ae Metrics Routing includes or excludes metrics on the route. Two actions are supported: send and drop. If not specified, the default action is to send the metrics.\n\nsend\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalues\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, values must include a single string. When the inoperator is used, values can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource\n: Values appropriate to an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\n--rules RULES","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-metrics-router-cli"},{"document_id":"ibmcld_09615-8271-10037","score":20.0861290048,"text":"\n: Action defines whether IBM Cloud\u00ae Metrics Routing includes or excludes metrics on the route. Two actions are supported: send and drop. If not specified, the default action is to send the metrics.\n\nsend\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalues\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, values must include a single string. When the inoperator is used, values can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource\n: Values appropriate to an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\n--rules RULES","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-metrics-router-cli"},{"document_id":"ibmcld_09628-1427-3147","score":20.0461002297,"text":"\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\n\n\n\n\n Inclusion filters \n\nInclusion filters define the conditions that are used to determine which metrics are routed to the targets specified in the rule.\n\nTo route all metrics, exclude the inclusion_filters definition when you configure a route.\n\nInclusion filters are composed of an operand, operator, and value:\n\noperand\n: Operand is the name of the property in the target that is used to filter data. The following operands are supported: location, service_name, service_instance, resource_type, and resource. The value is extracted from the target CRN.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalue\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, value must include a single string. When the inoperator is used, value can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-route_rules_definitions"},{"document_id":"ibmcld_09623-1182-2897","score":20.0014824749,"text":"\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalue\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, value must include a single string. When the inoperator is used, value can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource\n: Values appropriate to an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nFor example, to define an inclusion filter that defines the condition where only metrics that are generated in the us-south region are routed, looks as follows:\n\n{\"operand\": \"location\",\"operator\": \"is\",\"values\": \"us-south\"}\n\n\n\n\n\n Configure the route \n\nRun the following command to exclude all metrics received by IBM Cloud Metrics Routing from the us-south region.\n\nibmcloud metrics-router route create --name drop-route --rules '[{\"action\": \"drop\", \"inclusion_filters\":{\"operand\": \"location\",\"operator\": \"is\",\"values\": \"us-south\"}]}]'\n\nWhere inclusion_filters specifies the filters.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-route-drop"},{"document_id":"ibmcld_09623-4-1600","score":19.8793537823,"text":"\n* CLI\n\n\n\n\n\n\n\n Excluding metrics by using the drop action \n\nYou can configure IBM Cloud\u00ae Metrics Routing to exclude (drop) metrics based on a configured rule. Dropped metrics are not sent on to a target.\n\n\n\n Prereqs \n\n\n\n1. [Install the IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-install-ibmcloud-cli).\n2. [Install the IBM Cloud Metrics Routing CLI](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-metrics-router-cli-config).\n3. Ensure you have the [correct IAM permissions to configure IBM Cloud Metrics Routing routes.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-iam)\n4. Log in to IBM Cloud. Run the following command: [ibmcloud login](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_cliibmcloud_login).\n\n\n\n\n\n\n\n Define the inclusion filter \n\nInclusion filters determine which metrics are routed to the targets.\n\nInclusion filters are comprised of an operand, operator, and values:\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location, service_name, service_instance, resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalue\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, value must include a single string.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-route-drop"},{"document_id":"ibmcld_09625-1179-2989","score":19.7983372537,"text":"\nStep 2: Define the inclusion filter \n\nInclusion filters determine which metrics are routed to the targets.\n\nInclusion filters are comprised of an operand, operator, and values:\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalue\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, value must include a single string. When the inoperator is used, value can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource\n: Values appropriate to an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nFor example, to define an inclusion filter that defines the condition where only metrics that are generated in the us-south region are routed, looks as follows:\n\n{\"operand\": \"location\",\"operator\": \"is\",\"values\": \"us-south\"}\n\n\n\n\n\n Step 3: Configure the route","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-route-from-1-location"},{"document_id":"ibmcld_04612-2600-4714","score":19.2255028338,"text":"\nThe CPU utilization can be affected by the total workload of the hosting hardware and other factors.\n* Responsetime is the average amount of time that the app takes to respond to a request. Responsetime is specified in ms (milliseconds).\n* Throughput is the total number of the requests that are processed in a time period. Throughput is specified in rps (requests per second).\n* Custom_metric is your own custom metric. The Custom_metric name can be any alphanumeric value. Autoscaling is triggered when the corresponding metric is emitted to the App Autoscaler. For more information, see the [custom metric usage guide](https:\/\/github.com\/cloudfoundry\/app-autoscaler\/tree\/develop\/docsauto-scale-your-application-with-custom-metrics).\n\n\n\nIn addition to specifying the metric type, specify an operator, threshold, breach duration, adjustment, and cooldown period values.\n\nWhen the threshold is continuously breached during the breach duration period, and beyond the cooldown period, the App AutoScaler triggers the defined autoscaling action. The number or percentage of app instances is adjusted.\n\n\n\n* The operator can be >=, >, <=, or <.\n* The threshold must be a numeric value.\n* The breach duration is defined in seconds. The default value is 120 seconds.\n* The adjustment value specifies how the number of app instances change in each scaling action. You can specify an absolute number or a percentage of instances to add or remove.\n* The cooldown period specifies the time to wait before the taking the next autoscaling action. A cooldown period ensures that your app does not launch new instances or stop existing instances before your app is stable. The cooldown period is specified in seconds. The default cooldown period is 300 seconds.\n\n\n\n4. (Optional) Define Schedules to scale your app during a set time period.\n\nYou can define specific time periods when you know that your app requires different numbers of instances to handle peak loads. The schedule policy overwrites the default instance limits and sets the number of instances to the Initial Minimum Instance Count value for the scheduled period.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-autoscale_cloud_foundry_apps"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16162-7-1800","score":24.442887138,"text":"\nMigrating legacy configurations to the current vSRX architecture \n\nMigrating IBM Cloud\u00ae Juniper vSRX configurations from the legacy to the current architecture requires careful consideration.\n\nvSRX 18.4 deployments leverage the current architecture in most cases. This includes the vSRX 18.4 1G SR-IOV offering. The older vSRX 18.4 1G Standard offering is based on Linux Bridging and has different network configurations on the Ubuntu host, the KVM hypervisor, and in the vSRX configuration. The host and KVM settings do not require any special migration steps, as the automation process handles the configuration changes. However, if you want to import the vSRX configuration from the legacy architecture into the current vSRX configuration, you likely need to refactor some of the configuration.\n\n\n\n Migrating 1G vSRX standalone configurations \n\nThere are some steps you potentially need to convert vSRX configuration settings on a Standalone 18.4 1G Public+Private Linux Bridge (legacy architecture) instance to a Standalone 18.4 1G Public+Private SR-IOV (current architecture) instance.\n\nYou can find a sample default configuration for SR-IOV based current architecture [in this topic](https:\/\/cloud.ibm.com\/docs\/vsrx?topic=vsrx-understanding-the-vsrx-default-configurationdefault-configuration-of-a-sample-standalone-vsrx-gateway).\n\nThe following is a sample default configuration for the Linux Bridge (legacy architecture). The example shows vSRX instances that were provisioned in different Datacenter pods. As a result, the transit VLAN\u2019s (native-vlan-id) are different.\n\n Last commit: 2020-04-16 22:48:33 UTC by root\nversion 18.4R1-S1.3;\nsystem {\nlogin {\nclass security {\npermissions [ security-control view-configuration ];\n}\nuser admin {\nuid 2000;\nclass super-user;\nauthentication {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vsrx?topic=vsrx-migrating-config"},{"document_id":"ibmcld_02952-7-2097","score":22.6785760166,"text":"\nConnecting customers with support \n\nNo matter where you deploy your assistant, give your customers a way to get additional support when they need it.\n\nBuild your dialog to recognize when customers need help that cannot be provided by the assistant. Add logic that can connect your customers to whatever type of professional support you offer. Your solutions might include:\n\n\n\n* A toll-free phone number to a call center that is manned by human agents\n* An online support ticket form that customers fill out and submit\n* A service desk solution that is configured to work with your custom client application. The built-in Zendesk and Salesforce integrations aren\u2019t supported.\n\n\n\nDesign your dialog to recognize customer requests for help and address them. Add an intent that understands the customer request, and then add a dialog branch that handles the request.\n\nYou might add an intent and use it in a dialog node like these example intents:\n\n\n\nAlternative support request intent examples\n\n Intent name Intent user example 1 Intent user example 2 Response from dialog node that conditions on intent \n\n call_support How do I reach support? What's your toll-free number? Call 1-800-555-0123 to reach a call center agent at any time. \n support_ticket How do I get help? Who can help me with an issue I'm having? Go to [Support Center](https:\/\/example.com\/support) and open a support ticket. \n\n\n\n\n\n Adding chat transfer support \n\nDesign your dialog so that it can transfer customers to human agents. Consider adding support for initiating a transfer in the following scenarios:\n\n\n\n* Any time a user asks to speak to a person.\n\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support"},{"document_id":"ibmcld_03270-4-2215","score":22.0604909882,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Connecting customers with support \n\nNo matter where you deploy your assistant, give your customers a way to get additional support when they need it.\n\nBuild your dialog to recognize when customers need help that cannot be provided by the assistant. Add logic that can connect your customers to whatever type of professional support you offer. Your solutions might include:\n\n\n\n* A toll-free phone number to a call center that is manned by human agents\n* An online support ticket form that customers fill out and submit\n* An integration with Intercom\n* A service desk solution that is configured to work with your web chat integration or a custom client application\n\n\n\nDesign your dialog to recognize customer requests for help and address them. Add an intent that understands the customer request, and then add a dialog branch that handles the request.\n\nFor example, you might add an intent and use it in a dialog node like the intents that are shown in the table below.\n\n\n\nAlternative support request intent examples\n\n Intent name Intent user example 1 Intent user example 2 Response from dialog node that conditions on intent \n\n call_support How do I reach support? What's your toll-free number? Call 1-800-555-0123 to reach a call center agent at any time. \n support_ticket How do I get help? Who can help me with an issue I'm having? Go to [Support Center](https:\/\/example.com\/support) and open a support ticket. \n\n\n\nIf you deploy your assistant with an integration that has built-in service desk support, you can use the special Connect to human agent response type in your dialog response to initiate a transfer.\n\n\n\n Adding chat transfer support \n\nDesign your dialog so that it can transfer customers to human agents. Consider adding support for initiating a transfer in the following scenarios:\n\n\n\n* Any time a user asks to speak to a person.\n\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-support"},{"document_id":"ibmcld_16262-6573-7996","score":20.9357184675,"text":"\n{\n\"output\": {\n\"generic\": [!\n{\n\"response_type\": \"text\",\n\"text\": \"Welcome to the Watson Assistant example\"\n}\n],\n\"intents\": [\n{\n\"intent\": \"hello\",\n\"confidence\": 1\n}\n],\n\"entities\": []\n},\n\"user_id\": \"my_user_id\",\n\"context\": {\n\"global\": {\n\"system\": {\n\"turn_count\": 1,\n\"user_id\": \"my_user_id\"\n}\n},\n\"skills\": {\n\"main skill\": {\n\"user_defined\": {\n\"account_number\": \"123456\"\n}\n}\n}\n}\n}\nShow more\n\n\n\n\n\n Restoring conversation state \n\nIn some situations, you might want the ability to restore a conversation to a previous state.\n\nYou can use the export option on stateful message requests to specify that you want the context object in the response to include complete session state data. If you specify true for this option, the returned skill context includes an encoded state property that represents the current conversation state.\n\nIf you are using the stateful message API, the service stores conversation state data only for the life of the session. However, if you save this context data (including state) and send it back to the service with a subsequent message request, you can restore the conversation to the same state, even if the original session expired or was deleted.\n\nIf you are using the stateless message API, the state property is always included in responses (along with the rest of context). Although stateless sessions do not expire, you can still use this state data to reset a conversation to a previous state.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client-get-context"},{"document_id":"ibmcld_03282-7502-9528","score":20.8678772761,"text":"\nFor example, to check if an entity or context variable contains the name O'Reilly, you must surround the name with parentheses.\n\n@person:(O'Reilly) and $person:(O'Reilly)\n\nYour assistant converts these shorthand references into these full SpEL expressions:\n\nentities['person']?.contains('O''Reilly') and context['person'] == 'O''Reilly'\n\nSpEL uses a second apostrophe to escape the single apostrophe in the name.\n* Checking for multiple values: If you want to check for more than one value, you can create a condition that uses OR operators (||) to list multiple values in the condition. For example, to define a condition that is true if the context variable $state contains the abbreviations for Massachusetts, Maine, or New Hampshire, you can use this expression:\n\n$state:MA || $state:ME || $state:NH\n* Checking for number values: When comparing numbers, first make sure the entity or variable you are checking has a value. If the entity or variable does not have a number value, it is treated as having a null value (0) in a numeric comparison.\n\nFor example, you want to check whether a dollar value that a user specified in user input is less than 100. If you use the condition @price < 100, and the @price entity is null, then the condition is evaluated as true because 0 is less than 100, even though the price was never set. To prevent this type of inaccurate result, use a condition such as @price AND @price < 100. If @price has no value, then this condition correctly returns false.\n* Checking for intents with a specific intent name pattern: You can use a condition that looks for intents that match a pattern. For example, to find any detected intents with intent names that start with 'User_', you can use a syntax like this in the condition:\n\nintents[0].intent.startsWith(\"User_\")\n\nHowever, when you do so, all of the detected intents are considered, even those with a confidence lower than 0.2. Also check that intents which are considered irrelevant by Watson based on their confidence score are not returned.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tips"},{"document_id":"ibmcld_03270-1613-3746","score":20.5683340559,"text":"\nIf you deploy your assistant with an integration that has built-in service desk support, you can use the special Connect to human agent response type in your dialog response to initiate a transfer.\n\n\n\n Adding chat transfer support \n\nDesign your dialog so that it can transfer customers to human agents. Consider adding support for initiating a transfer in the following scenarios:\n\n\n\n* Any time a user asks to speak to a person.\n\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.\n\nFor example, an insurance company might want questions about bereavement benefits always to be handled by a person. Or, if a customer wants to close an account, you might want to transfer the conversation to a respresentative who is authorized to offer incentives to keep the customer's business.\n* When the assistant repeatedly fails to understand a customer's request. Instead of asking the customer to retry or rephrase the question over and over, your assistant can offer to transfer the customer to a human agent.\n\n\n\nTo design a dialog that can transfer the conversation, complete the following steps:\n\n\n\n1. Add an intent to your skill that can recognize a user's request to speak to a human.\n\nYou can create your own intent or add the prebuilt intent named General_Connect_to_Agent that is provided with the General content catalog.\n2. Add a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-support"},{"document_id":"ibmcld_03112-6262-7898","score":19.9912600387,"text":"\n(For more information about using the context in your dialog, see [How the dialog is processed](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime).)\n\nYou can specify any variable name you want to use for a user-defined context variable. If the specified variable already exists, it is overwritten with the new value; if not, a new variable is added to the context.\n\nThe output from this request includes not only the usual output, but also the context, showing that the specified values have been added. If you are using the stateless message method, this context data must be stored locally and sent back to the Watson Assistant service as part of the next message. If you are using the stateful message method, this context is stored automatically and will persist for the life of the session.\n\n{\n\"output\": {\n\"generic\": [!\n{\n\"response_type\": \"text\",\n\"text\": \"Welcome to the Watson Assistant example\"\n}\n],\n\"intents\": [\n{\n\"intent\": \"hello\",\n\"confidence\": 1\n}\n],\n\"entities\": []\n},\n\"user_id\": \"my_user_id\",\n\"context\": {\n\"global\": {\n\"system\": {\n\"turn_count\": 1,\n\"user_id\": \"my_user_id\"\n}\n},\n\"skills\": {\n\"main skill\": {\n\"user_defined\": {\n\"account_number\": \"123456\"\n}\n}\n}\n}\n}\nShow more\n\n\n\n\n\n Restoring conversation state \n\nIn some situations, you might want the ability to restore a conversation to a previous state.\n\nYou can use the export option on stateful message requests to specify that you want the context object in the response to include complete session state data. If you specify true for this option, the returned skill context includes an encoded state property that represents the current conversation state.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-client-get-context"},{"document_id":"ibmcld_03310-8686-10732","score":19.7369628703,"text":"\n* To be more restrictive about which terms are identified as airports in the input when fuzzy matching is enabled, you can specify this expression in a node condition, for example: @airport && @airport.confidence > 0.7. The node will only execute if your assistant is 70% confident that the input text contains an airport reference.\n\n\n\nIn this example, the user input is Are there places to exchange currency at JFK, Logan, and O'Hare?\n\n\n\n* To capture multiple occurrences of an entity type in user input, use syntax like this:\n\n\"context\":{\n\"airports\":\"@airport.values\"\n}\n\nTo later refer to the captured list in a dialog response, use this syntax: You asked about these airports: <? $airports.join(', ') ?>. It is displayed like this: You asked about these airports: JFK, Logan, O'Hare.\n* To capture the literal values for multiple entity mentions, use the following syntax:\n\nentities['myEntityName'].literal]\n\n\n\n\n\n\n\n\n\n Accessing intents \n\nThe intents array contains one or more intents that were recognized in the user input, sorted in descending order of confidence.\n\nEach intent has one property only: the confidence property. The confidence property is a decimal percentage that represents your assistant's confidence in the recognized intent.\n\nWhile testing your dialog, you can see details of the intents that are recognized in user input by specifying this expression in a dialog node response:\n\n<? intents ?>\n\nFor the user input, Hello now, your assistant finds an exact match with the #greeting intent. Therefore, it lists the #greeting intent object details first. The response also includes the top 10 other intents that are defined in the skill regardless of their confidence score. (In this example, its confidence in the other intents is set to 0 because the first intent is an exact match.) The top 10 intents are returned because the \"Try it out\" pane sends the alternate_intents:true parameter with its request. If you are using the API directly and want to see the top 10 results, be sure to specify this parameter in your call.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-expression-language"},{"document_id":"ibmcld_03369-1415-3586","score":19.7198158739,"text":"\nThese changes are the result of migrating the Watson Assistant platform to Java 17, where locale values are updated by using specifications in [CLDR 39](https:\/\/cldr.unicode.org\/index\/downloads\/cldr-39).\n\nTo avoid or minimize the impact of similar changes in the future, you can use [Actions display formats](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-global-settingsactions-global-settings-display-formats).\n\n\n\n\n\n 18 May 2023 \n\nDifferences in contextual entity detection for dialog skills with few annotations\n: If you have 10 to 20 examples of contextual entities in your dialog skill, you might see differences in the entities detected due to updates made to address critical vulnerabilities. The impact of these differences is limited to only newly-trained models. Existing models are unaffected. You can mitigate these differences by annotating more examples. For more information, see [Annotation-based method](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entitiesentities-annotations-overview).\n\n\n\n\n\n 15 May 2023 \n\nChange to dialog skill context variables named request\n: If your dialog skill used a context variable that is named request, it was removed from the response payload of any \/message calls in the V1 or V2 API, or through the Watson Assistant user interface. After 15 May 2023, this behavior changes. Watson Assistant doesn't remove context variables that are named request from the response payload anymore.\n\n\n\n\n\n 3 May 2023 \n\nAlgorithm version Beta provides improved intent detection and action matching\n: The algorithm version Beta now provides improved intent detection and action matching. It includes a new foundation model that is trained using a transformer architecture to improve intent detection and action matching for English.\n\nImprovements include:\n\n\n\n* Improved robustness to variations in user inputs such as typos and different inflection forms\n* Less training data required to reach the same level of performance compared to previous algorithms\n\n\n\nFor more information, see [Algorithm version and training](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-algorithm-version).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_16364-9056-11175","score":19.5603208428,"text":"\n15 May 2023 \n\nChange to dialog skill context variables named request\n: If your dialog skill used a context variable that is named request, it was removed from the response payload of any \/message calls in the V1 or V2 API, or through the Watson Assistant user interface. After 15 May 2023, this behavior changes. Watson Assistant doesn't remove context variables that are named request from the response payload anymore.\n\n\n\n\n\n 5 May 2023 \n\nNew validation choices for date, time, and numeric customer responses\n: For Number, Date, Time, Currency, and Percentage customer responses, you can now customize the validation to check for a specific answer, such as a range of dates or a limited currency amount. For more information, see [Customizing validation for a response](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errorscustomize-validation).\n\n\n\n\n\n 3 May 2023 \n\nAlgorithm version Beta provides improved intent detection and action matching\n: The algorithm version Beta now provides improved intent detection and action matching. It includes a new foundation model that is trained using a transformer architecture to improve intent detection and action matching for English.\n\nImprovements include:\n\n\n\n* Improved robustness to variations in user inputs such as typos and different inflection forms\n* Less training data required to reach the same level of performance compared to previous algorithms\n\n\n\nFor more information, see [Algorithm version and training](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-algorithm-version).\n\n\n\n\n\n 24 April 2023 \n\nResponse modes randomization behavior\n: The response modes beta now uses the same randomization behavior during clarification that your actions have without response modes enabled. Previous to this change, when response modes were enabled, the clarification feature no longer periodically modified the options for clarification. Randomizing the clarification helps prevent bias that can be introduced by a percentage of people who always pick the first option without carefully reviewing all of their choices beforehand.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-137757-139782","score":16.3010417385,"text":"\nThe spec.status field will contain details of your component's status:\n\n\n\n* errorCode\n* lastHeartbeatTime: when the controller last reconciled the component\n* message: long explanation of the status type\n* reason: short explanation of the status\n* status: \"true\" or \"false\" based on if status is valid\n* version: the product (IBP) version of the component\n* versions: the operand version of the component\n* type: describes the current status of the component\n\n\n\n* Deploying: component pod(s) spinning up but not yet running and ready\n* Deployed: component pod(s) are running\n* Precreated: (specific to the Orderer) Orderer is waiting for the genesis block to be created\n* Error: component hit an error during reconcile, or a certificate has expired\n* Warning: one or more of the component's certificate will be expiring within 30 days (by default)\n* Initializing: component is being reconciled again due to spec updates in the pre-reconcile checks\n\n\n\n\n\n* Do you support using certificates from non-IBM Certificate Authorities?\n\nYes, you can bring your own certificates if they are issued by a CA that is X.509 compliant. The CA should sign by using ECDSA and the defaults should be set to use P256 curve. See this topic about [Using certificates from an external CA with your peer or ordering node](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-third-party-ca).\n* What is the recommended way to manage private keys?\n\nBecause private keys are not stored by the platform, users are responsible for downloading and securing their private key. Therefore, when a higher level of security is required for private keys, an HSM is recommended. An HSM is a hardware appliance that performs cryptographic operations and provides the capability to ensure that the cryptographic keys never leave the HSM. Hyperledger Fabric supports HSM devices that implement the PKCS #11 standard. PKCS #11 is a cryptographic standard for secure operations, generation, and storage of keys.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-137731-139756","score":16.3010417385,"text":"\nThe spec.status field will contain details of your component's status:\n\n\n\n* errorCode\n* lastHeartbeatTime: when the controller last reconciled the component\n* message: long explanation of the status type\n* reason: short explanation of the status\n* status: \"true\" or \"false\" based on if status is valid\n* version: the product (IBP) version of the component\n* versions: the operand version of the component\n* type: describes the current status of the component\n\n\n\n* Deploying: component pod(s) spinning up but not yet running and ready\n* Deployed: component pod(s) are running\n* Precreated: (specific to the Orderer) Orderer is waiting for the genesis block to be created\n* Error: component hit an error during reconcile, or a certificate has expired\n* Warning: one or more of the component's certificate will be expiring within 30 days (by default)\n* Initializing: component is being reconciled again due to spec updates in the pre-reconcile checks\n\n\n\n\n\n* Do you support using certificates from non-IBM Certificate Authorities?\n\nYes, you can bring your own certificates if they are issued by a CA that is X.509 compliant. The CA should sign by using ECDSA and the defaults should be set to use P256 curve. See this topic about [Using certificates from an external CA with your peer or ordering node](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-third-party-ca).\n* What is the recommended way to manage private keys?\n\nBecause private keys are not stored by the platform, users are responsible for downloading and securing their private key. Therefore, when a higher level of security is required for private keys, an HSM is recommended. An HSM is a hardware appliance that performs cryptographic operations and provides the capability to ensure that the cryptographic keys never leave the HSM. Hyperledger Fabric supports HSM devices that implement the PKCS #11 standard. PKCS #11 is a cryptographic standard for secure operations, generation, and storage of keys.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_10074-17590-19225","score":15.0196540388,"text":"\n5.4.1 Prefer using secrets as files over secrets as environment variables Not Scored 1 [Fail](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-412ibm-remediations-and-explanations-412) Shared \n 5.4.2 Consider external secret storage Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-412ibm-remediations-and-explanations-412) Shared \n\n\n\n\n\n\n\n 5.5 Extensible admission control \n\n\n\nSection 5.5 Extensible admission control benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 5.5.1 Configure Image Provenance using ImagePolicyWebhook admission controller Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-412ibm-remediations-and-explanations-412) Shared \n\n\n\n\n\n\n\n 5.6 General policies \n\n\n\nSection 5.6 General policies benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 5.6.1 Create administrative boundaries between resources using namespaces Not Scored 1 Pass Shared \n 5.6.2 Ensure that the seccomp profile is set to docker\/default in your pod definitions Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-412ibm-remediations-and-explanations-412) Shared \n 5.6.3 Apply Security Context to Your Pods and Containers Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-412ibm-remediations-and-explanations-412) Shared \n 5.6.4 The default namespace should not be used Scored 2 Pass Shared \n\n\n\n\n\n\n\n IBM remediations and explanations \n\n\n\nExplanations and remediations\n\n Section Remediation\/Explanation","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-412"},{"document_id":"ibmcld_10073-17590-19223","score":15.0196540388,"text":"\n5.4.1 Prefer using secrets as files over secrets as environment variables Not Scored 1 [Fail](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-411ibm-remediations-and-explanations-411) Shared \n 5.4.2 Consider external secret storage Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-411ibm-remediations-and-explanations-411) Shared \n\n\n\n\n\n\n\n 5.5 Extensible admission control \n\n\n\nSection 5.5 Extensible admission control benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 5.5.1 Configure Image Provenance using ImagePolicyWebhook admission controller Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-411ibm-remediations-and-explanations-411) Shared \n\n\n\n\n\n\n\n 5.6 General policies \n\n\n\nSection 5.6 General policies benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 5.6.1 Create administrative boundaries between resources using namespaces Not Scored 1 Pass Shared \n 5.6.2 Ensure that the seccomp profile is set to docker\/default in your pod definitions Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-411ibm-remediations-and-explanations-411) Shared \n 5.6.3 Apply Security Context to Your Pods and Containers Not Scored 2 [Fail](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-411ibm-remediations-and-explanations-411) Shared \n 5.6.4 The default namespace should not be used Scored 2 Pass Shared \n\n\n\n\n\n\n\n IBM remediations and explanations \n\n\n\nExplanation and remediation\n\n Section Remediation\/Explanation","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-411"},{"document_id":"ibmcld_10048-9343-11078","score":14.8745842607,"text":"\nSection 5.5 Extensible admission control benchmark results\n\n Section Recommendation Manual\/Automated Level Result \n\n 5.5.1 Configure image provenance by using image controller configuration parameters. Manual 2 Not checked \n\n\n\n\n\n\n\n 5.7 General policies \n\n\n\nSection 5.7 General policies benchmark results\n\n Section Recommendation Manual\/Automated Level Result \n\n 5.7.1 Create administrative boundaries between resources by using namespaces. Manual 1 Not checked \n 5.7.2 Ensure that the seccomp profile is set to docker\/default in your pod definitions. Manual 2 Not checked \n 5.7.3 Apply security context to your pods and containers. Manual 2 Not checked \n 5.7.4 Do not use the default namespace. Automated 2 Not checked \n\n\n\n\n\n\n\n\n\n IBM Remediations and explanations \n\n\n\nRemediations and explanations\n\n Section Recommendation\/Explanation \n\n 1.2.4 Red Hat OpenShift on IBM Cloud configures the IBM Cloud IAM identity provider by default. \n 1.2.19 Test will properly ignore Red Hat OpenShift version 4.11 and later clusters when [https:\/\/github.com\/ComplianceAsCode\/compliance-operator\/issues\/77](https:\/\/github.com\/ComplianceAsCode\/compliance-operator\/issues\/77) is fixed. \n 1.2.23 Red Hat OpenShift on IBM Cloud can optionally enable Kubernetes API server auditing. \n 1.2.33 Red Hat OpenShift on IBM Cloud can optionally enable a Kubernetes Key Management Service (KMS) provider. \n 1.2.34 Red Hat OpenShift on IBM Cloud can optionally enable a Kubernetes Key Management Service (KMS) provider. \n 2.7 Red Hat OpenShift on IBM Cloud configures a unique certificate authority for etcd. \n 5.2.8 Red Hat OpenShift on IBM Cloud installs custom SCCs. \n 5.3.1 Review the [issue in GitHub](https:\/\/github.com\/ComplianceAsCode\/content\/issues\/9047).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-benchmarks_411_co"},{"document_id":"ibmcld_10074-15307-16773","score":14.8385312563,"text":"\n5.2.2 Minimize the admission of containers wishing to share the host process ID namespace Scored 1 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-412ibm-remediations-and-explanations-412) Shared \n 5.2.3 Minimize the admission of containers wishing to share the host IPC namespace Scored 1 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-412ibm-remediations-and-explanations-412) Shared \n 5.2.4 Minimize the admission of containers wishing to share the host network namespace Scored 1 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-412ibm-remediations-and-explanations-412) Shared \n 5.2.5 Minimize the admission of containers with allowPrivilegeEscalation Scored 1 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-412ibm-remediations-and-explanations-412) Shared \n 5.2.6 Minimize the admission of root containers Not Scored 2 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-412ibm-remediations-and-explanations-412) Shared \n 5.2.7 Minimize the admission of containers with the NET_RAW capability Not Scored 1 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-412ibm-remediations-and-explanations-412) Shared \n 5.2.8 Minimize the admission of containers with added capabilities Not Scored 1 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-412ibm-remediations-and-explanations-412) Shared","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-412"},{"document_id":"ibmcld_10072-15151-16626","score":14.8385312563,"text":"\nNot Scored 1 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410ibm-remediations-and-explanations-410) Shared \n 5.2.2 Minimize the admission of containers wanting to share the host process ID namespace. Scored 1 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410ibm-remediations-and-explanations-410) Shared \n 5.2.3 Minimize the admission of containers wanting to share the host IPC namespace. Scored 1 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410ibm-remediations-and-explanations-410) Shared \n 5.2.4 Minimize the admission of containers wanting to share the host network namespace. Scored 1 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410ibm-remediations-and-explanations-410) Shared \n 5.2.5 Minimize the admission of containers with allowPrivilegeEscalation. Scored 1 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410ibm-remediations-and-explanations-410) Shared \n 5.2.6 Minimize the admission of root containers. Not Scored 2 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410ibm-remediations-and-explanations-410) Shared \n 5.2.7 Minimize the admission of containers with the NET_RAW capability. Not Scored 1 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410ibm-remediations-and-explanations-410) Shared \n 5.2.8 Minimize the admission of containers with added capabilities.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410"},{"document_id":"ibmcld_10073-15307-16773","score":14.8385312563,"text":"\n5.2.2 Minimize the admission of containers wishing to share the host process ID namespace Scored 1 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-411ibm-remediations-and-explanations-411) Shared \n 5.2.3 Minimize the admission of containers wishing to share the host IPC namespace Scored 1 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-411ibm-remediations-and-explanations-411) Shared \n 5.2.4 Minimize the admission of containers wishing to share the host network namespace Scored 1 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-411ibm-remediations-and-explanations-411) Shared \n 5.2.5 Minimize the admission of containers with allowPrivilegeEscalation Scored 1 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-411ibm-remediations-and-explanations-411) Shared \n 5.2.6 Minimize the admission of root containers Not Scored 2 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-411ibm-remediations-and-explanations-411) Shared \n 5.2.7 Minimize the admission of containers with the NET_RAW capability Not Scored 1 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-411ibm-remediations-and-explanations-411) Shared \n 5.2.8 Minimize the admission of containers with added capabilities Not Scored 1 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-411ibm-remediations-and-explanations-411) Shared","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-411"},{"document_id":"ibmcld_10078-15430-16891","score":14.8385312563,"text":"\nNot Scored 1 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-49ibm-remediations-and-explanations-49) Shared \n 5.2.2 Minimize the admission of containers wanting to share the host process ID namespace. Scored 1 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-49ibm-remediations-and-explanations-49) Shared \n 5.2.3 Minimize the admission of containers wanting to share the host IPC namespace. Scored 1 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-49ibm-remediations-and-explanations-49) Shared \n 5.2.4 Minimize the admission of containers wanting to share the host network namespace. Scored 1 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-49ibm-remediations-and-explanations-49) Shared \n 5.2.5 Minimize the admission of containers with allowPrivilegeEscalation. Scored 1 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-49ibm-remediations-and-explanations-49) Shared \n 5.2.6 Minimize the admission of root containers. Not Scored 2 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-49ibm-remediations-and-explanations-49) Shared \n 5.2.7 Minimize the admission of containers with the NET_RAW capability. Not Scored 1 [Pass](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-49ibm-remediations-and-explanations-49) Shared \n 5.2.8 Minimize the admission of containers with added capabilities.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-49"},{"document_id":"ibmcld_10051-9313-11116","score":14.761538141,"text":"\nSection 5.5 Extensible admission control benchmark results\n\n Section Recommendation Manual\/Automated Level Result \n\n 5.5.1 Configure image provenance by using image controller configuration parameters. Manual 2 Not checked \n\n\n\n\n\n\n\n 5.7 General policies \n\n\n\nSection 5.7 General policies benchmark results\n\n Section Recommendation Manual\/Automated Level Result \n\n 5.7.1 Create administrative boundaries between resources by using namespaces. Manual 1 Not checked \n 5.7.2 Ensure that the seccomp profile is set to docker\/default in your pod definitions. Manual 2 Not checked \n 5.7.3 Apply security context to your pods and containers. Manual 2 Not checked \n 5.7.4 Do not use the default namespace. Automated 2 Not checked \n\n\n\n\n\n\n\n\n\n IBM Remediations and explanations \n\nReview information from IBM Cloud about the CIS Benchmark results.\n\n\n\nRemediations and explanations\n\n Section Recommendation\/Explanation \n\n 1.2.4 Red Hat OpenShift on IBM Cloud configures the IBM Cloud IAM identity provider by default. \n 1.2.19 Test will properly ignore Red Hat OpenShift version 4.11 and later clusters when [https:\/\/github.com\/ComplianceAsCode\/compliance-operator\/issues\/77](https:\/\/github.com\/ComplianceAsCode\/compliance-operator\/issues\/77) is fixed. \n 1.2.23 Red Hat OpenShift on IBM Cloud can optionally enable Kubernetes API server auditing. \n 1.2.33 Red Hat OpenShift on IBM Cloud can optionally enable a Kubernetes Key Management Service (KMS) provider. \n 1.2.34 Red Hat OpenShift on IBM Cloud can optionally enable a Kubernetes Key Management Service (KMS) provider. \n 2.7 Red Hat OpenShift on IBM Cloud configures a unique certificate authority for etcd. \n 5.2.8 Red Hat OpenShift on IBM Cloud installs custom SCCs. \n 5.3.1 Review the [issue in GitHub](https:\/\/github.com\/ComplianceAsCode\/content\/issues\/9047).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-benchmarks_49_co"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16314-2927-4978","score":17.1650944165,"text":"\nAdd a step or edit an existing step to transfer the conversation to a live agent.\n\nTransferring the conversation to a live agent ends the action. If there are situations where you want the conversation to continue within the assistant rather than being transferred, use step conditions as needed.\n2. In the And then field at the end of the step, select Connect to agent.\n3. In the Settings window, you can customize messages the assistant displays as part of the transfer:\n\n![Connect to agent settings](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/connect-agent-settings.png)\n\n\n\n* Response if agents are online: The message the assistant sends to the customer when the conversation is being transferred to an agent. The default message is Let's send you to an available agent.\n* Response if agents are offline: The message the assistant sends to the customer when no agents are currently available to take over the conversation. The default message is There are no agents available at this time. When one becomes available, we'll connect you.\n* Message to agent: An optional message the assistant sends to the live agent when transferring the conversation.\n* Route to a specific queue: An optional selection to route customers to a specific integration, which can be helpful if you have more than one set up.\n\n\n\n4. Click Apply.\n\n\n\nIf you want to edit the transfer settings later, click Edit settings in the And then field.\n\n\n\n\n\n Fallback escalations \n\nExamples of fallback escalations include:\n\n\n\n* The customer repeatedly asks a question or makes a request that the assistant cannot match to any defined action.\n* The customer repeatedly gives an invalid answer to a question.\n* The customer explicitly asks to speak to a human.\n\n\n\nFallback escalations use the Fallback action, which is a built-in system action that is automatically triggered in any of these fallback scenarios. By default, the Fallback action handles these error conditions by initiating a transfer to a live agent.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-human-agent"},{"document_id":"ibmcld_16259-1485-3642","score":17.01485517,"text":"\nUnique user is anyone who interacts with your assistant. User ID identifies each user, using a unique label to track the level of service usage. A unique user can have multiple conversations, but a conversation never has more than one unique user.\n\nConversation is a set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back. Conversations can have multiple requests within a single conversation, but a single request doesn't span more than 1 conversation.\n\nRequest is a root-level utterance, such as an initial question or request, that signals the start of a specific flow. A user can initiate multiple requests. Requests are meant to represent the core concepts or topics your users are asking about. A request can have multiple steps within it, for example I want to order a pizza is a request. Delivery\/takeout, Small\/Medium\/Large, Cheese\/Pepperoni\/Mushrooms\/Peppers are all steps within the request of ordering a pizza.\n\n\n\n\n\n Completion and recognition \n\nThe completion and recognition charts provide information about the actions in your assistant.\n\n![Completion and recognition](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-completion-recognition-2.png)\n\n\n\n Completion \n\nCompletion is the measurement of how often users are able to successfully get through all steps of an action.\n\nYour assistant measures when someone reaches the final step of an action. The completion chart provides an overview of all the actions you have built and how many of these are being completed or not.\n\nCompletion is only applicable when a user question or request matched to an action, and the action starts.\n\nOne action can be triggered multiple times, so to better understand individual action performance, click Action completion to understand each action in more detail.\n\n\n\n\n\n Recognition \n\nRecognition is the measurement of how many requests are being recognized by the assistant and routed into starting an action.\n\nThe recognition chart provides you with a view into how many requests are matched to actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-overview"},{"document_id":"ibmcld_01178-16125-18417","score":16.6616287923,"text":"\nKafka quotas use sampling to determine how long clients should be paused before they can send or receive more data. For unpredictable workloads, or configurations that result in quota decisions being made using only a few samples, you might observe the percentage quota used metric going above 100%.\n\n\n\n Authentication failures \n\nIncrementing count of the number of authentication failures\n\n\n\nTable 7. Authentication failures metric metadata\n\n Metadata Description \n\n Metric Name ibm_eventstreams_kafka_authentication_failure_total \n Metric Type counter \n Value Type none \n Segment By Service instance, Service instance name \n\n\n\nIdeally zero. A nonzero value on this indicates that clients attempt to connect by using invalid credentials. Ensure that all clients are using valid credentials.\n\n\n\n\n\n Consume message conversion time \n\nIndicates that the accumulated time spent performing message conversion from clients that are consuming by using older protocol versions.\n\n\n\nTable 8. Consume message conversion time metric metadata\n\n Metadata Description \n\n Metric Name ibm_eventstreams_instance_consume_conversions_time_quantile \n Metric Type gauge \n Value Type second \n Segment By Service instance, Quantile, Service instance name \n\n\n\nIdeally zero, as nonzero indicates that clients are experiencing more latency because of using an older protocol level. Those clients are down-level and must be upgraded. Ensure that all clients are at the latest levels.\n\n\n\n\n\n Estimated connected clients percentage \n\nThe percentage of maximum number of connected clients.\n\n\n\nTable 9. Estimated connected clients percentage metric metadata\n\n Metadata Description \n\n Metric Name ibm_eventstreams_kafka_recommended_max_connected_clients_percent \n Metric Type gauge \n Value Type percent \n Segment By Service instance, Service instance name \n\n\n\nThis is for information to help you monitor trends in your usage. See [Choosing your plan](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-plan_choose) to determine what the recommended limits are for your plan and cluster.\n\n\n\n\n\n Connected clients software name and version \n\nThe number of connected clients with a particular client software name and version.\n\n\n\nTable 10. Connected clients software name and version metric metadata\n\n Metadata Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-metrics"},{"document_id":"ibmcld_16250-1908-4265","score":16.5549613258,"text":"\nHowever, using an active\/active topology likely requires using [webhooks](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-webhook-overview) to gather interaction data, and build custom data warehouses and reports to understand total usage.\n\n\n\n\n\n Session history for web chat and the v2 api \n\nSession history allows your web chats to maintain conversation history and context when users refresh a page or change to a different page on the same website. This feature doesn't work across instances, so in-progress conversations need to be restarted.\n\n\n\n\n\n Billing \n\nIBM calculates your bill based on the IBM Cloud Account. Watson Assistant calculates monthly average user (MAU) metrics by aggregating within a given service instance as follows:\n\n\n\n* The same MAU used in 2 different assistant resources in the same service instance counts as 1 MAU\n* The same MAU used in 2 different assistant resources in different service instances counts as 2 MAUs\n\n\n\nNote that for an active\/active topology, under the worst case scenario, the MAU count could end up being doubled for a given billing period.\n\n\n\n\n\n\n\n Phone integration \n\nA Watson Assistant phone integration in one region is unaware of a phone integration in a different region. You need to ensure that your assistants are identically configured in both regions. You also need to rely on the upstream SIP trunking provider to detect and manage failing over between regions.\n\n\n\n Monitoring \n\nSIP trunking providers can be configured to actively health-check the Watson Assistant session border controllers (SBCs) by sending periodic SIP OPTIONS messages to each zone within a region. A failure to receive a response from one of the zones being health-checked can be used to either provide notification of a failure to trigger a manual failover, or it can be used to automate removal of the failed zone from the route list.\n\n\n\n\n\n Failover \n\nThe SIP trunking provider plays an important role in detecting and managing a failover, especially if an automatic failover is expected between regions. In most cases, SIP trunking providers should be configured to treat each zone within a region as active\/active and two regions where an assistant is configured as active\/passive. SIP trunking providers should always be configured to load balance and fail over between zones within a single region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-failover"},{"document_id":"ibmcld_02898-0-1202","score":16.1952140076,"text":"\n\n\n\n\n\n\n  Planning the dialog \n\nLearn how to approach building a dialog.\n\n\n\n*  Plan out the design of the dialog that you want to build before you add a single dialog node. Sketch it out on paper, if necessary.\n*  Whenever possible, base your design decisions on data from real-world evidence and behaviors. Do not add nodes to handle a situation that someone thinks might occur.\n*  Avoid copying business processes as-is. They are rarely conversational.\n*  If people already use a process, examine how they approach it. People typically optimize the process from a conversational perspective.\n*  Decide on the tone, personality, and positioning of your assistant. Consistently reflect these choices in the dialog you create.\n*  Never misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it.\n*  Not everything has to be a conversation. Sometimes a web form works better.\n\n\n\nPrevious topic:[Dialog overview](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-build)\n\nNext topic:[Building a conversational flow](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview)\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-plan"},{"document_id":"ibmcld_14420-2835-4826","score":15.9349235298,"text":"\n4. Click Apply.\n\n\n\nFor stretched L2 bandwidth throttling, QoS can be employed for UDP 500 and 4500 for the tunnel traffic between the L2C appliances.\n\n\n\n\n\n\n\n Monitoring HCX components \n\nMonitor HCX components such as HCX Manager, Cloud Gateway, WAN opt, and the Layer 2 Concentrator operations in the following ways:\n\n\n\n* Configure HCX Manager to send logs to a syslog server. Use the HCX Manager appliance management utility to run the https:\/\/<hcxhostname or IP>:9443 command.\n* Set up a ping to a VM that is migrated before network swing for each stretched L2 network.\n* Monitor the HCX component VM health with VMware Aria\u00ae Operations\u2122 Manager or other VMware VM monitoring tools.\n\n\n\n\n\n\n\n Bandwidth use \n\nUse the following methods to monitor bandwidth use and latency.\n\n\n\n* vMotion traffic is best accomplished by using the WAN Opt web UI. The WAN Opt reduces the traffic that is going over the WAN and reduces packet loss by sending redundant packets. IThe typical ratio LAN to WAN bandwidth usage is approximately 3:1 (350 Mbps LAN = 90-120Mbps WAN).\n* Replication-based (bulk) migration of VMs within HCX results in VMs being moved with thick provisioning. While this method is not desirable, the WAN opt UI reveals a high ratio between LAN and WAN use when you move unused disk data. Conversely, it is observed that when non-compressible data is migrated, such as DB data and digital media, WAN use is at its highest and it comes closer to LAN use.\n\n\n\n\n\n Observations \n\n\n\n* The vMotion migration of a VM within HCX does not generate more throughput than the vMotion networking for a single ESXi host.\n* As bulk migration can have multiple migrations in flight simultaneously, it achieves higher bandwidth use than a vMotion migration. The ratio observed at a customer side with 1 Gbps vMotion links to the ESX hosts was of 8 replications = bandwidth use of 1 vMotion.\n* As a result of moving empty space on disk, a high LAN use with a high ratio is displayed, therefore, low WAN use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-hcxclient-monitoring"},{"document_id":"ibmcld_02844-4-2018","score":15.7421633271,"text":"\n{{site.data.content.newlink}}\n\n\n\n Audit events \n\nAs a security officer, auditor, or manager, you can use the [IBM Cloud Pak for Data audit service](https:\/\/www.ibm.com\/docs\/en\/cloud-paks\/cp-data\/latest?topic=considerations-auditing-cloud-pak-data) to track how users and applications interact with Watson Assistant.\n\nIBM Cloud Pak for Data audit service records user-initiated activities that change the state of a service in Watson Assistant. You can use this service to investigate abnormal activity and critical actions and to comply with regulatory audit requirements. For more information about exporting audit records to your security information and event management (SIEM) solutions, see [Auditing Cloud Pak for Data](https:\/\/www.ibm.com\/docs\/en\/cloud-paks\/cp-data\/latest?topic=considerations-auditing-cloud-pak-data).\n\n\n\n List of events \n\nThe following table lists the Watson Assistant activities that generate events.\n\n\n\nTable 1. Activities that generate events\n\n Action Triggered when someone... \n\n conversation.assistant.create creates an assistant. \n conversation.assistant.delete deletes an assistant. \n conversation.assistant.update updates an assistant. For example, renames the skill, changes the session timeout, or changes its associated skills. \n conversation.counterexample.create marks test user input in the Try it out pane as being irrelevant or corrects the categorization of a user input that was incorrectly assigned to an intent by marking it as irrelevant. \n conversation.counterexample.delete deletes a counterexample. \n conversation.counterexample.update edits a counterexample. \n conversation.data.update does a bulk action, such as importing a CSV file of intents or entities to the skill, or deleting multiple training data items, such as multiple entities or intents. \n conversation.entity.create creates an entity. \n conversation.entity.delete deletes an entity. \n conversation.entity.update edits an entity. \n conversation.example.create adds a user input example to an intent.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-audit-events"},{"document_id":"ibmcld_03273-3976-5874","score":15.2008529361,"text":"\nTo add a context variable, specify the variable name, and press Enter.\n2. To define a default value for the context variable, find the context variable you added in the list, and then specify a value for it.\n\n\n\nSee [Context variables](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-context) for more information.\n8. Continue to interact with the dialog to see how the conversation flows through it.\n\n\n\n* To find and resubmit a test utterance, you can press the Up key to cycle through your recent inputs.\n* To remove prior test utterances from the chat pane and start over, click the Clear link. Not only are the test utterances and responses removed, but this action also clears the values of any context variables that were set as a result of your interactions with the dialog.\n\n\n\n\n\n\n\n What to do next \n\nMake changes to the dialog to address issues you see when testing:\n\n\n\n* If you determine that the wrong intents or entities are being recognized, you might need to modify your intent or entity definitions.\n* If the correct intents and entities are being recognized, but the wrong nodes are being triggered in your dialog, make sure your conditions are written properly.\n\n\n\nIf you are ready to put the conversation to work helping your users, integrate your assistant with a messaging platform or custom application. See [Adding integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add).\n\n\n\n\n\n\n\n Searching your dialog \n\nYou can search the dialog to find one or more dialog nodes that mention a given word or phrase.\n\n\n\n1. Select the Search icon: ![Search icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/search_icon.png)\n2. Enter a search term or phrase.\n\nThe first time you search, an index is created. You might be asked to wait while the text in your dialog nodes is indexed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks"},{"document_id":"ibmcld_03285-13886-15581","score":15.0844689273,"text":"\nOnly changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_03109-8981-10943","score":15.0451039995,"text":"\nOnly data that was added by using the POST \/message API endpoint with an associated customer ID can be deleted using this delete method. Data that was added by other methods cannot be deleted based on customer ID. For example, entities and intents that were added from customer conversations, cannot be deleted in this way. Personal Data is not supported for those methods.\n\nIMPORTANT: Specifying a customer_id will delete all messages with that customer_id that were received before the delete request, across your entire Watson Assistant instance, not just within one skill.\n\nAs an example, to delete any message data associated with a user that has the customer ID abc from your Watson Assistant instance, send the following cURL command:\n\ncurl -X DELETE -u \"apikey:3Df... ...Y7Pc9\" \"{url}\/v2\/user_data?customer_id=abc&version=2020-04-01\"\n\nwhere {url} is the appropriate URL for your instance. For more details, see [Service endpoint](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2service-endpoint).\n\nAn empty JSON object {} is returned.\n\nFor more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2deleteuserdata).\n\nNote: Delete requests are processed in batches and may take up to 24 hours to complete.\n\n\n\n\n\n\n\n Web chat usage data \n\nThe Watson Assistant web chat sends limited usage data to the [Amplitude service](https:\/\/amplitude.com\/). When the web chat widget is being interacted with by a user, we track the features that are being used, and events such as how many times the widget is opened and how many users start conversations. This information does not include Assistant training data or the content of any chat interactions. The information being sent to Amplitude is not Content as defined in the Cloud Service Agreement (CSA); it is Account Usage Information as described in Section 9.d of the CSA and is handled accordingly as described in the [IBM Privacy Statement](https:\/\/www.ibm.com\/privacy).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-securing"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16306-8539-10329","score":25.5417942308,"text":"\nIf no utterance is received before the timeout occurs, the phone integration sends a message to the assistant that includes the post_response_timeout_occurred property set to true. \n cdr_custom_data Object A JSON object containing key\/value pairs to be stored in the CDR record for the call. Each time this object is sent, its contents are merged with data sent previously during the call. \n turn_settings.timeout_count Integer The time (in milliseconds) to wait for Watson Assistant to finish processing each conversation turn. \n\n\n\n\n\n\n\n Example request JSON \n\n\"voice_telephony\" : {\n\"post_response_timeout_count\":10000,\n\"final_utterance_timeout_count\":30000,\n\"turn_settings\": {\n\"timeout_count\": 5000\n},\n\"cdr_custom_data\" : {\n\"custom_data_1\": \"data 1\",\n\"custom_data_2\": \"data 2\"\n}\n}\n\n\n\n\n\n\n\n text_messaging \n\nIncluded only if the SMS with Twilio integration is in use.\n\n\n\n Properties \n\nProperties contained in the private object are treated as private variables, which are not included in logs.\n\n\n\nProperties of the text_messaging object\n\n Name Type Description \n\n assistant_phone_number String The phone number associated with with the Watson Assistant end of the conversation. \n private.user_phone_number String The phone number from which the customer's SMS message originated. \n\n\n\n\n\n\n\n Example JSON \n\n\"text_messaging\": {\n\"private\":{\n\"user_phone_number\":\"+18595553456\"\n},\n\"assistant_phone_number\":\"+18885556789\"\n}\n\n\n\n\n\n\n\n whatsapp \n\nIncluded only if the WhatsApp integration is in use.\n\n\n\n Properties \n\nProperties contained in the private object are treated as private variables, which are not included in logs.\n\n\n\nProperties of the whatsapp object\n\n Name Type Description \n\n assistant_phone_number String The phone number associated with with the Watson Assistant end of the conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-expression-integration-variables"},{"document_id":"ibmcld_16261-12076-14011","score":23.4575185303,"text":"\nBecause we are using the stateless message method, the assistant does not store the context, so it is the responsibility of our client application to maintain it from one turn of the conversation to the next.\n\nThe context includes a session ID for each conversation, as well as a counter that is incremented with each turn of the conversation. The assistant updates the context and returns it with each response. But our previous version of the example did not preserve the context, so these updates were lost, and each round of input appeared to be the start of a new conversation. We can fix that by saving the context and sending it back to the assistant each time.\n\nIn addition to maintaining our place in the conversation, the context can also contain action variables that store any other data you want to pass back and forth between your application and the assistant. This can include persistent data you want to maintain throughout the conversation (such as a customer's name or account number), or any other data you want to track (such as the contents of a shopping cart or user preferences).\n\n\n\n* Python\n* Node\n\n\n\n Example 3: Preserves context to maintain state.\n\nfrom ibm_watson import AssistantV2\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n\n Create Assistant service object.\nauthenticator = IAMAuthenticator('{apikey}') replace with API key\nassistant = AssistantV2(\nversion = '2021-11-27',\nauthenticator = authenticator\n)\nassistant.set_service_url('{url}') replace with service instance URL\nassistant_id = '{environment_id}' replace with environment ID\n\n Initialize with empty message to start the conversation.\nmessage_input = {\n'message_type:': 'text',\n'text': ''\n}\ncontext = {}\n\n Initialize with empty message to start the conversation.\nmessage_input = {\n'message_type:': 'text',\n'text': ''\n}\ncontext = {}\n\n Main input\/output loop\nwhile message_input['text'] != 'quit':\n\n Send message to assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client"},{"document_id":"ibmcld_16322-7-2220","score":23.2793666526,"text":"\nPhone integration context variables \n\nYou can use context variables to manage the flow of conversations with customers who interact with your assistant over the telephone.\n\nThe following tables describe the context variables that have special meaning in the context of the phone integration. They should not be used for any purpose other than the documented use.\n\n\n\n Context variables that are set by the phone channel \n\n\n\nContext variables set by the phone channel\n\n Name Type Description \n\n sip_call_id string The SIP call ID associated with the Watson Assistant session. \n sip_custom_invite_headers object A JSON object containing key\/value pairs defining SIP headers that are pulled from the initial SIP INVITE request and passed to the Watson Assistant service (for example, {\"Custom-Header1\": \"123\"}). \n private.sip_from_uri string The SIP From URI associated with the Watson Assistant service. \n private.sip_request_uri string The SIP request URI that started the conversation session. \n private.sip_to_uri string The SIP To URI associated with the conversation session. \n private.user_phone_number string The phone number that the call was received from. \n assistant_phone_number string The phone number associated with the Watson Assistant side that received the phone call. \n\n\n\n\n\n\n\n Input parameters that are set by the phone channel \n\nThe following input parameters are only valid for the current conversation turn.\n\n\n\nInput parameters set by the phone channel\n\n Name Type Description \n\n post_response_timeout_occurred boolean Whether the post response timeout expired. \n barge_in_occurred boolean Whether barge-in occurred. \n final_utterance_timeout_occurred true or false Whether the final utterance timeout expired. \n dtmf_collection_succeeded boolean Whether the DTMF collection succeeded or failed. When true, a DTMF collection succeeded, and returns the expected number of digits. When false, a DTMF collection failed to collect the specified number of digits. Even when dtmf_collection_succeeded is false, all collected digits are passed to the dialog in the input string of the turn request. \n is_dtmf boolean Whether the input to Watson Assistant is dual-tone multi-frequency signaling (DTMF).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-context"},{"document_id":"ibmcld_03367-2935-4844","score":23.2663386263,"text":"\nprivate.sip_request_uri string The SIP request URI that started the conversation session. \n private.sip_to_uri string The SIP To URI associated with the conversation session. \n private.user_phone_number string The phone number that the call was received from. \n assistant_phone_number string The phone number associated with the Watson Assistant side that received the phone call. \n\n\n\n\n\n\n\n Input parameters that are set by the phone channel \n\nThe following input parameters are only valid for the current conversation turn.\n\n\n\nInput parameters set by the phone channel\n\n Name Type Description \n\n post_response_timeout_occurred boolean Whether the post response timeout expired. \n barge_in_occurred boolean Whether barge-in occurred. \n final_utterance_timeout_occurred true or false Whether the final utterance timeout expired. \n dtmf_collection_succeeded boolean Whether the DTMF collection succeeded or failed. When true, a DTMF collection succeeded, and returns the expected number of digits. When false, a DTMF collection failed to collect the specified number of digits. Even when dtmf_collection_succeeded is false, all collected digits are passed to the dialog in the input string of the turn request. \n is_dtmf boolean Whether the input to Watson Assistant is dual-tone multi-frequency signaling (DTMF). \n speech_to_text_result object The final response from the Speech to Text service in JSON format, including the transcript and confidence score for the top hypothesis and any alternatives. The format matches exactly the format that is received from the Speech to Text service. (For more information, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-textrecognize).) \n\n\n\n\n\n Example \n\n{\n\"input\": {\n\"text\": \"agent \",\n\"integrations\": {\n\"voice_telephony\": {\n\"speech_to_text_result\": {\n\"result_index\": 0,\n\"stopTimestamp\": \"2021-09-29T17:43:31.036Z\",\n\"transaction_ids\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-phone-context"},{"document_id":"ibmcld_03367-1712-3458","score":23.1150904348,"text":"\nIf this time is exceeded, the phone integration tries again to contact Watson Assistant. If the service still can't be reached, the call fails. N\/A \n cdr_custom_data object Any JSON key\/value pairs to collect and store with the CDR record at the end of the phone call. Each time this object is received, it is merged with any previously received cdr_custom_data context. N\/A \n\n\n\n\n\n Example \n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"text\",\n\"text\": \"Hello\"\n}\n]\n},\n\"context\": {\n\"integrations\": {\n\"voice_telephony\": {\n\"post_response_timeout_count\": 10000,\n\"turn_settings\": {\n\"timeout_count\": 5000\n},\n\"cdr_custom_data\": {\n\"key1\": \"value1\",\n\"key2\": \"value2\"\n}\n}\n}\n}\n}\nShow more\n\n\n\n\n\n\n\n Context variables that are set by the phone channel \n\n\n\nContext variables set by the phone channel\n\n Name Type Description \n\n sip_call_id string The SIP call ID associated with the Watson Assistant session. \n sip_custom_invite_headers object A JSON object containing key\/value pairs defining SIP headers that are pulled from the initial SIP INVITE request and passed to the Watson Assistant service (for example, {\"Custom-Header1\": \"123\"}). \n private.sip_from_uri string The SIP From URI associated with the Watson Assistant service. \n private.sip_request_uri string The SIP request URI that started the conversation session. \n private.sip_to_uri string The SIP To URI associated with the conversation session. \n private.user_phone_number string The phone number that the call was received from. \n assistant_phone_number string The phone number associated with the Watson Assistant side that received the phone call. \n\n\n\n\n\n\n\n Input parameters that are set by the phone channel \n\nThe following input parameters are only valid for the current conversation turn.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-phone-context"},{"document_id":"ibmcld_16261-10613-12744","score":22.2376778951,"text":"\nBecause we need a way to end the conversation, the client app is also watching for the literal command quit to indicate that the program should exit.\n\nBut something still isn't right:\n\nWelcome to the Watson Assistant example. What's your name?\n>> Robert\nI'm afraid I don't understand. Please rephrase your question.\n>> I want to make an appointment.\nWhat day would you like to come in?\n>> Thursday\nI'm afraid I don't understand. Please rephrase your question.\n>>\n\nThe assistant is starting out with the correct greeting, but it doesn't understand when you tell it your name. And if you tell it you want to make an appointment, the correct action is triggered; but once again, it doesn't understand when you answer the follow-up question.\n\nThis is happening because we are using the stateless message method, which means that it is the responsibility of our client application to maintain state information for the conversation. Because we are not yet doing anything to maintain state, the assistant sees every round of user input as the first turn of a new conversation. Because it has no memory of asking a question, it tries to interpret your answer as a new question or request.\n\n\n\n\n\n Maintaining state \n\nState information for your conversation is maintained using the context. The context is an object that is passed back and forth between your application and the assistant, storing information that can be preserved and updated as the conversation goes on. Because we are using the stateless message method, the assistant does not store the context, so it is the responsibility of our client application to maintain it from one turn of the conversation to the next.\n\nThe context includes a session ID for each conversation, as well as a counter that is incremented with each turn of the conversation. The assistant updates the context and returns it with each response. But our previous version of the example did not preserve the context, so these updates were lost, and each round of input appeared to be the start of a new conversation. We can fix that by saving the context and sending it back to the assistant each time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client"},{"document_id":"ibmcld_16262-6573-7996","score":21.9259927554,"text":"\n{\n\"output\": {\n\"generic\": [!\n{\n\"response_type\": \"text\",\n\"text\": \"Welcome to the Watson Assistant example\"\n}\n],\n\"intents\": [\n{\n\"intent\": \"hello\",\n\"confidence\": 1\n}\n],\n\"entities\": []\n},\n\"user_id\": \"my_user_id\",\n\"context\": {\n\"global\": {\n\"system\": {\n\"turn_count\": 1,\n\"user_id\": \"my_user_id\"\n}\n},\n\"skills\": {\n\"main skill\": {\n\"user_defined\": {\n\"account_number\": \"123456\"\n}\n}\n}\n}\n}\nShow more\n\n\n\n\n\n Restoring conversation state \n\nIn some situations, you might want the ability to restore a conversation to a previous state.\n\nYou can use the export option on stateful message requests to specify that you want the context object in the response to include complete session state data. If you specify true for this option, the returned skill context includes an encoded state property that represents the current conversation state.\n\nIf you are using the stateful message API, the service stores conversation state data only for the life of the session. However, if you save this context data (including state) and send it back to the service with a subsequent message request, you can restore the conversation to the same state, even if the original session expired or was deleted.\n\nIf you are using the stateless message API, the state property is always included in responses (along with the rest of context). Although stateless sessions do not expire, you can still use this state data to reset a conversation to a previous state.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client-get-context"},{"document_id":"ibmcld_03423-14168-15303","score":21.6885027742,"text":"\nThe assistant_interaction_summaries object contains the following keys:\n\n\n\nKeys for the assistant_interaction_summaries object\n\n Key Type Description \n\n assistant_id string The unique identifier of the assistant. \n session_id string The unique identifier of the session. \n turns JSON array An array of the Watson Assistant transactions that took place during the conversation. \n\n\n\nThe turn object contains the following keys:\n\n\n\nKeys for the turn object\n\n Key Type Description \n\n assistant.log_id string A unique identifier for the logged transaction. Can be used to correlate between message logs and CDR events. \n assistant.start_timestamp string. Time in the ISO format yyyy-MM-ddTHH:mm:ss.SSSZ Time when the request was sent to Watson Assistant. \n assistant.response_milliseconds number Time between when the request was sent and when the response was received from Watson Assistant. \n request JSON object A request sent to Watson Assistant. \n response JSON array An array of the response objects associated with the request. \n\n\n\nThe request object contains the following keys:\n\n\n\nKeys for the request object\n\n Key Type Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-log"},{"document_id":"ibmcld_16274-4164-6148","score":21.3993384934,"text":"\nheaders.from_uri String The SIP URI from the initial SIP INVITE From header. \n headers.to_uri String The SIP URI from the initial SIP INVITE To header. \n\n\n\n\n\n\n\n assistant_interaction_summaries \n\nThe assistant_interaction_summaries object contains the following properties:\n\n\n\nProperties of the assistant_interaction_summaries object\n\n Property Type Description \n\n assistant_id String The unique identifier of the assistant. \n session_id String The unique identifier of the session. \n turns Array An array of objects describing the Watson Assistant interactions that took place during the conversation. See [assistant_interaction_summaries.turns]](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-cdr-log-referencecdr-log-reference-turns). \n\n\n\n\n\n assistant_interaction_summaries.turns[] \n\nThe objects in the assistant_interaction_summaries.turns array contain the following properties:\n\n\n\nProperties of the objects in the assistant_interaction_summaries.turns[] array\n\n Property Type Description \n\n assistant.log_id String A unique identifier for the logged event. This can be used to correlate between message logs and CDR events. \n assistant.start_timestamp String The time when the request was sent to the assistant, in ISO format (yyyy-MM-ddTHH:mm:ss.SSSZ). \n assistant.response_milliseconds Number The time (in milliseconds) between when the request was sent and when the response was received from the assistant. \n request Object A request sent to the assistant. See [assistant_interaction_summaries.turns].request](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-cdr-log-referencecdr-log-reference-request). \n response Array An array of the response objects associated with the request. \n\n\n\n\n\n assistant_interaction_summaries.turns[].request \n\nThe assistant_interaction_summaries.turns[].request object contains the following properties:\n\n\n\nProperties of the assistant_interaction_summaries.turns[].request object\n\n Property Type Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-cdr-log-reference"},{"document_id":"ibmcld_03285-32947-34893","score":21.2119498643,"text":"\nTo send me your street address, respond to this text message with your address.\"\n}\n}\n}\n}\n]\n}\n}\nShow more\n\nYou can specify any of the following parameters in the parameters object:\n\n\n\n Parameter Type Description \n\n message string The text of the SMS message to send. Required. \n mediaURL list A list of URLs for media files to be sent with the message as MMS attachments. Optional. \n tenantPhoneNumber string The phone number that is associated with the tenant. The format of the number must match the format that is required by the SMS provider. If no tenantPhoneNumber value is provided, the tenant ID from the phone integration configuration for the active call is used. Optional. \n userPhoneNumber string The phone number to send the SMS message to. The format of the number must match the format that is required by the SMS provider. If no userPhoneNumber value is provided, the voice caller's phone number from From header of the incoming SIP INVITE request is used. Optional. \n\n\n\nIf your SMS with Twilio integration supports more than one SMS phone number, or you are using a non-Twilio SIP trunk, be sure to specify the phone number that you want to use to send the text message. Otherwise, the text is sent using the same phone number that was called.\n\nAfter the assistant receives an SMS message, a new conversation turn is initiated with the text input vgwSMSMessage. This input indicates that a message was received from the caller. The text of the customer's message is included as the value of the vgwSMSMessagecontext variable.\n\nIf the assistant is unable to send an SMS message to the caller, a new turn is initiated with the text input vgwSMSFailed. This input indicates that an SMS message could not be sent the caller. You can design your dialog or actions to handle such a failure by creating intents or actions that are triggered by the input text vgwSMSFailed.\n\n{\n\"input\": {\n\"message_type\": \"text\",\n\"text\": \"vgwSMSMessage\"\n},","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05891-234382-236109","score":16.865366531,"text":"\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster that you want to update a logging filter for.\n\n--id FILTER_ID\n: The ID of the log filter to update.\n\n--type LOG_TYPE\n: The type of logs that you want to apply the filter to. Currently all, container, and host are supported.\n\n-lc, --logging-config CONFIG\n: Optional: The logging configuration ID. If not provided, the filter is applied to all the cluster logging configurations that are passed to the filter. You can view log configurations that match the filter by using the --show-matching-configs option with the command. To specify multiple IDs, use multiple options, such as -lc id1 -lc id2.\n\n-n, --namespace KUBERNETES_NAMESPACE\n: Optional: The Kubernetes namespace from which you want to filter logs.\n\n--container CONTAINER_NAME\n: Optional: The name of the container from which you want to filter out logs. This option applies only when you are using log type container.\n\n--level LOGGING_LEVEL\n: Optional: Filters out logs that are at the specified level and less. Acceptable values in their canonical order are fatal, error, warn\/warning, info, debug, and trace. As an example, if you filtered logs at the info level, debug, and trace are also filtered. Note: You can use this option only when log messages are in JSON format and contain a level field. Example output {\"log\": \"hello\", \"level\": \"info\"}\n\n--message MESSAGE\n: Optional: Filters out any logs that contain a specified message anywhere in the log. Example: The messages \"Hello\", \"!\", and \"Hello, World!\", would apply to the log \"Hello, World!\".\n\n--regex-message MESSAGE\n: Optional: Filters out any logs that contain a specified message that is written as a regular expression anywhere in the log.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_04489-234834-236561","score":16.865366531,"text":"\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster that you want to update a logging filter for.\n\n--id FILTER_ID\n: The ID of the log filter to update.\n\n--type LOG_TYPE\n: The type of logs that you want to apply the filter to. Currently all, container, and host are supported.\n\n-lc, --logging-config CONFIG\n: Optional: The logging configuration ID. If not provided, the filter is applied to all the cluster logging configurations that are passed to the filter. You can view log configurations that match the filter by using the --show-matching-configs option with the command. To specify multiple IDs, use multiple options, such as -lc id1 -lc id2.\n\n-n, --namespace KUBERNETES_NAMESPACE\n: Optional: The Kubernetes namespace from which you want to filter logs.\n\n--container CONTAINER_NAME\n: Optional: The name of the container from which you want to filter out logs. This option applies only when you are using log type container.\n\n--level LOGGING_LEVEL\n: Optional: Filters out logs that are at the specified level and less. Acceptable values in their canonical order are fatal, error, warn\/warning, info, debug, and trace. As an example, if you filtered logs at the info level, debug, and trace are also filtered. Note: You can use this option only when log messages are in JSON format and contain a level field. Example output {\"log\": \"hello\", \"level\": \"info\"}\n\n--message MESSAGE\n: Optional: Filters out any logs that contain a specified message anywhere in the log. Example: The messages \"Hello\", \"!\", and \"Hello, World!\", would apply to the log \"Hello, World!\".\n\n--regex-message MESSAGE\n: Optional: Filters out any logs that contain a specified message that is written as a regular expression anywhere in the log.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"},{"document_id":"ibmcld_05891-230244-232067","score":16.7166377544,"text":"\nAcceptable values in their canonical order are fatal, error, warn\/warning, info, debug, and trace. As an example, if you filtered logs at the info level, debug, and trace are also filtered. Note: You can use this option only when log messages are in JSON format and contain a level field. Example output {\"log\": \"hello\", \"level\": \"info\"}\n\n--message MESSAGE\n: Optional: Filters out any logs that contain a specified message anywhere in the log. Example: The messages \"Hello\", \"!\", and \"Hello, World!\", would apply to the log \"Hello, World!\".\n\n--regex-message MESSAGE\n: Optional: Filters out any logs that contain a specified message that is written as a regular expression anywhere in the log. Example: The pattern \"hello [0-9]\" would apply to \"hello 1\", \"hello 2\", and \"hello 9\".\n\n--force-update\n: Force your Fluentd pods to update to the latest version. Fluentd must be at the latest version to change your logging configurations.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\nExamples:\n\nThis example filters out all logs that are forwarded from containers with the name test-container in the default namespace that are at the debug level or less, and have a log message that contains \"GET request\".\n\nibmcloud ks logging filter create --cluster example-cluster --type container --namespace default --container test-container --level debug --message \"GET request\"\n\nThis example filters out all the logs that are forwarded, at an info level or less, from a specific cluster. The output is returned as JSON.\n\nibmcloud ks logging filter create --cluster example-cluster --type all --level info --output json\n\n\n\n\n\n ibmcloud ks logging filter get \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nView a logging filter configuration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_04489-230696-232519","score":16.7166377544,"text":"\nAcceptable values in their canonical order are fatal, error, warn\/warning, info, debug, and trace. As an example, if you filtered logs at the info level, debug, and trace are also filtered. Note: You can use this option only when log messages are in JSON format and contain a level field. Example output {\"log\": \"hello\", \"level\": \"info\"}\n\n--message MESSAGE\n: Optional: Filters out any logs that contain a specified message anywhere in the log. Example: The messages \"Hello\", \"!\", and \"Hello, World!\", would apply to the log \"Hello, World!\".\n\n--regex-message MESSAGE\n: Optional: Filters out any logs that contain a specified message that is written as a regular expression anywhere in the log. Example: The pattern \"hello [0-9]\" would apply to \"hello 1\", \"hello 2\", and \"hello 9\".\n\n--force-update\n: Force your Fluentd pods to update to the latest version. Fluentd must be at the latest version to change your logging configurations.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\nExamples:\n\nThis example filters out all logs that are forwarded from containers with the name test-container in the default namespace that are at the debug level or less, and have a log message that contains \"GET request\".\n\nibmcloud ks logging filter create --cluster example-cluster --type container --namespace default --container test-container --level debug --message \"GET request\"\n\nThis example filters out all the logs that are forwarded, at an info level or less, from a specific cluster. The output is returned as JSON.\n\nibmcloud ks logging filter create --cluster example-cluster --type all --level info --output json\n\n\n\n\n\n ibmcloud ks logging filter get \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nView a logging filter configuration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"},{"document_id":"ibmcld_05832-21399-23084","score":16.6971321424,"text":"\nIf not provided, the filter is applied to all the cluster logging configurations that are passed to the filter. You can view log configurations that match the filter by using the --show-matching-configs option. \n <kubernetes_namespace> Optional: The Kubernetes namespace that you want to forward logs from. This option applies only when you are using log type container. \n <container_name> Optional: The name of the container from which you want to filter logs. \n <logging_level> Optional: Filters out logs that are at the specified level and less. Acceptable values in their canonical order are fatal, error, warn\/warning, info, debug, and trace. As an example, if you filtered logs at the info level, debug, and trace are also filtered. Note: You can use this option only when log messages are in JSON format and contain a level field. To display your messages in JSON, append the --output json option to the command. \n <message> Optional: Filters out logs that contain a specified message that is written as a regular expression. \n <filter_ID> Optional: The ID of the log filter. \n --show-matching-configs Optional: Show the logging configurations that each filter applies to. \n --all Optional: Delete all your log forwarding filters. \n\n\n\n\n\n1. Create a logging filter.\n\nibmcloud ks logging filter create --cluster <cluster_name_or_ID> --type <log_type> --logging-configs <configs> --namespace <kubernetes_namespace> --container <container_name> --level <logging_level> --regex-message <message>\n2. View the log filter that you created.\n\nibmcloud ks logging filter get --cluster <cluster_name_or_ID> --id <filter_ID> --show-matching-configs\n3. Update the log filter that you created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health"},{"document_id":"ibmcld_05891-228817-230600","score":16.4998457687,"text":"\nFilter out logs that are forwarded by your logging configuration.\n\nibmcloud ks logging filter create --cluster CLUSTER --type LOG_TYPE [--logging-config CONFIG] [--namespace KUBERNETES_NAMESPACE] [--container CONTAINER_NAME] [--level LOGGING_LEVEL] [--message MESSAGE] [--regex-message MESSAGE] [--force-update] [--output json] [-q]\n\nMinimum required permissions\n: Editor platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster to create a logging filter for.\n\n--type LOG_TYPE\n: The type of logs that you want to apply the filter to. Currently all, container, and host are supported.\n\n-lc, --logging-config CONFIG\n: Optional: The logging configuration ID. If not provided, the filter is applied to all the cluster logging configurations that are passed to the filter. You can view log configurations that match the filter by using the --show-matching-configs option with the command. To specify multiple IDs, use multiple options, such as -lc id1 -lc id2.\n\n-n, --namespace KUBERNETES_NAMESPACE\n: Optional: The Kubernetes namespace from which you want to filter logs.\n\n--container CONTAINER_NAME\n: Optional: The name of the container from which you want to filter out logs. This option applies only when you are using log type container.\n\n--level LOGGING_LEVEL\n: Optional: Filters out logs that are at the specified level and less. Acceptable values in their canonical order are fatal, error, warn\/warning, info, debug, and trace. As an example, if you filtered logs at the info level, debug, and trace are also filtered. Note: You can use this option only when log messages are in JSON format and contain a level field. Example output {\"log\": \"hello\", \"level\": \"info\"}\n\n--message MESSAGE","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_04489-229269-231052","score":16.4998457687,"text":"\nFilter out logs that are forwarded by your logging configuration.\n\nibmcloud ks logging filter create --cluster CLUSTER --type LOG_TYPE [--logging-config CONFIG] [--namespace KUBERNETES_NAMESPACE] [--container CONTAINER_NAME] [--level LOGGING_LEVEL] [--message MESSAGE] [--regex-message MESSAGE] [--force-update] [--output json] [-q]\n\nMinimum required permissions\n: Editor platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster to create a logging filter for.\n\n--type LOG_TYPE\n: The type of logs that you want to apply the filter to. Currently all, container, and host are supported.\n\n-lc, --logging-config CONFIG\n: Optional: The logging configuration ID. If not provided, the filter is applied to all the cluster logging configurations that are passed to the filter. You can view log configurations that match the filter by using the --show-matching-configs option with the command. To specify multiple IDs, use multiple options, such as -lc id1 -lc id2.\n\n-n, --namespace KUBERNETES_NAMESPACE\n: Optional: The Kubernetes namespace from which you want to filter logs.\n\n--container CONTAINER_NAME\n: Optional: The name of the container from which you want to filter out logs. This option applies only when you are using log type container.\n\n--level LOGGING_LEVEL\n: Optional: Filters out logs that are at the specified level and less. Acceptable values in their canonical order are fatal, error, warn\/warning, info, debug, and trace. As an example, if you filtered logs at the info level, debug, and trace are also filtered. Note: You can use this option only when log messages are in JSON format and contain a level field. Example output {\"log\": \"hello\", \"level\": \"info\"}\n\n--message MESSAGE","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"},{"document_id":"ibmcld_05891-232998-234699","score":16.3356781084,"text":"\nibmcloud ks logging filter rm \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nDelete a logging filter.\n\nibmcloud ks logging filter rm --cluster CLUSTER [--id FILTER_ID] [--all] [--force-update] [-q]\n\nMinimum required permissions\n: Editor platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: The name or ID of the cluster that you want to delete a filter from.\n\n--id FILTER_ID\n: The ID of the log filter to delete.\n\n--all\n: Optional: Delete all your log forwarding filters.\n\n--force-update\n: Force your Fluentd pods to update to the latest version. Fluentd must be at the latest version to change your logging configurations.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example logging filter rm command \n\nibmcloud ks logging filter rm --cluster mycluster --id 885732\n\n\n\n\n\n\n\n ibmcloud ks logging filter update \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nUpdate a logging filter.\n\nibmcloud ks logging filter update --cluster CLUSTER --id FILTER_ID --type LOG_TYPE [--logging-config CONFIG] [--namespace KUBERNETES_NAMESPACE] [--container CONTAINER_NAME] [--level LOGGING_LEVEL] [--message MESSAGE] [--regex-message MESSAGE] [--force-update] [--output json] [-q]\n\nMinimum required permissions\n: Editor platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster that you want to update a logging filter for.\n\n--id FILTER_ID\n: The ID of the log filter to update.\n\n--type LOG_TYPE\n: The type of logs that you want to apply the filter to. Currently all, container, and host are supported.\n\n-lc, --logging-config CONFIG","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_04489-233450-235151","score":16.3356781084,"text":"\nibmcloud ks logging filter rm \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nDelete a logging filter.\n\nibmcloud ks logging filter rm --cluster CLUSTER [--id FILTER_ID] [--all] [--force-update] [-q]\n\nMinimum required permissions\n: Editor platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: The name or ID of the cluster that you want to delete a filter from.\n\n--id FILTER_ID\n: The ID of the log filter to delete.\n\n--all\n: Optional: Delete all your log forwarding filters.\n\n--force-update\n: Force your Fluentd pods to update to the latest version. Fluentd must be at the latest version to change your logging configurations.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example logging filter rm command \n\nibmcloud ks logging filter rm --cluster mycluster --id 885732\n\n\n\n\n\n\n\n ibmcloud ks logging filter update \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nUpdate a logging filter.\n\nibmcloud ks logging filter update --cluster CLUSTER --id FILTER_ID --type LOG_TYPE [--logging-config CONFIG] [--namespace KUBERNETES_NAMESPACE] [--container CONTAINER_NAME] [--level LOGGING_LEVEL] [--message MESSAGE] [--regex-message MESSAGE] [--force-update] [--output json] [-q]\n\nMinimum required permissions\n: Editor platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster that you want to update a logging filter for.\n\n--id FILTER_ID\n: The ID of the log filter to update.\n\n--type LOG_TYPE\n: The type of logs that you want to apply the filter to. Currently all, container, and host are supported.\n\n-lc, --logging-config CONFIG","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"},{"document_id":"ibmcld_05891-235706-237564","score":15.9710294561,"text":"\nExample output {\"log\": \"hello\", \"level\": \"info\"}\n\n--message MESSAGE\n: Optional: Filters out any logs that contain a specified message anywhere in the log. Example: The messages \"Hello\", \"!\", and \"Hello, World!\", would apply to the log \"Hello, World!\".\n\n--regex-message MESSAGE\n: Optional: Filters out any logs that contain a specified message that is written as a regular expression anywhere in the log. Example: The pattern \"hello [0-9]\" would apply to \"hello 1\", \"hello 2\", and \"hello 9\"\n\n--force-update\n: Force your Fluentd pods to update to the latest version. Fluentd must be at the latest version to change your logging configurations.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\nExamples:\n\nThis example filters out all logs that are forwarded from containers with the name test-container in the default namespace that are at the debug level or less, and have a log message that contains \"GET request\".\n\nibmcloud ks logging filter update --cluster example-cluster --id 885274 --type container --namespace default --container test-container --level debug --message \"GET request\"\n\nThis example filters out all the logs that are forwarded, at an info level or less, from a specific cluster. The output is returned as JSON.\n\nibmcloud ks logging filter update --cluster example-cluster --id 274885 --type all --level info --output json\n\n\n\n\n\n ibmcloud ks logging refresh \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nRefresh the logging configuration for the cluster. This action refreshes the logging token for any logging configuration that is forwarding to the space level in your cluster.\n\nThe logging config refresh alias for this command is deprecated.\n\nibmcloud ks logging refresh --cluster CLUSTER [--force-update] [-q]\n\nMinimum required permissions","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00589-8040-10059","score":29.2123299789,"text":"\niam_apikey_description\n: Description of IAM API key.\n\niam_apikey_name\n: ID of IAM API key.\n\niam_role_crn\n: The IAM role that the IAM API key has.\n\niam_serviceid_crn\n: The CRN of service ID.\n\npassword\n: The IBM Cloudant legacy credential password.\n\nport\n: IBM Cloudant service port.\n\nurl\n: IBM Cloudant service URL, including embedded IBM Cloudant legacy credentials.\n\nusername\n: The IBM Cloudant legacy credential username.\n\nNote the included username and password are always equivalent to IAM's Manager credentials. Therefore, the use of Use both legacy credentials and IAM is insecure when used with Reader, Writer, Monitor, or Checkpointer IAM roles.\n\n\n\n\n\n\n\n Must I use Use only IAM or Use both legacy credentials and IAM? \n\nIf possible, Use only IAM is preferred. The major advantages for using IBM Cloud IAM are shown in the following list:\n\n\n\n* Management of access to IBM Cloudant with the standard tools of IBM Cloud rather than a combination of IBM Cloud and IBM Cloudant-specific credential management.\n* Credentials can be easily revoked and rotated when you use IBM Cloud IAM.\n\n\n\nFurther description of the advantages and disadvantages of each approach follows.\n\nWhen you use IAM roles other than Manager, such as Reader, Writer, Monitor, or Checkpointer, you must use Use only IAM to avoid supplying users with legacy credentials that include greater access permissions.\n\n\n\n Advantages and disadvantages of the two access control mechanisms \n\nOverall, IBM Cloud IAM is the recommended authentication model. However, the primary disadvantages to the approach are if you have an existing application or are unable to use an IBM Cloudant-supported client library.\n\n\n\n Advantages of IAM mode \n\n\n\n* Manage access for many services by using one interface.\n* Revoke access to a user globally.\n* Account-level API keys that use service IDs.\n* Easy-to-rotate credentials.\n* Activity Tracker logs capture individual humans and services.\n* IAM federates with other identity systems, like enterprise LDAP repositories.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant"},{"document_id":"ibmcld_07578-414710-416563","score":29.2121545202,"text":"\n* Unique to IBM Cloudant.\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n\n\n\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n\n\n\n\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n\n\n\n\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",\n\"host\": \"2922d728-27c0-4c7f-aa80-1e59fbeb04d0-bluemix.cloudant.com\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-414684-416537","score":29.2121545202,"text":"\n* Unique to IBM Cloudant.\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n\n\n\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n\n\n\n\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n\n\n\n\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",\n\"host\": \"2922d728-27c0-4c7f-aa80-1e59fbeb04d0-bluemix.cloudant.com\",","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-419683-421572","score":29.0614582929,"text":"\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n* Why is the Use only IAM mode preferred?\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n* How can I create an instance by using the command line?\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n* How can I generate service credentials?\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-419665-421554","score":29.0614582929,"text":"\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n* Why is the Use only IAM mode preferred?\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n* How can I create an instance by using the command line?\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n* How can I generate service credentials?\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00531-7-2145","score":27.9096424429,"text":"\nAuthenticating with IBM Cloudant FAQ \n\nIBM Cloud\u00ae Identity and Access Management (IAM) combines managing user identities, services, and access control into one approach. IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae integrates with IBM Cloud Identity and Access Management.\n\n\n\n What is the difference between IBM Cloudant legacy and IAM access controls? \n\n\n\n IBM Cloud IAM \n\n\n\n* Centrally managed access management across IBM Cloud.\n* Allows a user or service to access many different resources by using the same set of credentials (for example, same username and password or IAM API key).\n* IAM API keys can be granted access to account management functions, like creating new databases.\n\n\n\n\n\n\n\n IBM Cloudant legacy \n\n\n\n* Unique to IBM Cloudant.\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n\n\n\n\n Why is the Use only IAM mode preferred? \n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n\n\n\n\n\n How can I create an instance by using the command line? \n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" cloudantnosqldb Standard us-south -p '{\"legacyCredentials\": false}'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-authenticating-cloudant"},{"document_id":"ibmcld_00579-7-1988","score":27.3852607573,"text":"\nIndexing and querying \n\nThe Index and querying document is the second best practice document in the series. It shows you the following best practices:\n\n\n\n* How to understand the different results between emitting data into a view or not.\n* Why you must never rely on IBM Cloudant Query's ability to query without creating explicit indexes.\n* Why you must limit the number of fields with IBM Cloudant Search (or IBM Cloudant Query indexes of type text).\n* How to manage design documents.\n* Why partitioned queries are faster and cheaper.\n* How to use the primary index as a free search index.\n\n\n\nFor more information, see [Data modeling](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling) or [IBM Cloudant in practice](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-in-practice).\n\nThe content in this document was originally written by Stefan Kruger as a [Best and worst practice](https:\/\/blog.cloudant.com\/2019\/11\/21\/Best-and-Worst-Practices.html) blog post on 21 November 2019.\n\n\n\n Understand the tradeoffs in emitting data or not into a view \n\nAs the document that is referenced by a view is always available by using include_docs=true, it is possible to do something like the following example to allow lookups on indexed_field:\n\nemit(doc.indexed_field, null);\n\nThis example has the following advantages and disadvantages:\n\n\n\n* The index is compact. This index size is good, since index size contributes to storage costs.\n* The index is robust. Since the index does not store the document, you can access any field without thinking ahead about what to store in the index.\n* The disadvantage is that getting the document back is more costly than the alternative of emitting data into the index itself. First, the database has to look up the requested key in the index and then read the associated document. Also, if you\u2019re reading the whole document, but need only a single field, you\u2019re making the database read and transmit data that you don\u2019t need.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-querying"},{"document_id":"ibmcld_00589-9560-11733","score":26.7036261066,"text":"\nHowever, the primary disadvantages to the approach are if you have an existing application or are unable to use an IBM Cloudant-supported client library.\n\n\n\n Advantages of IAM mode \n\n\n\n* Manage access for many services by using one interface.\n* Revoke access to a user globally.\n* Account-level API keys that use service IDs.\n* Easy-to-rotate credentials.\n* Activity Tracker logs capture individual humans and services.\n* IAM federates with other identity systems, like enterprise LDAP repositories.\n* Fine-grained permissions (for example, Reader, Writer, Monitor, or Checkpointer).\n\n\n\n\n\n\n\n Disadvantages of IAM mode \n\n\n\n* If you are not using the supported libraries from IBM Cloudant, application changes are likely to be required to use IAM's API keys and access tokens.\n* No database-level permissions (yet).\n* Some endpoints are not available. For more information, see [unavailable endpoints](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantunavailable-endpoints).\n* No way to specify a database as \"public\", that is, not requiring an authorized user to access.\n\n\n\n\n\n\n\n Advantages of legacy mode \n\n\n\n* No need to change existing applications or client library dependencies.\n* Database-level permissions.\n\n\n\n\n\n\n\n Disadvantages of legacy mode \n\n\n\n* Separate management of IBM Cloudant credentials, so unable to get full overview of all access within centralized interface.\n\n\n\n\n\n\n\n\n\n\n\n Create a replication job by using IAM credentials only \n\nFollow these instructions to generate IAM API keys, generate the bearer token, create the _replicator database, and create the replication job.\n\n\n\n Generating IAM API keys for Source and Target and one for IBM Cloudant API access \n\nIn this exercise, the first two API keys are created so that the two instances can talk to each other during the replication process. The third API key is for the user to access the IBM Cloudant API, create the _replicator database, and then add the replication document to it.\n\nFollow these steps to generate IAM API keys and API access for IBM Cloudant. You must write down the credentials that are requested in the following steps to continue with the example.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant"},{"document_id":"ibmcld_03630-7-2200","score":21.8952601543,"text":"\nAbout RAID \n\nRAID (Redundant Array of Independent Disks) creates a single usable data disk, where several physical disks are combined into an array for better speed and fault tolerance. Following are the three key concepts in RAID:\n\n\n\n* Mirroring: copying data to more than one disk\n* Striping: splitting data across more than one disk\n* Error correction (fault tolerance): redundant data is stored to allow problems to be detected and possibly fixed.\n\n\n\nAlthough many different levels of RAID exist, IBM chooses to support the most common RAID types: 0, 1, 5, 6, and 10. The different RAID levels use one or more of the following techniques, depending on the system requirements. The main purpose of using RAID is to improve reliability by using either 3Ware 9550SX Raid SATA or an Adaptec SA-SCSI RAID controller for all RAID solutions deployed.\n\nRAID is not a backup solution. Rather, RAID creates a single usable data disk, where several physical disks are combined into an array for better speed and fault tolerance.\n\nRAID 0 (Striped set without parity \/ Non-Redundant Array) Implements data striping, where file blocks are written across multiple disks in fragments that require a minimum of two disks. The advantage of a RAID 0 is that the read\/write speed is dramatically increased. The more disks that are in the array, the greater the bandwidth. The disadvantage to a RAID 0 is that it has no fault tolerance. If a single drive fails, the array is broken. Also, RAID 0 does not implement error checking. So, any error is also unrecoverable. A common solution for fault tolerance is to have a drive outside of the array that is used as backup storage in a hardware failure.\n\nRAID 1 (Mirrored set without parity) Implements data mirroring. Data is duplicated on 2 or 4 disks through a hardware raid controller and provides some fault tolerance. The array is recoverable if at least one drive does not fail. It provides faster read performance than a single drive and provides drive redundancy if a drive failure occurs. Write speed is slightly reduced.\n\nRAID 5 (Striped set with dual distributed parity) Implements data striping at a block level and distributes parity among the disks.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/bare-metal?topic=bare-metal-bm-raid-levels"},{"document_id":"ibmcld_05138-7979-9034","score":21.2538512409,"text":"\nAfter your bucket is created with Activity Tracker and Monitoring, it may take a few minutes for the rules to take effect.\n\nYou are now ready to store data in a secure content store with encryption, monitoring, and audit observability!\n\n\n\n\n\n Get started by uploading data \n\n\n\n* See [uploading data](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-upload) for more information.\n\n\n\n\n\n\n\n Add capabilities \n\nAdd capabilities to protect objects from ransomware and accidental deletion such as [versioning](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-versioning) and [immutable retention polices](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-ol-overview) for supporting immutable storage, and immutable backup and archive data.\n\n\n\n\n\n Library of Object Storage tutorials \n\nCheck out the IBM Cloud Tutorials library for more tutorials when deploying solutions with [Cloud Object Storage](https:\/\/cloud.ibm.com\/docs?tab=tutorials&page=1&pageSize=20&tags=cloud-object-storage).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-secure-content-store"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03618-1804-3397","score":33.5478072194,"text":"\nThe TPM device is integrated within the server system and provides a range of Intel TXT security-related functions.\n\n\n\n\n\n What does Intel TXT does for you \n\nIntel TXT is especially advantageous for large enterprises subject to compliance and audit regulations, such as healthcare, financial services, and government organizations. It helps assure that tracking of all trusted resources can be integrated, managed, and reported on with the relevant compliance organizations (HIPAA, PCI, FedRAMP, ISO, FISMA, and SSAE 16). For the first time, these organizations are able to certify that a cloud computing system is secured for workloads such as\n\n\n\n* Governance and enterprise risk\n* Information and lifecycle management\n* Compliance and audit\n* Application security\n* Identity and access management\n* Incident response\n\n\n\nFor more information about Intel TXT on IBM Cloud Bare Metal Servers, see [Intel\u00ae Trusted Execution Technology](https:\/\/www.ibm.com\/cloud\/bare-metal-servers\/intel-txt).\n\n\n\n\n\n Special technical notice \n\nIntel TXT is provided by Intel\u00ae and operates on the IBM Cloud Bare Metal Servers that require specific technical knowledge to support and manage. The IBM Cloud current delivery model can turn Intel\u00ae TXT either on or off. IBM Cloud can't assist with configuration of Intel TXT settings because of the sensitivity of customer environments and data. The recommendation is that you either include staff who is trained in Intel TXT technologies or engage with a consulting firm with expertise in orchestrating root of trust and measured launch environment (MLE) architecture.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/bare-metal?topic=bare-metal-bm-hardware-monitroing-security-controls"},{"document_id":"ibmcld_04866-6428-8391","score":24.7005911143,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-6428-8442","score":24.4802156238,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05075-10227-12120","score":21.1596088491,"text":"\nThere should be no adverse interactions when using Object Lock with other Object Storage features, such as setting CORS policies, setting IP firewalls or condition based restrictions, bucket quotas, or Code Engine.\n\n\n\n\n\n\n\n IAM actions \n\nThere are new IAM actions associated with Object Lock.\n\n\n\n IAM Action Role \n\n cloud-object-storage.bucket.get_object_lock_configuration Manager, Writer, Reader \n cloud-object-storage.bucket.put_object_lock_configuration Manager, Writer \n cloud-object-storage.object.get_object_lock_retention Manager, Writer, Reader \n cloud-object-storage.object.put_object_lock_retention Manager, Writer \n cloud-object-storage.object.get_object_lock_retention_version Manager, Writer, Reader \n cloud-object-storage.object.put_object_lock_retention_version Manager, Writer \n cloud-object-storage.object.get_object_lock_legal_hold Manager, Writer, Reader \n cloud-object-storage.object.put_object_lock_legal_hold Manager, Writer \n cloud-object-storage.object.get_object_lock_legal_hold_version Manager, Writer, Reader \n cloud-object-storage.object.put_object_lock_legal_hold_version Manager, Writer \n\n\n\nBe advised that users with the Writer role are capable of making objects un-deletable for many years (possibly thousand of years). Be careful, and consider crafting custom roles that do not allow most users to set a Retain Until Date.\n\n\n\n\n\n Activity Tracker events \n\nObject Lock generates additional events.\n\n\n\n* cloud-object-storage.bucket-object-lock.create\n* cloud-object-storage.bucket-object-lock.read\n* cloud-object-storage.object-object-lock-legal-hold.create\n* cloud-object-storage.object-object-lock-legal-hold.read\n* cloud-object-storage.object-object-lock-retention.create\n* cloud-object-storage.object-object-lock-retention.read\n\n\n\nFor cloud-object-storage.bucket-object-lock.create events, the following fields provide extra information:\n\n\n\n Field Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-ol-overview"},{"document_id":"ibmcld_07679-0-891","score":20.9444630491,"text":"\n\n\n\n\n\n\n  AU-14 - Session Audit \n\n\n\n  Control requirements \n\nAU-14 - 0\n:   The information system provides the capability for authorized users to select a user session to capture\/record or view\/hear.\n\n\n\n\n\n  Implementation guidance \n\nSee the resources that follow to learn more about how to implement this control.\n\n\n\n*  [Running operator actions through a bastion host](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-connectivity-bastion)\n\n\n\n\n\n\n\n  NIST supplemental guidance \n\nSession audits include, for example, monitoring keystrokes, tracking websites visited, and recording information and\/or file transfers. Session auditing activities are developed, integrated, and used in consultation with legal counsel in accordance with applicable federal laws, Executive Orders, directives, policies, regulations, or standards.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-au-14"},{"document_id":"ibmcld_05088-36762-38638","score":19.4892057802,"text":"\nexcept ClientError as be:\nprint(\"CLIENT ERROR: {0}n\".format(be))\nexcept Exception as e:\nprint(\"Unable to get bucket protection config: {0}\".format(e))\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\n\n\n Value Type Description \n\n Retention-Period Non-negative integer (seconds) Retention period to store on the object in seconds. The object can be neither overwritten nor deleted until the amount of time that is specified in the retention period has elapsed. If this field and Retention-Expiration-Date are specified a 400 error is returned. If neither is specified the bucket's DefaultRetention period will be used. Zero (0) is a legal value assuming the bucket's minimum retention period is also 0. \n Retention-expiration-date Date (ISO 8601 Format) Date on which it will be legal to delete or modify the object. You can only specify this or the Retention-Period header. If both are specified a 400 error will be returned. If neither is specified the bucket's DefaultRetention period will be used. \n Retention-legal-hold-id string A single legal hold to apply to the object. A legal hold is a Y character long string. The object cannot be overwritten or deleted until all legal holds associated with the object are removed. \n\n\n\ndef put_object_add_legal_hold(bucket_name, object_name, file_text, legal_hold_id):\nprint(\"Add legal hold {0} to {1} in bucket {2} with a putObject operation.n\".format(legal_hold_id, object_name, bucket_name))\n\ncos.put_object(\nBucket=bucket_name,\nKey=object_name,\nBody=file_text,\nRetentionLegalHoldId=legal_hold_id)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-python"},{"document_id":"ibmcld_14708-2831-4126","score":19.0747669492,"text":"\nThis action allows data to be received from the proxy servers during backup and restore processes.\n\nufw status\nStatus: active\nTo Action From\n-- ------ ----\n6162\/tcp ALLOW 10.38.207.157 Allow Veeam Mgmt from Veeam BUR server\n2500\/tcp ALLOW Anywhere Veeam rule 876f0752-7209-4e8b-8b34-fa0af7dbced4\n2501\/tcp ALLOW Anywhere Veeam rule 876f0752-7209-4e8b-8b34-fa0af7dbced4\n6162\/tcp ALLOW OUT Anywhere Veeam transport rule\n2500\/tcp ALLOW OUT Anywhere Veeam rule 876f0752-7209-4e8b-8b34-fa0af7dbced4\n2501\/tcp ALLOW OUT Anywhere Veeam rule 876f0752-7209-4e8b-8b34-fa0af7dbced4\n\nZoom\n\n![Veeam backup](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/veeam-cr-sa-lhbr-proxy.svg)\n\nFigure 2. Veeam backup\n\n\n\n Best practices for a Linux hardened repository \n\nThe [Compliance assessment report (by Cohasset)](https:\/\/www.veeam.com\/wp-compliance-assessment-report-cohasset.html) describes the settings that must be configured to become compliant with the following regulations:\n\n\n\n* FINRA Rule 4511.\n* SEC Rule 17a-4(f).\n* CFTC Rule 1 .31 (c)-(d).\n\n\n\nThe previous assessment report considers the following details as best practice for a Linux hardened repository:\n\n\n\n* The Linux hardened repository can be independent or Scale-out backup repository.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-lhr"},{"document_id":"ibmcld_04939-57496-59284","score":18.955819235,"text":"\nSystem.out.printf(\"Minimum Retention (Days): %sn\", config.getMinimumRetentionInDays());\nSystem.out.printf(\"Default Retention (Days): %sn\", config.getDefaultRetentionInDays());\nSystem.out.printf(\"Maximum Retention (Days): %sn\", config.getMaximumRetentionInDays());\n}\n}\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\n\n\n Value Type Description \n\n Retention-Period Non-negative integer (seconds) Retention period to store on the object in seconds. The object can be neither overwritten nor deleted until the amount of time specified in the retention period has elapsed. If this field and Retention-Expiration-Date are specified a 400 error is returned. If neither is specified the bucket's DefaultRetention period will be used. Zero (0) is a legal value assuming the bucket's minimum retention period is also 0. \n Retention-expiration-date Date (ISO 8601 Format) Date on which it will be legal to delete or modify the object. You can only specify this or the Retention-Period header. If both are specified a 400 error will be returned. If neither is specified the bucket's DefaultRetention period will be used. \n Retention-legal-hold-id string A single legal hold to apply to the object. A legal hold is a Y character long string. The object cannot be overwritten or deleted until all legal holds associated with the object are removed. \n\n\n\npublic static void putObjectAddLegalHold(String bucketName, String objectName, String fileText, String legalHoldId) {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/libraries?topic=cloud-object-storage-java"},{"document_id":"ibmcld_05070-20435-22267","score":18.955819235,"text":"\nfunction getProtectionConfigurationOnBucket(bucketName) {\nconsole.log(Retrieve the protection on bucket ${bucketName});\nreturn cos.getBucketProtectionConfiguration({\nBucket: bucketName\n}).promise()\n.then((data) => {\nconsole.log(Configuration on bucket ${bucketName}:);\nconsole.log(data);\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\n\n\n Value Type Description \n\n Retention-Period Non-negative integer (seconds) Retention period to store on the object in seconds. The object can be neither overwritten nor deleted until the amount of time specified in the retention period has elapsed. If this field and Retention-Expiration-Date are specified a 400 error is returned. If neither is specified the bucket's DefaultRetention period will be used. Zero (0) is a legal value assuming the bucket's minimum retention period is also 0. \n Retention-expiration-date Date (ISO 8601 Format) Date on which it will be legal to delete or modify the object. You can only specify this or the Retention-Period header. If both are specified a 400 error will be returned. If neither is specified the bucket's DefaultRetention period will be used. \n Retention-legal-hold-id string A single legal hold to apply to the object. A legal hold is a Y character long string. The object cannot be overwritten or deleted until all legal holds associated with the object are removed. \n\n\n\nfunction putObjectAddLegalHold(bucketName, objectName, legalHoldId) {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-node"},{"document_id":"ibmcld_05044-57476-59264","score":18.955819235,"text":"\nSystem.out.printf(\"Minimum Retention (Days): %sn\", config.getMinimumRetentionInDays());\nSystem.out.printf(\"Default Retention (Days): %sn\", config.getDefaultRetentionInDays());\nSystem.out.printf(\"Maximum Retention (Days): %sn\", config.getMaximumRetentionInDays());\n}\n}\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\n\n\n Value Type Description \n\n Retention-Period Non-negative integer (seconds) Retention period to store on the object in seconds. The object can be neither overwritten nor deleted until the amount of time specified in the retention period has elapsed. If this field and Retention-Expiration-Date are specified a 400 error is returned. If neither is specified the bucket's DefaultRetention period will be used. Zero (0) is a legal value assuming the bucket's minimum retention period is also 0. \n Retention-expiration-date Date (ISO 8601 Format) Date on which it will be legal to delete or modify the object. You can only specify this or the Retention-Period header. If both are specified a 400 error will be returned. If neither is specified the bucket's DefaultRetention period will be used. \n Retention-legal-hold-id string A single legal hold to apply to the object. A legal hold is a Y character long string. The object cannot be overwritten or deleted until all legal holds associated with the object are removed. \n\n\n\npublic static void putObjectAddLegalHold(String bucketName, String objectName, String fileText, String legalHoldId) {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-java"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.5,"ndcg_cut_5":0.5,"ndcg_cut_10":0.5}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06808-1384-2991","score":47.3338959533,"text":"\n[Learn more](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cos-bucket-evidencecd-devsecops-cos-bucket-resiliency).\n\n\n\n\n\n Naming your bucket \n\nCloud Object Storage object names consist of the following components:\n\n{NAMESPACE} \/ {PIPELINE_RUN_ID} \/ {TYPE} \/ {FILE_NAME} _ {HASH}\n\n\n\n Examples: \n\nci\/48decaa9-9042-498f-b58d-3577e0ac0158\/evidences\/build-vulnerability-advisor.json_362c06afa88b3f304878f0d0979e834f\n\nci\/48decaa9-9042-498f-b58d-3577e0ac0158\/artifacts\/app-image-va-report.json_b3f30487f0d0979e834f362c06afaaa8\n\nThe name component {NAMESPACE} \/ {PIPELINE_RUN_ID} \/ {TYPE} is useful as a prefix when you're looking for collected data from a certain pipeline run.\n\n\n\n\n\n Retention policy \n\nYou can set Cloud Object Storage buckets to enforce a retention policy or period for uploaded objects, otherwise known as [Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable). Immutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a Write-One-Read-Many (WORM), non-erasable, and non-rewritable manner. You cannot change or delete objects in protected buckets within the retention period, or delete protected buckets with objects themselves until the retention period is over. The policy is enforced until the end of a retention period and the removal of any legal holds.\n\nIt is recommended that teams set a retention policy for the buckets that are used as their evidence locker that stores every object for a minimum of 365 days.\n\n\n\n\n\n\n\n Audit event log","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cos-bucket-evidence"},{"document_id":"ibmcld_04866-7-2136","score":46.8342479424,"text":"\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-7-2136","score":46.8342479424,"text":"\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_02361-24500-26305","score":46.1753408627,"text":"\n[Information about Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time? [Information about archiving COS files for long term storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-archive) \n Encryption of data at-rest with my own key [5] Can I use my own key to encrypt data at-rest? [Information about encryption of data at-rest](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-encryption) \n Data resiliency [6] Do you need to store the data in a specific geographical location? [Information about resiliency](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-endpoints) \n\n\n\n[1]: Data might sit untouched for long periods of time. For less active workloads, you can create buckets with different storage classes. For example, use the standard storage class for active workloads, where you need to access data at any time.\n\n[2]: You can choose Immutable Object Storage to preserve electronic records and maintain data integrity. When you define a retention policy for a bucket, you are specifying that the data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds. Notice that Immutable Object Storage is available in certain regions only.\n\n[3]: You can use an expiration rule to delete objects automatically after a defined period from the object creation date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-adoption"},{"document_id":"ibmcld_05032-6428-8442","score":45.2288863881,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_09275-31436-33181","score":45.0079964767,"text":"\n[Information about expiration rules](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time? [Information about archiving COS files for long term storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-archive) \n Encryption of data at-rest with my own key [5] Can I use my own key to encrypt data at-rest? [Information about encryption of data at-rest](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-encryption) \n Data resiliency [6] Do you need to store the data in a specific geographical location? [Information about resiliency](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-endpoints) \n\n\n\n[1]: Data might sit untouched for long periods of time. For less active workloads, you can create buckets with different storage classes. For example, use the standard storage class for active workloads, where you need to access data at any time.\n\n[2]: You can choose Immutable Object Storage to preserve electronic records and maintain data integrity. When you define a retention policy for a bucket, you are specifying that the data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds. Notice that Immutable Object Storage is available in certain regions only.\n\n[3]: You can use an expiration rule to delete objects automatically after a defined period from the object creation date.\n\n[4]: You can define a retention policy to retain data for a long period of time and have the data available for downloads and queries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-adoption"},{"document_id":"ibmcld_05168-15740-17188","score":44.9676411612,"text":"\nfmt.Println(r)\nfmt.Println(e)\n\n}\n\nShow more\n\nThe typical response is exemplified here.\n\n{\nRules: [{\nFilter: {\n\n},\nID: \"id3\",\nStatus: \"Enabled\",\nTransitions: {\nDays: 5,\nStorageClass: \"GLACIER\"\n}]\n}]\n}\n\n\n\n\n\n Immutable Object Storage \n\nUsers can configure buckets with an Immutable Object Storage policy to prevent objects from being modified or deleted for a defined period of time. The retention period can be specified on a per-object basis, or objects can inherit a default retention period set on the bucket. It is also possible to set open-ended and permanent retention periods. Immutable Object Storage meets the rules set forth by the SEC governing record retention, and IBM Cloud administrators are unable to bypass these restrictions.\n\nNote: Immutable Object Storage does not support Aspera transfers via the SDK to upload objects or directories at this stage.\n\nfunc main() {\n\n\/\/ Create Client\nsess := session.Must(session.NewSession())\nclient := s3.New(sess, conf)\n\n\/\/ Create a bucket\ninput := &s3.CreateBucketInput{\nBucket: aws.String(\"<BUCKET_NAME>\"),\n}\nd, e := client.CreateBucket(input)\nfmt.Println(d) \/\/ should print an empty bracket\nfmt.Println(e) \/\/ should print <nil>\n\n\/\/ PUT BUCKET PROTECTION CONFIGURATION\npInput := &s3.PutBucketProtectionConfigurationInput{\nBucket: aws.String(\"<BUCKET_NAME>\"),\nProtectionConfiguration: &s3.ProtectionConfiguration{\nDefaultRetention: &s3.BucketProtectionDefaultRetention{\nDays: aws.Int64(100),\n},","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-using-go"},{"document_id":"ibmcld_04866-4961-6763","score":44.5462241811,"text":"\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https:\/\/www.finra.org\/rules-guidance\/rulebooks\/finra-rules\/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-4961-6763","score":44.5462241811,"text":"\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https:\/\/www.finra.org\/rules-guidance\/rulebooks\/finra-rules\/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_04866-6428-8391","score":44.198561128,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09782-7-1715","score":20.7264433982,"text":"\nMonitoring (ibmcloud monitoring) CLI \n\nThe IBM Cloud\u00ae command-line interface (CLI) provides extra capabilities for service offerings. This information describes how you can use the CLI to access information in IBM Cloud Monitoring.\n\n\n\n Prerequisites \n\n\n\n* Install the [IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-getting-started).\n* Install the IBM Cloud Monitoring CLI by running the following command:\n\nibmcloud plugin install monitoring\n\n\n\nYou are notified on the command line when updates to the IBM Cloud CLI and plug-ins are available. Be sure to keep your CLI up to date so that you can use the latest commands. You can view the current version of all installed plug-ins by running ibmcloud plugin list.\n\n\n\n\n\n ibmcloud monitoring alert add \n\nUse this command to add an alert.\n\nibmcloud monitoring alert add --name NAME [--alert-name ALERT_NAME] [--description DESCRIPTION] [--type TYPE] [--timespan TIMESPAN] [--condition CONDITION] [--severity SEVERITY] [--severity-label LOW, MEDIUM OR HIGH] [--disable] [--segment SEGMENT] [--segment-condition SEGMENT_CONDITION] [--user-filter USER_FILTER] [--notify NOTIFY] [--file JSON_FILE] [--region REGION] [--output FORMAT] [--team TEAM_NAME]\n\n\n\n Command options \n\n--name <NAME> | --n <NAME>\n: Name of the instance.\n\n--alert-name <ALERT_NAME>\n: Name of the alert.\n\n--description <DESCRIPTION>\n: Information about the alert.\n\n--type <TYPE>\n: Type of alert. Valid values are MANUAL, BASELINE, and HOST_COMPARISON.\n\n--timespan <TIMESPAN>\n: Minimum time interval, in microseconds, for which the alert condition must be met before the alert is triggered. The default value is 60,000,000 microseconds.\n\n--condition <CONDITION>\n: Threshold of the alert.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-monitor-cli"},{"document_id":"ibmcld_09701-8202-9428","score":19.1360447606,"text":"\n\"enabled\": false,\n\"filter\": null,\n\"type\": \"\",\n\"condition\": \"\",\n\"timespan\": 600000000,\n\"notificationChannelIds\": ],\n\"reNotify\": false,\n\"reNotifyMinutes\": 30,\n\"segmentBy\": ],\n\"segmentCondition\": {\n\"type\": \"\"\n},\n\"severityLabel\": \"\"\n}\n}\n]\n}\n\n\n\n\n\n Alerts schema: Response body \n\n{\n\"alerts\": [\n{\n\"alert\": {\n\"autoCreated\": false,\n\"condition\": \"\",\n\"createdOn\": 1551358413000,\n\"enabled\": false,\n\"id\": 23211,\n\"modifiedOn\": 1551634372000,\n\"name\": \"\",\n\"filter\": \"\",\n\"notificationChannelIds\": ],\n\"segmentBy\": ],\n\"segmentCondition\": {\n\"type\": \"ANY\"\n},\n\"notificationCount\": 60,\n\"rateOfChange\": false,\n\"reNotify\": false,\n\"severity\": 0,\n\"severityLabel\": \"\",\n\"teamId\": 493,\n\"timespan\": 60000000,\n\"type\": \"\",\n\"version\": 9\n}\n}\n]\n}\n\n\n\n\n\n Error response codes \n\nThe following table show common error response codes:\n\n\n\nTable 1. RC\n\n RC Description \n\n 400 The alert configuration is not valid. \n 401 Unauthorized access. \n 404 The alert ID is not recognized. \n 409 There is a version mismatch. \n 422 The alert name is not valid. The name is already used. \n\n\n\n\n\n\n\n Body parameters \n\n\n\n id (integer) \n\nID of an alert.\n\n\n\n\n\n condition (string) \n\nDefines the threshold that is configured for the alert. This parameter is required for MANUAL alerts only.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert_api"},{"document_id":"ibmcld_09702-5331-6744","score":17.8308894558,"text":"\nalert_found = False\n\nfor alert in res['alerts']:\nif alert['name'] == alert_name:\nalert_found = True\nif 'notificationChannelIds' in alert:\nalert['notificationChannelIds'] = alert['notificationChannelIds']\nupdate_txt = '(changed by update_alert)'\nif alert['description'] != update_txt:\nalert['description'] = alert['description'] + update_txt\nalert['timespan'] = alert['timespan'] * 2 Note: Expressed in seconds * 1000000\nres_update = sdclient.update_alert(alert)\n\nif not res_update:\nprint(\"Alert update failed\")\n\nif not alert_found:\nprint('Alert to be updated not found')\nShow more\n\n\n\n\n\n Deleting an alert (DELETE) \n\nTo delete an existing alert, you need the ID of that alert.\n\nThe following code shows the structure of a Python script that you can use to delete an alert:\n\n Reference the Python client\nfrom sdcclient import IbmAuthHelper, SdMonitorClient\n\n Add the monitoring instance information that is required for authentication\nURL = <MONITORING-ENDPOINT>\nAPIKEY = <IAM_APIKEY>\nGUID = <GUID>\nibm_headers = IbmAuthHelper.get_headers(URL, APIKEY, GUID)\n\n Instantiate the Python client\nsdclient = SdMonitorClient(sdc_url=URL, custom_headers=ibm_headers)\n\nres = sdclient.get_alerts()\nif not res[0]:\nprint(\"Failed to fetch existing alerts\")\n\nfor alert in res['alerts']:\nif alert['name'] == alert_name:\nprint(\"Deleting alert\")\nres = sdclient.delete_alert(alert)\nif not res:\nprint(\"Alert deletion failed\")\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert_python"},{"document_id":"ibmcld_09701-2229-3786","score":17.3331256815,"text":"\n* <REST_API_ENDPOINT> indicates the endpoint targetted by the REST API call. For more information, see [Monitoring REST API endpoints](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-endpointsendpoints_rest_api). For example, the public endpoint for an instance that is available in us-south is the following: https:\/\/us-south.monitoring.cloud.ibm.com\/api\n* You can pass multiple headers by using -H.\n\nAuthorization and IBMInstanceID are headers that are required for authentication.\n\nTeamID is optional. When you specify this header, you limit the request to the data and resources available for the team specified.\n\nTo get an AUTH_TOKEN and the GUID see, [Headers for IAM Tokens](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-mon-curlmon-curl-headers-iam).\n* You can pass data to create the alert in the alert.json file by using -d.\n\nWhen you create an alert, include the following parameters: type, name, severity, timespan, condition, segmentby, segmentConditionn, filter, notificationChannelIds, enabled\n\nFor more information, see [Alert schema](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert_apialert-api-schema-req).\n\n\n\nThe following sample shows the request body parameters that you can set to create an alert:\n\n{\n\"alert\": {\n\"version\": null,\n\"name\": \"My Alert!\",\n\"description\": null,\n\"teamId\": null,\n\"enabled\": false,\n\"filter\": null,\n\"type\": \"MANUAL\",\n\"condition\": \"avg(timeAvg(uptime)) <= 0\",\n\"timespan\": 600000000,\n\"notificationChannelIds\": [],\n\"reNotify\": false,\n\"reNotifyMinutes\": 30,\n\"segmentBy\": [\n\"host.hostName\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert_api"},{"document_id":"ibmcld_02714-0-689","score":17.2829377686,"text":"\n\n\n\n\n\n\n  Why am I receiving the Status Code - \"429 Too Many Requests\" as response to the API Calls? \n\n  What\u2019s happening \n\nAPI requests to App Configuration service is returning the HTTP status code as 429.\n\n  Why it\u2019s happening \n\nAll the APIs of the App Configuration service are rate-limited. Excessive number of requests sent to App Configuration from a single source will be blocked if they exceed the threshold value within a specific time period.\n\n  How to fix it \n\nEvaluate the reason of the excessive requests being sent to App Configuration exceeding the threshold value. Also, you may retry the request again after the interval specified in the retry-after response header.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-troubleshooting-rate-limiting"},{"document_id":"ibmcld_09782-1362-3189","score":17.0067304464,"text":"\n: Information about the alert.\n\n--type <TYPE>\n: Type of alert. Valid values are MANUAL, BASELINE, and HOST_COMPARISON.\n\n--timespan <TIMESPAN>\n: Minimum time interval, in microseconds, for which the alert condition must be met before the alert is triggered. The default value is 60,000,000 microseconds.\n\n--condition <CONDITION>\n: Threshold of the alert. This parameter is required for manual alerts, and does not apply to other alert types.\n\n--severity <SEVERITY> | -s <SEVERITY>\n: Level of severity. Valid values range from 0 to 7. 0 means emergency and 7 means debug. By default, severity is set to 4.\n\n--severity-label <LOW | MEDIUM | HIGH>\n: Criticality of an alert. Valid values are HIGH, MEDIUM, LOW. A lower severity value indicates a higher severity.\n\n--disable\n: State of the alert. By default, an alert is enabled when it is created. You must set this parameter to disable the alert when it is created.\n\n--segment <SEGMENT>\n: Additional segmentation criteria. For example, you can segment an alert by ['host.mac', 'proc.name'].\n\n--segment-condition <SEGMENT_CONDITION>\n: Defines when the alert is triggered for each monitored entity that is specified in the --segment parameter. This parameter is required for manual alerts, and does not apply to other alert types. Valid values are ANY and ALL. ANY indicates that the alert is triggered when at least one of the monitored entities satisfies the condition. ALL indicates that the alert is triggered when all of the monitored entities satisfy the condition.\n\n--user-filter <USER_FILTER>\n: Boolean expression that you can set to reduce the scope of the alert. Use this parameter to configure segments, such as filters like kubernetes.namespace.name='production' or container.image='nginx'.\n\n--notify <NOTIFY>\n: Type of notification that you want this alert to generate.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-monitor-cli"},{"document_id":"ibmcld_09782-3970-5739","score":16.3087628432,"text":"\n--team <TEAM_NAME>\n: The name of the IBM Cloud Monitoring team to be used for authorization. If no team is specified, the default team will be used.\n\n--help | -h\n: List options available for the command.\n\n\n\n\n\n Examples \n\nThe following are examples using the ibmcloud monitoring alert add command.\n\nAdd an alert for the IBM Cloud Monitoring abc instance to detect a CrashLoopBackOff in the last 5 minutes.\n\nibmcloud monitoring alert add --name \"IBM Cloud Monitoring abc\" --description \"Alert to report crashLoopBackOffs that are detected\" --severity 2 --timespan 300 --condition 'sum(avg(kubernetes.pod.restart.count)) > 1' --alert-name '[Kubernetes] Pod crash\/restart loop'\n\nAdd an alert for the IBM Cloud Monitoring abc instance to detect a CrashLoopBackOff in the last 5 minutes with severity set to medium.\n\nibmcloud monitoring alert add --name \"IBM Cloud Monitoring abc\" --description \"Alert to report crashLoopBackOffs that are detected\" --severity 2 --severity-label MEDIUM --timespan 300 --condition 'sum(avg(kubernetes.pod.restart.count)) > 1' --alert-name '[Kubernetes] Pod crash\/restart loop'\n\n\n\n\n\n\n\n ibmcloud monitoring alert list \n\nUse this command to list the alerts for the specified instance.\n\nibmcloud monitoring alert list --name NAME [--severity SEVERITY] [--enabled TRUE or FALSE] [--region REGION] [--output FORMAT] [--team TEAM_NAME]\n\n\n\n Command options \n\n--name <NAME> | --n <NAME>\n: Name of the instance.\n\n--region <REGION> | -r <REGION>\n: Name of the region, for example, us-south or eu-gb. If not specified, the region logged into or targeted will be used.\n\n--severity <SEVERITY> | -s <SEVERITY>\n: A comma-separated list of severity values enclosed in double-quotes (\"). If only a single severity is specified, the double-quotes can be omitted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-monitor-cli"},{"document_id":"ibmcld_00450-7-2086","score":16.0239053357,"text":"\nAdvanced replication \n\nYou can learn about advanced replication concepts and tasks, such as the ones in the following list and more:\n\n\n\n* Maintaining your replication database\n* Scheduling and monitoring replications\n* Authenticating during replication\n\n\n\nYou might also find it helpful to review details of the underlying [replication protocol](https:\/\/docs.couchdb.org\/en\/stable\/replication\/protocol.html), and review the [API reference](https:\/\/cloud.ibm.com\/apidocs\/cloudantintroduction) documentation.\n\n\n\n Replication database maintenance \n\nA replication database must be monitored like any other database. Without regular database maintenance, you might accumulate invalid documents that were caused by interruptions to the replication process. Having many invalid documents can result in an excess load on your cluster when the replicator process is restarted by IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae operations.\n\nTo maintain a replication database, remove old documents. You can remove old documents by determining their age and [deleting them](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-documentsdelete-a-document) if they're no longer needed.\n\n\n\n\n\n The replication scheduler \n\nThe new IBM Cloudant Replication Scheduler provides a number of improvements and enhancements when compared with the previous IBM Cloudant replication mechanism.\n\nIn particular, network usage during replication is more efficient. The scheduler accounts for the current load for individual database nodes within a cluster when it determines the allocation of replication tasks.\n\nFinally, the state of a replication is now more detailed, and consists of seven distinct states:\n\n\n\n1. initializing - The replication was added to the scheduler, but isn't yet initialized or scheduled to run. The status occurs when a new or updated replication document is stored within the [_replicator database](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-replication-apithe-replicator-database).\n2. error - The replication can't be turned into a job. This error might be caused in several different ways.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-advanced-replication"},{"document_id":"ibmcld_09701-1314-2591","score":13.8013117121,"text":"\n* <ALERT_ID> defines the ID of the alert that you want to modify.\n\n\n\nFor example, the response body for an alert looks as follows:\n\n{\n\"alert\": {\n\"autoCreated\": false,\n\"condition\": \"min(min(dallas_prod)) = 0\",\n\"createdOn\": 1551358413000,\n\"enabled\": false,\n\"id\": 23211,\n\"modifiedOn\": 1551634372000,\n\"name\": \"Monitoring Uptime Alert\",\n\"filter\": \"env in (\"prod\")\",\n\"notificationChannelIds\": [\n4\n],\n\"segmentBy\": [\n\"host.hostname\"\n],\n\"segmentCondition\": {\n\"type\": \"ANY\"\n},\n\"notificationCount\": 60,\n\"rateOfChange\": false,\n\"reNotify\": false,\n\"severity\": 0,\n\"severityLabel\": \"HIGH\",\n\"teamId\": 493,\n\"timespan\": 60000000,\n\"type\": \"MANUAL\",\n\"version\": 9\n}\n}\n\n\n\n\n\n Create an alert \n\nYou can use the following cURL command to create an alert:\n\ncurl -X POST <REST_API_ENDPOINT>\/api\/alerts -H \"Authorization: $AUTH_TOKEN\" -H \"IBMInstanceID: $GUID\" -H \"TeamID: $TEAM_ID\" -H \"content-type: application\/json\" -d @alert.json\n\nWhere\n\n\n\n* <REST_API_ENDPOINT> indicates the endpoint targetted by the REST API call. For more information, see [Monitoring REST API endpoints](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-endpointsendpoints_rest_api). For example, the public endpoint for an instance that is available in us-south is the following: https:\/\/us-south.monitoring.cloud.ibm.com\/api","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert_api"},{"document_id":"ibmcld_16699-1208-2591","score":13.3920112255,"text":"\nFor example, if pod A under deployment A communicates multiple times with pod B under deployment B, only one entry will appear in the UI. Or, if pod A1 and pod A2 are both under deployment A, and both communicate with pod B, deployment A will represent all its pods.\n\nTo set the scope, do the following:\n\n\n\n1. Open the [Workload Protection UI](https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-launch).\n2. Click the Network icon ![Network icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/667adc0b8a7fdb0b349b1158d8e128640b5bc72b\/workload-protection\/\/images\/network.png).\n3. Select your Cluster and Namespace.\n4. Select the type of Kubernetes entity.\n\n\n\n* Service\n* Deployment\n* Daemonset\n* Stateful Set\n* ChronJob - Choose this option to have communication aggregated at the scheduler level rather than the job. This can reduce extraneous entries.\n* Job - Choose this option to see entries where a job has no chronjob parent.\n\n\n\n5. Select the timespan you would like to see at the bottom of the page.\n\n\n\n\n\n\n\n Reviewing and cusomizing ingress and egress \n\nUse the Ingress and Egress tabs to see the communications for the selected entity and time period.\n\nYou can use the ![Include icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/667adc0b8a7fdb0b349b1158d8e128640b5bc72b\/workload-protection\/\/images\/include.png) to include a listed communication or the !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-netsec_policy"}],"retriever_scores":{}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11211-56813-58613","score":7.2006243324,"text":"\n* --image value: Linux for SAP (HANA) operating system image identifier or name.\n* --profile-id value: The unique identifier of the SAP profile.\n* --networks value: Space separated identifier\/name of the network and optional IP address to associate with the instance.\n* --pin-policy vlaue: Pin policy state none, soft, or hard. Default Pin policy is none.\n* --volumes value: Space separated list of identifiers or names of the volume(s) to associate with the instance.\n* --storage-type value: Storage type for SAP PVM instance deployment when deploying a stock image (use \"ibmcloud pi storage-types\" to see available storage types in the targeted region). If --storage-pool or --storage-affinity is provided then this it cannot be specified. Only valid when one of the IBM supplied stock images is deployed.\n* --storage-pool value: Storage pool for SAP PVM instance deployment. Only valid when you deploy one of the IBM supplied stock images.\n* --storage-affinity value: Affinity policy for storage pool selection. Valid values are \"affinity\" and \"anti-affinity\". If --storage-pool is provided then this it cannot be specified.\n* --storage-affinity-instance value: PVM instance identifier or name to base storage affinity policy against; required if \"--storage-affinity affinity\" is specified and --storage-affinity-volume is not provided.\n* --storage-affinity-volume value: Volume identifier or name to base storage affinity policy against; required if \"--storage-affinity affinity\" is specified and --storage-affinity-instance is not provided.\n* --storage-anti-affinity-instances value: Space separated list of PVM instance identifiers or names to base storage affinity policy against; required if \"--storage-affinity anti-affinity\" is specified and --storage-anti-affinity-volumes is not provided.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas-cli-plugin?topic=power-iaas-cli-plugin-power-iaas-cli-reference"},{"document_id":"ibmcld_11211-22215-24035","score":7.176999113,"text":"\n* --network value: Space-separated list of identifier or name and optional IP address to associate with the instance.\n* --processors value: Number of processors to allocate to the instance. Default is 1 core.\n* --processor-type value: Type of processors: 'shared' or 'dedicated' or 'capped'.\n* --volumes value: Space separated list of identifiers or names of the volume(s) to associate with the instance.\n* --key-name value: Name of SSH key.\n* --sys-type value: Name of System Type (\"s922\", \"e880\", \"e980\"). Default is \"s922\".\n* --storage-type value: Storage type for server deployment when deploying a stock image (use \"ibmcloud pi storage-types\" to see available storage types in the targeted region). If --storage-pool or --storage-affinity is provided then this it cannot be specified. Only valid when one of the IBM supplied stock images is deployed. Storage type and pool for a custom image (an imported image or an image that is created from a PVMInstance capture) defaults to the storage type and pool the image was created in.\n* --storage-connection value: The storage connection type. Valid value is \"vSCSI\".\n* --storage-pool value: Storage pool for server deployment. Only valid when you deploy one of the IBM supplied stock images. Storage type and pool for a custom image (an imported image or an image that is created from a PVMInstance capture) defaults to the storage type and pool the image was created in.\n* --storage-affinity value: Affinity policy for storage pool selection. Valid values are \"affinity\" and \"anti-affinity\". If --storage-pool is provided then this it cannot be specified.\n* --storage-affinity-instance value: PVM instance identifier or name to base storage affinity policy against; required if \"--storage-affinity affinity\" is specified and --storage-affinity-volume is not provided.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas-cli-plugin?topic=power-iaas-cli-plugin-power-iaas-cli-reference"},{"document_id":"ibmcld_08335-4647-6685","score":7.0035948607,"text":"\nNo, any SSH connection to the bootstrap, compute, or storage nodes is only possible through the bastion node for security reasons. You would use the following command to connect to your bootstrap, compute, or storage nodes (the IP address is specific to your particular node): ssh -J ubuntu@<bastion_IP_address> vpcuser@<IP_address>\n\n\n\n\n\n Can I establish an SSH connection between compute and storage nodes? \n\nThe compute and storage clusters are created to not have the same passwordless SSH keys. This ensures that there are separate administration domains for the compute and storage clusters; therefore, SSH between nodes from different clusters is not possible.\n\n\n\n\n\n Does the Spectrum Scale offering support multiple key_pairs to establish SSH to all of the nodes? \n\nNo, the current version of the Spectrum Scale offering supports only a single key_pair that can be provided for access to all of the nodes that are part of the cluster.\n\n\n\n\n\n Can I use my own resource group to configure the resources? \n\nYes, you can provide the resource group of your choice for the deployment of your cluster's VPC resources. Due to the use of trusted profiles in this offering, you must ensure that all of the key_pair values that are specified in the deployment values are created in the same resource group.\n\n\n\n\n\n Which operating system versions are supported for the images used for the compute and storage nodes in Spectrum Scale? \n\nWith Spectrum Scale, you can use custom or stock images based on RHEL 7.9 or RHEL 8.4. For compute nodes, both RHEL 7.9 or 8.4 can be used. For storage nodes, only RHEL 8.4 is supported.\n\n\n\n\n\n Why does Spectrum Scale not allow use of the default value of 0.0.0.0\/0 for security group creation? \n\nFor security reasons, Spectrum Scale does not allow you to provide a default value that would allow network traffic from any external device. Instead, you can provide the address of your user system (for example, by using [https:\/\/ipv4.icanhazip.com\/](https:\/\/ipv4.icanhazip.com\/)) or a multiple IP address range.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-spectrum-scale?topic=hpc-spectrum-scale-spectrum-scale-faqs"},{"document_id":"ibmcld_14492-8686-10586","score":6.9955730819,"text":"\n* Before the service is installed in your environment, a check is completed against the available capacity of the target cluster in the environment to ensure that the service components can fit. The storage capacity check applies only to vSAN storage. For NFS clusters, a new NFS datastore, dedicated to Red Hat OpenShift, is added.\n* The cluster is associated with the Red Hat account from the pull secret that is provided.\n* The Latency Sensitivity setting of the Red Hat OpenShift cluster VMs can affect Kubernetes scheduling performance. By default, the setting is set to Normal, but it can be set to High if you encounter Kubernetes performance issues.\n\n\n\n\n\n\n\n Considerations when you delete Red Hat OpenShift for VMware \n\n\n\n* Before you delete Red Hat OpenShift for VMware, you must remove any additional VMs that you created in the ocp directory on VMware. The VMware Solutions automation removes only the items that were deployed during the initial installation of Red Hat OpenShift (VMs, storage, and NSX). Any node that is deployed after the installation is not cleaned up.\n* The VXLAN, DLR, and the Edge Gateway that were created during the initial deployment of Red Hat OpenShift for VMware is deleted. The VMs that you deployed on VXLAN will lose connectivity after the removal of Red Hat OpenShift for VMware starts.\n* If your cluster uses NFS storage, deleting Red Hat OpenShift deletes the NFS datastore that was added during installation.\n* If you are using a vSAN datastore, delete any persistent volumes that you no longer need before you uninstall Red Hat OpenShift. Any volumes that are not deleted will remain in the vSAN storage after the Red Hat OpenShift uninstallation.\n* Before you delete the service, you must remove any personal VMs that were deployed with this service, from the storage. Red Hat OpenShift only orders personal VMs if it\u2019s not vSAN.\n\n\n\n\n\n\n\n Related links","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_overview"},{"document_id":"ibmcld_01209-2759-4378","score":6.9548706875,"text":"\n* For Endurance (Tiered IOPS), select an IOPS Tier greater than 0.25 IOPS\/GB of your storage. You can increase the IOPS tier at any time. However, decreasing is available only once a month.\n* For Performance (Allocated IOPS), specify new IOPS option for your storage by entering a value in the range 100 - 48,000 IOPS. (Be sure to look at any specific boundaries that are required by size in the order form.)\n\n\n\n4. Review your selection and the new pricing. Click Modify.\n5. Your new storage allocation is going to be available in a few minutes.\n\n\n\n\n\n\n\n Adjusting the IOPS on your Storage from the CLI \n\nYou can update your IOPS from the SLCLI by using the following command.\n\n slcli file volume-modify --help\nUsage: slcli file volume-modify [OPTIONS] VOLUME_ID\n\nOptions:\n-c, --new-size INTEGER New Size of file volume in GB. If no size\nis given, the original size of volume is\nused.\nPotential Sizes: [20, 40, 80, 100,\n250, 500, 1000, 2000, 4000, 8000, 12000]\nMinimum: [the original size of the volume]\n-i, --new-iops INTEGER Performance Storage IOPS, between 100 and 6000\nin multiples of 100 [only for performance\nvolumes] If no IOPS value is specified, the\noriginal IOPS value of the volume will be\nused.\nRequirements: [If original IOPS\/GB\nfor the volume is less than 0.3, new IOPS\/GB\nmust also be less than 0.3. If original\nIOPS\/GB for the volume is greater than or\nequal to 0.3, new IOPS\/GB for the volume must\nalso be greater than or equal to 0.3.]\n-t, --new-tier [0.25|2|4|10] Endurance Storage Tier (IOPS per GB) [only for\nendurance volumes] If no tier is specified,\nthe original tier of the volume will be\nused.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-adjustingIOPS"},{"document_id":"ibmcld_14730-1393-3224","score":6.9008102928,"text":"\n* Windows Server VM with iSCSI storage. This option is not supported by VMware\u00ae Regulated Workloads instances.\n* Single Windows VSI with iSCSI storage. This option is not supported by Security and Compliance Readiness Bundle instances or VMware Regulated Workloads instances.\n* Bare metal server with local storage. This option requires VMware vSphere 7.\n\n\n\n\n\n\n\n Storage size \n\nThe capacity that meets your storage needs. This option is not applicable to the Bare metal server with local storage deployment type.\n\nFor an example that shows what the capacity might be like, see [Capacity planning for backup repositories](https:\/\/helpcenter.veeam.com\/docs\/one\/reporter\/capacity_planning_for_repositories.html?ver=100).\n\n\n\n\n\n Storage performance \n\nThe IOPS (input\/output operations per second) per GB based on your workload requirements. This option is not applicable to the Bare metal server with local storage deployment type.\n\n\n\n\n\n Backup disk \n\nThe backup disks are used as storage repositories for backups. This option is applicable only to the Bare metal server with local storage deployment type.\n\n\n\n\n\n Linux hardened repository \n\nYou can order a Linux\u00ae hardened repository (LHR) to use for immutable storage. If you select a Linux hardened repository, a list of backup disk size options is displayed. Select the disk size that you want to order.\n\nThe Linux hardened repository is only supported for vSphere 7 NSX-T instances.\n\nFor more information, see [Hardened Repository](https:\/\/helpcenter.veeam.com\/docs\/backup\/vsphere\/hardened_repository.html?ver=120) in the Veeam documentation.\n\n\n\n\n\n Number of VMs to license \n\nEnter the number of VMs (virtual machines) to license (minimum 1).\n\nYou can order a maximum of 3,000 licenses. If you need to have multiple licenses under a single license key, you must first purchase them.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeam_ordering"},{"document_id":"ibmcld_01167-5250-5943","score":6.885219134,"text":"\noffset.storage.partitions Number of partitions for connector offsets topic (default 25) \n config.storage.topic Connector configuration topic \n status.storage.topic Connector status topic \n status.storage.partitions Number of partitions for connector status topic (default 5) \n\n\n\nFor example, you can use the following key-value pairs in your properties file:\n\noffset.storage.topic=connect-offsets\nconfig.storage.topic=connect-configs\nstatus.storage.topic=connect-status\n\nConsider reducing the number of partitions if you are making only light use of Kafka Connect.\n\nFor more information about Kafka Connect, see [Kafka Connect overview](http:\/\/kafka.apache.org\/documentation\/connect_overview).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-kafka_connect"},{"document_id":"ibmcld_15869-10798-12628","score":6.8723178804,"text":"\nThis feature can be used in disaster recovery scenarios when you need to start your virtual server instance and data volumes in a different region. Or you can use the remote copy to create storage volumes in a new region to expand your VPC.\n\nWhen you choose to create a cross-regional copy of a snapshot, you need to specify a single snapshot to be copied to the target region. The snapshot is created as normal, and stored in your regional Object Storage. A copy of the snapshot is created in an Object Storage bucket in the target region.\n\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy.\n\nOnly one copy of the snapshot can exist in each region. You can't create a copy in the local (source) region.\n\nThe first time that you create a cross-regional copy, the snapshot is a full copy of the parent volume's data. Subsequent snapshots of the same volume contain only the changes that occurred since the previous snapshot was taken. The only exception to this rule is when you change the encryption type or the encryption key of the parent snapshot. When you change the encryption, the new remote copy needs to be a full copy of the parent snapshot, not an incremental copy.\n\nYou can use and manage the cross-regional snapshot in the target region independently from the parent volume or the original snapshot.\n\nCreating a cross-regional copy affects billing. You're charged for the data transfer and the storage consumption in the target region separately.\n\nYou can create and manage cross-regional snapshot copies in the UI, from the CLI, with the API, or Terraform.\n\n\n\n\n\n Tags for Block Storage for VPC snapshots","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about"},{"document_id":"ibmcld_15883-10840-12670","score":6.8723178804,"text":"\nThis feature can be used in disaster recovery scenarios when you need to start your virtual server instance and data volumes in a different region. Or you can use the remote copy to create storage volumes in a new region to expand your VPC.\n\nWhen you choose to create a cross-regional copy of a snapshot, you need to specify a single snapshot to be copied to the target region. The snapshot is created as normal, and stored in your regional Object Storage. A copy of the snapshot is created in an Object Storage bucket in the target region.\n\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy.\n\nOnly one copy of the snapshot can exist in each region. You can't create a copy in the local (source) region.\n\nThe first time that you create a cross-regional copy, the snapshot is a full copy of the parent volume's data. Subsequent snapshots of the same volume contain only the changes that occurred since the previous snapshot was taken. The only exception to this rule is when you change the encryption type or the encryption key of the parent snapshot. When you change the encryption, the new remote copy needs to be a full copy of the parent snapshot, not an incremental copy.\n\nYou can use and manage the cross-regional snapshot in the target region independently from the parent volume or the original snapshot.\n\nCreating a cross-regional copy affects billing. You're charged for the data transfer and the storage consumption in the target region separately.\n\nYou can create and manage cross-regional snapshot copies in the UI, from the CLI, with the API, or Terraform.\n\n\n\n\n\n Tags for Block Storage for VPC snapshots","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=api"},{"document_id":"ibmcld_15896-10837-12667","score":6.8723178804,"text":"\nThis feature can be used in disaster recovery scenarios when you need to start your virtual server instance and data volumes in a different region. Or you can use the remote copy to create storage volumes in a new region to expand your VPC.\n\nWhen you choose to create a cross-regional copy of a snapshot, you need to specify a single snapshot to be copied to the target region. The snapshot is created as normal, and stored in your regional Object Storage. A copy of the snapshot is created in an Object Storage bucket in the target region.\n\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy.\n\nOnly one copy of the snapshot can exist in each region. You can't create a copy in the local (source) region.\n\nThe first time that you create a cross-regional copy, the snapshot is a full copy of the parent volume's data. Subsequent snapshots of the same volume contain only the changes that occurred since the previous snapshot was taken. The only exception to this rule is when you change the encryption type or the encryption key of the parent snapshot. When you change the encryption, the new remote copy needs to be a full copy of the parent snapshot, not an incremental copy.\n\nYou can use and manage the cross-regional snapshot in the target region independently from the parent volume or the original snapshot.\n\nCreating a cross-regional copy affects billing. You're charged for the data transfer and the storage consumption in the target region separately.\n\nYou can create and manage cross-regional snapshot copies in the UI, from the CLI, with the API, or Terraform.\n\n\n\n\n\n Tags for Block Storage for VPC snapshots","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=ui"}],"retriever_scores":{}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02361-24500-26305","score":13.4032975379,"text":"\n[Information about Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time? [Information about archiving COS files for long term storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-archive) \n Encryption of data at-rest with my own key [5] Can I use my own key to encrypt data at-rest? [Information about encryption of data at-rest](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-encryption) \n Data resiliency [6] Do you need to store the data in a specific geographical location? [Information about resiliency](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-endpoints) \n\n\n\n[1]: Data might sit untouched for long periods of time. For less active workloads, you can create buckets with different storage classes. For example, use the standard storage class for active workloads, where you need to access data at any time.\n\n[2]: You can choose Immutable Object Storage to preserve electronic records and maintain data integrity. When you define a retention policy for a bucket, you are specifying that the data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds. Notice that Immutable Object Storage is available in certain regions only.\n\n[3]: You can use an expiration rule to delete objects automatically after a defined period from the object creation date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-adoption"},{"document_id":"ibmcld_05138-7979-9034","score":13.3865889142,"text":"\nAfter your bucket is created with Activity Tracker and Monitoring, it may take a few minutes for the rules to take effect.\n\nYou are now ready to store data in a secure content store with encryption, monitoring, and audit observability!\n\n\n\n\n\n Get started by uploading data \n\n\n\n* See [uploading data](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-upload) for more information.\n\n\n\n\n\n\n\n Add capabilities \n\nAdd capabilities to protect objects from ransomware and accidental deletion such as [versioning](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-versioning) and [immutable retention polices](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-ol-overview) for supporting immutable storage, and immutable backup and archive data.\n\n\n\n\n\n Library of Object Storage tutorials \n\nCheck out the IBM Cloud Tutorials library for more tutorials when deploying solutions with [Cloud Object Storage](https:\/\/cloud.ibm.com\/docs?tab=tutorials&page=1&pageSize=20&tags=cloud-object-storage).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-secure-content-store"},{"document_id":"ibmcld_14704-5996-7720","score":13.1655690298,"text":"\nThe immutable backup solution architecture consists of:\n\n\n\n* Linux hardened repository - The hardened repository is one or more IBM Cloud bare metal servers that run a supported Linux OS. The hardened repository is configured as an immutable storage repository. The IBM Cloud bare metal servers are ordered with internal disks and a RAID card to present this directly attached storage to the OS to be used as a backup repository.\n* Optionally, the immutable backup solution architecture can include one or more sandboxes. For more information, see [Veeam technologies used in the sandbox](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sandboxveeam).\n\n\n\nThe solution architecture does not show the components to adhere to the 3-2-1 backup rule. The 3-2-1 rule describes a backup architecture that:\n\n\n\n* 3 - At least three copies of data: production, primary backup, and backup copy\n* 2 - Use of two different types of media\n* 1 - Keep one backup copy offsite\n\n\n\nTo adhere to this rule, consider:\n\n\n\n* Use a Scale-Out-Repository capacity tier to copy data to Cloud Object Storage. Currently, IBM Cloud Object Storage cannot be used by Veeam as an immutable capacity tier.\n* Set up a Veeam backup copy job to transfer the backup to another backup repository hosted in another IBM Cloud data center.\n\n\n\n\n\n Related links \n\n\n\n* [Overview of VMware Solutions](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-solution_overview)\n* [Veeam on bare metal server introduction](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeam-bms-archi-intro)\n* [Veeam Backup and Replication 12 overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeamvm_overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-ib"},{"document_id":"ibmcld_04866-4961-6763","score":12.9813906842,"text":"\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https:\/\/www.finra.org\/rules-guidance\/rulebooks\/finra-rules\/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-4961-6763","score":12.9813906842,"text":"\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https:\/\/www.finra.org\/rules-guidance\/rulebooks\/finra-rules\/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_04866-6428-8391","score":12.9113274085,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_14704-4668-6517","score":12.9077891123,"text":"\n* You have a vCenter Server instance with vSAN. This solution architecture does not dictate the type of vSphere data store.\n* You have extra optional services, such as Caveonix, VMware Aria Operations Manager, and VMware Aria Operations\u2122 for Logs.\n* You select a different option for the Veeam service as three options are available. This solution architecture does not dictate the VM option for the Veeam service. VSI or bare metal options are also available. For more information, see [Veeam Backup and Replication 12 overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeamvm_overview).\n* You expand your Veeam service from a simple deployment \"all-in-one\" to an advanced deployment by deploying extra Veeam components on different servers.\n* You select a different ADDNS option. This solution architecture does not dictate the type of option, either two VMs or a single VSI options are available. For more information, see [Domain Name System Configuration](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_orderinginstance-network-interface-settingsvc_orderinginstance-dns-config).\n\n\n\nIf you have a vCenter Server instance that is deployed with the Veeam service added and Veeam is version 12, then this is a suitable base topology for the immutable backup solution architecture. The immutable backup solution architecture consists of:\n\n\n\n* Linux hardened repository - The hardened repository is one or more IBM Cloud bare metal servers that run a supported Linux OS. The hardened repository is configured as an immutable storage repository. The IBM Cloud bare metal servers are ordered with internal disks and a RAID card to present this directly attached storage to the OS to be used as a backup repository.\n* Optionally, the immutable backup solution architecture can include one or more sandboxes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-ib"},{"document_id":"ibmcld_05032-6428-8442","score":12.7743578008,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_14704-7-1976","score":12.7161752676,"text":"\nImmutable backup solution architecture \n\nThe immutable backup solution architecture is suitable for clients who want to extend their VMware vCenter Server\u00ae instance with the Veeam\u00ae service to use immutable storage and minimize costs. The immutable backup solution architecture does not preclude any of the vCenter Server options such as Caveonix, Entrust, and VMware Aria\u00ae Operations\u2122.\n\nThe solution architecture is enabled by the following key technologies:\n\n\n\n* The immutable storage is provided by a Veeam Linux\u00ae hardened repository that is hosted on an IBM Cloud\u00ae bare metal server. For more information, see [Veeam Linux hardened repository](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-lhr).\n* Optionally, if a sandbox is required, the following technologies are used:\n\n\n\n* Veeam vPower NFS service enables a virtual machine (VM) to be started and run directly from the backup file that is hosted in the backup repository.\n* Veeam Instant Restore enables a VM to be started directly from the backup files. Veeam vPower NFS service is used to access the backup files.\n* The Veeam VM Recovery with the restore to new location option, enables a copy of the VM to be started and connected to an isolated network. The backup file is converted to VMDK files and placed in the designated data store.\n* Veeam Secure Restore is only available for Microsoft\u00ae Windows\u00ae VMs. It is an extra option in the VM Recovery workflow that enables the VM to be scanned by antivirus software before you restore the VM. The VMs disks are connected to a mount server and then the antivirus software on the mount server that is used to scan files from the mounted disks.\n* VMware NSX-T\u2122 overlay segments allow the creation of isolated segments onto which copies of the VMs can be attached and isolated from the production VMs.\n* NSX-T distributed firewall provides the required isolation so that only required cybertoolsets can access the copies of the VMs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-ib"},{"document_id":"ibmcld_06805-71772-72968","score":12.436470894,"text":"\nAppends com.ibm.immutable_storage evidence to the summary.\n\n\n\n* See [cocoa locker](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-clicocoa-locker) section on how to configure the Cloud Object Storage bucket.\n\n\n\n* --dry-run: Has an effect when combined with --check-immutable-storage. If used, com.ibm.immutable_storage evidence is only appended to the summary but it does not get uploaded to the evidence locker.\n\n\n\nRun the command:\n\n$ cocoa locker evidence summary docker:\/\/us.icr.io\/foo\/bar@sha256:1234567812345678123456781234567812345678123456781234567812345678 docker:\/\/us.icr.io\/baz\/quux@sha256:1234567812345678123456781234567812345678123456781234567812345678 --scope 11a1aa11-1a11-11a1-aa11-a11a1a1111a1 --scope 22a2aa22-2a22-22a2-aa22-a22a2a2222a2\n\nExample read from stdin:\n\n$ cat <<EOF | cocoa locker evidence summary\ndocker:\/\/us.icr.io\/foo\/bar@sha256:1234567812345678123456781234567812345678123456781234567812345678\ndocker:\/\/us.icr.io\/baz\/quux@sha256:1234567812345678123456781234567812345678123456781234567812345678\nEOF\n\n\n\n\n\n cocoa locker attachment get < attachment-id > \n\nRetrieves an attachment that was previously uploaded with cocoa locker evidence add.\n\nOptions:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cli"}],"retriever_scores":{}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05138-7979-9034","score":21.6614254504,"text":"\nAfter your bucket is created with Activity Tracker and Monitoring, it may take a few minutes for the rules to take effect.\n\nYou are now ready to store data in a secure content store with encryption, monitoring, and audit observability!\n\n\n\n\n\n Get started by uploading data \n\n\n\n* See [uploading data](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-upload) for more information.\n\n\n\n\n\n\n\n Add capabilities \n\nAdd capabilities to protect objects from ransomware and accidental deletion such as [versioning](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-versioning) and [immutable retention polices](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-ol-overview) for supporting immutable storage, and immutable backup and archive data.\n\n\n\n\n\n Library of Object Storage tutorials \n\nCheck out the IBM Cloud Tutorials library for more tutorials when deploying solutions with [Cloud Object Storage](https:\/\/cloud.ibm.com\/docs?tab=tutorials&page=1&pageSize=20&tags=cloud-object-storage).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-secure-content-store"},{"document_id":"ibmcld_02361-24500-26305","score":21.6566470481,"text":"\n[Information about Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time? [Information about archiving COS files for long term storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-archive) \n Encryption of data at-rest with my own key [5] Can I use my own key to encrypt data at-rest? [Information about encryption of data at-rest](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-encryption) \n Data resiliency [6] Do you need to store the data in a specific geographical location? [Information about resiliency](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-endpoints) \n\n\n\n[1]: Data might sit untouched for long periods of time. For less active workloads, you can create buckets with different storage classes. For example, use the standard storage class for active workloads, where you need to access data at any time.\n\n[2]: You can choose Immutable Object Storage to preserve electronic records and maintain data integrity. When you define a retention policy for a bucket, you are specifying that the data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds. Notice that Immutable Object Storage is available in certain regions only.\n\n[3]: You can use an expiration rule to delete objects automatically after a defined period from the object creation date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-adoption"},{"document_id":"ibmcld_06808-1384-2991","score":20.656037953,"text":"\n[Learn more](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cos-bucket-evidencecd-devsecops-cos-bucket-resiliency).\n\n\n\n\n\n Naming your bucket \n\nCloud Object Storage object names consist of the following components:\n\n{NAMESPACE} \/ {PIPELINE_RUN_ID} \/ {TYPE} \/ {FILE_NAME} _ {HASH}\n\n\n\n Examples: \n\nci\/48decaa9-9042-498f-b58d-3577e0ac0158\/evidences\/build-vulnerability-advisor.json_362c06afa88b3f304878f0d0979e834f\n\nci\/48decaa9-9042-498f-b58d-3577e0ac0158\/artifacts\/app-image-va-report.json_b3f30487f0d0979e834f362c06afaaa8\n\nThe name component {NAMESPACE} \/ {PIPELINE_RUN_ID} \/ {TYPE} is useful as a prefix when you're looking for collected data from a certain pipeline run.\n\n\n\n\n\n Retention policy \n\nYou can set Cloud Object Storage buckets to enforce a retention policy or period for uploaded objects, otherwise known as [Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable). Immutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a Write-One-Read-Many (WORM), non-erasable, and non-rewritable manner. You cannot change or delete objects in protected buckets within the retention period, or delete protected buckets with objects themselves until the retention period is over. The policy is enforced until the end of a retention period and the removal of any legal holds.\n\nIt is recommended that teams set a retention policy for the buckets that are used as their evidence locker that stores every object for a minimum of 365 days.\n\n\n\n\n\n\n\n Audit event log","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cos-bucket-evidence"},{"document_id":"ibmcld_05168-15740-17188","score":20.5870542533,"text":"\nfmt.Println(r)\nfmt.Println(e)\n\n}\n\nShow more\n\nThe typical response is exemplified here.\n\n{\nRules: [{\nFilter: {\n\n},\nID: \"id3\",\nStatus: \"Enabled\",\nTransitions: {\nDays: 5,\nStorageClass: \"GLACIER\"\n}]\n}]\n}\n\n\n\n\n\n Immutable Object Storage \n\nUsers can configure buckets with an Immutable Object Storage policy to prevent objects from being modified or deleted for a defined period of time. The retention period can be specified on a per-object basis, or objects can inherit a default retention period set on the bucket. It is also possible to set open-ended and permanent retention periods. Immutable Object Storage meets the rules set forth by the SEC governing record retention, and IBM Cloud administrators are unable to bypass these restrictions.\n\nNote: Immutable Object Storage does not support Aspera transfers via the SDK to upload objects or directories at this stage.\n\nfunc main() {\n\n\/\/ Create Client\nsess := session.Must(session.NewSession())\nclient := s3.New(sess, conf)\n\n\/\/ Create a bucket\ninput := &s3.CreateBucketInput{\nBucket: aws.String(\"<BUCKET_NAME>\"),\n}\nd, e := client.CreateBucket(input)\nfmt.Println(d) \/\/ should print an empty bracket\nfmt.Println(e) \/\/ should print <nil>\n\n\/\/ PUT BUCKET PROTECTION CONFIGURATION\npInput := &s3.PutBucketProtectionConfigurationInput{\nBucket: aws.String(\"<BUCKET_NAME>\"),\nProtectionConfiguration: &s3.ProtectionConfiguration{\nDefaultRetention: &s3.BucketProtectionDefaultRetention{\nDays: aws.Int64(100),\n},","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-using-go"},{"document_id":"ibmcld_04866-4961-6763","score":20.2927287503,"text":"\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https:\/\/www.finra.org\/rules-guidance\/rulebooks\/finra-rules\/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-4961-6763","score":20.2927287503,"text":"\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https:\/\/www.finra.org\/rules-guidance\/rulebooks\/finra-rules\/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_04866-6428-8391","score":20.2436344382,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05075-8514-10699","score":20.0827365752,"text":"\nDeleting a versioned object creates a delete marker. The object may appear to be deleted, but if the object is protected it is not possible to delete the protected version. Delete markers themselves are not protected.\n\n\n\n\n\n Replication \n\nObject Lock cannot be used on the source bucket for replication, only on the destination. Objects will be assigned the default retention period.\n\n\n\n\n\n Key Management Systems \n\nProtected objects will be encrypted using the root key of the bucket. When Object Lock is enabled on a bucket, the root key hosted by Key Protect or Hyper Protect Crypto Services is protected from deletion as long as an associated bucket has Object Lock enabled. This prevents crypto shredding of protected objects.\n\n\n\n\n\n Lifecycle configurations \n\nIt is possible to enable lifecycle policies that [archive locked objects](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-archive), but naturally not those that [expire objects](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry) under retention or legal hold (unprotected objects in the bucket can still be expired).\n\n\n\n\n\n Immutable Object Storage \n\nObject Lock is an alternative to the retention policies available when using Immutable Object Storage. As Object Lock requires versioning to be enabled, and Immutable Object Storage is not compatible with versioning, it is not possible to have both WORM solutions enabled on the same bucket. It is possible to have a mix of buckets in a Service Instance, each using either Immutable Object Storage or Object Lock.\n\n\n\n\n\n Object Tagging \n\nThere are no restrictions on adding or modifying tags on a protected object.\n\n\n\n\n\n Other interactions \n\nThere should be no adverse interactions when using Object Lock with other Object Storage features, such as setting CORS policies, setting IP firewalls or condition based restrictions, bucket quotas, or Code Engine.\n\n\n\n\n\n\n\n IAM actions \n\nThere are new IAM actions associated with Object Lock.\n\n\n\n IAM Action Role \n\n cloud-object-storage.bucket.get_object_lock_configuration Manager, Writer, Reader \n cloud-object-storage.bucket.put_object_lock_configuration Manager, Writer","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-ol-overview"},{"document_id":"ibmcld_05032-6428-8442","score":20.0504403441,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_04866-7-2136","score":19.8965215897,"text":"\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"}],"retriever_scores":{}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03070-4760-6731","score":21.4757403225,"text":"\nYour assistant recognizes that the question triggers the #restaurant_opening_hours intent, but ignores it and displays the prompt associated with the @sys-time slot again instead.\n\n\n\nYou successfully prevented the user from digressing away from the restaurant booking process.\n\n\n\n\n\n Step 4: Digressing to a node that does not return \n\nYou can configure a dialog node to not go back to the node that your assistant digressed away from for the current node to be processed. To demonstrate this, you will change the digression setting for the restaurant hours node. In Step 2, you saw that after digressing away from the restaurant booking node to go to the restaurant opening hours node, your assistant went back to the restaurant booking node to continue with the reservation process. In this exercise, after you change the setting, you will digress away from the Job opportunities dialog to ask about restaurant opening hours and see that your assistant does not return to where it was.\n\n\n\n1. Click to open the Restaurant opening hours node.\n2. Click Customize, and then click the Digressions tab.\n3. Expand the Digressions can come into this node section, and deselect the Return after digression checkbox. Click Apply, and then click ![Close](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/close.png) to close the node edit view.\n4. Click Clear in the Try it out pane to reset the dialog.\n5. To engage the Job opportunities dialog node, type I'm looking for a job.\n\nYour assistant responds by saying, We are always looking for talented people to add to our team. What type of job are you interested in?\n6. Instead of answering this question, ask the bot an unrelated question. Type What time do you open?\n\nYour assistant digresses away from the Job opportunities node to the Restaurant opening hours node to answer your question. Your assistant responds with The restaurant is open from 8:00 AM to 10:00 PM.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial-digressions"},{"document_id":"ibmcld_03404-4859-6857","score":21.4360644953,"text":"\nYour assistant recognizes that the question triggers the #restaurant_opening_hours intent, but ignores it and displays the prompt that is associated with the @sys-time slot again instead.\n\n\n\nYou successfully prevented the user from digressing away from the restaurant booking process.\n\n\n\n\n\n Step 4: Digressing to a node that does not return \n\nYou can configure a dialog node to not go back to the node that your assistant digressed away from for the current node to be processed. To demonstrate this configuration, you will change the digression setting for the restaurant hours node. In Step 2, you saw that after you digressed away from the restaurant booking node to go to the restaurant opening hours node, your assistant went back to the restaurant booking node to continue with the reservation process. In this exercise, after you change the setting, you will digress away from the Job opportunities dialog to ask about restaurant opening hours and see that your assistant does not return to where it left off.\n\n\n\n1. Click to open the Restaurant opening hours node.\n2. Click Customize, and then click the Digressions tab.\n3. Expand the Digressions can come into this node section, and deselect the Return after digression checkbox. Click Apply, and then click ![Close](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/close.png) to close the node edit view.\n4. Click Clear in the \"Try it out\" pane to reset the dialog.\n5. To engage the Job opportunities dialog node, type I'm looking for a job.\n\nYour assistant responds by saying, We are always looking for talented people to add to our team. What type of job are you interested in?\n6. Instead of answering this question, ask the bot an unrelated question. Type What time do you open?\n\nYour assistant digresses away from the Job opportunities node to the Restaurant opening hours node to answer your question. Your assistant responds with The restaurant is open from 8:00 AM to 10:00 PM.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial-digressions"},{"document_id":"ibmcld_03249-22805-24506","score":21.3694303894,"text":"\nGetting confirmation \n\nAdd a slot after the others that asks the user to confirm that the information you have collected is accurate and complete. The slot can look for responses that match the #yes or #no intent.\n\n\n\nConfirmation slot\n\n Check for Save it as Prompt Follow-up if found Follow-up if not found \n\n #yes #no $confirmation I'm going to order you a $size pizza for delivery at $time. Should I go ahead? \n\n\n\nComplex response Because users might include affirmative or negative statements at other times during the dialog (Oh yes, we want the pizza delivered at 5pm) or (no guests tonight, let's make it a small), use the slot_in_focus property to make it clear in the slot condition that you are looking for a Yes or No response to the prompt for this slot only.\n\n(yes || no) && slot_in_focus\n\nThe slot_in_focus property always evaluates to a boolean (true or false) value. Only include it in a condition for which you want a boolean result. Do not use it in slot conditions that check for an entity type and then save the entity value, for example.\n\nIn the Not found prompt, clarify that you are expecting the user to provide a Yes or No answer.\n\n{\n\"output\":{\n\"text\": {\n\"values\": [\n\"Respond with Yes to indicate that you want the order to\nbe placed as-is, or No to indicate that you do not.\"\n]\n}\n}\n}\n\nIn the Found prompt, add a condition that checks for a No response (#no). When found, ask for the information all over again and reset the context variables that you saved earlier.\n\n{\n\"conditions\": \"no\",\n\"output\":{\n\"text\": {\n\"values\": [\n\"Let's try this again. Tell me what size pizza\nyou want and the time...\"\n]\n}\n},\n\"context\":{\n\"size\": null,\n\"time\": null,\n\"confirmation\": null\n}\n}\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-slots"},{"document_id":"ibmcld_03269-4919-6270","score":21.3493066187,"text":"\n* The skill's analytics feature uses this node to learn about the topics that your dialog can't address. The coverage metric looks for occurrences of nodes with the anything_else condition being processed in the user conversation logs. It uses this information to determine the frequency with which your dialog is able to match user requests to intents that can address them. The node is registered by the metric if it conditions on anything_else alone or when it's used in combination with another condition, such as anything_else && positive_feedback.\n\nFor more information about the coverage metric, see [Graphs and statistics](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overviewlogs-overview-graphs).\n* If you want your assistant to redirect queries to the search skill when the dialog is unable to address them, this node recognizes when it's time to initiate the search. It's when a customer's message reaches the anything_else node that the message is sent to the search skill to find a relevant answer in your configured data collections. For more information about searching for an answer, see [Search triggers](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-addskill-search-add-trigger).\n\nMessages that trigger search in this way are still registered by the coverage metric as messages that are not covered.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-start"},{"document_id":"ibmcld_06953-1532-3194","score":20.0281489158,"text":"\nAlternatively, you can add a generative language service named NeuralSeek between the Watson Discovery and Watson Assistant services. For more information, see [Use NeuralSeek to return polished answers from existing help content](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-tutorial-neuralseek).\n\n\n\n How the assistant calls Discovery \n\nWhen a user asks your assistant a question that triggers a search, the following API request is sent to Discovery if Emphasize the answer is enabled.\n\nThe Emphasize the answer feature is available from instances that are managed by IBM Cloud only.\n\n{\n\"aggregation\": \"\",\n\"sort\": \"\",\n\"count\": 10,\n\"return\": [],\n\"filter\": <custom_filter_specified_in_assistant>\n\"passages\": {\n\"enabled\": \"true\",\n\"fields\": [\n<search_config_body_field_specified_in_assistant>\n],\n\"characters\": 325,\n\"per_document\": true,\n\"max_per_document\": 3,\n\"find_answers\": true,\n\"max_answers_per_passage\": 1\n},\n\"highlight\": false,\n\"spelling_suggestions\": false,\n\"table_results\": {\n\"enabled\": false\n},\n\"suggested_refinements\": {\n\"enabled\": false\n}\n}\nShow more\n\nWhen Emphasize the answer is used (\"find_answers\": true), Discovery rescores and reorders the documents to ensure that documents with the highest-quality answers are returned first.\n\n\n\n\n\n Choosing a project type \n\nIf the Conversational Search project type isn't providing the best answers and you want to understand why, switch to using a Document Retrieval project type.\n\nMost often, the Conversational Search project type is the right choice. You get great results from the start, and when you enable extra features like Emphasize the answer, the answers are clear and concise.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-chat-choose-project"},{"document_id":"ibmcld_11141-0-1850","score":19.6841111776,"text":"\n\n\n\n\n\n\n  Why don't I get results in the FAQ or tutorial library? \n\nIf you filter for content in IBM Cloud\u00ae docs FAQs or tutorials libraries and don't get results, try searching the IBM Cloud docs for related content.\n\n  What\u2019s happening \n\nYou filter for content in the IBM Cloud docs [FAQ library](https:\/\/cloud.ibm.com\/docs?tab=faqs) or [tutorials library](https:\/\/cloud.ibm.com\/docs?tab=tutorials) and see the following related message.\n\nIn the FAQ library:\n\n> No FAQs found\n>\n> It seems we can't find what you're looking for. Try updating your filter selections.\n\nIn the tutorials library:\n\n> No tutorials found\n>\n> Sorry, there are no tutorials that match your criteria. Try updating your filter selections.\n\n  Why it\u2019s happening \n\nThere might not be any content with your selected filters, or a topic might not be set with the correct filter value.\n\n  How to fix it \n\nClear the selected filters, and try filtering the library again. If you still don't see any content, try searching all of the IBM Cloud docs for related content.\n\n\n\n1.  Go to the [IBM Cloud docs search](https:\/\/cloud.ibm.com\/docs\/search).\n2.  Enter search terms for the topic that you're trying to find, and press Enter. For example, if the page was about configuring Kubernetes clusters, you might enter config Kubernetes cluster.\n3.  To search in the docs for a product or category of products, refine your search results by clicking the Filter icon ![Filter icon \"Filter\"](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/adcecdbe4e86955f88aac7f3c1e7ec3ff44992ef\/icons\/filter.svg) , selecting the category or product, and clicking Filter.\n\n\n\nIf you still can't find a tutorial or FAQ with information that you were looking for, let the IBM Cloud docs team know about the missing page by [submitting feedback](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-feedback).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-troubleshoot-library"},{"document_id":"ibmcld_02934-24362-26111","score":19.2118948838,"text":"\nShould I go ahead? Your pizza is on its way! see *Complex response* \n\n\n\nComplex response Because users might include affirmative or negative statements at other times during the dialog (Oh yes, we want the pizza delivered at 5pm) or (no guests tonight, let's make it a small), use the slot_in_focus property to make it clear in the slot condition that you are looking for a Yes or No response to the prompt for this slot only.\n\n(yes || no) && slot_in_focus\n\nThe slot_in_focus property always evaluates to a Boolean (true or false) value. Only include it in a condition for which you want a boolean result. Do not use it in slot conditions that checks for an entity type and then save the entity value, for example.\n\nIn the Not found prompt, clarify that you are expecting the user to provide a Yes or No answer.\n\n{\n\"output\":{\n\"text\": {\n\"values\": [\n\"Respond with Yes to indicate that you want the order to\nbe placed as-is, or No to indicate that you do not.\"\n]\n}\n}\n}\n\nIn the Found prompt, add a condition that checks for a No response (#no). When found, ask for the information all over again and reset the context variables that you saved earlier.\n\n{\n\"conditions\": \"no\",\n\"output\":{\n\"text\": {\n\"values\": [\n\"Let's try this again. Tell me what size pizza\nyou want and the time...\"\n]\n}\n},\n\"context\":{\n\"size\": null,\n\"time\": null,\n\"confirmation\": null\n}\n}\nShow more\n\n\n\n\n\n Replacing a slot context variable value \n\nIf, at any time before the user exits a node with slots, the user provides a new value for a slot, then the new value is saved in the slot context variable, replacing the previously-specified value. Your dialog can acknowledge explicitly that this replacement has occurred by using special properties that are defined for the Found condition:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots"},{"document_id":"ibmcld_07120-7686-9754","score":18.5455786378,"text":"\n15c3-5 In November 2011, the SEC implemented the final provision of Rule 15c3-5 curbing unfiltered market access. The provision mandated that brokers verify their clients\u2019 order flow for compliance with credit and capital thresholds before routing to market centers\n\nAgain, the answer is accurate (despite there being some extraneous text at the beginning of the passage).\n\nIn both examples, a somewhat complex question is asked and the passage that is returned provides a valid answer.\n\nHowever, not every question returns as clear an answer. Next, we try some queries that generate answers we might want to improve.\n4. Enter Where do muni bond trades get reported to?\n\nIn this case, the response does not answer the question completely.\n\nPost-trade transparency, in the form of transaction reports, generally is available for corporate and municipal bonds. 1. Transaction Reports in Corporate Bonds: TRACE Transactions in corporate bonds must be reported to the Trade Reporting\n5. Similarly, the search query, What are PTFs?, does not return a direct answer.\n\nDespite the surge in trading volume during the event window, there was no noticeable change in net positions of PTFs or bank-dealers. However, the report also finds evidence that some PTFs and bank-dealers may have contributed to the volatility\n\n\n\nYour project is answering some of the questions successfully. Only one passage is being returned for each query. Let's see whether we can improve the responses that are given to these simpler search queries.\n\n\n\n\n\n Step 5: Create a user-trained Smart Document Understanding (SDU) model \n\nTo improve the quality of the search results, build a Smart Document Understanding model for this document. The model helps Discovery understand the document structure. You can then instruct Discovery about which sections of the document to search and which sections to ignore.\n\n\n\n1. From the Improvement tools panel of the Improve and customize page, expand Define structure, and then click New fields.\n\nZoom\n\n![Shows the New fields tool in the Improvement tools panel.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-tutorial-sdu"},{"document_id":"ibmcld_06953-2615-5096","score":18.268008119,"text":"\nWhen Emphasize the answer is used (\"find_answers\": true), Discovery rescores and reorders the documents to ensure that documents with the highest-quality answers are returned first.\n\n\n\n\n\n Choosing a project type \n\nIf the Conversational Search project type isn't providing the best answers and you want to understand why, switch to using a Document Retrieval project type.\n\nMost often, the Conversational Search project type is the right choice. You get great results from the start, and when you enable extra features like Emphasize the answer, the answers are clear and concise. However, for advanced use cases, or if you want to be able to troubleshoot issues, a Document Retrieval project type might be a better fit.\n\nTo help you choose the right Discovery project type, review the project type differences that are described in the following table.\n\n\n\nProject type details\n\n Function Conversational Search Document Retrieval \n\n Enrichment support Only the Part of Speech enrichment is applied. The Part of Speech and Entities enrichments are applied. The Entities enrichment is helpful for identifying important information and introduces more ways to filter query results. \n Testing queries from the Improve and customize page in Discovery You see only one of the responses that are returned from the chatbot. You cannot see all of the available responses and cannot analyze individual query results. You can filter query results by enrichment-based facets. You can review details about fields that are indexed in the source documents that are returned for a query. Access to more information makes it easier to troubleshoot unexpected results. \n Search triggers Returns answers from the text field automatically. If answers are stored in another field, you must change the configuration. You can apply a Smart Document Understanding (SDU) model or enrichments to your collections and retrieve useful information from fields other than text when search is triggered from the assistant. \n\n\n\nFor both project types, the best way to test is to trigger search from the Watson Assistant preview. When you configure search support for an assistant, you can fine-tune the experience in ways that aren't available in Discovery.\n\nAnd settings that are available from the Search results tool for a Document Retrieval project type are replaced by configuration settings that you specify in Watson Assistant. For example, the query response title and body are defined in Watson Assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-chat-choose-project"},{"document_id":"ibmcld_07120-6565-8229","score":17.8489134195,"text":"\n(https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/tut-sdu-activity.png)\n\nFigure 6. Activity page that shows the data upload is finished\n\n\n\n\n\n Step 4: Test your project \n\n\n\n1. After the crawl is completed, go to the Improve and customize page. From the navigation panel, click Improve and customize.\n2. In the Search field, enter When did the Flash Crash occur and why?\n\nThe following passage is returned as the response:\n\nThese could in turn generate systemic destabilizing market events, such as the May 2010 \u201cFlash Crash.\u201d The \u201cFlash Crash\u201d occurred on May 6, 2010, when an algorithm rapidly sold 75,000 S&P500 e-mini futures contracts.\n\nThe returned passage contains an accurate answer to the question.\n\nZoom\n\n![Shows the passages that are returned by search.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/tut-sdu-search-fast-crash.png)\n\nFigure 7. Search results\n3. Ask another question, What is the purpose of Rule 15c3-5?\n\nThe following passage is returned as the response:\n\nmechanism.306 b. 15c3-5 In November 2011, the SEC implemented the final provision of Rule 15c3-5 curbing unfiltered market access. The provision mandated that brokers verify their clients\u2019 order flow for compliance with credit and capital thresholds before routing to market centers\n\nAgain, the answer is accurate (despite there being some extraneous text at the beginning of the passage).\n\nIn both examples, a somewhat complex question is asked and the passage that is returned provides a valid answer.\n\nHowever, not every question returns as clear an answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-tutorial-sdu"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07098-4987-7173","score":24.4367624025,"text":"\nUp to 60 passages are sent to the answer-finding service. How these 60 passages are chosen differs based on the passages.per_document parameter value.\n\n\n\n* If passages.per_document is false, the top 60 passages from all of the documents that are returned by search are chosen based on their passage scores only.\n* If passages.per_document is true, the returned documents are ranked first, and then the top 60 passages from these top documents are chosen.\n\nFor example, if you set the query to return 100 documents (count=100) and ask for 2 passages from each document (passages.max_per_document=2), then 2 passages are chosen from each of the 30 top-ranked documents (2 x 30 = 60 passages) only. No passages are chosen from the remaining 70 documents.\n\n\n\nIf your goal is to get the best 10 short answers, a good approach is to give the answer-finding feature various passages from more documents than just the top 10. To do so, set passages.per_document to true, and then request 20 documents and up to 3 passages from each document with the answer-finding feature enabled. The answer-finding feature searches for answers in up to 20*3 = 60 passages.\n\nAnswer finding does not use the transformed query string that is generated by query analysis. Instead, it uses a copy of the user's original input that is stored at query time to find the best short answer. If the answer-finding module is confident that it found an answer in one of the passages, the answer confidence score is combined with the document and passage scores to produce a final ranking, which can promote a document or passage that might otherwise be missed.\n\n\n\n\n\n Answer-finding API details \n\nThe answer-finding API adds the following parameters to the passage section of the query API:\n\n\n\n* find_answers is optional and defaults to false. If it is set to true (and the natural_language_query parameter is set to a query string), the answer-finding feature is enabled.\n* max_answers_per_passage is optional and defaults to 1. In this case, the answer-finding feature finds the number of answers that are specified at most from any one passage.\n\n\n\nA section is also added to the return value within each passage object.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parameters"},{"document_id":"ibmcld_07098-1507-3651","score":21.539409606,"text":"\nWhen the answer-finding feature is enabled, Discovery also provides a \"short answer\" within the passage, and a confidence score to show whether the \"short answer\" answers the question that is explicit or implicit in the user query. Applications that use the answer-finding feature can display the short answer alone or can display the short answer emphasized in the context of the full passage. For most applications, displaying the short answer emphasized within the full passage is preferable, because answers generally make more sense in context.\n\nThe answer finding feature behaves in the following ways:\n\nIn the passage examples that follow, the short answers are shown in bold font.\n\n\n\n* Finds answers. It doesn\u2019t create answers. The answer must be part of the text; it can't be inferred.\n\n\u201cWhat was IBM\u2019s revenue in 2022?\u201d can get a correct answer if you have a document that states what IBM\u2019s revenue was in 2022. However, if you have a document that lists what IBM\u2019s revenue was in each quarter of 2022, it doesn't add them up and give you a total.\n* Handles synonyms and lexical variations if the answer is available.\n\n\n\n* Example question: \u201cWhen did IBM purchase Red Hat?\u201d\n* Passage: \u201cIBM closed its $34 billion acquisition of Red Hat in July of 2019.\"\n\n\n\n* Combines information across multiple sentences if they are close together (within approximately 2,000 characters).\n\n\n\n* Example question: \u201cWhen did IBM purchase Red Hat?\u201d\n* Passage: \u201cIBM acquired Red Hat for $34 billion. The deal closed in July of 2019.\"\n\n\n\n* Handles implicit questions similar to the way it would handle the equivalent explicit question.\n\nExample questions:\n\n\n\n* company that developed the AS\/400\n* What company developed the AS\/400?\n\n\n\n* Works well with questions with longer phrase or clause answers.\n\n\n\n* Example question: How do I flip a pancake?\n* Passage: The key to getting a world-class pancake is flipping it properly. The best way to flip a pancake is to stick a spatula under it, lift it at least 4 inches in the air, and quickly rotate the spatula 180 degrees.\n\n\n\n* Many how or why questions are only fully answered by much longer spans of text.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parameters"},{"document_id":"ibmcld_07191-6546-8841","score":20.0672747588,"text":"\nA boolean that specifies whether the service returns a set of the most relevant passages from the documents returned by a query that uses the natural_language_query parameter. The passages are generated by sophisticated Watson algorithms to determine the best passages of text from all of the documents returned by the query. The default is false.\n\nThe passages parameter can only be used on private collections. It cannot be used on the IBM Watson\u2122 Discovery News collection.\n\nDiscovery attempts to return passages that start at the beginning of a sentence and stop at the end using sentence boundary detection. To do so, it first searches for passages approximately the length specified in the [passages.characters parameter](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parameterspassages_characters). The default is 400. It then expands each passage to the limit of twice the specified length to return full sentences. If your passages.characters parameter is short and\/or the sentences in your documents are very long, there might be no sentence boundaries close enough to return the full sentence without going over twice the requested length. In that case, Discovery stays within the limit of twice the passages.characters parameter, so the passage returned does not include the entire sentence and omits the beginning, end, or both.\n\nBecause sentence boundary adjustments expand passage size, there is a substantial increase in average passage length. If your application has limited screen space, you might want to set a smaller value for passages.characters and\/or truncate the passages that are returned by Discovery. Sentence boundary detection works for all supported languages and uses language-specific logic.\n\nYou can adjust the fields in the documents over which passage retrieval searches with the [passages.fields](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parameterspassages_fields) parameter.\n\nThe passages parameter returns matching passages (passage_text), as well as the score, document_id, the name of the field the passage was extracted from (field), and the starting and ending characters of the passage text within the field (start_offset and end_offset), as shown in the following example. The query is shown at the top of the example.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parameters"},{"document_id":"ibmcld_06953-1532-3194","score":20.0365532888,"text":"\nAlternatively, you can add a generative language service named NeuralSeek between the Watson Discovery and Watson Assistant services. For more information, see [Use NeuralSeek to return polished answers from existing help content](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-tutorial-neuralseek).\n\n\n\n How the assistant calls Discovery \n\nWhen a user asks your assistant a question that triggers a search, the following API request is sent to Discovery if Emphasize the answer is enabled.\n\nThe Emphasize the answer feature is available from instances that are managed by IBM Cloud only.\n\n{\n\"aggregation\": \"\",\n\"sort\": \"\",\n\"count\": 10,\n\"return\": [],\n\"filter\": <custom_filter_specified_in_assistant>\n\"passages\": {\n\"enabled\": \"true\",\n\"fields\": [\n<search_config_body_field_specified_in_assistant>\n],\n\"characters\": 325,\n\"per_document\": true,\n\"max_per_document\": 3,\n\"find_answers\": true,\n\"max_answers_per_passage\": 1\n},\n\"highlight\": false,\n\"spelling_suggestions\": false,\n\"table_results\": {\n\"enabled\": false\n},\n\"suggested_refinements\": {\n\"enabled\": false\n}\n}\nShow more\n\nWhen Emphasize the answer is used (\"find_answers\": true), Discovery rescores and reorders the documents to ensure that documents with the highest-quality answers are returned first.\n\n\n\n\n\n Choosing a project type \n\nIf the Conversational Search project type isn't providing the best answers and you want to understand why, switch to using a Document Retrieval project type.\n\nMost often, the Conversational Search project type is the right choice. You get great results from the start, and when you enable extra features like Emphasize the answer, the answers are clear and concise.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-chat-choose-project"},{"document_id":"ibmcld_07098-17286-19445","score":19.9700043965,"text":"\n\" digital and <em>hybrid<\/em> <em>cloud<\/em> transformation.<\/p>n<p>URL: http:\/\/www.ibm.com\/press\/us\/en\/pressrelease\/50837.wss<\/p>nnnn<\/body><\/html>\",\n\" continuity software for nenterprise data centers and <em>cloud<\/em> infrastructure. Adding these ncapabilities\"\n] ! !\n}\n}\nShow more\n<-- <\/section \"id=\"section-highlight\" \"> --><-- <section \"id=\"section-passages\" \"> --> passages A Boolean that specifies whether the service returns a set of the most relevant passages from the documents that are returned by a query that uses the natural_language_query parameter. The passages are generated by sophisticated Watson algorithms that determine the best passages of text from all of the documents returned by the query. The default value for the parameter differs based on your project type. For more information about default values, see Default query settings]] .Discovery attempts to return passages that start at the beginning of a sentence and stop at the end by using sentence boundary detection. To do so, it first searches for passages approximately the length specified in the passages.characters parameter]passages.characters_ parameter] (for most project types, the default is 200). It then expands each passage to the limit of twice the specified length so as to return full sentences. If your passages.characters parameter is short or the sentences in your documents are long there might be no sentence boundaries close enough to return the full sentence without going over twice the requested length. In that case, Discovery stays within the limit of twice the passages.characters parameter, so the passages that are returned might not include the entire sentence and can omit the beginning, end, or both.Since sentence boundary adjustments expand passage size, the average passage length can increase. If your application has limited screen space, you might want to set a smaller value for passages.characters or truncate the passages that are returned by Discovery. Sentence boundary detection works for all supported languages and uses language-specific logic.Passages are grouped with each document result and are ordered by passage relevance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parameters"},{"document_id":"ibmcld_07098-18799-20669","score":19.7295587336,"text":"\nIn that case, Discovery stays within the limit of twice the passages.characters parameter, so the passages that are returned might not include the entire sentence and can omit the beginning, end, or both.Since sentence boundary adjustments expand passage size, the average passage length can increase. If your application has limited screen space, you might want to set a smaller value for passages.characters or truncate the passages that are returned by Discovery. Sentence boundary detection works for all supported languages and uses language-specific logic.Passages are grouped with each document result and are ordered by passage relevance. Including passage retrieval in queries increases the response time because it takes more time to score the passages.You can adjust the fields in the documents for passage retrieval to search with the passages.fields]passages.fields] parameter.The passages parameter returns matching passages (passage_text), and the score, document_id, the name of the field that the passage was extracted from (field), and the starting and ending characters of the passage text within the field (start_offset and end_offset), as shown in the following example. curl -H \"Authorization: Bearer {token}\" 'https:\/\/{hostname}\/{instance_name}\/v2\/projects\/{project_id}\/collections\/{collection_id}\/query?version=2019-11-29&natural_language_query=Hybrid%20cloud%20companies&passages=true&passages.per_document=false'\nThe JSON that is returned from the query has the following format: {\n\"matching_results\":2,\n\"passages\":\n{\n\"document_id\":\"ab7be56bcc9476493516b511169739f0\",\n\"passage_score\":15.230205287402338,\n\"passage_text\":\"a privately held company that provides hybrid cloud recovery, cloud migration and business continuity software for enterprise data centers and cloud infrastructure.\",\n\"start_offset\":120,\n\"end_offset\":300,\n\"field\":\"text\"\n},\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parameters"},{"document_id":"ibmcld_07103-22905-25134","score":19.6597573735,"text":"\nFor more information about adding a document classifier by using the product user interface, see [Classifying documents](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-cm-doc-classifier).\n\n\n\n\n\n 21 March 2022 \n\nVisualize enrichments found in your documents\n: When you click to view the passage from a search result, a document preview page is displayed that shows a representation of the original document where the search result was found. For most document types, you can open a new advanced view of the document to see useful summary information, such as the number of occurrences of any enrichments that are detected in the document. You also can select one of the enrichments to highlight every occurrence of the element within the document text.\n\nCurrently, only the Entities and Keywords enrichments are listed.\n\nImproved format of search results from PDF documents\n: When you click to view a passage from a search result that is extracted from a PDF document, a document preview page is displayed that shows the returned passage in the context of the original PDF page.\n\nThe in-context view is available for PDF files to which a Smart Document Understanding model is applied. The rich preview does not work on images, meaning it doesn't work on scanned PDF documents. The in-context view is available for PDFs in all languages; however, the enrichment highlighting might be misaligned in some languages.\n\nTell us what you think\n: Share your opinions and ideas with us at any time by clicking the Share feedback button from the page header of the product user interface.\n\n\n\n\n\n 10 March 2022 \n\nManage the data in a collection from the new Manage data page\n: You can now access the Manage data page for a collection from the Manage collections navigation pane. Go there to see a list of the documents in your collection and get a quick view of information about the documents. You can also delete documents from a collection with just a few clicks. For more information, see [Excluding content from query results](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-hide-data).\n\n\n\n\n\n 15 February 2022 \n\nAn alternative authentication mechanism is available for Microsoft Sharepoint Online connectors","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_10811-8754-10304","score":19.6482095283,"text":"\n[query](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery) Action username, password, iam_access_token, iam_apikey, iam_url, headers, headers[X-Watson-Learning-Opt-Out], url, environment_id, collection_id, filter, query, natural_language_query, passages, aggregation, count, return_fields, offset, sort, highlight, passages_fields, passages_count, passages_characters, deduplicate, deduplicate_field, similar, similar_document_ids, similar_fields Query your collection. \n [query-entities](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-entities) Action username, password, iam_access_token, iam_apikey, iam_url, headers, headers[X-Watson-Learning-Opt-Out], url, environment_id, collection_id, feature, entity, context, count, evidence_count Query a Knowledge Graph entity. \n [query-notices](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-notices) Action username, password, iam_access_token, iam_apikey, iam_url, headers, headers[X-Watson-Learning-Opt-Out], url, environment_id, collection_id, filter, query, natural_language_query, passages, aggregation, count, return_fields, offset, sort, highlight, passages_fields, passages_count, passages_characters, deduplicate_field, similar, similar_document_ids, similar_fields Query system notices. \n [query-relations](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-relations) Action username, password, iam_access_token, iam_apikey, iam_url, headers, headers[X-Watson-Learning-Opt-Out], url, environment_id, collection_id, entities, context, sort, filter, count, evidence_count Query a Knowledge Graph relationship.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_discovery"},{"document_id":"ibmcld_07120-6565-8229","score":19.3186150586,"text":"\n(https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/tut-sdu-activity.png)\n\nFigure 6. Activity page that shows the data upload is finished\n\n\n\n\n\n Step 4: Test your project \n\n\n\n1. After the crawl is completed, go to the Improve and customize page. From the navigation panel, click Improve and customize.\n2. In the Search field, enter When did the Flash Crash occur and why?\n\nThe following passage is returned as the response:\n\nThese could in turn generate systemic destabilizing market events, such as the May 2010 \u201cFlash Crash.\u201d The \u201cFlash Crash\u201d occurred on May 6, 2010, when an algorithm rapidly sold 75,000 S&P500 e-mini futures contracts.\n\nThe returned passage contains an accurate answer to the question.\n\nZoom\n\n![Shows the passages that are returned by search.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/tut-sdu-search-fast-crash.png)\n\nFigure 7. Search results\n3. Ask another question, What is the purpose of Rule 15c3-5?\n\nThe following passage is returned as the response:\n\nmechanism.306 b. 15c3-5 In November 2011, the SEC implemented the final provision of Rule 15c3-5 curbing unfiltered market access. The provision mandated that brokers verify their clients\u2019 order flow for compliance with credit and capital thresholds before routing to market centers\n\nAgain, the answer is accurate (despite there being some extraneous text at the beginning of the passage).\n\nIn both examples, a somewhat complex question is asked and the passage that is returned provides a valid answer.\n\nHowever, not every question returns as clear an answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-tutorial-sdu"},{"document_id":"ibmcld_07046-13262-15106","score":19.1765086871,"text":"\n* The field with the longest string value and highest number of distinct values is chosen.\n* If more than one field meets the previous condition, one of the fields is chosen at random.\n\n\n\n* If you want to apply an enrichment to a nested field, you must create a Content Mining project, and then apply the enrichment to the field. If you want to use a project type other than Content Mining, you can reuse the collection that you created with the Content Mining project type elsewhere. For more information, see [Applying enrichments](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-connector-database-cp4dconnector-database-cp4d-enrich-db).\n\n\n\nYou can specify the normalizations and conversions objects in the [Update a collection](https:\/\/cloud.ibm.com\/apidocs\/discovery-dataupdatecollection) method of the API to move or merge JSON fields.\n\n\n\n\n\n\n\n How passages are derived \n\nDiscovery uses sophisticated algorithms to determine the best passages of text from all of the documents that are returned by a query. Passages are returned per document by default. They are displayed as a section within each document query result and are ordered by passage relevance.\n\nDiscovery uses sentence boundary detection to pick a passage that includes a full sentence. It searches for passages that have an approximate length of 200 characters, then looks at chunks of content that are twice that length to find passages that contain full sentences. Sentence boundary detection works for all supported languages and uses language-specific logic.\n\nFor all project types except Conversational Search, you can change how the passages are displayed in the search results from the Customize display > Search results page. For example, you can configure the number of passages that are shown per document and the maximum character size per passage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-index-overview"}],"retriever_scores":{}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-1076793-1078629","score":28.5584693997,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1079289-1081125","score":28.5584693997,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01660-7085-8964","score":28.3285534341,"text":"\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_07578-1075256-1077185","score":27.2707449145,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1077752-1079681","score":27.2707449145,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_04488-133306-134586","score":26.7602105165,"text":"\ncreate a Cloud Object Storage (COS) instance\n \"lite\" is the pricing plan and \"global\" is the region\n$ COS_NAME=my-cos-1\n\n$ ibmcloud resource service-instance-create $COS_NAME cloud-object-storage lite global\n\nCreating service instance my-cos-1 in resource group Default of account <account name> as <email address>...\nOK\nService instance my-cos-1 was created.\nName: my-cos-1\nID: crn:v1:bluemix:public:cloud-object-storage:global:a\/ea998d3389c3473aa0987652b46fb146:4b636e74-f3ca-40bb-80b8-3bd21801ccb8::\nGUID: 4b636e74-f3ca-40bb-80b8-3bd21801ccb8\nLocation: global\nState: active\nType: service_instance\nSub Type:\nAllow Cleanup: false\nLocked: false\nCreated at: 2020-06-15T16:03:39Z\nUpdated at: 2020-06-15T16:03:39Z\nLast Operation: Status create succeeded Message Completed create instance operation\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=4b636e74-f3ca-40bb-80b8-3bd21801ccb8\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1\n\n$ ibmcloud resource service-instance-create $KMS_NAME kms tiered-pricing us-south\n\nCreating service instance my-kms-1 in resource group Default of account <account name> as <email address>...\nOK\nService instance my-kms-1 was created.\nName: my-kms-1","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-reference"},{"document_id":"ibmcld_09055-96989-98298","score":25.8003317383,"text":"\nThe ibmcloud resource service-instance-create command requires a service plan name and a location, which is in the catalog. show the catalog offerings for cloud object storage (COS) and Key Protect\n$ ibmcloud catalog service cloud-object-storage\n\n$ ibmcloud catalog service kms\n create a Cloud Object Storage (COS) instance\n \"lite\" is the pricing plan and \"global\" is the region\n$ COS_NAME=my-cos-1\n\n$ ibmcloud resource service-instance-create $COS_NAME cloud-object-storage lite global\n\nCreating service instance my-cos-1 in resource group Default of account <account name> as <email address>...\nOK\nService instance my-cos-1 was created.\nName: my-cos-1\nID: crn:v1:bluemix:public:cloud-object-storage:global:a\/ea998d3389c3473aa0987652b46fb146:4b636e74-f3ca-40bb-80b8-3bd21801ccb8::\nGUID: 4b636e74-f3ca-40bb-80b8-3bd21801ccb8\nLocation: global\nState: active\nType: service_instance\nSub Type:\nAllow Cleanup: false\nLocked: false\nCreated at: 2020-06-15T16:03:39Z\nUpdated at: 2020-06-15T16:03:39Z\nLast Operation:\nStatus create succeeded\nMessage Completed create instance operation\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=4b636e74-f3ca-40bb-80b8-3bd21801ccb8\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_01660-8584-10307","score":25.3151124516,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_09055-104201-105670","score":25.1725854591,"text":"\nService instance my-cos-1 with ID crn:v1:bluemix:public:cloud-object-storage:global:a\/ea998d3389c3473aa0987652b46fb146:4b636e74-f3ca-40bb-80b8-3bd21801ccb8:: is deleted successfully\n\n view resources (COS and KMS should no longer exist)\n$ ibmcloud resource service-instances\n\nRetrieving instances with type service_instance in resource group Default in all locations under account <account name> as <email address>...\nOK\nNo service instance found.\n<-- <\/section \"id=\"section-kp-registrations-example-2\" \"> --><-- <section \"id=\"section-kp-registrations-example-3\" \"> --> Example 3 This example shows what happens when one of the following occurs between COS and Key Protect (KP) - COS is not able to access the Key Protect root key.<-- <ul> --> * Delete the KP root key * Remove the CMS\/KP authorization policy<-- <\/ul> -->This example does not show command output except when relevant. create a Cloud Object Storage (COS) service instance\n \"lite\" is the pricing plan and \"global\" is the region\n$ COS_NAME=my-cos-1\n\n$ ibmcloud resource service-instance-create $COS_NAME cloud-object-storage lite global\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=c488e11a-c8a0-4688-b002-9327266ea55f\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1\n\n$ ibmcloud resource service-instance-create $KMS_NAME kms tiered-pricing us-south\n\n capture the Key Protect (KP) instance id (GUID)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_00558-2925-4840","score":25.1674844812,"text":"\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service. To create a new instance, either delete your existing Lite plan instance or select a paid plan.\n\n\n\n\n\n Standard plan \n\nThe IBM Cloudant Standard plan is available to all paid IBM Cloud\u00ae accounts, either as pay-as-you-go or subscription, and scales to meet the needs of your application. The Standard plan is priced based on two factors: the provisioned throughput capacity that is allocated, and the amount of data that is stored in the instance.\n\nPricing is pro-rated hourly with a starting provisioned throughput capacity of 100 reads per second, 50 writes per second, and 5 global queries per second. This rate is equal to a starting cost of USD $0.105 per hour. You can toggle the provisioned throughput capacity up or down by using the user interface or API. Toggle in increments of 100 reads per second, 50 writes per second, and 5 global queries per second. Costs are calculated for the provisioned throughput capacity that is allocated and not on the metered volume of requests. The Standard plan includes 20 GB of data storage. If you store more than 20 GB, you're charged a defined cost per GB per hour.\n\nRefer to the IBM Cloud Pricing Calculator in the dashboard for pricing at different capacities and currencies, and the [pricing](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pricingpricing) information for examples to estimate costs.\n\n\n\n\n\n Dedicated Hardware plan","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3868528072,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.5802792109}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07214-60873-63067","score":26.5235164145,"text":"\nThese queries can be used as a starting point for writing your own queries. Sample queries are available for both IBM Watson\u2122 Discovery News and private collections.\n\nNew beta visual aggregation builder : Added the beta ability to write aggregations with a visual builder. Click Build in visual mode above the Write an aggregation query using the Discovery Query Language field to try it out. As you build your aggregation visually, the query displays in the Discovery Query Language below it.\n: The visual aggregation builder is currently supported only as a beta capability.\n\n\n\n\n\n 31 July 2017 \n\nNew release of Discovery News : A new version of IBM Watson\u2122 Discovery News was released. The original version is renamed as IBM Watson\u2122 Discovery News Original and is retired, with a removal from service date of 15 January 2018. : If you create a new instance of Discovery, you only have access to the new version of IBM Watson\u2122 Discovery News.\n\nNew pricing structure : A new pricing plan for IBM Watson\u2122 Discovery was released. See [Discovery pricing plans](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-discovery-pricing-plans) for details.\n\nUpdate to version string : The version string for all API calls changed to 2017-08-01 from 2017-07-19. This version includes updates for the new pricing plan and the new version of Watson Discovery News. Update the version string to avoid conflicts and possible errors.\n\n\n\n\n\n 19 July 2017 \n\nChange to Pricing plans : Pricing changes will take effect on 1 August 2017. : Users that are currently on the deprecated 30 day free trial plan will be automatically migrated to the Lite plan. As a result of this transition, existing users might meet or exceed the lite plan limit on documents (2000), storage (200Mb), or number of collections (2). If you exceed the limit of the Lite plan, you cannot add any additional content into the service, but you can still query collections. : View the current status of all these limits by using the Discovery tooling or API. To resume adding content to the Discovery instance, you must complete one of the following actions: : Remove collections or documents so that limits of the Lite plan are not exceeded.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_16242-3349-4513","score":26.1057971756,"text":"\n[Action response mode](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/response-mode-modal.png)\n\nAction response mode\n2. Click the other mode if you want to change it, and then click Save response mode.\n\n\n\n\n\n\n\n Override system defaults modes \n\nEnterprise\n\nFor Lite and Plus plans, the default settings can\u2019t be changed. For Enterprise plans, you can override system defaults to customize each mode in global settings for actions.\n\nTo override system defaults:\n\n\n\n1. Set the Override System Defaults toggle to On. This toggle is available only for Enterprise plans.\n2. Use the menu to modify any of the settings for either mode.\n\n\n\nIf you customize, the choices for each setting are;\n\n\n\nMode customization choices\n\n Setting Choices \n\n Clarify when one action matches More often, Sometimes, Less often \n Clarify when more than one action matches More often, Sometimes, Less often \n Offer support option when asking a clarifying question More often, Sometimes, Less often \n Step validation attempts before offering support 1 time, 2 times, 3 times \n\n\n\nIf you customize modes, be sure to test any changes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-action-response-modes"},{"document_id":"ibmcld_00558-2925-4840","score":25.1724644285,"text":"\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service. To create a new instance, either delete your existing Lite plan instance or select a paid plan.\n\n\n\n\n\n Standard plan \n\nThe IBM Cloudant Standard plan is available to all paid IBM Cloud\u00ae accounts, either as pay-as-you-go or subscription, and scales to meet the needs of your application. The Standard plan is priced based on two factors: the provisioned throughput capacity that is allocated, and the amount of data that is stored in the instance.\n\nPricing is pro-rated hourly with a starting provisioned throughput capacity of 100 reads per second, 50 writes per second, and 5 global queries per second. This rate is equal to a starting cost of USD $0.105 per hour. You can toggle the provisioned throughput capacity up or down by using the user interface or API. Toggle in increments of 100 reads per second, 50 writes per second, and 5 global queries per second. Costs are calculated for the provisioned throughput capacity that is allocated and not on the metered volume of requests. The Standard plan includes 20 GB of data storage. If you store more than 20 GB, you're charged a defined cost per GB per hour.\n\nRefer to the IBM Cloud Pricing Calculator in the dashboard for pricing at different capacities and currencies, and the [pricing](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pricingpricing) information for examples to estimate costs.\n\n\n\n\n\n Dedicated Hardware plan","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-2979-4903","score":25.150078495,"text":"\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service. To create a new instance, either delete your existing Lite plan instance or select a paid plan.\n\n\n\n\n\n Standard plan \n\nThe IBM Cloudant Standard plan is available to all paid IBM Cloud\u00ae accounts, either as pay-as-you-go or subscription, and scales to meet the needs of your application. The Standard plan is priced based on two factors: the provisioned throughput capacity that is allocated, and the amount of data that is stored in the instance.\n\nPricing is pro-rated hourly with a starting provisioned throughput capacity of 100 reads per second, 50 writes per second, and 5 global queries per second. This rate is equal to a starting cost of USD $0.105 per hour. You can toggle the provisioned throughput capacity up or down by using the user interface or API. Toggle in increments of 100 reads per second, 50 writes per second, and 5 global queries per second. Costs are calculated for the provisioned throughput capacity that is allocated and not on the metered volume of requests. The Standard plan includes 20 GB of data storage. If you store more than 20 GB, you're charged a defined cost per GB per hour.\n\nRefer to the IBM Cloud Pricing Calculator in the dashboard for pricing at different capacities and currencies, and the [pricing](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pricingpricing) information for examples to estimate costs.\n\n\n\n\n\n Dedicated Hardware plan","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_07578-47319-49349","score":24.2632984715,"text":"\n* Can I continue to use the Speech to Text Standard plan?\n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https:\/\/%7BDomainName%7D\/catalog\/speech-to-text). They will continue to have access to all of their settings and custom models after upgrading. And, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n* What pricing plan do I need to use the service's customization interface?\n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n* How do I upgrade from the Lite plan to the Plus plan?\n\nYou can upgrade from the Lite plan to the Plus plan, for example, to gain access to customization. To upgrade from the Lite plan to the Plus plan, use the Upgrade button in the resource catalog page for your service instance:\n\n\n\n* From the [resource list](https:\/\/cloud.ibm.com\/resources), click on your Speech to Text instance to go to the Speech to Text dashboard page.\n* From the Manage page, click Upgrade to move to the Plus plan.\n* Follow the steps on the Plan page to complete your upgrade.\n\n\n\n* What does \"pricing per minute\" mean?\n\nFor the Plus plan, pricing is based on the cumulative amount (number of minutes) of audio that you send to the service in any one month. The per-minute price of all audio that you recognize in a month is reduced once you reach the threshold of one million minutes of audio for that month. The price does not depend on how long the service takes to process the audio. (Per-minute pricing is different for the Standard plan.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-47304-49334","score":24.2632984715,"text":"\n* Can I continue to use the Speech to Text Standard plan?\n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https:\/\/%7BDomainName%7D\/catalog\/speech-to-text). They will continue to have access to all of their settings and custom models after upgrading. And, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n* What pricing plan do I need to use the service's customization interface?\n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n* How do I upgrade from the Lite plan to the Plus plan?\n\nYou can upgrade from the Lite plan to the Plus plan, for example, to gain access to customization. To upgrade from the Lite plan to the Plus plan, use the Upgrade button in the resource catalog page for your service instance:\n\n\n\n* From the [resource list](https:\/\/cloud.ibm.com\/resources), click on your Speech to Text instance to go to the Speech to Text dashboard page.\n* From the Manage page, click Upgrade to move to the Plus plan.\n* Follow the steps on the Plan page to complete your upgrade.\n\n\n\n* What does \"pricing per minute\" mean?\n\nFor the Plus plan, pricing is based on the cumulative amount (number of minutes) of audio that you send to the service in any one month. The per-minute price of all audio that you recognize in a month is reduced once you reach the threshold of one million minutes of audio for that month. The price does not depend on how long the service takes to process the audio. (Per-minute pricing is different for the Standard plan.)","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_13336-7-1965","score":23.5457085643,"text":"\nPricing FAQs \n\nIBM Cloud\n\nThe IBM Watson\u00ae Speech to Text service is available at three pricing plans: Lite, Plus, and Premium. The following FAQs provide an overview of the pricing plans. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/cloud.ibm.com\/catalog\/speech-to-text).\n\nThe Standard plan is no longer available for purchase by users. The Standard plan continues to be available to its existing users indefinitely. For more information, see [Can I continue to use the Speech to Text Standard plan?](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-faq-pricingfaq-pricing-standard) For new users, read about the new Plus and Premium plans below.\n\n\n\n What is the price for using the Speech to Text Lite plan? \n\nThe Lite plan lets you get started with 500 minutes per month of speech recognition at no cost. You can use any available model for speech recognition. The Lite plan does not provide access to customization. You must use a paid plan to use customization.\n\nThe Lite plan is intended for any user who wants to try out the service before committing to a purchase. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/cloud.ibm.com\/catalog\/speech-to-text). Services that are created with the Lite plan are deleted after 30 days of inactivity.\n\n\n\n\n\n What is the price for using the Speech to Text Plus plan? \n\nThe Plus plan provides access to all of the service's features:\n\n\n\n* Use of all available models (same as the Lite plan).\n* Unlimited creation and use of custom language and custom acoustic models at no extra charge.\n* A maximum of one hundred concurrent transcription requests from all interfaces, WebSocket and HTTP, combined.\n\n\n\nThe plan uses a simple tiered pricing model to give high-volume users further discounts as they use the service more heavily. Pricing is based on the aggregate number of minutes of audio that you recognize per month:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-faq-pricing"},{"document_id":"ibmcld_13336-3083-5168","score":23.1372162714,"text":"\nAnd, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n\n\n\n\n\n What pricing plan do I need to use the service's customization interface? \n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n\n\n\n\n\n How do I upgrade from the Lite plan to the Plus plan? \n\nYou can upgrade from the Lite plan to the Plus plan, for example, to gain access to customization. To upgrade from the Lite plan to the Plus plan, use the Upgrade button in the resource catalog page for your service instance:\n\n\n\n* From the [resource list](https:\/\/cloud.ibm.com\/resources), click on your Speech to Text instance to go to the Speech to Text dashboard page.\n* From the Manage page, click Upgrade to move to the Plus plan.\n* Follow the steps on the Plan page to complete your upgrade.\n\n\n\n\n\n\n\n What does \"pricing per minute\" mean? \n\nFor the Plus plan, pricing is based on the cumulative amount (number of minutes) of audio that you send to the service in any one month. The per-minute price of all audio that you recognize in a month is reduced once you reach the threshold of one million minutes of audio for that month. The price does not depend on how long the service takes to process the audio. (Per-minute pricing is different for the Standard plan.)\n\nFor information about pricing for the Plus and Standard plans, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/cloud.ibm.com\/catalog\/speech-to-text).\n\n\n\n\n\n Do you round up to the nearest minute for every call to the API? \n\nIBM does not round up the length of the audio for every API call that the service receives. Instead, IBM aggregates all usage for the month and rounds to the nearest minute at the end of the month. For example, if you send two audio files that are each 30 seconds long, IBM sums the duration of the total audio for that month to one minute.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-faq-pricing"},{"document_id":"ibmcld_07578-503127-505414","score":22.7395861966,"text":"\nSelect a Pricing plan.\n5. Configure your resource by providing a Service name for your instance, or use the preset name.\n6. Select a Resource group.\n7. Optional: Add Tags to help you to identify and organize the instance in your account. If your tags are billing related, consider writing tags as key: value pairs to help group-related tags, such as costctr: 124.\n8. Optional: Add Access management tags that helps you apply flexible access policies on specific resources.\n9. Accept the licensing agreements and terms by clicking the checkbox.\n10. Click Create. A new service instance is created and the App Configuration service console displayed.\n\n\n\n* What pricing plans are available with App Configuration?\n\nApp Configuration has three pricing plans:\n\n\n\nTable 1. Pricing plans\n\n Plan Inclusions Capabilities \n\n Lite This plan is a free evaluation plan that includes 10 active entity IDs and 5,000 API calls. <br>Lite plan services are deleted after 30 days of inactivity. Includes all App Configuration capabilities for evaluation only. Not to be used for production. \n Standard The monthly instance price includes 1000 active entity IDs and 100,000 API calls. This plan includes feature flags in addition to the property management capabilities. \n Enterprise The monthly instance price includes 10,000 active entity IDs and 1,000,000 API calls. This plan includes percentage rollout and targeting segments in addition to property management and feature flags that are found in the Standard plan. \n\n\n\n* What are the charges to use App Configuration?\n\nThe fundamental pricing metrics for App Configuration are Application Instance, Active Entity ID, and API Call.\n\nApplication Instance - An Application Instance is a uniquely named copy of App Configuration created by you but managed by IBM. Multiple instances of App Configuration within a single environment are all considered separate application instances, as are individual App Configuration instances in multiple environments (such as test, development, staging, or production).\n\nA single instance of App Configuration can serve multiple environments, and in fact the service is designed to do so.\n\nActive Entity ID - An active entity ID is a unique identifier for each entity that interacts with the App Configuration service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-503069-505356","score":22.7395861966,"text":"\nSelect a Pricing plan.\n5. Configure your resource by providing a Service name for your instance, or use the preset name.\n6. Select a Resource group.\n7. Optional: Add Tags to help you to identify and organize the instance in your account. If your tags are billing related, consider writing tags as key: value pairs to help group-related tags, such as costctr: 124.\n8. Optional: Add Access management tags that helps you apply flexible access policies on specific resources.\n9. Accept the licensing agreements and terms by clicking the checkbox.\n10. Click Create. A new service instance is created and the App Configuration service console displayed.\n\n\n\n* What pricing plans are available with App Configuration?\n\nApp Configuration has three pricing plans:\n\n\n\nTable 1. Pricing plans\n\n Plan Inclusions Capabilities \n\n Lite This plan is a free evaluation plan that includes 10 active entity IDs and 5,000 API calls. <br>Lite plan services are deleted after 30 days of inactivity. Includes all App Configuration capabilities for evaluation only. Not to be used for production. \n Standard The monthly instance price includes 1000 active entity IDs and 100,000 API calls. This plan includes feature flags in addition to the property management capabilities. \n Enterprise The monthly instance price includes 10,000 active entity IDs and 1,000,000 API calls. This plan includes percentage rollout and targeting segments in addition to property management and feature flags that are found in the Standard plan. \n\n\n\n* What are the charges to use App Configuration?\n\nThe fundamental pricing metrics for App Configuration are Application Instance, Active Entity ID, and API Call.\n\nApplication Instance - An Application Instance is a uniquely named copy of App Configuration created by you but managed by IBM. Multiple instances of App Configuration within a single environment are all considered separate application instances, as are individual App Configuration instances in multiple environments (such as test, development, staging, or production).\n\nA single instance of App Configuration can serve multiple environments, and in fact the service is designed to do so.\n\nActive Entity ID - An active entity ID is a unique identifier for each entity that interacts with the App Configuration service.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16242-7-2224","score":23.325015945,"text":"\nResponse modes \n\nIBM Cloud\n\nYou can choose a response mode for each action to set how it behaves. The modes are clarifying and confident.\n\nClarifying mode: Start here. In the clarifying mode, your assistant is eager to ask questions so you can ensure that your customer gets to the action they need. An assistant is more likely to ask questions to be sure an action matches what a customer is asking. A new or untested action gets the training that it needs.\n\nConfident mode: Take the next step. After you use analytics to improve your assistant, use the confident mode. Your assistant solves customer issues with authority and accuracy. An assistant is less likely to ask questions and is more likely to trigger actions that match. Use confident mode after you test and train actions.\n\nResponse modes are a beta feature that is available for evaluation and testing purposes on IBM Cloud only.\n\n\n\n Settings \n\nSettings for the two modes are in the global settings. For more information, see [Global settings for actions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-global-settings).\n\nYou can choose what mode to use when you create a new action. Clarifying mode is the default and is designed for use with new, untested actions that need training.\n\nThe settings are:\n\nClarify when one action matches: If an assistant prioritizes one action that it thinks matches the customer's request, it can clarify the match by asking the customer to confirm. This clarification helps you ensure that the action is the right one and allows the customer to give input before proceeding. For example, if the assistant thinks that a single action named Pay Bill is the right one, it can clarify the choice by asking the customer Did you mean: Pay Bill.\n\nClarify when more than one action matches: When your assistant finds that more than one action might fulfill a customer's request, it can automatically ask for clarification. Instead of guessing which action to use, your assistant shows a list of the possible actions to the customer and asks the customer to pick the right one.\n\nOffer support option when asking a clarifying question: The assistant can include a choice to connect to other support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-action-response-modes"},{"document_id":"ibmcld_16242-1610-3614","score":22.9149531569,"text":"\nFor example, if the assistant thinks that a single action named Pay Bill is the right one, it can clarify the choice by asking the customer Did you mean: Pay Bill.\n\nClarify when more than one action matches: When your assistant finds that more than one action might fulfill a customer's request, it can automatically ask for clarification. Instead of guessing which action to use, your assistant shows a list of the possible actions to the customer and asks the customer to pick the right one.\n\nOffer support option when asking a clarifying question: The assistant can include a choice to connect to other support. If the customer picks this choice, the assistant uses your Fallback action.\n\nStep validation attempts before offering support: If a customer provides invalid answers for a step in an action, the assistant can offer to connect to other support in the Fallback action. The step validation count measures how many invalid answers can occur before the assistant provides this choice.\n\nThis table shows the default settings for each mode.\n\n\n\nDefault settings\n\n Clarifying Confident \n\n Clarify when one action matches More often Sometimes \n Clarify when more than one action matches More often Sometimes \n Offer support option when asking a clarifying question More often Sometimes \n Step validation attempts before offering support 1 time 3 times \n\n\n\n\n\n\n\n Choosing a mode for individual actions \n\nWhen you edit an action, you can see the mode that it uses and change it if you need to.\n\n\n\n1. Click the Action response mode icon ![Action response mode icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/response-mode-icon.svg). The mode in use is checked.\n\nZoom\n\n![Action response mode](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/response-mode-modal.png)\n\nAction response mode\n2. Click the other mode if you want to change it, and then click Save response mode.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-action-response-modes"},{"document_id":"ibmcld_16359-6868-8948","score":21.7546377304,"text":"\nAs part of development that is in progress to help the assistant learn automatically from user choices, the actions that are included and their order in the list is randomized on purpose. Randomizing the order helps to prevent bias that can be introduced by a percentage of people who always pick the first option without carefully reviewing all of their choices beforehand.\n\n\n\n Customizing clarifying questions \n\nTo customize clarification, you can:\n\n\n\n* Change settings like the wording your assistant uses to introduce the clarification list or when no action matches.\n* Enable response modes to modify the assistant's behavior when it asks questions. For more information, see [Response modes](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-action-response-modes).\n\n\n\nTo change settings, complete the following steps:\n\n\n\n1. From the Actions page of the assistant, click Global settings![Gear icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/settings.svg).\n2. On the Clarifying questions tab, you can edit the Ask clarifying questions section:\n\n\n\nAsk clarifying question settings\n\n Field Default text Description \n\n Assistant says Did you mean: The text that is displayed before the list of clarification choices. You can change it to something else, such as What do you want to do? or Pick what to do next. \n No action matches None of the above The choice that customers can click when none of the other choices are right. If the customer picks this choice, the assistant uses your No action matches action. You can change it to something else, such as I need something else or These aren't what I want. Or, you can remove the text to omit offering this choice. \n\n\n\n3. If you enable response modes, you can modify this text:\n\n\n\nResponse modes settings\n\n Field Default text Description \n\n One action matches Something else If an assistant prioritizes one action that it thinks matches the customer need, it can clarify the match by asking the customer to confirm. This choice accompanies the single action in case the customer needs something else.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questions"},{"document_id":"ibmcld_16359-9997-12076","score":21.7028315852,"text":"\nSet the Enable disambiguation switch to Off.\n4. Click Save, and then click Close.\n5. Publish a new version of your assistant to the live environment to disable clarification. For more information, see [Publishing your content](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish).\n\n\n\n\n\n\n\n Excluding an action from clarifying questions \n\nYou can also prevent a single action from being used in a clarifying question. The effect of this choice depends on the confidence score for the action that you exclude.\n\nIf the action has the highest confidence score for a customer's question, no clarifying question is asked, and the action is triggered.\n\nIf the action doesn't have the highest confidence score, the action is excluded from the list of choices in the clarifying question.\n\nFor more information about confidence scores, see [Confidence scoring](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questionsunderstand-questions-confidence-scoring).\n\nTo exclude an action from clarification:\n\n\n\n1. From the action editor, click the Action settings icon ![Gear icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/settings.svg).\n2. In Action Settings, toggle the Ask clarifying question switch to Off.\n\n\n\n\n\n\n\n\n\n Coordinating how multiple actions start \n\nAs you work on your assistant, it's a good idea to coordinate customer phrase examples across multiple actions. It's important to distinguish how each action is triggered. When a user enters a question or request, the phrase is evaluated across all the Customer starts with examples in every action. If two actions have similar phrase examples, then the wrong action might get triggered by your user's question.\n\n\n\n Confidence scoring \n\nBehind the scenes, Watson Assistant determines a confidence score for each phrase. The score is absolute, meaning that a confidence score is assigned based on a predetermined scale, and not relative to other customer phrases. This approach adds flexibility in case multiple questions or requests are detected in a single user input.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questions"},{"document_id":"ibmcld_03313-1523-3328","score":21.457099461,"text":"\nContext variable A variable that you can use to collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on. A context variable is used by the dialog skill. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-contextdialog-runtime-context-variables). \n Dialog The component where you build the conversation that your assistant has with your customers. For each defined intent, you can author the response your assistant should return. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview). \n Digression A feature that gives the user the power to direct the conversation. It prevents customers from getting stuck in a dialog thread; they can switch topics whenever they choose. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-digressions). \n Disambiguation A feature that enables the assistant to ask customers to clarify their meaning when the assistant isn't sure what a user wants to do next. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-disambiguation). \n Entity Information in the user input that is related to the user's purpose. An intent represents the action a user wants to do. An entity represents the object of that action. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entities). \n Integrations Ways you can deploy your assistant to existing platforms or social media channels. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add). \n Intent The goal that is expressed in the user input, such as answering a question or processing a bill payment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-faqs"},{"document_id":"ibmcld_07578-1250-3085","score":21.2370777329,"text":"\nOr you can edit them to complement other intents that you create. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-catalog). \n Context variable A variable that you can use to collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on. A context variable is used by the dialog skill. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-contextdialog-runtime-context-variables). \n Dialog The component where you build the conversation that your assistant has with your customers. For each defined intent, you can author the response your assistant should return. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview). \n Digression A feature that gives the user the power to direct the conversation. It prevents customers from getting stuck in a dialog thread; they can switch topics whenever they choose. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-digressions). \n Disambiguation A feature that enables the assistant to ask customers to clarify their meaning when the assistant isn't sure what a user wants to do next. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-disambiguation). \n Entity Information in the user input that is related to the user's purpose. An intent represents the action a user wants to do. An entity represents the object of that action. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entities). \n Integrations Ways you can deploy your assistant to existing platforms or social media channels. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1250-3085","score":21.2370777329,"text":"\nOr you can edit them to complement other intents that you create. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-catalog). \n Context variable A variable that you can use to collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on. A context variable is used by the dialog skill. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-contextdialog-runtime-context-variables). \n Dialog The component where you build the conversation that your assistant has with your customers. For each defined intent, you can author the response your assistant should return. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview). \n Digression A feature that gives the user the power to direct the conversation. It prevents customers from getting stuck in a dialog thread; they can switch topics whenever they choose. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-digressions). \n Disambiguation A feature that enables the assistant to ask customers to clarify their meaning when the assistant isn't sure what a user wants to do next. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-disambiguation). \n Entity Information in the user input that is related to the user's purpose. An intent represents the action a user wants to do. An entity represents the object of that action. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entities). \n Integrations Ways you can deploy your assistant to existing platforms or social media channels. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add).","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-79680-81405","score":20.4440937877,"text":"\nFor example, you might want to ask for the customer's name and then address the person by name later on. A context variable is used by the dialog skill. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-variables). \n Dialog The component where you build the conversation that your assistant has with your customers. For each defined intent, you can author the response your assistant should return. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview). \n Digression A feature that gives the user the power to direct the conversation. It prevents customers from getting stuck in a dialog thread; they can switch topics whenever they choose. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtimedialog-runtime-digressions). \n Disambiguation A feature that enables the assistant to ask customers to clarify their meaning when the assistant isn't sure what a user wants to do next. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtimedialog-runtime-disambiguation). \n Entity Information in the user input that is related to the user's purpose. An intent represents the action a user wants to do. An entity represents the object of that action. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-entities). \n Integrations Ways you can deploy your assistant to existing platforms or social media channels. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-integration-add). \n Intent The goal that is expressed in the user input, such as answering a question or processing a bill payment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-79655-81380","score":20.4440937877,"text":"\nFor example, you might want to ask for the customer's name and then address the person by name later on. A context variable is used by the dialog skill. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-variables). \n Dialog The component where you build the conversation that your assistant has with your customers. For each defined intent, you can author the response your assistant should return. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview). \n Digression A feature that gives the user the power to direct the conversation. It prevents customers from getting stuck in a dialog thread; they can switch topics whenever they choose. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtimedialog-runtime-digressions). \n Disambiguation A feature that enables the assistant to ask customers to clarify their meaning when the assistant isn't sure what a user wants to do next. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtimedialog-runtime-disambiguation). \n Entity Information in the user input that is related to the user's purpose. An intent represents the action a user wants to do. An entity represents the object of that action. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-entities). \n Integrations Ways you can deploy your assistant to existing platforms or social media channels. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-integration-add). \n Intent The goal that is expressed in the user input, such as answering a question or processing a bill payment.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16312-7-1935","score":19.6912311232,"text":"\nGlossary \n\n\n\nGlossary\n\n Term Definition \n\n Action Actions represent the tasks or questions that your assistant can help customers with. Each action has a beginning and an end, making up a conversation between the assistant and a customer. [Learn more](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-build-actions-overview). \n Ask clarifying question A feature that enables the assistant to ask customers to clarify (disambiguate) their meaning when the assistant isn't sure what a user wants to do next. [Learn more](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questionsunderstand-questions-ask-clarifying-question). \n Assistant Container for your actions, channels, and integrations. You add actions and at least one channel to an assistant, and then deploy the assistant when you are ready to start helping your customers. [Learn more](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overview). \n Change conversation topic A feature that gives the user the power to direct the conversation. It allows digressions and prevents customers from getting stuck in a dialog thread; they can switch topics whenever they choose. [Learn more](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-change-topic). \n Channel The location where your assistant interacts with your users, for example, over the phone, on a website, or in Slack. At least one channel is required for every assistant. [Learn more](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-assistant). \n Completion Measures how often within a given time period users reach the end step of an action. [Learn more](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-action-completioncomplete-reasons). \n Content The conversation logic and words that are used to respond to your customer. Content is required for every assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-glossary"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02143-0-1216","score":22.6620973654,"text":"\n\n\n\n\n\n\n  Why can't I create a new Lite plan instance? \n\nYou try to create more than one instance in your Lite account.\n\n  What\u2019s happening \n\nYou receive the following error message when you try to create a new Lite plan instance:\n\n> Unable to provision new Lite instance\n>\n> The account already has an instance created with the Lite plan\n\n  Why it\u2019s happening \n\nThere's a limit of one instance per Lite plan to ensure that these plans stay free. For more information about Lite account features, see [Lite account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n  How to fix it \n\nYou can create more instances of the service by selecting one of the billable service plans, which are available in the billable accounts. To upgrade to a billable account from the console, go to Manage > Account in the IBM Cloud console, and select Account settings.\n\nIf you don't want to upgrade from a Lite account and are no longer using your existing Lite service instance, you can delete the existing Lite plan instance from the dashboard and then create a new instance. When you delete the Lite plan instance, all of the data that is associated with that instance is deleted and isn't recoverable.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-nosecondlite"},{"document_id":"ibmcld_05013-2864-3381","score":22.1446032255,"text":"\nCan I create more than one Object Storage service with a Lite account? \n\nIf you already have a Lite plan instance created, you may create other Standard plan instances, but only one Lite plan instance is allowed.\n\n\n\n\n\n What happens if I exceed the maximum usage allowed for a Lite plan? \n\nOnce you exceed the allowed usage, the service instance associated with the Lite plan becomes inaccessible. You will receive a warning notification email with corrective steps. If you do not take action, the instance is removed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-faq-provision"},{"document_id":"ibmcld_01025-7-2061","score":21.6689959323,"text":"\nFAQs - Lite plan \n\nThis is a collection of frequently asked questions (FAQ) about the IBM\u00ae Db2\u00ae on Cloud Lite plan.\n\n\n\n Will my free plan expire? \n\nYou can continue using the free plan for as long as you need. However, you must reactivate the free plan every 45 days. This reactivation process keeps resources available for other users by turning off inactive usage.\n\nWhen your plan nears its reactivation date, you will receive a reactivation request at the email address that you provided when creating the instance. Alternatively, you can reactivate in your Db2 on Cloud console.\n\n\n\n\n\n Will my data be deleted? \n\nAfter you create a Lite instance, you have 45 days before the next reactivation.\n\n\n\n* If you do not reactivate, your Lite plan will be disabled, but IBM Cloud still has your data. You will then have 60 days to reactivate your account.\n* If you don't reactivate within 60 days, your account and data will be deleted. We will send you multiple emails reminding you to reactivate.\n\n\n\nEach time you reactivate, the day counter resets, and you'll have another 45 days before being disabled (and 60 days before deletion).\n\n\n\n\n\n How can I download a backup of my data on the Lite plan? \n\nHere are two simple options for backing up Lite plan data:\n\n\n\n* Use Db2 tools like the command line tool (clp) or IBM Data Studio to do an export. You can then import at another time.\n* To quickly make a backup, use the Web console, run a query, then download the results to a CSV file.\n\n\n\n\n\n\n\n Can I change the email I use for reactivation? \n\nCreate a new Lite instance with the email you want to use going forward. If needed, first back up your data, delete your current Lite plan instance to create a new one, then load your data. You cannot change the email address associated with an existing Db2 Lite instance if you have only a Lite account with community support.\n\n\n\n\n\n I am having trouble with reactivation. What should I do? \n\nIf you have trouble with reactivation of a Lite plan instance, you can delete that faulty instance and create a new one.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-faq_db2oc_lite"},{"document_id":"ibmcld_07578-1076793-1078629","score":21.5902440973,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1079289-1081125","score":21.5902440973,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00558-1499-3456","score":21.479173223,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_07103-31052-33321","score":21.3529128781,"text":"\nYou cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, and Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 24 September 2021 \n\nNew scoring for NLU enrichments\n: Relevance and confidence scores are displayed for NLU enrichments that are returned by search. For example, when you open the JSON view of the document preview from a query result, you can see confidence scores for Entities mentions and relevance scores for Keyword mentions.\n\n\n\n\n\n 9 September 2021 \n\nNew location for Plus plan\n: The Plus plan is now available from the Sydney location. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product. For more information, see [Getting the most from Discovery](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-version-choose).\n\nChange to Lite and Advanced plans in most locations\n: Lite and Advanced plans are discontinued. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\n\n\n\n\n 26 August 2021 \n\nNew locations for the Plus plan\n: The Plus plan is now available from the London and Washington DC locations, in addition to Dallas, Frankfurt, and Tokyo.\n\nChange to Lite and Advanced plans in some locations\n: You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\nNew answer finding feature\n: Answer finding is now generally available for managed deployments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_01025-1621-3657","score":21.3249836027,"text":"\nIf needed, first back up your data, delete your current Lite plan instance to create a new one, then load your data. You cannot change the email address associated with an existing Db2 Lite instance if you have only a Lite account with community support.\n\n\n\n\n\n I am having trouble with reactivation. What should I do? \n\nIf you have trouble with reactivation of a Lite plan instance, you can delete that faulty instance and create a new one. If needed, first back up your data so you can load it to this new instance.\n\n\n\n\n\n I'm getting an error when creating a new instance. What's the problem? \n\nThere's a limit of one instance per Lite plan. You may see an error 500 message if you try to create a second Lite instance. To create a new Lite plan instance, you must first delete your existing one.\n\n\n\n\n\n I'm getting an error when creating a new schema or database. What's the problem? \n\nThe free Lite plan does not allow you to create new schemas or databases. There is an existing schema created for you to use. Use that schema.\n\n\n\n\n\n Why can\u2019t I open the web console? \n\nIf the Db2 web console does not load or returns an error message, try the following steps:\n\n\n\n* Go to the service page to check whether your Lite instance has expired. The Open Console button no longer appears for expired instances. Delete the expired instance and create a new one.\n* Try using the direct URL to open the console to check for errors. Select the Service credentials tab from your service page and expand the credentials that you want to view. If there are no existing credentials, click New credential. Use the values in the https_url, username, and password to open the web console.\n* To reset the password, select the Service credentials tab from your service page and then delete the existing service lite-tier service credential. Then click New credential to generate a new password for the existing username.\n* When you create a Lite instance, be sure to provide an email address so you receive reactivation notices and password reset notices.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-faq_db2oc_lite"},{"document_id":"ibmcld_07578-496072-498088","score":21.3249836027,"text":"\nIf needed, first back up your data, delete your current Lite plan instance to create a new one, then load your data. You cannot change the email address associated with an existing Db2 Lite instance if you have only a Lite account with community support.\n* I am having trouble with reactivation. What should I do?\n\nIf you have trouble with reactivation of a Lite plan instance, you can delete that faulty instance and create a new one. If needed, first back up your data so you can load it to this new instance.\n* I'm getting an error when creating a new instance. What's the problem?\n\nThere's a limit of one instance per Lite plan. You may see an error 500 message if you try to create a second Lite instance. To create a new Lite plan instance, you must first delete your existing one.\n* I'm getting an error when creating a new schema or database. What's the problem?\n\nThe free Lite plan does not allow you to create new schemas or databases. There is an existing schema created for you to use. Use that schema.\n* Why can\u2019t I open the web console?\n\nIf the Db2 web console does not load or returns an error message, try the following steps:\n\n\n\n* Go to the service page to check whether your Lite instance has expired. The Open Console button no longer appears for expired instances. Delete the expired instance and create a new one.\n* Try using the direct URL to open the console to check for errors. Select the Service credentials tab from your service page and expand the credentials that you want to view. If there are no existing credentials, click New credential. Use the values in the https_url, username, and password to open the web console.\n* To reset the password, select the Service credentials tab from your service page and then delete the existing service lite-tier service credential. Then click New credential to generate a new password for the existing username.\n* When you create a Lite instance, be sure to provide an email address so you receive reactivation notices and password reset notices.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-496054-498070","score":21.3249836027,"text":"\nIf needed, first back up your data, delete your current Lite plan instance to create a new one, then load your data. You cannot change the email address associated with an existing Db2 Lite instance if you have only a Lite account with community support.\n* I am having trouble with reactivation. What should I do?\n\nIf you have trouble with reactivation of a Lite plan instance, you can delete that faulty instance and create a new one. If needed, first back up your data so you can load it to this new instance.\n* I'm getting an error when creating a new instance. What's the problem?\n\nThere's a limit of one instance per Lite plan. You may see an error 500 message if you try to create a second Lite instance. To create a new Lite plan instance, you must first delete your existing one.\n* I'm getting an error when creating a new schema or database. What's the problem?\n\nThe free Lite plan does not allow you to create new schemas or databases. There is an existing schema created for you to use. Use that schema.\n* Why can\u2019t I open the web console?\n\nIf the Db2 web console does not load or returns an error message, try the following steps:\n\n\n\n* Go to the service page to check whether your Lite instance has expired. The Open Console button no longer appears for expired instances. Delete the expired instance and create a new one.\n* Try using the direct URL to open the console to check for errors. Select the Service credentials tab from your service page and expand the credentials that you want to view. If there are no existing credentials, click New credential. Use the values in the https_url, username, and password to open the web console.\n* To reset the password, select the Service credentials tab from your service page and then delete the existing service lite-tier service credential. Then click New credential to generate a new password for the existing username.\n* When you create a Lite instance, be sure to provide an email address so you receive reactivation notices and password reset notices.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-1076793-1078629","score":43.068500458,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1079289-1081125","score":43.068500458,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01660-8584-10307","score":39.4535798515,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_00558-1499-3456","score":36.3850197774,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-1535-3460","score":36.2916661995,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_01660-7085-8964","score":35.4848613911,"text":"\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_03729-1672-3956","score":35.1515532029,"text":"\nServices For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged. \n Tiered In this pricing model, you get a volumed-based discount according to your actual usage. Tiered pricing is typically used for charge metrics that are expected to have high quantities per month, such as API calls. Services might offer simple, graduated, or block tier pricing plans. Services For API Connect, one of the tiered plans charges $10,000 for the first 25 million monthly API calls and $40.00 USD per 100,000 API calls per month thereafter. \n Reserved Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment. Services Db2 on Cloud has reserved plans. \n\n\n\n\n\n Understanding monthly and hourly tags \n\nOn the usage dashboard, your products and resources can be labeled with Monthly, Hourly, or a combination of both tags to signify how often charges are updated.\n\nThe Monthly tag signifies that resources within your account have a fixed cost. These charge show up immediately after purchase and are prorated in proportion to how many days are left in the month. Any recurring monthly fixed costs are then shown at the first of every month.\n\nThe Hourly tag signifies that resources within your account have variable costs. These resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_07578-1320438-1322384","score":33.9803578419,"text":"\nNo, Lite Plan instances can only be upgraded to the Cloud Object Storage Standard plan.\n* Are there any minimum object size or minimum duration requirements for objects stored with the One-Rate plan?\n\nThere are no minimum object size or minimum duration requirements for the One-Rate plan.\n* What is the cost of data retrieval from One Rate Active buckets?\n\nThere is no data retrieval charge for the One Rate Active buckets.\n* What happens if I exceed my monthly allowance for Outbound bandwidth and Operational requests?\n\nFor any usage (Outbound bandwidth or Operational requests) that exceeds the allowance determined by aggregated monthly capacity, a small overage fee applies based on the One Rate pricing regions. See [One Rate pricing plan details](https:\/\/cloud.ibm.com\/objectstorage\/createpricing).\n* Is the overage pricing tiered for Outbound bandwidth and Operational requests?\n\nNo, the overage pricing for the One Rate plan has flat rates regardless of excess usage. See [One Rate pricing plan details](https:\/\/cloud.ibm.com\/objectstorage\/createpricing).\n* I already have a Cloud Object Storage Standard plan in my IBM Cloud account. Can I add a One Rate plan for my new workloads?\n\nYes, you can add a One Rate plan to your existing account in addition to the Standard plan. If you are a new to Cloud Object Storage, you can add either Standard or One Rate plan (or both) based on your workload requirements.\n* Why can I not create or delete a service instance?\n\nA user is required to have have at a minimum the platform role of editor for all IAM enabled services, or at least for Cloud Object Service. For more information, see the [IAM documentation on roles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iam-service-roles-actions).\n* Which one of my instances uses a Lite plan?\n\nAn account is limited to a single instance of IBM Cloud Object Storage that uses a Lite plan. You can find this instance three different ways:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1323103-1325049","score":33.9803578419,"text":"\nNo, Lite Plan instances can only be upgraded to the Cloud Object Storage Standard plan.\n* Are there any minimum object size or minimum duration requirements for objects stored with the One-Rate plan?\n\nThere are no minimum object size or minimum duration requirements for the One-Rate plan.\n* What is the cost of data retrieval from One Rate Active buckets?\n\nThere is no data retrieval charge for the One Rate Active buckets.\n* What happens if I exceed my monthly allowance for Outbound bandwidth and Operational requests?\n\nFor any usage (Outbound bandwidth or Operational requests) that exceeds the allowance determined by aggregated monthly capacity, a small overage fee applies based on the One Rate pricing regions. See [One Rate pricing plan details](https:\/\/cloud.ibm.com\/objectstorage\/createpricing).\n* Is the overage pricing tiered for Outbound bandwidth and Operational requests?\n\nNo, the overage pricing for the One Rate plan has flat rates regardless of excess usage. See [One Rate pricing plan details](https:\/\/cloud.ibm.com\/objectstorage\/createpricing).\n* I already have a Cloud Object Storage Standard plan in my IBM Cloud account. Can I add a One Rate plan for my new workloads?\n\nYes, you can add a One Rate plan to your existing account in addition to the Standard plan. If you are a new to Cloud Object Storage, you can add either Standard or One Rate plan (or both) based on your workload requirements.\n* Why can I not create or delete a service instance?\n\nA user is required to have have at a minimum the platform role of editor for all IAM enabled services, or at least for Cloud Object Service. For more information, see the [IAM documentation on roles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iam-service-roles-actions).\n* Which one of my instances uses a Lite plan?\n\nAn account is limited to a single instance of IBM Cloud Object Storage that uses a Lite plan. You can find this instance three different ways:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03729-3519-5413","score":33.4884838541,"text":"\nThese resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings\n* Encrypted data storage limit, for example 1 GB\n* Provisioned throughput capacity\n\n\n\nYou can easily find services for Lite plans in the catalog. By default, all services with a Lite plan are displayed with a Lite tag ![Lite tag](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/Lite.svg). Select a service to view the quota details for the associated Lite plan.\n\n\n\n\n\n Charges for compute resources \n\nYou're charged for the time that your apps run and the memory that's used in GB-hours. GB-hours is the calculation of the number of application instances that are multiplied by the memory per instance and by the hours that the instances run. You can customize the number of instances and the amount of memory per instance based on your needs. You can also add memory or instances to scale for more users. To get the amount charged, take your application instances that are multiplied by memory per instance and by hours running.\n\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01315-1363-3440","score":32.9619357895,"text":"\n[External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/www.ibm.com\/support\/knowledgecenter\/SSQP8H\/iot\/overview\/overview.html).\n\nNote: This document is intended only for users who have a Lite instance. If you previously created instances of the IoT Platform with either the Standard or Advanced Security plans, IBM\u00ae will work with you to migrate your existing Watson IoT Platform instance to the new non-production or production plans.\n\n\n\n Migration process overview \n\nBy migrating to Watson IoT Platform you remove the Lite plan limits of 500 devices and monthly data consumption.\n\nThe Watson IoT Platform plans include the following additional components to support end-to-end IoT application architecture:\n\n\n\n* Event Streams - an IBM hosted version of the Kafka streaming platform that your applications can use to receive IoT data.\n* Db2\u00ae Warehouse on Cloud for analytical data storage.\n* IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae DB for time series data.\n* IBM Cloud\u00ae Object Storage for long term data retention.\n\n\n\nThis document describes the types of data you might want to migrate from an existing Lite instance to a full version.\n\nNote: Generally it is easiest to set up your Watson IoT Platform non-production or production environment from scratch, as it includes components and features beyond the Watson IoT Platform Lite service. Also the devices and users created for testing in the Lite version will likely not be the same ones you'll use for production.\n\nIf, however, you want to transfer some of your existing Lite settings, the following sections take you through the process.\n\nDocumentation on the [Watson IoT Platform APIs](https:\/\/cloud.ibm.com\/docs\/services\/IoT?topic=IoT-api_overviewapi_overview) provides instructions on how to invoke the APIs and their full set of parameters.\n\n\n\n\n\n Before you begin \n\nBefore you can start the migration process you must purchase Watson IoT Platform (either production or non-production). Upon purchase, the IBM operations team will provision a new Watson IoT Platform instance for you.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/IoT?topic=IoT-org_migration"},{"document_id":"ibmcld_01316-2609-4002","score":30.3703398023,"text":"\nWatson IoT Platform Standard The Standard service plan includes the free data-transfer limit that is offered in the Lite plan and then usage-based billing beyond the free quote for data exchanged, data analyzed, and edge data analyzed. \n Watson IoT Platform Advanced Security The Advanced Security service plan includes the free data-transfer limit that is offered in the Lite plan and then usage-based billing beyond the free quote for data exchanged, data analyzed, and edge data analyzed. This plan also provides advanced Risk and Security Management features. \n\n\n\n\n\n\n\n\n\n Upgrading service plans \n\nIf you are an existing customer and want to take advantage of the full [Watson IoT Platform feature set ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/www.ibm.com\/support\/knowledgecenter\/SSQP8H\/iot\/overview\/overview.html), you can purchase one of the Connection and Analytics Service plans and then migrate your existing environment.\n\nTo migrate plans, contact your IBM\u00ae representative or raise a support ticket.\n\nTo migrate from Watson IoT Platform Lite plan, or to migrate to other plans with only the essential configuration settings included, see the instructions in [Migrating Watson IoT Platform Lite to Watson IoT Platform Non-production or Production](https:\/\/cloud.ibm.com\/docs\/services\/IoT?topic=IoT-org_migrationorg_migration).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/IoT?topic=IoT-plans_overview"},{"document_id":"ibmcld_13336-7-1965","score":28.2508636592,"text":"\nPricing FAQs \n\nIBM Cloud\n\nThe IBM Watson\u00ae Speech to Text service is available at three pricing plans: Lite, Plus, and Premium. The following FAQs provide an overview of the pricing plans. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/cloud.ibm.com\/catalog\/speech-to-text).\n\nThe Standard plan is no longer available for purchase by users. The Standard plan continues to be available to its existing users indefinitely. For more information, see [Can I continue to use the Speech to Text Standard plan?](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-faq-pricingfaq-pricing-standard) For new users, read about the new Plus and Premium plans below.\n\n\n\n What is the price for using the Speech to Text Lite plan? \n\nThe Lite plan lets you get started with 500 minutes per month of speech recognition at no cost. You can use any available model for speech recognition. The Lite plan does not provide access to customization. You must use a paid plan to use customization.\n\nThe Lite plan is intended for any user who wants to try out the service before committing to a purchase. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/cloud.ibm.com\/catalog\/speech-to-text). Services that are created with the Lite plan are deleted after 30 days of inactivity.\n\n\n\n\n\n What is the price for using the Speech to Text Plus plan? \n\nThe Plus plan provides access to all of the service's features:\n\n\n\n* Use of all available models (same as the Lite plan).\n* Unlimited creation and use of custom language and custom acoustic models at no extra charge.\n* A maximum of one hundred concurrent transcription requests from all interfaces, WebSocket and HTTP, combined.\n\n\n\nThe plan uses a simple tiered pricing model to give high-volume users further discounts as they use the service more heavily. Pricing is based on the aggregate number of minutes of audio that you recognize per month:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-faq-pricing"},{"document_id":"ibmcld_07578-47319-49349","score":27.8388156591,"text":"\n* Can I continue to use the Speech to Text Standard plan?\n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https:\/\/%7BDomainName%7D\/catalog\/speech-to-text). They will continue to have access to all of their settings and custom models after upgrading. And, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n* What pricing plan do I need to use the service's customization interface?\n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n* How do I upgrade from the Lite plan to the Plus plan?\n\nYou can upgrade from the Lite plan to the Plus plan, for example, to gain access to customization. To upgrade from the Lite plan to the Plus plan, use the Upgrade button in the resource catalog page for your service instance:\n\n\n\n* From the [resource list](https:\/\/cloud.ibm.com\/resources), click on your Speech to Text instance to go to the Speech to Text dashboard page.\n* From the Manage page, click Upgrade to move to the Plus plan.\n* Follow the steps on the Plan page to complete your upgrade.\n\n\n\n* What does \"pricing per minute\" mean?\n\nFor the Plus plan, pricing is based on the cumulative amount (number of minutes) of audio that you send to the service in any one month. The per-minute price of all audio that you recognize in a month is reduced once you reach the threshold of one million minutes of audio for that month. The price does not depend on how long the service takes to process the audio. (Per-minute pricing is different for the Standard plan.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-47304-49334","score":27.8388156591,"text":"\n* Can I continue to use the Speech to Text Standard plan?\n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https:\/\/%7BDomainName%7D\/catalog\/speech-to-text). They will continue to have access to all of their settings and custom models after upgrading. And, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n* What pricing plan do I need to use the service's customization interface?\n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n* How do I upgrade from the Lite plan to the Plus plan?\n\nYou can upgrade from the Lite plan to the Plus plan, for example, to gain access to customization. To upgrade from the Lite plan to the Plus plan, use the Upgrade button in the resource catalog page for your service instance:\n\n\n\n* From the [resource list](https:\/\/cloud.ibm.com\/resources), click on your Speech to Text instance to go to the Speech to Text dashboard page.\n* From the Manage page, click Upgrade to move to the Plus plan.\n* Follow the steps on the Plan page to complete your upgrade.\n\n\n\n* What does \"pricing per minute\" mean?\n\nFor the Plus plan, pricing is based on the cumulative amount (number of minutes) of audio that you send to the service in any one month. The per-minute price of all audio that you recognize in a month is reduced once you reach the threshold of one million minutes of audio for that month. The price does not depend on how long the service takes to process the audio. (Per-minute pricing is different for the Standard plan.)","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-44227-46133","score":27.8309929827,"text":"\nYou can backup and restore a workspace by following the steps in [Backing up and restoring data](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-backup-restore). These backup and restore tasks allow you to perform a manual data migration from one Knowledge Studio instance to another, backing up your data from one instance and restoring it on another instance.\n* Experimental services and features: What does experimental mean?\n\nIBM releases experimental services and features for you to try out. These services might be unstable, change frequently in ways that are not compatible with earlier versions, and might be discontinued with short notice. These services and features are not recommended for use in production environments.\n\nFor more information about experimental services, see the [IBM Cloud documentation ![External link icon](https:\/\/cloud.ibm.com\/icons\/launch-glyph.svg)](https:\/\/%7BDomainName%7D\/docs\/get-support\/servicessupport.htmls-services-exporcont). For the full details of experimental services, see the latest version of the [IBM Cloud Service Description ![External link icon](https:\/\/cloud.ibm.com\/icons\/launch-glyph.svg)](https:\/\/www.ibm.com\/software\/sla\/sladb.nsf\/sla\/bm?OpenDocument).\n\n\n\nSpeech to Text\n\n\n\n* What is the price for using the Speech to Text Lite plan?\n\nThe Lite plan lets you get started with 500 minutes per month of speech recognition at no cost. You can use any available model for speech recognition. The Lite plan does not provide access to customization. You must use a paid plan to use customization.\n\nThe Lite plan is intended for any user who wants to try out the service before committing to a purchase. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/%7BDomainName%7D\/catalog\/speech-to-text). Services that are created with the Lite plan are deleted after 30 days of inactivity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-44212-46118","score":27.8309929827,"text":"\nYou can backup and restore a workspace by following the steps in [Backing up and restoring data](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-backup-restore). These backup and restore tasks allow you to perform a manual data migration from one Knowledge Studio instance to another, backing up your data from one instance and restoring it on another instance.\n* Experimental services and features: What does experimental mean?\n\nIBM releases experimental services and features for you to try out. These services might be unstable, change frequently in ways that are not compatible with earlier versions, and might be discontinued with short notice. These services and features are not recommended for use in production environments.\n\nFor more information about experimental services, see the [IBM Cloud documentation ![External link icon](https:\/\/cloud.ibm.com\/icons\/launch-glyph.svg)](https:\/\/%7BDomainName%7D\/docs\/get-support\/servicessupport.htmls-services-exporcont). For the full details of experimental services, see the latest version of the [IBM Cloud Service Description ![External link icon](https:\/\/cloud.ibm.com\/icons\/launch-glyph.svg)](https:\/\/www.ibm.com\/software\/sla\/sladb.nsf\/sla\/bm?OpenDocument).\n\n\n\nSpeech to Text\n\n\n\n* What is the price for using the Speech to Text Lite plan?\n\nThe Lite plan lets you get started with 500 minutes per month of speech recognition at no cost. You can use any available model for speech recognition. The Lite plan does not provide access to customization. You must use a paid plan to use customization.\n\nThe Lite plan is intended for any user who wants to try out the service before committing to a purchase. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/%7BDomainName%7D\/catalog\/speech-to-text). Services that are created with the Lite plan are deleted after 30 days of inactivity.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_12865-4-1690","score":27.0554427955,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Defining your pricing model for software \n\nWhen onboarding your product, you need to define the pricing model for your software. Currently, the IBM Cloud\u00ae catalog supports free plans and bring your own license (BYOL).\n\n\n\n Adding a free plan by using the console \n\nBy adding a free plan, you are indicating that your product does not require any payment or license to use.\n\n\n\n1. In the IBM Cloud console, click the Navigation Menu icon ![Navigation Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ff5860bfede49db3197c4bbba7f7123769bdc068\/icons\/icon_hamburger.svg) > Partner Center > Sell > My products.\n2. Select the product that you're onboarding, and click Pricing.\n3. Select Free.\n\n\n\n\n\n\n\n Adding a BYOL plan by using the console \n\nBy adding a bring your own license plan, you are indicating that customers need to purchase a license to use your product. You are required to provide the name of the license and a URL where customers can purchase the license.\n\nIf you have not imported a version of your software, you can still create a BYOL plan. However, you need to import a version before your product is published. For more information, see [Onboarding your software](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-sw-validate).\n\n\n\n1. In the IBM Cloud console, click the Navigation Menu icon ![Navigation Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ff5860bfede49db3197c4bbba7f7123769bdc068\/icons\/icon_hamburger.svg) > Partner Center > Sell > My products.\n2. Select the product that you're onboarding, and click Pricing.\n3. Select Pricing plans.\n4. Click Add plan.\n5. Select BYOL.\n6. In the Add pricing plan panel, enter the Name of the license.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-sw-pricing"},{"document_id":"ibmcld_12865-1326-2924","score":27.0346724526,"text":"\n[Navigation Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ff5860bfede49db3197c4bbba7f7123769bdc068\/icons\/icon_hamburger.svg) > Partner Center > Sell > My products.\n2. Select the product that you're onboarding, and click Pricing.\n3. Select Pricing plans.\n4. Click Add plan.\n5. Select BYOL.\n6. In the Add pricing plan panel, enter the Name of the license. Customers use the license name to find and purchase the license.\n7. Enter the URL that customers can use to learn about and purchase the license.\n8. Enter the Description of your license. Explain why customers need to purchase the license and what access they will receive.\n9. Click Add.\n\n\n\nAll information that is entered in the Add pricing plan panel is displayed to customers in the IBM Cloud catalog to help them purchase the required license.\n\n\n\n\n\n Creating a free plan by using the API \n\nYou can programmatically create a free plan by calling the [Partner Center Sell API](https:\/\/cloud.ibm.com\/apidocs\/partner-center-sellupdate-catalog) as shown in the following sample request.\n\ncurl --request PATCH --url https:\/\/product-\nlifecycle.api.cloud.ibm.com\/openapi\/v1\/products\/9fab83da-98cb-4f18-\na7ba-b6f0435c9673\/catalog --header 'Authorization: Bearer TOKEN' --header 'Content-Type: application\/json' --data '{\n\"pricingModel\": \"free\",\n}'\n\n\n\n\n\n Creating a BYOL plan by using the API \n\nYou can programmatically create a BYOL plan by calling the [Partner Center Sell API](https:\/\/cloud.ibm.com\/apidocs\/partner-center-sellcreate-plan) as shown in the following sample request. The example creates a BYOL plan that is named Standard:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-sw-pricing"},{"document_id":"ibmcld_12824-7-1978","score":26.6606415401,"text":"\nFAQs for migrated products \n\nFAQs about products that are migrated from the Resource Management Console might include questions about Lite plans, changing pricing plans, and brokers connected to approved pricing plans.\n\nTo find all FAQs for IBM Cloud, see our [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n Why can't I add new block tier usage-based plans? \n\nBlock tier pricing plans are not currently supported in Partner Center. If you set up a block tier pricing plan in the Resource Management Console and the plan was approved and published, no changes have been made and it was migrated as-is with your product. However, you can't edit the plan or set up a new block tier pricing plan. If you have any questions, open a support case. For information about opening a support case, see [Creating a Partner Center support case](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-get-pc-supportpc-support-case).\n\n\n\n\n\n What changed with Lite plan support? \n\nLite plans are not supported in Partner Center. You can create a new free plan, and all users with Pay-As-You-Go and Subscription accounts can try out your product for free.\n\nIf you set up a Lite plan in the resource management console, and it was approved and published, no changes have been made and it was migrated as-is with your product. If you need to change a published pricing plan, open a support case. For information about opening a support case, see [Creating a Partner Center support case](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-get-pc-supportpc-support-case).\n\n\n\n\n\n Can I add a broker per location? \n\nNo. Brokers are added per pricing plan, not per location. And, brokers can't be disconnected from already approved plans.\n\n\n\n\n\n Can I set different locations per plan for a single product? \n\nYes. But, all plans for a single product must be set as either global or per location. Therefore, you can't have a plan that is set to global and then another plan set to be available for specific regions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-migrated-products"}],"retriever_scores":{}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-1076793-1078629","score":25.5800022966,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1079289-1081125","score":25.5800022966,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01660-7085-8964","score":25.0915895644,"text":"\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_07103-32746-34817","score":24.6854921622,"text":"\n: The Plus plan is now available from the London and Washington DC locations, in addition to Dallas, Frankfurt, and Tokyo.\n\nChange to Lite and Advanced plans in some locations\n: You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\nNew answer finding feature\n: Answer finding is now generally available for managed deployments. Use answer finding when you want to return a concise answer to a question. For more information, see [Answer finding](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parametersanswer-finding).\n\n\n\n\n\n 16 August 2021 \n\nNew locations for the Plus plan\n: The Plus plan is now available from the Frankfurt and Tokyo locations, in addition to Dallas.\n\nChange to Lite and Advanced plans in some locations\n: Lite and Advanced plans are no longer offered. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, or Tokyo locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\n\n\n\n\n 27 July 2021 \n\nImproved document size limit\n: Document size limit is increased. For Premium plan collections, you can now upload files that are up to 50 MB in size instead of 32 MB. For more information, see [Document limits](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collectionscollections-doc-limits).\n\n\n\n\n\n 23 July 2021 \n\nImproved SharePoint Online connector\n: The Microsoft SharePoint Online data source connector now accepts any valid Azure Active Directory user ID syntax; the format of the user ID doesn't need to match the <admin_user>@.onmicrosoft.com syntax. For more information, see [Microsoft SharePoint Online](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-connector-sharepoint-online-cloud).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_07578-1075256-1077185","score":24.0428932954,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1077752-1079681","score":24.0428932954,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01316-2609-4002","score":23.5687160014,"text":"\nWatson IoT Platform Standard The Standard service plan includes the free data-transfer limit that is offered in the Lite plan and then usage-based billing beyond the free quote for data exchanged, data analyzed, and edge data analyzed. \n Watson IoT Platform Advanced Security The Advanced Security service plan includes the free data-transfer limit that is offered in the Lite plan and then usage-based billing beyond the free quote for data exchanged, data analyzed, and edge data analyzed. This plan also provides advanced Risk and Security Management features. \n\n\n\n\n\n\n\n\n\n Upgrading service plans \n\nIf you are an existing customer and want to take advantage of the full [Watson IoT Platform feature set ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/www.ibm.com\/support\/knowledgecenter\/SSQP8H\/iot\/overview\/overview.html), you can purchase one of the Connection and Analytics Service plans and then migrate your existing environment.\n\nTo migrate plans, contact your IBM\u00ae representative or raise a support ticket.\n\nTo migrate from Watson IoT Platform Lite plan, or to migrate to other plans with only the essential configuration settings included, see the instructions in [Migrating Watson IoT Platform Lite to Watson IoT Platform Non-production or Production](https:\/\/cloud.ibm.com\/docs\/services\/IoT?topic=IoT-org_migrationorg_migration).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/IoT?topic=IoT-plans_overview"},{"document_id":"ibmcld_00558-7-1874","score":23.4874145885,"text":"\nPlans and provisioning \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Standard is IBM Cloudant's most feature-rich offering, receiving updates and new features first. Pricing is based on provisioned throughput capacity that is allocated and data storage that is used, making it suitable for any required load.\n\nThe free [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) includes a fixed amount of throughput capacity and data for development and evaluation purposes. The paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan) offers configurable provisioned throughput capacity and data storage pricing that scales as your application requirements change. An optional [Dedicated Hardware plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicdedicated-hardware-plan) is also available for an extra monthly fee to run one or more of your Standard plan instances on a dedicated hardware environment. The dedicated hardware environment is for your sole use. If a Dedicated Hardware plan instance is provisioned within a US location, you can optionally select a [HIPAA](https:\/\/en.wikipedia.org\/wiki\/Health_Insurance_Portability_and_Accountability_Act) -compliant configuration.\n\n\n\n Plans \n\nYou can select which plan to use when you [provision your IBM Cloudant service instance](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicprovisioning-a-cloudant-nosql-db-instance-on-ibm-cloud). The available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_01316-1441-3315","score":23.4123481773,"text":"\nWatson IoT Platform Connection and Analytics Service - Capacity 1 and Capacity 2 The Connection and Analytics Service plans offer a ready-to-run, pre-integrated, and fully managed SaaS IoT platform with extended connectivity, data management, and advanced analytics features. For more information about the features that are offered with these service plans, see [the Watson IoT Platform Knowledge Center ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/www.ibm.com\/support\/knowledgecenter\/SSQP8H\/iot\/overview\/overview.html) \n\n\n\nFor more information about purchasing these plans, see [Internet of Things Platform in the IBM Cloud catalog ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/cloud.ibm.com\/catalog\/services\/internet-of-things-platform).\n\n\n\n Plans that are withdrawn from marketing \n\nThe following Standard and Advanced security plans are available only for existing customers of those plans. If you are a new customer, you must use the Lite plan or purchase one of the Watson IoT Platform Connection and Analytics Service plans.\n\n\n\n Plan Description \n\n Watson IoT Platform Standard The Standard service plan includes the free data-transfer limit that is offered in the Lite plan and then usage-based billing beyond the free quote for data exchanged, data analyzed, and edge data analyzed. \n Watson IoT Platform Advanced Security The Advanced Security service plan includes the free data-transfer limit that is offered in the Lite plan and then usage-based billing beyond the free quote for data exchanged, data analyzed, and edge data analyzed. This plan also provides advanced Risk and Security Management features. \n\n\n\n\n\n\n\n\n\n Upgrading service plans \n\nIf you are an existing customer and want to take advantage of the full [Watson IoT Platform feature set !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/IoT?topic=IoT-plans_overview"},{"document_id":"ibmcld_12904-7-1919","score":23.3845065334,"text":"\nPlans and provisioning \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Standard is IBM Cloudant's most feature-rich offering, receiving updates and new features first. Pricing is based on provisioned throughput capacity that is allocated and data storage that is used, making it suitable for any required load.\n\nThe free [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) includes a fixed amount of throughput capacity and data for development and evaluation purposes. The paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan) offers configurable provisioned throughput capacity and data storage pricing that scales as your application requirements change. An optional [Dedicated Hardware plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicdedicated-hardware-plan) is also available for an extra monthly fee to run one or more of your Standard plan instances on a dedicated hardware environment. The dedicated hardware environment is for your sole use. If a Dedicated Hardware plan instance is provisioned within a US location, you can optionally select a [HIPAA](https:\/\/en.wikipedia.org\/wiki\/Health_Insurance_Portability_and_Accountability_Act) -compliant configuration.\n\n\n\n Plans \n\nYou can select which plan to use when you [provision your IBM Cloudant service instance](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicprovisioning-a-cloudant-nosql-db-instance-on-ibm-cloud). The available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00558-20425-22479","score":48.9503264266,"text":"\nThe data storage that is measured for billable purposes for an IBM Cloudant instance is inclusive of both JSON data, indexes, and attachments.\n\n\n\n Data storage included \n\nThis value is the storage capacity that is included in the plan. The Lite plan has a hard limit of 1 GB allowed. The paid Standard plan includes 20 GB for free and any additional data that is stored is metered for billing.\n\n\n\n\n\n Data overage \n\nAll Lite and Standard plans are monitored for disk space used. When you use more data than the plan allocates, you can expect the conditions that are described in the following sections to apply:\n\n\n\n Lite plan \n\n\n\n* Disk usage is capped on the Lite plan at 1 GB.\n* After you reach the cap, you receive a warning on the IBM Cloudant Dashboard and can't write new data. If you try to write new data, a 402: payment required response occurs.\n* To write new data, you must either upgrade to the Standard plan or delete data, and wait until the next check runs for your account to be reactivated.\n\n\n\n\n\n\n\n Standard plan \n\n\n\n* If the account uses more than the 20 GB of storage that is included in the Standard plan, the excess is considered \"disk overage\". Overage causes the account to be billed at the indicated price for each extra GB used beyond the plan allocation.\n* The cost for the amount of disk overage is calculated on an hourly basis.\n\n\n\nFor example, assume your Standard plan increases disk usage to 107 GB for half a day (12 hours). This change means that your instance caused overflow of 87 GB more than the 20 GB plan allocation, for 12 hours. As the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-20515-22569","score":48.9503264266,"text":"\nThe data storage that is measured for billable purposes for an IBM Cloudant instance is inclusive of both JSON data, indexes, and attachments.\n\n\n\n Data storage included \n\nThis value is the storage capacity that is included in the plan. The Lite plan has a hard limit of 1 GB allowed. The paid Standard plan includes 20 GB for free and any additional data that is stored is metered for billing.\n\n\n\n\n\n Data overage \n\nAll Lite and Standard plans are monitored for disk space used. When you use more data than the plan allocates, you can expect the conditions that are described in the following sections to apply:\n\n\n\n Lite plan \n\n\n\n* Disk usage is capped on the Lite plan at 1 GB.\n* After you reach the cap, you receive a warning on the IBM Cloudant Dashboard and can't write new data. If you try to write new data, a 402: payment required response occurs.\n* To write new data, you must either upgrade to the Standard plan or delete data, and wait until the next check runs for your account to be reactivated.\n\n\n\n\n\n\n\n Standard plan \n\n\n\n* If the account uses more than the 20 GB of storage that is included in the Standard plan, the excess is considered \"disk overage\". Overage causes the account to be billed at the indicated price for each extra GB used beyond the plan allocation.\n* The cost for the amount of disk overage is calculated on an hourly basis.\n\n\n\nFor example, assume your Standard plan increases disk usage to 107 GB for half a day (12 hours). This change means that your instance caused overflow of 87 GB more than the 20 GB plan allocation, for 12 hours. As the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00558-1499-3456","score":48.8961007095,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-1535-3460","score":48.8894546459,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_03729-3519-5413","score":47.2854254519,"text":"\nThese resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings\n* Encrypted data storage limit, for example 1 GB\n* Provisioned throughput capacity\n\n\n\nYou can easily find services for Lite plans in the catalog. By default, all services with a Lite plan are displayed with a Lite tag ![Lite tag](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/Lite.svg). Select a service to view the quota details for the associated Lite plan.\n\n\n\n\n\n Charges for compute resources \n\nYou're charged for the time that your apps run and the memory that's used in GB-hours. GB-hours is the calculation of the number of application instances that are multiplied by the memory per instance and by the hours that the instances run. You can customize the number of instances and the amount of memory per instance based on your needs. You can also add memory or instances to scale for more users. To get the amount charged, take your application instances that are multiplied by memory per instance and by hours running.\n\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_12837-5848-7620","score":38.5454661348,"text":"\nDay 3 to Day 15 1 1 \/ 1 (5.5 + 3.5 + (1 + 13) \/ 15 1.4666 (On Day 15 EOD) \n Day 15 to Day 30 0 0 \/ 1 (5.5 + 3.5 + (1 * 12) + (0 * 15) \/ 30 0.7333 (On Day 30 EOD) \n\n\n\n* As seen on the same day as when the usage was submitted.\n\n\n\n\n\n Daily proration Max \n\nCalculate the maximum usage per day and average it for the month. The maximum of each day is added up and divided by the number of days currently passed (in Coordinated Universal Time).\n\nFormula: Summation(daily max) \/ number of days passed in billing period\n\nThe quantity might change throughout the month, but what is rated is the maximum usage per day.\n\nGiven a 30-day month, see the following table to calculate the maximum usage per day and monthly average:\n\n\n\nTable 6. Maximum usage per day and monthly average calculations\n\n Time Usage Daily Max Calculation Quantity in dashboard* \n\n Day 1 (morning) 0 MAX(0) 0 \/ 1 0 \n Day 1 (night) 1 MAX(0, 1) 1 \/ 1 1 \n Day 2 to Day 15 1 MAX(1) (1 + 1 + ...) \/ day 1 \n Day 15 to Day 30 0 MAX(0) (1 + (1 * 14) + 0 + ...) \/ day < 1 \n\n\n\n* As seen on the same day as when the usage was submitted.\n\n\n\n\n\n Monthly proration \n\nDivides the usage cost at the time of service creation by the remaining number of days in the month (in UTC, including the current day). Each subsequent month is not prorated. The full monthly charge is applied, regardless of how much the instance is used.\n\nFormula:\n\n\n\n* If provisioned date is from the current month: (Unit Price) * (Number of days that are remaining in the month \/ Number of days in the month)\n* If provisioned date is from the previous month: (Unit Price)\n\n\n\nGiven a 30-day month, see the following table to calculate the monthly prorated cost:\n\n\n\nTable 7. Monthly prorated cost calculations\n\n Time Usage Calculation Quantity in dashboard","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-service-metering-integration"},{"document_id":"ibmcld_07103-29564-31587","score":38.4497068835,"text":"\nPreviously, the list included fields that were not valid choices.\n\n\n\n\n\n 14 October 2021 \n\nNew Discovery home page\n: A new home page is displayed when you start Discovery and gives you quick access to a product overview video, and tours. You can collapse the home page welcome banner to see more projects.\n\nNew plan usage section\n: Stay informed about plan usage and check your usage against the limits for your plan type from the Plan limits and usage page. From the product page header, click the user icon ![User icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/user--avatar.svg). The Usage section shows a short summary. Click View all to see usage information for all of the plan limit categories.\n\nChange to spelling settings in Search\n: The spelling correction setting changed from being enabled automatically in new projects to being disabled by default. If you want to alert users when they misspell a term in their query, turn on Spelling suggestions. For more information, see [Customizing the search bar](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-search-bar).\n\nImproved Guided tours availability\n: The Guided tours button is now available from the product page header, which make them accessible from anywhere. Previously, it was available from the My Projects page only.\n\n\n\n\n\n 1 October 2021 \n\nChange to Lite and Advanced plans in all locations\n: Lite and Advanced plans are discontinued. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, and Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 24 September 2021 \n\nNew scoring for NLU enrichments","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_02660-1509-3609","score":38.073247872,"text":"\nCurrently, Dallas (us-south), Washington DC (us-east), London (eu-gb), and Sydney (au-syd) regions are supported.\n4. Select a pricing plan - Based on your business requirements, select a pricing plan: Lite, Standard, and Enterprise.\n\n\n\n* Lite - Includes all App Configuration capabilities for evaluation only. Not to be used for production. Lite plan services are deleted after 30 days of inactivity.\n* Standard - The standard plan includes feature flags and property management capabilities. You can use simple and uniform REST APIs to configure, enable, segment, and monitor features to mobile devices and web applications.\n* Enterprise - The enterprise plan includes targeting segment in addition to the property management and feature flags that are found in the Standard plan. The enterprise plan now supports by using private endpoints.\n\n\n\nFor more information about App Configuration usage and billing, see [Usage and billing](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage).\n5. Configure your resource by providing a Service name for your instance, or use the preset name.\n6. Select a resource group - The resource group selection helps how you want resources to be organized in your account. The resource group that you select cannot be changed after the service instance is created.\n7. Optionally, define Tags to help you to identify and organize the instance in your account. If your tags are billing related, consider writing tags as key:value pairs to help group-related tags, such as costctr:124.\n8. Optionally, define Access management tags that are needed to apply flexible access policies on specific resources. For example, access:dev, proj:version-1.\n9. If you selected the Enterprise plan, then specify the Service endpoints. The following options are available:\n\n\n\n* Public network - The public network service endpoints are accessible from anywhere on the internet.\n* Both Public & Private network - use of both public and private service endpoint network access.\n\n\n\n10. Accept the licensing agreements and terms by clicking the checkbox.\n11.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-create-an-instance"},{"document_id":"ibmcld_03729-1672-3956","score":37.3005447203,"text":"\nServices For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged. \n Tiered In this pricing model, you get a volumed-based discount according to your actual usage. Tiered pricing is typically used for charge metrics that are expected to have high quantities per month, such as API calls. Services might offer simple, graduated, or block tier pricing plans. Services For API Connect, one of the tiered plans charges $10,000 for the first 25 million monthly API calls and $40.00 USD per 100,000 API calls per month thereafter. \n Reserved Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment. Services Db2 on Cloud has reserved plans. \n\n\n\n\n\n Understanding monthly and hourly tags \n\nOn the usage dashboard, your products and resources can be labeled with Monthly, Hourly, or a combination of both tags to signify how often charges are updated.\n\nThe Monthly tag signifies that resources within your account have a fixed cost. These charge show up immediately after purchase and are prorated in proportion to how many days are left in the month. Any recurring monthly fixed costs are then shown at the first of every month.\n\nThe Hourly tag signifies that resources within your account have variable costs. These resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_12837-4569-6098","score":36.9959148571,"text":"\nDay 3 (morning) 3 (4 + 0 + 5 + 3) \/ 4 3 \n Day 4 (night) 3 (4 + 0 + 5 + 3 + 3) \/ 5 3 \n\n\n\n\n\n\n\n Standard Max \n\nSee the following table for information about how to calculate the maximum monthly usage.\n\nFormula: MAX(usages)\n\n\n\nTable 4. Maximum monthly usage calculations\n\n Time Usage Calculation Quantity in dashboard \n\n Day 1 (morning) 5 MAX(5) 5 \n Day 1 (night) 10 MAX(5, 10) 10 \n Day 2 (morning) 0 MAX(10, 0) 10 \n Day 3 (morning) 15 MAX(10, 15) 15 \n Day 4 (night) 1 MAX(15, 1) 15 \n\n\n\n\n\n\n\n Daily proration Average \n\nCalculate the average usage for each day and average it for the month. The average of each day is added and divided by the number of days currently passed (in UTC).\n\nFormula: Summation(daily average) \/ Number of days passed in the billing period\n\nThe quantity might change throughout the month, but what is rated is the average usage per day.\n\nGiven a 30-day month, use the following table to calculate the daily proration average:\n\n\n\nTable 5. Average usage per day and monthly average calculations\n\n Time Usage Daily average Calculation Quantity in dashboard* \n\n Day 1 (morning) 8 8 \/ 1 8 \/ 1 8 \n Day 1 (night) 3 (8 + 3) \/ 2 5.5 \/ 1 5.5 (On Day 1 EOD) \n Day 2 (morning) 2 2 \/ 1 (5.5 + 2) \/ 2 3.75 \n Day 2 (night) 5 (2 + 5) \/ 2 (5.5 + 3.5) \/ 2 4.5 (On Day 2 EOD) \n Day 3 to Day 15 1 1 \/ 1 (5.5 + 3.5 + (1 + 13) \/ 15 1.4666 (On Day 15 EOD) \n Day 15 to Day 30 0 0 \/ 1 (5.5 + 3.5 + (1 * 12) + (0 * 15) \/ 30 0.7333 (On Day 30 EOD) \n\n\n\n* As seen on the same day as when the usage was submitted.\n\n\n\n\n\n Daily proration Max","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-service-metering-integration"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02143-0-1216","score":20.2985523887,"text":"\n\n\n\n\n\n\n  Why can't I create a new Lite plan instance? \n\nYou try to create more than one instance in your Lite account.\n\n  What\u2019s happening \n\nYou receive the following error message when you try to create a new Lite plan instance:\n\n> Unable to provision new Lite instance\n>\n> The account already has an instance created with the Lite plan\n\n  Why it\u2019s happening \n\nThere's a limit of one instance per Lite plan to ensure that these plans stay free. For more information about Lite account features, see [Lite account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n  How to fix it \n\nYou can create more instances of the service by selecting one of the billable service plans, which are available in the billable accounts. To upgrade to a billable account from the console, go to Manage > Account in the IBM Cloud console, and select Account settings.\n\nIf you don't want to upgrade from a Lite account and are no longer using your existing Lite service instance, you can delete the existing Lite plan instance from the dashboard and then create a new instance. When you delete the Lite plan instance, all of the data that is associated with that instance is deleted and isn't recoverable.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-nosecondlite"},{"document_id":"ibmcld_05013-2864-3381","score":19.8129667713,"text":"\nCan I create more than one Object Storage service with a Lite account? \n\nIf you already have a Lite plan instance created, you may create other Standard plan instances, but only one Lite plan instance is allowed.\n\n\n\n\n\n What happens if I exceed the maximum usage allowed for a Lite plan? \n\nOnce you exceed the allowed usage, the service instance associated with the Lite plan becomes inaccessible. You will receive a warning notification email with corrective steps. If you do not take action, the instance is removed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-faq-provision"},{"document_id":"ibmcld_07103-31052-33321","score":19.75922913,"text":"\nYou cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, and Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 24 September 2021 \n\nNew scoring for NLU enrichments\n: Relevance and confidence scores are displayed for NLU enrichments that are returned by search. For example, when you open the JSON view of the document preview from a query result, you can see confidence scores for Entities mentions and relevance scores for Keyword mentions.\n\n\n\n\n\n 9 September 2021 \n\nNew location for Plus plan\n: The Plus plan is now available from the Sydney location. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product. For more information, see [Getting the most from Discovery](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-version-choose).\n\nChange to Lite and Advanced plans in most locations\n: Lite and Advanced plans are discontinued. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\n\n\n\n\n 26 August 2021 \n\nNew locations for the Plus plan\n: The Plus plan is now available from the London and Washington DC locations, in addition to Dallas, Frankfurt, and Tokyo.\n\nChange to Lite and Advanced plans in some locations\n: You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\nNew answer finding feature\n: Answer finding is now generally available for managed deployments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_01025-7-2061","score":19.6006507525,"text":"\nFAQs - Lite plan \n\nThis is a collection of frequently asked questions (FAQ) about the IBM\u00ae Db2\u00ae on Cloud Lite plan.\n\n\n\n Will my free plan expire? \n\nYou can continue using the free plan for as long as you need. However, you must reactivate the free plan every 45 days. This reactivation process keeps resources available for other users by turning off inactive usage.\n\nWhen your plan nears its reactivation date, you will receive a reactivation request at the email address that you provided when creating the instance. Alternatively, you can reactivate in your Db2 on Cloud console.\n\n\n\n\n\n Will my data be deleted? \n\nAfter you create a Lite instance, you have 45 days before the next reactivation.\n\n\n\n* If you do not reactivate, your Lite plan will be disabled, but IBM Cloud still has your data. You will then have 60 days to reactivate your account.\n* If you don't reactivate within 60 days, your account and data will be deleted. We will send you multiple emails reminding you to reactivate.\n\n\n\nEach time you reactivate, the day counter resets, and you'll have another 45 days before being disabled (and 60 days before deletion).\n\n\n\n\n\n How can I download a backup of my data on the Lite plan? \n\nHere are two simple options for backing up Lite plan data:\n\n\n\n* Use Db2 tools like the command line tool (clp) or IBM Data Studio to do an export. You can then import at another time.\n* To quickly make a backup, use the Web console, run a query, then download the results to a CSV file.\n\n\n\n\n\n\n\n Can I change the email I use for reactivation? \n\nCreate a new Lite instance with the email you want to use going forward. If needed, first back up your data, delete your current Lite plan instance to create a new one, then load your data. You cannot change the email address associated with an existing Db2 Lite instance if you have only a Lite account with community support.\n\n\n\n\n\n I am having trouble with reactivation. What should I do? \n\nIf you have trouble with reactivation of a Lite plan instance, you can delete that faulty instance and create a new one.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-faq_db2oc_lite"},{"document_id":"ibmcld_07578-1076793-1078629","score":19.5854908805,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1079289-1081125","score":19.5854908805,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01029-0-4062","score":19.5567186033,"text":"\n\n\n\n\n\n\n  Free Lite plan \n\nThe IBM\u00ae Db2\u00ae on Cloud Lite plan provides basic resources for you to develop or learn about Db2 without charge.\n\nThere is no time limit on the Lite plan, but users must re-extend their Lite plan every 30 days.\n\nOnly community support is available.\n\n\n\n  Architecture \n\nUnlike other Db2 on Cloud plans, the free Db2 on Cloud Lite plan runs on a multi-tenant system.\n\nThe Lite plan uses one database schema.\n\nFor more information about the free Db2 on Cloud Lite plan, see the [FAQ](https:\/\/ibm.biz\/db2oc_free_plan_faq).\n\n\n\n\n\n  Regional availability \n\nThe Lite plan is available in the Dallas and London regions. If you do not see the Lite plan listed in the catalog, select either Dallas or London region.\n\n\n\n\n\n  Restrictions \n\nIt is recommended that you use an enterprise-level service plan rather than a Lite service plan for mission-critical or performance-sensitive workloads.\n\nThe following table contains Db2 on Cloud Lite plan restrictions:\n\n\n\nTable 1. Db2 on Cloud Lite plan restrictions\n\n Category                Item                                                                   Restriction                                                                                              \n\n Resources               Storage                                                                200 MB of storage per user                                                                               \n                         Connections                                                            15 connections per user                                                                                  \n                         Performance                                                            Performance might fluctuate due to workloads run by other users on the multi-tenant system               \n Features & functions    Federation                                                             Not supported                                                                                            \n                         Oracle compatibility                                                   Not supported                                                                                            \n                         User-defined extensions (UDFs)                                         Not supported on any Db2 on Cloud plans, including the Lite plan                                         \n                         User management                                                        User not given administrative authority                                                                  \n                         Row and column access control (RCAC)                                   Not supported                                                                                            \n                         IBM InfoSphere Data Replication for use in loading data                Not supported                                                                                            \n Networking environment  IBM Cloud Integrated Analytics                                         Not supported                                                                                            \n                         IBM Cloud Dedicated                                                    Not supported                                                                                            \n Security compliances    Health Information Portability and Accountability Act of 1996 (HIPAA)  Not supported. Refer to your Service Description.                                                        \n                         EU General Data Protection Regulation (GDPR)                           Not supported. Refer to your Service Description.                                                        \n Account management      Reactivation                                                           Reactivation required every 30 days. If not reactivated, Lite plan services are deleted 60 days later.   \n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-free_plan"},{"document_id":"ibmcld_00558-1499-3456","score":19.3674409384,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_07578-494591-496583","score":19.1955649524,"text":"\n* Will my free plan expire?\n\nYou can continue using the free plan for as long as you need. However, you must reactivate the free plan every 45 days. This reactivation process keeps resources available for other users by turning off inactive usage.\n\nWhen your plan nears its reactivation date, you will receive a reactivation request at the email address that you provided when creating the instance. Alternatively, you can reactivate in your Db2 on Cloud console.\n* Will my data be deleted?\n\nAfter you create a Lite instance, you have 45 days before the next reactivation.\n\n\n\n* If you do not reactivate, your Lite plan will be disabled, but IBM Cloud still has your data. You will then have 60 days to reactivate your account.\n* If you don't reactivate within 60 days, your account and data will be deleted. We will send you multiple emails reminding you to reactivate.\n\n\n\nEach time you reactivate, the day counter resets, and you'll have another 45 days before being disabled (and 60 days before deletion).\n* How can I download a backup of my data on the Lite plan?\n\nHere are two simple options for backing up Lite plan data:\n\n\n\n* Use Db2 tools like the command line tool (clp) or IBM Data Studio to do an export. You can then import at another time.\n* To quickly make a backup, use the Web console, run a query, then download the results to a CSV file.\n\n\n\n* Can I change the email I use for reactivation?\n\nCreate a new Lite instance with the email you want to use going forward. If needed, first back up your data, delete your current Lite plan instance to create a new one, then load your data. You cannot change the email address associated with an existing Db2 Lite instance if you have only a Lite account with community support.\n* I am having trouble with reactivation. What should I do?\n\nIf you have trouble with reactivation of a Lite plan instance, you can delete that faulty instance and create a new one. If needed, first back up your data so you can load it to this new instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-494573-496565","score":19.1955649524,"text":"\n* Will my free plan expire?\n\nYou can continue using the free plan for as long as you need. However, you must reactivate the free plan every 45 days. This reactivation process keeps resources available for other users by turning off inactive usage.\n\nWhen your plan nears its reactivation date, you will receive a reactivation request at the email address that you provided when creating the instance. Alternatively, you can reactivate in your Db2 on Cloud console.\n* Will my data be deleted?\n\nAfter you create a Lite instance, you have 45 days before the next reactivation.\n\n\n\n* If you do not reactivate, your Lite plan will be disabled, but IBM Cloud still has your data. You will then have 60 days to reactivate your account.\n* If you don't reactivate within 60 days, your account and data will be deleted. We will send you multiple emails reminding you to reactivate.\n\n\n\nEach time you reactivate, the day counter resets, and you'll have another 45 days before being disabled (and 60 days before deletion).\n* How can I download a backup of my data on the Lite plan?\n\nHere are two simple options for backing up Lite plan data:\n\n\n\n* Use Db2 tools like the command line tool (clp) or IBM Data Studio to do an export. You can then import at another time.\n* To quickly make a backup, use the Web console, run a query, then download the results to a CSV file.\n\n\n\n* Can I change the email I use for reactivation?\n\nCreate a new Lite instance with the email you want to use going forward. If needed, first back up your data, delete your current Lite plan instance to create a new one, then load your data. You cannot change the email address associated with an existing Db2 Lite instance if you have only a Lite account with community support.\n* I am having trouble with reactivation. What should I do?\n\nIf you have trouble with reactivation of a Lite plan instance, you can delete that faulty instance and create a new one. If needed, first back up your data so you can load it to this new instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00436-0-941","score":17.5069552431,"text":"\n\n\n\n\n\n\n  Updating CDN configuration details \n\nAfter your CDN is running, you can update CDN configuration details. Follow these steps.\n\n\n\n1.  On the CDN page, select your CDN, which takes you to the Overview page.\n2.  Select the Settings tab. Your CDN configuration details are displayed.\n\nYou only see SSL Certificate if your CDN was configured with HTTPS.\n\nFor Server, the following fields can be changed:\n\n\n\n*  Host header\n*  Origin server address\n*  HTTP\/HTTPS Port\n*  Serve Stale Content\n*  Respect Headers\n*  Optimization options\n*  Cache-query\n\n\n\nFor Object Storage, the following fields can be changed:\n\n\n\n*  Host header\n*  Endpoint\n*  Bucket name\n*  HTTPS Port\n*  Allowed file extensions\n*  Serve Stale Content\n*  Respect Headers\n*  Optimization options\n*  Cache-query\n\n\n\n3.  Update the Origin or Other Options details if needed, then click the Save button in the lower right corner to update your CDN configuration details.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-updating-cdn-configuration-details"},{"document_id":"ibmcld_15263-5634-7460","score":16.8406301629,"text":"\nibmcloud is instance-delete $vsi\n\nThe status of the instance changes to deleting immediately, but it still appears in a list query result. The deletion of an instance can take up to 30 minutes.\n\nYou can request other subnet resources to be deleted in parallel while you wait for the instance to be deleted. However, the subnet cannot be deleted until the instance and all other resources in the subnet no longer appear in the list query results.\n\nIf a secondary network interface exists in the subnet you are trying to delete, you must delete the instance. A network interface cannot be deleted from the instance without deleting the instance.\n\n\n\n\n\n Delete the subnet \n\nAfter all the resources inside the subnet were deleted, which means that they are not returned in a list query result, run the following command to delete the subnet:\n\nibmcloud is subnet-delete $subnet\n\nThe status of the subnet changes to deleting immediately, but it might take a few minutes until the subnet is deleted and no longer appears in the list query results.\n\n\n\n\n\n\n\n Step 3: Delete all public gateways in the VPC, if any \n\nTo list all public gateways in your account, run the following command:\n\nibmcloud is public-gateways\n\nFor each public gateway in the VPC you want to delete, run the following command to delete the public gateway, where $gateway is the public gateway ID.\n\nibmcloud is public-gateway-delete $gateway\n\n\n\n\n\n Step 4: Delete the VPC \n\nAfter all subnets and public gateways in the VPC are deleted, run the following command to delete the VPC, where $vpc is the ID of the VPC you are deleting.\n\nibmcloud is vpc-delete $vpc\n\nThe status of the VPC changes to deleting immediately, but it might take a few minutes until the VPC is deleted and no longer appears in the list query results.\n\n\n\n\n\n\n\n Deleting a VPC by using the REST APIs","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-deleting-vpc-resources"},{"document_id":"ibmcld_16666-11924-13606","score":16.8092820105,"text":"\nFor the steps to perform ingestion, see the [Ingesting data through the command-line interface (CLI)](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-ingest_data_cli)\n\n\n\n\n\n Step 7: Querying data \n\nIn this section of the tutorial, you learn how to navigate to the Query workspace, and create SQL queries to query your data from the bucket.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1. From the navigation menu, select SQL. The Query workspace page opens.\n2. Select the Presto engine from the Engine drop-down.\n3. Select a catalog, for example, default schema, and a table, for example, order_detail, to run the query.\n4. Click the overflow menu and select the required query.\n\n\n\n* For a catalog and schema, you can run the Generate Path query.\n* For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n* For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\nConsider the following sample query to view the details from the table:\n\nExample:\n\n!\/bin\/bash\nSELECT * FROM \"iceberg-beta\".\"default\".\"order_detail\" LIMIT 10;\n5. Click Run on to run the query.\n6. Select Result set or Details tab to view the results. If required, you can save the query.\n7. Click Saved queries to view the saved queries.\n8. Click [Explain](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query) to view the logical or distributed plan of execution for a specified SQL query.\n\n\n\n\n\n\n\n Step 8: Keep exploring \n\n\n\n1. Explore the other tutorials in the documentation.\n2. Monitor the promo code consumption to decide whether to buy, build on (default), decline or manually delete your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-tutorial_hp_intro"},{"document_id":"ibmcld_16670-5968-7639","score":16.541720509,"text":"\nYou must link the Db2 and Netezza databases to the Presto engine that is used to process the data.\n\nTo associate Db2 with the Presto engine, do the following steps:\n\n\n\n1. From the Infrastructure manager, select Db2 database. Click the overflow menu icon at the end of the row and click Associate.\n2. In the Associate with engine form, select the Presto engine that you want to use to process the data.\n3. Click Associate and restart engine. The Db2 database is associated with the Presto engine.\n\n\n\nSimilarly, select the Netezza database and link it to the Presto engine.\n\n\n\n\n\n Step 6: Combine data \n\nYou can also navigate to the Query workspace to create SQL queries to query your data.\n\nTo run the SQL query to join two tables, do the following steps:\n\n\n\n1. From the navigation menu, select SQL. The Query workspace page opens.\n2. Select the Presto engine from the Engine drop-down.\n3. Click the overflow menu and select the required query.\n\n\n\n* For a catalog and schema, you can run the Generate Path query.\n* For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n* For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\nConsider the following sample query to join the details from Db2 and Netezza:\n\nExample:\n\n!\/bin\/bash\nSELECT * FROM \"Db2\".\"default\".\"order_detail\" AS details\nLEFT JOIN \"Netezza\".\"gosales\".\"order_detail\" AS header\nON details.order_number=header.order_number\nLIMIT 10;\n4. Click the Run on button to run the query.\n5. Select Result set or Details tab to view the combined result. If required, you can save the query.\n6. Click Saved queries to view the saved queries.\n7.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-tutorial_join_data"},{"document_id":"ibmcld_02522-7188-8827","score":16.3801773553,"text":"\nWhen the Data Engine query UI opens, a COS bucket is automatically generated. This bucket is used by default by the Data Engine service to store the results from your SQL queries.\n\nWen you run queries, you can specify a custom bucket to store results in. If your query does not specify one, the default one is used.\n\n\n\n\n\n Step 3.2. Get information on the file that you want to query in COS \n\nComplete the following steps:\n\n\n\n1. In the IBM Cloud dashboard, click the Menu icon ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6f3c07c34058f637b1c86044ca4f9b24214330a7\/icons\/icon_hamburger.svg) > Resource list > Storage.\n2. Select the Data Engine instance that has the bucket with the archive files.\n\nContact your IBM Cloud Activity Tracker administrator to get the COS information.\n3. Select Buckets.\n4. Select the bucket name. You can see the list of archive files in the bucket.\n5. Identify the file that you want to query.\n\nNotice that the file name has the name of your IBM Cloud Activity Tracker instance and the date, in UTC format, of the events that are included.\n\nIf you get a file of 20 bytes, that file does not have any data.\n6. For that file, select SQL URL.\n\nA window opens that shows the URL.\n7. Copy the URL.\n\n\n\n\n\n\n\n Step 3.3. Get information on the COS bucket that is used to store results from queries \n\nComplete the following steps:\n\n\n\n1. In the COS instance UI, select Buckets.\n2. Select the bucket name that you plan to use to store the results from queries.\n3. For that bucket, select SQL URL.\n\nA window opens that shows the URL.\n4. Copy the URL.\n\n\n\n\n\n\n\n Step 3.4. Transform an archive file to PARQUET format","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-sqlquery"},{"document_id":"ibmcld_02547-1335-2984","score":16.3654034205,"text":"\nSelect Everything to see all the events, or a view.\n\n\n\nYou can view events through the view that you have selected.\n\n\n\n\n\n View a subset of the events by applying a search query \n\nYou can select the events that are displayed through a view by applying a search query. You can save that view for reuse later. [Learn more](https:\/\/cloud.ibm.com\/docs\/services\/activity-tracker?topic=activity-tracker-viewsviews_step2).\n\n\n\n\n\n View a subset of the events by applying a timeframe \n\nYou can select the events that are displayed through a view by applying a timeframe.\n\nYou can apply a timestamp by specifying an absolute time, a relative time, or a time range.\n\nComplete the following steps to jump to a specific time:\n\n\n\n1. [Go to the web UI](https:\/\/cloud.ibm.com\/docs\/services\/activity-tracker?topic=activity-tracker-launchlaunch).\n2. Click the Views icon ![Views icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6f3c07c34058f637b1c86044ca4f9b24214330a7\/activity-tracker\/images\/views.png).\n3. Select Everything or a view.\n4. Enter a time query. Choose any of the following options:\n\n\n\n* Enter an abosute time to jump to a point in time in your events such as May 20 7:00pm.\n* Enter a relative time such as 2 days ago, today at 12am, or an hour ago.\n* Enter a time range such as yesterday 10am to yesterday 11am, last fri 4:30pm to 11\/12 1 AM, last wed 4:30pm to 23\/05 1 AM, or May 20 10am to May 22 10am. Make sure to include to to separate the initial timestamp from the end timestamp.\n\n\n\n5. Press ENTER.\n\nYou might get the error message: Your request is taking longer than expected, try refreshing your browser in a bit as we try to catch up. Retry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-view_events"},{"document_id":"ibmcld_09437-7403-8993","score":15.9613296656,"text":"\nAfter you log in with your user ID and password, the IBM Cloud dashboard opens.\n2. Click the Menu icon ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f61dbc5d84bf0c89e477a05cab04c72f429e1b7a\/icons\/icon_hamburger.svg) > Resource list > Services.\n3. Select an Data Engine instance.\n4. From the Manage tab, select Launch Data Engine UI.\n\n\n\nWhen the Data Engine query UI opens, a COS bucket is automatically generated. This bucket is used by default by the Data Engine service to store the results from your SQL queries.\n\nWen you run queries, you can specify a custom bucket to store results in. If your query does not specify one, the default one is used.\n\n\n\n\n\n Step 3.2. Get information on the file that you want to query in COS \n\nComplete the following steps:\n\n\n\n1. In the IBM Cloud dashboard, click the Menu icon ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f61dbc5d84bf0c89e477a05cab04c72f429e1b7a\/icons\/icon_hamburger.svg) > Resource list > Storage.\n2. Select the Data Engine instance that has the bucket with the archive files.\n\nContact your Log Analysis administrator to get the COS information.\n3. Select Buckets.\n4. Select the bucket name. You can see the list of archive files in the bucket.\n5. Identify the file that you want to query.\n\nNotice that the file name has the ID of your Log Analysis instance and the date, in UTC format.\n6. For that file, copy the Object Data Engine URL.\n\n\n\n\n\n\n\n Step 3.3. Get information on the COS bucket that is used to store results from queries \n\nComplete the following steps:\n\n\n\n1. In the COS instance UI, select Buckets.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-sqlquery"},{"document_id":"ibmcld_02522-8519-10234","score":15.90664444,"text":"\nComplete the following steps:\n\n\n\n1. In the COS instance UI, select Buckets.\n2. Select the bucket name that you plan to use to store the results from queries.\n3. For that bucket, select SQL URL.\n\nA window opens that shows the URL.\n4. Copy the URL.\n\n\n\n\n\n\n\n Step 3.4. Transform an archive file to PARQUET format \n\nWhen you query an archive file, the format of the data is JSON. You must transform the format to PARQUET to query successfully the data.\n\nParquet is an open source file format that stores nested data structures into a flat columnar format, and preserves the schema of the original data.\n\nThe Data Engine UI is an editor that lets you immediately start composing SQL queries. Since SQL Query uses Spark SQL, you can use Spark SQL functions and ANSI SQL to compose both simple and complex queries that involve large amounts of data.\n\nComplete the following steps to run the query to transform content from JSON into PARQUET:\n\n\n\n1. In the SQL editor field of the Data Engine UI, enter the following SELECT statement:\n\nSELECT * FROM cleancols(SQL_URL STORED AS JSON)\nINTO RESULTS_BUCKET STORED AS PARQUET\n\nWhere\n\n\n\n* SQL_URL is the SQL URL of the archive file in COS\n* RESULTS_BUCKET is the SQL URL of the custom COS bucket that you plan to use to upload the query results\n* Use [cleancols](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference) to avoid transformation problems into PARQUET format when the name of the columns include special characters or blanks.\n\n\n\nFor example, the following query is used to transform an archive file:\n\nSELECT * FROM cleancols(cos:\/\/ams03\/at-eu-de\/999999d8f1f.2019-06-03.62.json.gz STORED AS JSON)\nINTO cos:\/\/eu-de\/results-at STORED AS PARQUET\n2. Click Run.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-sqlquery"},{"document_id":"ibmcld_02522-5994-7615","score":15.6108729168,"text":"\nChoose any of the following actions to manage IAM policies in the IBM Cloud:\n\n\n\n* To grant permissions to a user, see [Assigning access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resourcesassign-new-access).\n* To revoke permissions, see [Removing access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resourcesremoving-access-console)).\n* To review a user's permissions, see [Reviewing your assigned access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resourcesreview-your-access-console).\n\n\n\n\n\n\n\n Step 3. Running a query through the Data Engine UI \n\nIn SQL, the term query is just another way of saying SELECT statement.\n\nTo run a query, complete the following steps:\n\n\n\n Step 3.1. Launch the Data Engine query UI \n\n\n\n1. [Log in to your IBM Cloud account](https:\/\/cloud.ibm.com\/login).\n\nAfter you log in with your user ID and password, the IBM Cloud dashboard opens.\n2. Click the Menu icon ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6f3c07c34058f637b1c86044ca4f9b24214330a7\/icons\/icon_hamburger.svg) > Resource list > Services.\n3. Select an Data Engine instance.\n4. From the Manage tab, select Launch Data Engine UI.\n\n\n\nWhen the Data Engine query UI opens, a COS bucket is automatically generated. This bucket is used by default by the Data Engine service to store the results from your SQL queries.\n\nWen you run queries, you can specify a custom bucket to store results in. If your query does not specify one, the default one is used.\n\n\n\n\n\n Step 3.2. Get information on the file that you want to query in COS \n\nComplete the following steps:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-sqlquery"},{"document_id":"ibmcld_16671-4467-6313","score":15.5575683821,"text":"\nWhen you register your own bucket, ensure to provide the correct details for bucket configuration. Quick start wizard does not validate the bucket configuration details and you cannot modify them later.\n\nEnsure that the data bucket contains data.\n2. Click Next. This displays the Catalogs configuration page.\n3. In the Catalogs configuration page, select Apache Iceberg.\n4. Click Next. This displays the Engine configuration page.\n5. In the Engine configuration page, select the engine type and size.\n\nDepending on the workload that you have, you can select the type and size of the Presto engine.\n6. Click Next. This displays the Summary page.\n7. In the Summary page, review the configurations before you finish setting up your data infrastructure.\n\nWhen the setup is complete, the watsonx.data home page is displayed. You are all set to use the watsonx.data or you can configure it further.\n8. Click Finish and go. This displays the Infrastructure manager page.\n\n\n\nYou can add more engines, catalogs, buckets, and databases in the Infrastructure manager page if you want to. For more information about creating engines, catalogs, buckets, databases, see Configuring watsonx.data components in the How To section.\n\n--------------------\n\n\n\n\n\n Step 4: Querying data \n\nIn this section of the tutorial, you learn how to navigate to the Query workspace, and create SQL queries to query your data from the bucket.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1. From the navigation menu, select SQL. The Query workspace page opens.\n2. Select the Presto engine from the Engine drop-down.\n3. Select the catalog. In this scenario, consider the Apache Iceberg catalog, default schema, order_detail table, to run the query.\n4. Click the overflow menu and select the required query.\n\n\n\n* For a catalog and schema, you can run the Generate Path query.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-tutorial_prov_custbckt"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08172-3021-4877","score":16.3709787224,"text":"\nIn addition:\n\n\n\n* Check for user permissions. Be sure that your user account has sufficient permissions to create and manage VPC resources, create a IBM Cloud\u00ae Transit Gateway and create a IBM Cloud\u00ae Transit Gateway services. See the list of [required permissions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-user-permissions-for-vpc-resources) for VPC. You will also need the ability to create resource groups and IAM resources like access groups, policies, service IDs, ...\n* You need an SSH key to connect to the virtual servers. If you don't have an SSH key, see [the instructions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-ssh-keys) for creating a key for VPC.\n\n\n\n\n\n\n\n Plan the Identity and Access Management Environment \n\nThe admin team will enable the other teams to administer their resources as much as possible. The admin team will manage users and control access but will not create and destroy the resources shown in the architecture diagram.\n\nEditor, Operator, Viewer and Manager are [IAM access roles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userrolesiamusermanrol). Each service defines the exact meaning of the roles and the associated actions. For VPC see the [Required permissions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resource-authorizations-required-for-api-and-cli-calls) section.\n\nTeams:\n\n\n\n* Admin - define the account structure such as resource groups, access groups, users, roles.\n* Network - create network resources such as DNS Services, Transit Gateway service, VPC and subnets.\n* Shared - create VSI and block devices in the shared VPC. Create DNS records for shared services.\n* Application1 - create VSI and block devices in the application1 VPC\n* Application2 - create VSI and block devices in the application2 VPC.\n\n\n\n\n\n IAM Conceptual \n\n\n\n Network Team \n\nA conceptual team ownership model was implemented.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hardware-firewall-shared?topic=hardware-firewall-shared-vpc-tg-dns-iam"},{"document_id":"ibmcld_13873-3003-4859","score":16.3709787224,"text":"\nIn addition:\n\n\n\n* Check for user permissions. Be sure that your user account has sufficient permissions to create and manage VPC resources, create a IBM Cloud\u00ae Transit Gateway and create a IBM Cloud\u00ae Transit Gateway services. See the list of [required permissions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-user-permissions-for-vpc-resources) for VPC. You will also need the ability to create resource groups and IAM resources like access groups, policies, service IDs, ...\n* You need an SSH key to connect to the virtual servers. If you don't have an SSH key, see [the instructions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-ssh-keys) for creating a key for VPC.\n\n\n\n\n\n\n\n Plan the Identity and Access Management Environment \n\nThe admin team will enable the other teams to administer their resources as much as possible. The admin team will manage users and control access but will not create and destroy the resources shown in the architecture diagram.\n\nEditor, Operator, Viewer and Manager are [IAM access roles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userrolesiamusermanrol). Each service defines the exact meaning of the roles and the associated actions. For VPC see the [Required permissions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resource-authorizations-required-for-api-and-cli-calls) section.\n\nTeams:\n\n\n\n* Admin - define the account structure such as resource groups, access groups, users, roles.\n* Network - create network resources such as DNS Services, Transit Gateway service, VPC and subnets.\n* Shared - create VSI and block devices in the shared VPC. Create DNS records for shared services.\n* Application1 - create VSI and block devices in the application1 VPC\n* Application2 - create VSI and block devices in the application2 VPC.\n\n\n\n\n\n IAM Conceptual \n\n\n\n Network Team \n\nA conceptual team ownership model was implemented.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/transit-gateway?topic=transit-gateway-vpc-tg-dns-iam"},{"document_id":"ibmcld_16096-2979-4835","score":16.3709787224,"text":"\nIn addition:\n\n\n\n* Check for user permissions. Be sure that your user account has sufficient permissions to create and manage VPC resources, create a IBM Cloud\u00ae Transit Gateway and create a IBM Cloud\u00ae Transit Gateway services. See the list of [required permissions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-user-permissions-for-vpc-resources) for VPC. You will also need the ability to create resource groups and IAM resources like access groups, policies, service IDs, ...\n* You need an SSH key to connect to the virtual servers. If you don't have an SSH key, see [the instructions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-ssh-keys) for creating a key for VPC.\n\n\n\n\n\n\n\n Plan the Identity and Access Management Environment \n\nThe admin team will enable the other teams to administer their resources as much as possible. The admin team will manage users and control access but will not create and destroy the resources shown in the architecture diagram.\n\nEditor, Operator, Viewer and Manager are [IAM access roles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userrolesiamusermanrol). Each service defines the exact meaning of the roles and the associated actions. For VPC see the [Required permissions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resource-authorizations-required-for-api-and-cli-calls) section.\n\nTeams:\n\n\n\n* Admin - define the account structure such as resource groups, access groups, users, roles.\n* Network - create network resources such as DNS Services, Transit Gateway service, VPC and subnets.\n* Shared - create VSI and block devices in the shared VPC. Create DNS records for shared services.\n* Application1 - create VSI and block devices in the application1 VPC\n* Application2 - create VSI and block devices in the application2 VPC.\n\n\n\n\n\n IAM Conceptual \n\n\n\n Network Team \n\nA conceptual team ownership model was implemented.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-tg-dns-iam"},{"document_id":"ibmcld_05074-7-1939","score":16.2971154516,"text":"\nTagging objects in IBM Cloud Object Storage \n\nYour data can be expressly defined, categorized, and classified in IBM Cloud\u00ae Object Storage using associated metadata, called \"tags.\" This document will show you how to take full control in \"tagging\" the objects representing your data.\n\n\n\n Objects and metadata \n\nOrganizing your data can be a complex task. Basic methods, such as using key prefixes like organizational \"folders\" are a great start to hierarchical structures. But for more complex organization, you will need custom \"\n\ntags.\" Your metadata can describe the relationships inherent to your data, and provide more organization than titles or folders. Unlike mere labels, there are two parts to a tag: a key and a value, defined individually according to your needs.\n\n\n\n Tagging Objects \n\nManaging tags describing your objects can be performed through various interfaces and architectures. Using the [Console](https:\/\/cloud.ibm.com) provides a graphical user interface. Using the command line requires tools like [curl](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-curl) and the knowledge of how it interacts with Object Storage.\n\n\n\n\n\n Before you begin \n\nYou need:\n\n\n\n* An [IBM Cloud\u00ae Platform account](https:\/\/cloud.ibm.com\/login)\n* An [instance of IBM Cloud Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-provision) and a bucket created for this purpose\n* An [IAM API key](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/iam?topic=cloud-object-storage-iam-overview) with Writer access to your Object Storage bucket or instance\n* Either existing or new objects that will have tags applied to them.\n\n\n\n\n\n\n\n Reading tags \n\nTags are accessible throughout an instance with the proper permissions. While the true organizational power of using tags as an organizational principle scales with you, you can access tags on an individual basis as well.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-object-tagging"},{"document_id":"ibmcld_02293-2937-4812","score":15.5622319501,"text":"\nAfter you share it with a user and they click the link, the dashboard is added to their account.\n\nAll users with the dashboard link can share the dashboard, which means other users can see the populated data that they have permission to view. If they don\u2019t have the same permissions as the owner, for example, if they don\u2019t have access to Cora\u2019s chatbot resource group, they cannot view that data. Users without permissions to the scoped resources are able to view the dashboard layout, but not the populated data. A user with insufficient permissions might see a warning icon next to the dashboard that indicates a scoping error and that the data that's displayed might not be complete. Make sure that the users you share a dashboard with have access to the resources you scope the dashboard to.\n\n\n\n\n\n Step 3: Duplicate a dashboard \n\nCora decides that the team of developers she manages doesn't need to see the Usage for the project. Other than the Usage widget, she wants to share with them essentially the same dashboard that she shared with her program director.\n\nYou can duplicate a dashboard to include the same structure and layout without having to re-create the dashboard from scratch.\n\n\n\n1. To duplicate a dashboard, click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/action-menu-icon.svg) > Duplicate.\n2. Define the scope. The scope and assigned access is not saved from the dashboard that was duplicated. Cora applies the resource group filter for the chatbot project just like she did for the original dashboard.\n3. Click Save dashboard.\n4. Click the Actions icon ![Action icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/action-menu-icon.svg), and select Share to share the new dashboard with the correct users.\n\n\n\n\n\n\n\n Next steps","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-tutorial-custom-dash"},{"document_id":"ibmcld_09127-7-2416","score":15.4897016129,"text":"\nUnderstanding user roles and resources \n\nIBM\u00ae Key Protect for IBM Cloud\u00ae supports a centralized access control system that leverages IBM Cloud\u00ae Identity and Access Management to help you assign your users the correct roles and access for your account, service instances, encryption keys, and key rings.\n\nBecause Key Protect is a key management system that, by its nature, involves encrypting important and often confidential data, it is vital that the permissions structure over the account, service instances, encryption keys, and key rings is both powerful and flexible. To this end, IBM Cloud\u00ae Identity and Access Management roles can be assigned in varying combinations, depending on the level of administration in question.\n\nThese varying kinds of access are analogous to many kinds of life situations. A person might be the founder and CEO of a company and yet only be a regular member of a local club, and likewise have no authority at all to write traffic tickets. In a similar way, Key Protect roles are assigned within the context of a specific part of Key Protect, although to make things simpler, Key Protect does define \"default\" roles over certain resources unless specified otherwise (which we'll discuss in more detail later).\n\nThere are two main areas of administration for almost all IBM Cloud products: the account (also known as the \"platform\"), and the service instances owned by the account. A large bank, for example, might have only one account (controlled by executive leadership) and separate service instances for each of the organizational units within the bank (for example, one unit might manage bank accounts while another manages loans). While it is likely that users with rights at the account level will also have rights over the various instances (and perhaps, though not always, the other way around), note that the names given to account roles are different than those for the roles within the service instances, reflecting this difference between account roles and service instance roles. For more information on those roles, their names, and their permissions, check out [IAM roles and actions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iam-service-roles-actions).\n\n\n\n How IAM access works \n\nAfter you set up and organize resource groups in your account, you can take advantage of a couple of strategies to streamline the access management process:\n\nAccess groups","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-access"},{"document_id":"ibmcld_16427-1463-3303","score":15.4441621152,"text":"\nFor more information about user roles, see [Assembling a team](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-team).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio with an administrator ID.\n2. Click the Settings icon to open the Service Details page. The page lists all the user IDs that are registered as Knowledge Studio users. Each user ID has one of the following roles (in decreasing order of included permissions):\n\n\n\n* Admin\n* Project Manager\n* Human Annotator\n\n\n\nFor information about user roles, see [User roles in Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-roles).\n3. Verify that there is at least one user with the Admin role. A user ID with this role can create workspaces, and act as a project manager or human annotator.\n4. If you have access to additional user IDs, verify that there are at least two users with the Human Annotator role.\n\nCreating a real-life model typically involves multiple human annotators in addition to an administrator or project manager. However, for purposes of the tutorial, you can continue with a single user ID.\n5. Optional: Change the role that is assigned to a user ID. From the Action column of the table, click the Edit link, an then change the assigned user role.\n\nYou can upgrade a user ID to a role with greater permissions, but you cannot downgrade a user with an Admin or Project Manager role to the Human Annotator role.\n\n\n\n\n\n\n\n\n\n Lesson 2: Creating a workspace \n\nIn this lesson, you will learn how to create a workspace within Knowledge Studio.\n\n\n\n About this task \n\nA workspace defines all the resources that are required to create a machine learning model, including training documents, the type system, dictionaries, and annotations that are added by human annotators.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-getting-started"},{"document_id":"ibmcld_09375-7-2061","score":15.4236629882,"text":"\nUsing groups to control data access \n\nYou can configure, control, and manage data that is available to users in your IBM Cloud\u00ae account by configuring groups in the logging instance.\n\nA group is comprised of users with authorization to specific data.\n\n\n\n Before you begin \n\nBefore configuring and using groups, you need to understand the following requirements and limitations.\n\nUsers require specific IBM Cloud\u00ae Identity and Access Management permissions to work with groups and group members.\n\n\n\nTable 1. Roles required for groups\n\n Role Permissions \n\n Account management role Required to invite users, access groups, and define policies \n Administrator platform role Required to manage the service \n Manager service role Required to manage groups \n Platform role viewer, service role reader, or standard member Required to launch the logging instance \n\n\n\nUser roles defining permissions and access to manage auditing events are defined in IBM Cloud\u00ae Identity and Access Management.\n\nYou can map Cloud Identity and Access Management access groups to service groups. Consider the following information:\n\n\n\n* You must name your service groups with the same name as your access groups. Users that belong to an access group are granted access to manage data in the service group.\n* You must define a policy per service group, where the group that you specify matches the access group name.\n* You must define the scope of the data that each service group can manage when you define the service group through the web UI.\n\n\n\n\n\n\n\n Configuring default access settings \n\nComplete the following steps to define the default settings for viewing data:\n\n\n\n1. Log in to your IBM Cloud account.\n\nClick [Log in to IBM Cloud](https:\/\/cloud.ibm.com\/login) to sign in to the IBM Cloud.\n\nAfter you log in with your user ID and password, the IBM Cloud console opens.\n2. Select your account.\n3. Click the Menu icon ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f61dbc5d84bf0c89e477a05cab04c72f429e1b7a\/log-analysis\/\/images\/icon_hamburger.svg) > Observability.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-group_data_access"},{"document_id":"ibmcld_16447-7-2125","score":15.3034955226,"text":"\nUser roles in Knowledge Studio for IBM Cloud Pak for Data \n\nIBM Watson\u2122 Knowledge Studio roles are used to organize a team of people who create machine learning or rule-based models.\n\n\n\n Notes about roles in Knowledge Studio \n\n\n\n* Knowledge Studio roles control access to Knowledge Studio functionality and are managed in the Knowledge Studio application.\n* The first user to launch the Knowledge Studio application is assigned the Admin role.\n* Once assigned, user roles can't be downgraded from higher to lower levels of permissions. Admins can't be downgraded to project managers or human annotators, and project managers can't be downgraded to human annotators. For information about adding users, upgrading roles, and deactivating user accounts, see [Assembling a team](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-team).\n* To manage a workspace, project managers need to be assigned to the workspace by an admin.\n* Admins and project managers can perform the role of human annotators. They can also [directly annotate document sets](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotating-document-sets-directly) without creating annotation tasks.\n\n\n\n\n\n\n\n Knowledge Studio role descriptions \n\nKnowledge Studio roles are described in the following table. Roles are listed in order of highest to lowest level of permissions.\n\n\n\nTable 1. Role descriptions\n\n Role Description \n\n Admin Responsible for administrative tasks, which include managing users, resource consumption, and monthly charges. In large team settings, admins rarely participate in the model development process. \n Project manager Responsible for the overall organization of the workspace that she or he is assigned to. Tasks include creating the type system, managing assets, managing annotation work, evaluating the machine learning model, and deploying models. Users in this role need industry subject-matter expertise because they create the type system, teach the human annotators how to correctly apply the type system, and evaluate the model quality.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-roles"},{"document_id":"ibmcld_02476-7-2131","score":15.2951830923,"text":"\nUsing groups to control data access \n\nYou can configure, control, and manage data that is available to users in your IBM Cloud\u00ae account by configuring groups in the auditing instance.\n\nA group defines the scope of the data that is available for users that belong to that group.\n\n\n\n Before you begin \n\nBefore configuring and using groups, you need to understand the following requirements and limitations.\n\nUsers require specific IBM Cloud\u00ae Identity and Access Management permissions to work with groups and group members.\n\n\n\nTable 1. Roles required for groups\n\n Role Permissions \n\n Account management role Required to invite users, access groups, and define policies \n Administrator platform role Required to manage the service \n Manager service role Required to manage groups \n Platform role viewer, service role reader, or standard member Required to launch the auditing instance \n\n\n\nUser roles defining permissions and access to manage auditing events are defined in IBM Cloud\u00ae Identity and Access Management.\n\nYou can map Cloud Identity and Access Management access groups to service groups. Consider the following information:\n\n\n\n* You must name your service groups with the same name as your access groups. Users that belong to an access group are granted access to manage data in the service group.\n* You must define a policy per service group, where the group that you specify matches the access group name.\n* You must define the scope of the data that each service group can manage when you define the service group through the web UI.\n\n\n\n\n\n\n\n Configuring default access settings \n\nComplete the following steps to define the default settings for viewing data:\n\n\n\n1. Log in to your IBM Cloud account.\n\nClick [Log in to IBM Cloud](https:\/\/cloud.ibm.com\/login) to sign in to the IBM Cloud.\n\nAfter you log in with your user ID and password, the IBM Cloud console opens.\n2. Select your account.\n3. Click the Menu icon ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/icon_hamburger.svg) > Observability.\n4. Select Activity Tracker.\n5. For your instance, click Open Dashboard. The UI will be displayed.\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-group_data_access"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07120-7686-9754","score":42.908964353,"text":"\n15c3-5 In November 2011, the SEC implemented the final provision of Rule 15c3-5 curbing unfiltered market access. The provision mandated that brokers verify their clients\u2019 order flow for compliance with credit and capital thresholds before routing to market centers\n\nAgain, the answer is accurate (despite there being some extraneous text at the beginning of the passage).\n\nIn both examples, a somewhat complex question is asked and the passage that is returned provides a valid answer.\n\nHowever, not every question returns as clear an answer. Next, we try some queries that generate answers we might want to improve.\n4. Enter Where do muni bond trades get reported to?\n\nIn this case, the response does not answer the question completely.\n\nPost-trade transparency, in the form of transaction reports, generally is available for corporate and municipal bonds. 1. Transaction Reports in Corporate Bonds: TRACE Transactions in corporate bonds must be reported to the Trade Reporting\n5. Similarly, the search query, What are PTFs?, does not return a direct answer.\n\nDespite the surge in trading volume during the event window, there was no noticeable change in net positions of PTFs or bank-dealers. However, the report also finds evidence that some PTFs and bank-dealers may have contributed to the volatility\n\n\n\nYour project is answering some of the questions successfully. Only one passage is being returned for each query. Let's see whether we can improve the responses that are given to these simpler search queries.\n\n\n\n\n\n Step 5: Create a user-trained Smart Document Understanding (SDU) model \n\nTo improve the quality of the search results, build a Smart Document Understanding model for this document. The model helps Discovery understand the document structure. You can then instruct Discovery about which sections of the document to search and which sections to ignore.\n\n\n\n1. From the Improvement tools panel of the Improve and customize page, expand Define structure, and then click New fields.\n\nZoom\n\n![Shows the New fields tool in the Improvement tools panel.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-tutorial-sdu"},{"document_id":"ibmcld_13111-4747-6784","score":30.4219925027,"text":"\nThe amount of data that is scanned depends on the amount of data that Data Engine must read to run your query, and not on the actual size of your data. Several factors play a role when it comes to how much data needs to be accessed to run a query. First, data layout is important. Columnar formats, such as Parquet, lead to less data to be scanned, as Data Engine can selectively read ranges and single columns. Furthermore, the actual object layout determines how many objects need to be scanned. Read [How to lay out big data in IBM Cloud Object Storage for Spark SQL](https:\/\/www.ibm.com\/cloud\/blog\/big-data-layout) for more details on how to lay out big data on Cloud Object Storage to improve cost and performance of SQL queries. Each successful query is charged with at least 10 MB.\n\n\n\n Example \n\nAssume you have 1 PB of data that is stored on Cloud Object Storage that is laid out as described in the [blog post](https:\/\/www.ibm.com\/cloud\/blog\/big-data-layout) and is optimized for the queries you want to run. If you run a single query, the most expensive query possible is SELECT * FROM, as reading 1 PB of data is required. Any other query is much cheaper and faster. For example, a 1 PB data set consists of audit events for users of a system (user A performed action B in system X at time T) and the data is laid out in a way that it is partitioned by time (one file per day and system). So to answer a query like SELECT DISTINCT user FROM WHERE System='X' AND Day >= (TODAY - 30), Data Engine must access all objects for system X that contain data for the last 30 days. The sum of the size of these objects is the maximum estimate of data that is scanned that you would be charged for. But as Data Engine accesses only one field, and data is stored as Parquet, it is much less. Calculating the precise price of the query is not possible in advance because much of it depends on the data itself. Parquet, for example, stores compressed columns, so if the column can be compressed effectively, even less data needs to be read.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/sql-query?topic=sql-query-overview"},{"document_id":"ibmcld_13490-4738-6775","score":30.4219925027,"text":"\nThe amount of data that is scanned depends on the amount of data that Data Engine must read to run your query, and not on the actual size of your data. Several factors play a role when it comes to how much data needs to be accessed to run a query. First, data layout is important. Columnar formats, such as Parquet, lead to less data to be scanned, as Data Engine can selectively read ranges and single columns. Furthermore, the actual object layout determines how many objects need to be scanned. Read [How to lay out big data in IBM Cloud Object Storage for Spark SQL](https:\/\/www.ibm.com\/cloud\/blog\/big-data-layout) for more details on how to lay out big data on Cloud Object Storage to improve cost and performance of SQL queries. Each successful query is charged with at least 10 MB.\n\n\n\n Example \n\nAssume you have 1 PB of data that is stored on Cloud Object Storage that is laid out as described in the [blog post](https:\/\/www.ibm.com\/cloud\/blog\/big-data-layout) and is optimized for the queries you want to run. If you run a single query, the most expensive query possible is SELECT * FROM, as reading 1 PB of data is required. Any other query is much cheaper and faster. For example, a 1 PB data set consists of audit events for users of a system (user A performed action B in system X at time T) and the data is laid out in a way that it is partitioned by time (one file per day and system). So to answer a query like SELECT DISTINCT user FROM WHERE System='X' AND Day >= (TODAY - 30), Data Engine must access all objects for system X that contain data for the last 30 days. The sum of the size of these objects is the maximum estimate of data that is scanned that you would be charged for. But as Data Engine accesses only one field, and data is stored as Parquet, it is much less. Calculating the precise price of the query is not possible in advance because much of it depends on the data itself. Parquet, for example, stores compressed columns, so if the column can be compressed effectively, even less data needs to be read.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overview"},{"document_id":"ibmcld_10898-7-2339","score":29.2889125691,"text":"\nDisaster recovery testing \n\nDisaster recovery (DR) testing is what you must do to keep your ability to be resilient, hoping not to need to do it for real. There are different types of disaster recovery testing that you can do to verify your resiliency capabilities:\n\n\n\n* DR dry test\n* DR simulation\n* Switch-over\n\n\n\n\n\n Disaster recovery dry test \n\nA DR dry test is performed by checking all of the resource availability and runbooks on paper, without running a real DR simulation or switch-over.\n\nThis type of testing is normally run with higher frequency compared to the other testing flavors as no real activities are performed, but it does require the same effort in terms of skills and people.\n\nThe adoption of a recovery orchestrator software improves the whole dry testing process and reduces the time and effort to be run because most of the operations are performed by the software itself. This also increases the preparedness checking of a real DR simulation or switch-over by periodic scanning that all of the components of the DR solutions are in place and works as expected.\n\n\n\n\n\n Disaster recovery simulation \n\nDR simulation is a way to verify or audit the emergency runbooks and check the\n\nrecovery time objectives(RTO) andrecovery point objectives(RPO) provided by the solution by simulating as much as possible in the same conditions as a real emergency.\n\nThis means introducing disruptions on replication network connections before interrupting the communications among the sites, hence simulating the sudden loss of the primary site.\n\nYou can do this only if your data replication solution is resilient and not providing impact on the production, which continues on the primary site. If this is not the case, then look at the documentation for [plan and design for the worst conditions](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-understanding-drworst-conditions).\n\nDR simulation deploys a duplicate of your production environment on the DR site that you can use to perform validation and checking. This environment is cleaned at the end of the simulation and updates that happened to the DR test environment are discarded, as the real production has continued on the primary site.\n\nIt is important thus that network streams flowing to the DR test environment are copies of the real production environment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-dr-testing"},{"document_id":"ibmcld_07117-3483-5402","score":28.8011265385,"text":"\nIf you encounter this issue, export the PPT file as a PDF file, and then upload the PDF file instead. Apply a user-trained Smart Document Understanding (SDU) model to the document, and then use the SDU tool to identify the tables in the document. The resulting model handles table boundaries properly and can extract text from the tables cleanly.\n\n\n\n\n\n PDF file troubleshooting tips \n\nFailed to parse document due to invalid encoding\n: Enable OCR for the file.\n\n\n\n\n\n Enrichment troubleshooting tips \n\nTable Understanding: n input tables excluded by enrichment\n: If tables in a document have inconsistent column and row spans or are too large for the system to process completely, the table understanding enrichment is not applied to them. Information from such tables cannot be returned in search results. If you want the table understanding enrichment to be applied to a table that was skipped, consider editing the table. Change a table with inconsistent column and row spans to have a simpler table format. Split a large table into many smaller tables.\n\nTo find the table where the enrichment was not applied, check the warning message. It lists the character offsets where the table begins and ends in the HTML representation of the document. To see the full warning message and get the document ID, click View all, and then make a note of the document ID. From the Improve and customize page, submit an empty search query to return all of the indexed documents. Look for the document ID. (You can change the search result settings to show the document ID as the result title.) Click the View passage in document link for your document, and then click Open advanced view. Choose to view the document as JSON and then look for the html field. Copy and paste the HTML representation of the document into a text editor. Look for the character offsets that were listed in the original warning message to find the table.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-troubleshoot-ingestion"},{"document_id":"ibmcld_16364-150574-152699","score":28.0102794894,"text":"\nYou can now enable disambiguation and configure it from the skill's Options tab.\n\nAn introductory tour is now available\n: A short product tour is now displayed when a new service instance is created. Brand new users are also given help as they start development. A new assistant is created for them automatically. Informational popups are displayed to introduce the product user interface features, and guide the new user toward taking the key first step of creating a dialog skill.\n\n\n\n\n\n 10 April 2019 \n\nAutocorrection is now available\n: Autocorrection is a beta feature that helps your assistant understand what your customers want. It corrects misspellings in the input that customers submit before the input is evaluated. With more precise input, your assistant can more easily recognize entity mentions and understand the customer's intent. See [Correcting user input](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-spell-check) for more details.\n\n\n\n\n\n 22 March 2019 \n\nIntroducing search skill\n: A search skill helps you to make your assistant useful to customers faster. Customer inquiries that you did not anticipate and so have not built dialog logic to handle can be met with useful responses. Instead of saying it can't help, the assistant can query an external data source to find relevant information to share in its response. Over time, you can build dialog responses to answer customer queries that require follow-up questions to clarify the user's meaning or for which a short and clear response is suitable. And you can use search skill responses to address more open-ended customer queries that require a longer explanation. This beta feature is available to users of Premium and Plus service plans only.\n\nSee [Building a search skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add) for more details.\n\n\n\n\n\n 4 March 2019 \n\nSimplified navigation\n: The sidebar navigation with separate Build, Improve, and Deploy tabs has been removed. Now, you can get to all the tools you need to build a dialog skill from the main skill page.\n\nImprove page is now called Analytics","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_13483-993-2877","score":28.0089574516,"text":"\nConnection properties (except for the CRN) can be specified as part of the URL, separated by &, or through the Java connection properties object. The following properties are supported:\n\n\n\n* password (required): IBM Cloud API key for running the queries. The property name must start with a lowercase letter.\n* user (optional): A username is not required and is ignored if given. It must start with a lowercase letter.\n* targetcosurl (optional, but usually needed): Cloud Object Storage URI in SQL query style, where the results are stored. If this property is not specified, you cannot run queries that return a JDBC result set. The JDBC connection can still be used to retrieve database metadata and run DDL and [ETL-type statements](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-jdbcetl-type-statements). It must start with a lowercase letter.\n* loggerFile (optional, default none): file to write driver logs to.\n* loggerLevel (optional, default set by JDK: java.util.logging level for the driver. JDK default is usually INFO.\n\n\n\n* DEBUG\/FINER or TRACE\/FINEST are the most useful values.\n\n\n\n* filterType (optional, default none):\n\n\n\n* Only tables are returned if filterType value is set to table.\n* Only views are returned if filterType value is set to view.\n\n\n\n* appendInto (optional, default true):\n\n\n\n* If it is set to false, no INTO clause is appended, and results are not available through the driver. It is used with [ETL-type statements](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-jdbcetl-type-statements), where the INTO options are provided as part of the statement.\n\n\n\n\n\n\n\n\n\n Driver functions \n\nThis driver is designed as a facade to JVM applications for easy access to Data Engine service. The driver uses the REST API of the service to run queries, stores the results in Cloud Object Storage, and makes these results accessible through JDBC interfaces.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-jdbc"},{"document_id":"ibmcld_11098-1510-3924","score":27.2791970303,"text":"\nAnd, in some ways it is extremely modular in that the replacement unit is usually an entire server. But there is one major difference between the redundancy that is provided in a mainframe and the redundancy that is provided in the cloud \u2013 in the cloud the redundancy must be managed by the user. This means that to design a system to run with high availability on the cloud the system designer needs to be familiar with various high availability issues, as well as the design issues associated with the system that they are trying to build.\n\nThere are decades of academic and practical writings on high availability, and much of the work requires a good understanding of probability mathematics. However, much like with the formula, many of the principles become obvious when properly explained. Redundancy, which can be complicated in some cases, such as the various levels of RAID disk subsystems, is simply a way of dealing with a widely known principle of system design: \u201cAvoid single points of failure.\u201d Admittedly, while the phrase is simple and obvious, implementation can be tricky.\n\nRather than go into the complexities of such implementations, we cover a high-level overview of the areas that need to be addressed by anyone looking to build or run a highly available cloud system.\n\nBeyond the general principles of redundancy, fast repair, and single points of failure (SPOFs), probably the most important thing to understand is that improving availability requires spending effort on avoiding likely causes of outages, rather than trying to harden the system against all possible outages.\n\nAn example can help to make this clear. In astronomy, it is understood that our solar system will effectively end when the Sun goes nova. This will obviously cause all the computing systems on Earth to fail. Hence it is not something worth spending time and money on avoiding. Perhaps that particular example seems too extreme. So as a much simpler, business-oriented example, consider a city-wide fire, such as the one that burned down much of Chicago in the late 1800s. Fires on that scale are unusual, but not unique. As a business, should you spend time and money making sure that your computer systems could survive such a fire? The answer depends on various factors, but if for instance, your entire customer base is in Chicago, worrying about events that will wipe out the whole city is likely not useful.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-ha-considerations"},{"document_id":"ibmcld_09980-6235-7365","score":27.087499114,"text":"\n\"connection.user\": \"user1\",\n\"connection.password\": \"secret\",\n\"dialect.name\": \"GenericDatabaseDialect\",\n\"topics\": \"TEST_TABLE\",\n\"insert.mode\": \"insert\",\n\"name\": \"test-sink\"\n},\n\"tasks\": [],\n\"type\": \"sink\"\n}\nShow more\n\n\n\n6. Verify whether the registration was successful.\n\na) List the connectors.\n\ncurl -s http:\/\/localhost:8083\/connectors\/ | jq\n[\n\"test-source-jdbc\",\n\"test-sink\"\n]\n\nb) Check the status of the connectors.\n\ncurl -s http:\/\/localhost:8083\/connectors\/test-source-jdbc\/status | jq\n{\n\u00a0 \"name\": \"test-source-jdbc\",\n\u00a0 \"connector\": {\n\u00a0\u00a0\u00a0 \"state\": \"RUNNING\",\n\u00a0\u00a0\u00a0 \"worker_id\": \"10.11.112.15:8083\"\n},\n\u00a0 \"tasks\": [\n\u00a0\u00a0\u00a0 {\n\u00a0\u00a0\u00a0\u00a0\u00a0 \"id\": 0,\n\u00a0\u00a0\u00a0\u00a0 \"state\": \"RUNNING\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\"worker_id\": \"10.11.112.15:8083\"\n\u00a0\u00a0\u00a0 }\n\u00a0 ],\n\u00a0 \"type\": \"source\"\n}\nShow more\n\n\n\nYou can verify whether the connectors work correctly by checking the Netezza Performance Server logs.\n\n\n\n* For the source connector:\n\n2022-06-29 04:13:09.057046 PDT [27743]\u00a0 DEBUG:\u00a0 QUERY: SELECT 1\n2022-06-29 04:13:09.061443 PDT [27743]\u00a0 DEBUG:\u00a0 QUERY: SELECT * FROM \"DB1\".\"USER1\".\"TEST_TABLE\"\nANALYZE\n2022-06-29 04:13:09.064209 PDT [27743]\u00a0 DEBUG:\u00a0 QUERY: SELECT * FROM \"DB1\".\"USER1\".\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-netezzakafka"},{"document_id":"ibmcld_07115-7009-9068","score":27.069968311,"text":"\n* The rating that you apply to the result that indicates whether the result is relevant or not relevant\n\n\n\nTo apply relevancy training to a project, complete the following steps:\n\n\n\n1. Go to the Improve and customize page. On the Improvement tools panel, select Improve relevance, then Relevancy training.\n2. Enter a natural language query in the Enter a question to train field.\n\nDo not include a question mark in your query. Use the same wording as your users. For example, IBM Watson in healthcare. Write queries that include some of the terms that are mentioned in the target answer. Term overlap improves the initial results when the natural language query is evaluated.\n3. Click Add+.\n4. Click Rate results.\n5. After the results are displayed, assess each result, and then select Relevant or Not relevant, whichever option applies given the quality of the result.\n\nWhen you select Relevant, you apply a score of 10 to the result. Not relevant applies a score of 0. You can use a different scoring scale if you use the API to rate results, but you can't mix scoring scales within the same project.\n\nIf the result shows the message, \u201cNo content preview available for this document\u201d, it means that the document that was returned does not contain a text field or that its text field is empty. If none of the documents in your collection have a text field, use the API to train the project instead of training it from the product user interface.\n6. When you are finished, click Back to queries.\n7. Continue adding queries and rating them.\n\nAs you rate results, your progress is shown. Check your progress to see when enough rating information is available to meet the training threshold needs. Your progress is broken into the following tasks:\n\n\n\n* Add more queries\n* Rate more results\n* Add more variety to your ratings\n\n\n\nYou must evaluate at least 50 unique queries, maybe more, depending on the complexity of your data. You cannot add more than 10,000 training queries.\n8. You can continue adding queries and rating results after you reach the threshold.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-train"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07214-72932-74977","score":12.3250452633,"text":"\nNew enhancements to query API : Enhancements are now available for the query API (GET \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/query). See the [Query your collection](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-your-collection) method in the API reference for information.\n\nNew support for 'passages' parameter in the query API : The query API now supports the passages parameter. If the parameter is set to true, the query returns a set of the most relevant passages from the documents in your collection. The passages are generated by sophisticated Watson algorithms to determine the best passages of text from all of the documents returned by the query. This enables you to find information and context more precisely. See the [Query your collection](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-your-collection) method in the API reference for information. : Specifying passages=true in your query can reduce performance as a result of increased processing to extract passages. With larger environments, the performance impact can be lessened. : The passages parameter is supported only on private collections. It is not supported in the Watson Discovery News collection. : The passages parameter currently returns a maximum of 10 results. The number of returned results cannot be changed. [Update](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parameterspassages_count) : The passages parameter returns a maximum of three (3) passages from any given document in the collection. If a document contains more than three additional relevant passages, the parameter does not return them.\n\n\n\n\n\n 7 April 2017 \n\nNew support for 'sort' parameter in the query API : The query API (GET \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/query) now supports the sort parameter, which enables you to specify a comma-separated list of fields in the document to sort on. See the [Query your collection](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-your-collection) method in the API reference for information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_07016-7-1819","score":12.2583529323,"text":"\nCurations API \n\nThe Curations feature is beta functionality.\n\nUse curations to specify the exact document to return in response to a specific natural language query. Curations can guarantee that frequent or important questions always return the most valuable document. The confidence_score for a curated query is always 1.00000.\n\nThis beta feature is only available from the API and is applied only to natural language queries, not queries that are specified by using the Discovery Query Language. Beta features are not available from the SDKs.\n\nYou can define up to 1,000 curations. For more information, see [Create curation](https:\/\/cloud.ibm.com\/apidocs\/discovery-datacreatecuration) in the API reference.\n\nThis example shows how a curation is added with the API. When querying with the same or similar natural_language_query the document with the document_id of document_id1234 is returned.\n\n{\n\"natural_language_query\": \"curations in watson discovery\",\n\"curated_results\": [\n{\n\"document_id\": \"document_id1234\",\n\"collection_id\": \"collection_id1234\"\n}\n]\n}\n\nThe natural language query that is submitted by the customer must be an exact match for the query that is specified in the curation. Both queries, the one submitted by the user at run time and the one that is submitted by the curation API and then stored in the index, undergo query analysis. The query analyzer lemmatizes text, removes stop words, and adds query expansions.\n\nYou can optionally specify a hard-coded response to the query by including a snippet. A snippet is a response that you author and that is returned when the associated document is returned for the specified natural language query.\n\n{\n\"curations\": [\n{\n\"curation_id\": \"c1175536f509405bc68a9f76235fa7bbb6f9af2f\",\n\"natural_language_query\": \"What is a project\",\n\"curated_results\":\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-curations"},{"document_id":"ibmcld_07214-71282-73334","score":12.2541690933,"text":"\n: [Resolved](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notesdiscovery-30june2017)\n\nImproved tooling error log : The Tooling error log is no longer limited to a maximum of eight (8) pages of results. The error log still displays the document ID if the document name is not available.\n\nUpdate to configuration names : Configuration names are limited to 50 characters and must consist of the characters [a-zA-Z0-9-_].\n\nImproved availability of 'passages' parameter : The passages parameter previously available only through the API is now available through the Tooling as well as the API.\n\n\n\n\n\n 25 April 2017 \n\nNew training data functionality : Use training data to improve the accuracy of your query results. When you provide a Discovery instance with training data, the service uses advanced Watson algorithms to determine the most relevant results. As you add more training data, the service instance becomes more accurate and sophisticated in the results it returns. See [Improving the relevance of your query results](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api) and the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/discoverylist-training-data) for information.\n\nNew beta support for 'natural_language_query' parameter : The API now supports the natural_language_query parameter as a beta release. This parameter enables you to specify a query in natural language instead of in the Discovery service's query language. See the [Query your collection](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-your-collection) method in the API reference for information.\n\n\n\n\n\n 14 April 2017 \n\nNew enhancements to query API : Enhancements are now available for the query API (GET \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/query). See the [Query your collection](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-your-collection) method in the API reference for information.\n\nNew support for 'passages' parameter in the query API : The query API now supports the passages parameter.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_13475-2776-3323","score":12.2511927284,"text":"\n* [IBM Cloud Data Engine introduction](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-videovideo_samples_notebooks_api).\n* [How to connect to IBM Cloud Object Storage through the Command Line](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-videovideo_command_line).\n* [How to use the Data Engine REST API](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-videovideo_rest_api).\n* [How to operationalize SQL code and call it from an application](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-videovideo_samples_notebooks_api).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting-started"},{"document_id":"ibmcld_07045-4959-6113","score":12.1523499635,"text":"\nFor example, you might want to show facets based on keywords or dictionary categories. For more information, see [Facets](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-facets).\n\n\n\n\n\n Explore other search features \n\nWhen you test your project from the Discovery user interface, you submit a natural language query. Search features are available that you can enable to influence how the natural language query search is done. And Discovery Query Language search is another type of search that you can leverage by using the API. If the initial results don't meet your needs, experiment with another search method.\n\n\n\n* Discovery Query Language (DQL) search: A search mechanism that accepts more complex queries. You must use the query API to submit DQL queries.\n\nFor example, you can search for specific values in fields that are generated by enrichments that are applied to a collection.\n* Natural language query is the type of search that is triggered from the Improve and customize page.\n\n\n\nFor more information about the Query API, see [Query API overview](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-concepts).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-improvements"},{"document_id":"ibmcld_00512-5160-7348","score":12.014926209,"text":"\nSee also a brief overview of the underlying querying mechanism that you use to select the query mechanism that is best for each query your application needs to make.\n\n\n\n Global querying \n\nYou can make global queries to the following index types:\n\n\n\n* IBM Cloudant Query\n* Views\n* Search\n\n\n\nWhen you make a global query, the database must perform a scatter-gather operation across all data in the database. This action means making requests of many individual database servers. The API coordination node receives the responses from all these servers and combines them to form a single response to the client. This response might involve buffering data and delaying the response to the client if, for example, data requires sorting.\n\n\n\n\n\n Partition querying \n\nYou can make partition queries to the following index types:\n\n\n\n* IBM Cloudant Query\n* Views\n* Search\n\n\n\nWhen you make a partition query, the database can query just the data within a single partition. A partition's data resides in just one shard (with three replicas). The API coordination node can make a request directly to servers that host that data rather than needing to combine responses from many servers. The API coordination node is also free from buffering the response since it has no combination step to carry out. As a result, the data arrives at the client more quickly.\n\nAs the size of a database increases, the number of shards must also increase. The increase in shards directly increases the number of queries that the API coordination node needs to make to servers that host data when you use global queries. However, when you use partition queries, the number of shards has no effect on the number of servers the API coordination node needs to contact. As this number stays small, increasing data size has no effect on query latency, unlike global queries.\n\n\n\n\n\n\n\n Partitioned databases tutorials \n\nYou can see two examples of using partitioned databases:\n\n\n\n1. Read about [partitioned databases and Node.js](https:\/\/blog.cloudant.com\/2019\/05\/24\/Partitioned-Databases-with-Cloudant-Libraries.html) in this blog article that includes how to create a partitioned database, search, views, and a global index.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_13075-7-2200","score":12.0133774612,"text":"\nImproving result relevance with the tooling \n\nThe relevance of natural language query results can be improved in IBM Watson\u2122 Discovery with training. You can train your private collections using either the Discovery tooling, or the Discovery APIs. See [Improving the relevance of your query results with the API](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api) if you would prefer to use the APIs.\n\nRelevancy training is optional; if the results of your queries meet your needs, no further training is necessary. For information about use cases for relevancy training, see [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/).\n\nTo train Watson, you must provide the following:\n\n\n\n* Example queries that are representative of the queries your users enter\n* Ratings that indicate which results for each query are relevant and not relevant\n\n\n\nAfter Watson has enough training input, the information that you provide about which results are good and bad for each query is used to learn about your collection. Watson does not just memorize, but it also learns from the specific information about individual queries and applies the patterns it detects to all new queries. It does so, using machine-learning Watson techniques that find signals in your content and questions. After training, Discovery then reorders the query results to display the most relevant results at the top. As you add more and more training data, Discovery becomes more accurate in the ordering of query results.\n\nRelevance training currently applies only to natural language queries in private collections. It is not intended for use with structured Discovery Query Language queries. For more about the Discovery Query Language, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts).\n\nAll private collections return a confidence score in the query results in most cases. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-tooling"},{"document_id":"ibmcld_07178-14849-16999","score":11.9987872526,"text":"\n* The Discovery News is part of the system environment and cannot be included in multiple collection queries.\n* Individual collection relevancy training does not affect ranking of results when querying multiple collections. To rerank results returned when querying multiple collections implement [Continuous Relevancy Training](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-crt).\n* Reranking is not performed on any part of a multiple collection query, even if all collections in the query are trained.\n\n\n\nSee the [multiple collection query API reference](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-documents-in-multiple-collections) for more information.\n\nYou can view notices across multiple collections in the same environment by using the environments\/{environment_id}\/notices API method.\n\n\n\n* The collection_ids parameter must be specified when using this method. collection_ids is a comma-separated list of collections in the environment to query.\n* passages are supported when querying multiple collections.\n\n\n\nSee the [multiple collection notices API reference](https:\/\/cloud.ibm.com\/apidocs\/discoveryget-collection-details) for more information.\n\nYou can view the fields available across collections in the same environment by using the environments\/{environment_id}\/fields API method. See the [multiple collection field query API reference](https:\/\/cloud.ibm.com\/apidocs\/discoverylist-fields-across-collections) for more information.\n\n\n\n\n\n Query expansion \n\nYou can expand the scope of a query beyond exact matches - for example, you can expand a query for \"ibm\" to include \"international business machines\" and \"big blue\" - by uploading a list of query expansion terms. Query expansion terms are usually synonyms, antonyms, or typical misspellings for common terms.\n\nYou can define two types of expansions:\n\n\n\n* bidirectional - each expanded_term expands to include all expanded terms. For example, a query for ibm expands to ibm OR international business machines OR big blue).\n* unidirectional - the input_terms in the query are replaced by the expanded_terms. For example, a query for banana could expand to plantain and fruit.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts"},{"document_id":"ibmcld_07160-7-1535","score":11.9589433237,"text":"\nBuilding queries with the Discovery Query Language \n\nIn this tutorial, we will learn how to write a few different types of queries in the Discovery Query Language.\n\nFor more information about writing queries, see:\n\n\n\n* [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts)\n* [Query reference](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-reference) (includes the list of parameters, operators, and aggregations available in the Discovery Query Language)\n\n\n\nThese example queries are built using the Discovery tooling. If you'd like to use the API instead, add the query parameters to your API call. For more information and examples, see the Queries section of the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-your-collection).\n\nYou can also write natural language queries (such as \"IBM Watson partnerships\") using the Discovery tooling. This tutorial primarily focuses on how to write queries with Discovery Query Language because your requirements might necessitate a structured query, and filters and aggregations must be written in the Discovery Query Language.\n\n\n\n Before you begin \n\nGo to the Manage data screen and create a new collection named IBM Press Releases, and add these four documents to it: [test-doc1.html ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ded4adc3ea0bd2a81b113c579f2b1183926da211\/icons\/launch-glyph.svg)](https:\/\/watson-developer-cloud.github.io\/doc-tutorial-downloads\/discovery\/test-doc1.html), [test-doc2.html !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-getting-started-with-querying"},{"document_id":"ibmcld_07214-7810-9614","score":11.9542102762,"text":"\nDeprecated Knowledge Graph Beta APIs and Knowledge Graph relationship query : As announced [3 September 2019](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes3sept19), the IBM Watson\u2122 Discovery Knowledge Graph Beta APIs (Knowledge graph entity query \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/query_entities and Knowledge Graph relationship query \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/query_relations) are no longer accessible.\n\nDeprecated Preview API : As announced [4 June 2019](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes4jun19), the Preview API is deprecated and is no longer available.\n\n\n\n\n\n 3 September 2019 \n\nChange to Knowledge Graph Beta APIs and Knowledge Graph relationship query : IBM Watson\u2122 Discovery Knowledge Graph Beta APIs (Knowledge graph entity query \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/query_entities and Knowledge Graph relationship query \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/query_relations) are no longer be accessible, as of 30 September 2019. Data already in Discovery collections is not affected, nor are any other existing queries or operations affected. You can find the documentation for Knowledge Graph in the [Discovery archives](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-discovery-archiveskg) until 30 September 2019.\n\n\n\n\n\n 29 August 2019 \n\nUpdated Web crawl connector status : The Web crawl connector moved from beta status to GA status. See [Web crawl](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sourcesconnectwebcrawl) for more information about this connector.\n\n\n\n\n\n 4 June 2019 \n\nChange to Preview API : The Preview API is deprecated and is no longer available, effective 30 September 2019.\n\n\n\n\n\n 30 April 2019","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1390561795}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16551-0-1579","score":15.9819711574,"text":"\n\n\n\n\n\n\n  How can I address storage space limits? \n\nDepending on your subscription plan, you might reach the storage limit that is specified for your plan and be prevented from completing tasks.\n\n  What\u2019s happening \n\nYou might see a message about exceeding the allowed storage space when you attempt to perform one of these tasks:\n\n\n\n*  Upload documents or dictionaries\n*  Deploy a model or version a model\n*  Run a pre-annotator on documents\n\n\n\n  Why it\u2019s happening \n\nThe storage limit is met or exceeded if the action proceeds.\n\n  How to fix it \n\nThe largest consumers of storage space are machine learning and rule-based models. To free up space, you can take the following actions:\n\n\n\n*  Delete snapshot versions of any models that you do not expect to need to revert to.\n*  Delete any models that you do not need.\n*  If your models are too important to delete, consider upgrading your plan to one that provides a larger allotment of storage space.\n\n\n\nAfter you remove models or model versions, wait an hour before you retry the action that resulted in the error message. It can take up to an hour for the storage space that you freed up to be available for use.\n\nTo manage your monthly bill, if the Admin role is assigned to you and you have a Premium or Standard account, you can set a storage limit on the Service Details page in Knowledge Studio. To see the Service Details page and set the storage limit, from the top navigation bar in Knowledge Studio, click the Settings icon, click the View\/modify service details link, and then click the Set storage limit link.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_ts_storage"},{"document_id":"ibmcld_01241-13660-15370","score":13.7498953412,"text":"\n-h, --help Show this message and exit.\n\nIf you're using the replication feature, be sure that the schedule that you're deleting isn't the schedule that is used by replication. For more information about deleting a replication schedule, see [here](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-replication).\n\n\n\n\n\n Deleting a snapshot in the UI \n\nSnapshots that are no longer needed can be manually removed to free up space for future snapshots. Deletion is done through Storage > File Storage for Classic.\n\n\n\n1. Click your storage volume and click Snapshot to see the list of existing snapshots.\n2. Click Actions![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/04e9937a86546143babfc65ea21fdd4ea2d12d13\/icons\/action-menu-icon.svg) next to a particular snapshot and click Delete to delete the snapshot. This deletion doesn't affect any future or past snapshots on the same schedule as snapshots don't depend on each other.\n\n\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Deleting a snapshot from the SLCLI \n\nSnapshots that are no longer needed can be manually removed to free up space for future snapshots. You can delete a snapshot from the SLCLI by using the following command.\n\n slcli file snapshot-delete --help\nUsage: slcli file snapshot-delete [OPTIONS] SNAPSHOT_ID\n\nOptions:\n-h, --help Show this message and exit.\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Restoring storage volume to a specific point in time by using a snapshot in the UI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managingSnapshots"},{"document_id":"ibmcld_00241-13788-15540","score":13.6683260236,"text":"\n-h, --help Show this message and exit.\n\nIf you're using the replication feature, be sure that the schedule you're deleting isn't the schedule that is used by replication. For more information about deleting a replication schedule, see [Replicating Data](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-replication).\n\n\n\n\n\n Deleting a snapshot in the UI \n\nSnapshots that are no longer needed can be manually removed to free up space for future snapshots. Deletion is done through Storage > Block Storage for Classic.\n\n\n\n1. Click your storage volume and click Snapshot to see the list of existing snapshots.\n2. Click Actions![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/14cf2f2f32b430cf4ed67ad14b3cecc010f91c45\/icons\/action-menu-icon.svg) next to a particular snapshot and click Delete. Click the confirmation box that warns about possible data loss, then click Delete. This deletion doesn't affect any future or past snapshots on the same schedule as snapshots don't depend on each other.\n\n\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations (oldest first).\n\n\n\n\n\n Deleting a snapshot from the SLCLI \n\nSnapshots that are no longer needed can be manually removed to free up space for future snapshots. You can delete a snapshot from the SLCLI by using the following command.\n\n slcli block snapshot-delete\nUsage: slcli block snapshot-delete [OPTIONS] SNAPSHOT_ID\n\nOptions:\n-h, --help Show this message and exit.\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Restoring storage volume to a specific point in time by using a snapshot in the UI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-managingSnapshots"},{"document_id":"ibmcld_00308-7-2154","score":13.1828834626,"text":"\nSnapshots \n\nSnapshots are a feature of IBM Cloud\u00ae Block Storage for Classic. A snapshot represents a volume's contents at a particular point in time. With snapshots, you can protect your data with no performance impact and minimal consumption of space. Snapshots are considered your first line of defense for data protection. If a user accidentally modifies or deletes crucial data from a volume, the data can be easily and quickly restored from a snapshot copy.\n\nBlock Storage for Classic provides you with two ways to take your snapshots.\n\n\n\n* First, through a configurable snapshot schedule that creates and deletes snapshot copies automatically for each storage volume. You can also create extra snapshot schedules, manually delete copies, and manage schedules based on your requirements.\n* The second way is to take a manual snapshot.\n\n\n\nA snapshot copy is a read-only image of a Block Storage for Classic LUN that captures the state of the volume at a point in time. Snapshot copies are efficient both in the time that is needed to create them and in storage space. A Block Storage for Classic snapshot copy takes only a few seconds to create. It's typically less than 1 second, regardless of the size of the volume or the level of activity on the storage. After a snapshot copy is created, changes to data objects are reflected in updates to the current version of the objects, as if Snapshot copies didn't exist. Meanwhile, the copy of the data remains stable.\n\nA Snapshot copy incurs no performance decrease. Users can easily store up to 50 scheduled snapshots and 50 manual snapshots per Block Storage for Classic volume, all of which are accessible as read-only and online versions of the data.\n\nWith snapshots, you can:\n\n\n\n* Nondisruptively create point-in-time recovery points,\n* Revert volumes to previous points-in-time.\n\n\n\nYou must purchase some amount of snapshot space for your volume first so you can take snapshots of it. The snapshot space can be added during the initial order or afterward through the Volume Details page. Scheduled and manual snapshots share the snapshot space, so make sure you order enough Snapshot space.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-snapshots"},{"document_id":"ibmcld_01288-7-2152","score":13.1828834626,"text":"\nSnapshots \n\nSnapshots are a feature of IBM Cloud\u00ae File Storage for Classic. A snapshot represents a volume's contents at a particular point in time. With snapshots, you can protect your data with no performance impact and minimal consumption of space. Snapshots are considered your first line of defense for data protection. If a user accidentally modifies or deletes crucial data from a volume, the data can be easily and quickly restored from a snapshot copy.\n\nFile Storage for Classic provides you with two ways to take your snapshots.\n\n\n\n* First, through a configurable snapshot schedule that creates and deletes snapshot copies automatically for each storage volume. You can also create extra snapshot schedules, manually delete copies, and manage schedules based on your requirements.\n* The second way is to take a manual snapshot.\n\n\n\nA snapshot copy is a read-only image of a File Storage for Classic volume that captures the state of the volume at a point in time. Snapshot copies are efficient both in the time that is needed to create them and in storage space. A File Storage for Classic snapshot copy takes only a few seconds to create. It's typically less than 1 second, regardless of the size of the volume or the level of activity on the storage. After a snapshot copy is created, changes to data objects are reflected in updates to the current version of the objects, as if Snapshot copies didn't exist. Meanwhile, the copy of the data remains stable.\n\nA Snapshot copy incurs no performance decrease. Users can easily store up to 50 scheduled snapshots and 50 manual snapshots per File Storage for Classic volume, all of which are accessible as read-only and online versions of the data.\n\nWith snapshots, you can:\n\n\n\n* Nondisruptively create point-in-time recovery points,\n* Revert volumes to previous points-in-time.\n\n\n\nYou must purchase some amount of snapshot space for your volume first so you can take snapshots of it. The snapshot space can be added during the initial order or afterward through the Volume Details page. Scheduled and manual snapshots share the snapshot space, so make sure you order enough Snapshot space.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-snapshots"},{"document_id":"ibmcld_01225-7204-8862","score":13.0195449623,"text":"\nUnmount, then mount the modified volume, so the OS can recognize the extra storage space.\n\n\n\n\n\n Resizing storage with Terraform \n\nYou can increase your storage capacity by using the ibm_storage_file resource, and specifying a different number in the capacity argument. The following example increases the capacity of an Endurance volume to 40 GB.\n\nresource \"ibm_storage_file\" \"fs_endurance\" {\ntype = \"Endurance\"\ndatacenter = \"dal09\"\ncapacity = 40\niops = 0.25\n}\n\nThe following example increases the capacity of a Performance volume to 40 GB.\n\nresource \"ibm_storage_file\" \"fs_performance\" {\ntype = \"Performance\"\ndatacenter = \"dal09\"\ncapacity = 40\niops = 100\n}\n\nFor more information about the arguments and attributes, see [ibm_storage_file](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/resources\/storage_file).\n\nUnmount, then mount the modified volume, so the OS can recognize the extra storage space.\n\n\n\n\n\n Expanding Storage over 12 TB \n\nIf you need to increase your Storage volume capacity beyond 12 TB, you can request to be added to the allowlist by submitting a [support case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/add). When the request is approved by the Offering Manager, you're going to be notified through the case process. You're also going to see the option to increase your storage up to 24 TB in the console.\n\nThe number of operations that can be performed on the storage is limited. This limit is 180k IOPS. So if you want to provision a volume with 10 IOPS, your maximum volume size is 18 TB. If you want to provision the maximum size of 24 TB, then the maximum rate of reads and writes to the volume is 4 IOPS per GB.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-expandCapacity"},{"document_id":"ibmcld_01241-5726-7749","score":12.8643413856,"text":"\nThe snapshot is taken and displayed in the Snapshots section of the Detail page. Its schedule appears Manual.\n\n\n\n\n\n Taking a manual Snapshot from the SLCLI \n\nYou can use the following command to create a snapshot from the SLCLI.\n\n slcli file snapshot-create --help\nUsage: slcli file snapshot-create [OPTIONS] VOLUME_ID\n\nOptions:\n-n, --notes TEXT Notes to set on the new snapshot\n-h, --help Show this message and exit.\n\n\n\n\n\n Listing all Snapshots with Space Used Information and Management functions in the UI \n\nA list of retained snapshots and space that is used can be seen on the File Storage for Classic Detail page. Management functions (editing schedules and adding more space) are conducted on the File Storage for Classic Detail page by using the Actions menu or links in the various sections on the page. The Snapshot page displays how much capacity the volume has and how much of it is used.\n\nYou receive notifications when you reach space thresholds \u2013 75 percent, 90 percent, and 95 percent.\n\n\n\n* At 75 percent capacity, a warning is sent that snapshot space usage exceeded 75 percent. To remediate, you can manually add space, or delete retained unnecessary snapshots. You can reduce the number of retained snapshots in the schedule. If you reduce the snapshot data or increase the space, the warning system is reset, and no autodeletion occurs.\n* At 90 percent capacity, a second warning is sent when snapshot space usage exceeded 90 percent. Like with reaching 75 percent capacity, if you take the necessary actions to decrease the snapshot data or increase the space, the warning system is reset and no autodeletion occurs.\n* At 95 percent capacity, a final warning is sent. If no action is taken to bring your space usage under the threshold, automatic deletion starts so that future snapshots can be created. Scheduled snapshots are deleted, starting with the oldest, until usage drops under 95 percent. Snapshots continue to be deleted each time usage exceeds 95 percent until it drops under the threshold.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managingSnapshots"},{"document_id":"ibmcld_00241-5761-7733","score":12.7196196585,"text":"\nIts schedule appears Manual.\n\n\n\n\n\n Taking a manual Snapshot from the SLCLI \n\nYou can use the following command to create a snapshot from the SLCLI.\n\n slcli block snapshot-create --help\nUsage: slcli block snapshot-create [OPTIONS] VOLUME_ID\n\nOptions:\n-n, --notes TEXT Notes to set on the new snapshot\n-h, --help Show this message and exit.\n\n\n\n\n\n Listing all Snapshots with Space Used Information and Management functions in the UI \n\nA list of retained snapshots and space that is used can be seen on the Block Storage for Classic Detail page. Management functions (editing schedules and adding more space) are conducted on the Block Storage for Classic Detail page by using the Actions![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/14cf2f2f32b430cf4ed67ad14b3cecc010f91c45\/icons\/action-menu-icon.svg) menu or links in the various sections on the page. The Snapshot page displays how much capacity the volume has and how much of it is used.\n\nYou receive notifications when you reach space thresholds \u2013 75 percent, 90 percent, and 95 percent.\n\n\n\n* At 75 percent capacity, a warning is sent that snapshot space usage exceeded 75 percent. To remediate, you can manually add space, or delete retained unnecessary snapshots. You can reduce the number of retained snapshots in the schedule. If you reduce the snapshot data or increase the space, the warning system is reset, and no autodeletion occurs.\n* At 90 percent capacity, a second warning is sent when snapshot space usage exceeded 90 percent. Like with reaching 75 percent capacity, if you take the necessary actions to decrease the snapshot data or increase the space, the warning system is reset and no autodeletion occurs.\n* At 95 percent capacity, a final warning is sent. If no action is taken to bring your space usage under the threshold, automatic deletion starts so that future snapshots can be created. Scheduled snapshots are deleted, starting with the oldest, until usage drops under 95 percent.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-managingSnapshots"},{"document_id":"ibmcld_04693-5720-7686","score":12.6696531309,"text":"\nFor example, you might scale from 256 - 1256 MB by changing the memory quota on the app details page. However, because the disk quota remained the same, you didn't get more disk space.\n\n Why it\u2019s happening \n\nThe default disk quota that is allocated for an app is 1 GB. If you need more disk space, you must manually specify the disk quota.\n\n How to fix it \n\nUse one of the following methods to specify your disk quota. The maximum disk quota that you can specify is 2 GB. If 2 GB is still not enough, try an external service such as [Cloud Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-getting-started-cloud-object-storage).\n\n\n\n* In the manifest.yml file, add the following item:\n\ndisk_quota: <disk_quota>\n* Use the -k option with the ibmcloud cf push command when you push your app to IBM Cloud:\n\nibmcloud cf push appname -p app_path -k <disk_quota>\n\n\n\n\n\n\n\n Org's services limit is exceeded \n\nIf you are a Lite account user, you might be unable to create an app in IBM Cloud if you exceeded your organization's services limit.\n\n What\u2019s happening \n\nWhen you try to create an app in IBM Cloud, the following error message is displayed:\n\nBXNUI2032E: The <service_instances> resource wasn't created. While Cloud Foundry was being contacted to create the resource, an error occurred. Cloud Foundry message: \"You have exceeded your organization's services limit.\"\n\n Why it\u2019s happening \n\nThis error occurs when you exceed the limit on the number of service instances that you can have for your account.\n\n How to fix it \n\nDelete any services instances that aren't needed, or remove the limit on the number of service instances that you can have.\n\n\n\n* To delete a services instance, you can use the IBM Cloud console or the command line interface.\n\nTo use the IBM Cloud console to delete a service instance, complete the following steps: 1. In the resource list, click the Actions menu for the service that you want to delete. 2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-ts-cf-apps"},{"document_id":"ibmcld_00241-4-1958","score":12.3686616481,"text":"\n* UI\n* CLI\n* Terraform\n\n\n\n\n\n\n\n Managing Snapshots \n\nSnapshots are a feature of IBM Cloud\u00ae Block Storage for Classic. A snapshot represents a volume's contents at a particular point in time. With snapshots, you can protect your data with no performance impact and minimal consumption of space. Learn more about how to manage snapshots by reading the following instructions.\n\n\n\n Adding a Snapshot schedule in the UI \n\nYou decide how often and when you want to create a point in time reference of your storage volume with Snapshot schedules. You can have a maximum of 50 snapshots per storage volume. Schedules are managed through the Storage > Block Storage for Classic tab of the [IBM Cloud\u00ae console](https:\/\/cloud.ibm.com\/classic-gen1).\n\nBefore you can set up your initial schedule, you must first purchase snapshot space if you didn't purchase it during the initial provisioning of the storage volume. For more information, see [Ordering Snapshots](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-orderingsnapshots).\n\nSnapshots schedules can be set up for hourly, daily, and weekly intervals, each with a distinct retention cycle. The maximum limit of snapshots is 50 per storage volume, which can be a mix of hourly, daily, and weekly schedules, and manual snapshots.\n\n\n\n1. Click your storage volume, click Actions, and click Edit Snapshot Schedule.\n2. In the Snapshot Schedule window, you can select from three different snapshot frequencies. Use any combination of the three to create a comprehensive snapshot schedule.\n\n\n\n* Hourly\n\n\n\n* Specify the minute each hour that a snapshot is to be taken. The default is the current minute.\n* Specify the number of hourly snapshots to be retained before the oldest is discarded.\n\n\n\n* Daily\n\n\n\n* Specify the hour and minute that a snapshot is to be taken. The default is the current hour and minute.\n* Select the number of hourly snapshots to be retained before the oldest is discarded.\n\n\n\n* Weekly","title":"","source":"https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-managingSnapshots"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14654-7-1943","score":20.2503967313,"text":"\nPlanning for vCenter Server instances \n\nPlan your instance based on the IBM Cloud\u00ae data center location, your workload capacity requirements, and add-on services requirements. Review the following requirements before you order your VMware vCenter Server\u00ae instance.\n\n\n\n* New deployments of vCenter Server instances with VMware vSphere\u00ae 6.5 or 6.7 are not supported.\n* New deployments of vCenter Server multizone instances are not supported.\n* New deployments of vCenter Server with NSX-V instances are not supported.\n\n\n\n\n\n Account requirements \n\nThe account that you are using must meet certain requirements. For more information, see [Signing up for required accounts](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-signing_required_accounts).\n\n\n\n\n\n IBM Cloud data center availability \n\nThe vCenter Server deployment has strict requirements on the physical infrastructure. Therefore, you can deploy instances only in IBM Cloud data centers that meet the requirements. The following IBM Cloud data centers are available for vCenter Server deployment.\n\nAsia-Pacific\n\nEurope\n\nNA East\n\n\n\nTable 1. Available IBM Cloud data centers for vCenter Server instances\n\n Geography Data center Pod Server options for NSX-T<br><br>[1] Server options for NSX-V<br><br>[2] \n\n Asia-Pacific CHE01 01 Skylake, Cascade Lake Skylake, Cascade Lake, SAP-certified Cascade Lake<br><br>[3] \n Asia-Pacific OSA21 01 Cascade Lake, SAP-certified Cascade Lake Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA22 01 Cascade Lake, SAP-certified Cascade Lake Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA23 01 Cascade Lake, SAP-certified Cascade Lake Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SNG01 02 Skylake, Cascade Lake, SAP-certified Cascade Lake Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SYD01 01-02 Skylake, Cascade Lake, SAP-certified Skylake, Cascade Lake, SAP-certified Cascade Lake","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_planning"},{"document_id":"ibmcld_14823-7-1880","score":19.4609897702,"text":"\nPlanning for VMware vSphere \n\nReview the following requirements before you order a VMware vSphere\u00ae instance. Plan your VMware vSphere based on the IBM Cloud\u00ae data center location and your workload capacity requirements.\n\nYou are responsible for setting up the environment, installing, and configuring various VMware\u00ae components after the VMware ESXi\u2122 servers are deployed. The following examples are VMware components: VMware vCenter Server\u00ae, VMware NSX\u00ae, and VMware vSAN\u2122.\n\n\n\n Account requirements \n\nThe account that you are using must meet certain requirements. For more information, see [Signing up for required accounts](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-signing_required_accounts).\n\n\n\n\n\n IBM Cloud data center availability \n\nThe vSphere deployment has strict requirements on the physical infrastructure. Therefore, you can deploy clusters only in IBM Cloud data centers that meet the requirements. The following IBM Cloud data centers are available for vSphere deployment.\n\nCascade Lake bare metal servers are available in\n\nmultizone regionIBM Cloud data centers. For more information, see [Multizone region (MZR) overview](https:\/\/cloud.ibm.com\/docs\/loadbalancer-service?topic=loadbalancer-service-multi-zone-region-mzr-overview).\n\nIf you select a vSAN component, the location list is filtered by SSD (Solid-State Disk) availability.\n\nAsia-Pacific\n\nEurope\n\nNA East\n\n\n\nTable 1. Available IBM Cloud data centers for VMware vSphere instances\n\n Geography Data center Pod Server options<br><br>[1] \n\n Asia-Pacific CHE01 01 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA21 01 Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA22 01 Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA23 01 Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SNG01 02 Skylake, Cascade Lake, SAP-certified Cascade Lake","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_planning"},{"document_id":"ibmcld_14823-1485-2621","score":19.3769311941,"text":"\nGeography Data center Pod Server options<br><br>[1] \n\n Asia-Pacific CHE01 01 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA21 01 Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA22 01 Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA23 01 Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SNG01 02 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SYD01 01-02 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SYD04 01 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SYD05 01 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific TOK02 01-02 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific TOK04 01 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific TOK05 01 Skylake, Cascade Lake, SAP-certified Cascade Lake \n\n\n\n\n\n\n\n Related links \n\n\n\n* [Ordering VMware vSphere instances](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_orderinginstances-req)\n* [Adding ESXi servers to VMware vSphere instances](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_addingservers)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_planning"},{"document_id":"ibmcld_13162-12751-14416","score":19.26679047,"text":"\nCongratulations, you have built a data lake using Object Storage. Below are additional suggestions to enhance your data lake.\n\n\n\n* Experiment with additional datasets using Data Engine\n* Stream data from multiple sources into your data lake by completing [Big data logs with streaming analytics and SQL](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-big-data-log-analyticsbig-data-log-analytics)\n* Build a web app with a dashboard for line of business users utilizing [IBM Cognos Dashboard Embedded](https:\/\/cloud.ibm.com\/docs\/cognos-dashboard-embedded?topic=cognos-dashboard-embedded-gettingstartedtutorial).\n\n\n\n\n\n\n\n Step 8: Remove resources \n\nRun the following commands to remove services, applications and keys you created and used.\n\nibmcloud resource service-instance-delete data-lake-sql\n\nibmcloud resource service-instance-delete data-lake-studio\n\nibmcloud iam api-key-delete data-lake-cos-key\n\nibmcloud resource service-instance-delete data-lake-cos\n\nIf the deletion of data-lake-cos is not successful delete it from the storage section of the [Resource List](https:\/\/cloud.ibm.com\/resources).\n\nDepending on the resource it might not be deleted immediately, but retained (by default for 7 days). You can reclaim the resource by deleting it permanently or restore it within the retention period. See this document on how to [use resource reclamation](https:\/\/cloud.ibm.com\/docs\/account?topic=account-resource-reclamation).\n\n\n\n\n\n Related content \n\n\n\n* [ibmcloudsql](https:\/\/github.com\/IBM-Cloud\/sql-query-clients\/tree\/master\/Python)\n* [Jupyter Notebooks](https:\/\/jupyter.org\/)\n* [Folium](https:\/\/python-visualization.github.io\/folium\/)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake"},{"document_id":"ibmcld_13162-11690-13171","score":18.3693732748,"text":"\nHeatMap(locations, radius=15).add_to(m)\nm\n\nZoom\n\n![Notebook](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution29\/notebook-mapbox.png)\n\nNotebook\n3. Click File > Save to save your Notebook to Object Storage.\n\n\n\n\n\n\n\n Step 6: Share your dataset with the organization \n\nNot every user of the data lake is a data scientist. You can allow non-technical users to gain insight from the data lake. Tools with analytic capabilities or for visualization can import data stored in CSV files. Application developers can make use of [IBM Cognos Dashboard Embedded](https:\/\/cloud.ibm.com\/docs\/cognos-dashboard-embedded?topic=cognos-dashboard-embedded-gettingstartedtutorial) to let users build and use feature-rich dashboards. Such a dashboard for the traffic data is shown below.\n\nZoom\n\n![Dashboard Chart](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution29\/dashboard-chart.png)\n\nDashboard Chart\n\n\n\n\n\n Step 7: Expand the tutorial \n\nCongratulations, you have built a data lake using Object Storage. Below are additional suggestions to enhance your data lake.\n\n\n\n* Experiment with additional datasets using Data Engine\n* Stream data from multiple sources into your data lake by completing [Big data logs with streaming analytics and SQL](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-big-data-log-analyticsbig-data-log-analytics)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake"},{"document_id":"ibmcld_16729-11586-13439","score":18.3039087654,"text":"\n* 15 minutes\n* 2023-01-31\n\n\n\n[Build a data lake using object storage](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\nObject Storage Data Engine\n\n\n\n* 1 hour\n* 2023-06-14\n\n\n\nBlockchain[Setting up multiregion High Availability (HA) deployments for the ordering service](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-hadr-mr-os)Setting up multiregion High Availability (HA) deployments for the ordering service\n\nIn this tutorial, you learn how to set up a Raft ordering service with five ordering nodes that span multiple regions for maximum high availability.\n\nIBM Blockchain Platform\n\n\n\n* 2023-02-17\n\n\n\n[Using certificates from an external Certificate Authority](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-tutorial-extca)Using certificates from an external Certificate Authority\n\nIn this tutorial, you learn how to use certificates that were generated by an external Certificate Authority (CA) with your IBM\u00ae Blockchain Platform network. After you gather the required certificates for a peer or ordering node, you build a Membership Service Provider (MSP) definition that is used by your blockchain components.\n\nIBM Blockchain Platform\n\n\n\n* 30 minutes\n* 2023-02-17","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_03538-14399-15690","score":18.17468069,"text":"\nYour account settings would look like:\n\nibmcloud atracker setting get\nOK\nIBM Cloud Activity Tracker settings\nMetadata region primary: us-east\nDefault targets: []\nPermitted target regions: [us-east]\nPrivate api endpoint only: false\nAPI version: 2\n\nYour target would look like:\n\nibmcloud atracker target ls\nListing IBM Cloud Activity Tracker targets for all regions...\nOK\nName ID Region Type Service to Service Enabled CreatedAt UpdatedAt\ntarget-logdna <LOGDNA TARGET ID 1> us-east logdna - 2022-05-16T17:16:05.234Z 2022-05-16T17:16:05.234Z\n\n\n\n\n\n Data Lake scenario \n\nYou can choose any of the following options to send auditing events to a data lake:\n\n\n\n* Configure your account to route auditing events to Activity Tracker Event Routing hosted event search instances. Stream the events to Event Streams, and then, send them to a data lake. You can filter the data to be streamed to the data lake.\n\nSimplify the Activity Tracker Event Routing hosted event search configuration so only 1 instance needs to be configured to feed auditing events to Event Streams.\n* Configure Activity Tracker Event Routing in your account to route auditing events directly to an IBM Cloud Object Storage data lake.\n\nUse this option for Financial Services Cloud workloads where end-to-end compliance is required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/atracker?topic=atracker-scenarios&interface=cli"},{"document_id":"ibmcld_03537-14329-15620","score":18.17468069,"text":"\nYour account settings would look like:\n\nibmcloud atracker setting get\nOK\nIBM Cloud Activity Tracker settings\nMetadata region primary: us-east\nDefault targets: []\nPermitted target regions: [us-east]\nPrivate api endpoint only: false\nAPI version: 2\n\nYour target would look like:\n\nibmcloud atracker target ls\nListing IBM Cloud Activity Tracker targets for all regions...\nOK\nName ID Region Type Service to Service Enabled CreatedAt UpdatedAt\ntarget-logdna <LOGDNA TARGET ID 1> us-east logdna - 2022-05-16T17:16:05.234Z 2022-05-16T17:16:05.234Z\n\n\n\n\n\n Data Lake scenario \n\nYou can choose any of the following options to send auditing events to a data lake:\n\n\n\n* Configure your account to route auditing events to Activity Tracker Event Routing hosted event search instances. Stream the events to Event Streams, and then, send them to a data lake. You can filter the data to be streamed to the data lake.\n\nSimplify the Activity Tracker Event Routing hosted event search configuration so only 1 instance needs to be configured to feed auditing events to Event Streams.\n* Configure Activity Tracker Event Routing in your account to route auditing events directly to an IBM Cloud Object Storage data lake.\n\nUse this option for Financial Services Cloud workloads where end-to-end compliance is required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/atracker?topic=atracker-scenarios"},{"document_id":"ibmcld_13466-0-409","score":17.9926423103,"text":"\n\n\n\n\n\n\n  Data transport automation to Db2 on Cloud \n\nIBM Cloud\u00ae Data Engine supports automating the transport and transformation of data from IBM Cloud\u00ae Object Storage to IBM\u00ae Db2\u00ae on Cloud. Read how you can [automate serverless data pipelines for your data warehouse or data lakes](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/automate-serverless-data-pipelines-for-your-data-warehouse-or-data-lakes).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-db2"},{"document_id":"ibmcld_16728-5097-7108","score":17.9888731813,"text":"\n[solution icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/magic-wand.svg) [Best practices for organizing users, teams, applications](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-users-teams-applications)Best practices for organizing users, teams, applications Solution tutorial\n\nThis tutorial gives an overview of the concepts available in IBM Cloud for identity and access management and how they can be implemented to support the multiple development stages of an application.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Bring Your Own IP Address](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-byoip)Bring Your Own IP Address Solution tutorial\n\nThis tutorial presents a brief overview of BYOIP implementation patterns that can be used with IBM Cloud and a decision tree for identifying the appropriate pattern when realizing the secure enclosure as described in the Isolate workloads with a secure private network tutorial. Setup may require additional input from your onsite network team, IBM Cloud technical support or IBM Services.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Build a data lake using object storage](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage Solution tutorial\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=solutions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04326-10875-12516","score":25.6751837688,"text":"\nThe json file content example: \"[{\"column_name\":\"COL1\",\"column_type\":\"VARCHAR\"}]\"\n\n\n\n\n\n\n\n ibmcloud watson-query virtualized-table-delete \n\nRemove specified virtualized table. You must specify the schema and table name.\n\nibmcloud watson-query virtualized-table-delete --virtualized-schema VIRTUALIZED-SCHEMA --virtualized-name VIRTUALIZED-NAME\n\n\n\n Command options \n\n--virtualized-schema (string)\n: The schema of virtualized table to be deleted. Required.\n\n--virtualized-name (string)\n: The name of virtualized table to be deleted. Required.\n\n\n\n\n\n Examples \n\nDelete virtualized table\n\nibmcloud watson-query virtualized-table-delete --virtualized-schema DV_IBMID_270001PD8Q --virtualized-name TABLE1\n\n\n\n\n\n\n\n\n\n Primary catalog \n\nManage the primary WKC catalog information in watson query console.\n\n\n\n ibmcloud watson-query primary-catalog \n\nGet primary catalog ID from the table.\n\nibmcloud watson-query primary-catalog\n\n\n\n Examples \n\nGet primary catalog ID from the table DVSYS.INSTANCE_INFO\n\nibmcloud watson-query primary-catalog\n\n\n\n\n\n\n\n ibmcloud watson-query primary-catalog-set \n\nInsert primary catalog ID into table DVSYS.INSTANCE_INFO.\n\nibmcloud watson-query primary-catalog-set --guid GUID\n\n\n\n Command options \n\n--guid (string)\n: Primary catalog ID. Required.\n\n\n\n\n\n Examples \n\nInsert primary catalog ID into table DVSYS.INSTANCE_INFO\n\nibmcloud watson-query primary-catalog-set --guid d77fc432-9b1a-4938-a2a5-9f37e08041f6\n\n\n\n\n\n\n\n ibmcloud watson-query primary-catalog-delete \n\nRemove the setting of the primary catalog for enforced publication.\n\nibmcloud watson-query primary-catalog-delete --guid GUID\n\n\n\n Command options \n\n--guid (string)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-CLI-name"},{"document_id":"ibmcld_16567-10878-12519","score":25.6751837688,"text":"\nThe json file content example: \"[{\"column_name\":\"COL1\",\"column_type\":\"VARCHAR\"}]\"\n\n\n\n\n\n\n\n ibmcloud watson-query virtualized-table-delete \n\nRemove specified virtualized table. You must specify the schema and table name.\n\nibmcloud watson-query virtualized-table-delete --virtualized-schema VIRTUALIZED-SCHEMA --virtualized-name VIRTUALIZED-NAME\n\n\n\n Command options \n\n--virtualized-schema (string)\n: The schema of virtualized table to be deleted. Required.\n\n--virtualized-name (string)\n: The name of virtualized table to be deleted. Required.\n\n\n\n\n\n Examples \n\nDelete virtualized table\n\nibmcloud watson-query virtualized-table-delete --virtualized-schema DV_IBMID_270001PD8Q --virtualized-name TABLE1\n\n\n\n\n\n\n\n\n\n Primary catalog \n\nManage the primary WKC catalog information in watson query console.\n\n\n\n ibmcloud watson-query primary-catalog \n\nGet primary catalog ID from the table.\n\nibmcloud watson-query primary-catalog\n\n\n\n Examples \n\nGet primary catalog ID from the table DVSYS.INSTANCE_INFO\n\nibmcloud watson-query primary-catalog\n\n\n\n\n\n\n\n ibmcloud watson-query primary-catalog-set \n\nInsert primary catalog ID into table DVSYS.INSTANCE_INFO.\n\nibmcloud watson-query primary-catalog-set --guid GUID\n\n\n\n Command options \n\n--guid (string)\n: Primary catalog ID. Required.\n\n\n\n\n\n Examples \n\nInsert primary catalog ID into table DVSYS.INSTANCE_INFO\n\nibmcloud watson-query primary-catalog-set --guid d77fc432-9b1a-4938-a2a5-9f37e08041f6\n\n\n\n\n\n\n\n ibmcloud watson-query primary-catalog-delete \n\nRemove the setting of the primary catalog for enforced publication.\n\nibmcloud watson-query primary-catalog-delete --guid GUID\n\n\n\n Command options \n\n--guid (string)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugin"},{"document_id":"ibmcld_16582-10722-12330","score":24.7999336959,"text":"\nibmcloud watson-query virtualized-table-create --source-table-name table1 --source-table-def-file source_tabel_def.json --virtualized-schema DV_IBMID_270001PD8Q --sources CONN1:TABLE1 --virtualized-table-name TABLE1 --virtualized-table-def-file virtualized_table_def.json. The json file content example: \"[{\"column_name\":\"COL1\",\"column_type\":\"VARCHAR\"}]\"\n\n\n\n\n\n\n\n ibmcloud watson-query virtualized-table-delete \n\nRemove specified virtualized table. You must specify the schema and table name.\n\nibmcloud watson-query virtualized-table-delete --virtualized-schema VIRTUALIZED-SCHEMA --virtualized-name VIRTUALIZED-NAME\n\n\n\n Command options \n\n--virtualized-schema (string)\n: The schema of virtualized table to be deleted. Required.\n\n--virtualized-name (string)\n: The name of virtualized table to be deleted. Required.\n\n\n\n\n\n Examples \n\nDelete virtualized table\n\nibmcloud watson-query virtualized-table-delete --virtualized-schema DV_IBMID_270001PD8Q --virtualized-name TABLE1\n\n\n\n\n\n\n\n\n\n Primary catalog \n\nManage the primary WKC catalog information in watson query console.\n\n\n\n ibmcloud watson-query primary-catalog \n\nGet primary catalog ID from the table.\n\nibmcloud watson-query primary-catalog\n\n\n\n Examples \n\nGet primary catalog ID from the table DVSYS.INSTANCE_INFO\n\nibmcloud watson-query primary-catalog\n\n\n\n\n\n\n\n ibmcloud watson-query primary-catalog-set \n\nInsert primary catalog ID into table DVSYS.INSTANCE_INFO.\n\nibmcloud watson-query primary-catalog-set --guid GUID\n\n\n\n Command options \n\n--guid (string)\n: Primary catalog ID. Required.\n\n\n\n\n\n Examples \n\nInsert primary catalog ID into table DVSYS.INSTANCE_INFO","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugin?topic=watson-query-cli-plugin-CLI-name"},{"document_id":"ibmcld_16567-12215-13777","score":24.3494709347,"text":"\nibmcloud watson-query primary-catalog-set --guid d77fc432-9b1a-4938-a2a5-9f37e08041f6\n\n\n\n\n\n\n\n ibmcloud watson-query primary-catalog-delete \n\nRemove the setting of the primary catalog for enforced publication.\n\nibmcloud watson-query primary-catalog-delete --guid GUID\n\n\n\n Command options \n\n--guid (string)\n: The watson query user name, if the value is PUBLIC, it means revoke access privilege from all watson query users. Required.\n\n\n\n\n\n\n\n\n\n Publish objects \n\nPublish virtualized table to WKC.\n\n\n\n ibmcloud watson-query virtualized-table-publish \n\nPublish virtualized tables to WKC.\n\nibmcloud watson-query virtualized-table-publish --catalog-id CATALOG-ID --allow-duplicates ALLOW-DUPLICATES --assets ASSETS\n\n\n\n Command options \n\n--catalog-id (string)\n: Catalog ID. Required.\n\n--allow-duplicates (bool)\n: Whether duplicated asset allowd. Required.\n\n--assets ([CatalogPublishParametersAssetsItem[]](https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugincli-catalog-publish-parameters-assets-item-example-schema))\n: Asset description. Example: \"[{\"schema\": \"db2inst1\",\"table\": \"employee\"}]\". Required.\n\n\n\n\n\n Examples \n\nPublish virtualized tables to WKC\n\nibmcloud watson-query virtualized-table-publish --catalog-id 12c60f7e-c366-4cda-ba3a-bfbb577a5f56 --allow-duplicates true --virtualized-schema DV_IBMID_6610020D12 --virtualized-table EMPLOYEE\n\n\n\n\n\n\n\n\n\n Schema examples \n\nThe following schema examples represent the data that you need to specify for a command option. These examples model the data structure and include placeholder values for the expected value type.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugin"},{"document_id":"ibmcld_04326-12212-13773","score":24.3280537502,"text":"\nibmcloud watson-query primary-catalog-set --guid d77fc432-9b1a-4938-a2a5-9f37e08041f6\n\n\n\n\n\n\n\n ibmcloud watson-query primary-catalog-delete \n\nRemove the setting of the primary catalog for enforced publication.\n\nibmcloud watson-query primary-catalog-delete --guid GUID\n\n\n\n Command options \n\n--guid (string)\n: The watson query user name, if the value is PUBLIC, it means revoke access privilege from all watson query users. Required.\n\n\n\n\n\n\n\n\n\n Publish objects \n\nPublish virtualized table to WKC.\n\n\n\n ibmcloud watson-query virtualized-table-publish \n\nPublish virtualized tables to WKC.\n\nibmcloud watson-query virtualized-table-publish --catalog-id CATALOG-ID --allow-duplicates ALLOW-DUPLICATES --assets ASSETS\n\n\n\n Command options \n\n--catalog-id (string)\n: Catalog ID. Required.\n\n--allow-duplicates (bool)\n: Whether duplicated asset allowd. Required.\n\n--assets ([CatalogPublishParametersAssetsItem[]](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-CLI-namecli-catalog-publish-parameters-assets-item-example-schema))\n: Asset description. Example: \"[{\"schema\": \"db2inst1\",\"table\": \"employee\"}]\". Required.\n\n\n\n\n\n Examples \n\nPublish virtualized tables to WKC\n\nibmcloud watson-query virtualized-table-publish --catalog-id 12c60f7e-c366-4cda-ba3a-bfbb577a5f56 --allow-duplicates true --virtualized-schema DV_IBMID_6610020D12 --virtualized-table EMPLOYEE\n\n\n\n\n\n\n\n\n\n Schema examples \n\nThe following schema examples represent the data that you need to specify for a command option. These examples model the data structure and include placeholder values for the expected value type.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-CLI-name"},{"document_id":"ibmcld_16582-11984-13516","score":22.6339074515,"text":"\nibmcloud watson-query primary-catalog\n\n\n\n\n\n\n\n ibmcloud watson-query primary-catalog-set \n\nInsert primary catalog ID into table DVSYS.INSTANCE_INFO.\n\nibmcloud watson-query primary-catalog-set --guid GUID\n\n\n\n Command options \n\n--guid (string)\n: Primary catalog ID. Required.\n\n\n\n\n\n Examples \n\nInsert primary catalog ID into table DVSYS.INSTANCE_INFO\n\nibmcloud watson-query primary-catalog-set --guid d77fc432-9b1a-4938-a2a5-9f37e08041f6\n\n\n\n\n\n\n\n ibmcloud watson-query primary-catalog-delete \n\nRemove the setting of the primary catalog for enforced publication.\n\nibmcloud watson-query primary-catalog-delete --guid GUID\n\n\n\n Command options \n\n--guid (string)\n: The watson query user name, if the value is PUBLIC, it means revoke access privilege from all watson query users. Required.\n\n\n\n\n\n\n\n\n\n Publish objects \n\nPublish virtualized table to WKC.\n\n\n\n ibmcloud watson-query virtualized-table-publish \n\nPublish virtualized tables to WKC.\n\nibmcloud watson-query virtualized-table-publish --catalog-id CATALOG-ID --allow-duplicates ALLOW-DUPLICATES --assets ASSETS\n\n\n\n Command options \n\n--catalog-id (string)\n: Catalog ID. Required.\n\n--allow-duplicates (bool)\n: Whether duplicated asset allowd. Required.\n\n--assets ([CatalogPublishParametersAssetsItem[]](https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugin?topic=watson-query-cli-plugin-CLI-namecli-catalog-publish-parameters-assets-item-example-schema))\n: Asset description. Example: \"[{\"schema\": \"db2inst1\",\"table\": \"employee\"}]\". Required.\n\n\n\n\n\n Examples \n\nPublish virtualized tables to WKC","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugin?topic=watson-query-cli-plugin-CLI-name"},{"document_id":"ibmcld_06417-8695-9846","score":22.5984746172,"text":"\nMigration logs have been saved to \/root\/.enterprisedb\/migration-toolkit\/logs\n\n Migration Summary \nTables: 12 out of 12\n\nTotal objects: 12\nSuccessful count: 12\nFailed count: 0\nInvalid count: 0\n\n\nShow more\n\n\n\n\n\n\n\n\n\n Oracle to Databases for EnterpriseDB Migration by using MTK only \n\nYou can run schema extraction, schema migration, and data migration by using Migration Toolkit (MTK) only. To do that you need to:\n\n\n\n1. Install and setup MTK locally following the steps noted under the heading: [Install EnterpriseDB Migration toolkit](https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=databases-for-enterprisedb-oracle-migratinginstall-enterprisedb-migrationtoolkit)\n2. Follow the MTK command options for Import Options and Schema Creation to extract and migrate Oracle schema and data [here](https:\/\/www.enterprisedb.com\/edb-docs\/d\/edb-postgres-migration-toolkit\/user-guides\/user-guide\/53.0.2\/mtk_command_options.html)\n3. MTK also supports offline migration for both schema and data [here](https:\/\/www.enterprisedb.com\/edb-docs\/d\/edb-postgres-migration-toolkit\/user-guides\/user-guide\/53.0.2\/mtk_command_options.htmloffline-migration-options)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=databases-for-enterprisedb-oracle-migrating"},{"document_id":"ibmcld_06417-7547-9082","score":20.9282691238,"text":"\n[More about toolkit.properties](https:\/\/www.enterprisedb.com\/edb-docs\/d\/edb-postgres-migration-toolkit\/user-guides\/user-guide\/53.0.2\/building_toolkit.properties_file.html)\n2. Following the setup steps, the toolkit.properties file now resembles:\n\nSRC_DB_URL=jdbc:oracle:thin:@localhost:1521:ORCL\nSRC_DB_USER=ot\nSRC_DB_PASSWORD=password\n\nTARGET_DB_URL=jdbc:edb:\/\/$TARGET_HOST:TARGET_PORT\/ot_migration\nTARGET_DB_USER=enterprisedb\nTARGET_DB_PASSWORD=password\n3. Start MTK to begin the data migration process from OT Oracle schema to ot EnterpriseDB schema under ot_migration database. For more about MTK args, see [Migration Tookit](https:\/\/www.enterprisedb.com\/edb-docs\/d\/edb-postgres-migration-toolkit\/user-guides\/user-guide\/53.0.2\/mtk_command_options.html)\n\n\/usr\/edb\/migrationtoolkit\/bin\/runMTK.sh -dataOnly -targetSchema ot -truncLoad OT\n4. A successful migration output sample:\n\nEnabling FK constraints & triggers on ot.warehouses...\nEnabling indexes on ot.warehouses after data load...\nData Load Summary: Total Time (sec): 8.764 Total Rows: 2981 Total Size(MB): 0.105\n\nSchema OT imported successfully.\n\nMigration process completed successfully.\n\nMigration logs have been saved to \/root\/.enterprisedb\/migration-toolkit\/logs\n\n Migration Summary \nTables: 12 out of 12\n\nTotal objects: 12\nSuccessful count: 12\nFailed count: 0\nInvalid count: 0\n\n\nShow more\n\n\n\n\n\n\n\n\n\n Oracle to Databases for EnterpriseDB Migration by using MTK only \n\nYou can run schema extraction, schema migration, and data migration by using Migration Toolkit (MTK) only.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=databases-for-enterprisedb-oracle-migrating"},{"document_id":"ibmcld_16648-7285-8490","score":20.8203104958,"text":"\nResource ibm_resource The resource being measured by the service - typically an indentifying name or GUID \n Resource Type ibm_resource_type The type of the resource being measured by the service \n Resource group ibm_resource_group_name The resource group where the service instance was created \n Scope ibm_scope The scope is the account, organization, or space GUID associated with this metric \n Service name ibm_service_name Name of the service generating this metric \n\n\n\n\n\n\n\n Additional attributes \n\nThe following attributes are available for segmenting one or more attributes as described in the reference above. See the individual metrics for segmentation options.\n\n\n\nTable 14: Additional attributes\n\n Attribute Attribute Name Attribute Description \n\n Catalog in the Presto Server ibm_catalog Catalog in the Presto Server \n Catalog name ibm_catalog_name Catalog name \n Resource role ibm_resource_role Role in the resource group \n Role associated with Catalog ibm_catalog_role Role associated with Catalog \n Schema in the Presto Server ibm_schema Schema in the Presto Server \n Service instance ibm_service_instance The service instance segment identifies the instance that the metric is associated with","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-monitor_wxd"},{"document_id":"ibmcld_16627-0-1141","score":18.2740661241,"text":"\n\n\n\n\n\n\n  About Data manager \n\nThe Data manager page in IBM\u00ae watsonx.data is the entry point to browse the schemas and tables by engine. You can select an engine to view the associated catalogs, schemas, and tables.\n\nFrom the Data manager page, you can create schemas and tables by using the Create option that is provided in the left window. You can also select a catalog or schema, click the overflow menu, and use the corresponding Create option to create a schema or table. Create table from file option in the overflow menu of schema is also used to ingest a data file into watsonx.data. Similarly, schemas and tables can be dropped from the catalogs.\n\nWait for a few minutes to view the changes after a schema or table is dropped.\n\nAdding, renaming, or dropping a column are the other tasks that can be performed in the Data manager page.\n\nYou can browse the Table schema and upto 25 rows of Data sample for some tables. You can view the Time travel snapshots and use the Rollback feature to rollback to a given snapshot for Iceberg tables.\n\nPresto cannot roll back to the snapshots that are not ancestors of the current snapshot.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-exp_objects"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00512-8404-10414","score":20.7197377562,"text":"\nThe timestamp could also be an epoch timestamp.\n\nThis approach allows the data for each device to be queried efficiently by using partitioned indexes. However, global indexes might need to be used to create views over multiple devices, for example, all devices on a specific piece of infrastructure.\n\nFor illustrative purposes, let's make the scenario a bit more complicated. Assume that the application mostly needs to read all sensor data for a specific piece of infrastructure rather than for individual devices.\n\nIn this application, you query by infrastructure item to be most efficient, so partitioning the data by piece of infrastructure makes a lot more sense than by ID. This practice would allow all the devices for a specific piece of infrastructure to be efficiently queried as a group.\n\nFor the rare queries by device, you use two approaches:\n\n\n\n1. Build a global index that is keyed by device and query it. This approach is more effective if queries to individual devices are rare and not repeated.\n2. Build a global index-mapping device to infrastructure, then issue partition queries to the infrastructure partition. This approach makes sense if repeated queries to specific devices are used as the mapping can be cached. This approach is used for this application.\n\n\n\nLet's look at how this approach works out. Let's look at four queries:\n\n\n\n1. Readings for all time for a piece of infrastructure.\n2. Readings for today for a piece of infrastructure.\n3. Readings for all time for a specific device.\n4. Readings for today for a specific device.\n\n\n\n\n\n Creating the database \n\nTo create a partitioned database, pass true as the partitioned argument to the database creation request:\n\nAll tutorials in this section will use readings as the example database.\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl -X PUT \"$SERVICE_URL\/readings?partitioned=true\"\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.Ok;\nimport com.ibm.cloud.cloudant.v1.model.PutDatabaseOptions;","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_00640-7-1376","score":19.8529971013,"text":"\nSending multiple queries to a database \n\nNow, the following instructions describe how to send multiple queries to a database by using _all_docs and _view endpoints.\n\n\n\n Sending multiple queries to a database by using _all_docs \n\nTo send multiple queries to a specific database, send a POST request to https:\/\/$ACCOUNT.cloudant.com\/$DATABASE\/_all_docs\/queries.\n\nSee the following example that uses HTTP to send multiple queries to a database:\n\nPOST \/$DATABASE\/_all_docs\/queries HTTP\/1.1\n\nSee the following example to multi-query the list of all documents in a database:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -H \"Authorization: Bearer $API_BEARER_TOKEN\" -X POST \"$SERVICE_URL\/products\/_all_docs\/queries\" -H \"Content-Type: application\/json\" --data '{\n\"queries\": [\n{\n\"keys\":\n\"small-appliances:1000042\",\n\"small-appliances:1000043\"\n]\n},\n{\n\"limit\": 3,\n\"skip\": 2\n}\n]\n}'\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsQuery;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsQueriesResult;\nimport com.ibm.cloud.cloudant.v1.model.PostAllDocsQueriesOptions;\n\nimport java.util.Arrays;\n\nCloudant service = Cloudant.newInstance();\n\nAllDocsQuery query1 = new AllDocsQuery.Builder()\n.keys(Arrays.asList(\"small-appliances:1000042\",\n\"small-appliances:1000043\"))\n.build();\n\nAllDocsQuery query2 = new AllDocsQuery.Builder()\n.limit(3)\n.skip(2)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-send-multiple-queries-to-a-database"},{"document_id":"ibmcld_00539-7-1755","score":19.5242901413,"text":"\nUsing IBM Cloudant Query FAQ \n\n[IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Query](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query) is an API for querying slices of data based on the values of a database's document attributes. It is a flexible API that must be used carefully to ensure that database performance can be maintained as the data size grows over time.\n\n\n\n How do I use IBM Cloudant Query? \n\nIBM Cloudant Query is accessed through the [POST \/{db}\/_find](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostfind) API endpoint where the JSON specification of the query is passed in the HTTP POST body. For example, this query finds up to 10 documents where the firstname is \"Charles\" and the surname is \"Dickens\":\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"limit\": 10\n}\n\nFor more information, see [Selector Syntax](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-queryselector-syntax).\n\n\n\n\n\n How do I create an index to support an IBM Cloudant Query? \n\nWithout a suitable secondary index, IBM Cloudant Query scans each document in the database in turn until it has enough matches to satisfy the query. The larger the data set and the more documents it has to scan to find matching documents, the slower the response time. For faster performance, an IBM Cloudant Query _find must be backed by a suitable secondary index. A secondary index is a pre-calculated data structure that allows IBM Cloudant to quickly jump to the slice of data it needs without scanning irrelevant documents. For the surname fields, we call the [POST \/{db}\/_index](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostindex) endpoint to pass the JSON index definition as the HTTP POST body:\n\n{\n\"index\": {\n\"fields\": [\"firstname\", \"surname\"]\n},\n\"ddoc\": \"jsonindexes\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-using-cloudant-query"},{"document_id":"ibmcld_00640-5039-6415","score":19.3271992524,"text":"\n\"Aduki and orange casserole - microwave\"\n]\n},\n{\n\"id\" : \"Aioli-garlicmayonnaise\",\n\"key\" : \"Aioli - garlic mayonnaise\",\n\"value\" :\nnull,\n\"Aioli - garlic mayonnaise\"\n]\n},\n{\n\"id\" : \"Alabamapeanutchicken\",\n\"key\" : \"Alabama peanut chicken\",\n\"value\" :\nnull,\n\"Alabama peanut chicken\"\n]\n}\n],\n\"total_rows\" : 2667\n}\n]\n}\nShow more\n\nMultiple queries are also supported in \/$DATABASE\/_design_docs\/queries, which is similar to \/$DATABASE\/_all_docs\/queries.\n\n\n\n\n\n Sending multiple view queries to a database by using _view \n\nTo send multiple view queries to a specific database, send a POST request to https:\/\/$ACCOUNT.cloudant.com\/$DATABASE\/_design\/$DDOC\/_view\/$VIEW\/queries.\n\nSee the following example that uses HTTP to send multiple queries to a database:\n\nPOST \/_view\/$VIEW\/queries HTTP\/1.1\n\nSee the following example that runs multiple specified view queries against the view function from the specified design document:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -H \"Authorization: Bearer $API_BEARER_TOKEN\" -X POST \"$SERVICE_URL\/users\/_design\/allusers\/_view\/getVerifiedEmails\/queries\" -H \"Content-Type: application\/json\" --data '{ \"queries\": [ { \"include_docs\": true, \"limit\": 5 },{ \"descending\": true, \"skip\": 1 } ]}'\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.PostViewQueriesOptions;\nimport com.ibm.cloud.cloudant.v1.model.ViewQueriesResult;","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-send-multiple-queries-to-a-database"},{"document_id":"ibmcld_00512-19432-20915","score":19.192714142,"text":"\nfmt.Println(string(b))\n\nThe previous Go example requires the following import block:\n\nimport (\n\"encoding\/json\"\n\"fmt\"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n\"github.com\/IBM\/go-sdk-core\/v5\/core\"\n)\n\nAll Go examples require the service object to be initialized. For more information, see the API documentation's [Authentication section](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=goauthentication-with-external-configuration) for examples.\n\n\n\n\n\n\n\n\n\n Making queries \n\nOverall, you want to make four queries:\n\n\n\n1. Readings for all time for a piece of infrastructure.\n2. Readings for today for a piece of infrastructure.\n3. Readings for all time for a specific device.\n4. Readings for today for a specific device.\n\n\n\n\n\n Finding all readings for a piece of infrastructure \n\nThese partitions are infrastructure-based, so you can use _all_docs for a partition. For example, query all readings for the bridge-9876 infrastructure piece by using the following command.\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl -X POST \"$SERVICE_URL\/readings\/_partition\/bridge-9876\/_all_docs\" -H 'Content-Type:\napplication\/json' --data '{\"include_docs\": true}'\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsResult;\nimport com.ibm.cloud.cloudant.v1.model.PostPartitionAllDocsOptions;\nCloudant service = Cloudant.newInstance();\n\nPostPartitionAllDocsOptions allDocsOptions =\nnew PostPartitionAllDocsOptions.Builder()\n.db(\"readings\")\n.partitionKey(\"bridge-9876\")","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_00558-7394-9190","score":18.9517046113,"text":"\nTo create an IBM Cloudant Dedicated Hardware plan instance and provision a Standard plan instance on it, follow the [Creating and leveraging an IBM Cloudant Dedicated Hardware plan instance on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-and-leveraging-an-ibm-cloudant-dedicated-hardware-plan-instance-on-ibm-cloudcreating-and-leveraging-an-ibm-cloudant-dedicated-hardware-plan-instance-on-ibm-cloud) tutorial.\n\nThe Dedicated Hardware plan isn't available to IBM Cloud Dedicated customers. The Dedicated Hardware plan is only available to IBM Cloud customers.\n\n\n\n\n\n\n\n Request classes \n\nThroughput provision is identified and measured as one of the following types of request classes:\n\n\n\n1. Reads (formerly called lookups) which are described in this list.\n\n\n\n1. A read of a specific document, based on the _id of the document.\n2. A partitioned query, which is a request that is made to an IBM Cloudant query endpoint within the _partition namespace in the request path, including the following types:\n\n\n\n* Primary Index ([_all_docs](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostalldocs))\n* MapReduce View ([_view](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-viewsusing-views))\n* Search Index ([_search](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-searchqueries))\n* IBM Cloudant Query ([_find](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostfind))\n\n\n\nThe number of read operations that are used by a partitioned query request varies depending on the results returned.\n\n\n\n2. Writes, which are creation, modification, or deletion of individual documents.\n3. Global Queries to global indexes (formerly called queries), which are requests that are made to an IBM Cloudant query endpoint not within the _partition namespace, including the following types:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-7457-9253","score":18.9517046113,"text":"\nTo create an IBM Cloudant Dedicated Hardware plan instance and provision a Standard plan instance on it, follow the [Creating and leveraging an IBM Cloudant Dedicated Hardware plan instance on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-and-leveraging-an-ibm-cloudant-dedicated-hardware-plan-instance-on-ibm-cloudcreating-and-leveraging-an-ibm-cloudant-dedicated-hardware-plan-instance-on-ibm-cloud) tutorial.\n\nThe Dedicated Hardware plan isn't available to IBM Cloud Dedicated customers. The Dedicated Hardware plan is only available to IBM Cloud customers.\n\n\n\n\n\n\n\n Request classes \n\nThroughput provision is identified and measured as one of the following types of request classes:\n\n\n\n1. Reads (formerly called lookups) which are described in this list.\n\n\n\n1. A read of a specific document, based on the _id of the document.\n2. A partitioned query, which is a request that is made to an IBM Cloudant query endpoint within the _partition namespace in the request path, including the following types:\n\n\n\n* Primary Index ([_all_docs](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostalldocs))\n* MapReduce View ([_view](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-viewsusing-views))\n* Search Index ([_search](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-searchqueries))\n* IBM Cloudant Query ([_find](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostfind))\n\n\n\nThe number of read operations that are used by a partitioned query request varies depending on the results returned.\n\n\n\n2. Writes, which are creation, modification, or deletion of individual documents.\n3. Global Queries to global indexes (formerly called queries), which are requests that are made to an IBM Cloudant query endpoint not within the _partition namespace, including the following types:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00512-24512-26257","score":18.4040527786,"text":"\npanic(err)\n}\n\nb, _ := json.MarshalIndent(findResult, \"\", \" \")\nfmt.Println(string(b))\n\nThe previous Go example requires the following import block:\n\nimport (\n\"encoding\/json\"\n\"fmt\"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n)\n\nAll Go examples require the service object to be initialized. For more information, see the API documentation's [Authentication section](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=goauthentication-with-external-configuration) for examples.\n\n\n\n\n\n Finding the infrastructure ID for a device \n\nThe two queries we've yet to perform are shown in the following list:\n\n\n\n1. Readings for all time for a specific device.\n2. Readings for today for a specific device.\n\n\n\nFor these two queries, you need to find the partition for the devices by using the global by-device index. Then, you can query the individual partition for readings. While you might use a global index to query for the readings for individual devices, the mapping from device to infrastructure ID is highly cache-able. It never changes! With this approach, you can mostly use the cheaper and more efficient partitioned query for most requests.\n\nUsing a global index to query directly for device readings might be more efficient if caching the device to infrastructure mapping doesn't work well for a specific application.\n\nTo find the relevant partition for a device, you query the by-device view, sending the device ID as the key:\n\ncurl -X POST \"$SERVICE_URL\/readings\/_design\/infrastructure-mapping\/_view\/by-device' -H 'Content-Type: application\/json' --data '{\n\"keys\": [\"device-123456\"], \"limit\": 1\n}'\n\nFor more language examples that show querying a global view, see the [Query a MapReduce view in API Docs](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostview).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_00454-1832-2607","score":18.2776724764,"text":"\nIBM Cloudant audit logs can be used to understand:\n\n\n\n* What and when databases and documents were accessed within an account, and by whom.\n* What and when queries were run, and by whom.\n* What a specific principal or user that is accessed, updated, or deleted, and when.\n* What and when replication documents were created or deleted.\n\n\n\nTo request access to the audit logs for your account, contact IBM Cloudant support. Support provides a copy of the audit logs that are of interest to you.\n\nWhen you contact support, be sure to include the following information:\n\n\n\n* The IBM Cloudant account that the request relates to.\n* The time frame for audit logs (must not be more than one month per support request).\n* Any specific databases, documents, or principals of interest.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-audit-logging"},{"document_id":"ibmcld_00512-13573-14952","score":18.1089063648,"text":"\nTo return the readings for a specific device from a partition, you can use an IBM Cloudant Query index. For this document, use POST to _index with an index definition that includes the partitioned field set to true.\n\nFor Query index definitions, the partitioned field isn't nested inside an options object.\n\nFor these queries, you need two partitioned indexes:\n\n\n\n1. By timestamp\n2. By device ID and timestamp\n\n\n\n\n\n Uploading partitioned index by timestamp \n\nUpload the index by timestamp to the database by using this command:\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl -X POST \"$SERVICE_URL\/readings\/_index\" -H 'Content-Type: application\/json' --data '{\n\"index\": {\n\"fields\": [\n{\"ts\": \"asc\"}\n]\n},\n\"name\": \"timestamped-readings\",\n\"type\": \"json\",\n\"partitioned\": true\n}'\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.IndexDefinition;\nimport com.ibm.cloud.cloudant.v1.model.IndexField;\nimport com.ibm.cloud.cloudant.v1.model.IndexResult;\nimport com.ibm.cloud.cloudant.v1.model.PostIndexOptions;\n\nCloudant service = Cloudant.newInstance();\n\nIndexField indexField = new IndexField.Builder()\n.add(\"ts\", \"asc\")\n.build();\n\nIndexDefinition index = new IndexDefinition.Builder()\n.addFields(indexField)\n.build();\n\nPostIndexOptions indexOptions = new PostIndexOptions.Builder()\n.db(\"readings\")\n.index(index)\n.name(\"timestamped-readings\")\n.type(\"json\")","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.25,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.195190025,"ndcg_cut_10":0.195190025}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01533-4546-6910","score":41.8807114884,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4585-6962","score":41.8292239906,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-6329-8623","score":38.3053829876,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":38.3053829876,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_07578-365833-367834","score":37.8875420331,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-365807-367808","score":37.8875420331,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01415-6473-8616","score":37.4601829104,"text":"\nFor more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_00882-2700-4149","score":36.4129984314,"text":"\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \".\/Report-final.xml\" --type staticsecurityscan\n\nChange the type to dynamicsecurityscan if the report is from a dynamic scan.\n\n\n\n\n\n Uploading SonarQube results \n\nTo upload data from SonarQube, you must provide the SonarQube server token by using --token. Your SonarQube server is required to be accessible from your CI\/CD tool.\n\nAfter you run a scan by using SonarQube, you can upload SonarQube results by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \".scannerwork\/report-task.txt\" --type=sonarqube --token=$SONARQUBE_TOKEN\n\nreport-task.txt is a file that is generated during the SonarQube scan.\n\n\n\n\n\n Uploading IBM Vulnerability Advisor results \n\nTo get the result of the vulnerability advisor scan from the CLI, use the following command:\n\nibmcloud cr va ${PIPELINE_IMAGE_URL} -o json > vulnerability_advisor.json\n\nYou can get your image's repository and tag from the Vulnerability Advisor UI or in the CLI by using ibmcloud cr image-list. DevOps Insights accepts only the JSON output. You can upload Vulnerability Advisor output file to DevOps Insights by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"${APP_NAME}\" --buildnumber \"${BUILD_NUMBER}\" --filelocation \"vulnerability_advisor.json\" --type vulnerabilityadvisor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-publishing-test-data"},{"document_id":"ibmcld_07971-2155-4528","score":36.4077989446,"text":"\n* Document and evidence the execution of the system\/service and security testing\/scanning along with the results.\n* Track security flaws and flaw resolution within the system and report findings to designated personnel.\n\n\n\n\n\n Red Hat OpenShift on IBM Cloud \n\nWhen using Red Hat OpenShift on IBM Cloud to host workloads, you must use Container Registry and the Vulnerability Advisor component it contains. Red Hat OpenShift on IBM Cloud provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM\u00ae. You can use Container Registry by setting up your own image namespace and pushing container images to your namespace. By using Container Registry, only users with access to your IBM Cloud account can access your images.\n\nWhen you push images to Container Registry, you benefit from the built-in Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified. This verdict can be used by Portieris to prevent the deployment of nonsecure images in Container Registry. [Portieris](https:\/\/github.com\/IBM\/portieris) is a Kubernetes admission controller for the enforcement of image security policies. You can create image security policies for each Kubernetes namespace, or at the cluster level, and enforce different rules for different images.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nSee the following for more information on Container Registry and how to set it up:\n\n\n\n* [About Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-development-processes"},{"document_id":"ibmcld_01533-4-2366","score":35.7414609712,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01533-4-2366","score":39.2162732957,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4-2366","score":39.2162732957,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_00879-2782-4388","score":38.6255927981,"text":"\nvulnerabilityadvisor Vulnerability Advisor results from IBM Vulnerability Advisor on Cloud \n\n\n\nTest records must provide data in one of the following supported formats:\n\n\n\nTable 2. Supported formats\n\n Test Type Supported Formats \n\n Unit test Mocha, xUnit, Karma\/Mocha \n Functional verification test Mocha, xUnit, Karma\/Mocha \n Code coverage Cobertura, lcov, JaCoCo \n SonarQube Scan data that is provided by SonarQube scans \n Static AppScan Static App Scans that are provided by IBM Application Security on Cloud \n Dynamic AppScan Dynamic App Scans that are provided by IBM Application Security on Cloud \n Vulnerability Advisor Results Vulnerability Advisor results from IBM Vulnerability Advisor on Cloud \n\n\n\n\n\n\n\n Viewing test results \n\nWhen your pipeline runs, it publishes the test result data to DevOps Insights. You can view the test result data on the Quality Dashboard page.\n\n\n\n1. From the IBM Cloud console, click the menu icon ![hamburger icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/562806c0b18119f4d21cb66f5ae6d051634b4a16\/ContinuousDelivery\/images\/icon_hamburger.svg), and select Resource List.\n2. Select your toolchain.\n3. From your toolchain's Overview page, on the IBM Cloud tools card, click DevOps Insights.\n4. Click Quality Dashboard in the navigation to open the page.\n\n\n\nFor more information about the Quality Dashboard page, see [DevOps data aggregation](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-devops-data-aggregation).\n\n\n\n\n\n Next steps \n\n[Evaluate gates](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-evaluate-gates-cli).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-publish-test-cli"},{"document_id":"ibmcld_01533-1902-3785","score":38.5461256054,"text":"\nFor more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nThe following functions are available in version 3:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.\n* Provides recommendations to secure configuration files for a subset of application types.\n* Provides instructions about how to fix a reported [vulnerable package](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexpackages) or [configuration issue](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexapp_configurations) in its reports.\n* Applies exemption policies to reports at an account, [namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe following functions are available in version 4:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01533-4546-6910","score":38.4760263921,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4585-6962","score":38.4397413703,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01535-1902-3811","score":38.3831311292,"text":"\nFor more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nThe following functions are available in version 3:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.\n* Provides recommendations to secure configuration files for a subset of application types.\n* Provides instructions about how to fix a reported [vulnerable package](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages) or [configuration issue](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiapp_configurations) in its reports.\n* Applies exemption policies to reports at an account, [namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe following functions are available in version 4:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-6329-8623","score":38.3053829876,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":38.3053829876,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_07578-365833-367834","score":37.8875420331,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.2,"recall_3":0.4,"recall_5":0.4,"recall_10":0.4,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.55314647,"ndcg_cut_10":0.55314647}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01533-6329-8623","score":36.6380089817,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":36.6380089817,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01471-7-1919","score":35.8288528125,"text":"\nRelease notes for Container Registry \n\nLearn about the changes to IBM Cloud\u00ae Container Registry and Vulnerability Advisor. The changes are grouped by date.\n\n\n\n 19 June 2023 \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023\n: For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\n\n\n\n\n 19 May 2023 \n\nUpdate Vulnerability Advisor to version 4 by 19 June 2023\n: The Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\nFor more information, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4).\n\n\n\n\n\n 26 April 2023 \n\nUsing Portieris to block the deployment of images with issues is deprecated.\n: The use of Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n\n\n 11 November 2022 \n\nChange to virtual private endpoints\n: Virtual private endpoints are changing.\n\nOn 11 November 2022, virtual private endpoints (VPEs) for IBM Cloud Container Registry are being updated and the existing VPE version is being deprecated on 15 December 2022. If you use Container Registry VPE gateways, you must create new VPE gateways and remove your VPE gateways that were created before 11 November 2022 at the earliest opportunity so that you pick up these changes. VPE gateways that were created before 11 November 2022 are deprecated and will not work after 15 December 2022.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes"},{"document_id":"ibmcld_01415-7932-9985","score":34.9489627982,"text":"\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\n\n\n\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run the following command:\n\napk info <package_name>\n* To list all installed packages and their versions, run the following command:\n\napk list\n\n\n\n\n\n\n\n Debian and Ubuntu package manager commands \n\nOn Debian and Ubuntu, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\napt show <package_name>\n\ndpkg-query -l <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\napt list\n\ndpkg-query -W\n\n\n\n\n\n\n\n Red Hat and CentOS package manager commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_01415-9486-11005","score":34.8461019895,"text":"\nOn Debian and Ubuntu, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\napt show <package_name>\n\ndpkg-query -l <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\napt list\n\ndpkg-query -W\n\n\n\n\n\n\n\n Red Hat and CentOS package manager commands \n\nOn Red Hat\u00ae OpenShift\u00ae and CentOS, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\nrpm -qi <package_name>\n\nyum info <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\nrpm -qa\n\nyum list installed\n\n\n\n\n\n\n\n\n\n Does Vulnerability Advisor have versions? \n\nVulnerability Advisor is available in two versions, version 3 and version 4. For more information, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_01533-4-2366","score":34.6397426672,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4-2366","score":34.6397426672,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01471-4315-5983","score":34.6104775628,"text":"\nTo include security status, you can either add the --va option to the command, or use the [ibmcloud cr va](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_va) command to query the security status for an individual image.\n\nFor more information, see [Container Registry CLI stops returning security status results in lists by default from version 1.0.0](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_lists).\n\nAll releases of Container Registry plug-in 0.1 are deprecated\n: All releases of version 0.1 of the Container Registry CLI plug-in are deprecated. You can continue to use releases of version 0.1, but version 1.0.0 is available for you to use. Version 0.1 will continue to be updated with any required updates until 15 September 2023. To update the version of your CLI plug-in, see [Updating the container-registry CLI plug-in](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_setup_cli_namespace&interface=uiregistry_cli_update).\n\nVulnerability Advisor 4 is available from Container Registry plug-in 1.0.0\n: From Container Registry plug-in 1.0.0, you can choose whether to use Vulnerability Advisor version 3 or version 4 to run your commands. Vulnerability Advisor 4 is available from version 1.0.0 of the Container Registry plug-in. Vulnerability Advisor 3 is the default.\n\nIf you want to continue to use version 3, you don't need to do anything.\n\nIf you want to use version 4 to run the ibmcloud cr va, ibmcloud cr image-list, or ibmcloud cr image-digests commands, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes"},{"document_id":"ibmcld_01441-7-2257","score":34.4619519412,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-7-2257","score":34.4619519412,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.2303612461}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01441-7-2257","score":34.798750816,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-7-2257","score":34.798750816,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01441-1679-3819","score":34.1439574457,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-1679-3832","score":34.11952564,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01329-58331-60199","score":34.0530981676,"text":"\nibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01533-4-2366","score":33.8465348884,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4-2366","score":33.8465348884,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-6329-8623","score":32.873199157,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":32.873199157,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01471-5654-7396","score":32.4996402753,"text":"\nIf you want to continue to use version 3, you don't need to do anything.\n\nIf you want to use version 4 to run the ibmcloud cr va, ibmcloud cr image-list, or ibmcloud cr image-digests commands, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nFor more information about Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout). For more information about Vulnerability Advisor API 4, see [Vulnerability Advisor 4 for IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/apidocs\/container-registry\/va-v4).\n\nNew commands for setting and checking the Vulnerability Advisor version are available from Container Registry plug-in 1.0.0\n: From Container Registry plug-in 1.0.0, you can use new commands to check and set Vulnerability Advisor versions.\n\nIf you want to continue to use version 3, you don't need to do anything.\n\nIf you want to use version 4, you can set the version by running the [ibmcloud cr va-version-set](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_va_version_set) command.\n\nFor more information about setting the version by using the ibmcloud cr va-version-set command, see [ibmcloud cr va-version-set](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_va_version_set) and [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nTo find out which version of Vulnerability Advisor that you're running, see [ibmcloud cr va-version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_va_version).\n\n\n\n\n\n 3 August 2022","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01471-4315-5983","score":23.1675990495,"text":"\nTo include security status, you can either add the --va option to the command, or use the [ibmcloud cr va](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_va) command to query the security status for an individual image.\n\nFor more information, see [Container Registry CLI stops returning security status results in lists by default from version 1.0.0](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_lists).\n\nAll releases of Container Registry plug-in 0.1 are deprecated\n: All releases of version 0.1 of the Container Registry CLI plug-in are deprecated. You can continue to use releases of version 0.1, but version 1.0.0 is available for you to use. Version 0.1 will continue to be updated with any required updates until 15 September 2023. To update the version of your CLI plug-in, see [Updating the container-registry CLI plug-in](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_setup_cli_namespace&interface=uiregistry_cli_update).\n\nVulnerability Advisor 4 is available from Container Registry plug-in 1.0.0\n: From Container Registry plug-in 1.0.0, you can choose whether to use Vulnerability Advisor version 3 or version 4 to run your commands. Vulnerability Advisor 4 is available from version 1.0.0 of the Container Registry plug-in. Vulnerability Advisor 3 is the default.\n\nIf you want to continue to use version 3, you don't need to do anything.\n\nIf you want to use version 4 to run the ibmcloud cr va, ibmcloud cr image-list, or ibmcloud cr image-digests commands, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes"},{"document_id":"ibmcld_01441-1679-3819","score":22.7341969344,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-1679-3832","score":22.7015774171,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01410-2747-3497","score":22.4554281281,"text":"\nVersion 1.0.0 of the CLI was released on 15 September 2022.\n\nThis release has the following changes:\n\n\n\n* Vulnerability Advisor v4 is now available, see [Vulnerability Advisor 4 is available from Container Registry plug-in 1.0.0](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes15sep2022_va_version_4).\n* Image and digest list output no longer includes security status by default. You can either add the --va argument to include security status for all the listed images, or you can use the ibmcloud cr va command to query security status for an individual image.\n\n\n\n\n\n\n\n Version 0.1.582 \n\nVersion 0.1.582 of the CLI was released on 15 September 2022.\n\nThis release has the following changes:\n\n\n\n* Vulnerability remediations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_cli_change_log"},{"document_id":"ibmcld_01410-7-1755","score":22.1244118484,"text":"\nContainer Registry CLI change log \n\nIn this change log, you can learn about the most recent changes, improvements, and updates for the IBM Cloud\u00ae Container Registry CLI.\n\nFor more information about how to update the Container Registry CLI, see [Updating the container-registry CLI plug-in](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_setup_cli_namespaceregistry_cli_update).\n\nVersion 0.1 of the Container Registry CLI is deprecated, see [All releases of Container Registry plug-in 0.1 are deprecated](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes15sep2022_v0).\n\n\n\n Version 1.1.0 \n\nVersion 1.1.0 of the CLI was released on 7 July 2023.\n\nThis release has the following changes:\n\n\n\n* Fixes a Vulnerability Advisor versioning defect that affected some commands.\n\n\n\n\n\n\n\n Version 1.0.11 \n\nVersion 1.0.11 of the CLI was released on 19 June 2023.\n\nThis release has the following changes:\n\n\n\n* The backup default Vulnerability Advisor version is now version 4.\n* Vulnerability remediations.\n* Updated translations.\n\n\n\n\n\n\n\n Version 1.0.8 \n\nVersion 1.0.8 of the CLI was released on 5 April 2023.\n\nThis release has the following changes:\n\n\n\n* Vulnerability remediations.\n* Updated translations.\n* Updated error messages.\n\n\n\n\n\n\n\n Version 0.1.587 \n\nVersion 0.1.587 of the CLI was released on 26 January 2023.\n\nThis release has the following changes:\n\n\n\n* Vulnerability remediations.\n\n\n\n\n\n\n\n Version 1.0.6 \n\nVersion 1.0.6 of the CLI was released on 25 January 2023.\n\nThis release has the following changes:\n\n\n\n* Vulnerability remediations.\n\n\n\n\n\n\n\n Version 1.0.5 \n\nVersion 1.0.5 of the CLI was released on 5 December 2022.\n\nThis release has the following changes:\n\n\n\n* Vulnerability remediations.\n* Updated translations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_cli_change_log"},{"document_id":"ibmcld_01410-1390-3152","score":21.7673582403,"text":"\n* Vulnerability remediations.\n\n\n\n\n\n\n\n Version 1.0.6 \n\nVersion 1.0.6 of the CLI was released on 25 January 2023.\n\nThis release has the following changes:\n\n\n\n* Vulnerability remediations.\n\n\n\n\n\n\n\n Version 1.0.5 \n\nVersion 1.0.5 of the CLI was released on 5 December 2022.\n\nThis release has the following changes:\n\n\n\n* Vulnerability remediations.\n* Updated translations.\n* You can install and uninstall the container-registry plug-in by using the cr alias.\n\n\n\n\n\n\n\n Version 0.1.585 \n\nVersion 0.1.585 of the CLI was released on 5 December 2022.\n\nThis release has the following changes:\n\n\n\n* Vulnerability remediations.\n\n\n\n\n\n\n\n Version 1.0.2 \n\nVersion 1.0.2 of the CLI was released on 19 October 2022.\n\nThis release has the following changes:\n\n\n\n* Minor bug fixes.\n* Vulnerability remediations.\n* Updated translations.\n\n\n\n\n\n\n\n Version 0.1.584 \n\nVersion 0.1.584 of the CLI was released on 19 October 2022.\n\nThis release has the following changes:\n\n\n\n* Updated translations.\n\n\n\n\n\n\n\n Version 1.0.1 \n\nVersion 1.0.1 of the CLI was released on 23 September 2022.\n\nThis release has the following changes:\n\n\n\n* Vulnerability remediations.\n* Updated translations.\n\n\n\n\n\n\n\n Version 0.1.583 \n\nVersion 0.1.583 of the CLI was released on 23 September 2022.\n\nThis release has the following changes:\n\n\n\n* Vulnerability remediations.\n* Updated translations.\n\n\n\n\n\n\n\n Version 1.0.0 \n\nVersion 1.0.0 of the CLI was released on 15 September 2022.\n\nThis release has the following changes:\n\n\n\n* Vulnerability Advisor v4 is now available, see [Vulnerability Advisor 4 is available from Container Registry plug-in 1.0.0](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes15sep2022_va_version_4).\n* Image and digest list output no longer includes security status by default.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_cli_change_log"},{"document_id":"ibmcld_01441-7-2257","score":21.6489970462,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-7-2257","score":21.6489970462,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01471-5654-7396","score":21.2991167948,"text":"\nIf you want to continue to use version 3, you don't need to do anything.\n\nIf you want to use version 4 to run the ibmcloud cr va, ibmcloud cr image-list, or ibmcloud cr image-digests commands, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nFor more information about Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout). For more information about Vulnerability Advisor API 4, see [Vulnerability Advisor 4 for IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/apidocs\/container-registry\/va-v4).\n\nNew commands for setting and checking the Vulnerability Advisor version are available from Container Registry plug-in 1.0.0\n: From Container Registry plug-in 1.0.0, you can use new commands to check and set Vulnerability Advisor versions.\n\nIf you want to continue to use version 3, you don't need to do anything.\n\nIf you want to use version 4, you can set the version by running the [ibmcloud cr va-version-set](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_va_version_set) command.\n\nFor more information about setting the version by using the ibmcloud cr va-version-set command, see [ibmcloud cr va-version-set](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_va_version_set) and [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nTo find out which version of Vulnerability Advisor that you're running, see [ibmcloud cr va-version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_va_version).\n\n\n\n\n\n 3 August 2022","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes"},{"document_id":"ibmcld_01471-7-1919","score":21.2383385995,"text":"\nRelease notes for Container Registry \n\nLearn about the changes to IBM Cloud\u00ae Container Registry and Vulnerability Advisor. The changes are grouped by date.\n\n\n\n 19 June 2023 \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023\n: For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\n\n\n\n\n 19 May 2023 \n\nUpdate Vulnerability Advisor to version 4 by 19 June 2023\n: The Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\nFor more information, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4).\n\n\n\n\n\n 26 April 2023 \n\nUsing Portieris to block the deployment of images with issues is deprecated.\n: The use of Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n\n\n 11 November 2022 \n\nChange to virtual private endpoints\n: Virtual private endpoints are changing.\n\nOn 11 November 2022, virtual private endpoints (VPEs) for IBM Cloud Container Registry are being updated and the existing VPE version is being deprecated on 15 December 2022. If you use Container Registry VPE gateways, you must create new VPE gateways and remove your VPE gateways that were created before 11 November 2022 at the earliest opportunity so that you pick up these changes. VPE gateways that were created before 11 November 2022 are deprecated and will not work after 15 December 2022.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01533-4546-6910","score":23.7743461274,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4585-6962","score":23.739933934,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_06004-36463-38401","score":21.8434926162,"text":"\nAs you plan and develop your app, consider the following options to maintain a secure image, ensure that sensitive information is encrypted, encrypt traffic between app microservices, and control traffic between your app pods and other pods and services in the cluster.\n\nImage security\n: To protect your app, you must protect the image and establish checks to ensure the image's integrity. Review the [image and registry security topic](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityimages_registry) for steps that you can take to ensure secure container images. For example, you might use Vulnerability Advisor to check the security status of container images. When you add an image to your organization's IBM Cloud Container Registry namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability. To get started, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index).\n\nKubernetes secrets\n: When you deploy your app, don't store confidential information, such as credentials or keys, in the YAML configuration file, configmaps, or scripts. Instead, use [Kubernetes secrets](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitypi), such as an image pull secret for registry credentials. You can then reference these secrets in your deployment YAML file.\n\nSecret encryption\n: You can encrypt the Kubernetes secrets that you create in your cluster by using a key management service (KMS) provider. To get started, see [Encrypt secrets by using a KMS provider](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-encryptionkeyprotect) and [Verify that secrets are encrypted](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-encryptionverify_kms).\n\nMicroservice traffic encryption","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_deploy"},{"document_id":"ibmcld_10439-40150-42016","score":20.9750463314,"text":"\nAs you plan how many Service objects you need in your cluster, keep in mind that Kubernetes uses iptables to handle networking and port forwarding rules. If you run many services in your cluster, such as 5000, performance might be impacted.\n\n\n\n\n\n\n\n Securing apps \n\nAs you plan and develop your app, consider the following options to maintain a secure image, ensure that sensitive information is encrypted, and control traffic between your app pods and other pods and services in the cluster.\n\nImage security\n: To protect your app, you must protect the image and establish checks to ensure the image's integrity. Review the [image and registry security topic](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityimages_registry) for steps that you can take to ensure secure container images. For example, you might use Vulnerability Advisor to check the security status of container images. When you add an image to your organization's IBM Cloud Container Registry namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability. To get started, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index).\n\nKubernetes secrets\n: When you deploy your app, don't store confidential information, such as credentials or keys, in the YAML configuration file, configmaps, or scripts. Instead, use [Kubernetes secrets](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitypi), such as an image pull secret for registry credentials. You can then reference these secrets in your deployment YAML file.\n\nSecret encryption\n: You can encrypt the Kubernetes secrets that you create in your cluster by using a key management service (KMS) provider.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_deploy"},{"document_id":"ibmcld_07971-2155-4528","score":20.8320888565,"text":"\n* Document and evidence the execution of the system\/service and security testing\/scanning along with the results.\n* Track security flaws and flaw resolution within the system and report findings to designated personnel.\n\n\n\n\n\n Red Hat OpenShift on IBM Cloud \n\nWhen using Red Hat OpenShift on IBM Cloud to host workloads, you must use Container Registry and the Vulnerability Advisor component it contains. Red Hat OpenShift on IBM Cloud provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM\u00ae. You can use Container Registry by setting up your own image namespace and pushing container images to your namespace. By using Container Registry, only users with access to your IBM Cloud account can access your images.\n\nWhen you push images to Container Registry, you benefit from the built-in Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified. This verdict can be used by Portieris to prevent the deployment of nonsecure images in Container Registry. [Portieris](https:\/\/github.com\/IBM\/portieris) is a Kubernetes admission controller for the enforcement of image security policies. You can create image security policies for each Kubernetes namespace, or at the cluster level, and enforce different rules for different images.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nSee the following for more information on Container Registry and how to set it up:\n\n\n\n* [About Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-development-processes"},{"document_id":"ibmcld_01533-6329-8623","score":20.13179995,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":20.13179995,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_07578-365833-367834","score":20.0581730569,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-365807-367808","score":20.0581730569,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01533-3131-4993","score":19.7003509731,"text":"\n* Applies exemption policies to reports at an account, [namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe following functions are available in version 4:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.\n* Provides instructions about how to fix a reported [vulnerable package](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexpackages) in its reports.\n* Applies exemption policies to reports at an account, [namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe Security status column in the Images tab of the Container Registry dashboard displays the number of issues that are associated with each image. To find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16410-14917-17357","score":25.482763929,"text":"\nAnnotation guidelines \n\nThere is no prescribed format for how to document the guidelines, but it is important that the guidelines include detailed examples. Human annotators need to understand which entity type to apply to a mention given the context, and know which relation types are valid for a given pair of mentions. Examples drawn from your domain content are often the best way to convey the correct annotation choices to make.\n\nAnnotation guidelines are not static. As your project evolves, you'll likely discover instances of mentions and relationships that are not accurately captured in the guidelines. And you'll likely discover inconsistencies between multiple human annotators who interpret the guidelines in different ways. By updating the guidelines as situations arise, you can help improve the accuracy and consistency of annotations over time.\n\nBefore documents can be considered ground truth, any conflicts between how different human annotators annotated the same documents must be resolved. A key way to resolve the conflicts is by discussing what caused the confusion, thus helping human annotators learn from their mistakes. Improving and clarifying the guidelines can help reduce the number of conflicts and help ensure that accurately and consistently annotated documents are promoted to ground truth.\n\nTo help you manage the guidelines, you might want to divide what could become a long document into multiple parts, such as guidelines for annotating entities, guidelines for annotating relations, and guidelines for annotating the ways that mentions can be coreferenced. Changes that you make in one area must be evaluated and coordinated with changes that you make in another area. For example, if you add an entity type, review the guidelines for annotating relation types and specify how the new entity type can relate to other entity types.\n\n\n\n\n\n Annotation guidelines example \n\nMost annotation guidelines will need a lot of detail and examples to ensure that human annotators consistently annotate text.\n\nThe example presented here is a simple guideline that was created for a small domain that contains traffic incident reports.\n\n\n\n Task Goals \n\n\n\n* As project members, become familiar with the iterative process of manual annotation and machine learning model refinement.\n* Annotate documents in the automotive domain with the ground truth editor and use the annotations to train a machine learning model.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"},{"document_id":"ibmcld_16417-10079-12145","score":24.8055748513,"text":"\nWhen you find instances of disagreement, you must decide how to resolve the conflict, either by selecting the correct annotation from those applied by the human annotators or by selecting a different annotation to apply.\n\nA document is available for adjudication when at least one of the following conditions is true:\n\n\n\n* The project manager approves two or more annotation sets in a task at the same time, and the same document exists in at least two of the annotation sets (an overlapping document).\n* The project manager approves another annotation set before documents in the previously approved annotation sets are adjudicated. If you adjudicate a document that overlaps between annotation set A and annotation set B, promote the annotations to ground truth, and then approve another annotation set, C, that has the same document, the annotations in the newly approved document are promoted automatically to ground truth because conflicts no longer exist. Be aware that the annotations promoted in annotation set C override the ground truth established when the overlapping documents in annotation sets A and B were adjudicated. If you approve annotation set C before you promote the annotations in annotation set A and B, the overlapping documents in set C can be checked for conflicts and adjudicated.\n\n\n\nThe amount of time that you spend adjudicating might lessen over time if you take time to improve the annotation guidelines. By providing examples and clarifying areas that caused confusion, you can help human annotators learn from their mistakes and prevent future conflicts.\n\nHere are a few examples of various ways that human annotators disagree:\n\n\n\n* Mentions\n\n\n\n* Annotator_1 places a mention on a span of text; Annotator_2 does not.\n* Annotator_1's index begins or ends before or after Annotator_2's (there is a partial overlap or subrange of text).\n* Annotator_1 assigns an entity type that is different from the entity type that Annotator_2 assigned.\n\n\n\n* Relations\n\n\n\n* Annotator_1 creates a relation between two mentions; Annotator_2 does not.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-10078-12144","score":24.8055748513,"text":"\nWhen you find instances of disagreement, you must decide how to resolve the conflict, either by selecting the correct annotation from those applied by the human annotators or by selecting a different annotation to apply.\n\nA document is available for adjudication when at least one of the following conditions is true:\n\n\n\n* The project manager approves two or more annotation sets in a task at the same time, and the same document exists in at least two of the annotation sets (an overlapping document).\n* The project manager approves another annotation set before documents in the previously approved annotation sets are adjudicated. If you adjudicate a document that overlaps between annotation set A and annotation set B, promote the annotations to ground truth, and then approve another annotation set, C, that has the same document, the annotations in the newly approved document are promoted automatically to ground truth because conflicts no longer exist. Be aware that the annotations promoted in annotation set C override the ground truth established when the overlapping documents in annotation sets A and B were adjudicated. If you approve annotation set C before you promote the annotations in annotation set A and B, the overlapping documents in set C can be checked for conflicts and adjudicated.\n\n\n\nThe amount of time that you spend adjudicating might lessen over time if you take time to improve the annotation guidelines. By providing examples and clarifying areas that caused confusion, you can help human annotators learn from their mistakes and prevent future conflicts.\n\nHere are a few examples of various ways that human annotators disagree:\n\n\n\n* Mentions\n\n\n\n* Annotator_1 places a mention on a span of text; Annotator_2 does not.\n* Annotator_1's index begins or ends before or after Annotator_2's (there is a partial overlap or subrange of text).\n* Annotator_1 assigns an entity type that is different from the entity type that Annotator_2 assigned.\n\n\n\n* Relations\n\n\n\n* Annotator_1 creates a relation between two mentions; Annotator_2 does not.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16468-16607-18718","score":24.4022740328,"text":"\nImproving and clarifying the guidelines can help reduce the number of conflicts and help ensure that accurately and consistently annotated documents are promoted to ground truth.\n\nTo help you manage the guidelines, you might want to divide what could become a long document into multiple parts, such as guidelines for annotating entities, guidelines for annotating relations, and guidelines for annotating the ways that mentions can be coreferenced. Changes that you make in one area must be evaluated and coordinated with changes that you make in another area. For example, if you add an entity type, review the guidelines for annotating relation types and specify how the new entity type can relate to other entity types.\n\n\n\n\n\n Annotation guidelines example \n\nMost annotation guidelines will need a lot of detail and examples to ensure that human annotators consistently annotate text.\n\nThe example presented here is a simple guideline that was created for a small domain that contains traffic incident reports.\n\n\n\n Task Goals \n\n\n\n* As project members, become familiar with the iterative process of manual annotation and machine learning model refinement.\n* Annotate documents in the automotive domain with the ground truth editor and use the annotations to train a machine learning model. Annotate the entity types, relation types, and coreference the entities as needed.\n\n\n\n\n\n\n\n Guideline Notations \n\n\n\n* Square brackets [ ] indicate the extent to be annotated when less than the entire quoted text is annotated.\n\nInclude negations as appropriate, for example [no injuries]ACCIDENT_OUTCOME. The type system is not using entity class to represent negation.\n\n\n\n\n\n\n\n Entity Types \n\nThe type system does not use entity sub-types or roles, nor mention types or classes.\n\n\n\n Entity types Guidelines Examples \n\n ACCIDENT_OUTCOME A consequence of an accident. Applies to both humans (e.g., death) and cars (e.g., dented). Can include \"towed\" and \"air bag deployment\" as indicators of severity of damage, and \"transported to hospital\" (but not funeral home) as indicators of severity of injury. Can include negation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents"},{"document_id":"ibmcld_16417-3559-5683","score":23.4122832692,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-3559-5682","score":23.4122832692,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16242-7-2224","score":20.6323486263,"text":"\nResponse modes \n\nIBM Cloud\n\nYou can choose a response mode for each action to set how it behaves. The modes are clarifying and confident.\n\nClarifying mode: Start here. In the clarifying mode, your assistant is eager to ask questions so you can ensure that your customer gets to the action they need. An assistant is more likely to ask questions to be sure an action matches what a customer is asking. A new or untested action gets the training that it needs.\n\nConfident mode: Take the next step. After you use analytics to improve your assistant, use the confident mode. Your assistant solves customer issues with authority and accuracy. An assistant is less likely to ask questions and is more likely to trigger actions that match. Use confident mode after you test and train actions.\n\nResponse modes are a beta feature that is available for evaluation and testing purposes on IBM Cloud only.\n\n\n\n Settings \n\nSettings for the two modes are in the global settings. For more information, see [Global settings for actions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-global-settings).\n\nYou can choose what mode to use when you create a new action. Clarifying mode is the default and is designed for use with new, untested actions that need training.\n\nThe settings are:\n\nClarify when one action matches: If an assistant prioritizes one action that it thinks matches the customer's request, it can clarify the match by asking the customer to confirm. This clarification helps you ensure that the action is the right one and allows the customer to give input before proceeding. For example, if the assistant thinks that a single action named Pay Bill is the right one, it can clarify the choice by asking the customer Did you mean: Pay Bill.\n\nClarify when more than one action matches: When your assistant finds that more than one action might fulfill a customer's request, it can automatically ask for clarification. Instead of guessing which action to use, your assistant shows a list of the possible actions to the customer and asks the customer to pick the right one.\n\nOffer support option when asking a clarifying question: The assistant can include a choice to connect to other support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-action-response-modes"},{"document_id":"ibmcld_16468-14825-17168","score":19.3298465064,"text":"\nTo connect the ground truth editor and adjudication tool to your annotation guidelines:\n\n\n\n1. Log in as a Knowledge Studio administrator, and select your workspace.\n2. select the Settings > Annotation Guidelines tab.\n3. Specify the URL to where your guidelines are hosted.\n4. Click Save. The system connects the ground truth editor and adjudication tool to your annotation guidelines. Depending on the access permissions granted to users when you created the guidelines, human annotators and workspace administrators might be able to update the guidelines after opening them, for example, to add clarifications and examples.\n\n\n\n\n\n\n\n Annotation guidelines \n\nThere is no prescribed format for how to document the guidelines, but it is important that the guidelines include detailed examples. Human annotators need to understand which entity type to apply to a mention given the context, and know which relation types are valid for a given pair of mentions. Examples drawn from your domain content are often the best way to convey the correct annotation choices to make.\n\nAnnotation guidelines are not static. As your project evolves, you'll likely discover instances of mentions and relationships that are not accurately captured in the guidelines. And you'll likely discover inconsistencies between multiple human annotators who interpret the guidelines in different ways. By updating the guidelines as situations arise, you can help improve the accuracy and consistency of annotations over time.\n\nBefore documents can be considered ground truth, any conflicts between how different human annotators annotated the same documents must be resolved. A key way to resolve the conflicts is by discussing what caused the confusion, thus helping human annotators learn from their mistakes. Improving and clarifying the guidelines can help reduce the number of conflicts and help ensure that accurately and consistently annotated documents are promoted to ground truth.\n\nTo help you manage the guidelines, you might want to divide what could become a long document into multiple parts, such as guidelines for annotating entities, guidelines for annotating relations, and guidelines for annotating the ways that mentions can be coreferenced. Changes that you make in one area must be evaluated and coordinated with changes that you make in another area.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents"},{"document_id":"ibmcld_16456-21212-23338","score":16.0625667562,"text":"\nMove through the document and click each mention that means the same thing and is labeled by the same entity type. For example, click each occurrence of IBM, International Business Machines, and IBM Corp., assuming all these mentions have the entity type ORGANIZATION.\n2. Double-click the last mention that you want to add to the chain. A coreference chain is created in the side panel. The name of the chain matches the first mention that you selected.\n3. To highlight all mentions in a chain to review them in context, hover over the name of the chain in the side pane.\n\n\n\n8. The Single Mention List displays terms in the document that have been annotated, but have not been added to a chain. If you notice a mention in the list that belongs in a chain, you can add it to the chain from here.\n\n\n\n1. From the Single Mention List in the side panel, click the mention.\n2. From the drop-down list below the mention description, choose the number that represents the chain that you want to add the mention to.\n3. Click Merge to add the mention to the chain, and then click OK.\n\n\n\nThe mention is removed from the Single Mention List and the number of the chain that it now belongs to is displayed below the mention in the document.\n9. You can undo your work by using the following methods:\n\n\n\n* To remove a coreference chain that you just added, press Ctrl+Z to undo the action.\n* To remove a coreference chain later, from the Coreference Chains side panel, click the X next to the chain that you want to remove.\n* To remove a single mention from the chain, click the coreference ID to open a window that displays a list of the mentions in the chain, and then click the X next to the mention that you want to remove.\n\n\n\n10. Click Save at any time to save your work.\n\n\n\n\n\n\n\n What to do next \n\nAfter you finish annotating all entity mentions, relation mentions, and coreferences in the document, as applicable, change the document status from In Progress to Completed, click Save, and then close the document.\n\nAfter you finish annotating all documents and mark them Completed, the status of the annotation set changes to Submitted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-user-guide"},{"document_id":"ibmcld_16530-21212-23338","score":16.0625667562,"text":"\nMove through the document and click each mention that means the same thing and is labeled by the same entity type. For example, click each occurrence of IBM, International Business Machines, and IBM Corp., assuming all these mentions have the entity type ORGANIZATION.\n2. Double-click the last mention that you want to add to the chain. A coreference chain is created in the side panel. The name of the chain matches the first mention that you selected.\n3. To highlight all mentions in a chain to review them in context, hover over the name of the chain in the side pane.\n\n\n\n8. The Single Mention List displays terms in the document that have been annotated, but have not been added to a chain. If you notice a mention in the list that belongs in a chain, you can add it to the chain from here.\n\n\n\n1. From the Single Mention List in the side panel, click the mention.\n2. From the drop-down list below the mention description, choose the number that represents the chain that you want to add the mention to.\n3. Click Merge to add the mention to the chain, and then click OK.\n\n\n\nThe mention is removed from the Single Mention List and the number of the chain that it now belongs to is displayed below the mention in the document.\n9. You can undo your work by using the following methods:\n\n\n\n* To remove a coreference chain that you just added, press Ctrl+Z to undo the action.\n* To remove a coreference chain later, from the Coreference Chains side panel, click the X next to the chain that you want to remove.\n* To remove a single mention from the chain, click the coreference ID to open a window that displays a list of the mentions in the chain, and then click the X next to the mention that you want to remove.\n\n\n\n10. Click Save at any time to save your work.\n\n\n\n\n\n\n\n What to do next \n\nAfter you finish annotating all entity mentions, relation mentions, and coreferences in the document, as applicable, change the document status from In Progress to Completed, click Save, and then close the document.\n\nAfter you finish annotating all documents and mark them Completed, the status of the annotation set changes to Submitted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-user-guide"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01377-8075-10005","score":21.5289809186,"text":"\nView, inspect, pull, push, delete, and restore images.<br><br>View, add, analyze, and remove namespaces.<br><br>Assign namespaces to resource groups.<br><br>View and set quotas.<br><br>View vulnerability reports.<br><br>View and create image signatures.<br><br>Review and change pricing plans.<br><br>Enable IAM access policy enforcement.<br><br>List, add, and remove Vulnerability Advisor security issue exemption policies.<br><br>List types of security exemptions.<br><br>Set and run retention policies.<br><br>View the contents of the trash.<br><br>Restore images.<br><br>View the contents of the manifest for an image.<br><br>Prevent or allow image pulls or pushes over public network connections for your account.<br><br>Check whether the use of public connections is prevented for image pushes or pulls in your account.<br><br>Delete all untagged images in your Container Registry account. \n\n\n\nFor the following Container Registry commands, you must have at least one of the specified roles as shown in the following tables. To create a policy that allows access to Container Registry, you must create a policy where the following criteria apply.\n\n\n\n* The service name is container-registry.\n* The service instance is empty.\n* The region is the region that you want to grant access to, or is empty to give access to all regions.\n\n\n\n\n\n Access roles for configuring Container Registry \n\nTo grant a user permission to configure Container Registry in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you must not specify a resource type or resource. Policies for configuring Container Registry must not be set at a resource group level.\n\nFor example, run the following ibmcloud iam user-policy-create command. Where <user_email> is the user's email address, <region> is the region, and <roles> is the role, or roles, that you want the user to have.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam"},{"document_id":"ibmcld_01387-8101-10031","score":21.5289809186,"text":"\nView, inspect, pull, push, delete, and restore images.<br><br>View, add, analyze, and remove namespaces.<br><br>Assign namespaces to resource groups.<br><br>View and set quotas.<br><br>View vulnerability reports.<br><br>View and create image signatures.<br><br>Review and change pricing plans.<br><br>Enable IAM access policy enforcement.<br><br>List, add, and remove Vulnerability Advisor security issue exemption policies.<br><br>List types of security exemptions.<br><br>Set and run retention policies.<br><br>View the contents of the trash.<br><br>Restore images.<br><br>View the contents of the manifest for an image.<br><br>Prevent or allow image pulls or pushes over public network connections for your account.<br><br>Check whether the use of public connections is prevented for image pushes or pulls in your account.<br><br>Delete all untagged images in your Container Registry account. \n\n\n\nFor the following Container Registry commands, you must have at least one of the specified roles as shown in the following tables. To create a policy that allows access to Container Registry, you must create a policy where the following criteria apply.\n\n\n\n* The service name is container-registry.\n* The service instance is empty.\n* The region is the region that you want to grant access to, or is empty to give access to all regions.\n\n\n\n\n\n Access roles for configuring Container Registry \n\nTo grant a user permission to configure Container Registry in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you must not specify a resource type or resource. Policies for configuring Container Registry must not be set at a resource group level.\n\nFor example, run the following ibmcloud iam user-policy-create command. Where <user_email> is the user's email address, <region> is the region, and <roles> is the role, or roles, that you want the user to have.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam&interface=ui"},{"document_id":"ibmcld_01377-13470-15034","score":20.3442366777,"text":"\ncontainer-registry.settings.set [ibmcloud cr platform-metrics](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_platform_metrics) Update registry service settings for the targeted account, such as enabling platform metrics. Manager \n\n\n\n\n\n\n\n Access roles for using Container Registry \n\nTo grant a user permission to access Container Registry content in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you can restrict access to a specific namespace by specifying the resource type namespace and the namespace name as the resource. If you don't specify a resource-type and a resource, the policy grants access to all resources in the account. Alternatively, if your namespace is within a resource group, permission can be granted by using an IAM access policy on that resource group.\n\nFor example, use the following command to create a user policy. Where <user_email> is the user's email address, <region> is the region, <roles> is the role, or roles, that you want the user to have, and <namespace_name> is the name of the namespace.\n\nibmcloud iam user-policy-create <user_email> --service-name container-registry --region <region> --roles <roles> [--resource-type namespace --resource <namespace_name>]\n\nThe following table details actions that are mapped to operations on the service and to the service access roles for using Container Registry.\n\n\n\nTable 5. Service actions and operations for using Container Registry\n\n Action Operation on service Role Status","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam"},{"document_id":"ibmcld_01387-13496-15060","score":20.3442366777,"text":"\ncontainer-registry.settings.set [ibmcloud cr platform-metrics](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_platform_metrics) Update registry service settings for the targeted account, such as enabling platform metrics. Manager \n\n\n\n\n\n\n\n Access roles for using Container Registry \n\nTo grant a user permission to access Container Registry content in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you can restrict access to a specific namespace by specifying the resource type namespace and the namespace name as the resource. If you don't specify a resource-type and a resource, the policy grants access to all resources in the account. Alternatively, if your namespace is within a resource group, permission can be granted by using an IAM access policy on that resource group.\n\nFor example, use the following command to create a user policy. Where <user_email> is the user's email address, <region> is the region, <roles> is the role, or roles, that you want the user to have, and <namespace_name> is the name of the namespace.\n\nibmcloud iam user-policy-create <user_email> --service-name container-registry --region <region> --roles <roles> [--resource-type namespace --resource <namespace_name>]\n\nThe following table details actions that are mapped to operations on the service and to the service access roles for using Container Registry.\n\n\n\nTable 5. Service actions and operations for using Container Registry\n\n Action Operation on service Role Status","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam&interface=ui"},{"document_id":"ibmcld_01388-10517-12258","score":17.5807591484,"text":"\nList the policies for User B by running the following command.\n\nibmcloud iam user-policies <user.b@example.com>\n\nFind the policies that you created and note the Policy IDs.\n3. Delete the policies that you created by running the following command, where <Policy_ID> is the Policy ID.\n\nibmcloud iam user-policy-delete <user.b@example.com> <Policy_ID>\n\n\n\n\n\n\n\n\n\n Step 3: Create a service ID and grant access to a resource \n\nConfigure a service ID and grant it access to your IBM Cloud Container Registry namespace.\n\n\n\n1. Set up a service ID with access to IBM Cloud Container Registry and create an\n\nAPI keyfor it.\n\n\n\n1. Log in to User A's account by running the following command.\n\nibmcloud login\n2. Create a service ID named cr-roles-tutorial with the description \"Created during the access control tutorial for Container Registry\" by running the following command.\n\nibmcloud iam service-id-create cr-roles-tutorial --description \"Created during the access control tutorial for Container Registry\"\n3. Create a service policy for the service ID that grants the Reader role on namespace_a by running the following command.\n\nibmcloud iam service-policy-create cr-roles-tutorial --service-name container-registry --region <cloud_region> --resource-type namespace --resource namespace_a --roles Reader\n4. Create a second service policy that grants the Writer role on namespace_b by running the following command.\n\nibmcloud iam service-policy-create cr-roles-tutorial --service-name container-registry --region <cloud_region> --resource-type namespace --resource namespace_b --roles Writer\n5. Create an API key for the service ID by running the following command.\n\nibmcloud iam service-api-key-create cr-roles-tutorial-apikey cr-roles-tutorial\n\n\n\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access"},{"document_id":"ibmcld_05256-22076-24099","score":17.2562427709,"text":"\nIf you have a Service ID that you want to use, select it. If not, select Create, enter a name and description, and click Create.\n4. From the Service ID page, from the Access policies section, select Assign access.\n5. From the Assign service ID additional access section,\n\n\n\n1. Select Container Registry for type of access. Click Next.\n2. Select the type of access: All resources or Specific resources. If you specify Specific resources, you can add attributes based on resource group, geography, region, resource type, resource ID, or resource name to further restrict access. If you select a certain resource group, make sure to select Viewer access for Resource group access. Click Next.\n3. In the Roles and Actions section, select the type of access you want to grant. If you plan to use only images for your applications and jobs, select Reader. If you want to push the source code and images to Container Registry, then also select Writer. Click Review.\n4. Click Add and then Assign.\n\n\n\n\n\n\n\n\n\n Step 2 Enabling Container Registry discovery \n\nTo allow the Code Engine console to automatically discover Container registry, you must authenticate the service ID to the IAM Identity Service.\n\n\n\n1. From the Service ID page, from the Access policies section, select Assign access.\n2. From the Assign service ID additional access section,\n\n\n\n1. Select IAM Identity Service for type of access. Click Next.\n2. Select Specific resources for resource scope. Select Resource type as attribute type, keep string equals as operator and enter serviceid as value. Click Add a condition.\n3. Select Resource ID as attribute type, keep string equals as operator and put the identifier of your service ID. You can find your service ID on the Details page for the service ID or in the browser URL when configuring it. Click Next.\n4. In the Roles and Actions section, select Platform Operator access. Click Review\n5. Click Add and then Assign.\n\n\n\n\n\n\n\n\n\n Step 3 Creating an API key for a service ID \n\nCreate an API key for a service ID.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registry"},{"document_id":"ibmcld_01530-1294-3025","score":17.2414444501,"text":"\n* Decide on the roles that each user needs and on which resources in IBM Cloud Container Registry, see [IAM roles](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamiam). You can create multiple policies, for example, you can grant write access on a resource but grant read access only on another resource. Policies are additive, which means that a global read policy and a resource-scoped write policy grants both read and write access on that resource.\n* [Invite users to an account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iamuserinviamuserinv).\n\nIf you want users to create clusters in IBM Cloud Kubernetes Service, ensure that you assign the IBM Cloud Container Registry Administrator role to those users, and don't assign a resource group. For more information, see [Preparing to create clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clusterscluster_prepare).\n\n\n\nTo create policies for IBM Cloud Container Registry, the service name field must be container-registry.\n\nIf you want to access resources, you must assign roles to users or service IDs. If you want to grant access to everything, don't specify a resource type or a resource. If you want to grant access to a specific namespace, specify the resource type as namespace and use the namespace name as the resource.\n\n\n\n* To create a policy for users, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n* To create a policy for service IDs, run the ibmcloud iam service-policy-create command or use the IBM Cloud console to bind roles to your service IDs. To create policies, you must have the Administrator role. You automatically have the Administrator role on your own account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-user"},{"document_id":"ibmcld_01388-2747-4448","score":17.0994197937,"text":"\nibmcloud cr quota-set --traffic=4000\n\nThe command fails because User B doesn't have the correct access.\n\n\n\n3. Grant User B the Manager role so that User B can configure IBM Cloud Container Registry.\n\n\n\n1. Log back in to your account as yourself, User A, by running the following command.\n\nibmcloud login\n2. Create a policy that grants the Manager role to User B by running the following command.\n\nibmcloud iam user-policy-create <user.b@example.com> --service-name container-registry --roles Manager\n\n\n\n4. Prove that User B can now change quotas in User A's account.\n\n\n\n1. Log in as User B, targeting User A's account by running the following command.\n\nibmcloud login -c <YourAccountID>\n2. Try to edit your registry quota to 4 GB of traffic by running the following command.\n\nibmcloud cr quota-set --traffic=4000\n\nIt works because User B has the correct type of access.\n3. Now change the quota back by running the following command.\n\nibmcloud cr quota-set --traffic=5120\n\n\n\n5. Clean up.\n\n\n\n1. Log back in to your account as yourself, User A, by running the following command.\n\nibmcloud login\n2. List the policies for User B, find the policy that you created by running the following command, and note the ID.\n\nibmcloud iam user-policies <user.b@example.com>\n3. Delete the policy by running the following command, where <Policy_ID> is your Policy ID.\n\nibmcloud iam user-policy-delete <user.b@example.com> <Policy_ID>\n\n\n\n\n\n\n\n\n\n Step 2: Authorize a user to access specific namespaces \n\nCreate some\n\nnamespaceswith sample images, and grant access to them. You create policies to grant different roles to each namespace, and show what effect that has.\n\n\n\n1. Create three new namespaces in User A's account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access"},{"document_id":"ibmcld_01494-31513-33000","score":17.0303939131,"text":"\n* [Enforce security in your cluster](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflowregistry_tutorial_workflow_enforce_security)\n* [Resolve vulnerabilities in your image](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflowregistry_tutorial_workflow_resolve_vulnerabilities)\n\n\n\n* [Deploying to nondefault Kubernetes namespaces](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflowregistry_tutorial_workflow_deploy_nondefault_namespaces)\n\n\n\n\n\n\n\n Granting access to Container Registry resources tutorial \n\n[Granting access to Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessiam_access)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessiam_access_prereq)\n* [Authorize a user to configure the registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessconfigure_registry)\n* [Authorize a user to access specific namespaces](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessaccess_resources)\n* [Create a service ID and grant access to a resource](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessservice_id)\n* [Cleaning up your account](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessclean_up)\n\n\n\n\n\n\n\n Solution tutorials \n\n[Moving a VM based app to Kubernetes](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-vm-to-containers-and-kubernetesvm-to-containers-and-kubernetes)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-sitemap"},{"document_id":"ibmcld_16729-71418-73421","score":17.0152133701,"text":"\nIBM Cloud\u00ae Container Registry provides a multi-tenant private image registry that you can use to store and share your container images with users in your IBM Cloud account.\n\nKubernetes service Container Registry\n\n\n\n* 45 minutes\n* 2023-06-02\n\n\n\n[Encrypting images for content confidentiality](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_encrypt)Encrypting images for content confidentiality\n\nYou can protect the confidentiality of your IBM Cloud\u00ae Container Registry images, and ensure that hosts that aren't trusted can't run the images.\n\nKey Protect Container Registry\n\n\n\n* 2 hours\n* 2023-01-25\n\n\n\n[Granting access to Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access)Granting access to Container Registry resources tutorial\n\nUse this tutorial to find out how to grant access to your resources by configuring IBM Cloud\u00ae Identity and Access Management (IAM) for IBM Cloud\u00ae Container Registry.\n\nContainer Registry\n\n\n\n* 45 minutes\n* 2023-01-31\n\n\n\n[Container Registry and Vulnerability Advisor workflow tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflow)Container Registry and Vulnerability Advisor workflow tutorial\n\nUse this tutorial to find out about the basic functions of both IBM Cloud\u00ae Container Registry and Vulnerability Advisor.\n\nKubernetes service Container Registry\n\n\n\n* 2 hours\n* 2023-06-19\n\n\n\n[Onboarding a Certified Operator from a Red Hat registry](https:\/\/cloud.ibm.com\/docs\/account?topic=account-catalog-opbundle-tutorial)Onboarding a Certified Operator from a Red Hat registry\n\nThis tutorial walks you through how to onboard a sample Operator bundle from a Red Hat\u00ae registry to your account. By completing this tutorial, you learn how to create a private catalog in your account, import the Operator bundle, and validate that it can be installed on a Red Hat OpenShift on IBM Cloud cluster.\n\nContainer Registry Managing your account, resources, and access\n\n\n\n* 45 minutes\n* 2022-10-26","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05237-1279-3016","score":16.388941007,"text":"\nTo check whether an option is available for a specific command, use the -h, --help option with the command.\n\n\n\n --output FORMAT \n\nSpecifies an output format. Only JSON is supported.\n\n\n\n Examples \n\nPrint available resource groups in JSON format:\n\nibmcloud resource groups --output json\n\n\n\n\n\n\n\n -q, --quiet \n\nSuppresses verbose messages. Prompt messages like Getting information from... as ... do not display if -q, --quiet is specified.\n\n\n\n Examples \n\nPrint available resource groups in quiet mode:\n\nibmcloud resource groups -q\n\n\n\n\n\n\n\n\n\n ibmcloud help \n\nDisplays the general help for first-level built-in commands and supported namespaces of IBM Cloud CLI, or the help for a specific built-in command or namespace.\n\nibmcloud help [COMMAND|NAMESPACE]\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nCOMMAND|NAMESPACE\n: The command or namespace that help is displayed for. If not specified, the general help for IBM Cloud CLI is shown. Optional.\n\n\n\n\n\n Examples \n\nDisplay general help for the IBM Cloud CLI:\n\nibmcloud help\n\nDisplay help for the dev command:\n\nibmcloud help dev\n\n\n\n\n\n\n\n ibmcloud version \n\nPrint the version of the IBM Cloud CLI.\n\nibmcloud version\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nNone.\n\n\n\n\n\n Examples \n\nPrint the version of the IBM Cloud CLI:\n\nibmcloud version\n\n\n\n\n\n\n\n ibmcloud api \n\nSet or view the IBM Cloud API endpoint.\n\nibmcloud api [API_ENDPOINT] [--unset] [--skip-ssl-validation] [--vpc]\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nAPI_ENDPOINT\n: The API endpoint that is targeted, for example, https:\/\/cloud.ibm.com. If both the API_ENDPOINT and --unset options aren't specified, the current API endpoint is displayed. Optional.\n\n--skip-ssl-validation\n: Bypass SSL validation of HTTP requests.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-shell?topic=cloud-shell-ibmcloud_cli"},{"document_id":"ibmcld_04322-1288-3025","score":16.388941007,"text":"\nTo check whether an option is available for a specific command, use the -h, --help option with the command.\n\n\n\n --output FORMAT \n\nSpecifies an output format. Only JSON is supported.\n\n\n\n Examples \n\nPrint available resource groups in JSON format:\n\nibmcloud resource groups --output json\n\n\n\n\n\n\n\n -q, --quiet \n\nSuppresses verbose messages. Prompt messages like Getting information from... as ... do not display if -q, --quiet is specified.\n\n\n\n Examples \n\nPrint available resource groups in quiet mode:\n\nibmcloud resource groups -q\n\n\n\n\n\n\n\n\n\n ibmcloud help \n\nDisplays the general help for first-level built-in commands and supported namespaces of IBM Cloud CLI, or the help for a specific built-in command or namespace.\n\nibmcloud help [COMMAND|NAMESPACE]\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nCOMMAND|NAMESPACE\n: The command or namespace that help is displayed for. If not specified, the general help for IBM Cloud CLI is shown. Optional.\n\n\n\n\n\n Examples \n\nDisplay general help for the IBM Cloud CLI:\n\nibmcloud help\n\nDisplay help for the dev command:\n\nibmcloud help dev\n\n\n\n\n\n\n\n ibmcloud version \n\nPrint the version of the IBM Cloud CLI.\n\nibmcloud version\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nNone.\n\n\n\n\n\n Examples \n\nPrint the version of the IBM Cloud CLI:\n\nibmcloud version\n\n\n\n\n\n\n\n ibmcloud api \n\nSet or view the IBM Cloud API endpoint.\n\nibmcloud api [API_ENDPOINT] [--unset] [--skip-ssl-validation] [--vpc]\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nAPI_ENDPOINT\n: The API endpoint that is targeted, for example, https:\/\/cloud.ibm.com. If both the API_ENDPOINT and --unset options aren't specified, the current API endpoint is displayed. Optional.\n\n--skip-ssl-validation\n: Bypass SSL validation of HTTP requests.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli\/reference\/ibmcloud?topic=cli-ibmcloud_cli"},{"document_id":"ibmcld_04362-1361-3066","score":16.3019650323,"text":"\nSpecifies an output format. Only JSON is supported.\n\n\n\n Examples \n\nPrint available resource groups in JSON format:\n\nibmcloud resource groups --output json\n\n\n\n\n\n\n\n -q, --quiet \n\nSuppresses verbose messages. Prompt messages like Getting information from... as ... do not display if -q, --quiet is specified.\n\n\n\n Examples \n\nPrint available resource groups in quiet mode:\n\nibmcloud resource groups -q\n\n\n\n\n\n\n\n\n\n ibmcloud help \n\nDisplays the general help for first-level built-in commands and supported namespaces of IBM Cloud CLI, or the help for a specific built-in command or namespace.\n\nibmcloud help [COMMAND|NAMESPACE]\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nCOMMAND|NAMESPACE\n: The command or namespace that help is displayed for. If not specified, the general help for IBM Cloud CLI is shown. Optional.\n\n\n\n\n\n Examples \n\nDisplay general help for the IBM Cloud CLI:\n\nibmcloud help\n\nDisplay help for the dev command:\n\nibmcloud help dev\n\n\n\n\n\n\n\n ibmcloud version \n\nPrint the version of the IBM Cloud CLI.\n\nibmcloud version\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nNone.\n\n\n\n\n\n Examples \n\nPrint the version of the IBM Cloud CLI:\n\nibmcloud version\n\n\n\n\n\n\n\n ibmcloud api \n\nSet or view the IBM Cloud API endpoint.\n\nibmcloud api [API_ENDPOINT] [--unset] [--skip-ssl-validation] [--vpc]\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nAPI_ENDPOINT\n: The API endpoint that is targeted, for example, https:\/\/cloud.ibm.com. If both the API_ENDPOINT and --unset options aren't specified, the current API endpoint is displayed. Optional.\n\n--skip-ssl-validation\n: Bypass SSL validation of HTTP requests. This option isn't recommended.\n\n--vpc\n: Use a VPC connection for a private API endpoint.\n\n--unset","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_cli"},{"document_id":"ibmcld_00959-26137-26866","score":15.1648678541,"text":"\nFrom the location where the sample app is running, select namespace.\n\nZoom\n\n![Kubernetes namespace](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/562806c0b18119f4d21cb66f5ae6d051634b4a16\/ContinuousDelivery\/images\/ds_kub_misc_namespace.png)\n\nFigure 15. Kubernetes namespace\n5. Delete the related deployments, services, and ingresses that are listed within the selected namespace.\n\n\n\n\n\n\n\n Looking for help? \n\nGet help from the IBM Cloud\u00ae Continuous Delivery development teams by joining us on [Slack](https:\/\/ic-devops-slack-invite.us-south.devops.cloud.ibm.com\/).\n\nFor more support options, see [Getting help and support for Continuous Delivery](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-gettinghelp).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-tutorial-cd-kubernetes"},{"document_id":"ibmcld_00960-16578-17498","score":14.933399932,"text":"\nAfter your toolchain is set up and the Delivery Pipeline successfully completes, run the following steps to check your app:\n\n\n\n* From the [Clusters](https:\/\/cloud.ibm.com\/kubernetes\/clusters) home page, click the Red Hat OpenShift cluster that you used to deploy your app.\n* Click OpenShift web console.\n* In the Workloads > Pod section, filter by the project or the cluster namespace, and verify that the pods are running.\n* In the Networking > Routes section, filter by the project or the cluster namespace, and locate the app URL.\n* Verify that the app is running.\n\n\n\n\n\n\n\n\n\n Looking for help? \n\nGet help from the IBM Cloud\u00ae Continuous Delivery development teams by joining us on [Slack](https:\/\/ic-devops-slack-invite.us-south.devops.cloud.ibm.com\/).\n\nFor more support options, see [Getting help and support for Continuous Delivery](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-gettinghelp).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-tutorial-cd-only-satellite"},{"document_id":"ibmcld_04702-18684-20364","score":14.1959787625,"text":"\n: The name or ID for a namespace.\n\n--paramKEYVALUE, -pKEYVALUE\n: Parameter VALUES in the KEYVALUE format. This flag is optional.\n\n--param-fileFILE, -PFILE\n: A JSON file that contains parameter KEYS and VALUES. This flag is optional.\n\n--preview\n: Display the result of the command without running the command.\n\n--project PATH\n: The path to the serverless project. The default is . (current directory).\n\n--strict\n: Allow a user-defined runtime version.\n\n--verbose, -v\n: View verbose output.\n\n\n\n\n\n Example \n\nibmcloud fn undeploy --manifest folder\/manifest.yaml\n\n\n\n\n\n\n\n\n\n List command \n\nUse the list command to view packages, actions, triggers, and rules in the namespace.\n\n\n\n ibmcloud fn list \n\nView a grouped list of the packages, actions, triggers, and rules in the namespace.\n\nibmcloud fn list [--name-sort]\n\n\n\n Command options \n\n--name-sort, -n\n: Sort each group of returned entities by name, otherwise each group is sorted by creation date.\n\n\n\n\n\n Example \n\nibmcloud fn list\n\n\n\n\n\n\n\n\n\n Namespace commands \n\nCreate, update, delete, and find information about your namespace.\n\nTo learn how to target your Cloud Functions namespace, see [Targeting namespaces](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-namespacestargeting-namespaces).\n\nTo see CLI help for the namespace command, run ibmcloud fn namespace.\n\n\n\n ibmcloud fn namespace create \n\nCreate an IAM namespace.\n\nibmcloud fn namespace create NAMESPACE [--description DESCRIPTION]\n\n\n\n Command options \n\nNAMESPACE\n: The name for a namespace. Do not include hyphens (-) in the name. This value is required.\n\n--description DESCRIPTION, -n DESCRIPTION\n: Write your own unique description to help you identify the namespace.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-functions-cli-plugin?topic=cloud-functions-cli-plugin-functions-cli"},{"document_id":"ibmcld_04348-18684-20364","score":14.1959787625,"text":"\n: The name or ID for a namespace.\n\n--paramKEYVALUE, -pKEYVALUE\n: Parameter VALUES in the KEYVALUE format. This flag is optional.\n\n--param-fileFILE, -PFILE\n: A JSON file that contains parameter KEYS and VALUES. This flag is optional.\n\n--preview\n: Display the result of the command without running the command.\n\n--project PATH\n: The path to the serverless project. The default is . (current directory).\n\n--strict\n: Allow a user-defined runtime version.\n\n--verbose, -v\n: View verbose output.\n\n\n\n\n\n Example \n\nibmcloud fn undeploy --manifest folder\/manifest.yaml\n\n\n\n\n\n\n\n\n\n List command \n\nUse the list command to view packages, actions, triggers, and rules in the namespace.\n\n\n\n ibmcloud fn list \n\nView a grouped list of the packages, actions, triggers, and rules in the namespace.\n\nibmcloud fn list [--name-sort]\n\n\n\n Command options \n\n--name-sort, -n\n: Sort each group of returned entities by name, otherwise each group is sorted by creation date.\n\n\n\n\n\n Example \n\nibmcloud fn list\n\n\n\n\n\n\n\n\n\n Namespace commands \n\nCreate, update, delete, and find information about your namespace.\n\nTo learn how to target your Cloud Functions namespace, see [Targeting namespaces](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-namespacestargeting-namespaces).\n\nTo see CLI help for the namespace command, run ibmcloud fn namespace.\n\n\n\n ibmcloud fn namespace create \n\nCreate an IAM namespace.\n\nibmcloud fn namespace create NAMESPACE [--description DESCRIPTION]\n\n\n\n Command options \n\nNAMESPACE\n: The name for a namespace. Do not include hyphens (-) in the name. This value is required.\n\n--description DESCRIPTION, -n DESCRIPTION\n: Write your own unique description to help you identify the namespace.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-functions-cli"},{"document_id":"ibmcld_10717-18684-20364","score":14.1959787625,"text":"\n: The name or ID for a namespace.\n\n--paramKEYVALUE, -pKEYVALUE\n: Parameter VALUES in the KEYVALUE format. This flag is optional.\n\n--param-fileFILE, -PFILE\n: A JSON file that contains parameter KEYS and VALUES. This flag is optional.\n\n--preview\n: Display the result of the command without running the command.\n\n--project PATH\n: The path to the serverless project. The default is . (current directory).\n\n--strict\n: Allow a user-defined runtime version.\n\n--verbose, -v\n: View verbose output.\n\n\n\n\n\n Example \n\nibmcloud fn undeploy --manifest folder\/manifest.yaml\n\n\n\n\n\n\n\n\n\n List command \n\nUse the list command to view packages, actions, triggers, and rules in the namespace.\n\n\n\n ibmcloud fn list \n\nView a grouped list of the packages, actions, triggers, and rules in the namespace.\n\nibmcloud fn list [--name-sort]\n\n\n\n Command options \n\n--name-sort, -n\n: Sort each group of returned entities by name, otherwise each group is sorted by creation date.\n\n\n\n\n\n Example \n\nibmcloud fn list\n\n\n\n\n\n\n\n\n\n Namespace commands \n\nCreate, update, delete, and find information about your namespace.\n\nTo learn how to target your Cloud Functions namespace, see [Targeting namespaces](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-namespacestargeting-namespaces).\n\nTo see CLI help for the namespace command, run ibmcloud fn namespace.\n\n\n\n ibmcloud fn namespace create \n\nCreate an IAM namespace.\n\nibmcloud fn namespace create NAMESPACE [--description DESCRIPTION]\n\n\n\n Command options \n\nNAMESPACE\n: The name for a namespace. Do not include hyphens (-) in the name. This value is required.\n\n--description DESCRIPTION, -n DESCRIPTION\n: Write your own unique description to help you identify the namespace.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=cloud-functions-cli-plugin-functions-cli"},{"document_id":"ibmcld_04702-22532-24330","score":14.1874176219,"text":"\n: Exclude a specified number of the most recently created namespaces from the result. This flag is optional.\n\n\n\n\n\n Example \n\nibmcloud fn namespace list\n\n\n\n\n\n\n\n ibmcloud fn namespace target \n\nTarget an available IAM or Cloud Foundry namespace.\n\nibmcloud fn namespace target NAMESPACE\n\n\n\n Command options \n\nNAMESPACE\n: The name or ID for a namespace. This value is required.\n\n\n\n\n\n Example \n\nibmcloud fn namespace target HBCTeamProd\n\n\n\n\n\n\n\n ibmcloud fn namespace update \n\nChange the name or description of an IAM namespace.\n\nibmcloud fn namespace update NAMESPACE [NEW_NAMESPACE_NAME] [--description DESCRIPTION]\n\n\n\n Command options \n\nNAMESPACE\n: The name for a namespace. Do not include hyphens (-) in the name. This value is required.\n\nNAMESPACE_NAME\n: The new name for a namespace. Do not include hyphens (-) in the name. This value is optional.\n\n--description DESCRIPTION, -n DESCRIPTION\n: Write your own unique description to help you identify the namespace. If your description is more than one word, include quotation marks (\") around your description. This flag is optional.\n\n\n\n\n\n Example \n\nibmcloud fn namespace update HBCTeamProd HBCTeamStaging\n\n\n\n\n\n\n\n\n\n Package commands \n\nCreate, update, delete, bind, and find information about packages.\n\nTo see CLI help for the package command, run ibmcloud fn package.\n\n\n\n ibmcloud fn package bind \n\nBind parameters to a package. All the actions within the package inherit those parameters unless otherwise specified.\n\nibmcloud fn package bind PACKAGE_NAME BOUND_PACKAGE_NAME [--annotation ANNOTATION_KEY ANNOTATION_VALUE] [--annotation-file FILE] [--param KEY VALUE] [--param-file FILE]\n\n\n\n Command options \n\nPACKAGE_NAME\n: The name of the package. This value is required.\n\nBOUND_PACKAGE_NAME\n: The name of the package binding. This value is required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-functions-cli-plugin?topic=cloud-functions-cli-plugin-functions-cli"},{"document_id":"ibmcld_04348-22532-24330","score":14.1874176219,"text":"\n: Exclude a specified number of the most recently created namespaces from the result. This flag is optional.\n\n\n\n\n\n Example \n\nibmcloud fn namespace list\n\n\n\n\n\n\n\n ibmcloud fn namespace target \n\nTarget an available IAM or Cloud Foundry namespace.\n\nibmcloud fn namespace target NAMESPACE\n\n\n\n Command options \n\nNAMESPACE\n: The name or ID for a namespace. This value is required.\n\n\n\n\n\n Example \n\nibmcloud fn namespace target HBCTeamProd\n\n\n\n\n\n\n\n ibmcloud fn namespace update \n\nChange the name or description of an IAM namespace.\n\nibmcloud fn namespace update NAMESPACE [NEW_NAMESPACE_NAME] [--description DESCRIPTION]\n\n\n\n Command options \n\nNAMESPACE\n: The name for a namespace. Do not include hyphens (-) in the name. This value is required.\n\nNAMESPACE_NAME\n: The new name for a namespace. Do not include hyphens (-) in the name. This value is optional.\n\n--description DESCRIPTION, -n DESCRIPTION\n: Write your own unique description to help you identify the namespace. If your description is more than one word, include quotation marks (\") around your description. This flag is optional.\n\n\n\n\n\n Example \n\nibmcloud fn namespace update HBCTeamProd HBCTeamStaging\n\n\n\n\n\n\n\n\n\n Package commands \n\nCreate, update, delete, bind, and find information about packages.\n\nTo see CLI help for the package command, run ibmcloud fn package.\n\n\n\n ibmcloud fn package bind \n\nBind parameters to a package. All the actions within the package inherit those parameters unless otherwise specified.\n\nibmcloud fn package bind PACKAGE_NAME BOUND_PACKAGE_NAME [--annotation ANNOTATION_KEY ANNOTATION_VALUE] [--annotation-file FILE] [--param KEY VALUE] [--param-file FILE]\n\n\n\n Command options \n\nPACKAGE_NAME\n: The name of the package. This value is required.\n\nBOUND_PACKAGE_NAME\n: The name of the package binding. This value is required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-functions-cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16729-104404-106143","score":23.8297549955,"text":"\nIf you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 60 minutes\n* 2023-07-11\n\n\n\n[Installing OpenShift Data Foundation on a private cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-odf-private)Installing OpenShift Data Foundation on a private cluster\n\nOpenShift Data Foundation is a highly available storage solution that you can use to manage persistent storage for your containerized workloads in Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 2 hours\n* 2023-05-09\n\n\n\n[Creating Red Hat OpenShift on IBM Cloud clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial)Creating Red Hat OpenShift on IBM Cloud clusters\n\nCreate a cluster with worker nodes that come installed with Red Hat OpenShift container orchestration platform.\n\nRed Hat OpenShift on IBM Cloud\n\n\n\n* 45 minutes\n* 2023-07-13\n\n\n\n[Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial)Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)\n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 45 minutes\n* 2023-07-07\n\n\n\n[Setting capacity quotas for apps that use IBM Cloud Object Storage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-cos-tutorial-quota)Setting capacity quotas for apps that use IBM Cloud Object Storage","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_10702-7-1940","score":23.654626052,"text":"\nCreating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC) \n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nWith Red Hat OpenShift on IBM Cloud clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc).\n\n\n\n* Red Hat OpenShift on IBM Cloud gives you all the [advantages of a managed offering](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov) for your cluster infrastructure environment, while using the [Red Hat OpenShift tooling and catalog](https:\/\/docs.openshift.com\/container-platform\/4.11\/welcome\/index.html) that runs on Red Hat Enterprise Linux for your app deployments.\n* VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of Red Hat OpenShift on IBM Cloud [infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality.\n\n\n\nRed Hat OpenShift worker nodes are available for paid accounts and standard clusters only. You can create Red Hat OpenShift clusters that run version 4 only. The operating system is Red Hat Enterprise Linux 7.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create a Red Hat OpenShift on IBM Cloud cluster in a Virtual Private Cloud (VPC). Then, you access built-in Red Hat OpenShift components, deploy an app in a Red Hat OpenShift project, and expose the app on with a VPC load balancer so that external users can access the service.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in Red Hat OpenShift on IBM Cloud in VPC compute for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial"},{"document_id":"ibmcld_10154-17039-18368","score":23.3276591473,"text":"\nContainer-native virtualization You can set up [container-native virtualization add-on](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/about-virt.html) on bare metal machines, but not on virtual machines. Container-native virtualization is not supported by IBM. If you experience issues, you are responsible for resolving the issues and any impact to your workloads. \n Serverless workloads You can set up [Red Hat OpenShift Serverless](https:\/\/www.redhat.com\/en\/topics\/microservices\/why-choose-openshift-serverless). You can also set up Red Hat OpenShift Serverless. \n Service mesh You can set up the [Red Hat OpenShift Service Mesh](https:\/\/docs.openshift.com\/container-platform\/4.11\/service_mesh\/v1x\/installing-ossm.html). You can also set up the Red Hat OpenShift Service Mesh, but you must [apply a network policy](https:\/\/gist.githubusercontent.com\/kitch\/39c504a2ed9e381c2aadea436d5b52e4\/raw\/d8efa69f41d41425b16bb363a881a98d40d3708c\/mesh-policy.yaml) for the service mesh ingress to work. \n API and CLI tools OpenShift Container Platform clusters are set up with access to Kubernetes and Red Hat OpenShift API resources. You can also install command line tools such as oc and odo. Red Hat OpenShift on IBM Cloud clusters come with the same capabilities to use the Kubernetes and Red Hat OpenShift API and CLI tools.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_16729-218252-220002","score":23.0842823729,"text":"\nA VPC allows you to create your own space in IBM Cloud so that you can run an isolated environment in the public cloud with custom network policies.\n\nVirtual Private Cloud (VPC) Terraform on IBM Cloud\n\n\n\n* 2 hours\n* 2023-04-21\n\n\n\n[Updating VPC worker nodes that use OpenShift Data Foundation](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-vpc)Updating VPC worker nodes that use OpenShift Data Foundation\n\nFor VPC clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 60 minutes\n* 2023-07-11\n\n\n\n[Installing OpenShift Data Foundation on a private cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-odf-private)Installing OpenShift Data Foundation on a private cluster\n\nOpenShift Data Foundation is a highly available storage solution that you can use to manage persistent storage for your containerized workloads in Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 2 hours\n* 2023-05-09\n\n\n\n[Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial)Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)\n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 45 minutes\n* 2023-07-07","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_14497-7-1724","score":23.0111230081,"text":"\nVMware Solutions and Red Hat OpenShift overview \n\nIBM Cloud\u00ae for VMware Solutions includes fully automated, rapid deployments of VMware vCenter Server\u00ae in the IBM Cloud. These offerings complement the on-premises infrastructure and allow existing and future workloads to run in the IBM Cloud without conversion by using the same tools, skills, and processes they use on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae for VMware Solutions is a reference architecture and a manual build process to deploy a Red Hat OpenShift cluster 4.7 on to an existing vCenter Server instance. The components of Red Hat OpenShift cluster are deployed as virtual machines (VMs) and appliances by using NSX software-defined networking.\n\n\n\n* Reference architecture - [vCenter Server and Red Hat OpenShift architecture overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* Build process - The current document. The process and steps that are needed to install Red Hat OpenShift 4.7 on to an existing vCenter Server instance.\n\n\n\nZoom\n\n![VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_14497-11060-12784","score":22.8587374705,"text":"\nThe NSX DLR virtual machines are configured as an active - passive pair, and vSphere Distributed Resource Scheduler (DRS) anti-affinity rules are created to ensure that the DLR VMs do not run on the same host. This step is described in [Red Hat OpenShift NSX DLR configuration](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-nsxdlr-intro).\n* Update DNS - The infrastructure DNS, provisioned with the vCenter Server instance is updated with the names and IP addresses for the Red Hat OpenShift components by using a PowerShell script. This step is described in [VMware Solutions DNS configuration](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-dns-intro).\n\n\n\n* Phase 2 - Red Hat OpenShift installation. These steps are described in [Red Hat OpenShift 4.7 user provider infrastructure installation](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-install-intro).\n\n\n\n* A Red Hat virtual machine, the bastion node, is provisioned to run the Red Hat OpenShift installer and to host an HTTP Server. It is registered with Red Hat by using your subscription, and the Red Hat OpenShift installer is downloaded.\n* On the bastion node, the install-config.yaml file is populated with the required Red Hat OpenShift parameters and Red Hat OpenShift ignition is used to generate a number of files used for the installation of the bootstrap, control plane, and worker machines.\n* Terraform, on the bastion node, uses the files that are created by Ignition to create the Red Hat OpenShift VMs.\n\n\n\n* Phase 3 - Post deployment activities. Configure a persistent volume for use by the Red Hat OpenShift cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_08259-0-511","score":22.8001743869,"text":"\n\n\n\n\n\n\n  Release notes for Red Hat OpenShift for HPC \n\nUse these release notes to learn about the latest updates to Red Hat\u00ae OpenShift\u00ae for HPC that are grouped by date.\n\n\n\n  March 2022 \n\n\n\n  24 March 2022 \n\nIntroducing Red Hat OpenShift for HPC solutions\n:   You can now take advantage of automated deployment of a Red Hat OpenShift cluster along with a deployer virtual server instance, which allows you to easily assemble, compile, and deploy your HPC applications to the Red Hat OpenShift cluster.\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-openshift?topic=hpc-openshift-release-notes"},{"document_id":"ibmcld_08006-7-1967","score":22.4754601126,"text":"\nSingle-region IBM Cloud for Financial Services reference architecture for VPC with Red Hat OpenShift on IBM Cloud \n\nIf you want to use containers, you can add [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview) to your VPC. Except for the addition of Red Hat OpenShift on IBM Cloud, you use the same architectural patterns and components that were described for the [Single-region IBM Cloud for Financial Services reference architecture for VPC with Virtual Servers for VPC](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-detailed-vsi).\n\nThe following diagram shows a more detailed view of both the management and workload VPCs when Red Hat OpenShift on IBM Cloud is introduced.\n\n\n\n Architecture diagram \n\nZoom\n\n![Single region IBM Cloud for Financial Services reference architecture for VPC with Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9ac5c38b41e0aa1cb4ccc6cc7f547751ec805221\/framework-financial-services\/vpc\/images\/roks-single-region\/roks-single-region-consumer-intranet.svg)\n\nFigure 1. Single region IBM Cloud for Financial Services reference architecture for VPC with Red Hat OpenShift on IBM Cloud\n\nYou can choose to use Red Hat OpenShift on IBM Cloud alongside (or instead of) virtual servers in either or both VPCs. Even though it is shown in the diagram as an option, it is not required to put Red Hat OpenShift on IBM Cloud in your management VPC.\n\n\n\n\n\n Red Hat OpenShift on IBM Cloud concepts \n\nRed Hat OpenShift on IBM Cloud is a managed offering to create your own Red Hat OpenShift on IBM Cloud cluster of compute hosts to deploy and manage containerized apps on IBM Cloud. Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management for your apps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-detailed-openshift"},{"document_id":"ibmcld_10407-7-1954","score":22.4561242792,"text":"\nService limitations \n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae and the Red Hat OpenShift open source project come with default service settings and limitations to ensure security, convenience, and basic functionality. Some limitations you might be able to change where noted.\n\nIf you anticipate reaching any of the following Red Hat OpenShift on IBM Cloud limitations, [contact IBM Support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar) and provide the cluster ID, the new quota limit, and the region in your support ticket.\n\n\n\n Service and quota limitations \n\nRed Hat OpenShift on IBM Cloud comes with the following service limitations and quotas that apply to all clusters, independent of what infrastructure provider you plan to use. Keep in mind that the [classic](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_limitationsclassic_limits) and [VPC](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_limitationsks_vpc_gen2_limits) cluster limitations also apply.\n\nTo view quota limits on cluster-related resources in your IBM Cloud account, use the ibmcloud oc quota ls command.\n\n\n\nRed Hat OpenShift on IBM Cloud limitations\n\n Category Description \n\n API rate limits 200 requests per 10 seconds to the Red Hat OpenShift on IBM Cloud API from each unique source IP address. \n App deployment The apps that you deploy to and services that you integrate with your cluster must be able to run on the operating system of the worker nodes. \n Container-native virtualization The Red Hat OpenShift [container-native virtualization add-on](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/about-virt.html) to run VM workloads alongside container workloads is not supported by IBM. If you choose to install the add-on yourself, you must use bare metal machines, not virtual machines. You are responsible for resolving any issues and impact to your workloads from using container-native virtualization.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_limitations"},{"document_id":"ibmcld_14682-7-2113","score":22.3489213114,"text":"\nVMware vCenter Server and Red Hat OpenShift architecture overview \n\nThe IBM Cloud\u00ae for VMware Solutions offering includes fully automated, rapid deployments of VMware\u00ae vCenter Server\u00ae. This offering complements the on-premises infrastructure and allows existing and future workloads to run on IBM Cloud without conversion by using the same tools, skills, and processes that are used on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud for VMware Solutions provides the capability to deploy a Red Hat OpenShift Cluster by using an automated deployment of the VMware Software Defined Data Center (SDDC) architecture. The Red Hat OpenShift Cluster on IBM Cloud components are deployed as virtual machines (VM) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThis reference architecture is for Red Hat OpenShift clusters deployed on a vCenter Server instance. It provides the foundation for customers who are starting their application modernization journey to the IBM Cloud.\n\n\n\n* vCenter Server is an offering from IBM Cloud for VMware Solutions and is a VMware-based platform that is automatically provisioned on IBM Cloud.\n* Red Hat OpenShift is an application platform for developing and managing containerized applications, which are deployed onto virtualized infrastructure platforms, such as VMware.\n\n\n\nZoom\n\n![IBM Cloud for VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. IBM Cloud for VMware Solutions and OpenShift\n\n\n\n Application modernization on IBM Cloud \n\nApplication modernization is a term that describes the process of transitioning existing applications to use new approaches on the cloud. Customers today are seeking innovative, efficient approaches that help them make this transition based on business and application complexity.\n\nBusiness pressures demand faster time to market.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro"}],"retriever_scores":{}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08867-20399-21926","score":22.7309697136,"text":"\n+-------------------------------------------+\nSubscription Name: 30 Day Self-Supported Red Hat OpenShift Container Platform, 2-Core Evaluation\nProvides: Red Hat Ansible Engine\nRed Hat Software Collections (for RHEL Server for IBM Power LE)\nRed Hat OpenShift Enterprise Infrastructure\nRed Hat JBoss Core Services\nRed Hat Enterprise Linux Fast Data path\nRed Hat OpenShift Container Platform for Power\nJBoss Enterprise Application Platform\n:\nRed Hat OpenShift Container Platform Client Tools for Power\nRed Hat Enterprise Linux Fast Datapath (for RHEL Server for IBM Power LE)\nRed Hat OpenShift Enterprise JBoss EAP add-on\nRed Hat OpenShift Container Platform\nRed Hat Gluster Storage Management Console (for RHEL Server)\nRed Hat OpenShift Enterprise JBoss A-MQ add-on\nRed Hat Enterprise Linux for Power, little endian Beta\nRed Hat OpenShift Enterprise Client Tools\n:\nRed Hat OpenShift Enterprise Application Node\n:\nRed Hat OpenShift Service Mesh\n:\nRed Hat OpenShift Enterprise JBoss FUSE add-on\nSKU: SER0419\nContract: 123456789\nPool ID: 1a2345bcd6789098765abcde43219bc3\nProvides Management: Yes\nAvailable: 10\nSuggested: 1\nService Level: Self-Support\nService Type: L1-L3\nSubscription Type: Stackable\nStarts: 12\/03\/2018\nEnds: 01\/02\/2019\nSystem Type: Physical\n7. Exit the secure shell to return to your OpenShift installation directory inside your container.\n\nexit\n\nExample output:\n\nlogout\nConnection to 169.47.XXX.XX closed.\n\/go\/bin\/terraform-ibm-openshift \n\n\n\n2. Finish setting up and registering the nodes with the Red Hat Network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-redhat"},{"document_id":"ibmcld_14491-1340-3282","score":22.6333557009,"text":"\nRed Hat OpenShift for VMware configuration \n\nWhen you order the service, you must provide a Red Hat\u00ae pull secret. This pull secret is used to associate the new Red Hat OpenShift cluster with your existing Red Hat account. You can obtain a copy of your pull secret by [logging in to your Red Hat account](https:\/\/cloud.redhat.com\/openshift\/install\/vsphere\/user-provisioned) and clicking Copy Pull Secret.\n\n\n\n\n\n Setting up DNS to access your Red Hat OpenShift console \n\nRed Hat OpenShift depends on DNS to function properly. The ocp wildcard zone in your VMware environment root zone resolves all names to the IP address of the Red Hat OpenShift cluster application. This way, all applications that run within Red Hat OpenShift are routed through the Load Balancer, as needed.\n\nBecause the Red Hat OpenShift web console runs as an application within Red Hat OpenShift, your system must properly resolve DNS names before you can connect to the Red Hat OpenShift web console. You must complete the following steps before you open the Red Hat OpenShift console:\n\n\n\n1. Ensure you are connected to your environment by using the IBM Cloud infrastructure VPN.\n2. Ensure the system that you use to connect to the Red Hat OpenShift web console can properly resolve hostnames in the DNS zone for your VMware environment. For an existing DNS infrastructure, configure the DNS delegation. Therefore, the queries for hostnames within the VMware instance's root zone are handled by the AD DNS server that is running within your VMware environment.\n\n\n\nAlternately, you can configure your local hosts file with the following entries so you can access the Red Hat OpenShift web console. Use the following details for the example.\n\n\n\n* Replace APPLICATION_IP with the Red Hat OpenShift application IP address shown in the Red Hat OpenShift service details page.\n* Replace ROOTDOMAIN with the root domain shown on the Summary page for the vCenter Server instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_ordering"},{"document_id":"ibmcld_10422-7-1877","score":22.4567985282,"text":"\nRed Hat OpenShift on IBM Cloud version information \n\nReview information about the supported Red Hat OpenShift versions for Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nView information of version changes for major, minor, and patch updates that are available for your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters. Changes include updates to Red Hat OpenShift, Kubernetes, and IBM Cloud Provider components.\n\nUnless otherwise noted in the change logs, the IBM Cloud provider version enables Red Hat OpenShift APIs and features that are at beta. Red Hat OpenShift alpha features, which are subject to change, are disabled.\n\nCheck the [Security Bulletins on IBM Cloud Status](https:\/\/cloud.ibm.com\/status?selected=security) for security vulnerabilities that affect Red Hat OpenShift on IBM Cloud. You can filter the results to view only Kubernetes Service security bulletins that are relevant to Red Hat OpenShift on IBM Cloud. Change log entries that address other security vulnerabilities but don't also refer to an IBM security bulletin are for vulnerabilities that are not known to affect Red Hat OpenShift on IBM Cloud in normal usage. If you run privileged containers, run commands on the workers, or execute untrusted code, then you might be at risk.\n\nMaster patch updates are applied automatically. Worker node patch updates can be applied by reloading or updating the worker nodes. For more information about major, minor, and patch versions and preparation actions between minor versions, see [Red Hat OpenShift versions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n\nFor more details about the Red Hat OpenShift and Kubernetes project versions, review the Red Hat OpenShift release notes.\n\n\n\n* [Red Hat OpenShift 4.13 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.13\/release_notes\/ocp-4-13-release-notes.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions"},{"document_id":"ibmcld_14492-10142-11408","score":22.4021032519,"text":"\n* If you are using a vSAN datastore, delete any persistent volumes that you no longer need before you uninstall Red Hat OpenShift. Any volumes that are not deleted will remain in the vSAN storage after the Red Hat OpenShift uninstallation.\n* Before you delete the service, you must remove any personal VMs that were deployed with this service, from the storage. Red Hat OpenShift only orders personal VMs if it\u2019s not vSAN.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [vCenter Server and Red Hat OpenShift architecture overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* [VMware Solutions and Red Hat OpenShift overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro)\n* [Red Hat OpenShift Container Platform 4.7 documentation](https:\/\/docs.openshift.com\/container-platform\/4.7\/welcome\/index.html)\n* [Red Hat OpenShift Container Platform 4.7 release notes](https:\/\/docs.openshift.com\/container-platform\/4.7\/release_notes\/ocp-4-7-release-notes.html)\n* [What's new in Red Hat OpenShift](https:\/\/www.openshift.com\/learn\/whats-new)\n* [Succeeding with Red Hat OpenShift and VMware\u2019s Software-Defined Datacenter (SDDC)](https:\/\/blog.openshift.com\/red-hat-openshift-and-vmware-better-together\/)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_overview"},{"document_id":"ibmcld_10702-7-1940","score":22.329426273,"text":"\nCreating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC) \n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nWith Red Hat OpenShift on IBM Cloud clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc).\n\n\n\n* Red Hat OpenShift on IBM Cloud gives you all the [advantages of a managed offering](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov) for your cluster infrastructure environment, while using the [Red Hat OpenShift tooling and catalog](https:\/\/docs.openshift.com\/container-platform\/4.11\/welcome\/index.html) that runs on Red Hat Enterprise Linux for your app deployments.\n* VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of Red Hat OpenShift on IBM Cloud [infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality.\n\n\n\nRed Hat OpenShift worker nodes are available for paid accounts and standard clusters only. You can create Red Hat OpenShift clusters that run version 4 only. The operating system is Red Hat Enterprise Linux 7.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create a Red Hat OpenShift on IBM Cloud cluster in a Virtual Private Cloud (VPC). Then, you access built-in Red Hat OpenShift components, deploy an app in a Red Hat OpenShift project, and expose the app on with a VPC load balancer so that external users can access the service.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in Red Hat OpenShift on IBM Cloud in VPC compute for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial"},{"document_id":"ibmcld_10422-1393-2886","score":22.3087410604,"text":"\nFor more information about major, minor, and patch versions and preparation actions between minor versions, see [Red Hat OpenShift versions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n\nFor more details about the Red Hat OpenShift and Kubernetes project versions, review the Red Hat OpenShift release notes.\n\n\n\n* [Red Hat OpenShift 4.13 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.13\/release_notes\/ocp-4-13-release-notes.html)\n* [Red Hat OpenShift 4.12 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.12\/release_notes\/ocp-4-12-release-notes.html)\n* [Red Hat OpenShift 4.11 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.11\/release_notes\/ocp-4-11-release-notes.html)\n* [Red Hat OpenShift 4.10 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.10\/release_notes\/ocp-4-10-release-notes.html)\n* [Red Hat OpenShift 4.9 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.9\/release_notes\/ocp-4-9-release-notes.html)\n* [Kubernetes change log](https:\/\/github.com\/kubernetes\/kubernetes\/tree\/master\/CHANGELOG)\n\n\n\n\n\n Available Red Hat OpenShift versions \n\nRed Hat OpenShift on IBM Cloud supports the following versions of Red Hat OpenShift. Note that different Red Hat OpenShift versions might support different RHEL versions.\n\nDates that are marked with a dagger (\u2020) are tentative and subject to change.\n\nRHEL 7 is deprecated and becomes unsupported soon.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions"},{"document_id":"ibmcld_07968-7-1612","score":22.2712277895,"text":"\nWorking with Red Hat OpenShift on IBM Cloud \n\nIf you want to use containers in either either the VPC or Satellite reference architectures, you should use [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview). Red Hat OpenShift on IBM Cloud is a managed offering to create your own Red Hat OpenShift on IBM Cloud cluster of compute hosts to deploy and manage containerized apps on IBM Cloud. Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management for your apps. Combined with an intuitive user experience, built-in security and isolation, and advanced tools to secure, manage, and monitor your cluster workloads, you can rapidly deliver highly available and secure containerized apps in the public cloud.\n\n\n\n Deploying Red Hat OpenShift on IBM Cloud \n\n\n\n1. Install the CLI plugins for Red Hat OpenShift on IBM Cloud. For more information, see [Installing the Red Hat OpenShift on IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-containers-openshift).\n2. Setup the API for Red Hat OpenShift on IBM Cloud. For more information, see [Setting up the API](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_api_install).\n3. Create your Red Hat OpenShift on IBM Cloud cluster. For more information, see [Creating a Red Hat OpenShift on IBM Cloud cluster in your VPC](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial).\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-containers-openshift"},{"document_id":"ibmcld_14497-11060-12784","score":22.2453149488,"text":"\nThe NSX DLR virtual machines are configured as an active - passive pair, and vSphere Distributed Resource Scheduler (DRS) anti-affinity rules are created to ensure that the DLR VMs do not run on the same host. This step is described in [Red Hat OpenShift NSX DLR configuration](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-nsxdlr-intro).\n* Update DNS - The infrastructure DNS, provisioned with the vCenter Server instance is updated with the names and IP addresses for the Red Hat OpenShift components by using a PowerShell script. This step is described in [VMware Solutions DNS configuration](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-dns-intro).\n\n\n\n* Phase 2 - Red Hat OpenShift installation. These steps are described in [Red Hat OpenShift 4.7 user provider infrastructure installation](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-install-intro).\n\n\n\n* A Red Hat virtual machine, the bastion node, is provisioned to run the Red Hat OpenShift installer and to host an HTTP Server. It is registered with Red Hat by using your subscription, and the Red Hat OpenShift installer is downloaded.\n* On the bastion node, the install-config.yaml file is populated with the required Red Hat OpenShift parameters and Red Hat OpenShift ignition is used to generate a number of files used for the installation of the bootstrap, control plane, and worker machines.\n* Terraform, on the bastion node, uses the files that are created by Ignition to create the Red Hat OpenShift VMs.\n\n\n\n* Phase 3 - Post deployment activities. Configure a persistent volume for use by the Red Hat OpenShift cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_14492-7-1792","score":22.2375319549,"text":"\nRed Hat OpenShift for VMware overview \n\nThe Red Hat\u00ae OpenShift\u00ae for VMware\u00ae service deploys an Red Hat OpenShift cluster by using an automated deployment of the VMware SDDC (Software Defined Data Center) architecture. The Red Hat OpenShift components are deployed as virtual machines (VMs) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThe Red Hat OpenShift version available for deployment is 4.12.\n\nReview the following information before you install the Red Hat OpenShift for VMware service:\n\n\n\n* Red Hat OpenShift for VMware cannot be installed on multiple VMware vCenter Server\u00ae instances in a multisite configuration. Before you install Red Hat OpenShift for VMware on an instance, verify that the service is not installed on any other instances in the multisite configuration.\n* Red Hat OpenShift for VMware is supported for vCenter Server instances with VMware vSphere\u00ae 7.0 and VMware NSX-T\u2122 3.1 or later.\n* Red Hat OpenShift for VMware is not supported for new deployments or for ordering post-deployment for vCenter Server with NSX-V instances with vSphere 6.7.\n\n\n\nExisting installations of Red Hat OpenShift for VMware can be used or deleted for vSphere 6.7 instances.\n\nIBM Cloud\u00ae for VMware Solutions offers promotions for some services. Promotional pricing offers a number of months without charge for a service licenses, if the service has license charges. For more information, see [Promotions for VMware Solutions services](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_addingservicesvc_addingservices-service-promotions).\n\nThe cluster consists of the following components:\n\n\n\n* Three primary nodes\n* Three worker nodes, all running Red Hat\u00ae CoreOS\n* Two VMware NSX\u00ae VMs\n* A Red Hat CoreOS template\n* A bastion VM running CoreOS","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_overview"},{"document_id":"ibmcld_10203-7-1859","score":22.2240049173,"text":"\nDeploying apps in Red Hat OpenShift clusters \n\nWith Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters, you can deploy apps from a remote file or repository such as GitHub with a single command. Also, your clusters come with various built-in services that you can use to help operate your cluster.\n\n\n\n Moving your apps to Red Hat OpenShift \n\nTo create an app in your Red Hat OpenShift on IBM Cloud cluster, you can use the Red Hat OpenShift console or CLI.\n\nSeeing errors when you deploy your app? Red Hat OpenShift has different default settings than community Kubernetes, such as stricter security context constraints. Review the [common scenarios where you might need to modify your apps](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_deployopenshift_move_apps_scenarios) so that you can deploy them on Red Hat OpenShift clusters.\n\n\n\n Deploying apps through the console \n\nYou can create apps through various methods in the Red Hat OpenShift console by using the Developer perspective. For more information, see the [Red Hat OpenShift documentation](https:\/\/docs.openshift.com\/container-platform\/4.11\/applications\/creating_applications\/odc-creating-applications-using-developer-perspective.html).\n\n\n\n1. From the [Red Hat OpenShift clusters console](https:\/\/cloud.ibm.com\/kubernetes\/clusters?platformType=openshift), select your cluster.\n2. Click Red Hat OpenShift web console.\n3. From the perspective switcher, select Developer. The Red Hat OpenShift web console switches to the Developer perspective, and the menu now offers items such as +Add, Topology, and Builds.\n4. Click +Add.\n5. In the Add pane menu bar, select the Project that you want to create your app in from the drop-down list.\n6. Click the method that you want to use to add your app, and follow the instructions. For example, click From Git.\n\n\n\n\n\n\n\n Deploying apps through the CLI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy_app"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10154-1411-3594","score":33.4309903313,"text":"\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud. For more information, see Comparison between [Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes) and community Kubernetes clusters.\n\nSingle-tenant Kubernetes clusters with compute, network, and storage infrastructure isolation\n: Create your own customized infrastructure that meets the requirements of your organization.\n: Choose between [IBM Cloud Classic or VPC infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers).\n: Provision a dedicated and secured Red Hat OpenShift master, worker nodes, virtual networks, and storage by using the resources provided by IBM Cloud infrastructure.\n: Fully managed Kubernetes master that is continuously monitored and updated by IBM to keep your cluster available.\n: Option to provision worker nodes as bare metal servers for compute-intensive workloads such as data, GPU, and AI.\n: Store persistent data, share data between Kubernetes pods, and restore data when needed with the integrated and secure volume service.\n: Benefit from full support for all native Kubernetes APIs.\n\nMultizone clusters to increase high availability\n: Easily manage worker nodes of the same flavor (CPU, memory, virtual or physical) with worker pools.\n: Guard against zone failure by spreading nodes evenly across select multizones and by using anti-affinity pod deployments for your apps.\n: Decrease your costs by using multizone clusters instead of duplicating the resources in a separate cluster.\n: Benefit from automatic load balancing across apps with the multizone load balancer (MZLB) that is set up automatically for you in each zone of the cluster.\n\nHighly available masters","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_10214-7-1980","score":33.1634228307,"text":"\nFAQs \n\nReview frequently asked questions (FAQs) for using Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae.\n\n\n\n How does Red Hat OpenShift on IBM Cloud work? \n\nWith Red Hat OpenShift on IBM Cloud, you can create your own Red Hat OpenShift cluster to deploy and manage containerized apps on IBM Cloud. Your containerized apps are hosted on IBM Cloud infrastructure compute hosts that are called worker nodes. You can choose to provision your compute hosts as [virtual machines](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesvm) with shared or dedicated resources, or as [bare metal machines](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesbm) that can be optimized for GPU and software-defined storage (SDS) usage. Your worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n\n\n\n\n\n Why should I use Red Hat OpenShift on IBM Cloud? \n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_10531-7-2246","score":31.9404737701,"text":"\nRed Hat OpenShift on IBM Cloud partners \n\nTo provide you with all the capabilities that you need to run production workloads in the cloud, Red Hat OpenShift on IBM Cloud partners with other third-party service providers to enhance your cluster with logging, monitoring, and storage tools.\n\nReview the list of partners and the benefits of each solution that they provide. To find other proprietary IBM Cloud and third-party open source services that you can use in your cluster, see [Understanding IBM Cloud and 3rd party integrations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ibm-3rd-party-integrations).\n\n\n\n Portworx \n\n[Portworx](https:\/\/portworx.com\/products\/portworx-enterprise\/\/) is a highly available software-defined storage solution that you can use to manage local persistent storage for your containerized databases and other stateful apps, or to share data between pods across multiple zones.\n\nAn software defined storage (SDS), such as Portworx, solution abstracts storage devices of various types, sizes, or from different vendors that are attached to the worker nodes in your cluster. Worker nodes with available storage on hard disks are added as a node to a storage cluster. In this cluster, the physical storage is virtualized and presented as a virtual storage pool to the user. The storage cluster is managed by the SDS software. If data must be stored on the storage cluster, the SDS software decides where to store the data for highest availability. Your virtual storage comes with a common set of capabilities and services that you can leverage without caring about the actual underlying storage architecture.\n\n\n\n Benefits \n\nReview the following table to find a list of key benefits that you can get by using Portworx.\n\n\n\nBenefits of using Portworx\n\n Benefit Description \n\n Cloud native storage and data management for stateful apps Portworx aggregates available local storage that is attached to your worker nodes and that can vary in size or type, and creates a unified persistent storage layer for containerized databases or other stateful apps that you want to run in the cluster. By using Kubernetes persistent volume claims (PVC), you can add local persistent storage to your apps to store your data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-partners"},{"document_id":"ibmcld_07578-394005-396150","score":31.7062294984,"text":"\nYour worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n* Why should I use Red Hat OpenShift on IBM Cloud?\n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-393979-396124","score":31.7062294984,"text":"\nYour worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n* Why should I use Red Hat OpenShift on IBM Cloud?\n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_10170-12206-14575","score":31.5174219742,"text":"\nDevelopers don't need to become experts in cloud security, they can enforce policy driven authentication easily by using IBM Cloud App ID.\n\nWith Red Hat OpenShift on IBM Cloud, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the HR site, they could easily design Kubernetes clusters to fit their CPU, RAM, and storage needs. Another factor for less personnel costs is that IBM manages Kubernetes, so the Developers can focus on delivering better employee experience for benefits enrollment.\n\nRed Hat OpenShift on IBM Cloud provides scalable compute resources and the associated DevOps dashboards to create, scale, and tear down apps and services as needed. Using industry-standard containers technology apps can be quickly developed and shared across multiple Development, Test, and Production environments. This setup provides the immediate benefit of scalability. Using Kubernetes rich set of deployment and runtime objects, the HR team can monitor and manage upgrades to apps reliably. They can also replicate and scale the apps, by using defined rules and the automated Kubernetes orchestrator.\n\n\n\n Step 1: Containers, microservices, and the Garage Method \n\n\n\n* Apps are built in a set of cooperative microservices that run in Red Hat OpenShift on IBM Cloud. The architecture represents the functional areas of the app with the most quality problems.\n* Deploy apps to container in Red Hat OpenShift on IBM Cloud, continuously scanned with IBM Vulnerability Advisor.\n* Provide standardized DevOps dashboards through Kubernetes.\n* Adopt the essential agile and iterative development practices within the IBM Garage Method to enable frequent releases of new functions, patches, and fixes without downtime.\n\n\n\n\n\n\n\n Step 2: Connections to existing benefits back-end \n\n\n\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae is used to create a secure tunnel to on-premises systems that host the benefits systems.\n* Combination of on-premises data and Red Hat OpenShift on IBM Cloud lets them access sensitive data while they adhere to regulations.\n* Chatbot conversations fed back into HR policies, allowing the benefits site to reflect which benefits were most and least popular, including targeted improvements to poorly performing initiatives.\n\n\n\n\n\n\n\n Step 3: Chatbot and personalization","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_transport"},{"document_id":"ibmcld_05707-7-2073","score":31.4055015535,"text":"\nBenefits and service offerings \n\n[IBM Cloud\u00ae Kubernetes Service](https:\/\/www.ibm.com\/cloud\/kubernetes-service) delivers powerful tools by combining Docker containers, the Kubernetes technology, an intuitive user experience, and built-in security and isolation to automate the deployment, operation, scaling, and monitoring of containerized apps in a cluster of compute hosts. For more information about certification, see [Compliance on the IBM Cloud](https:\/\/www.ibm.com\/cloud\/compliance).\n\n\n\n Benefits of using the service \n\nClusters are deployed on compute hosts that provide native Kubernetes and IBM-specific capabilities.\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud. For more information, see Comparison between [Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovopenshift_kubernetes) and community Kubernetes clusters.\n\nSingle-tenant Kubernetes clusters with compute, network, and storage infrastructure isolation\n: Create your own customized infrastructure that meets the requirements of your organization.\n: Choose between [IBM Cloud Classic or VPC infrastructure providers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers).\n: Provision a dedicated and secured Kubernetes master, worker nodes, virtual networks, and storage by using the resources provided by IBM Cloud infrastructure.\n: Fully managed Kubernetes master that is continuously monitored and updated by IBM to keep your cluster available.\n: Option to provision worker nodes as bare metal servers for compute-intensive workloads such as data, GPU, and AI.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ov"},{"document_id":"ibmcld_10154-7-1896","score":31.2908856429,"text":"\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https:\/\/www.ibm.com\/products\/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_10534-1033-2260","score":31.0071641579,"text":"\n[Understanding Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewoverview)\n\n\n\n* [What is Red Hat OpenShift on IBM Cloud and how does it work?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-overview)\n* [What is Kubernetes?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-kube-overview)\n* [What are containers?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-are-containers-overview)\n* [What is Red Hat OpenShift?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-openshift-overview)\n* [What compute host infrastructure does the service offer?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-compute-infra-is-offered)\n* [Related resources](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewkubernetes-resources)\n\n\n\n[Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovcs_ov)\n\n\n\n* [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits)\n* [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_10534-1903-3343","score":30.8929534884,"text":"\n[Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovcs_ov)\n\n\n\n* [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits)\n* [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes)\n* [Comparison between clusters that run in IBM Cloud and standard OCP](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovcompare_ocp)\n\n\n\n[Supported infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersinfrastructure_providers)\n\n\n\n* [Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersvpc-gen2-infra-overview)\n* [Satellite](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providerssatellite-infra-overview)\n* [Classic](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersclassic-infra-overview)\n* [Troubleshooting and support](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersinfra-troubleshoot)\n\n\n\n[Your responsibilities with using Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-responsibilities_iksresponsibilities_iks)\n\n\n\n* [Overview of shared responsibilities](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-responsibilities_iksoverview-by-resource)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08206-0-2461","score":19.9830208676,"text":"\n\n\n\n\n\n\n  Hyper Protect Virtual Servers overview \n\nHyper Protect Virtual Servers is an IBM Cloud\u00ae service that provides highly secure virtual servers that can run Linux applications and containerized workloads. It offers a flexible and scalable framework that you can use to quickly and easily provision and manage the created virtual servers.\n\nFor more information about how to get started, take a look at the [tutorial](https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-getting-started).\n\n\n\n  Why IBM Cloud Hyper Protect Virtual Servers? \n\nHyper Protect Virtual Servers offers the following benefits:\n\n\n\n*  Security -\n\n\n\nUsing Hyper Protect Virtual Servers, you can deploy a virtual server in a Secure Service Container, which ensures confidentiality of your data and code that you run within the virtual server. No external access to your data is allowed, including privileged users such as cloud administrators.\n\n\n\n*  IBM Z capabilities on the cloud -\n\n\n\nHyper Protect Virtual Servers brings IBM Z capabilities into the cloud, from where you can use them to deploy workload into the most secure, highly performant Linux virtual server.\n\n\n\n*  No IBM Z hardware and skills required -\n\n\n\nBy deploying Hyper Protect Virtual Servers, you can access IBM Z technology without having to purchase, install, and maintain the required hardware.\n\n\n\n*  Easy to use, open, and flexible -\n\n\n\nEmbracing the openness and flexibility of a public cloud, Hyper Protect Virtual Servers offers user experience at parity with market leaders who apply IBM Z capabilities in an enterprise environment.\n\n\n\n\n\n  Key features \n\nHyper Protect Virtual Servers makes it possible to bring IBM Z into IBM\u2019s global public cloud data centers. Through the IBM Cloud catalog, you can gain access to industry-leading security capabilities to modernize your applications in the IBM Cloud.\n\n\n\n*  You can run both core and non-core workloads in a public cloud, observing all security and compliance policies of your enterprise.\n*  You can protect the assets of business while you simultaneously maintain enhanced business service levels.\n*  You can instantiate Linux virtual servers with your own public SSH key. Thus, only you can access your code and data. Not even an IBM Cloud administrator has access to your data.\n*  You can deploy any supported workload into the most secure, highly performant Linux system, taking advantage of strengths of the LinuxONE system.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-overview"},{"document_id":"ibmcld_14605-2659-4584","score":18.4914059813,"text":"\nIn this method, the existing instance and the new target instance have different data stores. When you migrate, you must take this issue into account, which also applies when you are using IBM Cloud File Storage. Plan the storage migration as part of the migration process.\n\nIt is possible to manually add and allow the existing IBM Cloud File Storage volumes to be accessible to the new vCenter Server with NSX-T instance. However, it is not generally advised leaving the volumes accessible for a longer period. The vCenter Server with NSX-T instance's automation is not aware of the old and manually added storage, and when you add new hosts and clusters to the new instance you might see unwanted behavior and the new hosts might not have access to this data store.\n\n\n\n\n\n Migrating workloads with Veeam \n\nvCenter Server offers an optional service for Veeam. The Veeam service seamlessly integrates directly with your VMware\u00ae hypervisors and you control both the backup and restore of all virtual machines (VMs) for your infrastructure directly from the Veeam console.\n\nThe current Veeam version that is installed by automation is Veeam Backup and Replication 12, but you might have an older version in your NSX-V based deployment. You can use Veeam's replication capabilities during the migration.\n\nFor more information, see [Ordering services for vCenter Server instances](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_addingservices) and [Veeam technical documentation](https:\/\/www.veeam.com\/documentation-guides-datasheets.html?ad=in-text-link).\n\n\n\n\n\n Migrating workloads with Zerto \n\nvCenter Server instances offer an optional service for Zerto. The Zerto service integrates replication and disaster recovery capabilities into the deployment offerings to protect and recover data in your VMware virtual environment on IBM Cloud.\n\nYou can use Zerto's replication capabilities during the migration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-v2t-l2-nsx-t"},{"document_id":"ibmcld_10885-20578-22292","score":18.0161238008,"text":"\nVirtual Servers and Bare Metal Servers offer the capability to achieve a multi-region architecture. You can provision servers in multiple locations on IBM Cloud.\n\nZoom\n\n![Server locations](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/adcecdbe4e86955f88aac7f3c1e7ec3ff44992ef\/overview\/images\/ServersLocation.png)\n\nFigure 11. Server locations\n\nWhen preparing for such architecture using Virtual Servers and Bare Metal Servers, consider the following: file storage, backups, recovery, and databases, selecting between a database as service, or installing a database on a virtual server.\n\nThe following architecture demonstrates the deployment of a multi-region architecture using Virtual Servers in an active\/passive architecture where one region is active and the second region is passive.\n\nZoom\n\n![VM Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/adcecdbe4e86955f88aac7f3c1e7ec3ff44992ef\/overview\/images\/BCDR-Architecture-Diagram-2.svg)\n\nFigure 12. VM architecture\n\nThe components that are required for such architecture are as follows:\n\n\n\n1. Users access the application through IBM Cloud Internet Services (CIS).\n2. CIS routes traffic to the active location.\n3. Within a location, a load balancer redirects traffic to a server.\n4. Databases are deployed on a virtual server. Backup is enabled and replication is set up between regions. The alternative would be to use a database-as-service, a topic discussed later in the tutorial.\n5. IBM Cloud File Storage for Classic to store the application images and files, File Storage for Classic offers the capability to take a snapshot at a given time and date, this snapshot then can be reused within another region, something that you would do manually.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-bcdr-app-recovery"},{"document_id":"ibmcld_11618-9058-10724","score":17.7117995935,"text":"\n* [IBM Power Virtual Server certified profiles for SAP HANA](https:\/\/cloud.ibm.com\/docs\/sap\/?topic=sap-hana-iaas-offerings-profiles-power-vs)\n* [VMware SDDC certified profiles for SAP HANA](https:\/\/cloud.ibm.com\/docs\/sap\/?topic=sap-hana-iaas-offerings-profiles-vmware)\n\n\n\n* SAP NetWeaver profiles\n\n\n\n* [Intel Bare Metal server certified profiles for SAP NetWeaver](https:\/\/cloud.ibm.com\/docs\/sap\/?topic=sap-nw-iaas-offerings-profiles-intel-bm)\n* [Intel Virtual Server certified profiles for SAP NetWeaver](https:\/\/cloud.ibm.com\/docs\/sap\/?topic=sap-nw-iaas-offerings-profiles-intel-vs-vpc)\n* [IBM Power Virtual Server certified profiles for SAP NetWeaver](https:\/\/cloud.ibm.com\/docs\/sap\/?topic=sap-nw-iaas-offerings-profiles-power-vs)\n* [VMware SDDC certified profiles for SAP NetWeaver](https:\/\/cloud.ibm.com\/docs\/sap\/?topic=sap-nw-iaas-offerings-profiles-vmware)\n\n\n\n\n\n\n\n Distributing your SAP Landscape on IBM Cloud Bare Metal and Virtual Servers \n\nGenerally, the entire infrastructure for the operation of all closely coupled runtime components of an SAP software solution must be installed on either Intel Virtual Servers (Gen2) or on Bare Metal Servers from IBM Cloud.\n\nTo assist customers looking to combine performance for the database and flexibility for the application solution\/s, testing has been performed when combining environments and networks.\n\nIntel Bare Metal Servers from IBM Cloud in the IBM Cloud Classic Infrastructure environment may offer greater performance capabilities. Notably this includes larger memory, local SSD storage in RAID arrays, access to IPMI, and more. Intel Virtual Servers (Gen2), on the other hand provide more flexibility.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-planning-your-system-landscape"},{"document_id":"ibmcld_14884-7-2123","score":17.3616765762,"text":"\nAbout virtual server instances for VPC \n\nIBM Cloud\u00ae Virtual Servers for Virtual Private Cloud is an Infrastructure-as-a-Service (IaaS) offering that gives you access to all of the benefits of IBM Cloud VPC, including network isolation, security, and flexibility.\n\nWith virtual server instances for VPC, you can quickly provision instances with high network performance. When you provision an instance, you select a profile that matches the amount of memory and compute power that you need for the application that you plan to run on the instance. Instances are available on the x86 architecture. After you provision an instance, you control and manage those infrastructure resources.\n\n\n\n How are virtual server instances for VPC different from other IBM virtual server offerings? \n\nIn the IBM Cloud Virtual Servers for Classic infrastructure offering, instances use native subnet and VLAN networking to communicate to each other within a data center (and single pod). Using subnet and VLAN networking in one pod works well until you must scale up or have large virtual resource demands that require resources to be created between pods. (Adding appliances for VLAN spanning can get expensive and complicated!)\n\nIBM Cloud VPC adds a network orchestration layer that eliminates the pod boundary, creating increased capacity for scaling instances. The network orchestration layer handles all of the networking for all virtual server instances that are within a VPC across regions and zones. With the software-defined networking capabilities that VPC provides, you have more options for multi-vNIC instances and larger subnet sizes.\n\nTo review and start deploying compute resources, see the following topics:\n\n\n\nTable 1. Deployment options\n\n Deployment options Description \n\n [Virtual Servers for VPC profiles](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-profilesprofiles) IBM Cloud Virtual Servers for VPC provide the advanced security of a private cloud with the agility and ease of a public cloud. Virtual servers for VPC offer the best network performance (up to 80 Gbps), best security, and fastest provisioning times.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-advanced-virtual-servers&interface=ui"},{"document_id":"ibmcld_11599-7-1873","score":17.2123753824,"text":"\nIBM Power Virtual Server certified profiles for SAP HANA \n\nWhen you provision IBM Power Virtual Servers, you can select from the following families of profiles: [Small](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-hana-iaas-offerings-profiles-power-vssmall), [Balanced](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-hana-iaas-offerings-profiles-power-vsbalanced), [Compute Intensive](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-hana-iaas-offerings-profiles-power-vscomputeintensive), [Ultra Memory](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-hana-iaas-offerings-profiles-power-vsumemory), and [High Memory](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-hana-iaas-offerings-profiles-power-vshmemory).\n\nCertified profiles for SAP HANA are a complementary offering from IBM Power Systems, with low latency access to IBM Cloud services\n\nA profile is a combination of instance attributes, such as the number of vCPUs, amount of RAM, and network bandwidth. The attributes define the size and capabilities of the virtual server instance that is provisioned. You can select the most recently used profile or click View All Profiles to choose the profile that best fits your needs.\n\n\n\n Profile families \n\nThe published names are subject to change.\n\nThe following section provides an overview of the SAP-certified profiles with IBM Power Virtual Servers and available profile families.\n\n\n\n Families Description \n\n [Custom](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-hana-iaas-offerings-profiles-power-vscustom) Custom profiles are for nonproduct development for testing or development use only. These profiles are not intended for production deployments and are not supported or certified for SAP production. \n [Small](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-hana-iaas-offerings-profiles-power-vssmall) Small profiles are best for balanced workloads that require less CPU and storage consumption.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-hana-iaas-offerings-profiles-power-vs"},{"document_id":"ibmcld_14301-7-1914","score":17.110365001,"text":"\nZerto on IBM Cloud overview \n\nZerto on IBM Cloud integrates replication and disaster recovery capabilities into the deployment offerings to protect and recover data in your VMware\u00ae virtual environment on IBM Cloud\u00ae. Zerto on IBM Cloud is a non-IBM product that is offered under terms and conditions from Zerto, not IBM.\n\nZerto is supported on VMware vCenter Server\u00ae instances that meet the following requirements:\n\n\n\n* VMware NSX-T\u2122 3.1 or later\n* VMware vSphere\u00ae 7.0\n\n\n\nIBM Cloud\u00ae for VMware Solutions offers promotions for some add-on services. Promotional pricing offers a number of months without charge for a service license, if the service has license charges. For more information, see [Promotions for VMware Solutions add-on services](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_addingservicesvc_addingservices-service-promotions).\n\nThe Zerto version available for deployment is 9.7u3.\n\n\n\n Before you begin \n\n\n\n* Ensure that your IBM Cloud account is a billable account, and that it is linked to the IBM Cloud infrastructure account where your instance is deployed. For more information, see [Billing for Zerto replication](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-zerto_orderingzerto_ordering-billing).\n* This service is available only to instances that are deployed in V1.2 or later.\n\n\n\n\n\n\n\n Technical specifications for Zerto \n\nFor more information about resource requirements and capacity checking for some services, see [Resource requirements for services](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_addingservicesvc_addingservices-resource-requirements).\n\nThe following components are ordered and included in the Zerto service.\n\nZerto Virtual Replication Appliance (VRA) components are deployed only into the default cluster.\n\n\n\n Virtual Service Instances \n\n\n\n* One Virtual Service Instance (VSI) - Zerto Virtual Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-addingzertodr"},{"document_id":"ibmcld_14400-7-2130","score":16.9971311274,"text":"\nFortinet FortiGate virtual machine (VM) overview \n\nIBM Cloud\u00ae for VMware Solutions offers various solutions to meet your network security requirements. The base offering includes VMware NSX\u2013T\u2122 for integrated virtual networking and security. More network security features are available with the FortiGate\u00ae VM offering, which provides Fortinet\u00ae\u2019s next\u2013generation firewall (NGFW) capabilities in the form of a highly available pair of virtual FortiGate appliances. In addition to the architecture for FortiGate VM, IBM Cloud\u00ae also offers a [FortiGate Security Appliance](https:\/\/cloud.ibm.com\/docs\/fortigate-10g) offering, which provides a perimeter firewall, NAT, and VPN services in the form of a physical appliance.\n\nThe solution is considered to be an extra component and extension of the VMware vCenter Server\u00ae offering on IBM Cloud. As a result, this document doesn\u2019t cover the existing configuration of the foundation solutions on IBM Cloud. For more information about the foundation solution architecture, see [Overview of VMware Solutions](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-solution_overview).\n\n\n\n Topologies \n\nYou can deploy FortiGate VM according to several different strategies:\n\n\n\n* FortiGate VM can be deployed as part of an ESXi\u2122 gateway cluster that is directly integrated with the IBM Cloud customer routers. It provides firewall and gateway functions for your private and public IBM Cloud network VLANs.\n* FortiGate VM can be deployed to your management and workload cluster. In this form, you can use FortiGate to provide firewall and gateway services between various networks. FortiGate VM provides controlled connectivity between:\n\n\n\n* Public and private networks\n* Private VLANs and NSX logical switches\n* Several VMware NSX\u00ae logical switches\n\n\n\n\n\nAdditionally, FortiGate VM offers direct integration with NSX\u2013T including service chaining and dynamic import of security groups.\n\n\n\n\n\n Key benefits \n\nSeveral licensing option bundles are available for FortiGate VM on IBM Cloud.\n\n\n\n* Standard FW - This bundle includes the following services.\n\n\n\n* Stateful packet inspection","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-fortigate-overview"},{"document_id":"ibmcld_11584-7-1950","score":16.9902253676,"text":"\nFast Path of IBM Cloud Intel Virtual Servers \n\nThis page is a collection of shortcuts to the documentation sections for each offering, excluding general information that applies to all offerings, such as SAP Sizing.\n\nUse the links in this section to quickly access relevant documents that you are already familiar with.\n\n\n\n Learn \n\nAn Infrastructure-as-a-Service (IaaS) environment consists primarily of compute, storage, and network components from a specified region (such as the US) and a designated site location (also referred to as zone, which is a data center site). For more information:\n\n\n\n* [IBM Cloud VPC Infrastructure environment introduction](https:\/\/cloud.ibm.com\/ddocs\/sap?topic=sap-vpc-env-introduction)\n\n\n\nCertified Infrastructure-as-a-Service for SAP HANA database server is available in many variations, each with different capabilities and sizes to fit many different SAP workload scenarios. For more information:\n\n\n\n* [Infrastructure certified for SAP - IBM Intel Virtual Server](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-iaas-offeringsiaas-intel-vs)\n\n\n\nThe following is an overview of the SAP-certified profiles with IBM Power Virtual Servers for SAP HANA and SAP NetWeaver. For more information:\n\n\n\n* [IBM Cloud Intel Virtual Server certified profiles for SAP HANA](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-hana-iaas-offerings-profiles-intel-vs-vpc)\n* [IBM Cloud Intel Virtual Server certified profiles for SAP NetWeaver](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-nw-iaas-offerings-profiles-intel-vs-vpc)\n* [Compute Profiles of SAP-certified IBM Cloud Intel Virtual Server](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-compute-os-design-considerationscompute-vs-vpc)\n\n\n\nYour business and functional requirements determine the SAP solutions powered by the SAP HANA Database Server or SAP NetWeaver Application Server, and therefore determine how your applications are run in the available infrastructure. For more information:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-fast-path-site-map-intel-vs-gen2"},{"document_id":"ibmcld_11585-7-1915","score":16.8915140234,"text":"\nFast Path of IBM Power Virtual Servers \n\nUse this collection of shortcuts to quickly access relevant documentation for each offering, excluding general information that applies to all offerings, such as SAP Sizing.\n\n\n\n Learn \n\nAn Infrastructure-as-a-Service (IaaS) environment consists primarily of compute, storage, and network components from a specified region (such as the US) and a designated zone and or data center. For more information, see [IBM Power Systems Infrastructure environment introduction](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-power-env-introduction).\n\nCertified IaaS for SAP HANA database server is available in many variations. Each variation has different capabilities and sizes to fit different SAP workload scenarios. For more information, see [Infrastructure that is certified for SAP - IBM Power Virtual Server](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-iaas-offeringsiaas-power-vs).\n\nThe following links give an overview of the SAP-certified profiles with IBM Power Virtual Servers for SAP HANA and SAP NetWeaver.\n\n\n\n* [IBM Power Virtual Server certified profiles for SAP HANA](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-hana-iaas-offerings-profiles-power-vs)\n* [IBM Power Virtual Server certified profiles for SAP NetWeaver](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-nw-iaas-offerings-profiles-power-vs)\n* [Compute Profiles of SAP-certified IBM Power Virtual Servers](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-compute-os-design-considerationscompute-power)\n\n\n\nYour specific requirements determine the SAP solutions that are powered by the SAP HANA Database Server or SAP NetWeaver Application Server and determine how your applications run in the available infrastructure. For more information, see the following links.\n\n\n\n* [Mapping CPUs derived from SAPS to an IBM Power Virtual Server](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-planning-your-system-landscapeselecting-iaas-power)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-fast-path-site-map-power-vs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14459-7-2518","score":27.2654315403,"text":"\nIBM Security Services for SAP on IBM Cloud overview \n\nIBM Security Services for SAP\u00ae on IBM Cloud offer a cybersecurity solution to automate the monitoring and protection of SAP applications on IBM Cloud, and to keep workloads compliant and secure from inside and outside threats. IBM Security Services for SAP on IBM Cloud is a non-IBM product that is offered under terms and conditions from Entrust and Intel, not IBM.\n\nThese services, developed between IBM Security and Onapsis (an IBM Business Partner), are designed to implement and configure Onapsis specifically to your environment requirements for continuous workload visibility and protection.\n\nThrough continuous monitoring, the Onapsis Security Platform delivers a near real-time, preventive, detective, and corrective solution for securing SAP systems and applications. The Onapsis Security Platform provides unmatched coverage and protection with context-aware insight across SAP NetWeaver ABAP, Java\u00ae Platform, Enterprise Edition, and HANA platforms. The platform integrates with network security, security management, and associated workflows.\n\n\n\n Technical specifications for IBM Security Services for SAP \n\nIBM Security Services for SAP offer the following features:\n\n\n\n* Comprehensive understanding of vulnerabilities and potential attack vectors.\n* Methods to implement and avoid defects in ABAP code or SAP Transports.\n* Identifying configuration vulnerabilities for ABAP, Java\u00ae, and HANA environments.\n* Identifying missing or outdated SAP notes and patches.\n* Identifying, monitoring and review of highly privileged SAP accounts.\n* Enabling continuous monitoring of vulnerabilities with integration to existing SIEM solution.\n\n\n\n\n\n\n\n Key benefits of IBM Security Services for SAP \n\nYou can expect the following benefits when you request IBM Security Services for SAP:\n\n\n\n* Consultative engagement methods centered on your business objectives.\n* Experienced end-to-end architectural experts that work jointly with the IBM Cloud team.\n* Accelerated cloud adoption for successful implementation of SAP workloads on the cloud.\n* Prescriptive best practices for solution implementation by using IBM Cloud Services products and features.\n* Rapid learning and risk mitigation through access to IBM Cloud experts.\n\n\n\n\n\n\n\n Procedure to request IBM Security Services for SAP \n\n\n\n1. In the IBM Cloud for VMware Solutions console, scroll down to the services section and click IBM Security Services for SAP in the Featured workload solutions category.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-managing-ss-sap"},{"document_id":"ibmcld_05727-8804-11229","score":24.8664731404,"text":"\n* Shipping customers have real-time access to shipments\u2019 locations, delivery schedules, and even approved port records.\n* Transit partners at various shipping terminals are aware of manifests and shipment details so that onsite logistics are improved, instead of delayed.\n\n\n\n\n\n\n\n\n\n Airline delivers innovative Human Resources (HR) benefits site in under 3 weeks \n\nAn HR Exec (CHRO) needs a new HR benefits site with an innovative chatbot, but current Development tools and platform mean long lead times for apps to go live. This situation includes long waits for hardware procurement.\n\nIBM Cloud Kubernetes Service provides easy spin-up of compute. Then, Developers can experiment easily, pushing changes to Development and Test systems quickly with open toolchains. Their traditional software development tools get a boost when they add on IBM Watson Assistant. The new benefits site was created in less than 3 weeks.\n\n\n\n Context \n\nRapidly building and deploying innovative HR benefits site in less than 3 weeks.\n\n\n\n* Employee growth and changing HR policies meant that a whole new site would be required for annual enrollment.\n* Interactive features, such as a chatbot, were expected to help communicate new HR policies to existing employees.\n* Due to growth in number employees, the site traffic is increasing, but their infrastructure budget remains flat.\n* The HR team faced pressure to move faster: roll out new site features quickly and post last-minute benefit changes frequently.\n* The enrollment period lasts for two weeks, and so downtime for the new app isn't tolerated.\n\n\n\n\n\n\n\n Solution \n\nThe airline wants to design an open culture that puts people first. The HR Executive is well aware that a focus on rewarding and retaining talent impacts the airline\u2019s profitability. Thus, the annual rollout of benefits is a key aspect of fostering an employee-centered culture.\n\nThey need a solution that helps the Developers and their users.\n\n\n\n* FRONT-END TO EXISTING BENEFITS: insurance, educational offerings, wellness, and more\n* REGION-SPECIFIC FEATURES: each country has unique HR policies so that the overall site might look similar but show region-specific benefits\n* DEVELOPER-FRIENDLY TOOLS that accelerate rollout of features and bug fixes\n* CHATBOT to provide authentic conversations about benefits and resolve users requests and questions efficiently.\n\n\n\nTechnical solution:\n\n\n\n* IBM Cloud Kubernetes Service","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_uc_transport"},{"document_id":"ibmcld_10170-8677-11078","score":23.7052220038,"text":"\n* Microservices greatly reduce time to delivery for patches, bug fixes, and new features. Initial development is fast, and updates are frequent.\n* Shipping customers have real-time access to shipments\u2019 locations, delivery schedules, and even approved port records.\n* Transit partners at various shipping terminals are aware of manifests and shipment details so that onsite logistics are improved, instead of delayed.\n\n\n\n\n\n\n\n\n\n Airline delivers innovative Human Resources (HR) benefits site in under 3 weeks \n\nAn HR Exec (CHRO) needs a new HR benefits site with an innovative chatbot, but current Development tools and platform mean long lead times for apps to go live. This situation includes long waits for hardware procurement.\n\nRed Hat OpenShift on IBM Cloud provides easy spin-up of compute. Then, Developers can experiment easily, pushing changes to Development and Test systems quickly with open toolchains. Their traditional software development tools get a boost when they add on IBM Watson Assistant. The new benefits site was created in less than 3 weeks.\n\n\n\n Context \n\nRapidly building and deploying innovative HR benefits site in less than 3 weeks.\n\n\n\n* Employee growth and changing HR policies meant that a whole new site would be required for annual enrollment.\n* Interactive features, such as a chatbot, were expected to help communicate new HR policies to existing employees.\n* Due to growth in number employees, the site traffic is increasing, but their infrastructure budget remains flat.\n* The HR team faced pressure to move faster: roll out new site features quickly and post last-minute benefit changes frequently.\n* The enrollment period lasts for two weeks, and so downtime for the new app isn't tolerated.\n\n\n\n\n\n\n\n Solution \n\nThe airline wants to design an open culture that puts people first. The HR Executive is well aware that a focus on rewarding and retaining talent impacts the airline\u2019s profitability. Thus, the annual rollout of benefits is a key aspect of fostering an employee-centered culture.\n\nThey need a solution that helps the Developers and their users.\n\n\n\n* FRONT-END TO EXISTING BENEFITS: insurance, educational offerings, wellness, and more\n* REGION-SPECIFIC FEATURES: each country has unique HR policies so that the overall site might look similar but show region-specific benefits\n* DEVELOPER-FRIENDLY TOOLS that accelerate rollout of features and bug fixes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_transport"},{"document_id":"ibmcld_14449-0-2012","score":22.5782457105,"text":"\n\n\n\n\n\n\n  KMIP for VMware overview \n\nThis solution architecture describes the KMIP\u2122 on VMware architecture for protecting your VMware\u00ae instances. Many storage encryption options are available to protect your VMware workload. KMIP for VMware works together with VMware native vSphere encryption and vSAN\u2122 encryption. The vSphere and vSAN encryption provides simplified storage encryption management together with the security and flexibility of IBM Cloud\u00ae Key Protect or IBM Cloud Hyper Protect Crypto Services customer-managed keys.\n\nThis solution is considered to be an extra component and extension of the vCenter Server offering on IBM Cloud. As a result, this document doesn't cover the existing configuration of these foundation solutions on IBM Cloud. To understand more about the foundation solution architecture, see [Overview of VMware Solutions](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-solution_overview).\n\n\n\n  Key benefits \n\nWhile many storage encryption solutions are available for your VMware workload, KMIP for VMware offers the following benefits:\n\n\n\n*  Integration with VMware vSAN encryption and vSphere encryption, both of which are implemented in the hypervisor layer rather than the storage or virtual machine layer. This approach allows easy management and transparency to your storage solution and application.\n*  Fully managed key management server available in many IBM Cloud multizone regions (MZRs).\n*  Integrating your VMware cluster with IBM Cloud Key Protect or IBM Cloud Hyper Protect Crypto Services provides you with fully customer-managed keys that you can revoke at any time.\n\n\n\n\n\n\n\n  Related links \n\n\n\n*  [Solution design](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-kmip-design)\n*  [Implementation and management](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-kmip-implementation)\n*  [High availability and disaster recovery](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-kmip-hadr)\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-kmip-overview"},{"document_id":"ibmcld_14611-7-1911","score":22.3785644288,"text":"\nTarget platforms in IBM Cloud \n\nIBM Cloud\u00ae for VMware Solutions has a number of offerings, deployment patterns, and options that can be used to create your target VMware NSX-T\u2122 environment:\n\n\n\n* Automated offerings - These offerings are available from the [VMware Solutions](https:\/\/cloud.ibm.com\/vmware) console.\n* Regulated workload offerings - These offerings are available from the [VMware Solutions](https:\/\/cloud.ibm.com\/vmware) console, the VMware Regulated Workloads card. They are suitable for clients that require a prescriptive reference architecture that matches the IBM Cloud Framework for Financial Services.\n* Automated offerings with manual customization tasks - These offerings are based on the offering available from the [VMware Solutions](https:\/\/cloud.ibm.com\/vmware) console. They require a number of post-deployment manual tasks to achieve the architectural pattern needed.\n\n\n\nBased on the assessment of your source NSX-V environment, you can identify the requirements for your target platform. After the analysis, do the following steps:\n\n\n\n1. Select the target platform that supports all your requirements from the information on the features that are shown in the following diagrams.\n2. Review [Getting started with VMware Solutions](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-getting-started) to learn more about the offerings, deployment patterns, and services.\n\n\n\nA summary and key capabilities of the target VMware Solutions offerings in IBM Cloud is provided with architectural guidance to ease up the selection process.\n\n\n\n Automated offerings \n\nThe offerings are described in detail in the following documents:\n\n\n\n* [vCenter Server as a single site deployment](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_vcenterserveroverview) - This offering deploys a VMware\u00ae based platform in a single IBM Cloud data center automatically.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-v2t-targets"},{"document_id":"ibmcld_14400-7-2130","score":21.8447816414,"text":"\nFortinet FortiGate virtual machine (VM) overview \n\nIBM Cloud\u00ae for VMware Solutions offers various solutions to meet your network security requirements. The base offering includes VMware NSX\u2013T\u2122 for integrated virtual networking and security. More network security features are available with the FortiGate\u00ae VM offering, which provides Fortinet\u00ae\u2019s next\u2013generation firewall (NGFW) capabilities in the form of a highly available pair of virtual FortiGate appliances. In addition to the architecture for FortiGate VM, IBM Cloud\u00ae also offers a [FortiGate Security Appliance](https:\/\/cloud.ibm.com\/docs\/fortigate-10g) offering, which provides a perimeter firewall, NAT, and VPN services in the form of a physical appliance.\n\nThe solution is considered to be an extra component and extension of the VMware vCenter Server\u00ae offering on IBM Cloud. As a result, this document doesn\u2019t cover the existing configuration of the foundation solutions on IBM Cloud. For more information about the foundation solution architecture, see [Overview of VMware Solutions](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-solution_overview).\n\n\n\n Topologies \n\nYou can deploy FortiGate VM according to several different strategies:\n\n\n\n* FortiGate VM can be deployed as part of an ESXi\u2122 gateway cluster that is directly integrated with the IBM Cloud customer routers. It provides firewall and gateway functions for your private and public IBM Cloud network VLANs.\n* FortiGate VM can be deployed to your management and workload cluster. In this form, you can use FortiGate to provide firewall and gateway services between various networks. FortiGate VM provides controlled connectivity between:\n\n\n\n* Public and private networks\n* Private VLANs and NSX logical switches\n* Several VMware NSX\u00ae logical switches\n\n\n\n\n\nAdditionally, FortiGate VM offers direct integration with NSX\u2013T including service chaining and dynamic import of security groups.\n\n\n\n\n\n Key benefits \n\nSeveral licensing option bundles are available for FortiGate VM on IBM Cloud.\n\n\n\n* Standard FW - This bundle includes the following services.\n\n\n\n* Stateful packet inspection","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-fortigate-overview"},{"document_id":"ibmcld_07578-394005-396150","score":21.8108479475,"text":"\nYour worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n* Why should I use Red Hat OpenShift on IBM Cloud?\n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-393979-396124","score":21.8108479475,"text":"\nYour worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n* Why should I use Red Hat OpenShift on IBM Cloud?\n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_14759-2917-4957","score":21.5077631335,"text":"\nFor day two of operation, it is your responsibility to monitor and manage the vCenter and NSX-T, including backups, patching, configuration, and monitoring of the VMware software and the underlying vSphere hypervisor.\n\n\n\n\n\n Key benefits \n\nThe architecture provides fundamental building blocks, which include VMware vSphere, vCenter Server, VMware NSX-T, and shared storage options, such as VMware vSAN or IBM Cloud VPC file share. These building blocks are needed to flexibly design a VMware software-defined data center solution that best fits your workloads.\n\nVMware Solutions in IBM Cloud VPC have the following key benefits over IBM Cloud classic deployments:\n\n\n\n* IBM Cloud VPC gives you the ability to easily and rapidly define and control a virtual network, which is logically isolated from all other tenants. The logical isolation is implemented by using virtual network functions and security that is built into the platform.\n* Provisioning the IBM Cloud bare metal server on IBM Cloud VPC takes minutes instead of hours when compared to the IBM Cloud bare metal server on IBM Cloud classic.\n* VMware workloads by running in IBM Cloud VPC can take advantage of all original functions for VPC networking capabilities and other IBM Cloud interconnectivity services.\n\n\n\nWith this single-tenant IBM Cloud bare metal server infrastructure that is provided in IBM Cloud VPC, you can quickly deploy network, compute, and storage capacity for your VMware environment to the IBM Cloud in minutes.\n\nUnlike the managed service offerings, this architecture gives you flexibility to design a solution for your needs, and provides you full and complete access to all components.\n\n\n\n\n\n Related links \n\n\n\n* [IBM Cloud VPC getting started](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-started)\n* [IBM Cloud VPC Bare Metal Servers](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-planning-for-bare-metal-servers)\n* [IBM Cloud VPC RYO VMware reference architecture](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vpc-ryo-arch-overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vpc-ryo-overview"},{"document_id":"ibmcld_11552-1740-3927","score":20.7939076709,"text":"\nThe scripts include Ansible scripts for:\n\n\n\n* OS requirements installation and configuration for SAP applications\n* Cluster components installation\n* Ansible scripts for SAP application cluster configuration and SAP HANA cluster configuration\n* HANA installation\n* HANA DB backup\n* HANA system replica configuration\n* ASCS and ERS instances installation\n* DB load\n* Primary and extra application servers installation\n\n\n\nAnsible is started by Terraform and must be available on the same host.\n\n\n\n\n\n SAP Solution implemented \n\nSAP S\/4HANA is an ERP system from SAP's ERP software product line. The software is based on the innovative SAP HANA database technology and was started as the fourth product generation in 2015. Users can choose between the SAP S\/4HANA Cloud and On-Premise solution.\n\nAn ERP system is used for demand-oriented business resource planning. It is used to control processes and to link departments and functional areas in a meaningful way. Individual modules include applications for accounting, sales, production, and marketing. More complex tasks in customer or supply chain management can also be done by ERP software. As the successor to the core product SAP ECC, SAP S\/4HANA was presented as the intelligent ERP system of the new generation. Thanks to modern technologies, the Software as Service (SaaS) version is designed to help companies standardize processes and make the leap to digitalization.\n\nWhile previous SAP ERP solutions support the most common databases, SAP S\/4HANA uses exclusively the SAP HANA in-memory database developed by SAP. This in-memory database offers users the greatest technical benefit and they benefit from increased performance. The \"S\" in S\/4HANA stands for \"simple\", while the \"4\" refers to the generation sequence. Compared to the SAP core product SAP ECC, which is still used in most companies, SAP S\/4HANA offers many innovative functions that revolutionize the system landscape from the ground up. As SAP plans to discontinue the mainstream maintenance of its existing ERP solutions by 2027, many SAP ECC users are already considering a migration to SAP HA SZ S\/4HANA\n\n\n\n\n\n What is created \n\nThe scripts work in two phases.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-automate-s4hana-ha-terraform-ansible"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10358-2392-3900","score":12.6518228341,"text":"\nBuild app containers from [images in the internal, public, or private registries](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-images).\n3. Specify your [app requirements in a YAML file](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_appsapp_yaml), which declares the configuration of the Kubernetes object.\n\n\n\n2. Version your app:\n\n\n\n1. Version 4: To plan customized configurations for more than one environment, such as development, testing, and production environments, [use the Kustomize tool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_appskustomize) to manage your configuration YAML file.\n2. If you want to run your app in multiple clusters, public and private environments, or even multiple cloud providers, [package your application to help automate deployments](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_deploypackaging).\n\n\n\n\n\nNeed help? Check out [Troubleshooting apps and integrations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_apps).\n\n\n\n\n\n Deploy your app \n\nDeploy your app to the cluster by running your app configuration file.\n\n\n\n* [Deploying apps through the console](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy_appdeploy_apps_ui).\n* [Deploying apps through the CLI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy_appdeploy_apps_cli).\n* [Deploying apps to specific worker nodes by using labels](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy_appnode_affinity).\n\n\n\nNeed help?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-learning-path-dev"},{"document_id":"ibmcld_10281-5616-6727","score":12.5309096924,"text":"\nNAME READY UP-TO-DATE AVAILABLE AGE\nrouter-default 2\/2 2 2 26m\n2. Check whether the Ingress controller's load balancer service exists and is assigned a public external IP address (classic clusters) or a hostname (VPC clusters).\n\n\n\n* If a service that is named router-default is listed and is assigned an IP address (classic clusters) or a hostname (VPC clusters), continue to the next step.\n* If no router-default service is created after several minutes, [review ways to get help](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-help).\n\n\n\noc get svc -n openshift-ingress\n\nExample output\n\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\nrouter-default LoadBalancer 172.21.47.119 169.XX.XX.XX 80:31182\/TCP,443:31154\/TCP 27m\nrouter-internal-default ClusterIP 172.21.51.30 <none> 80\/TCP,443\/TCP,1936\/TCP 26m\n\n\n\n5. Check again whether the Ingress subdomain and secret are created. If they are not available, but you verified that all the components in steps 1 - 3 exist, [review ways to get help](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-help).\n\nibmcloud oc cluster get -c <cluster_name_or_ID>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ingress_subdomain"},{"document_id":"ibmcld_10140-34792-36631","score":12.2285583261,"text":"\n* Removes the deprecated region get, region set, and region ls commands from help output.\n* Updates command structure to the new spaced format in help output.\n* Adds a warning to the output of legacy cluster config behavior. For more information, see the [version 1.0 plug-in documentation](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelogchangelog_beta).\n* Fixes a bug so that worker reload and messages commands now fail if the command errors.\n* Updates the help text in various languages.\n\n\n\n\n\n\n\n Version 0.4.23 \n\nVersion 0.4.23 of the CLI was released on 16 September 2019.\n\n\n\n* Decreases startup time for the plug-in.\n* Fixes a Go version issue for macOS users.\n* Improves debug tracing.\n* In ibmcloud oc logging filter commands, the syntax of the --logging-config option changes from accepting multiple values in a comma-separated list to requiring repeated options.\n* Minor bug and security fixes.\n* Updates message, warning, and help text.\n\n\n\n\n\n\n\n Version 0.4.3 \n\nVersion 0.4.3 of the CLI was released on 4 September 2019.\n\n\n\n* Adds deprecation warnings for legacy commands to error messages that are sent to stderr.\n\n\n\n\n\n\n\n Version 0.4.1 \n\nVersion 0.4.1 of the CLI was released on 3 April 2019.\n\n\n\n* Sets the Red Hat OpenShift on IBM Cloud plug-in to the redesigned format by default. This redesigned version includes changes such as categorical lists instead of an alphabetical list of commands in the output of ibmcloud oc help, spaced-structured commands instead of hyphenated-structure commands, repeated options instead of multiple values in comma-separated lists, and more. For a full list of the changes between version 0.3 and 0.4, see the comparison table in [Using the beta Red Hat OpenShift on IBM Cloud plug-in](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelogchangelog_beta).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelog"},{"document_id":"ibmcld_10534-530364-531637","score":12.2108831117,"text":"\n* [Is the service highly available?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsha_sla)\n* [What compliance standards does the service meet?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsstandards)\n* [Can I use IBM Cloud and other services with my cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsfaq_integrations)\n* [Does IBM support third-party and open source tools that I use with my cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsfaq_thirdparty_oss)\n* [What am I charged for? Can I estimate and control costs in my cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqscharges)\n* [Can I downgrade my cluster to a previous version?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqsdowngrade)\n\n\n\n\n\n\n\n Troubleshooting \n\n[Getting help and support for Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-helpget-help)\n\n\n\n* [General ways to resolve cluster issues](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-helphelp-general)\n* [Reviewing issues and status](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-helphelp-cloud-status)\n* [Feedback and questions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-helpfeedback-qs)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_10140-30424-32058","score":12.1937912088,"text":"\n* Deprecates the --disable-deployment option of the ibmcloud oc alb configure vpc-classic command.\n\n\n\n* VPC-specific command updates:\n\n\n\n* Fixes the [ibmcloud oc zone rm](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_zone_rm) command for VPC multizone clusters.\n* For the [ibmcloud oc vpcs](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_vpcs) command, defaults to list only generation 1 (vpc-classic) VPCs.\n* Revises the ibmcloud oc worker-pool create vpc-classic command to remove the --disable-disk-encrypt option and to hide the --hardware option because it only accepts one value.\n\n\n\n* Help documentation updates:\n\n\n\n* Add deprecation warnings to encourage you to use the newer classic subcommands. For example, use ibmcloud oc cluster create classic instead of ibmcloud oc cluster create.\n* Adds links to the Red Hat OpenShift on IBM Cloud documentation in various help topics.\n* Standardizes formatting in help text, such as adding single quotes around variable names or styling for URLs.\n* Updates the help text in various languages.|\n\n\n\n\n\n\n\n\n\n Version 0.4.66 \n\nVersion 0.4.66 of the CLI was released on 19 December 2019.\n\n\n\n* Adds a Status field to the ibmcloud oc alb cert get command. The previous Status field is now called State.\n* Fixes a bug so that help text is now properly displayed for some commands, such as ibmcloud oc flavors and ibmcloud oc subnets.\n\n\n\n\n\n\n\n Version 0.4.64 \n\nVersion 0.4.64 of the CLI was released on 11 December 2019.\n\n\n\n* Adds the --entitlement option to the ibmcloud oc cluster create and ibmcloud oc worker-pool create commands.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelog"},{"document_id":"ibmcld_10140-49448-51079","score":12.1185200522,"text":"\nVersion 0.2.19 of the CLI was released on 16 January 2019.\n\n\n\n* Adds the IKS_BETA_VERSION environment variable to enable the redesigned beta version of the Red Hat OpenShift on IBM Cloud plug-in CLI. To try out the redesigned version, see [Using the beta command structure](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelogchangelog_beta).\n* Increases the default timeout value for ibmcloud oc subnets to 60s.\n* Fixes a minor bug and updates the help text in various languages.\n\n\n\n\n\n\n\n\n\n Version 0.1 \n\nReview the following changes for 0.1 versions of the CLI plug-in.\n\nVersion 0.1 of the CLI plug-in is deprecated. To update to the latest version, see [Updating to version 1.0 of the plug-in](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelogchangelog_beta).\n\n\n\n Version 0.1.668 \n\nVersion 0.1.68 of the CLI was released on 18 December 2018.\n\n\n\n* Changes the default API endpoint from containers.bluemix.net to containers.cloud.ibm.com.\n* Fixes bug so that command help text and error messages display properly for various languages.\n* Displays command help faster.\n\n\n\n\n\n\n\n Version 0.1.654 \n\nVersion 0.1.654 of the CLI was released on 5 December 2018.\n\n\n\n* Updates the help text in various languages.\n\n\n\n\n\n\n\n Version 0.1.638 \n\nVersion 0.1.638 of the CLI was released on 15 November 2018.\n\n\n\n* Adds the [ibmcloud oc cluster-refresh](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_apiserver_refresh) alias to the apiserver-refresh command.\n* Adds the resource group name to the output of ibmcloud oc cluster get and ibmcloud oc cluster ls.\n\n\n\n\n\n\n\n Version 0.1.635","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelog"},{"document_id":"ibmcld_10140-19582-21132","score":12.0788962622,"text":"\nVersion 1.0.99 of the CLI was released on 15 June 2020.\n\n\n\n* Adds the --cos-instance option to the ibmcloud oc cluster create vpc-gen2 command to back up the images from your Red Hat OpenShift internal registry to a bucket in your IBM Cloud Object Storage instance.\n* Updates the help text in various places.\n\n\n\n\n\n\n\n Version 1.0.94 \n\nVersion 1.0.94 of the CLI was released on 9 June 2020.\n\n\n\n* Adds the [ibmcloud oc cluster addon enable static-route](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_cluster_addon_enable_static-route) and [ibmcloud oc cluster addon disable static-route](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_cluster_addon_disable_static-route) commands to manage the Static Route add-on for your cluster.\n* Adds the [ibmcloud oc worker-pool taint set](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cliworker_pool_taint_set) and [ibmcloud oc worker-pool taint rm](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cliworker_pool_taint_rm) commands to set and remove Kubernetes taints on worker nodes in a worker pool.\n* Beta: Adds the [ibmcloud oc storage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_storage) set of commands to view and modify storage resources in your cluster.\n* Moves the ibmcloud oc locations command to the Informational Commands group in the help output of ibmcloud oc.\n* Updates the help text for options in the ibmcloud oc nlb-dns monitor configure command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelog"},{"document_id":"ibmcld_10140-31683-32851","score":12.0551197681,"text":"\nThe previous Status field is now called State.\n* Fixes a bug so that help text is now properly displayed for some commands, such as ibmcloud oc flavors and ibmcloud oc subnets.\n\n\n\n\n\n\n\n Version 0.4.64 \n\nVersion 0.4.64 of the CLI was released on 11 December 2019.\n\n\n\n* Adds the --entitlement option to the ibmcloud oc cluster create and ibmcloud oc worker-pool create commands. Include this option only if you use this cluster with an [IBM Cloud Pak](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_cloud_paks) that has a Red Hat OpenShift entitlement.\n* Updates the Go version to 1.12.11.\n* Updates the help text in various languages.\n\n\n\n\n\n\n\n Version 0.4.61 \n\nVersion 0.4.61 of the CLI was released on 26 November 2019.\n\n\n\n* Removes the kube-audit log source option from ibmcloud oc logging config commands.\n* Adds a column to the output of ibmcloud oc addon-versions for the minimum required Red Hat OpenShift version.\n* Adds a check to verify that you are logged in to the IBM Cloud CLI before a command request is issued.\n* Updates the help text in various languages.\n\n\n\n\n\n\n\n Version 0.4.51 \n\nVersion 0.4.51 of the CLI was released on 7 November 2019.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelog"},{"document_id":"ibmcld_10534-130739-132089","score":12.0421780731,"text":"\n[Accessing the cluster master with admission controllers and webhooks](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_webhooksaccess_webhooks)\n\n\n\n* [Can I create my own admission controllers?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_webhooksaccess_webhooks_create_controllers)\n* [What are the best practices for using webhooks?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_webhookswebhook-best-practice)\n* [What other types of apps use admission controllers?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_webhooksaccess_webhooks-app-use-controllers)\n* [I need help with a broken webhook. What can I do?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_webhooksaccess_webhooks-help)\n\n\n\n[Accessing private clusters by using the WireGuard VPN](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-access-wireguardcluster-access-wireguard)\n\n\n\n\n\n Managing the cluster and worker node lifecycle \n\n[Adding worker nodes and zones to clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersadd_workers)\n\n\n\n* [Adding worker nodes by resizing an existing worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersresize_pool)\n* [Adding worker nodes in VPC clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersvpc_pools)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_10462-7-2030","score":12.0353034527,"text":"\nSetting pod priority \n\nWith pod priority and preemption, you can configure priority classes to indicate the relative priority of the pods that make up your Red Hat OpenShift cluster's workload. The Red Hat OpenShift controller takes into consideration the priority of a pod and can even preempt (remove) pods with lower priority to make room on a worker node for higher priority pods. For more information, see the [Red Hat OpenShift documentation](https:\/\/docs.openshift.com\/container-platform\/4.11\/nodes\/pods\/nodes-pods-priority.html).\n\nWhy do I set pod priority?\n: As a cluster administrator, you want to control which pods are more critical to your cluster workload. Priority classes can help you control the Red Hat OpenShift controller decisions to favor higher priority pods over lower priority pods. The Red Hat OpenShift controller can even preempt (remove) lower priority pods that are running so that pending higher priority pods can be scheduled.\n\nBy setting pod priority, you can help prevent lower priority workloads from impacting critical workloads in your cluster, especially in cases where the cluster starts to reach its resource capacity.\n\nMake sure that you have [set up proper user access](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-usersusers) to your cluster, and if applicable, [security context constraints (SCCs)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_sccoc_sccs). Access policies and SCCs can help prevent untrusted users from deploying high priority pods that prevent other pods from scheduling.\n\nHow does priority scheduling and preemption work?\n\nIn general, pending pods that have a higher priority are scheduled before lower prioritized pods. If you don't have enough resources remaining in your worker nodes, the Red Hat OpenShift controller can preempt (remove) pods to free up enough resources for the higher prioritized pods to be scheduled. Preemption is also affected by graceful termination periods, pod disruption budgets, and worker node affinity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-pod_priority"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03273-3976-5874","score":23.6118779143,"text":"\nTo add a context variable, specify the variable name, and press Enter.\n2. To define a default value for the context variable, find the context variable you added in the list, and then specify a value for it.\n\n\n\nSee [Context variables](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-context) for more information.\n8. Continue to interact with the dialog to see how the conversation flows through it.\n\n\n\n* To find and resubmit a test utterance, you can press the Up key to cycle through your recent inputs.\n* To remove prior test utterances from the chat pane and start over, click the Clear link. Not only are the test utterances and responses removed, but this action also clears the values of any context variables that were set as a result of your interactions with the dialog.\n\n\n\n\n\n\n\n What to do next \n\nMake changes to the dialog to address issues you see when testing:\n\n\n\n* If you determine that the wrong intents or entities are being recognized, you might need to modify your intent or entity definitions.\n* If the correct intents and entities are being recognized, but the wrong nodes are being triggered in your dialog, make sure your conditions are written properly.\n\n\n\nIf you are ready to put the conversation to work helping your users, integrate your assistant with a messaging platform or custom application. See [Adding integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add).\n\n\n\n\n\n\n\n Searching your dialog \n\nYou can search the dialog to find one or more dialog nodes that mention a given word or phrase.\n\n\n\n1. Select the Search icon: ![Search icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/search_icon.png)\n2. Enter a search term or phrase.\n\nThe first time you search, an index is created. You might be asked to wait while the text in your dialog nodes is indexed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks"},{"document_id":"ibmcld_03310-4141-5886","score":22.2757523738,"text":"\nYou can use the expression language to extract property information for the following global variables:\n\n\n\n Global variable Definition \n\n context JSON object part of the processed conversation message. \n entities[ ] List of entities that supports default access to 1st element. \n input JSON object part of the processed conversation message. \n intents[ ] List of intents that supports default access to first element. \n output JSON object part of the processed conversation message. \n\n\n\n\n\n\n\n Accessing entities \n\nThe entities array contains one or more entities that were recognized in user input.\n\nWhile testing your dialog, you can see details of the entities that are recognized in user input by specifying this expression in a dialog node response:\n\n<? entities ?>\n\nFor the user input, today, your assistant recognizes the @sys-date system entity, so the response contains this entity object:\n\n[\n{\n\"entity\":\"sys-date\",\n\"location\":0,5],\n\"value\":\"2020-12-30\",\n\"confidence\":1.0,\n\"metadata\":\n{\n\"calendar_type\":\"GREGORIAN\",\n\"timezone\":\"America\/New_York\"\n},\n\"interpretation\":\n{\n\"timezone\":\"America\/New_York\",\n\"relative_day\":0,\n\"granularity\":\"day\",\n\"calendar_type\":\"GREGORIAN\"\n}\n}\n]\nShow more\n\nIf you want to include text in the response, use the toJson() method in the expression to cast the returned entities list into a JSON object. For example:\n\nRecognized entities are: <? entities.toJson() ?>\n\n\n\n When placement of entities in the input matters \n\nWhen you use the shorthand expression, @city.contains('Boston'), in a condition, the dialog node returns true only ifBoston is the first entity detected in the user input. Only use this syntax if the placement of entities in the input matters to you and you want to check the first mention only.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-expression-language"},{"document_id":"ibmcld_02953-3805-5544","score":22.0789084998,"text":"\n* To find and resubmit a test utterance, you can press the Up key to cycle through your recent inputs.\n* To remove prior test utterances from the chat pane and start over, click the Clear link. Not only are the test utterances and responses removed, but this action also clears the values of any context variables that were set as a result of your interactions with the dialog. Context variable values that you explicitly set or change are not cleared.\n\n\n\n\n\n\n\n What to do next \n\nIf you determine that the wrong intents or entities are being recognized, you might need to modify your intent or entity definitions.\n\nIf the correct intents and entities are being recognized, but the wrong nodes are being triggered in your dialog, make sure your conditions are written properly.\n\nIf you are ready to put the conversation to work helping your users, call the assistant from a client application. See [Building a client application](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-api-client).\n\n\n\n\n\n\n\n Searching your dialog \n\nThe search capability was introduced with the 1.5.0 release.\n\nYou can search the dialog to find one or more dialog nodes that mention a given word or phrase.\n\n\n\n1. From the Dialog page header, click the Search icon ![Search icon in the Intents page header](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/search_icon.png).\n2. Enter a search term or phrase.\n\nThe first time you search, an index is created. You might be asked to wait for the text in your dialog nodes to be indexed and then resubmit your request.\n\n\n\nDialog nodes that contain your search term, with corresponding examples, are shown. Select a result to open it for editing.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tasks"},{"document_id":"ibmcld_03421-6867-8448","score":21.523947191,"text":"\nA context variable is a variable that you can use to pass information to your assistant before a conversation starts. It can also collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on.\n\nThe following script preserves the context of the conversation. In addition, it adds an $ismember context variable and sets it to true.\n\nThe name that is specified for the skill (main skill) is a hardcoded name that is used to refer to any skill that you create from the product user interface. You do not need to edit your skill name.\n\n<script>\nfunction preSendhandler(event) {\nevent.data.context.skills['main skill'].user_defined.ismember = true;\n}\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE_ID\",\n\nonLoad: function(instance) {\n\/\/ Subscribe to the \"pre:send\" event.\ninstance.on({ type: \"pre:send\", handler: preSendhandler });\ninstance.render();\n}\n};\n\nsetTimeout(function(){\nconst t=document.createElement('script');\nt.src='https:\/\/web-chat.global.assistant.dev.watson.appdomain.cloud\/versions\/' +\n(window.watsonAssistantChatOptions.clientVersion || 'latest') +\n'\/WatsonAssistantChatEntry.js';\ndocument.head.appendChild(t);});\n\n<\/script>\nShow more\n\nYou can reference the $ismember context variable from your dialog. For example, the following screen capture shows a dialog node that conditions on #General_Greetings. It has multiple conditioned responses.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16493-12128-14263","score":21.2425010132,"text":"\nThrough training and refinement of example input data, the model can deliver accurate, repeatable results when it analyzes new data.\n* machine learning annotator\n\nSee [machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-glossarygloss_M).\n* machine learning model\n\nA component that identifies entities and entity relationships according to a statistical model that is based on ground truth. The model applies past experience, such as training data, to determine or predict the correct outcome of future experiences based on characteristics of the data. These past experiences are captured in the form of a model by calculating feature scores for each candidate answer or evidence and combining that with known outcomes. Sometimes referred to as machine learning annotator.\n* mention\n\nA span of text that you consider relevant in your domain data. For example, in a type system about automotive vehicles, occurrences of terms like \"airbag\", \"Ford Explorer\", and \"child restraint system\" might be relevant mentions.\n\n\n\n\n\n\n\n N \n\n\n\n* named entity\n\nA concept in a domain that falls in to a well-defined category, such as names of organizations, locations, authors, or diseases.\n* natural language processing\n\nA field of artificial intelligence and linguistics that studies the problems inherent in the processing and manipulation of natural language, with an aim to increase the ability of computers to understand human languages.\n\n\n\n\n\n\n\n O \n\n\n\n* ontology\n\nAn explicit formal specification of the representation of the objects, concepts, and other entities that can exist in some area of interest and the relationships among them.\n\n\n\n\n\n\n\n P \n\n\n\n* part of speech (POS)\n\nIn a dictionary, individual lexical items are assigned part of speech (POS) tags. For example, the word 'fly' can be identified as a verb or a noun.\n* performance\n\nThe measurement of a Watson system in terms of accuracy, precision, and recall, for example, when answering questions, discovering relationships, or annotating text.\n* pre-annotation\n\nThe process of annotating a set of documents prior to human annotation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-glossary"},{"document_id":"ibmcld_16436-12448-14593","score":21.1637034199,"text":"\nThrough training and refinement of example input data, the model can deliver accurate, repeatable results when it analyzes new data.\n* machine learning annotator\n\nSee [machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-glossarygloss_M).\n* machine learning model\n\nA component that identifies entities and entity relationships according to a statistical model that is based on ground truth. The model applies past experience, such as training data, to determine or predict the correct outcome of future experiences based on characteristics of the data. These past experiences are captured in the form of a model by calculating feature scores for each candidate answer or evidence and combining that with known outcomes. Sometimes referred to as machine learning annotator.\n* mention\n\nA span of text that you consider relevant in your domain data. For example, in a type system about automotive vehicles, occurrences of terms like \"airbag\", \"Ford Explorer\", and \"child restraint system\" might be relevant mentions.\n\n\n\n\n\n\n\n N \n\n\n\n* named entity\n\nA concept in a domain that falls in to a well-defined category, such as names of organizations, locations, authors, or diseases.\n* natural language processing\n\nA field of artificial intelligence and linguistics that studies the problems inherent in the processing and manipulation of natural language, with an aim to increase the ability of computers to understand human languages.\n\n\n\n\n\n\n\n O \n\n\n\n* ontology\n\nAn explicit formal specification of the representation of the objects, concepts, and other entities that can exist in some area of interest and the relationships among them.\n\n\n\n\n\n\n\n P \n\n\n\n* part of speech (POS)\n\nIn a dictionary, individual lexical items are assigned part of speech (POS) tags. For example, the word 'fly' can be identified as a verb or a noun.\n* performance\n\nThe measurement of a Watson system in terms of accuracy, precision, and recall, for example, when answering questions, discovering relationships, or annotating text.\n* pre-annotation\n\nThe process of annotating a set of documents prior to human annotation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-glossary"},{"document_id":"ibmcld_09523-1565-3384","score":21.0319375208,"text":"\nA new Maximo Application Suite SaaS (MAS-SaaS) contract is in place.\n2. The source version of Maximo must be v7.6.1.2 or greater. For SaaS Flex (IBM hosted) clients, the technical upgrade is performed by the IBM SRE Team as part of the SaaS Flex offering per normal upgrade procedures. For on-premise clients, the technical upgrade is the responsibility of the client or business partner.\n3. The source database export is DB2 (the supported DB2 version depends on the timing of the migration).\n4. The MAS database timezone for each instance will be set to UTC when provisioned. This cannot be changed.\n5. Customer has run Maximo v7.6 Integrity Checker on source database and resolved all errors prior to sending to IBM.\n6. All items to be migrated are identified. For SaaS Flex (IBM hosted) clients this is a shared responsibility; for on-premise the customer is responsible.\n7. All custom java classes arre remediated and removed. Java classes can be replaced with automation scripts. See link for further information:\n\n[https:\/\/ibm-maximo-dev.github.io\/maximo-autoscript-documentation\/introduction\/whatisautoscript\/](https:\/\/ibm-maximo-dev.github.io\/maximo-autoscript-documentation\/introduction\/whatisautoscript\/)\n8. Database conversion tools won't address stored queries, relationships or reports. Ensure these are converted and tested on v7.6 before migrating to MAS.\n9. TEXT Search is not supported in MAS. All fields should be converted from TEXT search to another value (WILDCARD, EXACT, or NONE).\n10. Each user account can have only (1) primary email address.\n11. Each user account can have only (1) primary phone number.\n12. The user account added for the mxe.int.dfltuser property must have complete user application and related object access inside Manage for user syncronization to work after migration.\n13.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-saas?topic=mas-saas-migration-from-maximo-saas-flex-or-on-premise"},{"document_id":"ibmcld_09502-1592-3421","score":21.0319375208,"text":"\nA new Maximo Application Suite Dedicated (MAS-Dedicated) contract is in place.\n2. The source version of Maximo must be v7.6.1.2 or greater. For SaaS Flex (IBM hosted) clients, the technical upgrade is performed by the IBM SRE Team as part of the SaaS Flex offering per normal upgrade procedures. For on-premise clients, the technical upgrade is the responsibility of the client or business partner.\n3. The source database export is DB2 (the supported DB2 version depends on the timing of the migration).\n4. The MAS database timezone for each instance will be set to UTC when provisioned. This cannot be changed.\n5. Customer has run Maximo v7.6 Integrity Checker on source database and resolved all errors prior to sending to IBM.\n6. All items to be migrated are identified. For SaaS Flex (IBM hosted) clients this is a shared responsibility; for on-premise the customer is responsible.\n7. All custom java classes arre remediated and removed. Java classes can be replaced with automation scripts. See link for further information:\n\n[https:\/\/ibm-maximo-dev.github.io\/maximo-autoscript-documentation\/introduction\/whatisautoscript\/](https:\/\/ibm-maximo-dev.github.io\/maximo-autoscript-documentation\/introduction\/whatisautoscript\/)\n8. Database conversion tools won't address stored queries, relationships or reports. Ensure these are converted and tested on v7.6 before migrating to MAS.\n9. TEXT Search is not supported in MAS. All fields should be converted from TEXT search to another value (WILDCARD, EXACT, or NONE).\n10. Each user account can have only (1) primary email address.\n11. Each user account can have only (1) primary phone number.\n12. The user account added for the mxe.int.dfltuser property must have complete user application and related object access inside Manage for user syncronization to work after migration.\n13.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-ms?topic=mas-ms-migration-from-maximo-saas-flex-or-on-premise"},{"document_id":"ibmcld_00580-34804-36790","score":20.6137941454,"text":"\nYou can see from the first line that standard JavaScript objects can be used in your code and sent to IBM Cloudant with no conversion, as they turn into JSON natively in JavaScript.\n\nWriting a document is simply a matter of calling db.insert, which maps to a PUT\/POST API call or to _bulk_docs.\n\nTo summarize, the official libraries for IBM Cloudant are Java\u2122, Python, and Nodejs. They are thin wrappers around the IBM Cloudant HTTP API - so it's worth understanding the underlying API to understand all the parameters.\n\nThe libraries handle two things for you, which is useful:\n\nAuthentication\n: Exchanging your keys for tokens, whether it be legacy authentication or IAM.\n\nRetry logic\n: The libraries can be configured to retry API calls that exceeded your provisioned capacity. If configured this way, they pause and reattempt the API call multiple times with exponential back-off.\n\nRetrying such API calls is sensible if you have a temporary and unexpected elevation in traffic. If you are routinely exceeding your provisioned capacity, no amount of retrying gets the database work done - you need more capacity!\n\nThat's the end of this part. The next part is called Querying.\n\n\n\n\n\n\n\n Querying video \n\nLearn the different ways to query data in IBM Cloudant.\n\n\n\n* Querying video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 10 - Querying.\n\nSo far we performed CRUD (create, retrieve, update, and delete) operations from the command line, the dashboard, and from code. These operations use the document's _id:\n\n\n\n* Fetch document by _id.\n* Update document whose _id = 'x'.\n* Delete document whose _id = 'x'.\n* Get documents in the _id range 'a' to 'z'.\n\n\n\nThese operations are the building blocks of a database, but they get you only so far. What if you need to return a subset of documents that match on fields within the document? A person's birth date?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_08273-2444-3878","score":20.1052362905,"text":"\n* Change the API endpoint to the endpoint mentioned in [API endpoints](https:\/\/cloud.ibm.com\/apidocs\/schematics?code=pythonapi-endpoints) according to the location that you want your Schematics workspace to reside, for example, schematics_service.set_service_url('https:\/\/us.schematics.cloud.ibm.com').\n\n\n\n4. Inside the schematics_service.apply_workspace_command function, provide the following parameters:\n\n\n\n* Provide the workspace ID that you generated in the [Creating a workspace](https:\/\/cloud.ibm.com\/docs\/hpc-slurm?topic=hpc-slurm-creating-workspace&interface=api) task, for example, us-south.workspace.Terraform-Schematics-Python-Workspace.b3bbc9f5.\n* Run the following curl command to create a refresh token:\n\n\n\ncurl -X POST \"https:\/\/iam.cloud.ibm.com\/identity\/token\" -H \"Content-Type: application\/x-www-form-urlencoded\" -d \"grant_type=urn:ibm:params:oauth:grant-type:apikey&apikey=<ibmcloud-api-key>\" -u bx:bx |jq\n5. Run the Python script by using python3 <python-file-name> to apply a plan in the IBM Cloud.\n6. You get an activity ID in response if the parameters passed as part of the request are valid. You should see the plan being applied in the Schematics workspace that you created in the IBM Cloud console. If you don\u2019t get a successful response, the error response contains the errors that you need to resolve. Resolve those errors and run the script until you are able to get a valid response and apply a plan.\n7.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-slurm?topic=hpc-slurm-applying-plan"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13726-81042-83094","score":11.3348157268,"text":"\n: The Speech services operator now automatically installs the required License Server when it installs the Speech services. You no longer need to install the License Server from the IBM Cloud Pak for Data foundational services, and you no longer need to use additional YAML content to create an OperandRequest with the necessary bindings.\n\nRemoval of steps specific to PostgreSQL EnterpriseDB server\n: The previous version of the documentation included steps for the PostgreSQL EnterpriseDB server that were specific to the Speech services. These steps were documented in the topics Upgrading Watson Text to Speech (Version 4.0) and Uninstalling Watson Text to Speech. These additional steps are no longer necessary and have been removed from the documentation.\n\nRabbitMQ datastore is now used only by the sttAysnc component\n: The RabbitMQ datastore was previously used by components of both Speech services, Speech to Text and Text to Speech. It now handles non-persistent message queuing for the Speech to Text asynchronous HTTP component (sttAsync) only. It is used only if the sttAsync component is installed and enabled.\n\nNew Belgian Dutch and Czech neural voices\n: Two new neural voices are now available:\n\n\n\n* Belgian Dutch: A new male Belgian Dutch (Flemish) voice, nl-BE_BramVoice.\n* Czech: A new language, Czech, with a new female voice, cs-CZ_AlenaVoice.\n\n\n\nYou can install the new voices along with all neural voices by setting the voiceType property of the custom resource to neuralVoices.\n\n\n\n* For more information about using the custom resource to install voices, see [Installing Watson Text to Speech](https:\/\/www.ibm.com\/docs\/en\/cloud-paks\/cp-data\/4.0?topic=speech-installing-watson-text).\n* For more information about all available languages and voices, see [Languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices).\n\n\n\nDefect fix: Update SSML documentation\n: Defect fix: The SSML documentation was updated to correct the following errors:\n\n\n\n* The examples of the <break> element are now correct.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-release-notes-data"},{"document_id":"ibmcld_07060-1697-4102","score":11.3015516647,"text":"\nCroatian (hr) Classifier (Document and Text), Custom entities, Dictionary, Regular expressions, Parts of speech \n Czech (cs) Classifier (Document and Text), Custom entities, Dictionary, Optical character recognition v1, Parts of speech, Phrase sentiment, Regular expressions, Smart Document Understanding, Stemmer, Table Understanding \n Danish (da) Classifier (Document and Text), Custom entities, Dictionary, Optical character recognition v1, Parts of speech, Regular expressions, Smart Document Understanding, Stemmer, Table Understanding \n Dutch (nl) Advanced rules models, Built-in entities, Classifier (Document and Text), Custom entities, Dictionary, Document sentiment, Keywords, Machine Learning, Optical character recognition v1 (Installed), Optical character recognition v2 (Cloud-managed), Parts of speech, Phrase sentiment, Regular expressions, Smart Document Understanding, Stemmer, Table Understanding \n English (en) Advanced rules models, Built-in entities, Classifier (Document and Text), Contracts, Custom entities, Dictionary, Document sentiment, Keywords, Machine Learning, Optical character recognition v1 (Installed), Optical character recognition v2 (Cloud-managed), Parts of speech, Phrase sentiment, Regular expressions, Smart Document Understanding, Stemmer, Table Understanding \n Finnish (fi) Classifier (Document and Text), Custom entities, Dictionary, Parts of speech, Regular expressions, Smart Document Understanding, Stemmer, Table Understanding \n French (fr) Advanced rules models, Built-in entities, Classifier (Document and Text), Custom entities, Dictionary, Document sentiment, Keywords, Machine Learning, Optical character recognition v1 (Installed), Optical character recognition v2 (Cloud-managed), Parts of speech, Regular expressions, Smart Document Understanding, Stemmer, Table Understanding \n German (de) Advanced rules models, Built-in entities, Classifier (Document and Text), Custom entities, Dictionary, Document sentiment, Keywords, Machine Learning, Optical character recognition v1 (Installed), Optical character recognition v2 (Cloud-managed), Parts of speech, Regular expressions, Smart Document Understanding, Stemmer, Table Understanding \n Hebrew (he) Classifier (Document and Text), Custom entities, Dictionary, Optical character recognition v2 (Cloud-managed), Parts of speech, Regular expressions, Smart Document Understanding, Table Understanding","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support"},{"document_id":"ibmcld_07037-3003-4984","score":11.2496413888,"text":"\nFor example, in the URL \/collections\/5a525eb7-b175-3820-0000-017d00f0fcd1\/activity, the collection ID is 5a525eb7-b175-3820-0000-017d00f0fcd1.)\n\n\n\n* If the problem has to do with documents failing to load, provide the following information if known:\n\n\n\n* What kind of documents are being uploaded (such as PDF, Json, CSV). Was optical character recognition (OCR) enabled for the collection?\n* How were the documents loaded into the collection? (using the API, from the product UI, data source connector)\n* Did you identify fields in the collection by using Smart Document Understanding? If so, what type of SDU model was applied to the collection (user-trained or pretrained)?\n* What enrichments were applied to the collection?\n\n\n\n* If the problem is related to a particular document (of a small set of documents), provide the document_id of the document, if known. You can share example documents if they might be helpful.\n* If the problem is related to querying documents, describe the kind of query being used.\n\n\n\n\n\n\n\n\n\n IBM Cloud Pak for Data Contacting IBM Support for installed deployments \n\nInstalled deployments are deployment that you provision on IBM Cloud Pak for Data.\n\nYou can get help by opening a case from IBM Support from [IBM Support](https:\/\/www.ibm.com\/mysupport\/s\/topic\/0TO50000000IYkUGAW\/cloud-pak-for-data).\n\nBe ready to share the following information with IBM Support:\n\n\n\n Account information \n\n\n\n* Account name or customer name.\n* Business impact so IBM Support understands the urgency of the issue and can prioritize it.\n* Case information for any related cases or a parent case.\n* Software versions of both the Discovery service version and IBM Cloud Pak for Data version.\n* Relevant details about configuration choices that were made during installation and deployment.\n\n\n\n\n\n\n\n Problem description \n\n\n\n* What outcome were you expecting and what happened?\n* Message text that is displayed when the error occurs, especially the document ID, if specified.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-get-help"},{"document_id":"ibmcld_13726-64047-65962","score":11.2149526019,"text":"\nFor more information about End of Service for Text to Speech, which is part of the Watson API Kit, see [Software support discontinuance: IBM Watson API Kit for IBM Cloud Pak for Data 1.2.x](https:\/\/www.ibm.com\/common\/ssi\/cgi-bin\/ssialias?subtype=ca&infotype=an&appname=iSource&supplier=897<=tternum=ENUS922-038).\n\n\n\n\n\n 27 April 2022 (Version 4.0.8) \n\nVersion 4.0.8 is now available\n: Text to Speech for IBM Cloud Pak for Data version 4.0.8 is now available. This version supports IBM Cloud Pak for Data version 4.x and Red Hat OpenShift versions 4.6 and 4.8. For more information about installing and managing the service, see [Installing Watson Text to Speech](https:\/\/www.ibm.com\/docs\/en\/cloud-paks\/cp-data\/4.0?topic=speech-installing-watson-text).\n\nNew environment variables used in IBM Cloud Pak for Data documentation\n: Most commands in the Text to Speech for IBM Cloud Pak for Data documentation have been updated to use a common set of environment variables. The documentation provides a script to automatically export the environment variables before you run installation, upgrade, and administration commands. After you source the script, you can copy most commands from the documentation and run them without making any changes.\n\nThe environment variables that the script defines include the following:\n\n\n\n* ${PROJECT_CPD_INSTANCE} identifies the project where you plan to install IBM Cloud Pak for Data and the Speech services.\n* ${PROJECT_CPD_OPS} identifies the project for the IBM Cloud Pak for Data platform operator.\n* ${PROJECT_CPFS_OPS} identifies the project for the IBM Cloud Pak for Data foundational services.\n\n\n\nFor more information about using the environment variables, see [Best practice: Setting up install variables](https:\/\/www.ibm.com\/docs\/en\/cloud-paks\/cp-data\/4.0?topic=installing-best-practice-setting-up-install-variables).\n\nThe ttsVoiceMarginalCPU property is no longer documented","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-release-notes-data"},{"document_id":"ibmcld_14692-1290-2509","score":11.1310676423,"text":"\nThen, you can use the request system license add file-name command to install the license.\n\nOptionally, use the show system license command to view details of the licenses.\n\nroot@host> show system license\n\nThe license key is installed and activated on the vSRX instance.\n\n\n\n\n\n Related links \n\n\n\n* [Getting started with IBM Cloud Juniper vSRX](https:\/\/cloud.ibm.com\/docs\/vsrx?topic=vsrx-getting-started)\n* [Juniper Networks vSRX deployment guide for VMware](https:\/\/www.juniper.net\/documentation\/en_US\/vsrx\/information-products\/pathway-pages\/security-vsrx-vmware-guide-pwp.html)\n* [Juniper Networks requirements for vSRX on VMware](https:\/\/www.juniper.net\/documentation\/en_US\/vsrx\/topics\/reference\/general\/security-vsrx-vmware-system-requirement.html)\n* [Juniper Networks vSRX installation with vSphere Web Client](https:\/\/www.juniper.net\/documentation\/en_US\/vsrx\/topics\/task\/installation\/security-vsrx-vsphere-client-installing.html)\n* [Juniper Networks configuring a vSRX Chassis Cluster in Junos OS](https:\/\/www.juniper.net\/documentation\/en_US\/vsrx\/topics\/task\/multi-task\/security-vsrx-chassis-cluster-configuring.html)\n* [Configure ECMP on VMware NSX](https:\/\/letsv4real.com\/2016\/09\/23\/configure-ecmp-on-vmware-nsx\/)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcsvsrx-licensing"},{"document_id":"ibmcld_14687-2923-3564","score":11.1223928557,"text":"\n* [Juniper Networks requirements for vSRX on VMware](https:\/\/www.juniper.net\/documentation\/en_US\/vsrx\/topics\/reference\/general\/security-vsrx-vmware-system-requirement.html)\n* [Juniper Networks vSRX installation with vSphere Web Client](https:\/\/www.juniper.net\/documentation\/en_US\/vsrx\/topics\/task\/installation\/security-vsrx-vsphere-client-installing.html)\n* [Juniper Networks configuring a vSRX Chassis Cluster in Junos OS](https:\/\/www.juniper.net\/documentation\/en_US\/vsrx\/topics\/task\/multi-task\/security-vsrx-chassis-cluster-configuring.html)\n* [Configure ECMP on VMware NSX](https:\/\/letsv4real.com\/2016\/09\/23\/configure-ecmp-on-vmware-nsx\/)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcsvsrx-components"},{"document_id":"ibmcld_14689-4129-4945","score":11.0987278877,"text":"\n* [Juniper Networks vSRX deployment guide for VMware](https:\/\/www.juniper.net\/documentation\/en_US\/vsrx\/information-products\/pathway-pages\/security-vsrx-vmware-guide-pwp.html)\n* [Juniper Networks requirements for vSRX on VMware](https:\/\/www.juniper.net\/documentation\/en_US\/vsrx\/topics\/reference\/general\/security-vsrx-vmware-system-requirement.html)\n* [Juniper Networks vSRX installation with vSphere Web Client](https:\/\/www.juniper.net\/documentation\/en_US\/vsrx\/topics\/task\/installation\/security-vsrx-vsphere-client-installing.html)\n* [Juniper Networks configuring a vSRX Chassis Cluster in Junos OS](https:\/\/www.juniper.net\/documentation\/en_US\/vsrx\/topics\/task\/multi-task\/security-vsrx-chassis-cluster-configuring.html)\n* [Configure ECMP on VMware NSX](https:\/\/letsv4real.com\/2016\/09\/23\/configure-ecmp-on-vmware-nsx\/)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcsvsrx-deployment"},{"document_id":"ibmcld_14693-9462-10278","score":11.0987278877,"text":"\n* [Juniper Networks vSRX Deployment Guide for VMware](https:\/\/www.juniper.net\/documentation\/en_US\/vsrx\/information-products\/pathway-pages\/security-vsrx-vmware-guide-pwp.html)\n* [Juniper Networks Requirements for vSRX on VMware](https:\/\/www.juniper.net\/documentation\/en_US\/vsrx\/topics\/reference\/general\/security-vsrx-vmware-system-requirement.html)\n* [Juniper Networks vSRX installation with vSphere Web Client](https:\/\/www.juniper.net\/documentation\/en_US\/vsrx\/topics\/task\/installation\/security-vsrx-vsphere-client-installing.html)\n* [Juniper Networks configuring a vSRX Chassis Cluster in Junos OS](https:\/\/www.juniper.net\/documentation\/en_US\/vsrx\/topics\/task\/multi-task\/security-vsrx-chassis-cluster-configuring.html)\n* [Configure ECMP on VMware NSX](https:\/\/letsv4real.com\/2016\/09\/23\/configure-ecmp-on-vmware-nsx\/)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcsvsrx-planning"},{"document_id":"ibmcld_00488-7-1471","score":11.0766474763,"text":"\nCreating a backup \n\nThis tutorial demonstrates how to use the [CouchBackup](https:\/\/www.npmjs.com\/package\/@cloudant\/couchbackup) utility to back up and restore a CouchDB or IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae instance. CouchBackup backs up the database to a file. If the database fails, you can use the backup file to restore the information to an existing database.\n\n\n\n Objectives \n\n\n\n1. Install CouchBackup.\n2. Create a sample database with documents.\n3. Set an environment variable.\n4. Back up a database.\n5. Create a log file.\n6. Restore a backup from a text file.\n\n\n\n\n\n\n\n Step 1: Installing CouchBackup \n\nInstall CouchBackup by running the install command.\n\nnpm install -g @cloudant\/couchbackup\n\n\n\n\n\n Step 2: Creating a sample database \n\nCreate a sample couchbackup-demo database for use with this tutorial.\n\n\n\n1. Create a database by running this command.\n\ncurl \"https:\/\/username:password@myhost.cloudant.com\/couchbackup-demo\" -X PUT\n2. Review the results.\n\n{\n\"ok\": true\n}\n\n\n\n\n\n\n\n Step 3: Creating documents in the sample database \n\nThe documents that you create in this exercise contain the data that you back up and restore in later exercises.\n\n\n\n1. Copy the sample text to a data file named bulkcreate.dat to create all five documents.\n\n{\n\"docs\":\n[\n{\n\"_id\": \"doc1\",\n\"firstname\": \"Sally\",\n\"lastname\": \"Brown\",\n\"age\": 16,\n\"location\": \"New York City, NY\"\n},\n{\n\"_id\": \"doc2\",\n\"firstname\": \"John\",\n\"lastname\": \"Brown\",\n\"age\": 21,\n\"location\": \"New York City, NY\"\n},\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-a-backup"},{"document_id":"ibmcld_05190-7292-8651","score":11.0200947407,"text":"\nThe full URL will then resemble \"https:\/\/(project-name)-navigator-pn.(cluster-name).(region).containers.appdomain.cloud\".\n\nThe Platform Navigator home page offers the ability to create instances of the various components.\n\nSee the full documentation in [IBM Documentation](https:\/\/www.ibm.com\/support\/knowledgecenter\/SSGT7J_20.3\/welcome.html). See Capability deployment.\n\n\n\n\n\n Known limitations \n\nThe IBM Cloud software catalog installer for Cloud Pak for Integration does not support;\n\n\n\n* Multi-zone region (MZR) clusters in IBM Cloud Classic infrastructure\n* Clusters deployed in IBM Cloud VPC, in either single zone or multi-zone topologies\n\n\n\nThis restriction is because those environments do not natively provide the replicated File storage that is required to deploy Cloud Pak for Integration in a resilient fashion.\n\nInstallation into MZR Classic clusters and IBM Cloud VPC is supported by manual installation of Cloud Pak for Integration (i.e. not using the software catalog installer) which enables the user to specify your choice of replicated storage provider that has been separately made available for use in the cluster, such as Portworx. Customers wishing to manually install Cloud Pak for Integration in this way can find instructions in [IBM Documentation here](https:\/\/www.ibm.com\/docs\/en\/cloud-paks\/cp-integration\/2021.1?topic=installing).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-pak-integration"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10041-5131-6632","score":4.5646590069,"text":"\nDELETE\/v1\/clusters\/{idOrName}\/usersubnets\/{subnetId}\/vlans\/{vlanId} Remove a user-managed subnet from a cluster. containers-kubernetes.cluster.operate containers-kubernetes.vlan.delete \n GET\/v1\/clusters List the clusters that you have access to. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName} View details for a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/addons View details of the add-ons that are enabled in a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/apiserverconfigs\/auditwebhook View details for an audit webhook configuration. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/config Get the cluster-specific configuration and certificates. containers-kubernetes.cluster.read containers-kubernetes.cluster.config \n GET\/v1\/clusters\/{idOrName}\/services List the IBM Cloud services bound to a cluster across all namespaces. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/services\/{namespace} List the IBM Cloud services bound to a specific namespace in a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/subnets List subnets from your IBM Cloud infrastructure account that are bound to a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/usersubnets List user-managed subnets that are bound to a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/webhooks List all webhooks for a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05567-5113-6614","score":4.5646590069,"text":"\nDELETE\/v1\/clusters\/{idOrName}\/usersubnets\/{subnetId}\/vlans\/{vlanId} Remove a user-managed subnet from a cluster. containers-kubernetes.cluster.operate containers-kubernetes.vlan.delete \n GET\/v1\/clusters List the clusters that you have access to. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName} View details for a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/addons View details of the add-ons that are enabled in a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/apiserverconfigs\/auditwebhook View details for an audit webhook configuration. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/config Get the cluster-specific configuration and certificates. containers-kubernetes.cluster.read containers-kubernetes.cluster.config \n GET\/v1\/clusters\/{idOrName}\/services List the IBM Cloud services bound to a cluster across all namespaces. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/services\/{namespace} List the IBM Cloud services bound to a specific namespace in a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/subnets List subnets from your IBM Cloud infrastructure account that are bound to a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/usersubnets List user-managed subnets that are bound to a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName}\/webhooks List all webhooks for a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_10041-8604-10172","score":4.5488417951,"text":"\nPATCH\/v1\/clusters\/{idOrName}\/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH\/v1\/clusters\/{idOrName}\/subnets\/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST\/v1\/clusters Create a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.create \n POST\/v1\/clusters\/{idOrName}\/kms Create a key management service (KMS) provider configuration for a cluster. containers-kubernetes.cluster.create containers-kubernetes.account.update \n POST\/v1\/clusters\/{idOrName}\/services Bind an IBM Cloud service to a cluster. containers-kubernetes.cluster.update containers-kubernetes.service.create \n POST\/v1\/clusters\/{idOrName}\/usersubnets Add an existing user-managed subnet to a cluster. containers-kubernetes.cluster.operate containers-kubernetes.subnet.create \n POST\/v1\/clusters\/{idOrName}\/vlans\/{vlanId} Create an IBM Cloud infrastructure subnet and add it to an existing cluster. containers-kubernetes.cluster.create containers-kubernetes.vlan.create \n POST\/v1\/clusters\/{idOrName}\/webhooks Add a webhook to a cluster. containers-kubernetes.cluster.update containers-kubernetes.cluster.create \n POST\/v2\/applyRBACAndGetKubeconfig Apply IAM roles to the cluster, then retrieve the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n POST\/v2\/autoUpdateMaster Set the autoupdate status of the cluster master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05567-8586-10154","score":4.5488417951,"text":"\nPATCH\/v1\/clusters\/{idOrName}\/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH\/v1\/clusters\/{idOrName}\/subnets\/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST\/v1\/clusters Create a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.create \n POST\/v1\/clusters\/{idOrName}\/kms Create a key management service (KMS) provider configuration for a cluster. containers-kubernetes.cluster.create containers-kubernetes.account.update \n POST\/v1\/clusters\/{idOrName}\/services Bind an IBM Cloud service to a cluster. containers-kubernetes.cluster.update containers-kubernetes.service.create \n POST\/v1\/clusters\/{idOrName}\/usersubnets Add an existing user-managed subnet to a cluster. containers-kubernetes.cluster.operate containers-kubernetes.subnet.create \n POST\/v1\/clusters\/{idOrName}\/vlans\/{vlanId} Create an IBM Cloud infrastructure subnet and add it to an existing cluster. containers-kubernetes.cluster.create containers-kubernetes.vlan.create \n POST\/v1\/clusters\/{idOrName}\/webhooks Add a webhook to a cluster. containers-kubernetes.cluster.update containers-kubernetes.cluster.create \n POST\/v2\/applyRBACAndGetKubeconfig Apply IAM roles to the cluster, then retrieve the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n POST\/v2\/autoUpdateMaster Set the autoupdate status of the cluster master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_10041-15253-16718","score":4.5406166119,"text":"\nDELETE\/v1\/alb\/albs\/{albID} Disable an ALB in a classic cluster. containers-kubernetes.cluster.update cluster-alb.delete \n DELETE\/v1\/alb\/clusters\/{idOrName}\/albsecrets Delete an ALB secret that is imported from Secrets Manager from a classic cluster. containers-kubernetes.cluster.create cluster-ingress-secret.delete \n GET\/v1\/alb\/albs\/{albID} View details of an ALB in a classic cluster. containers-kubernetes.cluster.read cluster-alb.get \n GET\/v1\/alb\/albtypes List the ALB types that are supported in classic clusters. containers-kubernetes.cluster.read N\/A \n GET\/v1\/alb\/clusters\/{idOrName} List all ALBs in a classic cluster. containers-kubernetes.cluster.read cluster-alb.list \n GET\/v1\/alb\/clusters\/{idOrName}\/albsecrets View details of an ALB secret that you imported from Secrets Manager to a classic cluster. containers-kubernetes.cluster.create cluster-ingress-secret.list \n GET\/v1\/alb\/clusters\/{idOrName}\/updatepolicy Check if automatic updates for Ingress ALBs are enabled in a classic cluster. containers-kubernetes.cluster.update cluster-alb-policy.get \n GET\/v2\/alb\/getAlb View details of an ALB. containers-kubernetes.cluster.read cluster-alb.get \n GET\/v2\/alb\/getAlbImages List supported Ingress controller images. containers-kubernetes.cluster.read alb-image.list \n GET\/v2\/alb\/getClusterAlbs List all ALBs in a cluster. containers-kubernetes.cluster.read cluster-alb.list \n GET\/v2\/alb\/getMigrationStatus Get the status of the Ingress migration process.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05567-3930-5493","score":4.5406166119,"text":"\nGET\/v2\/getCACert Get the cluster's CA certificate. containers-kubernetes.cluster.view cluster-ca-certificate.get \n POST\/v2\/rotateCACert Rotate the cluster's CA certificate. containers-kubernetes.cluster.create cluster-ca-certificate.rotate \n POST\/v2\/createCA Create a CA certificate. cluster-ca-certificate.create containers-kubernetes.cluster.create \n\n\n\n\n\n\n\n Cluster \n\nReview the following cluster API methods, their corresponding actions in IBM Cloud IAM, and the events that are sent to IBM Cloud Activity Tracker for IBM Cloud Kubernetes Service.\n\n\n\nCluster API methods, IAM actions, and Activity Tracker events.\n\n API Method Description IAM action for the API Activity Tracker event \n\n DELETE\/v1\/clusters\/{idOrName} Delete a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.delete \n DELETE\/v1\/clusters\/{idOrName}\/apiserverconfigs\/auditwebhook Delete an audit webhook configuration. containers-kubernetes.cluster.operate containers-kubernetes.cluster.delete \n DELETE\/v1\/clusters\/{idOrName}\/services\/{namespace}\/{serviceInstanceId} Unbind an IBM Cloud service from a cluster. containers-kubernetes.cluster.operate containers-kubernetes.service.delete \n DELETE\/v1\/clusters\/{idOrName}\/usersubnets\/{subnetId}\/vlans\/{vlanId} Remove a user-managed subnet from a cluster. containers-kubernetes.cluster.operate containers-kubernetes.vlan.delete \n GET\/v1\/clusters List the clusters that you have access to. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName} View details for a cluster. containers-kubernetes.cluster.read N\/A","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_05567-15233-16698","score":4.5406166119,"text":"\nDELETE\/v1\/alb\/albs\/{albID} Disable an ALB in a classic cluster. containers-kubernetes.cluster.update cluster-alb.delete \n DELETE\/v1\/alb\/clusters\/{idOrName}\/albsecrets Delete an ALB secret that is imported from Secrets Manager from a classic cluster. containers-kubernetes.cluster.create cluster-ingress-secret.delete \n GET\/v1\/alb\/albs\/{albID} View details of an ALB in a classic cluster. containers-kubernetes.cluster.read cluster-alb.get \n GET\/v1\/alb\/albtypes List the ALB types that are supported in classic clusters. containers-kubernetes.cluster.read N\/A \n GET\/v1\/alb\/clusters\/{idOrName} List all ALBs in a classic cluster. containers-kubernetes.cluster.read cluster-alb.list \n GET\/v1\/alb\/clusters\/{idOrName}\/albsecrets View details of an ALB secret that you imported from Secrets Manager to a classic cluster. containers-kubernetes.cluster.create cluster-ingress-secret.list \n GET\/v1\/alb\/clusters\/{idOrName}\/updatepolicy Check if automatic updates for Ingress ALBs are enabled in a classic cluster. containers-kubernetes.cluster.update cluster-alb-policy.get \n GET\/v2\/alb\/getAlb View details of an ALB. containers-kubernetes.cluster.read cluster-alb.get \n GET\/v2\/alb\/getAlbImages List supported Ingress controller images. containers-kubernetes.cluster.read alb-image.list \n GET\/v2\/alb\/getClusterAlbs List all ALBs in a cluster. containers-kubernetes.cluster.read cluster-alb.list \n GET\/v2\/alb\/getMigrationStatus Get the status of the Ingress migration process.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_10041-3946-5511","score":4.5398190148,"text":"\nGET\/v2\/getCACert Get the cluster's CA certificate. containers-kubernetes.cluster.view cluster-ca-certificate.get \n POST\/v2\/rotateCACert Rotate the cluster's CA certificate. containers-kubernetes.cluster.create cluster-ca-certificate.rotate \n POST\/v2\/createCA Create a CA certificate. cluster-ca-certificate.create containers-kubernetes.cluster.create \n\n\n\n\n\n\n\n Cluster \n\nReview the following cluster API methods, their corresponding actions in IBM Cloud IAM, and the events that are sent to IBM Cloud Activity Tracker for Red Hat OpenShift on IBM Cloud.\n\n\n\nCluster API methods, IAM actions, and Activity Tracker events.\n\n API Method Description IAM action for the API Activity Tracker event \n\n DELETE\/v1\/clusters\/{idOrName} Delete a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.delete \n DELETE\/v1\/clusters\/{idOrName}\/apiserverconfigs\/auditwebhook Delete an audit webhook configuration. containers-kubernetes.cluster.operate containers-kubernetes.cluster.delete \n DELETE\/v1\/clusters\/{idOrName}\/services\/{namespace}\/{serviceInstanceId} Unbind an IBM Cloud service from a cluster. containers-kubernetes.cluster.operate containers-kubernetes.service.delete \n DELETE\/v1\/clusters\/{idOrName}\/usersubnets\/{subnetId}\/vlans\/{vlanId} Remove a user-managed subnet from a cluster. containers-kubernetes.cluster.operate containers-kubernetes.vlan.delete \n GET\/v1\/clusters List the clusters that you have access to. containers-kubernetes.cluster.read N\/A \n GET\/v1\/clusters\/{idOrName} View details for a cluster. containers-kubernetes.cluster.read N\/A","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05891-18940-20907","score":4.5322682211,"text":"\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-f\n: Optional: Force the command to run with no user prompts.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster ca create command \n\nibmcloud ks cluster ca create --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud ks cluster ca get \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nView the details of a cluster's CA certificate.\n\nibmcloud ks cluster ca get --cluster CLUSTER [ --output OUTPUT] [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster ca get command \n\nibmcloud ks cluster ca get --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud ks cluster ca rotate \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nRotate the certificate authority (CA) certificates of a cluster. Rotating invalidates certificates signed by the cluster's previous CA and issues certificates signed by the cluster's new CA to worker nodes.\n\nBefore you run this command, follow the steps in [Rotating CA certificates in your cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitycert-rotate) to ensure that any tooling that uses the old CA certificates is updated to use the new certificates and to update your worker nodes.\n\nibmcloud ks cluster ca rotate --cluster CLUSTER [-f] [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-f\n: Optional: Force the command to run with no user prompts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_04489-18604-20571","score":4.5322682211,"text":"\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-f\n: Optional: Force the command to run with no user prompts.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster ca create command \n\nibmcloud ks cluster ca create --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud ks cluster ca get \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nView the details of a cluster's CA certificate.\n\nibmcloud ks cluster ca get --cluster CLUSTER [ --output OUTPUT] [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster ca get command \n\nibmcloud ks cluster ca get --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud ks cluster ca rotate \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nRotate the certificate authority (CA) certificates of a cluster. Rotating invalidates certificates signed by the cluster's previous CA and issues certificates signed by the cluster's new CA to worker nodes.\n\nBefore you run this command, follow the steps in [Rotating CA certificates in your cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitycert-rotate) to ensure that any tooling that uses the old CA certificates is updated to use the new certificates and to update your worker nodes.\n\nibmcloud ks cluster ca rotate --cluster CLUSTER [-f] [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-f\n: Optional: Force the command to run with no user prompts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":23.4439194498,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_13724-72779-74671","score":23.2370111195,"text":"\nThe customization interface includes a collection of new HTTP methods that have the names POST \/v1\/customizations, POST \/v1\/customizations\/{customization_id}, POST \/v1\/customizations\/{customization_id}\/words, and PUT \/v1\/customizations\/{customization_id}\/words\/{word}. The service also provides a new GET \/v1\/pronunciation method that returns the pronunciation for any word and a new GET \/v1\/voices\/{voice} method that returns detailed information about a specific voice. In addition, existing methods of the service's interface now accept custom model parameters as needed.\n\nFor more information about customization and its interface, see [Understanding customization](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-customIntro) and the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\nThe customization interface is a beta release that currently supports US English only. All customization methods and the GET \/v1\/pronunciation method can currently be used to create and manipulate custom models and word translations only in US English.\n\nNew Brazilian Portuguese voice: pt-BR_IsabelaVoice\n: The service supports a new voice, pt-BR_IsabelaVoice, to synthesize audio in Brazilian Portuguese with a female voice. For more information, see [Languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices).\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile Software Development Kits (SDKs) are available for the speech services. The SDKs enable mobile applications to interact with both the Text to Speech and Speech to Text services. You can use the SDKs to send text to the Text to Speech service and receive an audio response.\n\n\n\n* The Watson Swift SDK is available from the [swift-sdk repository](https:\/\/github.com\/watson-developer-cloud\/swift-sdk) in the watson-developer-cloud namespace on GitHub.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-release-notes"},{"document_id":"ibmcld_01660-16615-18504","score":23.1844019249,"text":"\nThe account selector displays the account name and account number, and you select the current account to display a list of other accounts that you can access.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/account\/images\/account-faq.svg)\n\nFigure 2. Account selector displays all accounts to which you have access\n\n\n\n\n\n Can I move data between IBM Cloud accounts? \n\nData can't be directly migrated from one IBM Cloud account to another. But, you might be able to re-create configurations and add them to another account. Consider the following approaches:\n\n\n\n* Save your applications and replicate them in different accounts by using GitHub or another code repository.\n* Review the applicable documentation to determine whether your infrastructure services can be backed up and re-created in different accounts.\n* Use manifests and other documented methods to rebuild your applications and services by using documented methods to back up and restore your data.\n\n\n\nUsers with a Basic, Advanced, or Premium support plan can open a [Support case](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) for assistance with data migration questions.\n\n\n\n\n\n Can I bookmark a console page for a specific account? \n\nYou can target URLs for any IBM Cloud console page to a specific account. If you have multiple accounts, you can bookmark the account-specific URLs to easily access resources in different accounts without having to manually switch between them.\n\n\n\n1. Switch to the account that you want to target, and go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console. In the Account section, find the account ID, such as a1b2c3d4e5f61234567890fedcba4321.\n2. Go to the console page that you want to bookmark, and add ?bss_account=<account-id> to the URL, replacing <account-id> with the ID from your account. For example,:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_13429-166159-168045","score":22.8352192909,"text":"\nNew UK English and Arabic models\n: The service supports more languages with its transcription models: en-UK_BroadbandModel and en-UK_NarrowbandModel for UK English, and ar-AR_BroadbandModel for Modern Standard Arabic. For more information, see [Previous-generation languages and models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models).\n\nNew session_closed field for session-based methods\n: In the JSON responses that it returns for errors with session-based methods, the service now also includes a new session_closed field. The field is set to true if the session is closed as a result of the error. For more information about possible return codes for any method, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nHTTP platform timeout no longer applies\n: HTTP recognition requests are no longer subject to a 10-minute platform timeout. The service now keeps the connection alive by sending a space character in the response JSON object every 20 seconds as long as recognition is ongoing. For more information, see [Timeouts](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-inputtimeouts).\n\nRate limiting with curl command no longer needed\n: When you use the curl command to transcribe audio with the service, you no longer need to use the --limit-rate option to transfer data at a rate no faster than 40,000 bytes per second.\n\nChanges to HTTP error codes\n: The service no longer returns HTTP status code 490 for the session-based HTTP methods GET \/v1\/sessions\/{session_id}\/observe_result and POST \/v1\/sessions\/{session_id}\/recognize. The service now responds with HTTP status code 400 instead.\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile SDKs are available for the speech services. The SDKs enable mobile applications to interact with both the Speech to Text and Text to Speech services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_07642-0-563","score":22.3791160634,"text":"\n\n\n\n\n\n\n  AC-19 (5) - Full Device \/ Container-based Encryption \n\n\n\n  Control requirements \n\nAC-19 (5) - 0\n:   The organization employs [IBM Assignment: file level, full disk\/device, or both] to protect the confidentiality and integrity of information on [Assignment: organization-defined mobile devices].\n\n\n\n\n\n  NIST supplemental guidance \n\nContainer-based encryption provides a more fine-grained approach to the encryption of data\/information on mobile devices, including for example, encrypting selected data structures such as files, records, or fields.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ac-19.5"},{"document_id":"ibmcld_16727-1086316-1088349","score":22.2891978991,"text":"\nThe account selector displays the account name and account number.\n* How can I join accounts?\n\nThe account owner, organization manager, or a user with the correct permissions can invite you to join their account.\n\n\n\n* If you're new to IBM Cloud\u00ae, you receive an email that contains all the information you need.\n* As an existing member of IBM Cloud\u00ae, you can accept the invitation in your notifications, by email, or by using the CLI to onboard to the new account. To accept invitations in the CLI, use the [ibmcloud login](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_cliaccept-invitation-to-join-a-new-account-) command.\n\n\n\n* Can I switch between multiple accounts?\n\nIf you have access to more than one account, you can click your account name in the console menu bar to switch to another account.\n\n![A screen capture of the account selector in the console menu bar. The account selector displays the account name and account number, and you select the current account to display a list of other accounts that you can access.](https:\/\/cloud.ibm.com\/images\/account-faq.svg)\n\nFigure 2. Account selector displays all accounts to which you have access\n* Can I move data between IBM Cloud accounts?\n\nData can't be directly migrated from one IBM Cloud account to another. But, you might be able to re-create configurations and add them to another account. Consider the following approaches:\n\n\n\n* Save your applications and replicate them in different accounts by using GitHub or another code repository.\n* Review the applicable documentation to determine whether your infrastructure services can be backed up and re-created in different accounts.\n* Use manifests and other documented methods to rebuild your applications and services by using documented methods to back up and restore your data.\n\n\n\nUsers with a Basic, Advanced, or Premium support plan can open a [Support case](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) for assistance with data migration questions.\n* Can I bookmark a console page for a specific account?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1083825-1085863","score":22.2463062736,"text":"\nThe account selector displays the account name and account number.\n* How can I join accounts?\n\nThe account owner, organization manager, or a user with the correct permissions can invite you to join their account.\n\n\n\n* If you're new to IBM Cloud\u00ae, you receive an email that contains all the information you need.\n* As an existing member of IBM Cloud\u00ae, you can accept the invitation in your notifications, by email, or by using the CLI to onboard to the new account. To accept invitations in the CLI, use the [ibmcloud login](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_cliaccept-invitation-to-join-a-new-account-) command.\n\n\n\n* Can I switch between multiple accounts?\n\nIf you have access to more than one account, you can click your account name in the console menu bar to switch to another account.\n\n![A screen capture of the account selector in the console menu bar. The account selector displays the account name and account number, and you select the current account to display a list of other accounts that you can access.](https:\/\/cloud.ibm.com\/docs\/images\/account-faq.svg)\n\nFigure 2. Account selector displays all accounts to which you have access\n* Can I move data between IBM Cloud accounts?\n\nData can't be directly migrated from one IBM Cloud account to another. But, you might be able to re-create configurations and add them to another account. Consider the following approaches:\n\n\n\n* Save your applications and replicate them in different accounts by using GitHub or another code repository.\n* Review the applicable documentation to determine whether your infrastructure services can be backed up and re-created in different accounts.\n* Use manifests and other documented methods to rebuild your applications and services by using documented methods to back up and restore your data.\n\n\n\nUsers with a Basic, Advanced, or Premium support plan can open a [Support case](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) for assistance with data migration questions.\n* Can I bookmark a console page for a specific account?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_14390-16273-17983","score":21.5595944301,"text":"\n* At the end of the documented process, your vCenter Server instance is running vSphere 7.0 Update 1c with N-VDS distributed switches. This configuration is different than the currently supported [Software BOM for vCenter Server instances](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_bomvc_bom-software), which is vSphere 7.0 Update 3c with Distributed vSwitch 7.0.0.\n* For more information about the migration of N-VDS to VDS switches for vSphere 7.0 or later and NSX-T Data Center 3.0 and later, see [Migrate host switch to vSphere Distributed Switch](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.1\/administration\/GUID-1039A36F-F55E-4A0A-B6C6-2C383F4A716D.html). Currently, this procedure is not verified on a VMware Solutions vCenter Server instance.\n* IBM Cloud is undertaking an assessment of the N-VDS to VDS conversion and the required changes to the automation database to allow this in-place upgrade.\n* Currently, Day 2 automation workflows such as add host or add cluster, are not tested against VMware Solutions vCenter Server instances that are upgraded from vSphere 6.7 to 7 and still using N-VDS distributed switches. Customers must assume that this automation might fail and that if this automation is required then the lift and shift migration approach used. If this automation is not needed, you can use the upgrade process that is documented.\n* A workaround for the add nodes and add cluster features is to use the VMware vSphere offering. For more information, see [VMware vSphere overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_vsphereclusteroverview). You must complete a number of manual tasks after the automated deployment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-faq-v2t-migration"},{"document_id":"ibmcld_10852-44214-45420","score":21.1299445875,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_00959-2830-5215","score":20.8023803099,"text":"\n* Avoid application downtime.\n* Enable production testing of new functions without impacting customers.\n* Limit the impact of production issues to a subset of users.\n* Enable rapid rollback to the previous version if issues are found.\n\n\n\nMany possible deployment strategies are available. In general, they depend on running multiple instances of the application and managing how the various instances are updated. You can pre-configure the following common deployment strategies in Continuous Delivery:\n\nBasic\n: Deploys the new release by stopping and updating all of the running instances simultaneously, causing downtime. For rollback, you must deploy the previous version again, which causes extra downtime. Although this strategy is simple, fast, and has low runtime resource requirements, it is the riskiest and causes downtime. The Basic deployment strategy is not recommended for critical apps that must be highly available.\n\nRolling update\n: Similar to the Basic strategy, this deployment strategy is simple, fast, and has low runtime resource requirements. However, because each running instance is taken down and updated individually, avoiding downtime, rollback requires you to deploy the previous release again. This time consuming approach might cause issues if the current version of the app in production is broken.\n\nBlue-Green deployment\n: Creates two separate, permanent production environments (blue and green), and only one of those environments receives traffic at a time. The current release is always deployed to the idle environment and traffic is switched to it after deployment completes, with no downtime. Because you need to switch only the traffic to the unchanged environment, rollback does not cause downtime. Because this strategy requires two full production environments, the resource requirements are higher. However, this strategy enables powerful Developer flows, such as the ability to test new app versions in the production environment before it allows customer traffic. Blue-Green deployment also supports fast rollback.\n\nCanary release\n: Deploys a new release in parallel with the original production environment (similar to Blue-Green), with no downtime. The amount of traffic that is sent to both the updated and original instances is managed so that the new version is available to a controlled subset of users while the deployment proceeds.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-tutorial-cd-kubernetes"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-1342-3184","score":47.5827044664,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-44214-45420","score":44.3217410223,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-7-1802","score":44.1636581304,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-43319-44485","score":43.7971285437,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_04518-7-1743","score":36.1614951394,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_04518-1426-3052","score":32.7244323461,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10817-2884-4620","score":32.6749640268,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_07551-14062-16080","score":32.4447006709,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_07551-15747-17355","score":31.9844044742,"text":"\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https:\/\/github.com\/IBM\/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n\/Register iOS devices\/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_10817-6582-8092","score":28.4105123546,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.8854598816,"ndcg_cut_10":0.8854598816}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-1342-3184","score":46.6614662659,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-44214-45420","score":44.7382803462,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10852-43319-44485","score":43.290172614,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-7-1802","score":39.2103380332,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-7-1743","score":37.2586281324,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_04518-1426-3052","score":35.4073332699,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10817-2884-4620","score":34.7748788677,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_07551-15747-17355","score":29.4813975984,"text":"\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https:\/\/github.com\/IBM\/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n\/Register iOS devices\/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_10817-6582-8092","score":29.4530304825,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_07551-14062-16080","score":28.5744866046,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"}],"retriever_scores":{}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06951-1555-3580","score":26.0260764276,"text":"\nFor more information, see [Data source requirements](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collection-typesrequirements).\n\nBefore you implement a custom connector, you need to know the following information about the data source:\n\n\n\n* The data source's network location (server name or address, including port, or URL, including port)\n* The data source's authentication method and security credentials\n* The path or paths on the data source that the connector needs to crawl\n* The connection method or protocol that the data source supports\n\n\n\n\n\n\n\n Designing a custom connector \n\nA custom connector needs the following capabilities:\n\n\n\n* Configuring a crawler.\n\n\n\n* Configuring all settings that are required to connect to the data source.\n* Discovering a crawl space on the data source. At least one crawl space is required.\n\n\n\n* Crawling documents.\n\n\n\n* Crawling the documents on each data set.\n* Adding Access Control List (ACL) information to each document.\n\n\n\n* Retrieving ACL information for the username that authenticates to the data source.\n\n\n\nThese capabilities can be implemented by using the interfaces and methods that are described in [Developing custom connector code](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-connector-dev).\n\n\n\n\n\n Custom connector limitations \n\nObserve the following notes and warnings when you implement a custom connector.\n\n\n\n* Custom connectors do not support the following features:\n\n\n\n* Synchronization settings\n* Filtering documents based on user access at query time. (At crawl and index time, only documents that the current user has the right to access are returned.)\n* The required and hidden validation settings. They are ignored when the connector is displayed in Discovery\n* The use of <condition \/> tags in the definition file. These tags are currently ignored.\n\n\n\n* When you use the example connector code in the current release, Discovery does not collapse and group authentication settings for the custom connector's properties.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-build-connector"},{"document_id":"ibmcld_03390-18760-20691","score":24.4587181372,"text":"\nMentions of a date or time that are relative to the current time are resolved for a chosen time zone. By default, the time zone is Greenwich mean time. Therefore, REST API clients that are located in different time zones get the current Coordinated Universal Time when now is mentioned in input.\n\nOptionally, the REST API client can add the local time zone as the context variable $timezone. This context variable must be sent with every client request. For example, the $timezone value can be America\/Los_Angeles, EST, or UTC. For a full list of supported time zones, see [Supported time zones](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-time-zones).\n\nWhen the $timezone variable is provided, the values of relative @sys-date and @sys-time mentions are computed based on the client time zone instead of UTC.\n\nFor information about processing date and time values, see the [Date and time method reference](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-methodsdialog-methods-date-time).\n\n\n\n\n\n\n\n @sys-number entity \n\nThe @sys-number system entity detects mentions of numbers in user input. The number can be written with either numerals or words. In either case, a number is returned.\n\n\n\n Recognized formats \n\n\n\n* 21\n* twenty one\n* 3.13\n\n\n\n\n\n\n\n Attributes \n\n\n\n* .literal: Exact phrase in input that is interpreted to be the number.\n* .location: Index element values of the first and last letters in the text string that is interpreted to be a number.\n* .numeric_value: Canonical numeric value as an integer or a double.\n* .range_link: If present, indicates that the user's input contains a number range. The location value of the text that specifies the range is appended to the link name. Additional information is provided, including the role that each @sys-number plays in the range relationship. For example, the start number has a role type of number_from and the end number has a role type of number_to.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities"},{"document_id":"ibmcld_03056-18596-20547","score":24.3183416614,"text":"\nMentions of a date or time that are relative to the current time are resolved for a chosen time zone. By default, the time zone is Greenwich mean time. Therefore, REST API clients that are located in different time zones get the current Coordinated Universal Time when now is mentioned in input.\n\nOptionally, the REST API client can add the local time zone as the context variable $timezone. This context variable must be sent with every client request. For example, the $timezone value can be America\/Los_Angeles, EST, or UTC. For a full list of supported time zones, see [Supported time zones](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-time-zones).\n\nWhen the $timezone variable is provided, the values of relative @sys-date and @sys-time mentions are computed based on the client time zone instead of UTC.\n\nFor information about processing date and time values, see the [Date and time method reference](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-methodsdialog-methods-date-time).\n\n\n\n\n\n\n\n @sys-number entity \n\nThe @sys-number system entity detects mentions of numbers in user input. The number can be written with either numerals or words. In either case, a number is returned.\n\n\n\n Recognized formats \n\n\n\n* 21\n* twenty one\n* 3.13\n\n\n\n\n\n\n\n Attributes \n\n\n\n* .literal: Exact phrase in input that is interpreted to be the number.\n* .location: Index element values of the first and last letters in the text string that is interpreted to be a number.\n* .numeric_value: Canonical numeric value as an integer or a double.\n* .range_link: If present, indicates that the user's input contains a number range. The location value of the text that specifies the range is appended to the link name. Additional information is provided, including the role that each @sys-number plays in the range relationship. For example, the start number has a role type of number_from and the end number has a role type of number_to.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-system-entities"},{"document_id":"ibmcld_07549-17189-19772","score":23.5291073659,"text":"\nIf the place to copy the object code is a network server, the Corresponding Source may be on a different server (operated by you or a third party) that supports equivalent copying facilities, provided you maintain clear directions next to the object code saying where to find the Corresponding Source. Regardless of what server hosts the Corresponding Source, you remain obligated to ensure that it is available for as long as needed to satisfy these requirements.e) Convey the object code using peer-to-peer transmission, provided you inform other peers where the object code and Corresponding Source of the work are being offered to the general public at no charge under subsection 6d. A separable portion of the object code, whose source code is excluded from the Corresponding Source as a System Library, need not be included in conveying the object code work.A \"User Product\" is either (1) a \"consumer product\", which means any tangible personal property which is normally used for personal, family, or household purposes, or (2) anything designed or sold for incorporation into a dwelling. In determining whether a product is a consumer product, doubtful cases shall be resolved in favor of coverage. For a particular product received by a particular user, \"normally used\" refers to a typical or common use of that class of product, regardless of the status of the particular user or of the way in which the particular user actually uses, or expects or is expected to use, the product. A product is a consumer product regardless of whether the product has substantial commercial, industrial or non-consumer uses, unless such uses represent the only significant mode of use of the product.\"Installation Information\" for a User Product means any methods, procedures, authorization keys, or other information required to install and execute modified versions of a covered work in that User Product from a modified version of its Corresponding Source. The information must suffice to ensure that the continued functioning of the modified object code is in no case prevented or interfered with solely because modification has been made.If you convey an object code work under this section in, or with, or specifically for use in, a User Product, and the conveying occurs as part of a transaction in which the right of possession and use of the User Product is transferred to the recipient in perpetuity or for a fixed term (regardless of how the transaction is characterized), the Corresponding Source conveyed under this section must be accompanied by the Installation Information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-notices"},{"document_id":"ibmcld_16507-7-2044","score":23.491662142,"text":"\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Natural Language Understanding\n\nA pre-annotator that you can use to find mentions of entities in your documents automatically. If your source documents have general knowledge subject matter, then this pre-annotator is a good choice for you. If you are working with highly specialized documents that focus on a specific field, such as patent law research, for example, the dictionary pre-annotator or rule-based model might be a better choice.\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_05477-16516-18542","score":23.2122101037,"text":"\nIf the build and push step failure problem isn't a problem with memory, a container registry secret, or a Dockerfile, then the problem is likely with the Docker build. The problem might be an error in the Dockerfile itself, for example, a syntax error, or in the correctness of the operation that it performs. The problem can also be in your source code, which might fail to compile, for example, if Java\u00ae code is included.\n\nIf you successfully built your project locally, but the same source code does not build in Code Engine, then you might have files available locally that are not in your Git repository. For example, for Node.js projects, it is common to run the npm install command locally so that project dependencies are downloaded and placed in the node_modules directory inside the project directory. It is a good practice to include the node_modules directory in the [.gitignore file](https:\/\/git-scm.com\/docs\/gitignore) to keep your Git repository small. A common mistake is to forget to also run npm install (or npm ci) in the Dockerfile. A Docker build that you run locally can access the local node_modules directory, if you copy the whole project into the container, for example, by using the COPY . \/app command in the Dockerfile. But, the Code Engine build runs from a freshly checked-out Git repository and cannot access the node_modules directory. Therefore, you must run npm install (or npm ci) in the Dockerfile as part of the build.\n\nA good practice is to include directories like node_modules also in a [.dockerignore file](https:\/\/docs.docker.com\/engine\/reference\/builder\/dockerignore-file) so that the Docker build that you run locally behaves the same as the Code Engine build.\n\nAnother reason for a project to be successfully built locally but to fail as Code Engine build are security limitations. As with applications and batch jobs, Code Engine does not allow arbitrary system operations within the Code Engine cluster. Most of those system operations are not relevant for Docker builds anyway.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-ts-build-bldpush-stepfail"},{"document_id":"ibmcld_14123-0-2327","score":23.1692429698,"text":"\n\n\n\n\n\n\n  Migrating a Hyper-V virtual machine \n\n\n\n  Before you begin \n\nBefore you begin, review the following prerequisites.\n\n\n\n*  A compatible server.\n*  A method of connecting from Source server to Destination Server.\n*  Source and destination server must reside on the same VLAN. If they do not reside on the same VLAN, reissuing an IP for the virtual machine is necessary (requires opening a support ticket).\n*  Virtual machines with working network uplinks and installed working\/supported software.\n\n\n\n\n\n\n\n  Why you might need to relocate your Hyper-V virtual machine \n\nThere are two common reasons that you might need to relocate your Hyper-V Virtual Machine:\n\n\n\n*  The VM is on hardware that is not functioning properly,\n*  The current host server is running low on resources.\n\n\n\nIn either event, the Hyper-V migration can be completed quickly if you have the previously mentioned requirements, complete the following steps.\n\n\n\n1.  Log in to the source server and open the Hyper-V Manager. Select the virtual machine that you want to migrate to the destination server.\n2.  Shut down the virtual machine that you want to migrate. Then select Export under the Server actions list enter the location of the export file.\n3.  Now, using RDP on the source server, you can log in to the destination server with the C: drive mounted to bring the file over.\n\nYou are transferring the file via a resource mount by using RDP. You can choose the transfer method that is most comfortable to you for this process (Windows Sharing, Resource mount via RDP, FTP, and other transfer methods).\n4.  Make sure that the file you are exporting is in the default location for Hyper-V virtual hard disks (VHD). The default location is C:UsersPublicDocumentsHyper-VVirtual hard disks. If you changed this default location and are not sure of what it was, you can select Hyper-V Settings > Import Virtual Machine to view the location.\n5.  After you locate the exported file and click Import, the virtual machine populates into your Hyper-V Manager with all configurations and files it had previously. The server is now online and working. If your server did not match the requirements and the destination server resides in a different VLAN, you need to Re-IP the virtual machine with a portable subnet that is routed as Secondary on VLAN.\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtualization?topic=virtualization-migrating-a-hyper-v-virtual-machine"},{"document_id":"ibmcld_00957-1744-3743","score":22.9087771963,"text":"\nIf you use the IBM Cloud console, complete the following steps:\n\n\n\n1. In the Apps Dashboard, select your app. The app details page opens.\n2. In the runtime pane, you can reduce the maximum memory limit or the numbers of app instances, or both, for your app.\n\n\n\nIf you use the cf command line interface, complete the following steps:\n\n\n\n1. Check how much memory is being used for your apps. The cf apps command lists all the apps that you deployed in your current space. The status of each app is also displayed.\n\ncf apps\n2. To reduce the amount of memory that is used by your app, reduce the number of app instances or the maximum memory limit, or both:\n\ncf push appname -p app_path -i instance_number -m memory_limit\n3. Restart your app for the changes to take effect.\n\n\n\n\n\n\n\n Can I use sample scripts to build and deploy my application? \n\nThe [open-toolchain\/commons](https:\/\/github.com\/open-toolchain\/commons) GitHub repo contains a collection of common scripts that you can use in toolchains and pipelines. For example, you can use one of the shell scripts that is contained in this repo within your own toolchains in various ways.\n\n\n\n\n\n How do I bring my own code and deploy it by using Continuous Delivery \n\nYou can choose any of the following options to deploy your own code to Continuous Delivery:\n\n\n\n* Create a toolchain by using one of the available templates (dependent on the deployment target and tool integrations). On the Create a Toolchain page, select the appropriate provider for your source repository, and then specify the link to your source code repo. After you create your toolchain, you might need to adjust the pipeline scripts for your deployment goals.\n* Create an empty toolchain, and then add tool integrations to deploy your app. For more information about using this method to deploy your code to Continuous Delivery, see [Continuous Deployment to Kubernetes](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-continuous-deployment-to-kubernetes).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-ts_cd"},{"document_id":"ibmcld_05382-7-1767","score":22.5013145427,"text":"\nWorking with jobs and job runs \n\nLearn how to run jobs in IBM Cloud\u00ae Code Engine. A job runs one or more instances of your executable code. Unlike applications, which handle HTTP requests, jobs are designed to run one time and exit. When you create a job, you can specify workload configuration information that is used each time that the job is run.\n\nBefore you begin\n\n\n\n* If you want to use the Code Engine console, go to [Code Engine overview](https:\/\/cloud.ibm.com\/codeengine\/overview).\n* If you want to use the CLI, [set up your Code Engine CLI environment](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-install-cli).\n* Plan and choose your approach for making your code run as a Code Engine job component.\n\n\n\nCode Engine provides custom resource definition (CRD) methods. For more information, see [Code Engine API reference - Batch CRD methods](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-apiapi-crd-batch).\n\n\n\n How do I make my code run as a Code Engine job component? \n\nWhether your code exists as source in a local file or in a Git repository, or your code is a container image that exists in a public or private registry, Code Engine provides a streamlined way for you to run your code as a job.\n\n\n\n* If you have a container image, per the [Open Container Initiative (OCI) standard](https:\/\/opencontainers.org\/), then you need to provide only a reference to the image, which points to the location of your container registry when you create your job. You can create your job from images in a [public registry](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-create-job) or [private registry](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-create-job-private) and then access the referenced image from your job run.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-job-plan"},{"document_id":"ibmcld_05265-7-1995","score":22.1108887955,"text":"\nWorking with apps in Code Engine \n\nAn application, or app, runs your code to serve HTTP requests. In addition to traditional HTTP requests, IBM Cloud\u00ae Code Engine also supports applications that use WebSockets as their communications protocol. The number of running instances of an app are automatically scaled up or down (to zero) based on incoming requests and your configuration settings. An app contains one or more revisions. A revision represents an immutable version of the configuration properties of the app. Each update of an app configuration property creates a new revision of the app.\n\nBefore you begin\n\n\n\n* If you want to use the Code Engine console, go to [Code Engine overview](https:\/\/cloud.ibm.com\/codeengine\/overview).\n* If you want to use the CLI, [set up your Code Engine CLI environment](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-install-cli).\n* Plan and choose your approach for making your code run as a Code Engine application component.\n* Ensure that your app follows the [12-factor app methodology](https:\/\/12factor.net\/).\n\n\n\nFor security features provided with Code Engine, see [Code Engine and security](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secure).\n\nCode Engine provides custom resource definition (CRD) methods. For more information, see [Code Engine API reference - Serving CRD methods](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-apiapi-crd-serving).\n\n\n\n How do I make my code run as a Code Engine application component? \n\nWhether your code exists as source in a local file or in a Git repository, or your code is a container image that exists in a public or private registry, Code Engine provides you a streamlined way to run your code as an app.\n\n\n\n* If you have a container image, per the [Open Container Initiative (OCI) standard](https:\/\/opencontainers.org\/), then you need to provide only a reference to the image, which points to the location of your container registry when you create and deploy your app.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-application-workloads"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-2884-4620","score":13.0285063313,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-7-1802","score":12.9217034119,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02665-1570-3896","score":12.8683246399,"text":"\nStandard The monthly instance price includes 1000 active entity IDs and 100,000 API calls. This plan includes feature flags in addition to the property management capabilities. \n Enterprise The monthly instance price includes 10,000 active entity IDs and 1,000,000 API calls. This plan includes percentage rollout and targeting segments in addition to property management and feature flags that are found in the Standard plan. \n\n\n\n\n\n\n\n What are the charges to use App Configuration? \n\nThe fundamental pricing metrics for App Configuration are Application Instance, Active Entity ID, and API Call.\n\nApplication Instance - An Application Instance is a uniquely named copy of App Configuration created by you but managed by IBM. Multiple instances of App Configuration within a single environment are all considered separate application instances, as are individual App Configuration instances in multiple environments (such as test, development, staging, or production).\n\nA single instance of App Configuration can serve multiple environments, and in fact the service is designed to do so.\n\nActive Entity ID - An active entity ID is a unique identifier for each entity that interacts with the App Configuration service. For example, an entity might be an instance of an app that runs on a mobile device, a microservice that runs on the cloud, or a component of infrastructure that runs that microservice. For any entity to interact with App Configuration, it must provide a unique entity ID. This task is most easily accomplished by programming your app or microservice to send the Entity ID by using the App Configuration SDK.\n\nAPI Call - An API call is the invocation of the App Configuration through a programmable interface.\n\nExactly what constitutes an API call varies depending on the entity type (for example, a microservice or a mobile app). For server-side entities like microservices, when the state of a feature flag or property changes in the App Configuration, a websocket connection notifies the SDK in the microservice that a state change occurred. The microservice then calls back into the App Configuration to retrieve the update. This action is an API call.\n\nAn API call also occurs on startup to the retrieve the initial configuration state. For client-side entities like mobile apps, websockets are not used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage"},{"document_id":"ibmcld_13067-1715-3771","score":12.1742861668,"text":"\nIBM Cloud\u00ae services are connected to a three-tiered network, segmenting public, private, and management traffic.\n\n\n\n* Private endpoints are available for most requests originating from within IBM Cloud. Private endpoints provide better performance and do not incur charges for any outgoing or incoming bandwidth even if the traffic is cross regions or across data centers. Whenever possible, it is best to use a private endpoint.\n* Public endpoints can accept requests from anywhere and charges are assessed on outgoing bandwidth. Incoming bandwidth is free. Public endpoints should be used for access not originating from an IBM Cloud cloud computing resource.\n* Direct endpoints are used in Bring-Your-Own-IP scenarios, generally for requests originating from [resources within VPCs](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc). Like Private endpoints, Direct endpoints provide better performance over Public endpoints and do not incur charges for any outgoing or incoming bandwidth even if the traffic is cross regions or across data centers. Directions for connecting to IBM Cloud Object Storage from VPC are available [here](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-connecting-vpc-cos).\n\n\n\nRequests must be sent to the endpoint associated with a given bucket's location. If you aren't sure where a bucket is located, there is an [extension to the bucket listing API](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/api-reference?topic=cloud-object-storage-compatibility-api-bucket-operationscompatibility-api-list-buckets-extended) that returns the location and storage class information for all buckets in a service instance.\n\nWhen using Virtual Private Endpoints in an application that makes requests to IBM COS, it may be necessary to add some additional configuration for authentication. The IBM COS SDKs will automatically attempt to fetch an IAM token from https:\/\/iam.cloud.ibm.com\/identity\/token. If you are using a virtualized endpoint for token acquisition you will need alter the IAM endpoint appropriately.\n\n\n\n\n\n Regional Endpoints","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage?topic=cloud-object-storage-endpoints"},{"document_id":"ibmcld_03893-6835-9080","score":11.9161737394,"text":"\nNote that when smart contracts are installed on peers that run a Fabric v2.x image, the smart contract is launched in its own pod instead of a separate container on the peer, which accounts for the smaller amount of resources required on the peer.\n\nWhile users of a free cluster must use default sizes for the containers associated with their nodes, users of paid clusters can set these values while the node is being created by clicking the Resource allocation box during the creation of their nodes. If this box is not checked, the default resource allocations, which can be seen below, will be used.\n\nFor cases when a user wants to minimize charges without stopping or deleting a node, it is possible to scale the node down to a minimum of 0.001 CPU (1 milliCPU). Note that the node will not be functional when using this amount of CPU.\n\nWhile the figures in this topic endeavor to be precise, be aware that there are times when a node may not deploy even when it appears that you have enough space in your cluster. Make sure to reference your Kubernetes dashboard to see when components deploy and for error messages when they don't. In cases where a component doesn't deploy for a lack of resources, even if there seems to be enough space in the cluster, you will likely have to deploy additional cluster resources for the component to deploy.\n\nThe Resource allocation panel in the console provides default values for the various fields that are involved in creating a node. These values are chosen because they represent a good way to get started. However, every use case is different. While this topic provides guidance for ways to think about these values, it ultimately falls to the user to monitor their nodes and find sizings that work for them. Therefore, barring situations in which users are certain that they need values different from the defaults, a practical strategy is to use these defaults at first and adjust them later. For an overview of performance and scale of Hyperledger Fabric, which the IBM Blockchain Platform is based on, see [Answering your questions on Hyperledger Fabric performance and scale](https:\/\/www.ibm.com\/blogs\/blockchain\/2019\/01\/answering-your-questions-on-hyperledger-fabric-performance-and-scale\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deployment"},{"document_id":"ibmcld_00642-4873-6822","score":11.8633268684,"text":"\nfunction(newDoc, oldDoc, userCtx) {\n\/\/ any update to an existing doc is OK\nif(oldDoc) {\nreturn;\n}\n\n\/\/ reject tombstones for docs we don\u2019t know about\nif(newDoc[\"_deleted\"]) {\nthrow({forbidden : \"Deleted document rejected\"});\n}\n\nreturn; \/\/ Not strictly necessary, but clearer.\n}\n\nTo use a validate_doc_update function to remove tombstone documents:\n\n\n\n1. Stop replication from the source to the target database.\n2. If appropriate, delete the target database, then create a new target database.\n3. Add a suitable validate_doc_update function, similar to the example provided.\n4. Add it to a design document in the target database.\n5. Restart replication between the source and the (new) target database.\n6. When replication is complete, switch your application logic to use the new database.\n7. Verify that your applications work correctly with the new database.\n\n\n\nWhen you're satisfied that everything is working correctly, you might want to delete the old database.\n\nHere is another variation for using the validate_doc_update function to remove tombstone documents if possible.\n\n\n\n1. Add some metadata to the tombstone documents, for example, to record the deletion date.\n2. Use the function to inspect the metadata and allow deletion documents through if they must be applied to the target database.\n\n\n\nThis check helps ensure correct replication of the deletion.\n\n\n\n\n\n Performance implications of tombstone removal \n\nTombstones are used for more consistent deletion of documents from databases. This purpose is especially important for mobile devices: without tombstone documents, a deletion might not replicate correctly to a mobile device, with the result that documents might never be deleted from the device.\n\nIf you re-create a database, for example, a new target for a replication. Any clients that use the target database as a server must work through all the changes again because the database sequence numbers are likely to be different.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-tombstone-docs"},{"document_id":"ibmcld_14546-4405-6573","score":11.8252833224,"text":"\nThis value includes public outbound traffic. \n\n\n\n\n\n\n\n VMware Shared Solutions Reserved billing plan \n\nVMware Shared Solutions Reserved virtual data center resources are preallocated and guaranteed. Pricing is monthly based on the allocation size of the virtual data center.\n\nThe standard storage policy pricing is the same as the 4-IOPS\/GB storage policy. The number of IOPS\/GB for the standard storage policy is not guaranteed.\n\nStorage policy availability can vary by region and deployment topology. On the VMware Shared order page, select the About tab to view available storage policy offerings.\n\nGeneral metrics\n\nStorage metrics\n\nOperating system metrics\n\n\n\nTable 3. VMware Shared Solutions Reserved billing plan - General metrics\n\n Metric Frequency Description \n\n MAX_VCPU Monthly The peak vCPU allocation for the virtual data center over the period of one month. The peak vCPU metric is determined by the largest vCPU reservation value that is selected by the customer over a one month period. \n MAX_RAM_GB Monthly The peak memory allocation for the virtual data center over the period of one month. The peak vCPU metric is determined by the largest memory reservation value that is selected by the customer over a one month period. \n TOTAL_EGRESS_GB Usage The total outbound public traffic is charged per GB transferred over the period of one month. This value includes the outbound traffic through the virtual data center NSX edge to the public internet. \n\n\n\n\n\n\n\n Private network endpoint billing plan \n\nPrivate network endpoint usage incurs charges as part of the on-demand or reserved virtual data center plan. On the VMware Shared order page, select the About tab to view the pricing plan details.\n\n\n\nTable 4. Billing plan for private network endpoints\n\n Metric Frequency Description \n\n MAX_PRIVATE_NETWORK_ONE_G_COST Monthly Charge for private network endpoint at 1 GB uplink over a period of one month. \n MAX_PRIVATE_NETWORK_TEN_G_COST Monthly Charge for private network endpoint at 10 GB uplink over a period of one month. \n\n\n\n\n\n\n\n Licenses and fees for Veeam Availability Suite and Zerto \n\nVeeam\u00ae and Zerto usage incurs the following on-demand charges.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_pricing"},{"document_id":"ibmcld_07532-3613-6012","score":11.2218658601,"text":"\nThe IBM Cloud push service has two components to pricing: a destination instance fee and a consumption price.\n\nA pre-production destination instance fee is charged monthly. Every pre-production destination added to your Event Notifications instance incurs the fee.\n\nConsumption: Only 500 devices or 5000 outbound digital messages is permitted per pre-production destination. If either the number of devices or the number of outbound digital messages exceeds the permitted limit, the permitted number of devices is moved by additional 500 devices or by additional 5000 messages and charged.\n\nFor example, if you tried to send 5001th message, the message cap automatically is raised to 10000 (another 5000 messages are added) for the month and the device cap is raised to 1000 (another 500 devices are added) per month. Notice that both limits are always raised even if only one cap has been exceeded.\n\n\n\n\n\n Push charges for changing from pre-production destination to production destination \n\nYou can change a pre-production destination to a production destination at any particular time and the charges are calculated accordingly.\n\nThe push service has two components to pricing: a destination instance fee and a consumption price.\n\nA pre-production destination instance fee is charged monthly. Every pre-production destination added to your Event Notifications instance incurs the fee.\n\nA production destination instance fee is also charged monthly and allows unlimited devices and outbound messages.\n\nIf you change a pre-production destination to a production destination, the charges for the transition month would be the pre-producdtion fee + pro-rated charge for the production instance.\n\nFor example, assume the pre-production instance fee is $15 per month and the production instance fee is $50 per month.\n\nThese prices are assumed for this example only. Current pricing may be different from the amounts shown in the example. See the Event Notifications catalog page for current pricing.\n\n\n\n* As of 31 July, you create a pre-production destination and does not register any devices or send messages, the charges for July will be $15.\n* As of 1 August, you register 500 devices and 5001 messages sent. The charges for August will be $30 (This is due to the message threshold exceeds the permitted limit.)\n* As of 5 August, you change from pre-production destination to production destination.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-destinations-push"},{"document_id":"ibmcld_10852-45155-46272","score":11.1633862362,"text":"\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)\n* [Invoking actions with mobile SDK from WhiskButton](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-actions-whiskbutton)\n\n\n\n\n\n[Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage)\n\n\n\n* [Packages for Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstorageobstorage_packages)\n* [Setting up the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_ev)\n\n\n\n* [Prerequisites for working with the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragecos_changes_pre)\n* [1. Assigning the Notifications Manager role to your Cloud Functions namespace](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_auth)\n* [2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-6582-8092","score":11.0947690693,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.25,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.2463023887,"ndcg_cut_10":0.2463023887}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13360-2974-4481","score":20.4004412638,"text":"\nSuppose the user speaks one of the names from the grammar's rules, Yon See. The service returns a response that indicates a very high level of confidence in the match.\n\n{\n\"result_index\": 0,\n\"results\": [\n{\n\"alternatives\":\n{\n\"confidence\": 0.92,\n\"transcript\": \"Yon See\"\n}\n],\n\"final\": true\n}\n]\n}\n\nNow suppose that the user speaks two names separated by enough silence, at least 0.8 seconds, to indicate that they are separate utterances: Yon See [1.0 seconds of silence] Yi Wen Tan. In this case, the service sends two separate responses with a different confidence score for each result.\n\n{\n\"result_index\": 0,\n\"results\": [\n{\n\"alternatives\":\n{\n\"confidence\": 0.92,\n\"transcript\": \"Yon See\"\n}\n],\n\"final\": true\n}\n]\n},\n{\n\"result_index\": 1,\n\"results\": [\n{\n\"alternatives\":\n{\n\"confidence\": 0.83,\n\"transcript\": \"Yi Wen Tan\"\n}\n],\n\"final\": true\n}\n]\n}\nShow more\n\nNow consider the case where the user instead says something like Yon See [1.0 seconds of silence] Young Says He. For the first phrase, Yon See, the service sends a positive match with a confidence score, similar to the previous examples. For the second phrase, Young Says He, the service can have one of two possible responses:\n\n\n\n* It might send no response, indicating that the phrase does not match one of the grammar's rules.\n* It might instead send a response with a low confidence score, indicating that the phrase is acoustically similar to one of the rules but is not a likely match.\n\n\n\nOther factors and parameters can also effect grammar recognition:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarUnderstand"},{"document_id":"ibmcld_13360-1543-3265","score":19.9571630204,"text":"\nIt can also return no result if the input clearly does not match one of the two phrases.\n\nFor instance, if the user replies yes, the service likely returns a response that is very much like the following result. The score in the confidence field indicates a perfectly reliable match.\n\n{\n\"result_index\": 0,\n\"results\": [\n{\n\"alternatives\":\n{\n\"confidence\": 1.0,\n\"transcript\": \"yes\"\n}\n],\n\"final\": true\n}\n]\n}\n\nBut suppose, for example, the user replies nope. The service can return either a result with a very low confidence score or no result at all. An empty result is the clearest indication that the response does not match the grammar. An empty response is more likely to occur with complex grammars, where a valid response must match a specific multi-phrase sequence.\n\n\n\n\n\n Multi-phrase matches: The names grammar \n\nWith a multi-phrase grammar, the user's response must be complete to be recognized. The user cannot omit a word or stop in the middle of the response. The absence of even a single word can cause the service to return an empty result.\n\nMoreover, the service can return multiple transcripts if the user speaks phrases that are separated by sufficient silence to indicate that they are independent utterances. For example, consider the simple names grammar, which can match one of three multi-word names.\n\nABNF 1.0 ISO-8859-1;\nlanguage en-US;\nmode voice;\nroot $names;\n\n$names = Yi Wen Tan | Yon See | Youngjoon Lee ;\n\nSuppose the user speaks one of the names from the grammar's rules, Yon See. The service returns a response that indicates a very high level of confidence in the match.\n\n{\n\"result_index\": 0,\n\"results\": [\n{\n\"alternatives\":\n{\n\"confidence\": 0.92,\n\"transcript\": \"Yon See\"\n}\n],\n\"final\": true\n}\n]\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarUnderstand"},{"document_id":"ibmcld_12467-10799-12701","score":17.2256612158,"text":"\nTo help you to create a new lock and remove older locks in a single operation, you can also specify an optional mode at lock creation.\n\n\n\nTable 1. Optional lock modes and their descriptions\n\n Mode Query parameter Description \n\n Remove previous locks mode=remove_previous Removes any other locks that match the name that you specify. If any matching locks are found in the previous version of the secret, those locks are deleted when your new lock is created.<br><br>For example, suppose that the previous version of your secret contains a lock lock-x. Creating a lock and enabling the remove_previous mode on the current secret version results in removing lock-x from the previous version. \n Remove previous locks mode=remove_previous_and_delete Same as the remove_previous option, but also permanently deletes the data of the previous secret version if it doesn't have any locks that are associated with it.<br><br>Suppose that the previous version of your secret contains a lock lock-z. Creating a lock and enabling the remove_previous_and_delete mode on the current secret version results in removing lock-z from the previous version. Additionally, because the previous version doesn't have any other locks that are attached to it, the secret data that is associated with the previous version is also deleted. \n\n\n\n\n\n Creating locks on the current secret version \n\nThe following request creates two locks on the current version of a secret. When you call the API, replace the ID variables and IAM token with the values that are specific to your Secrets Manager instance.\n\ncurl -X POST\n-H \"Authorization: Bearer {iam_token}\" -H \"Accept: application\/json\" -H \"Content-Type: application\/json\" -d '{\n\"locks\": [\n{\n\"name\": \"lock-1\",\n\"description\": \"Lock for consumer 1.\",\n\"attributes\": {\n\"key\": \"value\"\n}\n},\n{\n\"name\": \"lock-2\",\n\"description\": \"Lock for consumer 2.\",\n\"attributes\": {\n\"key\": \"value\"\n}\n}\n]\n}'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secret-locks"},{"document_id":"ibmcld_12467-3399-5495","score":16.7805190804,"text":"\nRotation is allowed only after all locks on the previous secret version are removed.\n\n\n\n\n\n Creating locks in the UI \n\nYou can create up to 1000 locks on a secret by using the Secrets Manager UI. Each lock can be used to represent a single application or service that uses your secret.\n\nA secret is considered locked after you attach one or more locks to it. A lock can be applied only on a secret version that contains active payload, or secret data.\n\nTo help you to create a new lock and remove older locks in a single operation, you can also specify an optional mode at lock creation.\n\n\n\nTable 1. Optional lock modes and their descriptions\n\n Mode Description \n\n Remove previous locks Removes any other locks that match the name that you specify. If any matching locks are found in the previous version of the secret, those locks are deleted when your new lock is created.<br><br>For example, suppose that the previous version of your secret contains a lock lock-x. Creating a lock on the current version of your secret and enabling the Delete matching locks option results in removing lock-x from the previous version. \n Remve previous locks and delete previous version data Same as the previous option, but also permanently deletes the data of the previous secret version if it doesn't have any locks that are associated with it.<br><br>Suppose that the previous version of your secret contains a lock lock-z. Creating a lock on the current version of your secret with both the Delete matching locks and Delete previous version data options results in removing lock-z from the previous version. Additionally, because the previous version doesn't have any other locks that are attached to it, the secret data that is associated with the previous version is also deleted. \n\n\n\n\n\n Creating a lock on the current secret version \n\nYou can lock the current version of a secret by using the Secrets Manager UI. A successful request attaches a new lock to the current version of your selected secret, or replaces a lock of the same name if it already exists.\n\n\n\n1. In the console, click the Menu icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secret-locks"},{"document_id":"ibmcld_13423-3721-5107","score":16.7634477561,"text":"\nThe speaker might be reading a six-digit number from an identification card, for example, and pause to confirm the number.\n\nThe first example uses the default pause interval of 0.8 seconds:\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: audio\/wav\" --data-binary @{path}audio-file.wav \"{url}\/v1\/recognize\"\n\nIBM Cloud Pak for Data\n\ncurl -X POST --header \"Authorization: Bearer {token}\" --header \"Content-Type: audio\/wav\" --data-binary @{path}audio-file.wav \"{url}\/v1\/recognize\"\n\nBecause the pause is greater than the default interval, the service splits the transcript at the pause. The confidence of both results is 0.99, so transcription accuracy is very good despite the pause.\n\n{\n\"result_index\": 0,\n\"results\": [\n{\n\"alternatives\":\n{\n\"confidence\": 0.99,\n\"transcript\": \"one two three \"\n}\n],\n\"final\": true\n},\n{\n\"alternatives\":\n{\n\"confidence\": 0.99,\n\"transcript\": \"four five six \"\n}\n],\n\"final\": true\n}\n]\n}\nShow more\n\nBut suppose speech recognition is performed with a grammar that expects the user to speak six digits in a single-phrase response. Because the service splits the transcript at the one-second pause, the results are empty. The grammar is applied to each final result, but neither result, \"one two three\" nor \"four five six\", contains six digits.\n\nThe second example uses the same audio but sets the end_of_phrase_silence_time to 1.5 seconds:\n\nIBM Cloud","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-parsing"},{"document_id":"ibmcld_12467-7575-9740","score":16.6194652285,"text":"\nOptional: Attach JSON attributes to your lock.\n\nYou can include a JSON object with each lock to hold any information that you might need for an automated flow. For example, a key-value pair that identifies the resource that you want to associate with this lock.\n8. Click Create.\n\nA new lock is created for your selected secret version.\n\n\n\n\n\n\n\n\n\n Creating locks from the CLI \n\nYou can create up to 1000 locks on a secret by using the Secrets Manager CLI. Each lock can be used to represent a single application or service that uses your secret.\n\nA secret is considered locked after you attach one or more locks to it. A lock can be applied only on a secret version that contains active payload, or secret data.\n\nTo help you to create a new lock and remove older locks in a single operation, you can also specify an optional mode at lock creation.\n\n\n\nTable 1. Optional lock modes and their descriptions\n\n Mode Description \n\n Remove previous locks Removes any other locks that match the name that you specify. If any matching locks are found in the previous version of the secret, those locks are deleted when your new lock is created.<br><br>For example, suppose that the previous version of your secret contains a lock lock-x. Creating a lock on the current version of your secret and enabling the Delete matching locks option results in removing lock-x from the previous version. \n Remve previous locks and delete previous version data Same as the previous option, but also permanently deletes the data of the previous secret version if it doesn't have any locks that are associated with it.<br><br>Suppose that the previous version of your secret contains a lock lock-z. Creating a lock on the current version of your secret with both the Delete matching locks and Delete previous version data options results in removing lock-z from the previous version. Additionally, because the previous version doesn't have any other locks that are attached to it, the secret data that is associated with the previous version is also deleted. \n\n\n\n\n\n Creating a lock on the current secret version \n\nYou can lock the current version of a secret by using the Secrets Manager CLI.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secret-locks"},{"document_id":"ibmcld_01760-1538-3430","score":16.1658814,"text":"\n[Navigation Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_hamburger.svg) > Observability > Activity Tracker.\n2. Click Open dashboard on the dashboard that you use to monitor context-based restrictions.\n3. Use the search field to narrow the results to report-only context-based restrictions events.\n\n\n\n1. To view potentially blocked access requests, search for action:context-based-restrictions.policy.eval responseData.isEnforced:==false responseData.decision:Deny.\n\n\n\n* isEnforced:==false indicates that the rule is in report-only mode.\n* responseData.decision:Deny indicates that, if you enable the rule, this access request is blocked.\n\n\n\nEvaluate whether this access flow is supposed to be denied, or whether you need to update your rule to allow access so that your workflows don't break.\n2. To view potentially allowed access requests, search for action:context-based-restrictions.policy.eval responseData.isEnforced:==false responseData.decision:Permit.\n\n\n\n* isEnforced:==false indicates that the rule is in report-only mode.\n* responseData.decision:Permit indicates that, if you enable the rule, this access request is allowed.\n\n\n\nEvaluate whether this access flow is supposed to be allowed, or whether you need to update your rule to deny access so that your resources are protected.\n\n\n\n\n\n\n\n\n\n Determining how enabled rules affect access \n\nWhen you enable a rule, some users, applications, and workflows might be affected. If your users or applications can't access something that they previously had access to, you can search in Activity Tracker and view what rules are denying the requests. You can further refine the search by filtering on the subject or resource to identify the implicated rule, which is represented by the target id. Then, you can update the rule to allow access so that your workflows don't break.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-cbr-monitor"},{"document_id":"ibmcld_13499-23817-25273","score":15.8641396465,"text":"\n: Returns the first value of expr for a group of rows. If isIgnoreNull is true, returns only nonnull values.\n\n\n\n\n\n first_value \n\nfirst_value(expr[, isIgnoreNull])\n: Returns the first value of expr for a group of rows. If isIgnoreNull is true, returns only nonnull values.\n\n\n\n\n\n float \n\nfloat(expr)\n: Casts the value expr to the target data type float.\n\n\n\n\n\n floor \n\nfloor(expr)\n: Returns the largest integer not greater than expr.\n: Example of an SQL function usage fragment\n\n> SELECT floor(-0.1)\n: Result value\n\n-1\n: Example of an SQL function usage fragment\n\n> SELECT floor(5)\n: Result value\n\n5\n\n\n\n\n\n format_number \n\nformat_number(expr1, expr2)\n: Formats the number expr1 like '#,###,###.##', rounded to expr2 decimal places. If expr2 is 0, the result has no decimal point or fractional part. This function is supposed to work like MySQL's FORMAT.\n: Example of an SQL function usage fragment\n\n> SELECT format_number(12332.123456, 4)\n: Result value\n\n12,332.1235\n\n\n\n\n\n format_string \n\nformat_string(strfmt, obj, ...)\n: Returns a formatted string from printf-style format strings.\n: Example of an SQL function usage fragment\n\n> SELECT format_string(\"Hello World %d %s\", 100, \"days\")\n: Result value\n\nHello World 100 days\n\n\n\n\n\n from_json \n\nfrom_json(jsonStr, schema[, options])\n: Returns a struct value with the indicated jsonStr and schema.\n: Example of an SQL function usage fragment\n\n> SELECT from_json('{\"a\":1, \"b\":0.8}', 'a INT, b DOUBLE')\n: Result value","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sqlfunctions"},{"document_id":"ibmcld_13423-4658-6436","score":15.7305625229,"text":"\nBut suppose speech recognition is performed with a grammar that expects the user to speak six digits in a single-phrase response. Because the service splits the transcript at the one-second pause, the results are empty. The grammar is applied to each final result, but neither result, \"one two three\" nor \"four five six\", contains six digits.\n\nThe second example uses the same audio but sets the end_of_phrase_silence_time to 1.5 seconds:\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: audio\/wav\" --data-binary @{path}audio-file.wav \"{url}\/v1\/recognize?end_of_phrase_silence_time=1.5\"\n\nIBM Cloud Pak for Data\n\ncurl -X POST --header \"Authorization: Bearer {token}\" --header \"Content-Type: audio\/wav\" --data-binary @{path}audio-file.wav \"{url}\/v1\/recognize?end_of_phrase_silence_time=1.5\"\n\nBecause this value is greater than the length of the speaker's pause, the service returns a single final result that contains the entire spoken phrase. A grammar that expects to find six digits recognizes this transcript.\n\n{\n\"result_index\": 0,\n\"results\": [\n{\n\"alternatives\":\n{\n\"confidence\": 1.0,\n\"transcript\": \"one two three four five six \"\n}\n],\n\"final\": true\n}\n]\n}\n\n\n\n\n\n\n\n Split transcript at phrase end \n\nThe split_transcript_at_phrase_end parameter directs the service to split the transcript into multiple final results based on semantic features of the input. Setting the parameter to true causes the service to split the transcript at the conclusion of meaningful phrases such as sentences. The service bases its understanding of semantic features on the base language model that you use with the request along with a custom language model or grammar that you use. Custom language models and grammars can influence how and where the service splits a transcript.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-parsing"},{"document_id":"ibmcld_13373-7-1706","score":15.6264659482,"text":"\nKnown limitations \n\nThe Speech to Text service has the following known limitations. These issues apply to service functionality that spans releases for all platforms. For information about known limitations specific to Speech to Text for IBM Cloud Pak for Data version 4.6.x, see [Limitations and known issues in Watson Speech services](https:\/\/www.ibm.com\/docs\/en\/cloud-paks\/cp-data\/4.6.x?topic=issues-watson-speech-services).\n\n\n\n Issue: Interim results for previous-generation models \n\n27 April 2021: When you use previous-generation models with the WebSocket interface, if you request both speaker labels and interim results, the speaker labels response includes an extra object. The final results duplicate the object for the last speaker label. Instead of appearing once with \"final\": true, the object appears twice: once with \"final\": false and once with \"final\": true.\n\nFor example, a WebSocket request that includes both speaker labels and interim results sends a start message like the following:\n\nvar message = {\naction: 'start',\nspeaker_labels: true,\ninterim_results: true\n};\nwebsocket.send(JSON.stringify(message));\n\nTo indicate final results for speaker labels, the service is supposed to return a response of the following form:\n\n{\n\"speaker_labels\": [\n. . .\n{\n\"from\": 1.01,\n\"to\": 1.75,\n\"speaker\": 0,\n\"confidence\": 0.75,\n\"final\": false\n},\n{\n\"from\": 1.76,\n\"to\": 2.50,\n\"speaker\": 1,\n\"confidence\": 0.80,\n\"final\": true\n}\n]\n}\nShow more\n\nInstead, the service returns final results like the following. Note that the object for the last speaker label, which begins at 1.76 and ends at 2.50, is returned twice. The \"final\": true indication is associated with the second instance of the label.\n\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-known-limitations"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-6582-8092","score":20.113020607,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-7-1802","score":19.2835835412,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-2884-4620","score":19.2641317909,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-45155-46272","score":15.8774179019,"text":"\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)\n* [Invoking actions with mobile SDK from WhiskButton](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-actions-whiskbutton)\n\n\n\n\n\n[Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage)\n\n\n\n* [Packages for Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstorageobstorage_packages)\n* [Setting up the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_ev)\n\n\n\n* [Prerequisites for working with the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragecos_changes_pre)\n* [1. Assigning the Notifications Manager role to your Cloud Functions namespace](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_auth)\n* [2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-1342-3184","score":15.5429226487,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_00642-4873-6822","score":15.3826234301,"text":"\nfunction(newDoc, oldDoc, userCtx) {\n\/\/ any update to an existing doc is OK\nif(oldDoc) {\nreturn;\n}\n\n\/\/ reject tombstones for docs we don\u2019t know about\nif(newDoc[\"_deleted\"]) {\nthrow({forbidden : \"Deleted document rejected\"});\n}\n\nreturn; \/\/ Not strictly necessary, but clearer.\n}\n\nTo use a validate_doc_update function to remove tombstone documents:\n\n\n\n1. Stop replication from the source to the target database.\n2. If appropriate, delete the target database, then create a new target database.\n3. Add a suitable validate_doc_update function, similar to the example provided.\n4. Add it to a design document in the target database.\n5. Restart replication between the source and the (new) target database.\n6. When replication is complete, switch your application logic to use the new database.\n7. Verify that your applications work correctly with the new database.\n\n\n\nWhen you're satisfied that everything is working correctly, you might want to delete the old database.\n\nHere is another variation for using the validate_doc_update function to remove tombstone documents if possible.\n\n\n\n1. Add some metadata to the tombstone documents, for example, to record the deletion date.\n2. Use the function to inspect the metadata and allow deletion documents through if they must be applied to the target database.\n\n\n\nThis check helps ensure correct replication of the deletion.\n\n\n\n\n\n Performance implications of tombstone removal \n\nTombstones are used for more consistent deletion of documents from databases. This purpose is especially important for mobile devices: without tombstone documents, a deletion might not replicate correctly to a mobile device, with the result that documents might never be deleted from the device.\n\nIf you re-create a database, for example, a new target for a replication. Any clients that use the target database as a server must work through all the changes again because the database sequence numbers are likely to be different.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-tombstone-docs"},{"document_id":"ibmcld_10817-7707-9426","score":14.3052906991,"text":"\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate\nlet session = NSURLSession(configuration: NSURLSessionConfiguration.defaultSessionConfiguration(), delegate: NetworkUtilsDelegate(), delegateQueue:NSOperationQueue.mainQueue())\n\/\/ set the SDK to use this urlSession instead of the default shared one\nwhisk.urlSession = session\n\n\n\n Support for qualified names with mobile SDK \n\nAll actions and triggers have a fully qualified name that is made up of a namespace, a package, and an action or trigger name. The SDK can accept these elements as parameters when you are invoking an action or Firing a trigger. The SDK also provides a function that accepts a fully qualified name that looks like \/mynamespace\/mypackage\/nameOfActionOrTrigger. The qualified name string supports unnamed default values for namespaces and packages that all Cloud Functions users have, so the following parsing rules apply:\n\n\n\n* qName = \"foo\" results in namespace = default, package = default, action\/trrigger = \"foo\"\n* qName = \"mypackage\/foo\" results in namespace = default, package = mypackage, action\/trigger = \"foo\"\n* qName = \"\/mynamespace\/foo\" results in namespace = mynamespace, package = default, action\/trigger = \"foo\"\n* qName = \"\/mynamespace\/mypackage\/foo\" results in namespace = mynamespace, package = mypackage, action\/trigger = \"foo\"\n\n\n\nAll other combinations issue a WhiskError.QualifiedName error.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02674-7-1766","score":13.9973768278,"text":"\nApp Configuration server SDK for Go \n\nApp Configuration service provides SDK to integrate with your Golang web and mobile applications, microservices, and distributed environments.\n\n\n\n Prerequisites \n\nFollowing is the prerequisite for using App Configuration service SDK for Go:\n\n\n\n* Go version 1.16 or later\n\n\n\n\n\n\n\n Integrating server SDK for Go \n\nThe v1.x.x versions of the App Configuration Go SDK have been retracted.\n\nApp Configuration service provides SDK to integrate with your Golang web and mobile applications, microservices, and distributed environments. You can evaluate the values of your property and feature flag by integrating the App Configuration SDK.\n\n\n\n1. Install the SDK by using the following code from the git repository.\n\ngo get -u github.com\/IBM\/appconfiguration-go-sdk@latest\n2. In your Golang microservice or application, include the SDK module with:\n\nimport (\nAppConfiguration \"github.com\/IBM\/appconfiguration-go-sdk\/lib\"\n)\n\nRun go mod tidy to download and install the new dependency and update your Go application's go.mod file.\n3. Initialize the SDK to connect with your App Configuration service instance.\n\ncollectionId := \"airlines-webapp\"\nenvironmentId := \"dev\"\n\nappConfiguration = AppConfiguration.GetInstance()\nappConfiguration.Init(\"region\", \"guid\", \"apikey\")\nappConfiguration.SetContext(\"collectionId\", \"environmentId\")\n\nWhere,\n\n\n\n* region: Region name where the service instance is created. Use AppConfiguration.REGION_US_SOUTH for Dallas, AppConfiguration.REGION_US_EAST for Washington DC, AppConfiguration.REGION_EU_GB for London, and AppConfiguration.REGION_AU_SYD for Sydney.\n* guid: Instance ID of the App Configuration service. Get it from the service credentials section of the App Configuration service dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-golang"},{"document_id":"ibmcld_10805-1522-3235","score":13.6665240668,"text":"\nTo control inbound traffic, you might want to grant access to other users such as assigning Reader role to invoke actions. \n API key An API Key for the service ID that can be used to generate IAM tokens. You can use the tokens to authenticate the namespace with other IBM Cloud services. The API key is provided to actions as the environment variable __OW_IAM_NAMESPACE_API_KEY. \n\n\n\nYou can view a list of your service IDs by running the following command.\n\nibmcloud iam service-ids\n\nYou can view the API keys that are associated with a service ID by running the following command.\n\nibmcloud iam service-api-keys <ServiceID-12345678-1234-abcd-1234-123456789abc>\n\nDo not delete service IDs or API keys.\n\n\n\n\n\n Are there any limitations for namespaces? \n\nThe [mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk) is not supported for IAM-managed namespaces.\n\nThe names of all entities, including actions, triggers, rules, packages, and namespaces, are a sequence of characters that follow the following format:\n\n\n\n* The first character must be an alphanumeric character, or an underscore.\n* The subsequent characters can be alphanumeric, spaces, or any of the following values: _, @, ., -.\n* The last character can't be a space.\n\n\n\n\n\n\n\n What do I do if I have a Cloud Foundry-based namespace? \n\nYour Cloud Foundry-based namespaces still work. However, to take advantage of new features, you must create an IAM-enabled namespace.\n\n\n\n\n\n How do I see a list of my Cloud Functions namespaces? \n\nYou can see a list of your Cloud Functions namespaces by running the [namespace list](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=cloud-functions-cli-plugin-functions-clicli_namespace_list) command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-namespaces"},{"document_id":"ibmcld_10852-44214-45420","score":13.5942806226,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":23.4439194498,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_13724-72779-74671","score":23.2370111195,"text":"\nThe customization interface includes a collection of new HTTP methods that have the names POST \/v1\/customizations, POST \/v1\/customizations\/{customization_id}, POST \/v1\/customizations\/{customization_id}\/words, and PUT \/v1\/customizations\/{customization_id}\/words\/{word}. The service also provides a new GET \/v1\/pronunciation method that returns the pronunciation for any word and a new GET \/v1\/voices\/{voice} method that returns detailed information about a specific voice. In addition, existing methods of the service's interface now accept custom model parameters as needed.\n\nFor more information about customization and its interface, see [Understanding customization](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-customIntro) and the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\nThe customization interface is a beta release that currently supports US English only. All customization methods and the GET \/v1\/pronunciation method can currently be used to create and manipulate custom models and word translations only in US English.\n\nNew Brazilian Portuguese voice: pt-BR_IsabelaVoice\n: The service supports a new voice, pt-BR_IsabelaVoice, to synthesize audio in Brazilian Portuguese with a female voice. For more information, see [Languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices).\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile Software Development Kits (SDKs) are available for the speech services. The SDKs enable mobile applications to interact with both the Text to Speech and Speech to Text services. You can use the SDKs to send text to the Text to Speech service and receive an audio response.\n\n\n\n* The Watson Swift SDK is available from the [swift-sdk repository](https:\/\/github.com\/watson-developer-cloud\/swift-sdk) in the watson-developer-cloud namespace on GitHub.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-release-notes"},{"document_id":"ibmcld_01660-16615-18504","score":23.1844019249,"text":"\nThe account selector displays the account name and account number, and you select the current account to display a list of other accounts that you can access.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/account\/images\/account-faq.svg)\n\nFigure 2. Account selector displays all accounts to which you have access\n\n\n\n\n\n Can I move data between IBM Cloud accounts? \n\nData can't be directly migrated from one IBM Cloud account to another. But, you might be able to re-create configurations and add them to another account. Consider the following approaches:\n\n\n\n* Save your applications and replicate them in different accounts by using GitHub or another code repository.\n* Review the applicable documentation to determine whether your infrastructure services can be backed up and re-created in different accounts.\n* Use manifests and other documented methods to rebuild your applications and services by using documented methods to back up and restore your data.\n\n\n\nUsers with a Basic, Advanced, or Premium support plan can open a [Support case](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) for assistance with data migration questions.\n\n\n\n\n\n Can I bookmark a console page for a specific account? \n\nYou can target URLs for any IBM Cloud console page to a specific account. If you have multiple accounts, you can bookmark the account-specific URLs to easily access resources in different accounts without having to manually switch between them.\n\n\n\n1. Switch to the account that you want to target, and go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console. In the Account section, find the account ID, such as a1b2c3d4e5f61234567890fedcba4321.\n2. Go to the console page that you want to bookmark, and add ?bss_account=<account-id> to the URL, replacing <account-id> with the ID from your account. For example,:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_13429-166159-168045","score":22.8352192909,"text":"\nNew UK English and Arabic models\n: The service supports more languages with its transcription models: en-UK_BroadbandModel and en-UK_NarrowbandModel for UK English, and ar-AR_BroadbandModel for Modern Standard Arabic. For more information, see [Previous-generation languages and models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models).\n\nNew session_closed field for session-based methods\n: In the JSON responses that it returns for errors with session-based methods, the service now also includes a new session_closed field. The field is set to true if the session is closed as a result of the error. For more information about possible return codes for any method, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nHTTP platform timeout no longer applies\n: HTTP recognition requests are no longer subject to a 10-minute platform timeout. The service now keeps the connection alive by sending a space character in the response JSON object every 20 seconds as long as recognition is ongoing. For more information, see [Timeouts](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-inputtimeouts).\n\nRate limiting with curl command no longer needed\n: When you use the curl command to transcribe audio with the service, you no longer need to use the --limit-rate option to transfer data at a rate no faster than 40,000 bytes per second.\n\nChanges to HTTP error codes\n: The service no longer returns HTTP status code 490 for the session-based HTTP methods GET \/v1\/sessions\/{session_id}\/observe_result and POST \/v1\/sessions\/{session_id}\/recognize. The service now responds with HTTP status code 400 instead.\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile SDKs are available for the speech services. The SDKs enable mobile applications to interact with both the Speech to Text and Text to Speech services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_07642-0-563","score":22.3791160634,"text":"\n\n\n\n\n\n\n  AC-19 (5) - Full Device \/ Container-based Encryption \n\n\n\n  Control requirements \n\nAC-19 (5) - 0\n:   The organization employs [IBM Assignment: file level, full disk\/device, or both] to protect the confidentiality and integrity of information on [Assignment: organization-defined mobile devices].\n\n\n\n\n\n  NIST supplemental guidance \n\nContainer-based encryption provides a more fine-grained approach to the encryption of data\/information on mobile devices, including for example, encrypting selected data structures such as files, records, or fields.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ac-19.5"},{"document_id":"ibmcld_16727-1086316-1088349","score":22.2891978991,"text":"\nThe account selector displays the account name and account number.\n* How can I join accounts?\n\nThe account owner, organization manager, or a user with the correct permissions can invite you to join their account.\n\n\n\n* If you're new to IBM Cloud\u00ae, you receive an email that contains all the information you need.\n* As an existing member of IBM Cloud\u00ae, you can accept the invitation in your notifications, by email, or by using the CLI to onboard to the new account. To accept invitations in the CLI, use the [ibmcloud login](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_cliaccept-invitation-to-join-a-new-account-) command.\n\n\n\n* Can I switch between multiple accounts?\n\nIf you have access to more than one account, you can click your account name in the console menu bar to switch to another account.\n\n![A screen capture of the account selector in the console menu bar. The account selector displays the account name and account number, and you select the current account to display a list of other accounts that you can access.](https:\/\/cloud.ibm.com\/images\/account-faq.svg)\n\nFigure 2. Account selector displays all accounts to which you have access\n* Can I move data between IBM Cloud accounts?\n\nData can't be directly migrated from one IBM Cloud account to another. But, you might be able to re-create configurations and add them to another account. Consider the following approaches:\n\n\n\n* Save your applications and replicate them in different accounts by using GitHub or another code repository.\n* Review the applicable documentation to determine whether your infrastructure services can be backed up and re-created in different accounts.\n* Use manifests and other documented methods to rebuild your applications and services by using documented methods to back up and restore your data.\n\n\n\nUsers with a Basic, Advanced, or Premium support plan can open a [Support case](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) for assistance with data migration questions.\n* Can I bookmark a console page for a specific account?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1083825-1085863","score":22.2463062736,"text":"\nThe account selector displays the account name and account number.\n* How can I join accounts?\n\nThe account owner, organization manager, or a user with the correct permissions can invite you to join their account.\n\n\n\n* If you're new to IBM Cloud\u00ae, you receive an email that contains all the information you need.\n* As an existing member of IBM Cloud\u00ae, you can accept the invitation in your notifications, by email, or by using the CLI to onboard to the new account. To accept invitations in the CLI, use the [ibmcloud login](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_cliaccept-invitation-to-join-a-new-account-) command.\n\n\n\n* Can I switch between multiple accounts?\n\nIf you have access to more than one account, you can click your account name in the console menu bar to switch to another account.\n\n![A screen capture of the account selector in the console menu bar. The account selector displays the account name and account number, and you select the current account to display a list of other accounts that you can access.](https:\/\/cloud.ibm.com\/docs\/images\/account-faq.svg)\n\nFigure 2. Account selector displays all accounts to which you have access\n* Can I move data between IBM Cloud accounts?\n\nData can't be directly migrated from one IBM Cloud account to another. But, you might be able to re-create configurations and add them to another account. Consider the following approaches:\n\n\n\n* Save your applications and replicate them in different accounts by using GitHub or another code repository.\n* Review the applicable documentation to determine whether your infrastructure services can be backed up and re-created in different accounts.\n* Use manifests and other documented methods to rebuild your applications and services by using documented methods to back up and restore your data.\n\n\n\nUsers with a Basic, Advanced, or Premium support plan can open a [Support case](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) for assistance with data migration questions.\n* Can I bookmark a console page for a specific account?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_14390-16273-17983","score":21.5595944301,"text":"\n* At the end of the documented process, your vCenter Server instance is running vSphere 7.0 Update 1c with N-VDS distributed switches. This configuration is different than the currently supported [Software BOM for vCenter Server instances](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_bomvc_bom-software), which is vSphere 7.0 Update 3c with Distributed vSwitch 7.0.0.\n* For more information about the migration of N-VDS to VDS switches for vSphere 7.0 or later and NSX-T Data Center 3.0 and later, see [Migrate host switch to vSphere Distributed Switch](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.1\/administration\/GUID-1039A36F-F55E-4A0A-B6C6-2C383F4A716D.html). Currently, this procedure is not verified on a VMware Solutions vCenter Server instance.\n* IBM Cloud is undertaking an assessment of the N-VDS to VDS conversion and the required changes to the automation database to allow this in-place upgrade.\n* Currently, Day 2 automation workflows such as add host or add cluster, are not tested against VMware Solutions vCenter Server instances that are upgraded from vSphere 6.7 to 7 and still using N-VDS distributed switches. Customers must assume that this automation might fail and that if this automation is required then the lift and shift migration approach used. If this automation is not needed, you can use the upgrade process that is documented.\n* A workaround for the add nodes and add cluster features is to use the VMware vSphere offering. For more information, see [VMware vSphere overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_vsphereclusteroverview). You must complete a number of manual tasks after the automated deployment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-faq-v2t-migration"},{"document_id":"ibmcld_10852-44214-45420","score":21.1299445875,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_00959-2830-5215","score":20.8023803099,"text":"\n* Avoid application downtime.\n* Enable production testing of new functions without impacting customers.\n* Limit the impact of production issues to a subset of users.\n* Enable rapid rollback to the previous version if issues are found.\n\n\n\nMany possible deployment strategies are available. In general, they depend on running multiple instances of the application and managing how the various instances are updated. You can pre-configure the following common deployment strategies in Continuous Delivery:\n\nBasic\n: Deploys the new release by stopping and updating all of the running instances simultaneously, causing downtime. For rollback, you must deploy the previous version again, which causes extra downtime. Although this strategy is simple, fast, and has low runtime resource requirements, it is the riskiest and causes downtime. The Basic deployment strategy is not recommended for critical apps that must be highly available.\n\nRolling update\n: Similar to the Basic strategy, this deployment strategy is simple, fast, and has low runtime resource requirements. However, because each running instance is taken down and updated individually, avoiding downtime, rollback requires you to deploy the previous release again. This time consuming approach might cause issues if the current version of the app in production is broken.\n\nBlue-Green deployment\n: Creates two separate, permanent production environments (blue and green), and only one of those environments receives traffic at a time. The current release is always deployed to the idle environment and traffic is switched to it after deployment completes, with no downtime. Because you need to switch only the traffic to the unchanged environment, rollback does not cause downtime. Because this strategy requires two full production environments, the resource requirements are higher. However, this strategy enables powerful Developer flows, such as the ability to test new app versions in the production environment before it allows customer traffic. Blue-Green deployment also supports fast rollback.\n\nCanary release\n: Deploys a new release in parallel with the original production environment (similar to Blue-Green), with no downtime. The amount of traffic that is sent to both the updated and original instances is managed so that the new version is available to a controlled subset of users while the deployment proceeds.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-tutorial-cd-kubernetes"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":29.249698156,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-7-1743","score":28.340313138,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_02772-4213-5899","score":26.1687227882,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_04518-1426-3052","score":24.9379910273,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10852-43319-44485","score":23.4213591222,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-1342-3184","score":23.0282997411,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_12530-4747-5873","score":22.3843364365,"text":"\nThe evidence is reported to the IBM Cloud Security and Compliance Center, and included in an automated change rquest document.\n\nTwo types of issues are reported from your CI and CC pipelines: incident issues and nonincident issues. Incident issues can arise due to vulnerabilities or CVEs found inside the code or the deployed artifacts, and nonincident issues do not arise from vulnerabilities, but rather represent a deviation from the compliance posture, for example, unit test failures and branch protection check failures. For more information about managing issues, see [Processing incident and nonincident issues](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-issue-processing) and [Managing incident issues](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-incident-issues)\n\nCompliance evidence creates the trail that auditors look for during a compliance audit. One of the goals of DevSecOps is automated evidence generation and storage in auditable change requests and durable evidence lockers. For more information, see [Evidence](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-evidence).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-compliant-software-development"},{"document_id":"ibmcld_06872-7-2017","score":20.5965548722,"text":"\nProcessing incident and nonincident issues \n\nThe following types of issues are supported:\n\n\n\n* Incident issues, which can arise due to vulnerabilities or CVEs found inside the code or the deployed artifacts.\n* Nonincident issues, which do not arise from vulnerabilities, but rather represent a deviation from the compliance posture. For example, unit test failures and branch protection check failures.\n\n\n\n\n\n Adding default assignees to issues \n\nYou can define multiple default assignees for the issue by using the incident-assignees pipeline parameter. The incident-assignees parameter can be used only with GitHub accounts and GitLab Premium accounts. For more information about the incident-assignees parameter, see [Assigning issues to users](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-issue-processingassign-issues).\n\nYou can also set a default issue assignee for the pipeline with the incident-assignee pipeline parameter, however this parameter is deprecated and will be removed with the v1 evidence (legacy) collection.\n\n\n\n\n\n Filtering issues \n\nYou can filter and search for issues by using default and custom labels. The following default labels are assigned to the issues upon creation or update:\n\n\n\n* The [scan type](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-incident-issuesdue-date-supported-tools) that is used for the issue processing is added to the incident issue as a tool label (for example, tool:cra, tool:va, tool:sonarqube).\n* A severity label is also assigned to issues. The severity categories are defined based on the scan results and can be one of the following: severity:critical, severity:high, severity:medium, severity:low, severity:informational.\n* The has-exempt is a VA tool-specific label that is assigned to the issue if it is exempted based on the scan result. If the exempt status is not included in the scan result, you can exempt the issue manually by assigning the exempt label and adding a link to the source of the exempt issue ticket in a comment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-issue-processing"},{"document_id":"ibmcld_07456-22006-24308","score":20.5958397738,"text":"\nYou agree that this Agreement, including the policies it refers to (i.e. our Dispute Resolution Policy, etc.) constitute the complete and only agreement between You and IBM Cloud regarding the services contemplated herein.\n\n\n\n\n\n Venue; Waiver of Trial by Jury \n\nThis Agreement shall be deemed entered into in the state of Texas. Except for disputes concerning the user of a domain name registered with IBM Cloud, the laws and judicial decisions of Dallas County, Texas, shall be used to determine the validity, construction, interpretation and legal effect of this Agreement. You agree that any action relating to or arising out of this Agreement shall be brought in the courts of Dallas County, Texas. You agree to waive the right to trial by jury in any proceeding that takes place relating to or arising out of this Agreement.\n\n\n\n\n\n Notices \n\nYou agree that, with the exception of notices concerning breach of this Agreement, all notices from IBM Cloud to You may be posted on our web site, or sent to the email address You have on file with IBM Cloud, and will be deemed delivered within three days after posting\/sending. Notices concerning breach will be sent either to the email address You have on file with IBM Cloud or mailed first class postage to the postal address You have on file with IBM Cloud. In both cases, delivery shall be deemed to have been made five days after the date sent. Notices from You to IBM Cloud shall be made by email, sent to the address we provide on our web site.\n\n\n\n\n\n Provisions Specific to All Registrations \n\nYou agree to be bound by the rules, policies, and agreements of each Registry from which You purchase a domain registration, which may include, but are not limited to, Top Level Domain Registries and Second Level Domain Registries.\n\n\n\n\n\n Provisions Specific to .COM, and .NET Registrations Indemnification \n\nYou agree to indemnify, defend and hold harmless the .COM, .NET and .NAME Registry Operator, VeriSign, Inc., and its directors, officers, employees, agents, and affiliates from and against any and all claims, damages, liabilities, costs and expenses, including reasonable legal fees and expenses arising out of or relating to the Registered Name holder's domain name registration.\n\n\n\n\n\n Provisions Specific to .ORG Registrations Indemnification","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns?topic=dns-domain-registration-agreement"},{"document_id":"ibmcld_12530-3495-5274","score":20.2952550144,"text":"\nThe [CI](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-ci-pipeline)\/[CD](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cd-pipeline) pipelines ensure that the application code that your team develops is secure and free of vulnerabilities before code is pushed to production. Once your code reaches production, you can use the CC pipeline to continuously scan your production code for new vulnerabilities. The [CC pipeline](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-cc-pipeline) can be triggered manually or periodically by using triggers.\n\nThe CC pipeline scans existing deployed artifacts and their source repositories independent of your deployment schedule. It runs the static scans and dynamic scans on the Application Source Code, detect secrets in Git repos, Bill Of Materials (BOM) check, CIS check, and Vulnerability Advisor scan.\n\n\n\n\n\n Managing issues and collecting evidence to be audit-ready \n\nAfter scanning and running checks on artifacts and source repositories, the pipeline creates a new incident issue or updates the existing incident issues in the incident repository. Finally, using these issues and the results, the pipeline collects evidence and summarizes the evidence. The evidence is reported to the IBM Cloud Security and Compliance Center, and included in an automated change rquest document.\n\nTwo types of issues are reported from your CI and CC pipelines: incident issues and nonincident issues. Incident issues can arise due to vulnerabilities or CVEs found inside the code or the deployed artifacts, and nonincident issues do not arise from vulnerabilities, but rather represent a deviation from the compliance posture, for example, unit test failures and branch protection check failures.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-compliant-software-development"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.932521092}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09663-15216-17504","score":17.9725003541,"text":"\n* Apply the patch to the secondary replica in the primary MZR i.e. the SQL server in AZ2, if applicable:\n\n\n\n* Using SSMS, change the failover mode from Automatic to Manual to ensures that no automatic failover happens while the patches are installed.\n* Using SSMS, suspend data movement for the secondary replica databases so that the primary replica does not send any transaction block to the specific secondary replica.\n* Via RDP to the server hosting the secondary replica, apply the CU.\n* Restart the server.\n* Once the secondary replica comes online, connect to it using SSMS and perform the following validation:\n\n\n\n* Verify SQL Services are online.\n* SQL Server version validation.\n* Review SQL Server error logs for any errors, warnings.\n* It is also recommended to perform a database consistency checker (DBCC CHECKDB) after applying the patches.\n* Using SSMS, resume data movement to the secondary replica database and wait for the availability group dashboard to show healthy.\n\n\n\n\n\n* Apply the patch to the secondary replica in the recovery MZR, if applicable:\n\n\n\n* Using SSMS, suspend data movement for the secondary replica databases so that the primary replica does not send any transaction block to the specific secondary replica.\n* Via RDP to the server hosting the secondary replica, apply the CU.\n* Restart the server.\n* Once the secondary replica comes online, connect to it using SSMS and perform the following validation:\n* Verify SQL Services are online.\n* SQL Server version validation.\n* Review SQL Server error logs for any errors, warnings.\n* It is also recommended to perform a database consistency checker (DBCC CHECKDB) after applying the patches.\n* Using SSMS, resume data movement to the secondary replica database and wait for the availability group dashboard to show healthy.\n\n\n\n* Apply the patch to the primary replica:\n\n\n\n* Using SSMS, perform a manual failover from the primary replica to the secondary replica in the primary MZR. After the failover, the primary replica changes its state to a secondary replica.\n* Using SSMS, suspend data movement for the secondary replica databases so that the primary replica does not send any transaction block to the specific secondary replica.\n* Via RDP to the server hosting the secondary replica, apply the CU.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/microsoft?topic=microsoft-mssql-ops"},{"document_id":"ibmcld_16149-10569-12386","score":17.9631667554,"text":"\nFor more information on this issue, see [(SRX) IPSec comes UP when SRX-A is the Initiator, but fails when SRX-A becomes the responder](https:\/\/kb.juniper.net\/InfoCenter\/index?page=content&id=KB22239) in the Juniper Knowledge Base. Consult [vpn (Security)](https:\/\/www.juniper.net\/documentation\/en_US\/junos\/topics\/reference\/configuration-statement\/security-edit-vpn.html) for more details on these settings.\n\n\n\n\n\n Correcting warning 1177 \n\nOne or more security zone policy rules with the dynamic-application any configuration was detected. If the vSRX is not installed with the Content Security Bundle (CSB) license and application signature database, then this configuration might cause traffic disruption due to changes in newer vSRX releases, such as 19.4R2-S3.\n\nFor example, the following security policy configuration contains the dynamic-application any label:\n\nset security policies from-zone untrust to-zone untrust policy DYNAMIC-APPLICATION-POLICY-LOCAL match dynamic-application any\nset security policies from-zone untrust to-zone untrust policy DYNAMIC-APPLICATION-POLICY-LOCAL match source-address SL8\nset security policies from-zone untrust to-zone untrust policy DYNAMIC-APPLICATION-POLICY-LOCAL match destination-address SL8\nset security policies from-zone untrust to-zone untrust policy DYNAMIC-APPLICATION-POLICY-LOCAL then permit\n\nIf you are using a similar configuration, it is recommended that you either install the CSB license and the application signature database or remove the dynamic-application any rule.\n\n\n\n\n\n Correcting warning 1179 \n\nThe vSRX version running on the Gateway is not certified on IBM Cloud and is unsupported. Operations such as OS Reload and Rebuild Cluster will overwrite the current unsupported vSRX version with the version currently listed on the Gateway Details page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vsrx?topic=vsrx-correcting-readiness-errors"},{"document_id":"ibmcld_05503-18324-19557","score":16.4952221635,"text":"\nINFO[0008] RUN npm install\nINFO[0008] Taking snapshot of full filesystem...\nINFO[0010] cmd: \/bin\/sh\nINFO[0010] args: [-c npm install]\nINFO[0010] Running: [\/bin\/sh -c npm install]\nnpm WARN saveError ENOENT: no such file or directory, open '\/package.json'\nnpm notice created a lockfile as package-lock.json. You should commit this file.\nnpm WARN enoent ENOENT: no such file or directory, open '\/package.json'\nnpm WARN !invalid2 No description\nnpm WARN !invalid2 No repository field.\nnpm WARN !invalid2 No README data\nnpm WARN !invalid2 No license field.\n\nup to date in 0.267s\nfound 0 vulnerabilities\n\nINFO[0011] Taking snapshot of full filesystem...\nINFO[0011] COPY server.js .\nINFO[0011] Taking snapshot of files...\nINFO[0011] EXPOSE 8080\nINFO[0011] cmd: EXPOSE\nINFO[0011] Adding exposed port: 8080\/tcp\nINFO[0011] CMD [ \"node\", \"server.js\" ]\n\nmybuildrun-zg5rj-pod-z5gzb\/step-image-digest-exporter-ngl6j:\n2021\/02\/26 18:21:02 warning: unsuccessful cred copy: \".docker\" from \"\/tekton\/creds\" to \"\/tekton\/home\": unable to open destination: open \/tekton\/home\/.docker\/config.json: permission denied\n{\"severity\":\"INFO\",\"timestamp\":\"2021-02-26T18:21:26.372494581Z\",\"caller\":\"logging\/config.go:116\",\"message\":\"Successfully created the logger.\"}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-view-logs"},{"document_id":"ibmcld_05278-78655-79972","score":16.4640791091,"text":"\n{\"level\":\"info\",\"ts\":1614089509.0128207,\"caller\":\"git\/git.go:203\",\"msg\":\"Successfully initialized and updated submodules in path \/workspace\/source\"}\n\nmybuildrun-v2mb8-pod-tlzdx\/step-build-and-push:\nINFO[0000] Retrieving image manifest node:12-alpine\nINFO[0000] Retrieving image node:12-alpine\nINFO[0001] Retrieving image manifest node:12-alpine\nINFO[0001] Retrieving image node:12-alpine\nINFO[0001] Built cross stage deps: map[]\nINFO[0001] Retrieving image manifest node:12-alpine\nINFO[0001] Retrieving image node:12-alpine\nINFO[0002] Retrieving image manifest node:12-alpine\nINFO[0002] Retrieving image node:12-alpine\nINFO[0002] Executing 0 build triggers\nINFO[0002] Unpacking rootfs as cmd RUN npm install requires it.\nINFO[0006] RUN npm install\nINFO[0006] Taking snapshot of full filesystem...\nINFO[0008] cmd: \/bin\/sh\nINFO[0008] args: [-c npm install]\nINFO[0008] Running: [\/bin\/sh -c npm install]\nnpm WARN saveError ENOENT: no such file or directory, open '\/package.json'\nnpm notice created a lockfile as package-lock.json. You should commit this file.\nnpm WARN enoent ENOENT: no such file or directory, open '\/package.json'\nnpm WARN !invalid2 No description\nnpm WARN !invalid2 No repository field.\nnpm WARN !invalid2 No README data\nnpm WARN !invalid2 No license field.\n\nup to date in 0.27s\nfound 0 vulnerabilities","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-cli"},{"document_id":"ibmcld_04335-77203-78520","score":16.4640791091,"text":"\n{\"level\":\"info\",\"ts\":1614089509.0128207,\"caller\":\"git\/git.go:203\",\"msg\":\"Successfully initialized and updated submodules in path \/workspace\/source\"}\n\nmybuildrun-v2mb8-pod-tlzdx\/step-build-and-push:\nINFO[0000] Retrieving image manifest node:12-alpine\nINFO[0000] Retrieving image node:12-alpine\nINFO[0001] Retrieving image manifest node:12-alpine\nINFO[0001] Retrieving image node:12-alpine\nINFO[0001] Built cross stage deps: map[]\nINFO[0001] Retrieving image manifest node:12-alpine\nINFO[0001] Retrieving image node:12-alpine\nINFO[0002] Retrieving image manifest node:12-alpine\nINFO[0002] Retrieving image node:12-alpine\nINFO[0002] Executing 0 build triggers\nINFO[0002] Unpacking rootfs as cmd RUN npm install requires it.\nINFO[0006] RUN npm install\nINFO[0006] Taking snapshot of full filesystem...\nINFO[0008] cmd: \/bin\/sh\nINFO[0008] args: [-c npm install]\nINFO[0008] Running: [\/bin\/sh -c npm install]\nnpm WARN saveError ENOENT: no such file or directory, open '\/package.json'\nnpm notice created a lockfile as package-lock.json. You should commit this file.\nnpm WARN enoent ENOENT: no such file or directory, open '\/package.json'\nnpm WARN !invalid2 No description\nnpm WARN !invalid2 No repository field.\nnpm WARN !invalid2 No README data\nnpm WARN !invalid2 No license field.\n\nup to date in 0.27s\nfound 0 vulnerabilities","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cli"},{"document_id":"ibmcld_13900-52291-53957","score":15.4738307776,"text":"\nVRVDR-51828 Major SIAD ACL: BCM SDK error when deleting ACL configuration \n VRVDR-51639 Critical Response for \"request hardware-diag version\" takes much longer with 1912b \n VRVDR-51619 Critical SIAD ACL: Ensure that rulesets which would exceed the TCAM are rejected \n VRVDR-51616 Critical Storm Control triggered snmpd warning messages in journal \n VRVDR-51543 Critical IPsec peers stuck in 'init' state after upgrade from 1801q to 1912d \n VRVDR-51539 Critical Repeated FAL BCM \"L3 Interface\" for VSI 0 Syslog \n VRVDR-51521 Critical NAT64 opd yang file missing required type field in 1908 and 1912 \n VRVDR-51518 Critical Dataplane performance fails for forward pkts when scatter mode driver is used \n VRVDR-51483 Major Removing guest configuration fails with scripting error \n VRVDR-51385 Critical Dataplane Crash in next_hop_list_find_path_using_ifp \n VRVDR-51348 Major libsnmp-dev built from DANOS\/net-snmp is not API compatible with libsnmp-dev from upstream \n VRVDR-51345 Critical S9500-30XS: 100G Interface LED lit even when disabled \n VRVDR-51311 Blocker DAS Switch with 1912b seeing low rate of drops vs 1903m \n VRVDR-51295 Critical Changing speed on interface resets configured MTU to default \n VRVDR-51247 Major S9500 - missing hw_rev.cfg file \n VRVDR-51238 Major After broadcast storm, TACACS doesn't recover \n VRVDR-51185 Blocker Link doesn't come up after swapping 1000BASE-T SFP for 1000BASE-X SFP \n VRVDR-51183 Major 'FAL neighbor del' log is generated by dataplane for each ARP received for an unknown address \n VRVDR-51179 Critical live-cd installs should not install all unique state \n VRVDR-51148 Critical S9500 interface flaps when MTU is modified","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-ciena-vyatta-5600-vrouter-software-patches"},{"document_id":"ibmcld_15190-4070-5596","score":15.3354236543,"text":"\nThen, you can select Drive 0 and continue with the installation. When the installation is complete, shut down the virtual machine and remove the optical drives that you added: Windows installation ISO and virtio-win driver ISO. You can ignore any warnings about removing an optical drive.\n3. Use the default Windows updater to download and install Windows updates. Repeat the process of downloading and installing updates until no updates are available.\n4. Install [cloudbase-init](https:\/\/cloudbase.it\/cloudbase-init\/). For more information, see [cloudbase-init\u2019s documentation](https:\/\/cloudbase-init.readthedocs.io\/en\/latest\/index.html).\n5. Modify the cloudbase-init configuration file, C:Program FilesCloudbase SolutionsCloudbase-Initconfcloudbase-init.conf to match the values that are shown in the following example.\n\n[DEFAULT]\n \"cloudbase-init.conf\" is used for every boot\nconfig_drive_types=vfat,iso\nconfig_drive_locations=hdd,partition\nactivate_windows=true\nkms_host=kms.adn.networklayer.com:1688\nmtu_use_dhcp_config=false\nreal_time_clock_utc=false\nbsdtar_path=C:Program FilesCloudbase SolutionsCloudbase-Initbinbsdtar.exe\nmtools_path=C:Program FilesCloudbase SolutionsCloudbase-Initbin\ndebug=true\nlog_dir=C:Program FilesCloudbase SolutionsCloudbase-Initlog\nlog_file=cloudbase-init.log\ndefault_log_levels=comtypes=INFO,suds=INFO,iso8601=WARN,requests=WARN\nlocal_scripts_path=C:Program FilesCloudbase SolutionsCloudbase-InitLocalScripts\nmetadata_services=cloudbaseinit.metadata.services.configdrive.ConfigDriveService,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-windows-custom-image"},{"document_id":"ibmcld_00495-7-1795","score":14.9419520856,"text":"\nCreating and populating a database \n\nThis tutorial shows you how to use the [Python programming language](https:\/\/www.python.org\/) to create an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae database in your IBM Cloud service instance. You also learn how to populate the database with a simple collection of data.\n\nThis tutorial doesn't use the most efficient Python code. The intent is to show simple and easy-to-understand working code that you can learn from and apply to your own applications. You must apply normal best practices for checking and handling all warning or error conditions that are encountered by your own applications.\n\n\n\n Objectives \n\nThis tutorial builds on a series of Python language instructions, suitable for the following tasks:\n\n\n\n1. Connecting to an IBM Cloudant service instance on IBM Cloud\u00ae.\n2. Creating a database within the service instance.\n3. Storing a small collection of data as documents within the database.\n4. Retrieving data.\n5. Deleting the database.\n6. Closing the connection to the service instance.\n\n\n\n\n\n\n\n Before you begin \n\nThis tutorial provides you with the following options:\n\n\n\n* Follow each step as outlined in this tutorial.\n* Or [execute the Python script](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-and-populating-a-simple-ibm-cloudant-database-on-ibm-cloudexecute-the-complete-python-script), and come back to [Step 5. Retrieving data](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-and-populating-a-simple-ibm-cloudant-database-on-ibm-cloudretrieving-data).\n\n\n\n\n\n\n\n Installing Python \n\nNormally, you don't run commands individually in Python. You usually create a script, which is a list of the commands you want to run, stored in a Python file, with a py extension.\n\n\n\n1. Set up service credential requirements.\n\na.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-and-populating-a-simple-ibm-cloudant-database-on-ibm-cloud"},{"document_id":"ibmcld_12896-7-1813","score":14.8694028274,"text":"\nCreating and populating a database \n\nThis tutorial shows you how to use the [Python programming language](https:\/\/www.python.org\/) to create an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae database in your IBM Cloud service instance. You also learn how to populate the database with a simple collection of data.\n\nThis tutorial doesn't use the most efficient Python code. The intent is to show simple and easy-to-understand working code that you can learn from and apply to your own applications. You must apply normal best practices for checking and handling all warning or error conditions that are encountered by your own applications.\n\n\n\n Objectives \n\nThis tutorial builds on a series of Python language instructions, suitable for the following tasks:\n\n\n\n1. Connecting to an IBM Cloudant service instance on IBM Cloud\u00ae.\n2. Creating a database within the service instance.\n3. Storing a small collection of data as documents within the database.\n4. Retrieving data.\n5. Deleting the database.\n6. Closing the connection to the service instance.\n\n\n\n\n\n\n\n Before you begin \n\nThis tutorial provides you with the following options:\n\n\n\n* Follow each step as outlined in this tutorial.\n* Or [execute the Python script](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-creating-and-populating-a-simple-ibm-cloudant-database-on-ibm-cloudexecute-the-complete-python-script), and come back to [Step 5. Retrieving data](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-creating-and-populating-a-simple-ibm-cloudant-database-on-ibm-cloudretrieving-data).\n\n\n\n\n\n\n\n Installing Python \n\nNormally, you don't run commands individually in Python. You usually create a script, which is a list of the commands you want to run, stored in a Python file, with a py extension.\n\n\n\n1. Set up service credential requirements.\n\na.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-creating-and-populating-a-simple-ibm-cloudant-database-on-ibm-cloud"},{"document_id":"ibmcld_05865-1444-3235","score":14.7457670239,"text":"\nIn your [cluster dashboard](https:\/\/cloud.ibm.com\/kubernetes\/clusters), click the name of the cluster where you want to install the debug tool add-on.\n2. On the Diagnostics and Debug Tool card, click Install.\n3. In the dialog box, click Install. Note that it can take a few minutes for the add-on to be installed. To resolve some common issues that you might encounter during the add-on deployment, see [Reviewing add-on state and statuses](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_addons).\n4. On the Diagnostics and Debug Tool card, click Dashboard.\n5. In the debug tool dashboard, select the ingress group of tests. Some tests check for potential warnings, errors, or issues, and some tests only gather information that you can reference while you troubleshoot. For more information about the function of each test, click the information icon next to the test's name.\n6. Click Run.\n7. Check the results of each test.\n\n\n\n* If any test fails, click the information icon next to the test's name for information about how to resolve the issue.\n* You can also use the results of tests that only gather information while you debug your Ingress service in the following sections.\n\n\n\n\n\n\n\n\n\n Step 3: Check for error messages in your Ingress deployment and the ALB pod logs \n\nStart by checking for error messages in the Ingress resource deployment events and ALB pod logs. These error messages can help you find the root causes for failures and further debug your Ingress setup in the next sections.\n\n\n\n1. Check your Ingress resource deployment and look for warnings or error messages.\n\nkubectl describe ingress <myingress>\n\nIn the Events section of the output, you might see warning messages about invalid values in your Ingress resource or in certain annotations that you used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ingress-debug"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04518-7-1743","score":23.6762246101,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10817-7-1802","score":23.0930085608,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02772-4213-5899","score":20.7625956294,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_04518-1426-3052","score":20.5722108616,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10852-43319-44485","score":18.363127623,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_12332-1034-2510","score":18.0466048468,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_10817-1342-3184","score":16.9844145226,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_07551-14062-16080","score":11.7397302708,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_11130-7621-10352","score":-0.1654500043,"text":"\nThey are single-tenant and data plane products. They are accessed locally in customer accounts, data plane hosted on virtual resources in the customer's account, control plane security owned by IBM, and data plane security owned by the customer. IBM Cloud products of this type include IBM Cloud Kubernetes Service on classic infrastructure and Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae on classic infrastructure.\n\n\n\nTable 3. Shared responsibilities for self-managed products\n\n Resource Incident and Operations Management Change Management Identity and Access Management Security and Regulation Compliance Disaster Recovery \n\n Data Customer Customer Customer Customer Customer \n Application Customer Customer Customer Customer Customer \n Service instance Shared Shared Shared Shared Shared \n Operating system Shared Shared Shared Shared Shared \n Virtual and bare metal servers Shared Shared Shared Shared Shared \n Virtual storage Shared Shared Shared Shared Shared \n Virtual network Shared Shared Shared Shared Shared \n Hypervisor IBM IBM IBM IBM IBM \n Physical servers and memory IBM IBM IBM IBM IBM \n Physical storage IBM IBM IBM IBM IBM \n Physical network and devices IBM IBM IBM IBM IBM \n Facilities and data centers IBM IBM IBM IBM IBM \n\n\n\nFor areas marked as shared responsibilities, the customer is responsible for all the configurations, and IBM is responsible for all underlying management. For disaster recovery, the customer is responsible for creating resources in a secondary region and managing the application and data disaster recovery.\n\n\n\n\n\n Software packages \n\nSoftware packages are deployed by IBM as single tenant instances, and they are accessed locally in the customer account. The software instance is hosted on resources in the customer's accounts. The software deployment control plane security is owned by IBM, and the software instance security is owned by the customer.\n\nA generic software deployment control plane manages the lifecycle of deployed software package instances. At a minimum, it manages the deployment, upgrade, and delete actions. As the packages become smarter, the generic control plane might also manage the start, stop, migration, scaling, monitoring, backup, and restore tasks.\n\nYou can find a list of software in the IBM Cloud catalog on the Software tab.\n\n\n\nTable 4. Shared responsiblities for software packages\n\n Resource Incident and Operations Management Change Management Identity and Access Management Security and Regulation Compliance Disaster Recovery \n\n Data Customer Customer Customer Customer Customer \n Application Customer Customer Customer Customer Customer \n Software packages Shared Shared Customer Customer Shared \n Operating system Shared Shared Customer Customer Shared","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-shared-responsibilities"},{"document_id":"ibmcld_14612-4716-6208","score":-0.1667229123,"text":"\nDual Intel Xeon Silver 4210 processor 20 2.2 128 GB, 192 GB, 384 GB, 768 GB, 1.5 TB \n Dual Intel Xeon Gold 5218 processor 32 2.3 128 GB, 192 GB, 384 GB, 768 GB, 1.5 TB \n Dual Intel Xeon Gold 6248 processor 40 2.5 128 GB, 192 GB, 384 GB, 768 GB, 1.5 TB \n Dual Intel Xeon Gold 6250 processor 16 3.9 128 GB, 192 GB, 384 GB, 768 GB, 1.5 TB \n Dual Intel Xeon Platinum 8260 processor 48 2.4 128 GB, 192 GB, 384 GB, 768 GB, 1.5 TB \n Quad Intel Xeon Gold 6248 processor 80 2.5 384 GB, 768 GB, 1.5 TB, 3 TB \n Quad Intel Xeon Platinum 8260 processor 96 2.4 384 GB, 768 GB, 1.5 TB, 3 TB \n\n\n\n\n\n\n\n SAP-certified Cascade Lake \n\nFor SAP-certified Cascade Lake servers, you can select from the following configurations:\n\n\n\nTable 3. Options for SAP-certified Cascade Lake - NetWeaver and HANA\n\n CPU model SAP certification Cores GHz RAM Storage type \n\n Dual Intel Xeon Gold 5218 processor (Cascade Lake, BI.S4.NW192) NetWeaver 32 2.3 192 GB Up to 12 Drivers \n Dual Intel Xeon Gold 5218 processor (Cascade Lake, BI.S4.NW384) NetWeaver 32 2.3 384 GB Up to 12 Drivers \n Dual Intel Xeon Gold 6248 processor (Cascade Lake, BI.S4.NW768) NetWeaver 40 2.5 768 GB Up to 12 Drivers \n Dual Intel Xeon Platinum 8260 processor (Cascade Lake, BI.S4.NW768_v2) Netweaver 48 2.4 768 GB Up to 12 Drivers \n Dual Intel Xeon Platinum 8280M processor (Cascade Lake, BI.S4.NW1500) Netweaver 56 2.7 1.5 TB Up to 12 Drivers \n Dual Intel Xeon Platinum 8280M processor (Cascade Lake, BI.S4.NW3000) Netweaver 56 2.7 3 TB Up to 12 Drivers","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_addingclusters"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.4981892575,"ndcg_cut_10":0.6546154995}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04518-1426-3052","score":32.9515555202,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10817-1342-3184","score":28.0385394235,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-7-1743","score":21.877350064,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_12332-1034-2510","score":21.7953500612,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_07551-15747-17355","score":21.359054281,"text":"\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https:\/\/github.com\/IBM\/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n\/Register iOS devices\/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_07551-14062-16080","score":19.9668987238,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_10852-43319-44485","score":18.1374237417,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10852-44214-45420","score":17.6724822856,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-7-1802","score":13.2303514952,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_06968-8289-10541","score":10.6954357738,"text":"\nThe following table shows examples of how some words are stemmed versus lemmatized.\n\n\n\nStemmer versus Lemmatizer comparison\n\n Surface form Lemmatized form Stemmed form \n\n running run run \n ran run ran \n instructor instructor instruct \n instruction instruction instruct \n\n\n\nAs you can see from the examples, the lemmatizer captures the word meanings better than the stemmer. Both running and ran are recognized as different forms of the same root verb run. And the difference in meaning between the two nouns instructor and instruction is preserved. However, if the data contains misspellings such as instructer and instructoin, the normalized form that is generated by stemming (instruct) will return better matches.\n\nDiscovery normalizes words when it ingests and stores data in the index and at run time when it analyzes queries that are submitted by users. The same normalization method is used for both operations, even though one operation occurs at the collection-level and the other occurs at the project-level. When a query is submitted, it is federated to each collection within the project, where the query is normalized based on that collection's configuration. Collections that are configured to use the stemmer normalize the query by using stemming. The collections that are not, normalize the query by using lemmatization.\n\nTo enable the stemmer instead of the lemmatizer when you create the collection, expand More processing options, and then set the Use stemming instead of lemmatization when indexing switcher to On.\n\nIf you configure Discovery to use the stemmer, consider also designing the queries that extract information from the collection to allow for character differences during matching. For more information, see the [String variation operator](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operatorsvariation).\n\nFor more information about the languages for which the stemmer is supported, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n\n\n\n\n\n Collection limits \n\nThe number of collections that you can create per project differs by project type.\n\n\n\nCollections per project limits\n\n Project type Collections per project \n\n Document Retrieval 5","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collections"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.9066276098}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-1342-3184","score":35.9159642012,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-7-1743","score":24.5450507199,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_04518-1426-3052","score":24.2528648822,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_07551-14062-16080","score":21.7604792056,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_07551-15747-17355","score":20.4263844412,"text":"\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https:\/\/github.com\/IBM\/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n\/Register iOS devices\/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_04442-5207-6911","score":20.3795854169,"text":"\nibmcloud plugin download PLUGIN_NAME [-r REPO_NAME] [-v VERSION] [-d, --dest DOWNLOAD_DIRECTORY] [-f]\n\nibmcloud plugin download [-a, --all] [-r REPO_NAME] [-f]\n\nibmcloud plugin download URL [-f] [-d DOWNLOAD_DIRECTORY]\n\nIf no repository is specified, the command uses the default plug-in repository IBM Cloud. If you are downloading a single plug-in, and no version is specified, the command selects the latest available version to download. If the '-a, --all' flag is specified, the command downloads all latest available plug-ins in the repository.\n\nCommand options:\n\n-a, --all (optional)\n: Downloads all latest available plug-ins in the repository.\n\n-r REPO_NAME (optional)\n: The name of the repository where the plug-in binary is located. If no repository is specified, the command uses the default plug-in repository IBM Cloud.\n\n-v VERSION (optional)\n: Version of the plug-in to be downloaded. Accepts specific semantic version or constraint.\n\n-d, --dest DOWNLOAD_DIRECTORY (optional)\n: The destination directory for the downloaded plug-in. If not specified, this is the working directory.\n\n-f\n: Force downloads the plug-in without confirmation.\n\nThe IBM Cloud CLI has the official repository name of IBM Cloud.\n\nExamples:\n\nDownload a plug-in from the remote URL:\n\nibmcloud plugin download http:\/\/example.com\/downloads\/my-plugin\n\nDownload the container-service plug-in of the latest version from the IBM Cloud repository:\n\nibmcloud plugin download container-service -r \"IBM Cloud\"\n\nOr you can run:\n\nibmcloud plugin download container-service\n\nDownload the container-service plug-in with the version 0.1.425 from the official plug-in repository:\n\nibmcloud plugin download container-service -v 0.1.425","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_settings"},{"document_id":"ibmcld_12332-1034-2510","score":20.3460069322,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_04442-3871-5648","score":20.0947507979,"text":"\n-v VERSION (optional)\n: Version of the plug-in to be installed. Accepts specific semantic version or constraint.\n\n-f\n: Force installs the plug-in without confirmation.\n\nThe IBM Cloud CLI has the official repository name of IBM Cloud.\n\nExamples:\n\nInstall a plug-in from the local file:\n\nibmcloud plugin install \/downloads\/new_plugin\n\nInstall a plug-in from the remote URL:\n\nibmcloud plugin install http:\/\/example.com\/downloads\/my-plugin\n\nInstall the container-service plug-in of the latest version from the IBM Cloud repository:\n\nibmcloud plugin install container-service -r \"IBM Cloud\"\n\nor you can run:\n\nibmcloud plugin install container-service\n\nInstall the container-service plug-in with the version 0.1.425 from the official plug-in repository:\n\nibmcloud plugin install container-service -v 0.1.425\n\nInstall all latest available plug-ins from the official plug-in repository:\n\nibmcloud plugin install --all\n\nInstall all latest available plug-ins from the official plug-in repository without confirmation:\n\nibmcloud plugin install --all -f\n\nInstall multiple plug-ins at the same time:\n\nibmcloud plugin install container-service@0.1.425 secrets-manager@0.1.25\n\n\n\n\n\n ibmcloud plugin download \n\nDownload a specific version of a plug-in to IBM Cloud CLI from the specified repository, or all latest available plug-ins in the repository.\n\nibmcloud plugin download PLUGIN_NAME [-r REPO_NAME] [-v VERSION] [-d, --dest DOWNLOAD_DIRECTORY] [-f]\n\nibmcloud plugin download [-a, --all] [-r REPO_NAME] [-f]\n\nibmcloud plugin download URL [-f] [-d DOWNLOAD_DIRECTORY]\n\nIf no repository is specified, the command uses the default plug-in repository IBM Cloud. If you are downloading a single plug-in, and no version is specified, the command selects the latest available version to download.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_settings"},{"document_id":"ibmcld_04442-6477-8304","score":19.9501595515,"text":"\nibmcloud plugin download http:\/\/example.com\/downloads\/my-plugin\n\nDownload the container-service plug-in of the latest version from the IBM Cloud repository:\n\nibmcloud plugin download container-service -r \"IBM Cloud\"\n\nOr you can run:\n\nibmcloud plugin download container-service\n\nDownload the container-service plug-in with the version 0.1.425 from the official plug-in repository:\n\nibmcloud plugin download container-service -v 0.1.425\n\nDownload the container-service plug-in with the version 0.1.425 from the official plug-in repository, into the \/my_downloads directory:\n\nibmcloud plugin download container-service -v 0.1.425 -d \/my_downloads\n\nDownload all latest available plug-ins from the official plug-in repository:\n\nibmcloud plugin download --all\n\nDownload all latest available plug-ins from the official plug-in repository without confirmation:\n\nibmcloud plugin download --all -f\n\n\n\n\n\n ibmcloud plugin update \n\nUpgrade the plug-in from a repository.\n\nibmcloud plugin update [PLUGIN NAME] [-r REPO_NAME] [-v VERSION] [--all]\n\nIf no repository is specified, the command uses the default plug-in repository IBM Cloud. If no version is specified, the command selects the latest available version to install.\n\nCommand options:\n\nPLUGIN NAME\n: Name of the plug-in to update. If not specified, the command checks upgrades for all plug-ins installed.\n\n-r REPO_NAME\n: The name of the repository where the plug-in binary is located. If not specified, the command uses the default plug-in repository IBM Cloud.\n\n-v VERSION (optional)\n: The version of the plug-in to be updated to. If not provided, update the plug-in to the most recent version.\n\n--all\n: Update all available plug-ins.\n\nExamples:\n\nCheck for all available upgrades in the official plug-in repository IBM Cloud:\n\nibmcloud plugin update -r \"IBM Cloud\"\n\nor you can run:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_settings"},{"document_id":"ibmcld_13114-2662-3951","score":18.6954195853,"text":"\n[https:\/\/kubernetes.io\/docs\/tasks\/tools\/install-kubectl\/#install-kubectl-on-windows](https:\/\/kubernetes.io\/docs\/tasks\/tools\/install-kubectl\/install-kubectl-on-windows).\n2. Move kubectl.exe binary to your PATH.\n3. Verify the installation with:\n\nkubectl version --client=true\n\n\n\n\n\n\n\n oc \n\n\n\n1. Download the latest 4.x OpenShift CLI (oc) from [https:\/\/mirror.openshift.com\/pub\/openshift-v4\/clients\/ocp\/stable\/](https:\/\/mirror.openshift.com\/pub\/openshift-v4\/clients\/ocp\/stable\/).\n2. Move oc.exe binary to your PATH.\n3. Verify the installation with:\n\noc version\n\n\n\n\n\n\n\n Helm 3 \n\n\n\n1. Download helm from [https:\/\/github.com\/helm\/helm\/releases\/latest](https:\/\/github.com\/helm\/helm\/releases\/latest).\n2. Uncompress the downloaded archive.\n3. Move helm.exe binary to your PATH.\n4. Verify the installation with:\n\nhelm version\n\n\n\n\n\n\n\n Terraform \n\n\n\n1. Download terraform from [https:\/\/www.terraform.io\/downloads.html](https:\/\/www.terraform.io\/downloads.html).\n2. Uncompress the downloaded archive.\n3. Move the terraform.exe binary to your PATH.\n4. Verify the installation with:\n\nterraform version\n\n\n\nTo manage IBM Cloud resources with Terraform, you also need to install the IBM Cloud Provider. Starting with Terraform 0.13, the provider can be automatically downloaded from Terraform plugin registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials"}],"retriever_scores":{}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16342-4330-5240","score":32.3138589901,"text":"\nThis failure rarely happens with the Google custom search extension, but it might happen if you are searching a site with large volumes of metadata that is returned by Google custom search. If you think that this might be a problem, try running the query in an API testing tool like curl, [Insomnia](https:\/\/insomnia.rest\/), or [Postman](https:\/\/www.postman.com\/). Check how many bytes of data you are getting as search results. If the total is at or near 100 kb, you might be able to work around the issue by reducing num_of_results and getting fewer results for each query or by excluding sites or pages with large volumes of metadata.\n\nFor more information, see [Limit on Size of Search Results](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/blob\/master\/integrations\/extensions\/starter-kits\/watson-discovery\/README.mdlimit-on-size-of-search-results) in a starter kit for IBM Watson\u00ae Discovery.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-extension-google"},{"document_id":"ibmcld_16342-2855-4758","score":31.9482483096,"text":"\nFor general instructions on adding any custom extension, see [Adding an extension to your assistant](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-add-custom-extension).\n\n\n\n\n\n\n\n Add the Google custom search starter kit action template \n\n\n\n1. Open the Actions page.\n2. If you have no actions, choose Create a new action. If you already have some actions, choose New action.\n3. On Create an action, choose Quick start with templates.\n\nQuick start with templates is available in English-language assistants only.\n4. On Quick start with templates, add the Google custom search starter kit.\n\n\n\n\n\n\n\n Edit system actions \n\n\n\n1. Click Set by assistant and open the No action matches action.\n2. Delete the two default steps.\n3. Add a step. Set And then to Go to a subaction and choose the Google search action.\n4. If you aren't connecting your customers to a live agent, you might want to edit the Fallback action in the same way as No action matches.\n\n\n\n\n\n\n\n Using your Google custom search extension \n\nIssue a query to your assistant. If no action that matches that query, then it uses Google to produce search results.\n\n\n\n\n\n Limit on search results size \n\nWatson Assistant has a 100 kb limit on the size of information that is stored in context variables, which includes search results. If the results from your extension exceed that limit, the action can fail without any visible warning or error. Typically a long delay occurs and then there is no response. This failure rarely happens with the Google custom search extension, but it might happen if you are searching a site with large volumes of metadata that is returned by Google custom search. If you think that this might be a problem, try running the query in an API testing tool like curl, [Insomnia](https:\/\/insomnia.rest\/), or [Postman](https:\/\/www.postman.com\/). Check how many bytes of data you are getting as search results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-extension-google"},{"document_id":"ibmcld_16342-7-1910","score":25.8309197081,"text":"\nGoogle custom search extension setup \n\nYou can access Google search through an extension to your assistant that uses the [Google Programmable Search Engine](https:\/\/developers.google.com\/custom-search\/docs\/overview). It is a configurable search that you can customize based on your use case.\n\nTo set up the extension for Google search:\n\n\n\n Get Search Engine ID and API key \n\nCreate a Google Programmable Search Engine. Then, get its Search Engine ID and an API key. For detailed instructions, see [Create Programmable Search Engine](https:\/\/developers.google.com\/custom-search\/v1\/introductioncreate_programmable_search_engine) in the Google Programmable Search Engine documentation.\n\n\n\n\n\n Download the OpenAPI specification \n\nDownload the OpenAPI specification file: [google-custom-search-openapi.json](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/blob\/master\/integrations\/extensions\/starter-kits\/google-custom-search\/basic\/google-custom-search-openapi.json). You use this file to add the extension to your assistant.\n\nThe OpenAPI specification defines the following methods:\n\n\n\n* GET \/customsearch\/v1: Search for content over the entire web.\n* GET \/customsearch\/v1\/siterestrict: Search for content over a specific collection of websites.\n\n\n\nFor more information about the endpoints, see [Custom Search](https:\/\/developers.google.com\/custom-search\/v1\/reference\/rest\/v1\/cse\/list) or [Custom Search Site Restricted](https:\/\/developers.google.com\/custom-search\/v1\/reference\/rest\/v1\/cse.siterestrict\/list).\n\nThe endpoints have the same arguments and responses, but with differences:\n\n\n\n* Custom Search Site Restricted is restricted to searching 10 or fewer websites, each of which can have an unlimited number of pages.\n* Custom Search can support any number of websites that is indexed by Google, but has a [daily query limit](https:\/\/developers.google.com\/custom-search\/v1\/overviewpricing).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-extension-google"},{"document_id":"ibmcld_16342-1264-3251","score":24.0099373723,"text":"\nFor more information about the endpoints, see [Custom Search](https:\/\/developers.google.com\/custom-search\/v1\/reference\/rest\/v1\/cse\/list) or [Custom Search Site Restricted](https:\/\/developers.google.com\/custom-search\/v1\/reference\/rest\/v1\/cse.siterestrict\/list).\n\nThe endpoints have the same arguments and responses, but with differences:\n\n\n\n* Custom Search Site Restricted is restricted to searching 10 or fewer websites, each of which can have an unlimited number of pages.\n* Custom Search can support any number of websites that is indexed by Google, but has a [daily query limit](https:\/\/developers.google.com\/custom-search\/v1\/overviewpricing).\n\n\n\nFor a typical assistant focused on a specific topic, it is usually only necessary to search a single website or a few websites. Custom Search Site Restricted is a better fit since it doesn't have a limit on the number of queries that can be run per day. Assistants that need to search more than 10 websites need to use Custom Search instead.\n\n\n\n\n\n Create and add extension \n\n\n\n1. In your assistant, on the Integrations page, click Build custom extension and use the OpenAPI specification file to build a custom extension. For general instructions on building any custom extension, see [Building the custom extension](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-build-custom-extensionbuilding-the-custom-extension).\n2. After you build the Google custom search extension and it appears on your Integrations page, click Add to add it to your assistant. Use your Google programmable search engine API key to authenticate. For general instructions on adding any custom extension, see [Adding an extension to your assistant](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-add-custom-extension).\n\n\n\n\n\n\n\n Add the Google custom search starter kit action template \n\n\n\n1. Open the Actions page.\n2. If you have no actions, choose Create a new action. If you already have some actions, choose New action.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-extension-google"},{"document_id":"ibmcld_16244-7923-9226","score":23.4047424373,"text":"\nCoveo search [coveo.openapi.json](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/blob\/master\/integrations\/extensions\/starter-kits\/coveo\/coveo.openapi.json) [Coveo search setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-templatesactions-templates-extension-setup-coveo) \n Google custom search [google-custom-search-openapi.json](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/blob\/master\/integrations\/extensions\/starter-kits\/google-custom-search\/basic\/google-custom-search-openapi.json) [Google custom search setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-templatesactions-templates-extension-setup-google) \n HubSpot [hubspot.advanced.openapi.json](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/blob\/master\/integrations\/extensions\/starter-kits\/hubspot\/advanced\/hubspot.advanced.openapi.json) [HubSpot setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-templatesactions-templates-extension-setup-hubspot) \n NeuralSeek Requires a file specific to your instance of NeuralSeek. Refer to the setup instructions. [NeuralSeek extension setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-templatesactions-templates-extension-setup-neuralseek)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-templates"},{"document_id":"ibmcld_07096-5734-7445","score":23.2924718913,"text":"\nFor example, the following syntax searches for documents in which Google is identified as an entity or the string IBM is present:\n\n{\n\"query\":\"enriched_text.entities.text:Google|IBM\"\n}\n\nIt is treated as follows:\n\n(enriched_text.entities.text:Google) OR IBM\n\n\n\n\n\n , (and) \n\nBoolean operator for \"and\".\n\nIn the following example, documents in which Google and IBM both are identified as entities are returned:\n\n{\n\"query\":\"enriched_text.entities.text:Google,enriched_text.entities.text:IBM\"\n}\n\nThe includes (:,:!) and match (::, ::!) operators have precedence over the AND operator.\n\nFor example, the following syntax searches for documents in which Google is identified as an entity and the string IBM is present:\n\n{\n\"query\":\"enriched_text.entities.text:Google,IBM\"\n}\n\nIt is treated as follows:\n\n(enriched_text.entities.text:Google) AND IBM\n\n\n\n\n\n <=, >=, >, < (Numerical comparisons) \n\nCreates numerical comparisons of less than or equal to, greater than or equal to, greater than, and less than.\n\nOnly use numerical comparison operators when the value is a number or date.\n\nAny value that is surrounded by quotations is a String. Therefore, score>=0.5 is a valid query and score>=\"0.5\" is not.\n\nFor example:\n\n{\n\"query\":\"invoice.total>100.50\"\n}\n\n\n\n\n\n ^x (Score multiplier) \n\nIncreases the score value of a search term.\n\nFor example:\n\n{\n\"query\":\"enriched_text.entities.text:IBM^3\"\n}\n\n\n\n\n\n * (Wildcard) \n\nMatches unknown characters in a search expression. Do not use capital letters with wildcards.\n\nFor example:\n\n{\n\"query\":\"enriched_text.entities.text:ib\"\n}\n\n\n\n\n\n n (String variation) \n\nThe number of character differences that are allowed when matching a string. The maximum variation number that can be used is 2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operators"},{"document_id":"ibmcld_07190-1520-3331","score":22.9471325133,"text":"\nUse phrase queries with full-text, rank-based queries, and not with boolean filter operations. Do not use wildcards () in phrase queries.\n\nSingle quotes (') are not supported.\n\nFor example:\n\nenriched_text.entities.text:\"IBM watson\"\n\n\n\n\n\n (), [] [Nested grouping] \n\nLogical groupings can be formed to specify more specific information.\n\nFor example:\n\nenriched_text.entities:(text:IBM,type:Company)\n\n\n\n\n\n | [or] \n\nBoolean operator for \"or\".\n\nIn the following example, documents in which Google or IBM are identified as entities are returned:\n\nenriched_text.entities.text:Google|enriched_text.entities.text:IBM\n\nThe includes (:,:!) and match (::, ::!) operators have precedence over the OR operator.\n\nFor example, the following syntax searches for documents in which Google is identified as an entity or the string IBM is present:\n\nenriched_text.entities.text:Google|IBM\n\nThe query is treated as follows:\n\n(enriched_text.entities.text:Google) OR IBM\n\n\n\n\n\n , [and] \n\nBoolean operator for \"and\".\n\nIn the following example, documents in which Google and IBM both are identified as entities are returned:\n\nenriched_text.entities.text:Google,enriched_text.entities.text:IBM\n\nThe includes (:,:!) and match (::, ::!) operators have precedence over the AND operator.\n\nFor example, the following syntax searches for documents in which Google is identified as an entity and the string IBM is present:\n\nenriched_text.entities.text:Google,IBM\n\nThe query is treated as follows:\n\n(enriched_text.entities.text:Google) AND IBM\n\n\n\n\n\n <=, >=, >, < [Numerical comparisons] \n\nCreates numerical comparisons of less than or equal to, greater than or equal to, greater than, and less than.\n\nFor example:\n\nenriched_text.sentiment.document.score>0.679\n\n\n\n\n\n ^x [Score multiplier] \n\nIncreases the score value of a search term.\n\nFor example:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators"},{"document_id":"ibmcld_16344-1600-2402","score":22.1026759519,"text":"\nFor instructions on adding the built-in search integration, see [IBM Watson\u00ae Discovery search integration setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant\/?topic=watson-assistant-search-add).\n\n\n\n\n\n Add a search extension \n\nWith a search extension, you can \"bring your own search\" and use content from your website, knowledge base, or content management system.\n\nFor instructions on adding a search extension, see:\n\n\n\n* [Coveo search extension setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-extension-coveo)\n* [Google custom search extension setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-extension-google)\n* [NeuralSeek extension setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-extension-neuralseek)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-overview"},{"document_id":"ibmcld_16244-9556-11209","score":21.795330768,"text":"\nZendesk [zendesk-openapi.json](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/blob\/master\/integrations\/extensions\/starter-kits\/zendesk-support\/zendesk.openapi.json) [Zendesk extension setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-templatesactions-templates-extension-setup-zendesk) \n\n\n\n\n\n Coveo search extension setup \n\nTo set up the extension for Coveo search, see [Coveo search extension setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-extension-coveo).\n\n\n\n\n\n Google custom search extension setup \n\nTo set up the extension for Google custom search, see [Google custom search extension setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-extension-google).\n\n\n\n\n\n HubSpot extension setup \n\nTo set up the extension for HubSpot:\n\n\n\n1. In HubSpot, you need to create a developer account and then create a private app. The private app includes an access token that you need for authentication. For detailed instructions, see [Getting private app access token](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/blob\/master\/integrations\/extensions\/starter-kits\/hubspot\/readme.mdpre-req-1-getting-private-apps-access-token) in the HubSpot Custom Extension starter kit GitHub repository.\n2. Your HubSpot account needs custom properties. Follow the instructions in [Adding Custom Properties in HubSpot](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/blob\/master\/integrations\/extensions\/starter-kits\/hubspot\/readme.mdpre-req-2-adding-custom-properties-in-hubspot) in the HubSpot Custom Extension starter kit GitHub repository.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-templates"},{"document_id":"ibmcld_07096-4462-6143","score":19.5122569296,"text":"\n\"query\":\"enriched_text.entities.text::\"IBM Cloud\"\"\n}\n\n\n\n\n\n :! (Does not include) \n\nThis operator specifies that the results do not contain a match for the query term.\n\nFor example:\n\n{\n\"query\":\"enriched_text.entities.text:!\"cloud computing\"\"\n}\n\n\n\n\n\n ::! (Not an exact match) \n\nThis operator specifies that the results do not exactly match the query term.\n\nFor example:\n\n{\n\"query\":\"enriched_text.entities.text::!\"Cloud computing\"\"\n}\n\nExact matches are case-sensitive.\n\n\n\n\n\n (Escape character) \n\nEscape character that preserves the literal value of the character that follows it.\n\nFor example, you can place an escape character before a quotation mark in query text to include the quotation mark in the query string.\n\n{\n\"query\":\"title::Dorothy said: \"There's no place like home\"\"\n}\n\n\n\n\n\n (),[] (Nested grouping) \n\nLogical groupings can be formed to specify more specific information.\n\nFor example:\n\n{\n\"query\":\"enriched_text.entities:(text:IBM,type:Company)\"\n}\n\n\n\n\n\n | (or) \n\nBoolean operator for \"or\".\n\nIn the following example, documents in which Google or IBM are identified as entities are returned:\n\n{\n\"query\":\"enriched_text.entities.text:Google|enriched_text.entities.text:IBM\"\n}\n\nThe includes (:,:!) and match (::, ::!) operators have precedence over the OR operator.\n\nFor example, the following syntax searches for documents in which Google is identified as an entity or the string IBM is present:\n\n{\n\"query\":\"enriched_text.entities.text:Google|IBM\"\n}\n\nIt is treated as follows:\n\n(enriched_text.entities.text:Google) OR IBM\n\n\n\n\n\n , (and) \n\nBoolean operator for \"and\".\n\nIn the following example, documents in which Google and IBM both are identified as entities are returned:\n\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operators"}],"retriever_scores":{}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07191-7-2252","score":15.1124425759,"text":"\nQuery parameters \n\nIBM Watson\u2122 Discovery offers powerful content search capabilities through queries. After your content is uploaded and enriched by Discovery, you can build queries, integrate Discovery into your own projects, or create a custom application by using the Watson Explorer Application Builder. To get started with queries, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts). For the complete list of parameters, see the [Query reference](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-referenceparameter-descriptions).\n\nSearch parameters\n\nSearch parameters enable you to search your collection, identify a result set, and perform analysis on the result set.\n\nThe results set is the group of documents identified by the combined searches of the search parameters. The results set might be significantly larger than the returned results. If an empty query is performed, the results set is equal to all the documents in the collection.\n\n\n\n query \n\nA query search returns all documents in your data set with full enrichments and full text in order of relevance. A query also excludes any documents that don't mention the query content. These queries are written using the [Discovery Query Language](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators).\n\n\n\n\n\n filter \n\nA cacheable query that excludes any documents that don't mention the query content. Filter search results are not returned in order of relevance. These queries are written using the [Discovery Query Language](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators).\n\n\n\n Differences between the filter and query parameters \n\nIf you test the same search term on a small data set, you might find that the filter and query parameters return very similar (if not identical) results. However, there is a difference between the two parameters.\n\n\n\n* Using a filter parameter alone returns search results in no specific order.\n* Using a query parameter alone returns search results in order of relevance.\n\n\n\nIn large data sets, if you need results returned in order of relevance, it is advisable that you combine the filter and query parameters because using them together improves performance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parameters"},{"document_id":"ibmcld_07178-6197-7974","score":14.5871074713,"text":"\n[Example query structure](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ded4adc3ea0bd2a81b113c579f2b1183926da211\/discovery\/images\/query_structure2.png)\n\nOperators that evaluate a field (<= , >=, <, >) require a number or date as the value. Using quotations around a value always makes it a string. Therefore score>=0.5 is a valid query and score>=\"0.5\" is not. See [Query operators](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators) for a complete list of operators.\n\nConsiderations:\n\n\n\n* Not sure when to query on an entity, concept, or keyword? See [Understanding the difference between Entities, Concepts, and Keywords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configserviceudbeck).\n\n\n\nAfter you click Run query and open the JSON tab, query highlighting is turned on, by default. The setting adds a highlight field to your query results. Within the highlight field, the words that match your query are wrapped in HTML <em> (emphasis) tags. For more information, see the [Query parameters](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametershighlight).\n\n\n\n\n\n\n\n Building combined queries \n\nYou can combine query parameters together to build more targeted queries. For example, you can use the both the filter and query parameters together. For more information about filtering vs. querying, see [Differences between the filter and query parameters](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametersfiltervquery).\n\n\n\n\n\n How to structure an aggregation \n\nAggregations return a set of data values; for example, top keywords, overall sentiment of entities, and more. For the full list of aggregation options, see [Aggregations](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-referenceaggregations).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts"},{"document_id":"ibmcld_02590-7911-9371","score":14.3903181211,"text":"\nTo prevent [dangerous client bugs and backward-compatibility hazards](https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-robustnesssanitation-and-validation), unrecognized query parameters SHOULD and invalid parameter values MUST result in a 400 status code and appropriate error response model.\n\n\n\n\n\n Case insensitivity \n\nQuery parameter names SHOULD NOT be case-normalized to support case insensitivity; a parameter that does not match the case of a defined parameter but otherwise matches its name SHOULD be treated as any other extraneous input\n\n[4].\n\nHowever, parameter name case normalization MAY be supported for backward compatibility with existing clients.\n\n\n\n\n\n Parameter duplication \n\nRequests that provide a query string with duplicate single-value\n\n[5]query parameters of the same name and differing values[6] MUST result in a 400 status and appropriate error response model. For backward compatibility with existing clients, query strings containing duplicate query parameters of the same name and with the same value MAY be supported [7].\n\nIf a service supports parameter name [case insensitivity](https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-uriscase-insensitivity), parameter names MUST be normalized prior to validating uniqueness.\n\nSupport for array input in query parameters SHOULD use comma-separated values within a single parameter (for example, foo=1,2,3) instead of duplicated\n\n[8]parameters ( foo=1&foo=2&foo=3).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-uris"},{"document_id":"ibmcld_07191-1691-3739","score":14.0825749949,"text":"\nIf you test the same search term on a small data set, you might find that the filter and query parameters return very similar (if not identical) results. However, there is a difference between the two parameters.\n\n\n\n* Using a filter parameter alone returns search results in no specific order.\n* Using a query parameter alone returns search results in order of relevance.\n\n\n\nIn large data sets, if you need results returned in order of relevance, it is advisable that you combine the filter and query parameters because using them together improves performance. The reason is because the filter parameter runs first and caches results, and then the query parameter ranks them. For an example of using filters and queries together, see [Building combined queries](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsbuilding-combined-queries). Filters can also be used in aggregations.\n\nWhen you write a query that includes both a filter, and an aggregation, query, or natural_language_query parameter; the filter parameters run first, after which any aggregation, query, or natural_language_query parameters run in parallel.\n\nWith a simple query, especially on a small data set, filter and query often return the exact same (or similar) results. If a filter and query call return similar results, and getting a response in order of relevance does not matter, it is better to use filter because filter calls are faster and are cached. Caching means that the next time you make that call, you get a much quicker response, particularly in a big data set.\n\n\n\n\n\n\n\n aggregation \n\nAggregation queries return a count of documents matching a set of data values; for example, top keywords, overall sentiment of entities, and more. For the full list of aggregation options, see the [Aggregations table](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-aggregations). These aggregations are written using the [Discovery Query Language](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators).\n\n\n\n\n\n natural_language_query","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parameters"},{"document_id":"ibmcld_13406-1732-4088","score":13.8411830855,"text":"\nThey can also help you distinguish the absence of results due to\n\n\n\n* Lack of audio.\n* Lack of speech in submitted audio.\n* Engine stalls at the server and network stalls between the client and the server. To differentiate between engine and network stalls, results are periodic rather than event-based.\n\n\n\nThe metrics can also help you estimate response jitter by examining the periodic arrival times. Metrics are generated at a constant interval, so any difference in arrival times is caused by jitter.\n\n\n\n Requesting processing metrics \n\nTo request processing metrics, use the following optional parameters:\n\n\n\n* processing_metrics is a boolean that indicates whether the service is to return processing metrics. Specify true to request the metrics. By default, the service returns no metrics.\n* processing_metrics_interval is a float that specifies the interval in seconds of real wall-clock time at which the service is to return metrics. By default, the service returns metrics once per second. The service ignores this parameter unless the processing_metrics parameter is set to true.\n\nThe parameter accepts a minimum value of 0.1 seconds. The level of precision is not restricted, so you can specify values such as 0.25 and 0.125. The service does not impose a maximum value.\n\n\n\nHow you provide the parameters and how the service returns processing metrics differ by interface:\n\n\n\n* With the WebSocket interface, you specify the parameters with the JSON start message for a speech recognition request. The service calculates and returns metrics in real-time at the requested interval.\n* With the asynchronous HTTP interface, you specify query parameters with a speech recognition request. The service calculates the metrics at the requested interval, but it returns all metrics for the audio with the final transcription results.\n\n\n\nThe service also returns processing metrics for transcription events. If you request interim results with the WebSocket interface, you can receive metrics with greater frequency than the requested interval.\n\nTo receive processing metrics only for transcription events instead of at periodic intervals, set the processing interval to a large number. If the interval is larger than the duration of the audio, the service returns processing metrics only for transcription events.\n\n\n\n\n\n Understanding processing metrics","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-metrics"},{"document_id":"ibmcld_07098-7-2215","score":13.5761836371,"text":"\nQuery parameters \n\nYou can use these parameters when you write queries with the Discovery Query Language. For more information, see the Discovery [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery-dataquery). For an overview of query concepts, see the [Query overview](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-concepts).\n\nQueries that are written in the Discovery Query Language can include both search and structure parameters.\n\nThe default values for query parameters can differ by project type. For more information about default values, see [Default query settings](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-defaults).\n\n\n\n Search parameters \n\nUse search parameters to search your collection, identify a result set, and analyze the result set.\n\nThe results set is the group of documents that are identified by the combined searches of the search parameters. The results set might be significantly larger than the returned results. If an empty query is submitted, the results set is equal to all the documents in the collection.\n\nDocuments that you do not have permissions to access are not returned in query results.\n\n\n\n\n\n Answer finding \n\nIBM Cloud\n\nThe find_answers parameter is supported in managed deployments only.\n\nBy default, Discovery provides answers by returning the entire [passage](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parameterspassages) that contains the answer to a natural language query. When the answer-finding feature is enabled, Discovery also provides a \"short answer\" within the passage, and a confidence score to show whether the \"short answer\" answers the question that is explicit or implicit in the user query. Applications that use the answer-finding feature can display the short answer alone or can display the short answer emphasized in the context of the full passage. For most applications, displaying the short answer emphasized within the full passage is preferable, because answers generally make more sense in context.\n\nThe answer finding feature behaves in the following ways:\n\nIn the passage examples that follow, the short answers are shown in bold font.\n\n\n\n* Finds answers.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parameters"},{"document_id":"ibmcld_07067-26099-28206","score":13.3059144968,"text":"\nIf false, ranks the passages from all of the documents by passage quality regardless of the document quality and returns them in a separate passages field in the response.\n* When passages are returned for a query, you can also enable answer finding. When true, answer objects are returned as part of each passage in the query results. When find_answers and per_document are both set to true, the document search results and the passage search results within each document are reordered by using the answer confidences. The goal of this reordering is to place the best answer as the first answer of the first passage of the first document. Similarly, if the find_answers parameter is set to true and per_document parameter is set to false, then the passage search results are reordered in decreasing order of the highest confidence answer for each document and passage.\n* Both v1 and v2 support custom stop words. However, there are a few differences in how custom stop words are used:\n\n\n\n* There is no default custom stop words list for Japanese collections in v2.\n* When you define custom stop words in v1, your stop words list replaces the existing stop words list. In v2, your list augments the default list. You cannot replace the list, which means you cannot remove stop words that are part of the default list in v2.\n\n\n\n\n\n\n\n Update how your application handles query results \n\nThe way that your application shows query results might need to be updated due to the following differences between the query results document syntax between the v1 and v2 queries:\n\n\n\n* At the entity enrichment level, the following information is not supported in v2:\n\n\n\n* Disambiguation\n* Emotion\n* Sentiment\n\n\n\nThe Part of Speech enrichment is applied automatically to documents in most project types in v2, but the index fields that are generated by the enrichment are not displayed in the JSON representation of the document.\n\nZoom\n\n![Difference in entities data structure](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/compare-result-syntax.png)\n\nFigure 1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2"},{"document_id":"ibmcld_13446-15041-17074","score":13.1504745286,"text":"\nAvailability and usage Description \n\n Previous-generation models Not available. \n Next-generation models Generally available or beta for next-generation models that support low latency. For more information, see [Supported next-generation language models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models-ngmodels-ng-supported). \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n max_alternatives \n\nAn optional integer that specifies the maximum number of alternative hypotheses that the service returns. By default, the service returns a single final hypothesis. For more information, see [Maximum alternatives](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-metadatamax-alternatives).\n\n\n\nTable 17. The max_alternatives parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n model \n\nAn optional model that specifies the language in which the audio is spoken and the rate at which it was sampled: broadband\/multimedia or narrowband\/telephony. By default, en-US_BroadbandModel is used. For more information, see [Using a model for speech recognition](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models-use).\n\n\n\nTable 18. The model parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket Query parameter of \/v1\/recognize connection request \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n processing_metrics","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-summary"},{"document_id":"ibmcld_03285-5746-7932","score":13.0260527174,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_16321-5729-7915","score":13.0260527174,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2021073465,"ndcg_cut_10":0.3692678015}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13790-7-1700","score":17.6442458887,"text":"\nThe WebSocket interface \n\nTo synthesize text to speech with the WebSocket interface of the IBM Watson\u00ae Text to Speech service, you first establish a connection with the service by calling its \/v1\/synthesize method. You then send the text to be synthesized to the service as a JSON text message over the connection. The service automatically closes the WebSocket connection when it finishes processing the request.\n\nThe synthesize request and response cycle includes the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSopen).\n2. [Send input text](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSsend).\n3. [Receive a response](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSreceive).\n\n\n\nThe WebSocket interface accepts identical input and produces identical results as the GET and POST \/v1\/synthesize methods of the HTTP interface. In addition, the WebSocket interface also supports use of the SSML <mark> element to identify the location of user-specified markers in the audio. It can also return timing information for all strings of the input text. (The <mark> element and word timings are available only with the WebSocket interface.)\n\n\n\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13790-1284-2889","score":17.5856969696,"text":"\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\n\n\n Open a connection \n\nYou call the \/v1\/synthesize method over the WebSocket Secure (WSS) protocol to open a connection to the service. The method is available at the following endpoint:\n\nwss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id}\/v1\/synthesize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of the service instance.\n\nThe examples in the documentation abbreviate wss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id} to {ws_url}. So all WebSocket examples call the method as {ws_url}\/v1\/synthesize.\n\nA WebSocket client calls the \/v1\/synthesize method with the following query parameters to establish an authenticated connection with the service:\n\naccess_token (required string)\n: Pass a valid access token to authenticate with the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13455-7-1568","score":17.1846162647,"text":"\nThe WebSocket interface \n\nThe WebSocket interface of the IBM Watson\u00ae Speech to Text service is the most natural way for a client to interact with the service. To use the WebSocket interface for speech recognition, you first use the \/v1\/recognize method to establish a persistent connection with the service. You then send text and binary messages over the connection to initiate and manage recognition requests.\n\nBecause of their advantages, WebSockets are the preferred mechanism for speech recognition. For more information, see [Advantages of the WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-service-featuresfeatures-websocket-advantages). For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\n\n\n Managing a WebSocket connection \n\nThe WebSocket recognition request and response cycle has the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-open)\n2. [Initiate a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-start)\n3. [Send audio and receive recognition results](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-audio)\n4. [End a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-more)\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_10833-0-1231","score":16.4406280064,"text":"\n\n\n\n\n\n\n  WebSocket \n\nThe preinstalled \/whisk.system\/websocket package for IBM Cloud\u00ae Functions offers a convenient way to post messages to a WebSocket.\n\nThe package includes the following actions.\n\n\n\nTable 1. WebSocket package entities\n\n Entity                          Type     Parameters        Description                                 \n\n \/whisk.system\/websocket         Package  uri               Utilities for communicating with WebSockets \n \/whisk.system\/websocket\/send    Action   uri, payload      Send the payload to the WebSocket URI.      \n\n\n\nIf you plan to send many messages to the same WebSocket URI, creating a package binding with the uri value is suggested. With binding, you don't need to specify the value each time that you use the send action.\n\n\n\n  Send a message to a WebSocket \n\nThe \/whisk.system\/websocket\/send action sends a payload to a WebSocket URI. The parameters are as follows.\n\n\n\nTable 2. WebSocket send action parameters\n\n Parameter  Description                                                                \n\n uri        The URI of the WebSocket server. For example, ws:\/\/mywebsockethost:80.     \n payload    The message to send to the WebSocket.                                      \n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_websocket"},{"document_id":"ibmcld_10852-48513-49624","score":16.2991114141,"text":"\n* [Reading an object with the CLI](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_read_cli)\n* [Reference for Object Storage and Cloud Functions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_actions)\n\n\n\n\n\n[Slack](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_slackpkg_slack)\n\n\n\n* [Posting a message to a Slack channel](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_slackpkg_slack_post)\n* [Using the Slack token-based API](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_slackpkg_slack_api)\n\n\n\n[Utilities](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_utilspkg_utils)\n\n[WebSocket](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_websocketpkg_websocket)\n\n\n\n* [Send a message to a WebSocket](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_websocketsend-websocket)\n\n\n\n[Creating custom event provider feeds](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-feeds_customfeeds_custom)\n\n\n\n* [Feed architecture](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-feeds_customfeeds_arch)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_13429-163247-165127","score":16.2658427897,"text":"\nThe WebSocket section also discusses the maximum frame or message size of 4 MB enforced by the WebSocket interface.\n\nHTTP and WebSocket interfaces can now return warnings\n: The JSON response for a recognition request can now include an array of warning messages for invalid query parameters or JSON fields that are included with a request. Each element of the array is a string that describes the nature of the warning followed by an array of invalid argument strings. For example, \"warnings\": [ \"Unknown arguments: u'{invalid_arg_1}', u'{invalid_arg_2}'].\" ]. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nBeta Apple iOS SDK is deprecated\n: The beta Watson Speech Software Development Kit (SDK) for the Apple\u00ae iOS operating system is deprecated. Use the Watson SDK for the Apple\u00ae iOS operating system instead. The new SDK is available from the [ios-sdk repository](https:\/\/github.com\/watson-developer-cloud\/ios-sdk) in the watson-developer-cloud namespace on GitHub.\n\nWebSocket interface can produce delayed results\n: The WebSocket interface can take minutes to produce final results for a recognition request for an especially long audio file. For the WebSocket interface, the underlying TCP connection remains idle while the service prepares the response. Therefore, the connection can close due to a timeout. To avoid the timeout with the WebSocket interface, request interim results (\"interim_results\": \"true\") in the JSON for the start message to initiate the request. You can discard the interim results if you do not need them. This issue will be resolved in a future update.\n\n\n\n\n\n 19 January 2016 \n\nNew profanity filtering feature\n: The service was updated to include a new profanity filtering feature on January 19, 2016. By default, the service censors profanity from its transcription results for US English audio.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_13455-26115-26611","score":16.132290918,"text":"\nIf the socket closes with an error, the client receives an informative message of the form {\"error\":\"{message}\"} before the socket closes. Use the onerror event handler to respond appropriately. For more information about WebSocket return codes, see [IETF RFC 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\nThe WebSocket implementations of the SDKs can return different or additional response codes. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_13741-1529-3393","score":15.5894404671,"text":"\nSynthesizing speech with the service \n\nThe Text to Speech service offers an HTTP Representational State Transfer (REST) interface and a WebSocket interface:\n\n\n\n* [The HTTP interface](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingHTTP) provides both GET and POST versions of the service's \/v1\/synthesize method. The two versions of the method offer generally equivalent functionality. You pass the text that is to be synthesized as a query parameter with the GET method and as the body of the request with the POST method.\n* [The WebSocket interface](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket) provides a \/v1\/synthesize method. You pass the text that is to be synthesized over an established WebSocket connection.\n\n\n\nWith both the HTTP and WebSocket interfaces, you specify the language and voice that are to be used, and the format for the audio that is to be returned.\n\n\n\n* For an overview of the features that are available for speech synthesis, see [Using speech synthesis features](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-service-featuresfeatures-synthesis).\n* For detailed descriptions and examples of the speech synthesis methods, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n Data limits \n\nThe interfaces accept the following maximum amounts of text with a single request:\n\n\n\n* The HTTP GET \/v1\/synthesize method accepts a maximum of 8 KB of input, which includes the input text and the URL and headers.\n* The HTTP POST \/v1\/synthesize method accepts a maximum of 8 KB for the URL and headers, and a maximum of 5 KB for the input text that is sent in the body of the request.\n* The WebSocket \/v1\/synthesize method accepts a maximum of 5 KB of input text.\n\n\n\nThese limits include all characters of the input, including whitespace.\n\nIBM Cloud","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-service-features"},{"document_id":"ibmcld_03285-5746-7932","score":15.3666222968,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_16321-5729-7915","score":15.3666222968,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3065735964,"ndcg_cut_5":0.3065735964,"ndcg_cut_10":0.5249810332}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13790-1284-2889","score":17.5856969696,"text":"\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\n\n\n Open a connection \n\nYou call the \/v1\/synthesize method over the WebSocket Secure (WSS) protocol to open a connection to the service. The method is available at the following endpoint:\n\nwss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id}\/v1\/synthesize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of the service instance.\n\nThe examples in the documentation abbreviate wss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id} to {ws_url}. So all WebSocket examples call the method as {ws_url}\/v1\/synthesize.\n\nA WebSocket client calls the \/v1\/synthesize method with the following query parameters to establish an authenticated connection with the service:\n\naccess_token (required string)\n: Pass a valid access token to authenticate with the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13790-7-1700","score":17.428573685,"text":"\nThe WebSocket interface \n\nTo synthesize text to speech with the WebSocket interface of the IBM Watson\u00ae Text to Speech service, you first establish a connection with the service by calling its \/v1\/synthesize method. You then send the text to be synthesized to the service as a JSON text message over the connection. The service automatically closes the WebSocket connection when it finishes processing the request.\n\nThe synthesize request and response cycle includes the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSopen).\n2. [Send input text](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSsend).\n3. [Receive a response](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSreceive).\n\n\n\nThe WebSocket interface accepts identical input and produces identical results as the GET and POST \/v1\/synthesize methods of the HTTP interface. In addition, the WebSocket interface also supports use of the SSML <mark> element to identify the location of user-specified markers in the audio. It can also return timing information for all strings of the input text. (The <mark> element and word timings are available only with the WebSocket interface.)\n\n\n\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13455-7-1568","score":17.1846162647,"text":"\nThe WebSocket interface \n\nThe WebSocket interface of the IBM Watson\u00ae Speech to Text service is the most natural way for a client to interact with the service. To use the WebSocket interface for speech recognition, you first use the \/v1\/recognize method to establish a persistent connection with the service. You then send text and binary messages over the connection to initiate and manage recognition requests.\n\nBecause of their advantages, WebSockets are the preferred mechanism for speech recognition. For more information, see [Advantages of the WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-service-featuresfeatures-websocket-advantages). For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\n\n\n Managing a WebSocket connection \n\nThe WebSocket recognition request and response cycle has the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-open)\n2. [Initiate a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-start)\n3. [Send audio and receive recognition results](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-audio)\n4. [End a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-more)\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_10833-0-1231","score":16.4406280064,"text":"\n\n\n\n\n\n\n  WebSocket \n\nThe preinstalled \/whisk.system\/websocket package for IBM Cloud\u00ae Functions offers a convenient way to post messages to a WebSocket.\n\nThe package includes the following actions.\n\n\n\nTable 1. WebSocket package entities\n\n Entity                          Type     Parameters        Description                                 \n\n \/whisk.system\/websocket         Package  uri               Utilities for communicating with WebSockets \n \/whisk.system\/websocket\/send    Action   uri, payload      Send the payload to the WebSocket URI.      \n\n\n\nIf you plan to send many messages to the same WebSocket URI, creating a package binding with the uri value is suggested. With binding, you don't need to specify the value each time that you use the send action.\n\n\n\n  Send a message to a WebSocket \n\nThe \/whisk.system\/websocket\/send action sends a payload to a WebSocket URI. The parameters are as follows.\n\n\n\nTable 2. WebSocket send action parameters\n\n Parameter  Description                                                                \n\n uri        The URI of the WebSocket server. For example, ws:\/\/mywebsockethost:80.     \n payload    The message to send to the WebSocket.                                      \n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_websocket"},{"document_id":"ibmcld_10852-48513-49624","score":16.2991114141,"text":"\n* [Reading an object with the CLI](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_read_cli)\n* [Reference for Object Storage and Cloud Functions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_actions)\n\n\n\n\n\n[Slack](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_slackpkg_slack)\n\n\n\n* [Posting a message to a Slack channel](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_slackpkg_slack_post)\n* [Using the Slack token-based API](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_slackpkg_slack_api)\n\n\n\n[Utilities](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_utilspkg_utils)\n\n[WebSocket](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_websocketpkg_websocket)\n\n\n\n* [Send a message to a WebSocket](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_websocketsend-websocket)\n\n\n\n[Creating custom event provider feeds](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-feeds_customfeeds_custom)\n\n\n\n* [Feed architecture](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-feeds_customfeeds_arch)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_13429-163247-165127","score":15.8780395876,"text":"\nThe WebSocket section also discusses the maximum frame or message size of 4 MB enforced by the WebSocket interface.\n\nHTTP and WebSocket interfaces can now return warnings\n: The JSON response for a recognition request can now include an array of warning messages for invalid query parameters or JSON fields that are included with a request. Each element of the array is a string that describes the nature of the warning followed by an array of invalid argument strings. For example, \"warnings\": [ \"Unknown arguments: u'{invalid_arg_1}', u'{invalid_arg_2}'].\" ]. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nBeta Apple iOS SDK is deprecated\n: The beta Watson Speech Software Development Kit (SDK) for the Apple\u00ae iOS operating system is deprecated. Use the Watson SDK for the Apple\u00ae iOS operating system instead. The new SDK is available from the [ios-sdk repository](https:\/\/github.com\/watson-developer-cloud\/ios-sdk) in the watson-developer-cloud namespace on GitHub.\n\nWebSocket interface can produce delayed results\n: The WebSocket interface can take minutes to produce final results for a recognition request for an especially long audio file. For the WebSocket interface, the underlying TCP connection remains idle while the service prepares the response. Therefore, the connection can close due to a timeout. To avoid the timeout with the WebSocket interface, request interim results (\"interim_results\": \"true\") in the JSON for the start message to initiate the request. You can discard the interim results if you do not need them. This issue will be resolved in a future update.\n\n\n\n\n\n 19 January 2016 \n\nNew profanity filtering feature\n: The service was updated to include a new profanity filtering feature on January 19, 2016. By default, the service censors profanity from its transcription results for US English audio.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_13455-26115-26611","score":15.8291163264,"text":"\nIf the socket closes with an error, the client receives an informative message of the form {\"error\":\"{message}\"} before the socket closes. Use the onerror event handler to respond appropriately. For more information about WebSocket return codes, see [IETF RFC 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\nThe WebSocket implementations of the SDKs can return different or additional response codes. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_13741-1529-3393","score":15.5894404671,"text":"\nSynthesizing speech with the service \n\nThe Text to Speech service offers an HTTP Representational State Transfer (REST) interface and a WebSocket interface:\n\n\n\n* [The HTTP interface](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingHTTP) provides both GET and POST versions of the service's \/v1\/synthesize method. The two versions of the method offer generally equivalent functionality. You pass the text that is to be synthesized as a query parameter with the GET method and as the body of the request with the POST method.\n* [The WebSocket interface](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket) provides a \/v1\/synthesize method. You pass the text that is to be synthesized over an established WebSocket connection.\n\n\n\nWith both the HTTP and WebSocket interfaces, you specify the language and voice that are to be used, and the format for the audio that is to be returned.\n\n\n\n* For an overview of the features that are available for speech synthesis, see [Using speech synthesis features](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-service-featuresfeatures-synthesis).\n* For detailed descriptions and examples of the speech synthesis methods, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n Data limits \n\nThe interfaces accept the following maximum amounts of text with a single request:\n\n\n\n* The HTTP GET \/v1\/synthesize method accepts a maximum of 8 KB of input, which includes the input text and the URL and headers.\n* The HTTP POST \/v1\/synthesize method accepts a maximum of 8 KB for the URL and headers, and a maximum of 5 KB for the input text that is sent in the body of the request.\n* The WebSocket \/v1\/synthesize method accepts a maximum of 5 KB of input text.\n\n\n\nThese limits include all characters of the input, including whitespace.\n\nIBM Cloud","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-service-features"},{"document_id":"ibmcld_13455-1311-2796","score":15.2786155372,"text":"\n4. [End a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-more)\n6. [Keep a connection alive](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-keep)\n7. [Close a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-close)\n\n\n\nWhen the client sends data to the service, it must pass all JSON messages as text messages and all audio data as binary messages.\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\n\n\n Open a connection \n\nThe Speech to Text service uses the WebSocket Secure (WSS) protocol to make the \/v1\/recognize method available at the following endpoint:\n\nwss:\/\/api.{location}.speech-to-text.watson.cloud.ibm.com\/instances\/{instance_id}\/v1\/recognize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of your service instance.\n\nThe examples in the documentation abbreviate wss:\/\/api.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_03285-5746-7932","score":14.9932768551,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.4414924137,"ndcg_cut_10":0.4414924137}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16380-1665-3330","score":12.1622950321,"text":"\n<div id=\"WebChatContainer\"><\/div>\n2. Get a reference to your custom element so you can reference it in the web chat configuration. To get a reference, use whatever mechanism makes sense for the library you are using. For example, you can save the reference returned from document.createElement(), or you can use a query function to look up the element in the DOM. This example looks up the element using the ID we assigned to it:\n\nconst customElement = document.querySelector('WebChatContainer');\n3. In the web chat embed script, set the element property, specifying the reference to your custom element.\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE_ID\",\n\n\/\/ The important piece.\nelement: customElement,\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n4. Make sure that the main web chat window is hidden by default. You can do this in the onLoad event handler, after render has been called. You must also add handlers to listen for the window:open and window:close events so the customer can open and close the web chat after the page loads. In our example, we are using a CSS class called HideWebChat to do this (see the [full example](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/blob\/master\/integrations\/webchat\/examples\/custom-element\/client\/javascript-animation\/index.html) for the definition of this class):\n\nfunction onLoad(instance) {\ninstance.render();\ninstance.on({ type: 'window:close', handler: closeHandler });\ninstance.on({ type: 'window:open', handler: openHandler });\ninstance.elements.getMainWindow().addClassName('HideWebChat');","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-size-position"},{"document_id":"ibmcld_13724-31730-33173","score":11.9383490251,"text":"\n* [Using a custom prompt for speech synthesis](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-tbe-use)\n* [Managing custom prompts](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-tbe-custom-prompts)\n* [Managing speaker models](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-tbe-speaker-models)\n\n\n\nNew Tune be Example methods\n: The service includes eight new methods for working with the Tune by Example feature. The descriptions of the new methods that follow provide links to their entries in the API & SDK reference. You might need to select the Curl tab of the reference to see the new methods.\n\n\n\n* The service includes four methods for working with custom prompts:\n\n\n\n* [Add a custom prompt](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech\/text-to-speechaddcustomprompt): POST \/v1\/customizations\/{customization_id}\/prompts\/{prompt_id}\n* [List custom prompts](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech\/text-to-speechlistcustomprompts): GET \/v1\/customizations\/{customization_id}\/prompts\n* [Get a custom prompt](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech\/text-to-speechgetcustomprompt): GET \/v1\/customizations\/{customization_id}\/prompts\/{prompt_id}\n* [Delete a custom prompt](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech\/text-to-speechdeletecustomprompt): DELETE \/v1\/customizations\/{customization_id}\/prompts\/{prompt_id}\n\n\n\n* The service includes four methods for working with speaker models:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-release-notes"},{"document_id":"ibmcld_16380-7-2028","score":11.8546045394,"text":"\nTutorial: Customizing the size and position of the web chat \n\nThis tutorial shows how you can change the size and position of the web chat by rendering it in a custom element.\n\nFor a complete, working version of the example described in this tutorial, see [Custom elements for Watson Assistant web chat](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/custom-element).\n\nBy default, the web chat interface on your website is rendered in a host div element that is styled to appear in a fixed location on the page. If you want to change the size or position of the web chat, you can specify a custom element as the host location for the web chat. This host element is used as the location for both the main web chat interface and for the web chat launcher (unless you are using a custom launcher).\n\nWhen you use a custom element, you also take control of showing and hiding the web chat when it is opened or closed (such as when the customer clicks the launcher icon or the minimize button). This gives you the opportunity to apply additional effects, such as opening and closing animations. You can control showing and hiding the main window by using the [addClassName() and removeClassName()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodselements-get-main-window) functions.\n\nTo use a custom element, follow these steps:\n\n\n\n1. In your website code, define the custom element where you want the web chat to be rendered. There are many ways of doing this, depending on the framework you are using. A simple example is to define an empty HTML element with an ID:\n\n<div id=\"WebChatContainer\"><\/div>\n2. Get a reference to your custom element so you can reference it in the web chat configuration. To get a reference, use whatever mechanism makes sense for the library you are using. For example, you can save the reference returned from document.createElement(), or you can use a query function to look up the element in the DOM.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-size-position"},{"document_id":"ibmcld_16255-7734-9537","score":11.7033338782,"text":"\nUse the v1 \/logs method filter parameter to search an application log for specific user data. For example, to search for data specific to a customer_id that matches my_best_customer, the query might be:\n\ncurl -X GET -u \"apikey:3Df... ...Y7Pc9\" \"{url}\/v2\/assistants\/{assistant_id}\/logs?version=2020-04-01&filter=customer_id::my_best_customer\"\n\nwhere {url} is the appropriate URL for your instance. For more details, see [Service endpoint](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2service-endpoint).\n\nSee the [Filter query reference](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-filter-reference) for additional details.\n\n\n\n\n\n Deleting data \n\nTo delete any message log data associated with a specific user that your assistant might have stored, use the DELETE \/user_data v1 API method. Specify the customer ID of the user by passing a customer_id parameter with the request.\n\nOnly data that was added by using the POST \/message API endpoint with an associated customer ID can be deleted using this delete method. Data that was added by other methods cannot be deleted based on customer ID. For example, entities and intents that were added from customer conversations, cannot be deleted in this way. Personal Data is not supported for those methods.\n\nIMPORTANT: Specifying a customer_id will delete all messages with that customer_id that were received before the delete request, across your entire Watson Assistant instance, not just within one skill.\n\nAs an example, to delete any message data associated with a user that has the customer ID abc from your Watson Assistant instance, send the following cURL command:\n\ncurl -X DELETE -u \"apikey:3Df... ...Y7Pc9\" \"{url}\/v2\/user_data?customer_id=abc&version=2020-04-01\"\n\nwhere {url} is the appropriate URL for your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-securing"},{"document_id":"ibmcld_03007-4839-6655","score":11.6282652243,"text":"\n* v2: [Information security](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-information-security)\n\n\n\n\n\n\n\n Querying user data \n\nUse the v1 \/logs method filter parameter to search an application log for specific user data. For example, to search for data specific to a customer_id that matches my_best_customer, the query might be:\n\ncurl -X GET -u \"apikey:3Df... ...Y7Pc9\" \"{url}\/v2\/assistants\/{assistant_id}\/logs?version=2020-04-01&filter=customer_id::my_best_customer\"\n\nwhere {url} is the appropriate URL for your instance. For more details, see [Service endpoint](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v2service-endpoint).\n\nSee the [Filter query reference](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-reference) for additional details.\n\n\n\n\n\n Deleting data \n\nTo delete any message log data associated with a specific user that your assistant might have stored, use the DELETE \/user_data v1 API method. Specify the customer ID of the user by passing a customer_id parameter with the request.\n\nOnly data that was added by using the POST \/message API endpoint with an associated customer ID can be deleted using this delete method. Data that was added by other methods cannot be deleted based on customer ID. For example, entities and intents that were added from customer conversations, cannot be deleted in this way. Personal Data is not supported for those methods.\n\nIMPORTANT: Specifying a customer_id will delete all messages with that customer_id that were received before the delete request, across your entire Watson Assistant instance, not just within one skill.\n\nAs an example, to delete any message data associated with a user that has the customer ID abc from your Watson Assistant instance, send the following cURL command:\n\ncurl -X DELETE -u \"apikey:3Df...","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-information-security"},{"document_id":"ibmcld_03109-7703-9557","score":11.6164929749,"text":"\nTo delete any query data that is associated with a specific customer, you must send a separate delete request directly to the Discovery service instance that is linked your the assistant. See the Discovery [information security](https:\/\/cloud.ibm.com\/docs\/discovery\/information-security?topic=discovery-information-security) topic for details.\n\n\n\n\n\n Querying user data \n\nUse the v1 \/logs method filter parameter to search an application log for specific user data. For example, to search for data specific to a customer_id that matches my_best_customer, the query might be:\n\ncurl -X GET -u \"apikey:3Df... ...Y7Pc9\" \"{url}\/v2\/assistants\/{assistant_id}\/logs?version=2020-04-01&filter=customer_id::my_best_customer\"\n\nwhere {url} is the appropriate URL for your instance. For more details, see [Service endpoint](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2service-endpoint).\n\nSee the [Filter query reference](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-filter-reference) for additional details.\n\n\n\n\n\n Deleting data \n\nTo delete any message log data associated with a specific user that your assistant might have stored, use the DELETE \/user_data v1 API method. Specify the customer ID of the user by passing a customer_id parameter with the request.\n\nOnly data that was added by using the POST \/message API endpoint with an associated customer ID can be deleted using this delete method. Data that was added by other methods cannot be deleted based on customer ID. For example, entities and intents that were added from customer conversations, cannot be deleted in this way. Personal Data is not supported for those methods.\n\nIMPORTANT: Specifying a customer_id will delete all messages with that customer_id that were received before the delete request, across your entire Watson Assistant instance, not just within one skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-securing"},{"document_id":"ibmcld_12422-16047-17386","score":11.6163530758,"text":"\n\"service_id\":\"iam-ServiceId-c0c7cfa4-b24e-4917-ad74-278f2fee5ba0\",\n\"secret_type\": \"iam_credentials\",\n\"secret_group_id\": \"bfc0a4a9-3d58-4fda-945b-76756af516aa\",\n\"labels\": [\n\"dev\",\n\"us-south\"\n],\n\"ttl\": \"30m\",\n\"service_id\": \"ServiceId-c0c7cfa4-b24e-4917-ad74-278f2fee5ba0,\n\"reuse_api_key\": false,\n\"custom_metadata\": {\n\"metadata_custom_key\": \"metadata_custom_value\"\n},\n\"version_custom_metadata\": {\n\"custom_version_key\": \"custom_version_value\"\n}\n}' \"https:\/\/{instance_ID}.{region}.secrets-manager.appdomain.cloud\/api\/v2\/secrets\"\n\nA successful request returns the ID value of the secret, along with other metadata. For more information, check out the [API reference](https:\/\/cloud.ibm.com\/apidocs\/secrets-manager\/secrets-manager-v2).\n\n\n\n\n\n\n\n Creating IAM credentials with Terraform \n\nYou can create IAM credentials programmatically by using Terraform for Secrets Manager.\n\nYou must add a depends_on Terraform meta-argument and refer it to your IAM configuration resource. The depends_on meta-argument instructs Terraform to complete all actions on the IAM configuration before you perform actions on the IAM credentials secrets.\n\nThe following example shows a configuration that you can use to create IAM credentials.\n\nresource \"ibm_sm_iam_credentials_secret\" \"test_iam_credentials_secret\" {\ninstance_id = local.instance_id\nregion = local.region","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials"},{"document_id":"ibmcld_12428-16073-17412","score":11.6163530758,"text":"\n\"service_id\":\"iam-ServiceId-c0c7cfa4-b24e-4917-ad74-278f2fee5ba0\",\n\"secret_type\": \"iam_credentials\",\n\"secret_group_id\": \"bfc0a4a9-3d58-4fda-945b-76756af516aa\",\n\"labels\": [\n\"dev\",\n\"us-south\"\n],\n\"ttl\": \"30m\",\n\"service_id\": \"ServiceId-c0c7cfa4-b24e-4917-ad74-278f2fee5ba0,\n\"reuse_api_key\": false,\n\"custom_metadata\": {\n\"metadata_custom_key\": \"metadata_custom_value\"\n},\n\"version_custom_metadata\": {\n\"custom_version_key\": \"custom_version_value\"\n}\n}' \"https:\/\/{instance_ID}.{region}.secrets-manager.appdomain.cloud\/api\/v2\/secrets\"\n\nA successful request returns the ID value of the secret, along with other metadata. For more information, check out the [API reference](https:\/\/cloud.ibm.com\/apidocs\/secrets-manager\/secrets-manager-v2).\n\n\n\n\n\n\n\n Creating IAM credentials with Terraform \n\nYou can create IAM credentials programmatically by using Terraform for Secrets Manager.\n\nYou must add a depends_on Terraform meta-argument and refer it to your IAM configuration resource. The depends_on meta-argument instructs Terraform to complete all actions on the IAM configuration before you perform actions on the IAM credentials secrets.\n\nThe following example shows a configuration that you can use to create IAM credentials.\n\nresource \"ibm_sm_iam_credentials_secret\" \"test_iam_credentials_secret\" {\ninstance_id = local.instance_id\nregion = local.region","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials&interface=ui"},{"document_id":"ibmcld_15256-1470-3770","score":11.4059325135,"text":"\n* Must be an x86 image\n* Can't be encrypted\n* Can't be used with a bare metal profile\n* Can exist in only one version of one catalog product offering in one private catalog at a time\n* Must be in available status\n\n\n\n\n\n\n\n Using cross-account image references in a private catalog in the UI \n\nInstances you provision belong to your account. Images shared to your account through a private catalog might belong to other accounts. When you provision an instance from an image that belongs to another account or from an instance template that specifies such an image, the image still belongs to the other account even though the instance belongs to your account. A reference to such an image might exist in details of the instance and related resources. For example, details about its boot volume and any snapshot that was created from that boot volume might reference that image. Regardless of your authorizations, you can't access the referenced image by its ID or CRN and attempts fail as if the image does not exist.\n\nAdditionally, it is possible that the referenced image might have the same name as a custom image in your account. But these image names are for two different images in two different accounts. The ID and CRN each uniquely identifies an image across IBM Cloud\u00ae. To avoid possible retrieval or use of the wrong image, when you cut-and-paste an image\u2019s identity outside of the UI, use its ID or CRN, rather than its name.\n\n\n\n\n\n Using cross-account image references in a private catalog in the CLI \n\nInstances you provision belong to your account. Images shared to your account through a private catalog might belong to other accounts. When you provision an instance from an image that belongs to another account or from an instance template that specifies such an image, the image still belongs to the other account even though the instance belongs to your account. A reference to such an image might exist in details of the instance and related resources. For example, details about its boot volume and any snapshot that was created from that boot volume might reference that image. Regardless of your authorizations, you can't access this type of custom image by its ID and attempts fail as if the image does not exist.\n\nImage references are used in a few different places in the CLI.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-custom-image-cloud-private-catalog"},{"document_id":"ibmcld_10161-1400-3037","score":11.151485745,"text":"\nWhen you grant the supplemental group ID read and write access to the file storage, any non-root user that belongs to the group ID, including your pod, is granted access to the file storage.\n\nYou can use one of the provided [gid storage classes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-file_storagefile_storageclass_reference) or create a custom storage class to define your own supplemental group ID.\n\nAllocating a supplemental group ID for a non-root user of a file storage device is supported for single zone clusters only, and can't be used in multizone clusters.\n\n\n\n1. Select one of the [provided gid storage classes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-file_storagefile_storageclass_reference) to assign the default group ID 65531 to your non-root user that you want to read and write to your file storage. If you want to assign a custom group ID, create a YAML file for a customized storage class. In your customized storage class YAML file, include the gidAllocate: \"true\" parameter and define the group ID in the gidFixed parameter.\n\nExample storage classes for assigning the default group ID 65531.\n\n\n\n* ibmc-file-bronze-gid\n* ibmc-file-silver-gid\n* ibmc-file-gold-gid\n\n\n\nExample customized storage class to specify a different group ID.\n\napiVersion: storage.k8s.io\/v1beta1\nkind: StorageClass\nmetadata:\nname: ibmc-file-bronze-gid-custom\nlabels:\nkubernetes.io\/cluster-service: \"true\"\nprovisioner: ibm.io\/ibmc-file\nparameters:\ntype: \"Endurance\"\niopsPerGB: \"2\"\nsizeRange: \"[1-12000]Gi\"\nmountOptions: nfsvers=4.1,hard\nbillingType: \"hourly\"\nreclaimPolicy: \"Delete\"\nclassVersion: \"2\"\ngidAllocate: \"true\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_storage_nonroot"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16288-1733-3996","score":24.1925840067,"text":"\nIt's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call. This 503 response can then be used by the SIP trunking provider to reroute the call to another region. If you want to take advantage of this capability, open a service ticket against the Watson Assistant service instance that requires disaster recovery.\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by going to the Advanced options tab in the phone integration settings, and selecting one or both of the following options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Applying advanced SIP trunk configuration settings \n\nTo configure how your assistant interacts with a SIP trunk from an external provider, go to the SIP trunk tab in the phone integration settings, and update the following options in the SIP trunking integration section:\n\n\n\n* SIP INVITE headers to extract: List the headers that you want your assistant to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_03158-8929-11062","score":23.1881453771,"text":"\nFor more information, see [Configuring backup support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-transfer-service).\n* Call failure message: Add the message to say to a caller before you transfer them to a human agent.\n\n\n\nIf, after you transfer the caller to a human agent, the connection to the human agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message to stream to callers if the transfer to a human agent fails. The message can be up to 1,024 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after sharing the failure message. This option is enabled by default. If disabled, when a call transfer fails, your assistant can disconnect or process a different dialog node.\n\n\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by selecting one or both of the following configuration options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Apply advanced SIP trunk configuration settings \n\n\n\n* SIP INVITE headers to extract: List headers that you want to use in your dialog.\n\nThe SIP request often sends INVITE headers with information about the request that is used by the SIP network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_16291-1353-3298","score":21.4236984704,"text":"\nClick Users, and then locate and click the user account you want to use for the integration.\n4. Click the Access Keys tab.\n5. Click Generate New Access Key.\n6. Click Show Secret Key, and copy the secret key to a secure location.\n\nYou cannot retrieve the secret key again after you complete the next step and Save. You must generate a new key if the current one is lost or forgotten.\n7. Click Save.\n\n\n\n\n\n\n\n Set up the integration \n\nTo complete setup, you must have an assistant ready to deploy, your NICE CXone access keys, and phone numbers allocated for this integration.\n\nTo integrate your assistant with NICE CXone:\n\n\n\n1. In the Integrations section on the main page for your assistant under Essential Channels, you will see a tile for Phone.\n2. On the Phone tile, click Add.\n3. On the pop-up window, click Add again.\n4. Select NICE CXone on the Select contact center page.\n\nClick Next.\n5. On the Connect to contact center page, specify the following values: - the Authentication URL from NICE CXone - the API URL, which is the Admin API endpoint from NICE CXone - the Access key ID - the Access key secret\n\nClick Test connection to verify the credentials.\n\nClick Next.\n6. On the Phone number page, enter a phone number you allocated for the NICE CXone integration. You can add more phone numbers later.\n\nClick Next.\n7. On the Speech to Text page, select the instance of the Speech to Text service you want to use.\n\n\n\n* If you have existing Speech to Text instances, select the instance you want to use from the list.\n* If you do not have any existing Speech to Text instances, click Create new instance to create a new Plus or Enterprise instance.\n\n\n\n8. In the Choose your Speech to Text language model field, select the language you want to use.\n\nThe list of language models is automatically filtered to use the same language as your assistant. To see all language models, toggle the Filter models based on assistant language switch to Off.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone"},{"document_id":"ibmcld_03179-4-1759","score":21.2968955564,"text":"\nThis documentation for the classic Watson Assistant experience has moved. For the most up-to-date version, see [Integrating with WhatsApp](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-whatsapp). To see all documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Integrating with WhatsApp \n\nIntegrate with WhatsApp messaging so your assistant can exchange messages with your customers where they are.\n\nMany customers use WhatsApp because it provides fast, simple, secure messaging for free, and is available on phones all over the world. WhatsApp uses the phone Internet connection to send messages so customers can avoid SMS fees.\n\nThis integration creates a connection between your assistant and WhatsApp by using Twilio as a provider.\n\n\n\n Before you begin \n\nIf you don't have one, set up a Twilio messaging account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https:\/\/www.twilio.com\/).\n2. Create an account.\n3. From the All Products and Services menu ![Twilio All products and services icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/twilio-products.png), click Phone numbers.\n4. Follow the instructions to get a phone number.\n\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp. \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-whatsapp"},{"document_id":"ibmcld_16297-7-1893","score":20.7839994075,"text":"\nIntegrating with WhatsApp \n\nIBM Cloud\n\nIntegrate with WhatsApp messaging so your assistant can exchange messages with your customers where they are.\n\nMany customers use WhatsApp because it provides fast, simple, secure messaging for free, and is available on phones all over the world. WhatsApp uses the phone Internet connection to send messages so customers can avoid SMS fees.\n\nThis integration creates a connection between your assistant and WhatsApp by using Twilio as a provider.\n\n\n\n Before you begin \n\nIf you don't have one, set up a Twilio messaging account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https:\/\/www.twilio.com\/).\n2. Create an account.\n3. From the Develop tab, click Phone numbers.\n4. Follow the instructions to get a phone number.\n\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\nKeep the Twilio web page open in a web browser tab so you can refer to it again later.\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1. To register, go to the [Facebook Business Manager](https:\/\/business.facebook.com\/overview) website, and click Create account. Follow the instructions to create an account.\n2. Get your Facebook Business Manager ID. In [Settings](https:\/\/business.facebook.com\/settings), click the Business info tab. The Facebook Business Manager ID is at the top of the page.\n3. Submit the Request to enable your Twilio numbers for WhatsApp form from the [Twilio API for WhatsApp](https:\/\/www.twilio.com\/whatsapp\/request-access) web page.\n\nTips for specifying the following values:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-whatsapp"},{"document_id":"ibmcld_03158-4-2042","score":20.1060010793,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Integrating with phone ![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/plus.png) \n\nBy adding the phone integration to your assistant, you can make your assistant available to customers over the phone.\n\nWhen you add the phone integration to your assistant, you can automatically generate a working phone number that is automatically connected to your assistant. Or, if you prefer, you can connect the assistant to your existing infrastructure by configuring an existing Session Initiation Protocol (SIP) trunk.\n\nA SIP trunk is equivalent to an analog telephone line, except it uses Voice over Internet Protocol (VoIP) to transmit voice data and can support multiple concurrent calls. The trunk can connect to the public switched telephone network (PSTN) or your company's on-premises private branch exchange (PBX). If you choose to generate a free phone number for your assistant, a SIP trunk is automatically provisioned from IntelePeer. You can also choose to use an existing SIP trunk from a provider such as IntelePeer, Genesys, or Twilio.\n\nGenerating a free phone number is available only with new phone integrations. If you have an existing phone integration and you want to switch to a free phone number, you must delete the existing integration and create a new one.\n\nWhen your customer makes a phone call using the telephone number connected to your assistant, the phone integration answers. The integration converts output from your assistant into voice audio by using the IBM Watson\u00ae Text to Speech service. The audio is sent to the telephone network through the SIP trunk. When the customer replies, the voice input is converted into text by using the IBM Watson\u00ae Speech to Text service.\n\nThis feature is available only to Plus or Enterprise plan users.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_03158-2940-4987","score":19.9615985109,"text":"\nIn the Integrations section on the main page for your assistant, click Add integration.\n2. On the Add integration page, click Phone.\n3. Click Create.\n4. Choose whether you want to generate a free phone number for your assistant or connect to an existing SIP trunk:\n\n\n\n* To generate a free phone number for your assistant, click Generate a free phone number.\n\nGenerating a free phone number is supported only for Watson Assistant instances in the Dallas and Washington DC data centers.\n* To use an existing phone number you have already configured with a [SIP trunk provider](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-sip-providers), click Use an existing phone number with an external provider.\n\n\n\nClick Next.\n5. If you are using an existing phone number, follow the instructions to configure the SIP trunk. (If you are generating a free phone number, skip this step).\n\n\n\n1. On the Bring your own SIP trunk page, copy the SIP URI and assign it to your SIP trunk. Click Next.\n2. On the Phone number page, specify the phone number of the SIP trunk. Specify the number by using the international phone number format: +1 958 555 0123. Do not surround the area code with parentheses.\n\n\n\nCurrently, only one primary phone number can be added during initial setup of the phone integration. You can add more phone numbers in the phone integration settings later.\n\nClick Next.\n6. On the Speech to Text page, select the instance of the Speech to Text service you want to use for the phone integration.\n\n\n\n* If you have existing Speech to Text instances, select the instance you want to use from the list.\n* If you do not have any existing Speech to Text instances, click Create new instance to create a new Plus instance.\n\n\n\n7. In the Choose your Speech to Text language model field, select the language model you want to use.\n\nThe list of language models is automatically filtered to use the same language as your assistant. To see all language models, toggle the Filter models based on assistant language switch to Off.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_16280-3111-5196","score":19.8473617013,"text":"\nExtensions are not required for an assistant, but they are recommended.\n\n\n\nWhen you add a channel to your assistant, at least two instances of the channel are created. One instance of the channel is connected to the draft environment and the other instance is connected to the live environment. If you are using [multiple environments](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-multiple-environments), instances of the channel are added to your extra environments. To connect your assistant to a new channel, go to the Integrations catalog. For more information about adding integrations to your assistant, see [Adding integrations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-integration-add).\n\nAlthough a channel always exists in environments, you can configure your integration separately in each environment. For example, this allows you to test integrations on your draft environment before you go live with any integration configuration. After you add an integration, you must set it up to use it with your assistant. The Finish setup icon appears on any integration that you added but didn't yet set up.\n\nYou have multiple options for deploying your assistant, depending on how you want your customers to interact with it. In most cases, an assistant is deployed by using one of the following integrations:\n\n\n\n* [Web chat integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat): The web chat integration provides a secure and highly customizable widget you can add to your website. You can configure how and where the web chat widget appears, and you can use theming to align it with your branding and website design. If a customer needs help from a person, the web chat integration can transfer the conversation to an agent.\n* [Phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone): The phone integration enables your assistant to converse with customers on the phone by using the IBM Watson Text to Speech and Speech to Text services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-assistant"},{"document_id":"ibmcld_16288-7-2218","score":19.8245401104,"text":"\nPhone integration configuration \n\nIBM Cloud\n\nAfter you have set up the phone integration for your assistant, you can modify the phone integration settings to customize the call behavior.\n\n\n\n Handling call and transfer failures \n\nYou can configure the phone integration to transfer the caller to a human agent if the phone connection fails for any reason. To transfer the caller to a human agent automatically, go to the Advanced tab in the phone integration settings, and make the following configuration selections:\n\n\n\n* SIP target when a call fails: Add the SIP endpoint for your support agent service. Specify a SIP or telephone URI for a general call queue that can redirect requests to other queues. For more information, see [Configuring backup call center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-transfer-service).\n* Call failure message: Add the message you want the assistant to say to a caller before it transfers the call to a human agent.\n\n\n\nIf, after you transfer the call to a human, the connection to a live agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message you want the assistant to say to a caller if transfer to a live agent fails. The message can be up to 150 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after the failure message. This option is enabled by default. If this option is disabled, when a call transfer fails, your assistant can disconnect or process a different action.\n\nIf you choose to leave a call connected despite a transfer failure, Watson Assistant will initiate a new turn to determine the next step. It's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_03160-10290-11610","score":19.8035759816,"text":"\nIn the JSON editor, add a [connect_to_agent response](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-phone-context), specifying your phone number as the sip.uri (replace {phone_number} with the phone number of your SIP trunk):\n\n\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"connect_to_agent\",\n\"transfer_info\": {\n\"target\": {\n\"service_desk\": {\n\"sip\": {\n\"uri\": \"sip:+{phone_number}@flex.twilio.com\",\n\"transfer_headers_send_method\": \"refer_to_header\"\n}\n}\n}\n},\n\"agent_available\": {\n\"message\": \"Ok, I'm transferring you to an agent\"\n},\n\"agent_unavailable\": {\n\"message\": \"\"\n}\n}\n]\n}\n}\nShow more\n\nNote that this example does not show how to use the context passed from Watson Assistant to Twilio Flex. You can reference the User-to-User information from within the Twilio Flex flow as follows:\n\n{\n\"context\": {\n\"widgets\": {\n\"redirect_1\": {\n\"User-to-User\": \"value\",\n}\n}\n}\n}\n\nwhere redirect_1 is the name of your redirect widget. For example, if you set up multiple queues, you might want to use a Twilio Split widget to pick a queue based on the returned context.\n\n\n\n\n\n Test your assistant \n\nYour assistant should now be able to answer phone calls to your phone number and transfer calls back to your Twilio Flex flow. To test your assistant:\n\n\n\n1. Call your phone number. When the assistant responds, ask for an agent.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone-flex"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16288-6287-8401","score":23.5528588884,"text":"\nWhen you use the phone integration as the first line of assistance for customers, it's a good idea to have a live agent backup available. You can design your assistant to transfer a call to a human in case the phone connection fails, or if a user asks to speak to someone.\n\nYour company might already have one or more phone numbers that connect to an automatic call dispatcher (ACD) that can queue callers until an appropriate agent is available. If not, choose a call center service to use as your backup.\n\nA conversation cannot be transferred from one integration type to another. For example, if you use the web chat integration with service desk support, you cannot transfer a phone call to the service desk that is set up for the web chat.\n\nYou must provide the call center SIP URI for the call center service you use. You must specify this information in your assistant when you enable a call transfer from a dialog node or action step. For more information, see [Transferring a call to a live agent](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer).\n\n\n\n\n\n Optimize your actions for phone interaction \n\nFor the best customer experience, design your dialog with the capabilities of the phone integration in mind:\n\n\n\n* Do not include HTML elements in your action responses. To add formatting, use Markdown. For more information, see [Formatting responses](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-respondrespond-formatting).\n* You can use a search extension to include search results in actions that the phone integration will read. When search results are returned, the phone integration reads the introductory message (for example, I found this information that might be helpful), and then the body of only the first search result.\n\nThe entire search response (meaning the introductory message plus the body of the first search result) must be less than 5,000 characters long or the response will not be read at all. Be sure to test the search results that are returned and curate the data collection that you use as necessary.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_16288-1733-3996","score":20.9156043876,"text":"\nIt's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call. This 503 response can then be used by the SIP trunking provider to reroute the call to another region. If you want to take advantage of this capability, open a service ticket against the Watson Assistant service instance that requires disaster recovery.\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by going to the Advanced options tab in the phone integration settings, and selecting one or both of the following options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Applying advanced SIP trunk configuration settings \n\nTo configure how your assistant interacts with a SIP trunk from an external provider, go to the SIP trunk tab in the phone integration settings, and update the following options in the SIP trunking integration section:\n\n\n\n* SIP INVITE headers to extract: List the headers that you want your assistant to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_03165-4477-6547","score":20.5174250214,"text":"\nFrom the All Products and Services menu, click Phone Numbers.\n9. From the Active Numbers page, click one of your phone numbers. Scroll to the Messaging section, and then find the Webhook field that defines what to do when a message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n10. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n11. Click Save and exit.\n\n\n\nTo watch a video that walks through the setup process, see [Phone and SMS Integration](https:\/\/community.ibm.com\/community\/user\/watsonapps\/viewdocument\/phone-and-sms-integration?CommunityKey=7a3dc5ba-3018-452d-9a43-a49dc6819633&tab=librarydocuments) in the IBM Watson Apps Community.\n\nIf you want your assistant to be able to switch between voice and text during a customer interaction, enable both the phone and text messaging integrations. The integrations do not need to use the same third-party service provider. For more information, see [Integrating with phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone).\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your dialog for messaging \n\nFor the best customer experience, design your dialog with the capabilities of the Twilio integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* You can send media files or even documents in your response. These files can be intercepted and processed by a configured premessage webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-sms"},{"document_id":"ibmcld_03216-18448-20174","score":19.7922785644,"text":"\ndtmf \n\nSends commands to the phone integration to control input or output using dual-tone multi-frequency (DTMF) signals. (DTMF is a protocol used to transmit the tones that are generated when a user presses keys on a push-button phone.)\n\n\n\n Fields \n\n\n\n Name Type Description Required? \n\n response_type string dtmf Y \n command_info object Information specifying the DTMF command to send to the phone integration. Y \n command_info.type string The DTMF command to send (collect, disable_barge_in, enable_barge_in, or send). Y \n command_info.parameters object See [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions) N \n\n\n\nThe command_info.type field can specify any of the following supported commands:\n\n\n\n* collect: Collects DTMF keypad input.\n* disable_barge_in: Disables DTMF barge-in so that playback from the phone integration is not interrupted when the customer presses a key.\n* enable_barge_in: Enables DTMF barge-in so that the customer can interrupt playback from the phone integration by pressing a key.\n* send: Sends DTMF signals.\n\n\n\nFor detailed information about how to use each of these commands, see [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions).\n\n\n\n\n\n Example \n\nThis example shows the dtmf response type with the collect command, used to collect DTMF input. For more information, including examples of other DTMF commands, see [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions).\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"dtmf\",\n\"command_info\": {\n\"type\": \"collect\",\n\"parameters\": {\n\"termination_key\": \"\",\n\"count\": 16,\n\"ignore_speech\": true\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-responses-json"},{"document_id":"ibmcld_16337-10301-11908","score":19.5150547301,"text":"\nThe command_info.type field can specify any of the following supported commands:\n\n\n\n* collect: Collects DTMF keypad input.\n* disable_barge_in: Disables DTMF barge-in so that playback from the phone integration is not interrupted when the customer presses a key.\n* enable_barge_in: Enables DTMF barge-in so that the customer can interrupt playback from the phone integration by pressing a key.\n* send: Sends DTMF signals.\n\n\n\nFor detailed information about how to use each of these commands, see [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions).\n\n\n\n\n\n Example \n\nThis example shows the dtmf response type with the collect command, used to collect DTMF input. For more information, including examples of other DTMF commands, see [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions).\n\n{\n\"generic\": [\n{\n\"response_type\": \"dtmf\",\n\"command_info\": {\n\"type\": \"collect\",\n\"parameters\": {\n\"termination_key\": \"\",\n\"count\": 16,\n\"ignore_speech\": true\n}\n},\n\"channels\":\n{\n\"channel\": \"voice_telephony\"\n}\n]\n}\n]\n}\nShow more\n\n\n\n\n\n\n\n end_session \n\nSends a command to the channel ending the session. This response type instructs the phone integration to hang up the call.\n\n\n\n Integration channel support \n\n\n\n Phone SMS \n\n ![Yes](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/checkmark-icon.svg) \n\n\n\n\n\n* The SMS integration supports ending a session by using the terminateSession action command.\n\n\n\n\n\n\n\n Fields \n\n\n\n Name Type Description Required?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-response-types-reference"},{"document_id":"ibmcld_16321-7-1807","score":19.2179022597,"text":"\nHandling phone interactions \n\nIf your assistant uses the phone integration, you can use various response types to customize the behavior of the integration or manage the flow of conversations that your assistant has with customers over the telephone.\n\nYou can use response types to perform the following phone-specific actions:\n\n\n\n* [Apply advanced settings to the Speech to Text service](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-speech-advanced)\n* [Apply advanced settings to the Text to Speech service](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-text-advanced)\n* [Transfer a call to a live agent](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer)\n* [Play hold music or a voice recording](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-hold-music)\n* [Enable keypad entry](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-dtmf)\n* [Transfer the conversation to the web chat integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer-channel)\n* [End the call](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-hangup)\n* [Send a text message during a phone conversation](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-sms)\n\n\n\nIn some cases, you might want to combine response types to perform multiple actions. For example, you might want to implement two-factor authentication by requesting phone keypad entry and sending a text message from the same action step. For more information, see the following:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_03179-4-1759","score":18.9514284287,"text":"\nThis documentation for the classic Watson Assistant experience has moved. For the most up-to-date version, see [Integrating with WhatsApp](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-whatsapp). To see all documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Integrating with WhatsApp \n\nIntegrate with WhatsApp messaging so your assistant can exchange messages with your customers where they are.\n\nMany customers use WhatsApp because it provides fast, simple, secure messaging for free, and is available on phones all over the world. WhatsApp uses the phone Internet connection to send messages so customers can avoid SMS fees.\n\nThis integration creates a connection between your assistant and WhatsApp by using Twilio as a provider.\n\n\n\n Before you begin \n\nIf you don't have one, set up a Twilio messaging account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https:\/\/www.twilio.com\/).\n2. Create an account.\n3. From the All Products and Services menu ![Twilio All products and services icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/twilio-products.png), click Phone numbers.\n4. Follow the instructions to get a phone number.\n\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp. \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-whatsapp"},{"document_id":"ibmcld_16294-8240-10414","score":18.9219573186,"text":"\nOnce the phone number has been enabled for SMS, you will see a webhook icon beside the number.\n\nPaste the value that you copied from the Webhook URI field into it.\n15. Click Save.\n16. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n\n\n\n\n\n\n\n\n\n SMS Advanced configuration options \n\nThe Advanced options tab is available after you set up the SMS integration. Click the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your actions for messaging \n\nFor the best customer experience, design your actions with the capabilities of the SMS integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* The SMS integration does not support chat transfers that are initiated with the connect_to_agent response type.\n* Image, Audio, Video response types allow sending a message containing media. A title and description are sent along with the attachment. Note that depending on the carrier and device of the end user these messages may not be successfully received. For a list of the supported content types for Twilio, see [Twilio: Accepted Content Types for Media](https:\/\/www.twilio.com\/docs\/sms\/accepted-mime-types).\n\nFor more information on these response types, see [Response types reference](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-response-types-reference).\n\n\n\nIf you want to use the same action for an assistant that you deploy to many different platforms, add custom responses per integration type. You can add a conditioned response that tells the assistant to show the response only when the SMS integration is being used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-sms"},{"document_id":"ibmcld_16321-1374-3426","score":18.8144813793,"text":"\n* [Send a text message during a phone conversation](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-sms)\n\n\n\nIn some cases, you might want to combine response types to perform multiple actions. For example, you might want to implement two-factor authentication by requesting phone keypad entry and sending a text message from the same action step. For more information, see the following:\n\n\n\n* [Define a sequence of phone commands](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-sequence)\n\n\n\nYou can also perform the following phone-specific actions:\n\n\n\n* [Inject custom values into CDR log events](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-cdr-custom-data)\n* [Access phone integration context variables from your action](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-access-context-variables)\n\n\n\nFor reference information about response types, see [Response types reference](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-response-types-reference).\n\n\n\n Adding phone-specific responses to your assistant \n\nTo initiate a voice-specific interaction from a an action step, add a response within the generic array using the appropriate response type. For more information about using the JSON editor to add responses, see [Defining responses using the JSON editor](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-assistant-responses-json).\n\n\n\n\n\n Applying advanced settings to the Speech to Text service \n\nUse the speech_to_text response type to send configuration commands to the Speech to Text service instance used by the phone integration. By sending a speech_to_text response from an action step, you can dynamically change the Speech to Text configuration during a conversation.\n\nBy default, any Speech to Text configuration changes you make persist for the remainder of the conversation, or until you update them again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_16288-16580-18088","score":18.7315942764,"text":"\nA customer calls the customer support phone number that is managed by your Session Initiation Protocol (SIP) trunk provider.\n2. The SIP trunk service sends a SIP INVITE HTTP request to your assistant's phone integration to establish a connection.\n3. The phone integration connects to the speech services that are required to support the interaction.\n4. After the services are ready, the connection is established, and audio is sent over the Real-time Transport Protocol (RTP).\n\nRTP is a network protocol for delivering audio and video over IP networks.\n5. The greeting action of the assistant is processed. The response text is sent to the Text to Speech service to be converted to audio and the audio is sent to the caller.\n6. When the customer says something, the audio is converted to text by the Speech to Text service and is sent to your assistant for evaluation.\n7. The assistant processes the input and calculates the best response. The response text from the assistant is sent to the Text to Speech service to be converted to audio and the audio is sent back to the caller over the existing connection.\n8. If the caller asks to speak to a person, the assistant can transfer the person to a call center. A SIP REFER request is sent to the SIP trunk provider so it can transfer the call to the call center SIP URI that is specified in the dialog node where the transfer action is configured.\n9. When one of the participants of the call hangs up, a SIP BYE HTTP request is sent to the other participant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16287-7751-9832","score":30.1072325584,"text":"\nHowever, provisioning the new number might take several minutes.\n\n\n\n\n\n Adding more phone numbers \n\nIf you are using existing phone numbers you configured via a SIP trunk provider, you can add multiple numbers to the same phone integration.\n\nIf you generated a free phone number, you cannot add more numbers.\n\nTo add more phone numbers:\n\n\n\n1. In the phone integration settings, go to the Phone number tab.\n2. Use one of the following methods:\n\n\n\n* To add phone numbers one by one, click Add phone number in the table, and enter the phone number along with an optional description. Click the Add button to save the number.\n* To import a set of phone numbers that are stored in a comma-separated values (CSV) file, click the Upload a CSV file icon (![Add phone number][images\/phone-integ-import-number.png]), and then find the CSV file that contains the list of phone numbers.\n\nThe phone numbers you upload will replace any existing numbers in the table.\n\n\n\n\n\n\n\n\n\n Setting up live agent escalation \n\nIf you want your assistant to be able to transfer a conversation to a live agent, you can connect your phone integration to a contact center. For more information, see instructions for the supported platform:\n\n\n\n* [Genesys](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-genesys)\n* [Twilio Flex](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-flex)\n\n\n\n\n\n\n\n Phone integration limits \n\nAny speech service charges incurred by the phone integration are included as Voice add-on charges in your Watson Assistant service plan usage. The Voice add-on use is charged separately and in addition to your service plan charges.\n\nPlan usage is measured based on the number of monthly active users, where a user is identified by the caller's unique phone number. An MD5 hash is applied to the phone number and the 128-bit hash value is used for billing purposes.\n\nThe number of concurrent calls that your assistant can participate in at one time depends on your plan type.\n\n\n\nPlan details\n\n Plan Concurrent calls \n\n Enterprise 1,000","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone"},{"document_id":"ibmcld_16471-91132-93270","score":28.2923017718,"text":"\n* [group by<group by list>]\n\nGroups the tuples that are produced from the same document by common values of a specified field. This clause is optional.\n* [order by<order by list>]\n\nOrders the output tuples that are produced by the select statement from each document. The order is based on the values of the order-by list, a comma-delimited list of expressions. This clause is optional.\n* [limit <maximum number of output tuples for each document>]\n\nLimits the number of output tuples for each document to the specified maximum. This clause is optional.\n\n\n\n\n\n\n\n Usage Notes \n\nThe semantics of the select statement are as follows:\n\n\n\n* Determine the input data (in tuples) by taking the Cartesian product of relations in the from list.\n* For each input tuple that is generated, filter it by applying the predicates in the (optional) where clause.\n* If the optional group by clause is present, group tuples that are produced from the same document by the values that are specified in the group-by list and compute the result of the aggregate functions within the select list.\n* Consolidate any overlapping tuples, according to the policy defined in the (optional) consolidation clause. If the optional order by clause is present, order these tuples by the values of the order-by list.\n* Compute all expressions within the select list on each tuple, and rename the columns as specified by the as clauses.\n* If the optional limit clause is present, limit the number of output tuples to the specified number of tuples for each document.\n\n\n\n\n\n\n\n Examples \n\nAn example of how to use the select statement is to extract phone numbers that match a pattern. Assume that the PhoneNumbers view that extracts phone numbers of the pattern XXX-XXX-XXXX for United States is already defined. This select statement evaluates the regular expression for the pattern 444-888-XXXX across the input text. The view has the output columns documentText and phoneNumber. In addition, the output is limited to the first occurrence of this phone number pattern that is identified per document.\n\ncreate view PhoneNumbersPattern1 as\nselect D.documentText, D.phoneNumber","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_03165-4477-6547","score":27.5992060242,"text":"\nFrom the All Products and Services menu, click Phone Numbers.\n9. From the Active Numbers page, click one of your phone numbers. Scroll to the Messaging section, and then find the Webhook field that defines what to do when a message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n10. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n11. Click Save and exit.\n\n\n\nTo watch a video that walks through the setup process, see [Phone and SMS Integration](https:\/\/community.ibm.com\/community\/user\/watsonapps\/viewdocument\/phone-and-sms-integration?CommunityKey=7a3dc5ba-3018-452d-9a43-a49dc6819633&tab=librarydocuments) in the IBM Watson Apps Community.\n\nIf you want your assistant to be able to switch between voice and text during a customer interaction, enable both the phone and text messaging integrations. The integrations do not need to use the same third-party service provider. For more information, see [Integrating with phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone).\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your dialog for messaging \n\nFor the best customer experience, design your dialog with the capabilities of the Twilio integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* You can send media files or even documents in your response. These files can be intercepted and processed by a configured premessage webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-sms"},{"document_id":"ibmcld_06959-8071-9767","score":27.3461794007,"text":"\n$0 Displays the matched text as-is. \n $n If your regular expression pattern contains groups, you can specify a group number to return the matched text from the pattern group only. For example, if your regular expression consists of 3 groups that define a US phone number pattern, such as (d{3})-(d{3})-(d{4}), and you want to return only the area code portion of the phone number, you can specify $1. If the matched text is 212-555-1234, then the facet value is displayed as 212. Only specify a group as the facet value for patterns that you know will return matches. \n {prefix-text}:$0 Adds hardcoded text in front of the facet name. You might want to use this option if you want to distinguish facets that are generated by this regular expression from facets that are similar but generated in some other way. For example, MyRegex:$0 results in a facet named MyRegex:212-555-1234. \n\n\n\n4. Click Save.\n\n\n\nTo import patterns, complete the following steps:\n\n\n\n1. Define the patterns that you want to add in a JSON file.\n\nThe pattern definition must use the following syntax:\n\n[\n{\n\"name\": \"US Phone number\",\n\"description\": \"US mobile phone number\",\n\"pattern\": \"(\\d{3})-(\\d{3})-(\\d{4})\",\n\"facetPath\": \".regex.usphonenumber\",\n\"facetValue\": \"$0\"\n}\n]\n\nKeep the following notes in mind:\n\n\n\n* The patterns must be defined in an array, even if you plan to define only one pattern.\n* Escape any backslash () characters with a backslash.\n* For more information about the facet value options, see the Regular expression facet value options table.\n\n\n\n2. Click Import, and then choose the JSON file where the patterns are defined.\n3. Click Save.\n\n\n\n\n\n Regular expression limits \n\n\n\nRegular expression plan limits","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-cm-custom-annotator"},{"document_id":"ibmcld_16471-92779-94574","score":27.3294792706,"text":"\nAssume that the PhoneNumbers view that extracts phone numbers of the pattern XXX-XXX-XXXX for United States is already defined. This select statement evaluates the regular expression for the pattern 444-888-XXXX across the input text. The view has the output columns documentText and phoneNumber. In addition, the output is limited to the first occurrence of this phone number pattern that is identified per document.\n\ncreate view PhoneNumbersPattern1 as\nselect D.documentText, D.phoneNumber\nfrom PhoneNumbers D\nwhere MatchesRegex(\/444-888-d{4}\/,D.phoneNumber)\nlimit 1;\n\nAnother example of how you can use the select statement is to find approximate mappings of people and their corresponding phone numbers. Assume that the view Person is already defined, and that it has the columns person and the view PhoneNumbers. This select statement evaluates the where clause to find text spans that contain a person mention followed by a phone number within 1 to 3 words or tokens. The input to this statement is represented by a join of the Person and PhoneNumbers views in the from list.\n\ncreate view PersonPhone as\nselect P1.documentText, P1.person, P2.phoneNumber, CombineSpans(P1.person,P2.phoneNumber) as personPhoneSpan\nfrom Person P1, PhoneNumbers P2\nwhere FollowsTok(P1.person,P2.phoneNumber,1,3);\n\nThe personPhoneSpan column will contain the matching spans that give the approximate person-phone mapping.\n\npersonPhoneSpan\nJohn : 433-999-1000\nMartha Mob 433-999-1001\n\n\n\n* The select list The select list in an AQL select or extract statement consists of a comma-delimited list of output expressions.\n* The from list The second part of a select or an extract statement in AQL is the from list. The from list is a comma-separated list that is the source of the tuples to be selected or extracted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_16287-2974-4988","score":26.5873632988,"text":"\nChoose whether to generate a free phone number for your assistant, integrate with your contact center, or connect to an existing SIP trunk:\n\n\n\n* To generate a free phone number for your assistant, click Generate a free phone number.\n\nGenerating a free phone number is supported only for Watson Assistant instances in the Dallas and Washington DC data centers.\n* To integrate with a [contact center](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone), click Integrate with your contact center.\n* To use an existing phone number you have already configured with a [SIP trunk provider](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-sip-providers), click Use an existing phone number with an external provider.\n\n\n\nClick Next.\n5. If you are integrating with a contact center, follow the instructions to configure the contact center. Skip this step if you are generating a free phone number.\n\n\n\n1. On the Select contact center page, select the tile of the connect center you would like to use.\n2. On the Connect to contact center page, enter the required information. There is a Test Connection button on the page to validate the connection. Click Next.\n\n\n\n6. If you are using an existing phone number, follow the instructions to configure the SIP trunk. Skip this step if you are generating a free phone number.\n\n\n\n1. On the Bring your own SIP trunk page, copy the SIP URI and assign it to your SIP trunk. Click Next.\n\n\n\n7. On the Phone number page (only for Integrate with your contact center and Use an existing phone number with an external provider), specify the phone number of the SIP trunk. Specify the number by using the international phone number format: +1 958 555 0123. Do not surround the area code with parentheses.\n\nCurrently, only one primary phone number can be added during initial setup of the phone integration. You can add more phone numbers in the phone integration settings later.\n\nClick Next.\n8.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone"},{"document_id":"ibmcld_03158-6114-8033","score":26.5724439154,"text":"\nThe list of voices is automatically filtered to use the same language as your assistant. To see all voices, toggle the Filter voices based on assistant language switch to Off.\n\nFor more information about voice options, and to listen to audio samples, see [Languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices) in the Text to Speech documentation.\n\nClick Next.\n\n\n\nAny speech service charges that are incurred by the phone integration are billed with the Watson Assistant service plan as voice add-on charges. After the instances are created, you can access them directly from the IBM Cloud dashboard. Any use of the speech instances that occurs outside of your assistant are charged separately as speech service usage costs.\n\nThe phone integration setup is now complete. On the Phone page, you can click the tabs to view or edit the phone integration.\n\nIf you chose to generate a free telephone number, your new number is displayed on the Phone number tab immediately. However, provisioning the new number so it is ready to use might take several minutes.\n\n\n\n\n\n Adding more phone numbers \n\nIf you are using existing phone numbers you configured using a SIP trunk provider, you can add multiple numbers to the same phone integration.\n\nIf you generated a free phone number, you cannot add more numbers.\n\nTo add more phone numbers:\n\n\n\n1. In the phone integration settings, go to the Phone number tab.\n2. Use one of the following methods to add phone numbers:\n\n\n\n* To add phone numbers one by one, type each number in the table, along with an optional description. Click the checkmark icon ![checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/phone-checkmark-save.png) to save each number.\n* To import a set of phone numbers that are stored in a comma-separated values (CSV) file, click the Upload a CSV file icon (!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_16471-51070-53175","score":26.3458983496,"text":"\n* Consolidate tuples that pass the predicates according to the optional consolidation clause, and add the resulting tuples to the output.\n* If the optional limit clause is present, limit the output to the specified number of tuples for each document.\n\n\n\nThe semantics of the from clause of an extract pattern statement are different from other forms of extract statements that do not have a pattern specification. If at least one of the views in the <from list> does not contain any tuples on a particular document, then the output of the extract statement is empty. This output is empty because the set of all combinations of tuples in the input views is empty.\n\nIn the special case of extract pattern statements, the from clause is a placeholder that declares the names of relations that are involved in the pattern specification. The semantics of the statement are driven only by the pattern specification. In particular, the output of the statement can be non-empty even when some of the input views are empty.\n\n\n\n\n\n Examples \n\nExample 1: Extracting phone numbers from a pre-defined view\n\nThis sample extract statement evaluates a regular expression for United States phone numbers across input text that is represented by the pre-defined view Document. The output is then restricted to the first three phone numbers that are identified per each document. Field names in the having clause refer to the aliases at the beginning of the extract statement.\n\ncreate view PhoneNumbers as\nextract\nD.text as documentText,\nregex \/d{3}-d{3}-d{4}\/ on D.text as phoneNumber\nfrom Document D\nhaving MatchesRegex(\/d{3}.\/, phoneNumber)\nlimit 3;\n\nExample 2: Extracting blocks of capitalized words\n\nIn this example, the extract statement identifies blocks of two to three capitalized words. In AQL, a block refers to a contiguous span of tokens, in this case two to three tokens. This example also uses a consolidation policy to exclude blocks that are contained within larger blocks from the output set of tuples.\n\ncreate view CapitalizedWord as\nextract\nregex \/[A-Z]\/\nwith flags 'CANON_EQ'\non 1 token in D.text\nas word","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_03158-2940-4987","score":26.3252882843,"text":"\nIn the Integrations section on the main page for your assistant, click Add integration.\n2. On the Add integration page, click Phone.\n3. Click Create.\n4. Choose whether you want to generate a free phone number for your assistant or connect to an existing SIP trunk:\n\n\n\n* To generate a free phone number for your assistant, click Generate a free phone number.\n\nGenerating a free phone number is supported only for Watson Assistant instances in the Dallas and Washington DC data centers.\n* To use an existing phone number you have already configured with a [SIP trunk provider](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-sip-providers), click Use an existing phone number with an external provider.\n\n\n\nClick Next.\n5. If you are using an existing phone number, follow the instructions to configure the SIP trunk. (If you are generating a free phone number, skip this step).\n\n\n\n1. On the Bring your own SIP trunk page, copy the SIP URI and assign it to your SIP trunk. Click Next.\n2. On the Phone number page, specify the phone number of the SIP trunk. Specify the number by using the international phone number format: +1 958 555 0123. Do not surround the area code with parentheses.\n\n\n\nCurrently, only one primary phone number can be added during initial setup of the phone integration. You can add more phone numbers in the phone integration settings later.\n\nClick Next.\n6. On the Speech to Text page, select the instance of the Speech to Text service you want to use for the phone integration.\n\n\n\n* If you have existing Speech to Text instances, select the instance you want to use from the list.\n* If you do not have any existing Speech to Text instances, click Create new instance to create a new Plus instance.\n\n\n\n7. In the Choose your Speech to Text language model field, select the language model you want to use.\n\nThe list of language models is automatically filtered to use the same language as your assistant. To see all language models, toggle the Filter models based on assistant language switch to Off.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_16289-2888-4673","score":26.0020243445,"text":"\nYou will need this value in a subsequent step.\n\n\n\n\n\n\n\n Configuring the phone number \n\n\n\n1. In the navigation menu, click the All Products & Services icon.\n2. Click Phone Numbers.\n3. Under Manage Numbers, configure the phone number you want your assistant to use. Select Buy a Number to buy a new number, or Port & Host to port an existing phone number.\n4. In the Active Numbers list, click the new phone number.\n5. Under Voice and Fax, configure the following settings:\n\n\n\n* For CONFIGURE WITH field, select Webhook, TwiML Bins, Functions, Studio, or Proxy.\n* For A CALL COMES IN, select Studio Flow. Select your flow from the drop-down list.\n* For PRIMARY HANDLER FAILS, select Studio Flow. Select your flow from the drop-down list.\n\n\n\n6. Go to the Watson Assistant user interface, open the phone integration settings for your assistant.\n7. In the Phone number field, type the phone number you configured in Flex Studio.\n8. Click Save and exit.\n\n\n\n\n\n\n\n Test your phone number \n\nYou can now test that your phone number is connected to your flow by triggering a Say\/Play widget in the Twilio Flex Flow editor.\n\n\n\n1. Drag a Say\/Play widget onto your flow canvas.\n2. Configure the Say\/Play widget with a simple phrase like I'm alive..\n3. Connect the Incoming call node on your Trigger widget to your Say\/Play widget.\n4. Call your phone number. You should hear your Twilio flow respond with your test phrase.\n5. Delete the Say\/Play widget and continue to the next step.\n6. If this test did not work as expected, double check your phone number configuration to make sure its attached to your flow.\n\n\n\n\n\n\n\n Creating a Twilio function to handle incoming calls \n\nNow we need to configure the call flow to direct inbound calls to the assistant using a Twilio function. Follow these steps:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-flex"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07839-0-1665","score":39.3442368436,"text":"\n\n\n\n\n\n\n  PS-7 - Third-party Personnel Security \n\n\n\n  Control requirements \n\nThe organization:\n\nPS-7 (a)\n:   Establishes personnel security requirements including security roles and responsibilities for third-party providers;\n\nPS-7 (b)\n:   Requires third-party providers to comply with personnel security policies and procedures established by the organization;\n\nPS-7 (c)\n:   Documents personnel security requirements;\n\nPS-7 (d)\n:   Requires third-party providers to notify [Assignment: organization-defined personnel or roles] of any personnel transfers or terminations of third-party personnel who possess organizational credentials and\/or badges, or who have information system privileges within [IBM Assignment: same day]; and\n\nPS-7 (e)\n:   Monitors provider compliance.\n\n\n\n\n\n  NIST supplemental guidance \n\nThird-party providers include, for example, service bureaus, contractors, and other organizations providing information system development, information technology services, outsourced applications, and network and security management. Organizations explicitly include personnel security requirements in acquisition-related documents. Third-party providers may have personnel working at organizational facilities with credentials, badges, or information system privileges issued by organizations. Notifications of third-party personnel changes ensure appropriate termination of privileges and credentials. Organizations define the transfers and terminations deemed reportable by security-related characteristics that include, for example, functions, roles, and nature of credentials\/privileges associated with individuals transferred or terminated.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ps-7"},{"document_id":"ibmcld_16288-10521-12298","score":35.0419441183,"text":"\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Add a number and then Buy a Number.\n* If you already have a number, you can click Add a number and then Add an Existing Number.\n\n\n\n\n\nIf you use a Lite or Trial Twilio account for testing purposes, then be sure to verify the transfer target. For more information, see the [Twilio documentation](https:\/\/support.twilio.com\/hc\/en-us\/articles\/223136107-How-does-Twilio-s-Free-Trial-work-).\n\nYou cannot enable SIP authentication if you choose Twilio as your SIP trunk provider. Twilio doesn't support SIPS for originating calls.\n\n\n\n\n\n Using other third-party providers \n\nYou can ask for help setting up an account with another SIP trunk provider by opening a support request.\n\nIBM has established relationships with the following SIP trunk providers:\n\n\n\n* [Five9](https:\/\/www.five9.com\/products\/capabilities\/contact-center-software)\n* [Genesys](https:\/\/www.genesys.com\/en-sg\/definitions\/what-is-a-trunk)\n* [Vonage](https:\/\/www.vonage.com\/communications-apis\/sip-trunking\/)\n* [Voximplant](https:\/\/voximplant.com\/)\n\n\n\nThe SIP trunk provider sets up a SIP trunk for your voice traffic, and manages access from allowed IP addresses. Most of the major SIP trunk providers have existing relationships with IBM. Therefore, the network configuration that is required to support the SIP trunk connection typically can be handled for you with minimal effort.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_03158-17978-19852","score":34.196826714,"text":"\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Buy a Number.\n* If you already have a number, you can click the plus sign (+) to provision a new phone number in your region.\n\n\n\n8. Assign the number to the SIP trunk you created by going back to the SIP trunk and clicking the number sign (#) icon.\n\n\n\nIf you use a Lite or Trial Twilio account for testing purposes, then be sure to verify the transfer target.\n\nYou cannot enable SIP authentication if you choose Twilio as your SIP trunk provider. Twilio doesn't support SIPS for originating calls.\n\n\n\n\n\n Using other third-party providers \n\nYou can ask for help setting up an account with another SIP trunk provider by opening a support request.\n\nIBM has established relationships with the following SIP trunk providers:\n\n\n\n* [Five9](https:\/\/www.five9.com\/products\/capabilities\/contact-center-software)\n* [Genesys](https:\/\/www.genesys.com\/en-sg\/definitions\/what-is-a-trunk)\n* [Vonage](https:\/\/www.vonage.com\/communications-apis\/sip-trunking\/)\n* [Voximplant](https:\/\/voximplant.com\/)\n\n\n\nThe SIP trunk provider sets up a SIP trunk for your voice traffic, and manages access from allowed IP addresses. Most of the major SIP trunk providers have existing relationships with IBM. Therefore, the network configuration that is required to support the SIP trunk connection typically can be handled for you with minimal effort.\n\n\n\n1. Create a [IBM Cloud case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form).\n2. Click Customer success as the case type.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_10769-4829-6342","score":32.2677922472,"text":"\nThe feed action sets up a ruleT -> pollMyService.\n\n\n\nThis procedure implements a polling-based trigger entirely by using Cloud Functions actions, without any need for a separate service.\n\n\n\n\n\n Implementing feeds by using connections \n\nThe previous two architectural choices are simple and easy to implement. However, if you want a high-performance feed, you can use persistent connections and long-polling or similar techniques.\n\nSince Cloud Functions actions must be short-running, an action cannot maintain a persistent connection to a third party. Instead, you can stand up a separate service, called provider services, outside of Cloud Functions that run all the time. A provider service can maintain connections to third-party event sources that support long polling or other connection-based notifications.\n\nThe provider service has a REST API that allows the Cloud Functions feed action to control the feed. The provider service acts as a proxy between the event provider and Cloud Functions. When it receives events from the third party, it sends them on to Cloud Functions by firing a trigger.\n\nThe IBM Cloudant changes feed is the canonical example as it stands up a cloudanttrigger service, which mediates between IBM Cloudant notifications over a persistent connection, and Cloud Functions triggers.\n\nThe alarm feed is implemented with a similar pattern.\n\nThe connection-based architecture is the highest performance option, but operations are more labor-intensive than polling and hook architectures.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-feeds_custom"},{"document_id":"ibmcld_12832-4-1984","score":31.3884239021,"text":"\n* UI\n\n\n\n\n\n\n\n Defining your support experience \n\nMaking sure that your users understand how to get help and support for your product is key. Defining your support experience includes providing details about how users can contact your support team and escalate issues. To define your product's support experience, you need to select the type of support that is provided, add support details, and then provide information about how users can escalate support cases.\n\n\n\n Selecting your product's support provider \n\nSelect your product's support provider to add the necessary details that are associated with the third-party or community provider types.\n\nThird-party products\n: Provided by individual service entities, IBM Business Partners, or independent service vendors (ISV). Support for third-party products is provided by the third-party provider. If the root cause analysis determines that the issue is a defect in a third-party product, IBM Cloud isn't required to provide a fix. However, IBM Cloud shares analysis with the third-party provider, if needed, and can work with the third-party provider to help solve the issue.\n\nCommunity products\n: Provided by open source communities. If a root cause analysis determines that a support issue is a defect in an open source or community product, IBM Cloud isn't required to provide a fix. IBM Cloud closes the case and refers users to the community or forum for assistance. Users can get community assistance for technical issues through [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud).\n\nUse the following steps to select your product's support provider.\n\n\n\n1. In the IBM Cloud console, click the Navigation Menu icon ![Navigation Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ff5860bfede49db3197c4bbba7f7123769bdc068\/icons\/icon_hamburger.svg) > Partner Center > Sell > My Products.\n2. Select the product that you're onboarding, and click Support.\n3. Select your product's support provider.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-saas-support-details"},{"document_id":"ibmcld_12867-4-1990","score":31.3655480748,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Defining your support experience \n\nMaking sure that your users understand how to get help and support for your product is key. Defining your support experience includes providing details about how users can contact your support team and escalate issues. To define your product's support experience, you need to select the type of support that is provided, add support details, and then provide information about how users can escalate support cases.\n\n\n\n Selecting your product's support provider \n\nSelect your product's support provider to add the necessary details that are associated with the third-party or community provider types.\n\nThird-party products\n: Provided by individual service entities, IBM Business Partners, or independent service vendors (ISV). Support for third-party products is provided by the third-party provider. If the root cause analysis determines that the issue is a defect in a third-party product, IBM Cloud isn't required to provide a fix. However, IBM Cloud shares analysis with the third-party provider, if needed, and can work with the third-party provider to help solve the issue.\n\nCommunity products\n: Provided by open source communities. If a root cause analysis determines that a support issue is a defect in an open source or community product, IBM Cloud isn't required to provide a fix. IBM Cloud closes the case and refers users to the community or forum for assistance. Users can get community assistance for technical issues through [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud).\n\nUse the following steps to select your product's support provider.\n\n\n\n1. In the IBM Cloud console, click the Navigation Menu icon ![Navigation Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ff5860bfede49db3197c4bbba7f7123769bdc068\/icons\/icon_hamburger.svg) > Partner Center > Sell > My Products.\n2. Select the product that you're onboarding, and click Support.\n3. Select your product's support provider.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-sw-support-details"},{"document_id":"ibmcld_12789-1513-3693","score":31.068053484,"text":"\nThird-party services that offer paid usage-based pricing plans receive disbursements through an Electronic Funds Transfer (EFT). To set up this method to receive disbursements in IBM Cloud Partner Center Sell, you must submit the EFT form when you set up your first usage-based pricing plan. You can download the form from the Payments to me page.\n\n\n\n\n\n When are disbursements sent to me? \n\nIf any disbursements are due to a third-party provider, they are sent on the last business day of the second calendar month. For example, March activity would be paid on the last calendar day of May, unless the last day of the month falls on a weekend or holiday. In this case, disbursements are sent on the next business day. Disbursements are calculated from beginning of the month to the end of the month.\n\n\n\n\n\n What is the fee structure? \n\nDisbursements are paid against revenue recognized by IBM\u00ae in a royalty month. IBM pays a third-party provider for each sale of a product as follows:\n\n\n\n* As-a-service products: 87% of net revenue\n* Software products: 80% of net revenue\n\n\n\n\n\n\n\n Can a third-party provider run activity reports and payout reconciliations? \n\nWe are adding features to support reports in the near future. Disbursements are based on the quantities that you submit to the usage metering service and the price that is defined when you set up your pricing plan in Partner Center. Third-party disbursements are calculated as a percentage of the net revenue for each product sold by IBM for a given calendar month. Net revenue is defined as the revenue recognized by IBM or an IBM affiliate calculated using applicable discounts, refunds, returns, offsets, and other adjustments determined in accordance with the current revenue recognition policies of IBM and its affiliates and the controlling accounting principles. For full detail regarding payouts, refer to the Digital Platform Reseller Agreement that must be signed in Partner Center to offer usage-based pricing.\n\n\n\n\n\n How can I generate a new IBM Cloud Identity and Access Management API Key? \n\nYou're given your API Key when you enable IAM. It is critical that you save the API Key. The value is not shown again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-3p-faqs"},{"document_id":"ibmcld_03158-16828-18419","score":30.8024425138,"text":"\nYou can set up a SIP trunk in the following ways:\n\n\n\n* [Create a Twilio SIP trunk](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-twilio-setup)\n* [Use other third-party providers](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-request-setup)\n* [Bring your own SIP trunk](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-byost)\n* [Migrate from Voice Agent with Watson](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-migrate-from-va)\n\n\n\n\n\n Creating a Twilio SIP trunk \n\nTo set up a Twilio SIP trunk, complete the following steps:\n\n\n\n1. Create a Twilio account on the [Twilio website](https:\/\/www.twilio.com\/sip-trunking).\n2. From the Twilio website, go to the Elastic SIP Trunking dashboard.\n3. Select Trunks from the navigation bar and create a SIP trunk. If you already have a SIP trunk, click the plus sign (+). Enter a name for your SIP trunk and click Create.\n4. From the Elastic SIP Trunks page, select your SIP trunk.\n5. Select Origination from the navigation bar for your SIP trunk and configure the origination SIP URI.\n\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Buy a Number.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_07448-0-1638","score":30.5947580154,"text":"\n\n\n\n\n\n\n  About domains \n\nIBM Cloud\u00ae offers domain management for all customers, by using the [IBM Cloud console](https:\/\/cloud.ibm.com\/). There is no need to register, renew, and manage your domains with a third party. You can register, renew, transfer, and manage a domain using the same tool.\n\n\n\n  Reverse DNS \n\nReverse DNS is a method of resolving an IP address into a domain name, just as the domain name system (DNS) resolves domain names into associated IP addresses. One application of reverse DNS is a spam filter. Typically, a spammer uses an invalid IP address that does not match the domain name. A reverse DNS lookup program inputs IP addresses of incoming messages to a DNS database. If no valid name is found to match the IP address, the server blocks the message. Reverse DNS is also used for things like network troubleshooting calls (such as ping) and for network monitoring tools.\n\n\n\n\n\n  Secondary domains \n\nA secondary domain is a domain that IBM Cloud DNS servers transfer from your server to our authoritative DNS servers, ns1.softlayer.com and ns2.softlayer.com.\n\nTo set up a secondary domain, you need three pieces of information: the domain, the IP address of the master DNS server we're transferring from and how often, in minutes, you'd like the domain transferred.\n\nAfter a secondary domain is configured, you'll have the ability to change the master server's IP address and the transfer interval. You are also able to view the domain as we're transferring, request a manual transfer, convert your secondary domain to a primary domain, and view any error messages we logged during the transfer process.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns?topic=dns-about-domains"},{"document_id":"ibmcld_16288-9295-10984","score":30.3323808141,"text":"\n* [Use other third-party providers](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-request-setup)\n* [Bring your own SIP trunk](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-byost)\n* [Migrate from Voice Agent with Watson](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-migrate-from-va)\n\n\n\n\n\n Creating a Twilio SIP trunk \n\nTo set up a Twilio SIP trunk, complete the following steps:\n\n\n\n1. Create a Twilio account on the [Twilio website](https:\/\/www.twilio.com\/sip-trunking).\n2. From the Twilio website, go to the Elastic SIP Trunking dashboard. If you do not see it on the sidebar, go to the Search Bar at the top and search for 'Elastic SIP Trunking', then select Elastic SIP Trunks.\n3. On the Elastic SIP Trunks page, click the Create new SIP Trunk button to create a SIP trunk. Enter a name for your SIP trunk and click Create. If you already have a SIP trunk, go to the next step.\n4. From the Elastic SIP Trunks page, select your SIP trunk.\n5. Select Origination from the navigation bar for your SIP trunk and configure the origination SIP URI.\n\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Add a number and then Buy a Number.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3868528072,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.3868528072}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12498-8087-10171","score":18.5471304179,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_06843-4238-6198","score":16.881097636,"text":"\nThis command returns either cc, cd, ci, or pr, depending on which pipeline is running. This way, you can reuse the setup script between pipelines if necessary.\n\n\n\n\n\n Static code scan \n\nThe static code scan stage runs a static code analyzer tool on the specified app repo codebases.\n\nCC pipeline provides the repos that are found in the inventory for the scanner.\n\nYou can use any of the following methods to add static code to your pipeline:\n\n\n\n* Provide an already running SonarQube instance name, URL, and credentials by adding the SonarQube tool to your toolchain. The static-scan task runs a scan on the specified repos.\n* Add your code to the static-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\n\n\n\n\n Dynamic scan \n\nThe Dynamic scan stage runs a dynamic application security testing tool to find vulnerabilities in the deployed application.\n\n\n\n* Add your own dynamic scan code to the dynamic-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\nTo learn more about configuring dynamic scan by using OWASP-ZAP, see [Configuring ZAP scan for CC pipeline](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-zap-scanszap-scan-for-cc).\n\n\n\n\n\n Scans and checks in compliance checks \n\n\n\nTable 3. Compliance scans and checks\n\n Scan or check Description \n\n Detect secrets The [IBM Detect Secrets](https:\/\/github.com\/IBM\/detect-secrets) tool identifies where secrets are visible in app code. \n Code Risk Analyzer vulnerability scan Finds vulnerabilities for all of the app package dependencies, container base images, and operating system packages. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer CIS check Runs configuration checks on Kubernetes deployment manifests. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer Bill of Material (BOM) check The BOM for a specified repo that captures the pedigree of all of the dependencies. This BOM is collected at different granularities.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-cc-pipeline"},{"document_id":"ibmcld_12498-9696-11699","score":15.8775522785,"text":"\n[IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL\/TLS certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_06836-7569-8653","score":15.1380369276,"text":"\nup from the environment-properties configmap\n\n Eg. if there's a prop: my-config entry in the environment properties,\n then my-config is going to be used for $prop\nconfigmap: $prop\n\n the mechanism described works for secrets as well!\nsecret: $my-secrets\n\n the script is executed inside the checked out app repo\nscript: \n!\/bin\/sh\n...\n\n test runs after setup, but before building the docker image\ntest:\nimage: ibmcom\/pipeline-base-image:2.7\nscript: \n!\/bin\/sh\n...\n\n static-scan runs after test, but before building the docker image\nstatic-scan:\nimage: ibmcom\/pipeline-base-image:2.12\nscript: \n!\/bin\/sh\n...\n\n deploy runs after building the docker image\ndeploy:\nimage: ibmcom\/pipeline-base-image:2.7\n\n the script has access to the built docker image, which is available at \/config\/image\nscript: \n!\/bin\/sh\n\ncat \/config\/image\n\n dynamic-scan runs after deploy, but before the acceptance test run\ndynamic-scan:\nimage: ibmcom\/pipeline-base-image:2.12\nscript: \n!\/bin\/sh\n...\n\n acceptance-test runs after deploy\nacceptance-test:\nimage: ibmcom\/pipeline-base-image:2.7\nscript: \n!\/bin\/sh\n...\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-custom-scripts"},{"document_id":"ibmcld_16729-294066-295916","score":14.2969599929,"text":"\nA script and tool will assist you to simulate the transmission of web server log messages from a static file to Event Streams.\n\nObject Storage Event Streams\n\n+3\n\nAnalytics Engine,Data Engine,Key Protect\n\n\n\n* 3 hours\n* 2023-05-05\n\n\n\n[Getting started with Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-getting-started)Getting started with Secrets Manager\n\nThis tutorial focuses on storing and managing a username and password in IBM Cloud\u00ae Secrets Manager. With Secrets Manager, you can create, lease, and centrally manage secrets that are used in IBM Cloud services or your custom-built applications. Secrets are stored in a dedicated Secrets Manager instance, built on open source HashiCorp Vault.\n\nSecrets Manager\n\n\n\n* 10 minutes\n* 2023-03-01\n\n\n\n[Access a storage bucket by using a dynamic secret](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-access-storage-bucket)Access a storage bucket by using a dynamic secret\n\nIn this tutorial, you learn how to use IBM Cloud\u00ae Secrets Manager to create and lease an IAM credential that can be used to access a bucket in Cloud Object Storage.\n\nSecrets Manager Object Storage\n\n\n\n* 1 hour\n* 2023-05-30\n\n\n\n[Secure secrets for apps that run in your Kubernetes cluster](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-kubernetes-secrets)Secure secrets for apps that run in your Kubernetes cluster\n\nThis tutorial is for the Classic flavor of Kubernetes Service clusters. External Secrets is also available as an OpenShift operator.\n\nSecrets Manager\n\n\n\n* 45 minutes\n* 2023-06-15\n\n\n\n[Part 2: Create a GitHub issue when your certificates are about to expire](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-expiring-secrets-part-2)Part 2: Create a GitHub issue when your certificates are about to expire","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_07844-4589-6711","score":13.8407548992,"text":"\nRA-5 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br> \n RA-5 (d) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br> \n\n\n\n\n\n\n\n NIST supplemental guidance \n\nSecurity categorization of information systems guides the frequency and comprehensiveness of vulnerability scans. Organizations determine the required vulnerability scanning for all information system components, ensuring that potential sources of vulnerabilities such as networked printers, scanners, and copiers are not overlooked. Vulnerability analyses for custom software applications may require additional approaches such as static analysis, dynamic analysis, binary analysis, or a hybrid of the three approaches.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"},{"document_id":"ibmcld_12415-7-1973","score":13.6158878789,"text":"\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-faqs"},{"document_id":"ibmcld_07844-3757-5369","score":13.3970656526,"text":"\nRA-5 (b) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br> \n RA-5 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"},{"document_id":"ibmcld_07844-2925-4586","score":13.3067207231,"text":"\nRA-5 (a) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br> \n RA-5 (b) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"},{"document_id":"ibmcld_07578-1213887-1215935","score":13.2639969882,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.8503449055,"ndcg_cut_10":0.8503449055}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09835-0-777","score":16.6880260539,"text":"\n\n\n\n\n--------------------\n\n\n\n  Identifying software vulnerabilities \n\nYou can also use the IBM Cloud Monitoring Workload Protection service to find and prioritize software vulnerabilities, detect and respond to threats, and manage configurations, permissions and compliance from source to run.\n\nThe ability to monitor software vulnerabilities is included when you use the [Graduated Tier - Sysdig Secure + Monitor service plan](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-service_plans). This plan integrates IBM Cloud Security and Compliance Center Workload Protection as part of IBM Cloud Monitoring.\n\nFor more information, see the [IBM Cloud Security and Compliance Center Workload Protection documentation.](https:\/\/cloud.ibm.com\/docs\/workload-protection)\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-workoad-protection"},{"document_id":"ibmcld_10510-53754-56042","score":16.3468279668,"text":"\nTo protect your app, you must protect the image and establish checks to ensure the image's integrity.\n\nShould I use a public or a private registry to store my images?\n: Public registries, such as Docker Hub, can be used to get started with Docker images and Kubernetes to create your first containerized app in a cluster. But when it comes to enterprise applications, avoid registries that you don't know or don't trust to protect your cluster from malicious images. Keep your images in a private registry, like the one provided in IBM Cloud Container Registry or the [internal registry](https:\/\/docs.openshift.com\/container-platform\/4.11\/registry\/index.html) that is automatically set up in your Red Hat OpenShift cluster, and make sure to control access to the registry and the image content that can be pushed.\n\nWhy is it important to check images against vulnerabilities?\n: Research shows that most malicious attacks leverage known software vulnerabilities and weak system configurations. When you deploy a container from an image, the container spins up with the OS and extra binaries that you described in the image. Just like you protect your virtual or physical machine, you must eliminate known vulnerabilities in the OS and binaries that you use inside the container to protect your app from being accessed by unauthorized users.\n\nTo protect your apps, consider to address the following areas:\n\n\n\n1. Automate the build process and limit permissions: Automate the process to build your container image from your source code to eliminate source code variations and defects. By integrating the build process into your CI\/CD pipeline, you can ensure that your image is scanned and built only if the image passes the security checks that you specified. To avoid that developers apply hot fixes to sensitive images, limit the number of people in your organization who have access to the build process.\n2. Scan images before they deploy into production: Make sure to scan every image before you deploy a container from it. For example, if you use IBM Cloud Container Registry, all images are automatically scanned for vulnerabilities when you push the image to your namespace. If vulnerabilities are found, consider eliminating the vulnerabilities or block deployment for those images.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"},{"document_id":"ibmcld_06063-54813-57067","score":16.2126338215,"text":"\nBut when it comes to enterprise applications, avoid registries that you don't know or don't trust to protect your cluster from malicious images. Keep your images in a private registry, like the one provided in IBM Cloud Container Registry and make sure to control access to the registry and the image content that can be pushed.\n\nWhy is it important to check images against vulnerabilities?\n: Research shows that most malicious attacks leverage known software vulnerabilities and weak system configurations. When you deploy a container from an image, the container spins up with the OS and extra binaries that you described in the image. Just like you protect your virtual or physical machine, you must eliminate known vulnerabilities in the OS and binaries that you use inside the container to protect your app from being accessed by unauthorized users.\n\nTo protect your apps, consider to address the following areas:\n\n\n\n1. Automate the build process and limit permissions: Automate the process to build your container image from your source code to eliminate source code variations and defects. By integrating the build process into your CI\/CD pipeline, you can ensure that your image is scanned and built only if the image passes the security checks that you specified. To avoid that developers apply hot fixes to sensitive images, limit the number of people in your organization who have access to the build process.\n2. Scan images before they deploy into production: Make sure to scan every image before you deploy a container from it. For example, if you use IBM Cloud Container Registry, all images are automatically scanned for vulnerabilities when you push the image to your namespace. If vulnerabilities are found, consider eliminating the vulnerabilities or block deployment for those images. Find a person or team in your organization who is responsible for monitoring and removing vulnerabilities. Depending on your organizational structure, this person might be part of a security, operations, or deployment team. Enable [content trust](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_trustedcontentregistry_trustedcontent) so that images must be approved by a trusted signer before they can be pushed to the container registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security"},{"document_id":"ibmcld_06836-18833-20499","score":15.9549647574,"text":"\nPull request pipeline stages setup, test, detect-secrets, and branch-protection. The detect-secrets and branch-protection stages are not custom stages. They are provided by the pipelines by default. \n Continuous integration pipeline stages setup, test, static-scan, containerize, sign-artifact, deploy, acceptance-test, scan-artifact, release, detect-secrets, branch-protection, bom-check, cis-check, and vulnerability-scan. The detect-secrets, branch-protection, bom-check, cis-check, and vulnerability-scan stages are not custom stages. They are provided by the pipelines by default. \n continuous deployment pipeline stages setup, deploy, acceptance-test, create-change-request, change-request-check-approval, change-request-change-state-to-implement, and close-change-request. The create-change-request, change-request-check-approval, change-request-change-state-to-implement, and close-change-request stages are not custom stages. They are provided by the pipelines by default. \n Continuous compliance pipeline stages setup, test, static-scan, scan-artifact, acceptance-test, detect-secrets, branch-protection, bom-check, cis-check, and vulnerability-scan. The detect-secrets, branch-protection, bom-check, cis-check, and vulnerability-scan stages are not custom stages. They are provided by the pipelines by default. \n\n\n\n\n\n Example usage \n\n List saved stage results\n$ get_data result\ndetect-secrets\nbranch-protection\n\n Get stage result\n$ get_data result detect-secrets\nsuccess\n\nFor more information about the Stage Results API, see [Using the Stage Results API in custom scripts](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-stage-results).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-custom-scripts"},{"document_id":"ibmcld_16691-7674-9167","score":15.9102905012,"text":"\n[Configure a notification channel](https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-notificationsnotifications_create) You can configure a notification channel to get notified about events, anomalies, or security incidents that require attention. \n [Scan container images](https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-scan_kube) You can scan container images for vulnerabilities, and other violations. \n [Configure an image scanning alert](https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-alert-config) You can set up a runtime Scanning Alert to detect if an image is impacted by newly discovered vulnerabilities. You can scan a repository that hosts container images for vulnerabilities, secrets, and license violations. Then, you can configure an alert on the repository to receive notifications on issues that need your attention. \n [Configure a rule](https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-manage_rules) You can create a Detection Rule to detect and respond to anomalous runtime activity. <br>You can create a rule to specify which image versions can be used. \n [Define a policy](https:\/\/cloud.ibm.com\/docs\/docs\/workload-protection?topic=workload-protection-manage_policies) You can configure a policy on a resource and define what to do when 1 or more rules that are included in the policy are noncompliant. <br>Secure includes a number of pre-defined policies that you can use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-getting-started"},{"document_id":"ibmcld_06063-53153-55320","score":15.3501757337,"text":"\nImage Vulnerability Scanner: By default, Vulnerability Advisor scans images that are stored in IBM Cloud Container Registry to find potential security vulnerabilities. For more information, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index).\n4. IBM Cloud Security and Compliance Center: When you enable IBM Cloud Security and Compliance Center, you can view reports about suspicious incoming and outgoing network traffic. For more information, see [What is IBM Cloud Security and Compliance Center?](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n5. IBM Cloud\u00ae Secrets Manager: You can store your Ingress and Kubernetes secrets in IBM Cloud\u00ae Secrets Manager. When you integrate Secrets Manager into your cluster, you set a default Secrets Manager instance where all Ingress subdomain secrets are uploaded. For more information, see [Setting up Secrets Manager in your Kubernetes Service cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-secrets-mgr).\n\n\n\n\n\n\n\n Image and registry \n\nEvery deployment is based on an image that holds the instructions for how to spin up the container that runs your app. These instructions include the operating system inside the container and extra software that you want to install. To protect your app, you must protect the image and establish checks to ensure the image's integrity.\n\nShould I use a public or a private registry to store my images?\n: Public registries, such as Docker Hub, can be used to get started with Docker images and Kubernetes to create your first containerized app in a cluster. But when it comes to enterprise applications, avoid registries that you don't know or don't trust to protect your cluster from malicious images. Keep your images in a private registry, like the one provided in IBM Cloud Container Registry and make sure to control access to the registry and the image content that can be pushed.\n\nWhy is it important to check images against vulnerabilities?\n: Research shows that most malicious attacks leverage known software vulnerabilities and weak system configurations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security"},{"document_id":"ibmcld_01494-54686-56173","score":15.2109493329,"text":"\n* [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexabout)\n\n\n\n* [Data protection](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexabout_data_protection)\n\n\n\n* [Types of vulnerabilities](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indextypes)\n\n\n\n* [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexpackages)\n* [Configuration issues - version 3 only](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexapp_configurations)\n\n\n\n* [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_set_version)\n* [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing)\n\n\n\n* [Reviewing a vulnerability report by using the console - version 3 only](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing_gui)\n* [Reviewing a vulnerability report by using the CLI](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_registry_cli)\n\n\n\n* [Setting organizational exemption policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_managing_policy)\n\n\n\n* [Setting exemption policies by using the console](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_managing_policy_gui)\n* [Setting exemption policies by using the CLI](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_managing_policy_cli)\n\n\n\n\n\n\n\n\n\n Setting up Terraform for Container Registry","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-sitemap"},{"document_id":"ibmcld_07848-0-703","score":15.1518933888,"text":"\n\n\n\n\n\n\n  RA-5 (5) - Privileged Access \n\n\n\n  Control requirements \n\nRA-5 (5) - 0\n:   The information system implements privileged access authorization to [IBM Assignment: operating systems, databases, container images, and web applications] for selected [IBM Assignment: vulnerability scans].\n\n\n\n\n\n  NIST supplemental guidance \n\nIn certain situations, the nature of the vulnerability scanning may be more intrusive or the information system component that is the subject of the scanning may contain highly sensitive information. Privileged access authorization to selected system components facilitates more thorough vulnerability scanning and also protects the sensitive nature of such scanning.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5.5"},{"document_id":"ibmcld_16696-7-2390","score":15.044411523,"text":"\nKey features of IBM Cloud Security and Compliance Center Workload Protection \n\nIBM Cloud\u00ae Security and Compliance Center Workload Protection offers functionality to protect workloads, get deep cloud and container visibility, posture management (compliance, benchmarks, CIEM), vulnerability scanning, forensics, and threat detection and blocking.\n\n\n\n Provides a unified and centralized framework to manage the security and compliance of applications, workloads and infrastructure \n\n\n\n* Provides a unified and centralized framework to manage the security and compliance of applications, workloads and infrastructure and protect workloads and resources that run on IBM Cloud, in other clouds, and on-prem. Presents relevant performance and security data in one location.\n* Is built on open standards for cloud native security and control, including Falco, the open source standard for cloud threat detection, and Open Policy Agent (OPA), the open source standard for policy-as-code.\n* Offers a workload protection platform (WPP) that focuses on management and security controls for workloads.\n* Offers a compliance platform (CP) that focuses on management and compliance controls that are required to meet industry standards and laws.\n* Includes Cloud security posture management (CSPM) to help you secure the infrastructure where workloads are deployed.\n* Includes Kubernetes Security Posture Management (KSPM) to help you secure Kubernetes clusters or Openshift clusters, and the workloads running within it.\n* Offers alerting on violations, and assists with remediation tasks.\n\n\n\n\n\n\n\n Offers host and image scanning, auditing, and runtime vulnerability management capabilities \n\n\n\n* Filters and surfaces vulnerabilities in images, clusters, namespaces, or hosts.\n* Alerts on unscanned images or images when the evaluation status changes with new vulnerabilities.\n* Logs user actions, container activity, and command arguments.\n* Enforces security policies and blocks attacks.\n\n\n\n\n\n\n\n Provides posture management for a distributed environment \n\n\n\n* Schedules customized benchmark tests to run across cloud, hosts, services, or clusters.\n* Controls compliance at cloud, orchestrator, and container level.\n* Tracks and optimizes cloud users permissions and entitlements.\n* Exports results to SIEM, logging clusters, or other tools.\n\n\n\n\n\n\n\n Provides runtime detection and data enrichment","title":"","source":"https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-key-features"},{"document_id":"ibmcld_01533-4546-6910","score":14.8436730056,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12389-7-2298","score":19.4541294835,"text":"\nBest practices for rotating and locking secrets \n\nWith IBM Cloud\u00ae Secrets Manager, you can design a strategy for rotating your secrets and sensitive data. Review the following suggested guidelines for implementing best practices around your secrets management.\n\n\n\n Define your rotation strategy \n\nAs you use Secrets Manager to design your secrets management strategy, consider how often you want to rotate your secrets based on the internal guidelines for your organization. Determine ahead of time which users or service IDs require access to rotate secrets, and how those secrets can be rotated manually to avoid interruptions to your applications.\n\n\n\n1. Determine a frequency of rotation for your secrets.\n\nAfter you store a secret in Secrets Manager, you decide the frequency of its rotation. You might want to rotate secrets due to personnel turnover, process malfunction, or according to your organization's internal guidelines. Rotate your secrets regularly, for example every 90 days, to meet best practices around secrets management.\n2. Test out rotation workflows for each type of secret that you manage in Secrets Manager.\n\nThe way in which Secrets Manager evaluates a request to rotate a secret differs depending on the type of secret. For example, some secrets are replaced immediately with the data that you provide on rotation, whereas other secrets, such as public certificates, move into an extra validation step. For more information about how Secrets Manager handles rotation requests, see [Manually rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotationmanual-rotate-by-type).\n3. Establish a process for deploying the newest secret versions to your applications.\n\nUse an automated flow to obtain and deploy the latest version of your secret after it is rotated. For more information, see [Avoid application outages by locking your secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-rotate-secretsbest-practices-lock-secrets).\n\n\n\n\n\n\n\n Set up alerts for expiring secrets \n\nConnect to the Event Notifications service so that Secrets Manager can notify you in advance when your secrets or certificates are about to expire.\n\n\n\n1. Set up alerts for your instance by enabling event notifications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-rotate-secrets"},{"document_id":"ibmcld_12384-9214-11044","score":19.4506769304,"text":"\n2. In the row for the secret that you want to edit, click the Actions menu ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/991f60ddbe3ab0a9aa69481a07a0a73b359fa329\/icons\/actions-icon-vertical.svg)> Edit details.\n3. Use the Automatic rotation option to enable or disable automatic rotation for the secret.\n\n\n\n\n\nRotation is available only for IAM credentials where the reuse key is set to true. The defined rotation interval cannot be higher than the defined time-to-live (TTL). You can set the TTL for secrets by using minute units of time but rotation is not available for those secrets.\n\n\n\n\n\n\n\n Scheduling automatic rotation from the CLI \n\nYou can schedule the automatic rotation of secrets by using the Secrets Manager CLI plug-in.\n\n\n\n Setting an automatic rotation policy for user credentials \n\nSchedule the automatic rotation for user credentials by using the Secrets Manager CLI plug-in.\n\nibmcloud secrets-manager secret-metadata-update --id=SECRET_ID --rotation='{\"auto_rotate\": true,\"interval\": 30,\"unit\": \"day\"}'\n\nTo remove a policy, keep the resources block empty.\n\n\n\n\n\n Setting an automatic rotation policy for public certificates \n\nSchedule the automatic rotation for public certificates by using the Secrets Manager CLI plug-in.\n\nibmcloud secrets-manager secret-metadata-update --id=SECRET_ID --rotation='{\"auto_rotate\": true, \"rotate_keys\": true}'\n\n\n\n\n\n Setting an automatic rotation policy for private certificates \n\nSchedule the automatic rotation for private certificates by using the Secrets Manager CLI plug-in.\n\nibmcloud secrets-manager secret-metadata-update --id=SECRET_ID --rotation='{\"auto_rotate\": true,\"interval\": 30,\"unit\": \"day\"}'\n\n\n\n\n\n Setting an automatic rotation policy for IAM credentials \n\nSchedule the automatic rotation for IAM credentials by using the Secrets Manager CLI plug-in.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation"},{"document_id":"ibmcld_12447-4-2115","score":19.119745553,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Manually rotating secrets \n\nWith IBM Cloud\u00ae Secrets Manager, you can manually create new versions of a secret by using the UI or APIs.\n\nWhen you rotate a secret in your service instance, you create a new version of its value. Rotating your credentials limits how long a protected resource can be accessed by a single secret, which can protect your business against the risks that are associated with compromised credentials. Rotate your secrets regularly, for example every 30 or 60 days, so that you're always meeting best practices around secrets management.\n\n\n\n Before you begin \n\nBefore you get started, be sure that you have the required level of access. To rotate secrets, you need the [Writer service role or higher](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam).\n\n\n\n Supported secret types \n\nAll the secrets that you store in Secrets Manager can be rotated and replaced on-demand. How Secrets Manager evaluates a request to rotate a secret depends on the secret type.\n\n\n\nTable 1. Describes how Secrets Manager evaluates manual rotation by secret type\n\n Type Rotation description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) Arbitrary secrets are immediately replaced with the data that you provide on rotation. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) IAM credentials, which consist of a service ID and API key, are immediately regenerated according to their initial configuration. If the IAM credentials secret was created by using an existing service ID in the account, only the API key is regenerated as part of a manual rotation. In contrast, if the secret was created by selecting an access group, both the service ID and API key values are regenerated when they're manually rotated.<br><br>The Reuse IAM credentials until lease expires (reuse_api_key) option for an IAM credentials secret impacts whether it can be rotated manually. If this field is false or set to Off in the UI, manual rotation isn't supported.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation&interface=ui"},{"document_id":"ibmcld_12384-4-1975","score":19.1065490211,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Automatically rotating secrets \n\nYou can schedule automatic rotation for secrets by using IBM Cloud\u00ae Secrets Manager.\n\nWhen you rotate a secret in your service instance, you create a new version of its value. By scheduling automatic rotation of your secrets at regular intervals, you can reduce the likelihood of compromise and ensure that your credentials never expire.\n\nAutomatic rotation is available only for secrets that are generated by Secrets Manager. If the secret was imported initially, you must provide new secret data to rotate it. For more information, see [Manually rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n\n\n\n Before you begin \n\nBefore you get started, be sure that you have the required level of access. To rotate secrets, you need the [Writer service role or higher](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam).\n\n\n\n Supported secret types \n\nAutomatic rotation is supported for [private certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificatescreate-certificates), [public certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificatesorder-certificates), [user credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) and [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials). Depending on the type of secret, automatic rotation takes place immediately on the date and time that you set, or it might need to complete a few extra steps before a new version of the secret can be created.\n\n\n\nTable 1. Describes how Secrets Manager evaluates manual rotation by secret type\n\n Type Rotation description \n\n [Private certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificatescreate-certificates) The existing certificate value is replaced with new certificate content.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation"},{"document_id":"ibmcld_12384-10659-12564","score":19.0917618439,"text":"\nSchedule the automatic rotation for private certificates by using the Secrets Manager CLI plug-in.\n\nibmcloud secrets-manager secret-metadata-update --id=SECRET_ID --rotation='{\"auto_rotate\": true,\"interval\": 30,\"unit\": \"day\"}'\n\n\n\n\n\n Setting an automatic rotation policy for IAM credentials \n\nSchedule the automatic rotation for IAM credentials by using the Secrets Manager CLI plug-in.\n\nibmcloud secrets-manager secret-metadata-update --id=SECRET_ID --rotation='{\"auto_rotate\": true,\"interval\": 30,\"unit\": \"day\"}'\n\nTo remove a policy, keep the resources block empty.\n\n\n\n\n\n\n\n Scheduling automatic rotation with the API \n\nYou can schedule the automatic rotation of secrets by using the Secrets Manager API.\n\n\n\n Setting an automatic rotation policy for user credentials \n\nThe following example request creates an automatic rotation policy for a user credentials (username_password) secret. When you call the API, replace the ID variables and IAM token with the values that are specific to your Secrets Manager instance.\n\ncurl -X PATCH\n-H \"Authorization: Bearer {iam_token}\" -H \"Accept: application\/json\" -H 'Content-Type: application\/merge-patch+json' -d '{\n\"rotation\": {\n\"auto_rotate\": true,\n\"interval\": 1,\n\"unit\": \"month\"\n}\n}' \n\"https:\/\/{instance_ID}.{region}.secrets-manager.appdomain.cloud\/api\/v2\/secrets\/{id}\/metadata\"\n\nA successful response returns the ID value for the secret, along with other metadata. For more information about the required and optional request parameters, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/secrets-manager\/secrets-manager-v2update-secret).\n\nTo remove a policy, keep the resources block empty.\n\n\n\n\n\n Setting an automatic rotation policy for public certificates \n\nIf you prefer to schedule your certificates to be automatically renewed, you can enable automatic rotation for certificates when you order them, or by editing the details of an existing certificate.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation"},{"document_id":"ibmcld_12389-1833-3915","score":19.0657952752,"text":"\nFor more information, see [Avoid application outages by locking your secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-rotate-secretsbest-practices-lock-secrets).\n\n\n\n\n\n\n\n Set up alerts for expiring secrets \n\nConnect to the Event Notifications service so that Secrets Manager can notify you in advance when your secrets or certificates are about to expire.\n\n\n\n1. Set up alerts for your instance by enabling event notifications. To connect your instance to the Event Notifications service, go to the Secrets Manager UI > Settings > Event Notifications.\n2. Create topics and subscriptions in Event Notifications so that alerts can be forwarded and delivered to your [selected destinations](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-event-notificationsevent-notifications-destinations), for example Slack or email.\n\nLooking for examples? Check out our [tutorial series](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-expiring-secrets-part-1) that guides you through sending notifications to GitHub and Slack.\n\n\n\n\n\n\n\n Enable automatic rotation for secrets \n\nSimplify the process of rotating secrets in your instance by enabling automatic rotation.\n\n\n\n1. Use automatic rotation to limit how long your secrets remain active.\n\nBy scheduling automatic rotation of secrets at regular intervals, you reduce the likelihood of compromised credentials. When it's time to rotate the secret based on the rotation interval that you specify, Secrets Manager automatically creates a new version of your secret. For more information, see [Automatically rotating your secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation).\n2. Schedule automatic rotation to take place before your secrets are set to expire.\n\nTo avoid interruptions to your applications, it's recommended that you set the minimum interval between automatic rotation and expiration date to 30 days.\n\n\n\n\n\n\n\n Avoid application outages by locking your secrets \n\nUse locks to plan for periodic rotation of secrets.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-rotate-secrets"},{"document_id":"ibmcld_12384-7792-9442","score":18.7438615268,"text":"\nIn the Secrets table, view a list of your existing Private certificates.\n2. In the row for the certificate that you want to edit, click the Actions menu ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/991f60ddbe3ab0a9aa69481a07a0a73b359fa329\/icons\/actions-icon-vertical.svg)> Edit details.\n3. Use the Automatic rotation option to add or remove a rotation policy for the secret.\n\n\n\n\n\n\n\n\n\n Setting an automatic rotation policy for IAM credentials \n\nIf you prefer to schedule your API key to be automatically rotated at regular intervals, you can enable automatic rotation for your IAM credentials at their creation. You can also enable auto rotation by editing the details of an existing secret. Choose between a 30, 60, or 90-day rotation interval.\n\nIf you need more control over the rotation frequency of a secret, you can use the Secrets Manager API to set a custom interval by using day or month units of time. For more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/secrets-manager\/secrets-manager-v2put-policy).\n\n\n\n1. If you're [adding a secret](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentialsiam-credentials-ui), enable the rotation option by selecting a 30, 60, or 90-day rotation interval.\n2. If you're editing an existing secret, enable automatic rotation by updating its details.\n\n\n\n1. In the Secrets table, view a list of your existing secrets.\n2. In the row for the secret that you want to edit, click the Actions menu ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/991f60ddbe3ab0a9aa69481a07a0a73b359fa329\/icons\/actions-icon-vertical.svg)> Edit details.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation"},{"document_id":"ibmcld_12447-3178-4817","score":18.7133367362,"text":"\nSecrets Manager sends the request to the configured certificate authority (CA), for example Let's Encrypt, to validate the ownership of your domains. If the validation completes successfully, a new certificate is issued. \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) Passwords that are associated with user credentials secrets are immediately replaced with the data that you provide on rotation. \n\n\n\n\n\n\n\n\n\n Creating new secret versions in the UI \n\nYou can manually rotate your secrets and certificates by using the Secrets Manager UI.\n\n\n\n Rotating arbitrary secrets \n\nYou can use the Secrets Manager UI to manually rotate your arbitrary secrets.\n\n\n\n1. In the console, click the Menu icon ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/991f60ddbe3ab0a9aa69481a07a0a73b359fa329\/icons\/icon_hamburger.svg)> Resource List.\n2. From the list of services, select your instance of Secrets Manager.\n3. In the Secrets Manager UI, go to the Secrets list.\n4. In the row for the secret that you want to rotate, click the Actions menu ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/991f60ddbe3ab0a9aa69481a07a0a73b359fa329\/icons\/actions-icon-vertical.svg)> Rotate.\n5. Select a new file or enter a new secret value.\n6. Optional: Add metadata to your secret or to a specific version of your secret.\n\n\n\n1. Upload a file or enter the metadata and the version metadata in JSON format.\n\n\n\n7. To rotate the secret immediately, click Rotate.\n8. Optional: Check the version history to view the latest updates.\n\nIn the row of the secret that you rotated, click the Actions menu !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation&interface=ui"},{"document_id":"ibmcld_12447-23717-25820","score":18.6759457822,"text":"\n{region}.secrets-manager.appdomain.cloud\/api\/v2\/secrets\/{id}\/versions\"\n\nTo have the service generate and assign a random password to your credential, you can pass an empty string on the password field. For example, { \"password\": \"\"}. Secrets Manager replaces the existing value with a randomly generated 32-character password that contains uppercase letters, lowercase letters, digits, and symbols.\n\nA successful response returns the ID value for the secret, along with other metadata. For more information about the required and optional request parameters, check out the [API docs](https:\/\/cloud.ibm.com\/apidocs\/secrets-manager\/secrets-manager-v2update-secret).\n\n\n\n\n\n\n\n Manually rotating secrets with Terraform \n\nYou can manually rotate your arbitrary secrets, key-value secrets, or imported certificates by using Terraform for Secrets Manager. To manually rotate other types of secrets, you must use the UI, the API or the CLI.\n\n\n\n Rotating arbitrary secrets \n\nYou can rotate arbitrary secrets by using Terraform for Secrets Manager.\n\nTo rotate an arbitrary secret, modify the value of the payload attribute in your ibm_sm_arbitrary_secret resource configuration, and run terraform apply to apply the change. If you're using an input variable for the payload, modify its value in the variables.tf file.\n\nYou can also modify other attributes of the arbitrary secret at the same time, including metadata attributes such as description, custom_metadata, or version_custom_metadata.\n\n\n\n\n\n Rotating key-value secrets \n\nTo rotate a key-value secret by using Terraform for Secrets Manager, modify the value of the data attribute in your ibm_sm_kv_secret resource configuration, and run terraform apply to apply the change. If you're using an input variable for the payload, modify its value in the variables.tf file.\n\nYou can also modify other attributes of the key-value secret at the same time, including metadata attributes such as description, custom_metadata or version_custom_metadata.\n\n\n\n\n\n Rotating imported certificates \n\nYou can rotate imported certificates by using Terraform for Secrets Manager.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation&interface=ui"},{"document_id":"ibmcld_12384-12067-13868","score":18.5843530279,"text":"\nFor more information about the required and optional request parameters, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/secrets-manager\/secrets-manager-v2update-secret).\n\nTo remove a policy, keep the resources block empty.\n\n\n\n\n\n Setting an automatic rotation policy for public certificates \n\nIf you prefer to schedule your certificates to be automatically renewed, you can enable automatic rotation for certificates when you order them, or by editing the details of an existing certificate. In the certificate's next rotation cycle, Secrets Manager reorders the certificate 31 days before its expiry date.\n\n\n\n Ordering a public certificate that renews automatically \n\nThe following example request orders a certificate with automatic rotation enabled. When you call the API, set the auto_rotate property to true. Optionally, you can set rotate_keys to true to request a new private key for the certificate on each rotation.\n\ncurl -X POST\n-H \"Authorization: Bearer {iam_token}\" -H \"Accept: application\/json\" -H \"Content-Type: application\/json\" -d '{\n\"custom_metadata\": {\n\"metadata_custom_key\": \"metadata_custom_value\"\n},\n\"rotation\": {\n\"auto_rotate\": true,\n\"rotate_keys\": true\n},\n\"version_custom_metadata\": {\n\"custom_version_key\": \"custom_version_value\"\n}\n}' \n\"https:\/\/{instance_ID}.{region}.secrets-manager.appdomain.cloud\/api\/v2\/secrets\"\n\nA successful response returns the ID value for the certificate, along with other metadata. For more information about the required and optional request parameters, check out the [API reference](https:\/\/cloud.ibm.com\/apidocs\/secrets-manager\/secrets-manager-v2create-secret).\n\n\n\n\n\n\n\n Setting an automatic rotation policy for IAM credentials \n\nThe following example request creates an automatic rotation policy for a IAM credentials (iam_credentials) secret.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.5585075863,"ndcg_cut_10":0.5585075863}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03369-42156-43963","score":16.2761816542,"text":"\nService API endpoint change\n: As explained in [December 2019](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notesassistant-dec122019), as part of work done to fully support IAM authentication, the endpoint you use to access your Watson Assistant service programmatically is changing. The old endpoint URLs are deprecated and will be retired on 26 May 2021. Update your API calls to use the new URLs.\n\nThe pattern for the endpoint URL changes from gateway-{location}.watsonplatform.net\/assistant\/api\/ to api.{location}.assistant.watson.cloud.ibm.com\/. The domain, location, and offering identifier are different in the new endpoint. For more information, see [Updating endpoint URLs from watsonplatform.net](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-change).\n\n\n\n* If your service instance API credentials show the old endpoint, create a new credential and start using it today. After you update your custom applications to use the new credential, you can delete the old one.\n* For a web chat integration, you might need to take action depending on when and how you created your integration.\n\n\n\n* If you tied your deployment to a specific web chat version by using the clientVersion parameter and specified a version earlier than version 3.3.0, update the parameter value to use version 3.3.0 or later. Web chat integrations that use the latest or 3.3.0 and later versions will not be impacted by the endpoint deprecation.\n* If you created your web chat integration before May 2020, check the code snippet that you embedded in your web page to see if it refers to watsonplatform.net. If so, you must edit the code snippet to use the new URL syntax. For example, change the following URL:\n\n<script src=\"https:\/\/assistant-web.watsonplatform.net\/loadWatsonAssistantChat.js\"><\/script>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_10056-9379-11260","score":15.8827178561,"text":"\nWhen you delete the PVC, only the PVC is deleted. The PV, the physical storage device in your IBM Cloud infrastructure account, and your data still exist. To reclaim the storage and use it in your cluster again, you must remove the PV and follow the steps for [using existing block storage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-block_storageexisting_block).\n* If you want the PV, the data, and your physical block storage device to be deleted when you delete the PVC, choose a storage class without retain.\n\n\n\n6. Choose if you want to be billed hourly or monthly. The default setting is hourly billing.\n\n\n\n\n\n\n\n Setting up encryption for Block Storage for Classic \n\nYou can set up encryption for Block Storage for Classic by using IBM Key Protect.\n\nThe following example explains how to create a service ID with the required access roles for Key Protect and your cluster. The credentials of this service ID are used to enable encryption for your Block Storage for Classic volumes.\n\nYou can enable encryption by creating a Kubernetes secret that uses your personal API key as long as you have the Reader service access role for your Key Protect instance as well as the Viewer platform access role and the Writer service access role for your cluster.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\n\n\n1. Make sure that you are assigned the Editor platform access role and the Writer service access role for Key Protect so that you can create your own root key that you use to encrypt your Block Storage for Classic instance. You can review your IAM access roles in the [IAM console](https:\/\/cloud.ibm.com\/iam). For more information about IAM roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-block_storage"},{"document_id":"ibmcld_16364-77484-79416","score":15.8443743285,"text":"\nNote that initial context must be set using a conversation_start node. For more information, see [Starting the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-startdialog-start-welcome).\n\nConnect to human agent response type allows more text\n: In a dialog skill, the response type Connect to human agent now allows 320 characters in the Response when agents are online and Response when no agents are online fields. The previous limit was 100 characters.\n\nLegacy system entities deprecated\n: In January 2020, a new version of the system entities was introduced. As of April 2021, only the new version of the system entities is supported for all languages. The option to switch to using the legacy version is no longer available.\n\n\n\n\n\n 6 April 2021 \n\nService API endpoint change\n: As explained in [December 2019](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-noteswatson-assistant-dec122019), as part of work done to fully support IAM authentication, the endpoint you use to access your Watson Assistant service programmatically is changing. The old endpoint URLs are deprecated and will be retired on 26 May 2021. Update your API calls to use the new URLs.\n\nThe pattern for the endpoint URL changes from gateway-{location}.watsonplatform.net\/assistant\/api\/ to api.{location}.assistant.watson.cloud.ibm.com\/. The domain, location, and offering identifier are different in the new endpoint. For more information, see [Updating endpoint URLs from watsonplatform.net](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-change).\n\n\n\n* If your service instance API credentials show the old endpoint, create a new credential and start using it today. After you update your custom applications to use the new credential, you can delete the old one.\n* For a web chat integration, you might need to take action depending on when and how you created your integration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_16628-0-1541","score":14.6569930587,"text":"\n\n\n\n\n\n\n  About Visual Explain \n\nThe visual explain feature in IBM\u00ae watsonx.data shows the execution plan for a specified SQL query. This feature also validates the SQL query. The output results can be visualized in different formats, which can be rendered into a graph or a flow chart. Data exchange happens between single or multiple nodes within a fragment. Each fragment has a set of data that is distributed between the nodes.\n\nWith this visual explain feature, you can run the query and show the output in a distributed environment. You can output the results in different formats. When queries are run, they scan through the database. The queries retrieve table metadata to fetch the correct output.\n\nWith this visual explain feature, you can visualize the query in a graphical representation. When a query is run in the SQL editor and selects the Explain option, watsonx.data uses an EXPLAIN SQL statement on the query to create a corresponding graph. This graph can be used to analyze, fix, and improve the efficiency of your queries by saving time and cost.\n\nTo view the execution plans for a query that is run in watsonx.data SQL editor, follow the steps:\n\n\n\n1.  In the Query workspace page, enter the query and click Run on starter to get the results.\n2.  Click Explain on the screen to visualize the graphical representation of the query.\n\n\n\nOn the Explain window, click a stage to view the details on the right window. The details of each stage that is displayed are the estimate values for rows, CPU, memory, and network.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query"},{"document_id":"ibmcld_02490-7-2074","score":14.4874797404,"text":"\nManaging events from log in actions in an account \n\nAs a security officer, auditor, or manager, you can use the IBM Cloud Activity Tracker service to track how users, applications, and services interact with your account. The IBM Cloud\u00ae Identity and Access Management (IAM) service in IBM Cloud generates events that you can use to monitor log in activity to your account. This tutorial explains the different log in options to IBM Cloud and what happens from an IAM and an IBM Cloud Activity Tracker perspective. You can also find out how to define views and dashboards to monitor these actions in your account.\n\nTo work in the IBM Cloud, a user, an application, or a service must log in to IBM Cloud. The user, application, or service needs valid credentials to access an account and run actions on services in that account.\n\nAs a user, you can log in to the IBM Cloud in any of the following ways:\n\n\n\n* Log in through the IBM Cloud UI\n* Log in from the command-line interface (CLI) by using an API key\n* Log in from the command-line interface (CLI) by using a one-time passcode\n* Log in from the command-line interface (CLI) by using a user ID and password\n\n\n\nAs a service, you log in to the IBM Cloud by using an API key that is associated to a service ID.\n\nIf you are a new user of the IBM Cloud, [you must request an IBMid](https:\/\/cloud.ibm.com\/login). When you register to work in the IBM Cloud, you get an IBMid, and an account is created and associated to your IBMid.\n\nOnce you have registered to IBM Cloud, you can be invited to be a member in other accounts in IBM Cloud. When you are invited to work in an account that is different from the default account that is associated with your IBMid, an event with action user-management.user.create is generated and available in the account where you are invited to work. Users in the account with permissions to monitor Activity Tracker Event Routing events can monitor these events through the IBM Cloud Activity Tracker instance in Frankfurt (eu-de).\n\nFor a user to log in successfully to your account:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-iam_manage_login"},{"document_id":"ibmcld_07161-7-1967","score":14.4308723996,"text":"\nGetting started with the Data Crawler \n\nThe Data Crawler is no longer supported or available for download beginning [17 April 2019](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes17apr19). This content is provided for existing installations only. See [Connecting to Data Sources](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sources) for other available connectivity options.\n\nThis topic explains how to use the data crawler to ingest files from your local filesystem, to use with IBM Watson\u2122 Discovery.\n\nBefore attempting this task, create an instance of Discovery in IBM Cloud\u00ae. To complete this guide, you must use the credentials that are associated with the instance of the service that you created.\n\n\n\n Create an environment \n\nUse the bash POST \/v1\/environments method to create an environment. Think of an environment as the warehouse where you are storing all your boxes of documents. The following example creates an environment that is called my-first-environment:\n\nReplace {apikey} with your service credentials.\n\n(For more detailed information about using {apikey} credentials, see [Getting started with the API](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-gs-api).)\n\ncurl -X POST -u \"apikey:{apikey}\" -H \"Content-Type: application\/json\" -d \"{ \"name\":\"my-first-environment\", \"description\":\"exploring environments\"}\" \"{url}\/v1\/environments?version=2019-04-30\"\n\nThe API returns a response that includes information such as your environment ID, environment status, and how much storage your environment is using. Do not go on to the next step until your environment status is ready. When you create the environment, if the status returns status:pending, use the GET \/v1\/environments\/{environment_id} method to check the status until it is ready. In this example, replace {apikey} with your service credentials, and replace {environment_id} with the environment ID that was returned when you created the environment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-getting-started-with-the-data-crawler"},{"document_id":"ibmcld_02379-14575-16228","score":14.3994740529,"text":"\nTo view these events, you must [provision an instance](https:\/\/cloud.ibm.com\/docs\/services\/activity-tracker?topic=activity-tracker-provisionprovision) of the IBM Cloud Activity Tracker service in the Frankfurt (eu-de) region. Then, you must [open the IBM Cloud Activity Tracker UI](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-launchlaunch_cloud_ui).\n\n\n\n\n\n Analyzing events \n\n\n\n Catalog events \n\nYou can find the value unavailable in catalog events. This value indicates when an update is made, but specific details about the update aren't included.\n\n\n\n\n\n User management events \n\nThis section explains events that are generated when you manage users from the Manage > Access IAM > Users dashboard.\n\nWhen you analyze user management events, target.name is set to the user ID of the user on which the action is requested.\n\n\n\n Modify the status of a user \n\nWhen you modify the status of a user by selecting a user, clicking Edit in the Details section, and changing the User status, you get the following event:\n\n\n\n* Event with action user-management.user.update that reports a request in the account to modify the user's properties.\n\n\n\nFor example, see the action field for the event user-management.user.update:\n\n\"action\": \"user-management.user.update\",\n\"message\": \"User management service: update user\"\n\"initiator\": {\n\"id\": \"IBMid-12345\",\n\"typeURI\": \"service\/security\/account\/user\",\n\"name\": \"example@ibm.com\",\n\"host\": {\n\"agent\": \"\",\n\"address\": \"...\",\n\"addressType\": \"IPv4\"\n},\n\"credential\": {\n\"type\": \"token\"\n}\n},\n\"target\": {\n\"id\": \"crn:v1:bluemix:public:user-management:global:a\/account1234:::\",\n\"typeURI\": \"user-management\/user\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-at_events_acc_mgt"},{"document_id":"ibmcld_00610-7-2079","score":14.1709918647,"text":"\nMigrating an instance with legacy credentials and IAM Authentication to IAM Only Authentication \n\nWhen you create a new service credential by using the IBM Cloud Dashboard or the IBM Cloud CLI, it always produces a new username and password combination. This method applies to legacy credentials as well as a new IAM API key. This tutorial guides you through migrating your instance from generating new legacy credentials and IAM API keys to generating new IAM API keys only.\n\nThis tutorial is only applicable to IBM Cloudant instances within resource groups with legacy credentials that are enabled.\n\nSee the effects of this tutorial on existing legacy credentials:\n\n\n\n* New format legacy credentials (usernames that start with apikey-v2-) continue to function until the service credential is deleted.\n* URL style legacy credentials if still active are revoked. If you would like to revoke them separately, follow the [Revoking credential that is tied to your instance URL](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-revoke-instance-url-style-credential) steps before you complete this tutorial.\n\n\n\n\n\n Objectives \n\n\n\n1. Update your applications to use IAM credentials instead of legacy credentials.\n2. Disable creation of new legacy credentials.\n\n\n\n\n\n\n\n Step 1: Generating new IBM Cloudant IAM Credentials \n\n\n\n1. Use the IBM Cloud Dashboard or the IBM Cloud CLI to [generate new service credentials](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudantcreating-service-credentials) for your IBM Cloudant instance. For more information, see [Creating service credentials](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-to-iam-onlycreating-service-credentials) for further instructions.\n\n\n\n\n\n\n\n Step 2: Updating applications \n\n\n\n1. Update all applications to use IAM access tokens when you authenticate with the IBM Cloudant instance.\n\n\n\n\n\n\n\n Step 3: Migrating to IAM only \n\nThis operation cannot be undone. Make sure all applications that access the instance are using IAM to authenticate before you start this step.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-to-iam-only"},{"document_id":"ibmcld_00483-3212-4996","score":14.025599576,"text":"\n: The legacy credentials password that is required for applications to access the service instance. This field displays only if the Use both legacy credentials and IAM option is chosen.\n\nhost\n: The hostname that is used by applications to locate the service instance. This field displays only if the Use both legacy credentials and IAM option is chosen.\n\nport\n: The HTTPS port number for accessing the service instance on the host. It's 443 as only HTTPS access is allowed by IBM Cloudant. This field displays only if the Use both legacy credentials and IAM option is chosen.\n\nurl\n: The HTTPS URL to access the IBM Cloudant instance. If the Use both legacy credentials and IAM option is chosen, it also includes the embedded legacy username and password.\n\napikey\n: The IAM API key.\n\niam_apikey_description\n: Description of the IAM API key.\n\niam_apikey_name\n: ID of the IAM API key.\n\niam_role_crn\n: The IAM role that the IAM API key has.\n\niam_serviceid_crn\n: The CRN of the service ID.\n\n\n\n\n\n Authentication \n\nIBM Cloudant has two authentication methods available at provisioning time, either Use only IAM or Use both legacy credentials and IAM. You can see the details about your legacy credentials in the service credentials only if the Use both legacy credentials and IAM authentication method is chosen. The credentials display on the Service credentials tab for your instance. For more information, see the [IAM guide](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant) and [legacy authentication](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-work-with-your-accountauthentication) document for details about using either style of authentication.\n\nThe IBM Cloudant team recommends you use IAM access controls for authentication whenever possible.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-connecting"},{"document_id":"ibmcld_12493-34686-35762","score":13.979602472,"text":"\nConfigure an IAM credential with a lease duration of 1 hour and assign it to the default secret group.\n\nvault write -format=json ibmcloud\/iam_credentials\/roles\/test-iam-credentials access_groups=AccessGroupId-985dc0a3-857b-48bd-b6d6-33819da7ba42 ttl=1h description=\"My test IAM credential.\" labels=test,us-south\n\nConfigure an IAM credential with a lease duration of 1 hour and assign it to a specified secret group.\n\nvault write -format=json ibmcloud\/iam_credentials\/roles\/groups\/9ab2250f-a369-4e07-ade7-d417d63ad587\/test-iam-credential-in-group access_groups=AccessGroupId-985dc0a3-857b-48bd-b6d6-33819da7ba42 ttl=1h description=\"My test IAM credential that is assigned to a secret group.\" labels=test,us-south\n\n\n\n\n\n Output \n\nThe command returns the following output:\n\n{\n\"request_id\": \"d4150a28-1184-8864-dcd3-15b0d18da7c1\",\n\"lease_id\": \"\",\n\"lease_duration\": 0,\n\"renewable\": false,\n\"data\": {\n\"access_groups\": [\n\"AccessGroupId-985dc0a3-857b-48bd-b6d6-33819da7ba42\"\n],\n\"created_by\": \"iam-ServiceId-b7ebcf90-c7a9-495b-8ce8-bbf33cb95ca0\",\n\"creation_date\": \"2020-10-09T17:13:47Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-vault-cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12385-3409-5426","score":31.5122405152,"text":"\nIf you accidentally assign a secret to the wrong secret group, or if you don't want a secret to belong to the default secret group, delete the secret and create a new one.\n2. Optionally, use secret groups to allow privileged access to specific resources in your account.\n\nSecret groups can be used to grant direct access to resources that otherwise wouldn't be possible through IAM. For example, assume that User A has no access to Service A in IAM. If you create an IAM access policy that assigns User A to Secret Group A, and Secret Group A contains an [IAM credential](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) with a service ID that gives access to Service A, then you grant User A access to Service A. In this scenario, Secret Group A becomes a gateway to Service A, even if a restriction exists in IAM. Keep in mind that with this scenario it is possible to grant access to a resource unintentionally. Review your configuration carefully to ensure that your secret group assignments do not override your IAM access policies accidentally.\n3. Audit your secret groups regularly and remove them when they're no longer needed.\n\nGrant only the minimum access that is required, and delete a secret group when it is no longer needed.\n\nTo delete a secret group, it must be empty. If you need to remove a secret group that contains secrets, you must first [delete the secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-delete-secrets) that are part of the group.\n\n\n\n\n\n\n\n Track your related secrets by adding labels \n\nAdd labels so that you can further search by and categorize the secrets in your instance. When you use a consistent labeling schema, you can easily group similar secrets together.\n\n\n\n1. Label your secrets by using a consistent schema, such as creating labels to differentiate which secrets are used for a specific purpose. To add labels by using the Secrets Manager UI, go to the Secrets page, and then select a secret to edits its details.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets"},{"document_id":"ibmcld_07503-7275-9846","score":24.7078695277,"text":"\nIn addition, fine grained access control to configurations within a project can be used to restrict the set of users are allowed to approve and deploy changes to production infrastructure.\n\n\n\n\n\n\n\n Rationale for centralized infrastructure as code management \n\nCentralizing management of deployable architectures and their configuration into a production administration account for each BU provides the following benefits:\n\n\n\n* BU operators can manage their own workloads within the constraints that are imposed by the centralized organization\n\nThe application and infrastructure catalogs ensure that only approved, tested, and compliant deployable architectures are available. Using two catalogs makes it easy to set an IAM policy such that users have access to the correct set of deployable architectures according to their roles. For example, DevOps users get access to infrastructure and application developers get access to application development tools.\n* Centralized access control and monitoring for the BU\n\nPlacing the catalogs and projects in a centralized account makes it easier to ensure the principle of least privilege is applied. Use of projects also ensures that credentials with the capability to manipulate applications and infrastructure are not accessible to users and thus cannot be misused. Finally, keeping these related projects in the BU account makes it easy to monitor deployments and ensure that the infrastructure is up to date and compliant.\n* Ensures that development and production are aligned\n\nUsing a single project across development and production makes it possible to align development and test environments with production environments. The single project helps reduce the chance of defects that are related to environmental differences while providing control to the team over testing new deployable architecture versions in different environments. It also ensures that the lifecycle of these resources is properly managed across all environments. For example, if a project is no longer needed, it is easy to clean up all resources across nonproduction and production environments.\n* Allows all project resources to be tracked for accounting and configuration management\n\nUsing a single project across nonproduction and production ensures that all project (or application) resources are tracked and allocated to the project. Projects enforce resource tagging and track resource providence, approvals, and so on. This ensures that accounting and configuration management needs are covered.\n* Only one schematics agent is needed per BU","title":"","source":"https:\/\/cloud.ibm.com\/docs\/enterprise-account-architecture?topic=enterprise-account-architecture-bu-admin-account"},{"document_id":"ibmcld_12791-3746-5818","score":24.4445238875,"text":"\nTable 2. Roles and example actions for a policy on all IAM account management services\n\n Roles Actions \n\n Viewer All viewer role actions for IAM services \n Operator All operator role actions for IAM services \n Editor All editor role actions for IAM services and the ability to create resource groups \n Administrator All administrator role actions for IAM services and the ability to create resource groups \n User API key creator Create API keys when the account setting to restrict API key creation is enabled \n Service ID creator Create service IDs when the account setting to restrict service ID creation is enabled \n\n\n\nSome roles that you might assign on a policy for All IAM Account Management services affect only certain resources. For example, the role Service ID Creator is relevant to only the IAM Identity service.\n\n\n\n\n\n Billing \n\nYou can give users access to update account settings, view subscriptions, view offers, apply subscription and feature codes, update spending limits, and track usage by using the Billing service.\n\n\n\nTable 3. Roles and example actions for the Billing service\n\n Roles Actions \n\n Viewer View account feature settings<br><br>View subscriptions in account<br><br>View account name<br><br>View subscription balances and track usage \n Operator View account feature settings<br><br>View subscriptions in account<br><br>View and change account name \n Editor View and update account feature settings<br><br>View subscriptions in account<br><br>View offers in account<br><br>View and apply subscription and feature codes<br><br>View and change account name<br><br>View and update spending limits<br><br>Set spending notifications<br><br>View subscription balances and track usage \n Administrator View and update account feature settings<br><br>View subscriptions in account<br><br>View offers in account<br><br>View and apply subscription and feature codes<br><br>View and change account name<br><br>View and update spending limits<br><br>Set spending notifications<br><br>View subscription balances and track usage<br><br>Create an enterprise","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-account-services"},{"document_id":"ibmcld_07819-7-2471","score":23.7488574319,"text":"\nPL-4 - Rules of Behavior \n\n\n\n Control requirements \n\nThe organization:\n\nPL-4 (a)\n: Establishes and makes readily available to individuals requiring access to the information system, the rules that describe their responsibilities and expected behavior with regard to information and information system usage;\n\nPL-4 (b)\n: Receives a signed acknowledgment from such individuals, indicating that they have read, understand, and agree to abide by the rules of behavior, before authorizing access to information and the information system;\n\nPL-4 (c)\n: Reviews and updates the rules of behavior [IBM Assignment: at least every annually]; and\n\nPL-4 (d)\n: Requires individuals who have signed a previous version of the rules of behavior to read and re-sign when the rules of behavior are revised\/updated.\n\n\n\n\n\n Additional IBM Cloud for Financial Services specifications \n\nCustomer consent must be obtained prior to releasing any data outside its intended use.\n\nOrganization must have resources in place that are accountable for data management (Data Quality and Control).\n\nThe organization shall ensure their resources do not conduct customer business using non-customer institution accounts unless approved by the customer (e.g. personal email, social media, and blogs).\n\nRules of behavior must include data handling requirements according to customer\u2019s security classification, including but not limited to:\n\n\n\n* Clear desk policy to safeguard sensitive information\n* Customer data may not be stored on laptops or mobile devices\n* When users stop work and move away from the immediate vicinity of the system, screen locks must be used to conceal information previously visible on the display with a publicly viewable image\n* Credentials must not be shared and must be rotated and stored in accordance with authentication and encryption policies\n* Collaboration spaces must be secured and data only shared with authorized individuals granted permissions to access the data\n\n\n\nRules of behavior must include user responsibilities and expected behavior with regard to asset\/device use and handling practices, including but not limited to:\n\n\n\n* Encryption usage\n* Safeguarding office, desk, drawer keys for storing work resources (e.g., laptops, mobile devices, documents, data)\n* Customer information must not be photographed, recorded, or taped.\n* Text and instant messaging may only be used for valid business purposes\n* Printing customer data only for authorized purposes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-pl-4"},{"document_id":"ibmcld_12791-34649-36492","score":23.6754585271,"text":"\nViewer View account feature settings<br><br>View subscriptions in account<br><br>View account name<br><br>View subscription balances and track usage crn:v1:bluemix:public:iam::::role:Viewer \n Operator View account feature settings<br><br>View subscriptions in account<br><br>View and change account name crn:v1:bluemix:public:iam::::role:Operator \n Editor View and update account feature settings<br><br>View subscriptions in account<br><br>View offers in account<br><br>View and apply subscription and feature codes<br><br>View and change account name<br><br>View and update spending limits<br><br>Set spending notifications<br><br>View subscription balances and track usage crn:v1:bluemix:public:iam::::role:Editor \n Administrator View and update account feature settings<br><br>View subscriptions in account<br><br>View offers in account<br><br>View and apply subscription and feature codes<br><br>View and change account name<br><br>View and update spending limits<br><br>Set spending notifications<br><br>View subscription balances and track usage<br><br>Create an enterprise crn:v1:bluemix:public:iam::::role:Administrator \n\n\n\nIt's possible to view subscription balances and usage from the Account settings page, but you can't view the Account settings page with the Viewer or Operator roles. To access the Account settings page and your subscription information from that page, you need the Editor role or higher.\n\n\n\n\n\n Catalog management \n\nYou can give users access to view private catalogs and catalog filters, create private catalogs, add software to private catalogs, and set catalog filters.\n\n\n\nTable 5. Roles and example actions for the catalog management service\n\n Roles Actions role_ID value \n\n Viewer View account-level filters set for the IBM Cloud catalog<br><br>View private catalogs crn:v1:bluemix:public:iam::::role:Viewer","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-account-services"},{"document_id":"ibmcld_12791-33407-34995","score":22.9545299885,"text":"\nOperator All operator role actions for IAM services crn:v1:bluemix:public:iam::::role:Operator \n Editor All editor role actions for IAM services and the ability to create resource groups crn:v1:bluemix:public:iam::::role:Editor \n Administrator All administrator role actions for IAM services and the ability to create resource groups crn:v1:bluemix:public:iam::::role:Administrator \n User API key creator Create API keys when the account setting to restrict API key creation is enabled crn:v1:bluemix:public:iam-identity::::serviceRole:UserApiKeyCreator \n Service ID creator Create service IDs when the account setting to restrict service ID creation is enabled crn:v1:bluemix:public:iam-identity::::serviceRole:ServiceIdCreator \n\n\n\nSome roles that you might assign on a policy for All IAM Account Management services affect only certain resources. For example, the role Service ID Creator is relevant to only the IAM Identity service.\n\n\n\n\n\n Billing \n\nYou can give users access to update account settings, view subscriptions, view offers, apply subscription and feature codes, update spending limits, and track usage by using the Billing service.\n\n\n\nTable 4. Roles and example actions for the Billing service\n\n Roles Actions role_ID value \n\n Viewer View account feature settings<br><br>View subscriptions in account<br><br>View account name<br><br>View subscription balances and track usage crn:v1:bluemix:public:iam::::role:Viewer \n Operator View account feature settings<br><br>View subscriptions in account<br><br>View and change account name crn:v1:bluemix:public:iam::::role:Operator","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-account-services"},{"document_id":"ibmcld_06097-4966-6150","score":22.6941867535,"text":"\nif [! \"$1\" = \"iam\" ]] && [! \"$1\" = \"pod-identity\" ]]; then\necho \"Provide a valid auth-type\"\nusage; exit 1\nfi\n\nIBMCLOUD_AUTHTYPE=$1\nSECRET=$2\n}\n\nusage - prints the usage for execution of script\nusage() {\necho \"USAGE:\nbash generate-secret.sh <auth-type> <apikey\/profile-id>\nauth-type: auth-type should be either iam or pod-identity. Provide iam to use api key, pod-identity to use trusted profile\"\n}\n\nmain\nmain() {\n\nvalidate_options \"$@\"\n\nauth_type=\"IBMCLOUD_AUTHTYPE=$IBMCLOUD_AUTHTYPE\"\n\nsecret=\n\nif [ \"$IBMCLOUD_AUTHTYPE\" == \"iam\" ]]; then\nsecret=\"IBMCLOUD_APIKEY=$SECRET\"\nelse\nsecret=\"IBMCLOUD_PROFILEID=$SECRET\"\nfi\n\nencodedValue=$(echo -e \"$auth_typen$secret\" | base64)\non certain os, base64 encoding introduces newline, removing the same here.\nencodedValue=${encodedValue\/\/$'n'\/}\n\nfetch the controller pod name\ncontrollerPodName=$(kubectl get pods -n kube-system | grep ibm-vpc-block-csi-controller | awk '{print $1}')\nerror \"$(date +\"%b %d %G %H:%M:%S\"): Unable to fetch controller pod.\"\nif [ \"$controllerPodName\" == \"\" ]]; then\necho \"$(date +\"%b %d %G %H:%M:%S\"): VPC Block CSI Driver addon is not enabled\"\nexit 1\nfi\n\necho \"apiVersion: v1\ndata:\nibm-credentials.env: $encodedValue","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-block-vpc-trusted-profiles"},{"document_id":"ibmcld_12436-1582-3738","score":22.6549016642,"text":"\nAs a workaround, during the certificate order process, you can configure a shorter domain name so that it can be used as the certificate CN in your DNS provider. Then, you can order a multi-domain SAN certificate that uses the same shortened domain as the CN, along with longer application domains that are specified as Subject Alternative Names (SANs). \n Users that have Writer or Manager service access that is scoped to secret groups are unable to create some types of secrets when they use the Secrets Manager UI. If you have Viewer platform access and Writer or Manager service access that is scoped to a Secrets Manager service secret group, it might not be possible to create secrets in the Secrets Manager dashboard that require an engine configuration, for example, IAM credentials, public certificates, or private certificates. As a workaround, you can use the Secrets Manager CLI, APIs, or SDKs to manage those secret types. \n Community plug-ins for Vault are not supported. It is not possible to integrate a community plug-in for Vault with Secrets Manager, unless it is written against a secrets engine that Secrets Manager supports. To manage IBM Cloud secrets by using the full Vault native experience, use the [stand-alone IBM Cloud plug-ins for Vault](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-faqsfaq-vault-community-plugins). \n When you delete an instance of the service, your API keys are not deleted from IAM. If you have a service ID or API key that was generated by the IAM credentials secret engine and delete your instance of Secrets Manager, you must also delete the secret from IAM. \n\n\n\n\n\n\n\n Limits \n\nConsider the following service limits as you use Secrets Manager.\n\n\n\n Account limits \n\nThe following limits apply per IBM Cloud account.\n\n\n\nTable 1. Secrets Manager limits per account\n\n Resource Limit \n\n Secrets Manager service instances Trial plan: 1 per IBM Cloud account at any time <br>Standard plan: No limit on number of instances per account \n\n\n\n\n\n\n\n Instance limits \n\nThe following limits apply to Secrets Manager service instances.\n\n\n\nTable 2. Secrets Manager limits per instance\n\n Resource Limit","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-known-issues-and-limits"},{"document_id":"ibmcld_12493-34686-35762","score":22.5245723687,"text":"\nConfigure an IAM credential with a lease duration of 1 hour and assign it to the default secret group.\n\nvault write -format=json ibmcloud\/iam_credentials\/roles\/test-iam-credentials access_groups=AccessGroupId-985dc0a3-857b-48bd-b6d6-33819da7ba42 ttl=1h description=\"My test IAM credential.\" labels=test,us-south\n\nConfigure an IAM credential with a lease duration of 1 hour and assign it to a specified secret group.\n\nvault write -format=json ibmcloud\/iam_credentials\/roles\/groups\/9ab2250f-a369-4e07-ade7-d417d63ad587\/test-iam-credential-in-group access_groups=AccessGroupId-985dc0a3-857b-48bd-b6d6-33819da7ba42 ttl=1h description=\"My test IAM credential that is assigned to a secret group.\" labels=test,us-south\n\n\n\n\n\n Output \n\nThe command returns the following output:\n\n{\n\"request_id\": \"d4150a28-1184-8864-dcd3-15b0d18da7c1\",\n\"lease_id\": \"\",\n\"lease_duration\": 0,\n\"renewable\": false,\n\"data\": {\n\"access_groups\": [\n\"AccessGroupId-985dc0a3-857b-48bd-b6d6-33819da7ba42\"\n],\n\"created_by\": \"iam-ServiceId-b7ebcf90-c7a9-495b-8ce8-bbf33cb95ca0\",\n\"creation_date\": \"2020-10-09T17:13:47Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-vault-cli"},{"document_id":"ibmcld_10529-13357-14863","score":22.2065391902,"text":"\n2. Navigate to your volume mount path that you defined earlier and list the files in your volume mount path.\n\ncd <volume_mountpath> && ls\n\nExample output\n\nbinding\n\nThe binding file includes the service credentials that you stored in the Kubernetes secret.\n3. View the service credentials. The credentials are stored as key value pairs in JSON format.\n\ncat binding\n\nExample output\n\n{\"apikey\":\"<API_key>\",\"host\":\"<ID_string>-bluemix.cloudant.com\",\"iam_apikey_description\":\"Auto generated apikey during resource-key operation for Instance - crn:v1:bluemix:public:cloudantnosqldb:us-south:a\/<ID_string>:<ID_string>::\",\"iam_apikey_name\":\"auto-generated-apikey-<ID_string>\",\"iam_role_crn\":\"crn:v1:bluemix:public:iam::::serviceRole:Writer\",\"iam_serviceid_crn\":\"crn:v1:bluemix:public:iam-identity::a\/<ID_string>::serviceid:ServiceId-<ID_string>\",\"password\":\"<ID_string>\",\"port\":443,\"url\":\"https:\/\/<ID_string>-bluemix.cloudant.com\",\"username\":\"123b45da-9ce1-4c24-ab12-rinwnwub1294-bluemix\"}\n4. Configure your app to parse the JSON content and retrieve the information that you need to access your service.\n\n\n\n\n\n\n\n\n\n Referencing the secret in environment variables \n\nYou can add the service credentials and other key value pairs from your Kubernetes secret as environment variables to your deployment.\n\n\n\n1. List available secrets in your cluster and note the name of your secret. Look for a secret of type Opaque. If multiple secrets exist, contact your cluster administrator to identify the correct service secret.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-binding"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10767-9756-11495","score":20.3965584049,"text":"\nTo estimate costs for a serverless application, you can use the [pricing calculator](https:\/\/cloud.ibm.com\/functions\/learn\/pricing).\n\n\n\n Limitless capacity \n\nIn traditional architectures, each service consumes the amount of capacity that is allocated to them and you are billed for the capacity consumption. Cloud Functions serverless architecture reduces the constraint on the granularity of your microservices architecture.\n\nWhen not in use, Cloud Functions costs nothing. Your code runs only when a specific action occurs, such as an HTTP call, database state change, or other type of event that triggers the execution of your code. You get billed by millisecond of execution time rounded up to the nearest 100 MS, not per hour of VM utilization regardless of whether that VM was doing useful work. Because you pay only when events are consumed and not based on the number of environments, you can break down your app into 100, 1000, or even more microservices.\n\n\n\n\n\n Run actions in any region \n\nIn traditional architectures, code must be running in each region to be executed there and the infrastructure for that region must also be paid for. With Cloud Functions, actions can be deployed and made available to run in any region at no extra cost. You can increase the availability and resiliency of your code without the traditional cost restrictions.\n\n\n\n\n\n Redundancy by design \n\nIn traditional architectures, apps must be redundant. With Cloud Functions, processes don't need to be highly available (HA) because serverless apps are stateless and request-event that is driven by design. By eliminating the need for explicitly creating redundancy, the stateless nature of serverless apps can significantly reduce infrastructure costs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-faas"},{"document_id":"ibmcld_00007-7-2159","score":18.422562376,"text":"\nGetting started tutorial \n\nIBM Analytics Engine Serverless instance is allocated to compute and memory resources on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n\n\n\n* [Serverless instance architecture and concepts](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts)\n* [Provisioning a serverless instance](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless)\n\n\n\n\n\n Getting started using serverless IBM Analytics Engine instances \n\nThe IBM Analytics Engine Standard Serverless plan for Apache Spark offers the ability to spin up IBM Analytics Engine serverless instances within seconds, customize them with library packages of your choice, and run your Spark workloads.\n\nCurrently, you can create IBM Analytics Engine serverless instances only in the US South region.\n\n\n\n\n\n Before you begin \n\nTo start running Spark applications in IBM Analytics Engine, you need:\n\n\n\n* An IBM Cloud\u00ae account.\n* Instance home storage in IBM Cloud Object Storage that is referenced from the IBM Analytics Engine instance. This storage is used to store Spark History events, which are created by your applications and any custom library sets, which need to be made available to your Spark applications.\n* An IBM Analytics Engine serverless instance.\n\n\n\n\n\n\n\n Provision an instance and create a cluster \n\nTo provision an IBM Analytics Engine instance:\n\n\n\n1. Get a basic understanding of the architecture and key concepts. See [Serverless instance architecture and concepts](https:\/\/cloud.ibm.com\/docs\/analyticsengine?-serverless-architecture-concepts).\n2. [Provision a serverless instance](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless)\n\n\n\n\n\n\n\n Run applications \n\nTo run Spark applications in a serverless IBM Analytics Engine instance:\n\n\n\n1. Optionally, give users access to the provisioned instance to enable collaboration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine"},{"document_id":"ibmcld_00033-7-2292","score":18.1163164257,"text":"\nFAQs \n\n\n\n What is IBM Analytics Engine serverless? \n\nThe IBM Analytics Engine Standard serverless plan for Apache Spark offers a new consumption model using Apache Spark. An Analytics Engine serverless instance does not consume any resources when no workloads are running. When you submit Spark applications, Spark clusters are created in seconds and are spun down as soon as the applications finish running. You can develop and deploy Spark SQL, data transformation, data science, or machine learning jobs using the Spark application API.\n\n\n\n\n\n What are the advantages of IBM Analytics Engine serverless instances? \n\nWith IBM Analytics Engine serverless, compute and memory resources are allocated on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine serverless instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n\n\n\n\n\n Does the IBM Analytics Engine Standard serverless plan for Apache Spark support Hadoop? \n\nNo, currently, the IBM Analytics Engine Standard serverless plan for Apache Spark only supports Apache Spark.\n\n\n\n\n\n Can I change the instance home storage of a serverless instance? \n\nNo, you can't. After an instance home storage is associated with an IBM Analytics Engine serverless instance, it cannot be changed because instance home contains all instance relevant data, such as the Spark events and custom libraries. Changing instance home would result in the loss of the Spark history data and custom libraries.\n\n\n\n\n\n How is user management and access control managed in a serverless instance? \n\nUser management and access control of an IBM Analytics Engine serverless instance and its APIs is done through IBM Cloud\u00ae Identity and Access Management (IAM). You use IAM access policies to invite users to collaborate on your instance and grant them the necessary privileges. See [Granting permissions to users](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n\n\n\n\n\n How do I define the size of the cluster to run my Spark application? \n\nYou can specify the size of the cluster either at the time the instance is created or when submitting Spark applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-faqs-serverless"},{"document_id":"ibmcld_10864-1874-4290","score":18.0827119354,"text":"\nThis comparison equates to 10 continuously running and billable processes in a single availability zone, 20 when run across 2 availability zones, and 40 when run across two regions with two zones each. To achieve the same goal with Cloud Functions, you can run them across as many availability zones or regions as you like, without having to pay a penny of incremental costs.\n\n\n\n\n\n Web apps \n\nGiven Cloud Functions\u2019s event-driven nature, it offers several benefits for user-facing applications, whereas the HTTP requests coming from the user\u2019s browser serve as the events. Cloud Functions applications use compute capacity and billed only when they are serving user requests. Idle standby or waiting mode is nonexistent. This feature makes Cloud Functions considerably less expensive when compared to traditional containers or Cloud Foundry applications. Both of those tools have idle time, waiting for inbound user requests, and you are billed for all that \u201csleeping\u201d time.\n\nFull web application can be built and run with Cloud Functions. Combining serverless APIs with static file hosting for site resources such as HTML, JavaScript, and CSS, means that you can build entirely serverless web applications. The simplicity of operating a hosted Cloud Functions environment is not having to operate anything at all. Since Cloud Functions is hosted on IBM Cloud, it is a great benefit when compared to standing up, and operating a Node.js Express or other traditional server runtime.\n\n\n\n\n\n IoT \n\nInternet of Things scenarios are often inherently sensor-driven. For example, an action in Cloud Functions might be triggered if a need to react to a sensor that exceeds a specific temperature. IoT interactions are usually stateless with the potential of high load in major spontaneous events such as natural disasters, significant weather storms, or traffic jams. A need is created for an elastic system where normal workload might be small, but needs to scale quickly with predictable response time. So the ability to handle many simultaneous events with no prior warning to the system is desirable. It is difficult to build a system to meet these requirements that use traditional server architectures. As they tend to either be underpowered, and unable to handle peak load in traffic, or be over-provisioned and highly expensive.\n\nIt is possible to implement IoT applications that use traditional server architectures.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-use_cases"},{"document_id":"ibmcld_07578-107943-110247","score":18.0626347178,"text":"\n* Port 8443 Knox\n* Port 22 SSH\n* Port 9443 Ambari\n\n\n\n* What is IBM Analytics Engine serverless?\n\nThe IBM Analytics Engine Standard serverless plan for Apache Spark offers a new consumption model using Apache Spark. An Analytics Engine serverless instance does not consume any resources when no workloads are running. When you submit Spark applications, Spark clusters are created in seconds and are spun down as soon as the applications finish running. You can develop and deploy Spark SQL, data transformation, data science, or machine learning jobs using the Spark application API.\n* What are the advantages of IBM Analytics Engine serverless instances?\n\nWith IBM Analytics Engine serverless, compute and memory resources are allocated on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine serverless instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n* Does the IBM Analytics Engine Standard serverless plan for Apache Spark support Hadoop?\n\nNo, currently, the IBM Analytics Engine Standard serverless plan for Apache Spark only supports Apache Spark.\n* Can I change the instance home storage of a serverless instance?\n\nNo, you can't. After an instance home storage is associated with an IBM Analytics Engine serverless instance, it cannot be changed because instance home contains all instance relevant data, such as the Spark events and custom libraries. Changing instance home would result in the loss of the Spark history data and custom libraries.\n* How is user management and access control managed in a serverless instance?\n\nUser management and access control of an IBM Analytics Engine serverless instance and its APIs is done through IBM Cloud\u00ae Identity and Access Management (IAM). You use IAM access policies to invite users to collaborate on your instance and grant them the necessary privileges. See [Granting permissions to users](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n* How do I define the size of the cluster to run my Spark application?\n\nYou can specify the size of the cluster either at the time the instance is created or when submitting Spark applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-107922-110226","score":18.0626347178,"text":"\n* Port 8443 Knox\n* Port 22 SSH\n* Port 9443 Ambari\n\n\n\n* What is IBM Analytics Engine serverless?\n\nThe IBM Analytics Engine Standard serverless plan for Apache Spark offers a new consumption model using Apache Spark. An Analytics Engine serverless instance does not consume any resources when no workloads are running. When you submit Spark applications, Spark clusters are created in seconds and are spun down as soon as the applications finish running. You can develop and deploy Spark SQL, data transformation, data science, or machine learning jobs using the Spark application API.\n* What are the advantages of IBM Analytics Engine serverless instances?\n\nWith IBM Analytics Engine serverless, compute and memory resources are allocated on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine serverless instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n* Does the IBM Analytics Engine Standard serverless plan for Apache Spark support Hadoop?\n\nNo, currently, the IBM Analytics Engine Standard serverless plan for Apache Spark only supports Apache Spark.\n* Can I change the instance home storage of a serverless instance?\n\nNo, you can't. After an instance home storage is associated with an IBM Analytics Engine serverless instance, it cannot be changed because instance home contains all instance relevant data, such as the Spark events and custom libraries. Changing instance home would result in the loss of the Spark history data and custom libraries.\n* How is user management and access control managed in a serverless instance?\n\nUser management and access control of an IBM Analytics Engine serverless instance and its APIs is done through IBM Cloud\u00ae Identity and Access Management (IAM). You use IAM access policies to invite users to collaborate on your instance and grant them the necessary privileges. See [Granting permissions to users](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n* How do I define the size of the cluster to run my Spark application?\n\nYou can specify the size of the cluster either at the time the instance is created or when submitting Spark applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_10864-7-2446","score":17.9983646148,"text":"\nCommon use cases \n\nThe execution model that is offered by IBM Cloud\u00ae Functions supports various use cases. The following sections include typical examples. For a more detailed discussion of Serverless architecture, example use cases, pros and cons discussion, and implementation best practices, read the excellent [Mike Roberts article on Martin Fowler's blog](https:\/\/martinfowler.com\/articles\/serverless.html).\n\n\n\n Microservices \n\nDespite their benefit, microservice-based solutions remain difficult to build by using mainstream cloud technologies, often requiring control of a complex toolchain, and separate build and operations pipelines. Small and agile teams waste too much time with infrastructural and operational complexities such as fault-tolerance, load balancing, auto scaling, and logging. These teams want a way to develop streamlined, value-added code with programming languages they already know, love, and that are best suited to solve particular problems.\n\nThe modular and inherently scalable nature of Cloud Functions makes it ideal for implementing granular pieces of logic in actions. Cloud Functions actions are independent of each other and can be implemented by using various different languages that are supported by Cloud Functions and access various backend systems. Each action can be independently deployed and managed, is scaled independently of other actions. Interconnectivity between actions is provided by Cloud Functions in the form of rules, sequences, and naming conventions. This type of environment bodes well for microservices based applications.\n\nAnother important argument in favor of Cloud Functions is the cost of a system in a disaster recovery configuration. Compare microservices with PaaS or CaaS verses using Cloud Functions by assuming that you have 10 microservices, which use containers or Cloud Foundry runtimes. This comparison equates to 10 continuously running and billable processes in a single availability zone, 20 when run across 2 availability zones, and 40 when run across two regions with two zones each. To achieve the same goal with Cloud Functions, you can run them across as many availability zones or regions as you like, without having to pay a penny of incremental costs.\n\n\n\n\n\n Web apps \n\nGiven Cloud Functions\u2019s event-driven nature, it offers several benefits for user-facing applications, whereas the HTTP requests coming from the user\u2019s browser serve as the events.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-use_cases"},{"document_id":"ibmcld_00007-1713-3490","score":17.7444502004,"text":"\nSee [Serverless instance architecture and concepts](https:\/\/cloud.ibm.com\/docs\/analyticsengine?-serverless-architecture-concepts).\n2. [Provision a serverless instance](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless)\n\n\n\n\n\n\n\n Run applications \n\nTo run Spark applications in a serverless IBM Analytics Engine instance:\n\n\n\n1. Optionally, give users access to the provisioned instance to enable collaboration. See [Managing user access to share instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n2. Optionally, customize the instance to fit the requirements of your applications. See [Customizing the instance](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-cust-instance).\n3. Submit your Spark application by using the Spark application REST API. See [Running Spark batch applications](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-batch-serverless).\n4. Submit your Spark application by using the Livy batch API. See [Running Spark batch applications using the Livy API](https:\/\/cloud.ibm.com\/docs\/analyticsengine?topic=AnalyticsEngine-livy-api-serverless).\n\n\n\n\n\n\n\n End-to-end scenario using the Analytics Engine serverless CLI \n\nTo help you get started quickly and simply with provisioning an Analytics Engine instance and submitting Spark applications, you can use the Analytics Engine serverless CLI.\n\nFor an end-to-end scenario of the steps you need to take, from creating the services that are required, to submitting and managing your Spark applications by using the Analytics Engine CLI, see [Create service instances and submit applications using the CLI](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-using-cli).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine"},{"document_id":"ibmcld_00055-7-1864","score":17.0105614741,"text":"\nProvisioning an IBM Analytics Engine serverless instance \n\nYou can create a serverless IBM Analytics Engine service instance:\n\n\n\n* [Using the IBM Cloud console](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverlessconsole-provisioning)\n* [Using the IBM Cloud command-line interface](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverlesscli-provisioning)\n* [Using the Resource Controller REST API](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverlessrest-api-provisioning)\n\n\n\nNote that you are not able to define certain limitation and quota settings while provisioning a serverless instance. These values are predefined. See [Limits and quotas for Analytics Engine instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-limits) for a list of these settings and their values.\n\nYou must have access to either the IBM Cloud\u00ae us-south (Dallas) or the eu-de (Frankurt) region.\n\n\n\n Creating a service instance from the IBM Cloud console \n\nYou can create an instance using the IBM Cloud console. To understand the concepts behind provisioning settings in the UI, see [Architecture and concepts in serverless instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts).\n\nTo create an IBM Analytics Engine instance:\n\n\n\n1. Log into the [IBM Cloud\u00ae console](https:\/\/cloud.ibm.com\/catalog).\n2. Click Sevices and select the category Analytics.\n3. Search for Analytics Engine and then click on the tile to open the service instance creation page.\n4. Choose the location in which you want the service instance to be deployed. Currently, us-south and eu-de are the only supported regions.\n5. Select a plan. Currently, Standard Serverless for Apache Spark is the only supported serverless plan.\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless"},{"document_id":"ibmcld_00052-7-2119","score":16.9819003141,"text":"\nManaging serverless instances using the IBM Cloud console \n\nYou can manage your severless instance by:\n\n\n\n* Changing configuration settings, for example, to include library add-ons or to configure instance home after you created the instance.\n* Monitoring the status of submitted applications and kernels created in the instance.\n\n\n\n\n\n Console configuration tab \n\nYou can view and edit the current configuration settings for your IBM Analytics Engine serverless instance from the IBM Cloud\u00ae Resource list.\n\n\n\n1. Access the [IBM Cloud\u00ae Resource list](https:\/\/test.cloud.ibm.com\/resources).\n2. Click Services and software, find your IBM Analytics Engine serverless instance and click the instance to see the details.\n3. Click Manage > Configuration to view:\n\n\n\n* The runtime. Currently, you can only select the Default Spark runtime which includes the geospatial, data skipping and Parquet encryption packages.\n* The instance home volume to add an instance home or change the access credentials of an existing instance home\n\n\n\n* You can set instance home after you created your IBM Analytics Engine serverless instance. Instance home must be associated with an IBM Cloud Object Storage instance. You can choose an instance:\n\n\n\n* In your account by selecting it from the list\n* From another account. For this instance, you need to enter:\n\n\n\n* The GUID of the IBM Cloud Object Storage instance\n* The endpoint\n* The region\n* The HMAC access and secret key\n\n\n\n\n\n* You can change the access credentials of an existing instance home volume. For this instance, you need to enter:\n\n\n\n* The new HMAC access and secret key\n\n\n\n\n\nFor details on how to access Object Storage, see [Using IBM Object Storage as the instance home volume](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-cos-serverless).\n* The default Spark configuration options to override configuration settings.\n\nFor a list of the default Spark configurations set for serverless instances, see [Default Spark configurations](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-conceptsdefault-spark-config).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-manage-serverless-console"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.25,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.397322007,"ndcg_cut_10":0.397322007}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16628-0-1541","score":15.0588806337,"text":"\n\n\n\n\n\n\n  About Visual Explain \n\nThe visual explain feature in IBM\u00ae watsonx.data shows the execution plan for a specified SQL query. This feature also validates the SQL query. The output results can be visualized in different formats, which can be rendered into a graph or a flow chart. Data exchange happens between single or multiple nodes within a fragment. Each fragment has a set of data that is distributed between the nodes.\n\nWith this visual explain feature, you can run the query and show the output in a distributed environment. You can output the results in different formats. When queries are run, they scan through the database. The queries retrieve table metadata to fetch the correct output.\n\nWith this visual explain feature, you can visualize the query in a graphical representation. When a query is run in the SQL editor and selects the Explain option, watsonx.data uses an EXPLAIN SQL statement on the query to create a corresponding graph. This graph can be used to analyze, fix, and improve the efficiency of your queries by saving time and cost.\n\nTo view the execution plans for a query that is run in watsonx.data SQL editor, follow the steps:\n\n\n\n1.  In the Query workspace page, enter the query and click Run on starter to get the results.\n2.  Click Explain on the screen to visualize the graphical representation of the query.\n\n\n\nOn the Explain window, click a stage to view the details on the right window. The details of each stage that is displayed are the estimate values for rows, CPU, memory, and network.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query"},{"document_id":"ibmcld_11164-6586-7646","score":13.5078021699,"text":"\n* A design document explains how load balancing is used to keep a service highly available.\n* Where multi-site failover occurs, the disaster recovery plan must explain who does what to cause the failover and ensure restart.\n* The disaster recovery plan must define how the solution works and include restore point objectives that clearly explain how much data might be lost in the outage, if any. The disaster recovery plan also includes a detailed recovery workflow for restoring services and data if a multi-availability zone failure.\n* It must confirm how the Maximum Tolerable Downtime is met and be stored on the Disaster Recovery Plan database.\n* The disaster recovery plan specifies the security controls for running in Disaster mode, if they are different from what's running in production.\n\n\n\n\n\n\n\n Management of the disaster recovery plan \n\nThe requirements that IBM Cloud follows are:\n\n\n\n* The disaster recovery plan must be updated after any major infrastructure change, major application release, and after any test.\n* It must be approved annually.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtime"},{"document_id":"ibmcld_16670-7352-7811","score":13.0862590228,"text":"\ngosales\".\"order_detail\" AS header\nON details.order_number=header.order_number\nLIMIT 10;\n4. Click the Run on button to run the query.\n5. Select Result set or Details tab to view the combined result. If required, you can save the query.\n6. Click Saved queries to view the saved queries.\n7. Click [Explain](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query) to view the logical or distributed plan of execution for a specified SQL query.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-tutorial_join_data"},{"document_id":"ibmcld_09988-1469-3494","score":12.6318680392,"text":"\nGo to Queries > Stored queries.\n2. Select a query.\n3. From the overflow menu, click Remove.\n4. Confirm your choice by clicking Remove again.\n\n\n\n\n\n\n\n\n\n Query history \n\nTo access the page, go to Queries > Query history or select Query history from the home page.\n\nWhen you are on the Query history page, you can do the following:\n\n\n\n* View your data in a table or card view.\n* Export data to export your query history to a data file.\n* Sort any column by placing the cursor on the column header.\n* Find specific queries by using various filtering criteria.\n\nFor example, you can use it to find queries that are submitted by a particular user or group, or queries that run on a particular database.\n* Search the query history but clicking Search. You can use a predefined search criteria, or create a new search option.\n* Select the columns to display in the table.\n\nClick the settings icon next to the Find query history field to edit columns.\n* View metrics, access the explain graph, explain summary, explain verbose, explain distribution pages, and view the plan file and statistics status.\n\n\n\n\n\n Query history columns \n\n\n\n* Start time Specifies the time when the query started.\n* End time Specifies the time when the query finished.\n* Elapsed time Specifies the time that it took the query to run.\n* Query text Specifies the SQL command of the query.\n* Database Specifies the name of the database on which the query ran.\n* Schema Specifies the schema that was used for the query.\n* User name Species the name of the user that ran the query.\n* Group Specifies the group of users from which the query originates.\n* Result rows Specifies the number of result rows that were returned by the query.\n* Prep time Specifies the preparation time that was needed for the query.\n* Status Specifies the completion status of the query.\n* Plan ID Specifies the ID of the system-generated plan for the query.\n* Client IP Specifies the IP of the client that ran the SQL query.\n* GRA time Specifies the time that the query spent at the GRA.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-queries"},{"document_id":"ibmcld_09888-10897-12309","score":12.3014186038,"text":"\n* [Connections in C MQI&JMS programs](https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-mqoc_connect_app_ssl)\n\n\n\n\n\n\n\n Enabling TLS between a client and a queue manager \n\nIf TLS security has not been enabled on a queue manager, the following document explains how to correctly configure a queue manager. This walkthrough covers an \"anonymous\" one-way TLS connection as well as a \"mutual\" two-way connection.\n\n\n\n* [Enabling TLS between a client and a queue manager](https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-mqoc_jms_tls)\n\n\n\n\n\n\n\n Advanced Message Security (AMS) \n\nThe following documents explains queue manager advanced message security, and how to enable it, along with application advanced message security.\n\n\n\n* [Enabling queue manager Advanced Message Security (AMS)](https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-mqoc_qm_ams)\n* [Enabling application Advanced Message Security (AMS)](https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-mqoc_app_ams)\n\n\n\nThe queue manager you wish to apply AMS to must not have TLS already enabled on it.\n\n\n\n\n\n Refreshing the queue manager TLS security \n\nA TLS security refresh will be needed if a change has been made to the queue manager key store or trust store, otherwise the change won't take effect. The following document explains this process:\n\n\n\n* [Refreshing the queue manager TLS security](https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-mqoc_refresh_security)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-security"},{"document_id":"ibmcld_00499-6096-7785","score":12.2052376018,"text":"\nIf two or more candidate indexes still exist, the index with the first alphabetical name is chosen.\n* If a json type index and a text type index might both satisfy a selector, the json index is chosen by default.\n* The text type index is chosen when the following conditions are met:\n\n\n\n* A json type index and a text type index exist in the same field (for example fieldone).\n* The selector can be satisfied only by using a text type index.\n\n\n\n\n\nFor example, assume that you have a text type index and a json type index for the field foo, and you want to use a selector similar to the following sample:\n\n{\n\"foo\": {\n\"$in\": [\"red\",\"blue\",\"green\"]\n}\n}\n\nIBM Cloudant Query uses the text type index because a json type index can't satisfy the selector.\n\nHowever, you might use a different selector with the same indexes:\n\n{\n\"foo\": {\n\"$gt\": 2\n}\n}\n\nIn this example, IBM Cloudant Query uses the json type index because both types of indexes can satisfy the selector.\n\nTo identify which index is being used by a particular query, send a POST to the _explain endpoint for the database, with the query as data. The details of the index in use are shown in the index object within the result.\n\nSee the following example that uses HTTP to show how to identify the index that was used to answer a query:\n\nPOST \/movies\/_explain HTTP\/1.1\nHost: $SERVICE_URL\nContent-Type: application\/json\n{\n\"selector\": {\n\"$text\": \"Pacino\",\n\"year\": 2010\n}\n}\n\nSee the following example that uses the command line to show how to identify the index that was used to answer a query:\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl \"$SERVICE_URL\/movies\/_explain\" \t-X POST \t-H \"Content-Type: application\/json\" \t-d '{\n\"selector\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-selector-expressions"},{"document_id":"ibmcld_00539-3574-5364","score":12.1893534686,"text":"\nThe [POST \/{db}\/_explain](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=javapostexplain) API endpoint when passed a JSON object that is usually sent to the [POST \/{db}\/_find](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostfind) endpoint, explains how such a query is handled and which indexes, if any, might be used.\n\nIf the index object in the response indicates that \"all_docs\" is being used, a full database scan is required to service the query. We recommend that you use the _explain mechanism to check each IBM Cloudant query to ensure it is using an index before you deploy to production.\n\nFor example, a type=json index on firstname, surname and date is suitable for finding documents for:\n\n\n\n* A known firstname, lastname, and date.\n* A known firstname, lastname, and a range of date values (that use $lt, $lte, $gt, $gte operators).\n* A known firstname and lastname sorted by date.\n\n\n\nIt can also be used to assist queries on firstname, surname, date, and other attributes. In other words, it might be able to answer only part of the query but it can help reduce the number of documents that are scanned to find the answer.\n\n\n\n\n\n How can I ensure that my query is efficent? \n\nIdeally, an IBM Cloudant Query execution would need to scan only one document for each document returned. If a query has to scan a million documents for each one returned, it is clearly not optimal, and is in need of a secondary index to help.\n\nWhen you execute a query, passing execution_stats: true as an extra parameter forces IBM Cloudant to enumerate the number of documents it scanned in performing the query, for example:\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"sort\": [\"date\"],\n\"limit\": 10,\n\"execution_stats\": true\n}\n\nThe returned data now includes an extra JSON object:\n\n{\n...","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-using-cloudant-query"},{"document_id":"ibmcld_02934-31538-33861","score":12.0173181852,"text":"\nFor Not found responses (that are displayed when the user does not provide a valid value), you can choose one of these actions to perform:\n\n\n\n* Wait for user input (Default): Pauses the conversation and your assistant waits for the user to respond. In the simplest case, the text you specify here can more explicitly state the type of information you need the user to provide. If you use this action with a conditional response, be sure to word the conditional response such that you clearly state what was wrong with the user's answer and what you expect them to provide instead.\n* Prompt again: After displaying the Not found response, your assistant repeats the slot prompt again and waits for the user to respond. If you use this action with a conditional response, the response can merely explain what was wrong about the answer the user provided. It does not need to reiterate the type of information you want the user to provide because the slot prompt typically explains that.\n\nIf you choose this option, consider adding at least one variation of the Not found response so that the user does not see the exact same text more than once. Take the opportunity to use different wording to explain to the user what information you need them to provide and in what format.\n* Skip this slot: Instructs your assistant to stop trying to fill the current slot, and instead, move on to the prompt for the next empty slot. This option is useful in a slot where you want to both make the slot optional and to display a prompt that asks the user for information. For example, you might have a @seating entity that captures restaurant seating preferences, such as outside, near the fireplace, private, and so on. You can add a slot that prompts the user with, Do you have any seating preferences? and checks for @seating.values. If a valid response is provided, it saves the preference information to $seating_preferences. However, by choosing this action as the Not found response next step, you instruct your assistant to stop trying to fill this slot if the user does not provide a valid value for it.\n* Skip to response: If, when the condition you define is met, you no longer need to fill any of the remaining slots in this node, choose this action to skip the remaining slots and go directly to the node-level response next.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots"},{"document_id":"ibmcld_03249-32329-34629","score":12.0173181852,"text":"\n* Wait for user input (Default): Pauses the conversation and your assistant waits for the user to respond. In the simplest case, the text you specify here can more explicitly state the type of information you need the user to provide. If you use this action with a conditional response, be sure to word the conditional response such that you clearly state what was wrong with the user's answer and what you expect them to provide instead.\n* Prompt again: After displaying the Not found response, your assistant repeats the slot prompt again and waits for the user to respond. If you use this action with a conditional response, the response can merely explain what was wrong about the answer the user provided. It does not need to reiterate the type of information you want the user to provide because the slot prompt typically explains that.\n\nIf you choose this option, consider adding at least one variation of the Not found response so that the user does not see the exact same text more than once. Take the opportunity to use different wording to explain to the user what information you need them to provide and in what format.\n* Skip this slot: Instructs your assistant to stop trying to fill the current slot, and instead, move on to the prompt for the next empty slot. This option is useful in a slot where you want to both make the slot optional and to display a prompt that asks the user for information. For example, you might have a @seating entity that captures restaurant seating preferences, such as outside, near the fireplace, private, and so on. You can add a slot that prompts the user with, Do you have any seating preferences? and checks for @seating.values. If a valid response is provided, it saves the preference information to $seating_preferences. However, by choosing this action as the Not found response next step, you instruct your assistant to stop trying to fill this slot if the user does not provide a valid value for it.\n* Skip to response: If, when the condition you define is met, you no longer need to fill any of the remaining slots in this node, choose this action to skip the remaining slots and go directly to the node-level response next. For example, if after capturing the one-way flight information, the slot prompt is, Are you buying round trip tickets?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-slots"},{"document_id":"ibmcld_03354-5778-8129","score":11.6149485264,"text":"\nAny edits you then make within the dialog skill for the Development assistant will only affect the Development assistant's dialog skill, even though you\u2019re using data from messages sent to the Production assistant.\n\nSimilarly, if you create multiple versions of a skill, you might want to use message data from one version to improve the training data of another version.\n\nYou cannot access log data from assistants that were created in other service instances.\n\n\n\n Picking a data source \n\nThe term data source refers to the logs compiled from conversations between customers and the assistant or custom application by which a dialog skill was deployed.\n\nWhen you open the Analytics page, metrics are shown that were generated by user interactions with the current dialog skill. No metrics are shown if the current skill has not been deployed and used by customers.\n\nTo populate the metrics with message data from a dialog skill or skill version that was added to a different assistant or custom application, one that has interacted with customers, complete these steps:\n\n\n\n1. Click the Data source field to see a list of assistants with log data that you might want to use.\n\nThe list includes assistants that have been deployed and to which you have access. Or you can choose to show a list of other deployments. For more information about other types of deployments, see [Show deployment IDs explained](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logslogs-deployment-id-explained).\n2. Choose a data source.\n\n\n\nStatistical information for the selected data source is displayed.\n\nNotice the list does not include skill versions. To get data that is associated with a specific skill version, you must know the time frame during which a specific skill version was used by a deployed assistant. You can select the assistant as the data source, and then filter the metrics by the appropriate dates to see only log data that was generated by the assistant while it was using the skill version.\n\n\n\n\n\n Show deployment IDs explained \n\nApplications that use the older v1 runtime API must specify a deployment ID in each messages sent using the \/message API. This ID identifies the deployed app that the call was made from. The Analytics page can use this deployment ID to retrieve and display logs that are associated with a specific live application.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13481-5443-6857","score":46.6015963939,"text":"\n.config(\"spark.hive.metastore.uris\", \"thrift:\/\/catalog.<region>.sql-query.cloud.ibm.com:9083\") \n.config(\"spark.hive.metastore.use.SSL\", \"true\") \n.config(\"spark.hive.metastore.truststore.password\", \"changeit\") \n.config(\"spark.hive.metastore.client.auth.mode\", \"PLAIN\") \n.config(\"spark.hive.metastore.client.plain.username\", '<YourDataengineCRN>') \n.config(\"spark.hive.metastore.client.plain.password\", '<YourAPIkey>') \n.config(\"spark.hive.execution.engine\", \"spark\") \n.config(\"spark.hive.stats.autogather\", \"false\") \n.config(\"spark.sql.warehouse.dir\", \"file:\/\/\/tmp\") \n only spark is allowed as the default catalog\n.config(\"metastore.catalog.default\", \"spark\") \n.enableHiveSupport() \n.getOrCreate()\nShow more\n\n\n\n\n\n Apache Hive metastore version 3.1.2 compatible client \n\nDownload the [Hive-compatible client](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/hive-metastore-standalone-client-3.1.2-sqlquery-1.0.13.jar) and place it in a directory of your Apache Spark cluster that is not on the classpath. This step is necessary, as the client is loaded into an isolated classloader to avoid version conflicts. Note that in the examples the files are placed in \/tmp\/dataengine, when you use a different folder, adjust the example accordingly.\n\nThe client differs from the Hive version 3.1.2 release by more enhancements that add support for TLS and authentication through IBM Cloud\u00ae Identity and Access Management.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_16636-0-1664","score":45.0914028691,"text":"\n\n\n\n\n\n\n  Integrating Presto with Apache Hudi using a Hudi connector \n\nYou can integrate Presto with Apache Hudi by using the Hudi connector. You can query Hudi tables that are synced to Hive metastore (HMS) using Presto's SQL interface. This combination offers the benefits of fast and interactive analytics on large-scale, high-velocity data stored in Hudi. Hudi connector uses the metastore to track partition locations. It uses underlying Hudi file system and input formats to list data files.\n\n\n\n  Configuring a catalog in Presto \n\nCreate a hudi.properties file inside \/opt\/presto\/etc\/catalog directory in the presto container.\n\n hudi.properties\nconnector.name=hudi\n\n HMS thrift URI\nhive.metastore.uri=thrift:\/\/<hostname>:<port>\n\n properties to enable connection to object-storage bucket\nhive.s3.ssl.enabled=true\nhive.s3.path-style-access=true\nhive.s3.endpoint=<Bucket API Endpoint>\nhive.s3.aws-access-key=<INSERT YOUR ACCESS KEY>\nhive.s3.aws-secret-key=<INSERT YOUR SECRET KEY>\n\n properties to enable TLS connection to HMS\nhive.metastore.thrift.client.tls.enabled=true\nhive.metastore.authentication.type=PLAIN\nhive.metastore.thrift.client.tls.truststore.path=<Truststore Path>\nhive.metastore.thrift.client.tls.truststore.password=<Truststore Password>\nhive.metastore.thrift.client.tls.keystore.path=<Keystore Path>\nhive.metastore.thrift.client.tls.keystore.password=<Keystore Password>\nShow more\n\n\n\n\n\n  Limitations \n\n\n\n1.  Connector does not support DDL or DML SQL statements. Presto can query data using the Hudi connector, but cannot directly perform write operations.\n2.  Data modifications must be done through Hudi-specific tools and workflows.\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-hudi-conn"},{"document_id":"ibmcld_16641-6629-7897","score":45.076228542,"text":"\n\"spark.sql.catalog.lakehouse.type\": \"hive\",\n\"spark.sql.catalog.lakehouse.uri\": \"<hms-thrift-endpoint-from-watsonx.data> for example (thrift:\/\/81823aaf-8a88-4bee-a0a1-6e76a42dc833.cfjag3sf0s5o87astjo0.databases.appdomain.cloud:32683) \",\n\"spark.hive.metastore.client.auth.mode\": \"PLAIN\",\n\"spark.hive.metastore.client.plain.username\": \"<hms-user-from-watsonx.data> (for example, ibmlhapikey)\",\n\"spark.hive.metastore.client.plain.password\": \"<hms-password-from-watsonx.data>\",\n\"spark.hive.metastore.use.SSL\": \"true\",\n\"spark.hive.metastore.truststore.type\": \"JKS\",\n\"spark.hive.metastore.truststore.path\": \"file:\/\/\/opt\/ibm\/jdk\/lib\/security\/cacerts\",\n\"spark.hive.metastore.truststore.password\": \"changeit\"\n}\nShow more\n* INSTANCE_ID: The Analytics Engine instance ID. For more information about how to retrieve an instance ID, see [Obtaining the service endpoints](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverlessendpoints-cli)\n* Hms-thrift-endpoint-from-watsonx.Data: Specify the credentials for watsonx.data. For more information on getting the HMS credentials, see [Getting (Hive metastore) HMS Credentials](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-hms).\n* Hms-user-from-watsonx.Data: The watsonx.data username.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-lh-config-ae"},{"document_id":"ibmcld_00029-8568-9861","score":44.8621211616,"text":"\n\"spark.hive.metastore.client.auth.mode\":\"PLAIN\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.use.SSL\":\"true\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.stats.autogather\":\"false\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.username\":\"<CHANGEME-CRN-DATA-ENGINE-INSTANCE>\",\n for spark 3.3\n\"spark.hive.metastore.truststore.path\":\"\/opt\/ibm\/jdk\/lib\/security\/cacerts\",\n for spark 3.1, spark 3.2\n\"spark.hive.metastore.truststore.path\":\"file:\/\/\/opt\/ibm\/jdk\/jre\/lib\/security\/cacerts\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.catalogImplementation\":\"hive\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.hive.metastore.jars\":\"\/opt\/ibm\/connectors\/data-engine\/hms-client\/\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.hive.metastore.version\":\"3.0\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.warehouse.dir\":\"file:\/\/\/tmp\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.catalogImplementation\":\"hive\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hadoop.metastore.catalog.default\":\"spark\"\n},\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"application\": \"cos:\/\/mybucket.ALIAS NAME\/select_query_data_engine.py\"\n\u00a0\u00a0\u00a0 }\n}\nShow more\n\nParameter values:\n\n\n\n* ALIAS NAME: specify the data engine endpoint for your region. For more information on the currently supported data engine endpoints, see [Data engine endpoints](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overviewendpoints).\n* THRIFT URL: specify the region-specific thrift URL. For example, thrift:\/\/catalog.us.dataengine.cloud.ibm.com:9083.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"},{"document_id":"ibmcld_16641-4554-5850","score":44.3361855548,"text":"\n\"spark.sql.catalog.lakehouse.type\": \"hive\",\n\"spark.sql.catalog.lakehouse.uri\": \"<hms-thrift-endpoint-from-watsonx.data> for example (thrift:\/\/81823aaf-8a88-4bee-a0a1-6e76a42dc833.cfjag3sf0s5o87astjo0.databases.appdomain.cloud:32683) \",\n\"spark.hive.metastore.client.auth.mode\": \"PLAIN\",\n\"spark.hive.metastore.client.plain.username\": \"<hms-user-from-watsonx.data> (for example, ibmlhapikey)\",\n\"spark.hive.metastore.client.plain.password\": \"<hms-password-from-watsonx.data>\",\n\"spark.hive.metastore.use.SSL\": \"true\",\n\"spark.hive.metastore.truststore.type\": \"JKS\",\n\"spark.hive.metastore.truststore.path\": \"file:\/\/\/opt\/ibm\/jdk\/lib\/security\/cacerts\",\n\"spark.hive.metastore.truststore.password\": \"changeit\"\n}\nShow more\n* BASE_URL: The Analytics Engine URL for the region where you provisioned the instance. For example, api.region.ae.ibmcloud.com.\n* INSTANCE_ID: The Analytics Engine instance ID. For more information about how to retrieve an instance ID, see [Obtaining the service endpoints](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverlessendpoints-cli).\n* hms-thrift-endpoint-from-watsonx.data: Specify the credentials for watsonx.data.\n* hms-user-from-watsonx.data: The watsonx.data username.\n* hms-password-from-watsonx.data: The watsonx.data password.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-lh-config-ae"},{"document_id":"ibmcld_00029-7452-8829","score":43.6971385254,"text":"\ntablesDF=spark.sql(\"SHOW TABLES\")\ntablesDF.show()\nstatesDF=spark.sql(\"SELECT * from COUNTRIESCAPITALS\");\nstatesDF.show()\n\ndef main():\nspark,sc = init_spark()\nselect_query_data_engine(spark,sc)\n\nif __name__ == '__main__':\nmain()\nShow more\n\nNote that for the SELECT command to work, you must pass the IBM Cloud Object Storage identifiers as one of the standard Data Engine aliases, in this example, we have used ALIAS NAME. If you do not pass the expected ones, you might see the following error: Configuration parse exception: Access KEY is empty. Please provide valid access key.\n\nselect_query_data_engine_payload.json:\n\n{\n\"application_details\": {\n\"conf\": {\n\"spark.hadoop.fs.cos.ALIAS NAME.endpoint\": \"CHANGEME\",\n\"spark.hadoop.fs.cos.ALIAS NAME.access.key\": \"CHANGEME\",\n\"spark.hadoop.fs.cos.ALIAS NAME.secret.key\": \"CHANGEME\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.truststore.password\" : \"changeit\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.execution.engine\":\"spark\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.password\":\"APIKEY-WITH-ACCESS-TO-DATA-ENGINE-INSTANCE\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.uris\":\"THRIFT URL\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.auth.mode\":\"PLAIN\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.use.SSL\":\"true\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.stats.autogather\":\"false\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.username\":\"<CHANGEME-CRN-DATA-ENGINE-INSTANCE>\",\n for spark 3.3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"},{"document_id":"ibmcld_13481-4684-5710","score":43.5253232919,"text":"\n.config(\"fs.cos.impl\", \"com.ibm.stocator.fs.ObjectStoreFileSystem\") \n.config(\"fs.stocator.scheme.list\", \"cos\") \n.config(\"fs.stocator.cos.impl\", \"com.ibm.stocator.fs.cos.COSAPIClient\") \n.config(\"fs.stocator.cos.scheme\", \"cos\") \n register the required Cloud Object Storage path used in our application, add endpoints for all buckets\n.config(\"spark.hadoop.fs.cos.us-geo.endpoint\", \"https:\/\/s3.us.cloud-object-storage.appdomain.cloud\") \n.config(\"spark.hadoop.fs.cos.us-geo.iam.endpoint\", \"https:\/\/iam.cloud.ibm.com\/identity\/token\") \n.config(\"spark.hadoop.fs.cos.us-geo.iam.api.key\", '<YourAPIkey>') \n.config(\"spark.sql.hive.metastore.version\", \"3.0\") \n directory where the Hive client has been placed\n.config(\"spark.sql.hive.metastore.jars\", \"\/tmp\/dataengine\/\") \n.config(\"spark.hive.metastore.uris\", \"thrift:\/\/catalog.<region>.sql-query.cloud.ibm.com:9083\") \n.config(\"spark.hive.metastore.use.SSL\", \"true\") \n.config(\"spark.hive.metastore.truststore.password\", \"changeit\") \n.config(\"spark.hive.metastore.client.auth.mode\", \"PLAIN\")","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_16641-2355-3755","score":43.4916464405,"text":"\nspark.sql.catalog.lakehouse.uri = <hms-thrift-endpoint-from-watsonx.data> for example (thrift:\/\/81823aaf-8a88-4bee-a0a1-6e76a42dc833.cfjag3sf0s5o87astjo0.databases.appdomain.cloud:32683)\nspark.hive.metastore.client.auth.mode = PLAIN\nspark.hive.metastore.client.plain.username = <hms-user-from-watsonx.data> (for example, ibmlhapikey)\nspark.hive.metastore.client.plain.password = <hms-password-from-watsonx.data>\nspark.hive.metastore.use.SSL = true\nspark.hive.metastore.truststore.type = JKS\nspark.hive.metastore.truststore.path = file:\/\/\/opt\/ibm\/jdk\/lib\/security\/cacerts\nspark.hive.metastore.truststore.password = changeit\nShow more\n\n\n\nParameter value:\n\n\n\n* Hms-thrift-endpoint-from-watsonx.Data: Specify the credentials for watsonx.data.\n* Hms-user-from-watsonx.Data: The watsonx.data username.\n* Hms-password-from-watsonx.Data: The watsonx.data password.\n\n\n\n\n\n\n\n Configuring Analytics Engine instance by using Analytics Engine API \n\nTo configure your IBM Analytics Engine instance from the Analytics Engine API, complete the following steps:\n\n\n\n1. Generate an IAM token to connect to the IBM Analytics Engine API. For more information about how to generate an IAM token, see [IAM token](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverlessendpoints-cli).\n2. Run the following API command to invoke the Analytics Engine API by using the generated IAM token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-lh-config-ae"},{"document_id":"ibmcld_13481-7-1988","score":41.4140289187,"text":"\nConnecting Apache Spark with Data Engine \n\nIBM Cloud\u00ae Data Engine catalog provides an interface that is compatible with Apache Hive metastore. This unified metadata repository enables any Big Data engine, such as Apache Spark, to use Data Engine as metastore. The same definition for tables and views can be created once and used from any connected engine. Each instance of Data Engine exports its catalog as a database called default.\n\n\n\n Catalog usage within Data Engine \n\nThe Catalog can be used in Data Engine in read and write mode. Seamless access is configured without any configuration steps needed.\n\n\n\n\n\n Connecting Apache Spark with Data Engine \n\nWhen you use the Hive metastore compatible interface, access is limited to read only operations. Thus, existing tables and views can be used, but not modified.\n\nDepending from where you want to connect to your catalog, the steps may vary.\n\n\n\n Usage within Watson Studio Notebooks \n\nWatson Studio has the compatible Hive metastore client already included. It also includes a convenience library to configure the connection to the Hive metastore. Set the required variables (CRN and apikey) and call the helper function to connect to the Hive metastore:\n\n change the CRN and the APIkey according to your instance\ncrn='yourDataengineCRN'\napikey='yourAPIkey'\n\nfrom dataengine import SparkSessionWithDataengine\n\n call the helper function to create a session builder equipped with the correct config\nsession_builder = SparkSessionWithDataengine.enableDataengine(crn, apikey, \"public\")\nspark = session_builder.appName(\"Spark DataEngine integration test\").getOrCreate()\n\nDisplay your tables and run an SQL statement:\n\nspark.sql('show tables').show(truncate=False)\n\n replace yourTable with a valid table. Do not use the sample tables as you do not have access to the data!\nspark.sql('select * from yourTable').show()\n\n\n\n\n\n Usage with IBM Analytics Engine \n\nThe Hive metastore client is also already included in IBM\u00ae Analytics Engine.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_13481-6212-7871","score":41.0305231041,"text":"\nDownload the [Hive-compatible client](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/hive-metastore-standalone-client-3.1.2-sqlquery-1.0.13.jar) and place it in a directory of your Apache Spark cluster that is not on the classpath. This step is necessary, as the client is loaded into an isolated classloader to avoid version conflicts. Note that in the examples the files are placed in \/tmp\/dataengine, when you use a different folder, adjust the example accordingly.\n\nThe client differs from the Hive version 3.1.2 release by more enhancements that add support for TLS and authentication through IBM Cloud\u00ae Identity and Access Management. For user, specify the CRN and for password a valid API key with access to your Data Engine. Find the endpoint to use in the following table.\n\n\n\nTable 1. Region endpoints\n\n Region Endpoint \n\n us-south thrift:\/\/catalog.us.dataengine.cloud.ibm.com:9083 \n eu-de thrift:\/\/catalog.eu-de.dataengine.cloud.ibm.com:9083 \n\n\n\n\n\n\n\n Convenience libraries to configure Spark \n\nWhile the Data Engine catalog is compatible with the Hive metastore and can be used as any other external Hive metastore server, an SDK is provided to minimize the steps that are needed to configure Apache Spark. The SDK simplifies connecting to the Hive metastore and IBM Cloud Object Storage buckets referenced by tables or views.\n\nIn case of using Python download both, the Scala and the Python SDK, and place them in a folder that is in the classpath of your Apache Spark cluster. When using Scala, the Scala SDK is enough.\n\n\n\n* [spark-dataengine-scala](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/dataengine-spark-integration-1.4.51.jar)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.6049306995}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-1672-3877","score":29.8500100656,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":27.5699817071,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-7-2225","score":24.0330873963,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04111-35313-36062","score":20.2212606136,"text":"\nGet Bot Management settings. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/score_source} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Timeseries. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/timeseries} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Top Attributes. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/top_ns} internet-svcs.security.read internet-svcs.bot-analytics.read","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_04105-5067-6335","score":19.6342236961,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04146-1603-3385","score":19.5118381651,"text":"\nhttp.request.method String POST The HTTP method, in upper case \n http.request.uri String \/articles\/index?section=539061&expand=comments The absolute URI of the request \n http.request.uri.path String \/articles\/index The path of the request \n http.request.uri.query String section=539061&expand=comments The whole query string, minus the delimiting prefix \"?\" \n http.user_agent String Mozilla\/5.0 (X11; Linux x86_64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/65.0.3325.181 Safari\/537.36 The whole HTTP user agent \n http.x_forwarded_for String The full X-Forwarded-For HTTP header \n ip.src IP address 93.155.208.22 The client TCP IP address, which can be adjusted to reflect the real client IP of the original client as applicable (for example, using HTTP headers like X-Forwarded-For or X-Real-IP) \n ip.geoip.asnum Number 222 The [Autonomous System](https:\/\/ibm.biz\/BdzqdD) (AS) number \n ip.geoip.country String GB The [2-letter country code](https:\/\/www.iso.org\/obp\/ui\/search\/code\/) \n ssl Boolean true Whether the HTTP connection to the client is encrypted \n\n\n\nThese standard fields follow the naming convention of the Wireshark display field reference. However, some subtle variations might exist in the preceding example values.\n\nIn addition to the standard fields, the following Cloudflare-defined fields are also available:\n\n\n\nTable 2. Available Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"},{"document_id":"ibmcld_04146-2946-5057","score":19.5118381651,"text":"\nAvailable Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet. It is rare to see values above 60, so tune your firewall rules to challenge those above 10, and to block those above 50. \n\n\n\n\n\n\n\n\n\n Functions \n\nThe firewall rules language has a number of functions to convert fields.\n\nThese are not currently supported in the CIS UI Visual Expression Builder.\n\n\n\nTable 3. Firewall rules functions\n\n Function name Argument types Return type Usage example Notes \n\n lower String String lower(http.host) == \"www.example.com\" Converts a string field to lowercase. Only uppercase ASCII bytes are being converted, every other bytes are left as-is. \n upper String String upper(http.host) == \"www.example.com\" Converts a string field to uppercase. Only lowercase ASCII bytes are being converted, every other bytes are left as-is. \n\n\n\n\n\n\n\n Expressions \n\nAn expression returns true or false based on a match against incoming traffic. For example:\n\nhttp.host eq \"www.example.com\" and ip.src in 92.182.212.0\/24\n\nIn this example, two single expressions comprise a compound expression. Think of each single expression as a condition. Each condition is evaluated individually before applying and logic to determine the final result of the compound expression.\n\nLooking at the first single expression, you can see that it contains:\n\n\n\n* a field - http.host\n* a comparison operator - eq\n* a value - \"www.example.com\"\n\n\n\nNot all conditions have the same structure. Additional examples using different structures are discussed in the next section.\n\n\n\n Comparison operators \n\nThe following comparison operators are available for use in expressions:\n\n\n\nTable 4. Comparison operators for expressions\n\n English C-like Description \n\n eq == Equal \n ne != Not equal","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"},{"document_id":"ibmcld_04111-34153-35639","score":18.529220488,"text":"\nGET \/v1\/{crn}\/zones\/{domain_id}\/setting\/origin_error_page_pass_thru internet-svcs.zones.update internet-svcs.origin-error-page-pass-thru-setting.update \n Get brotli compression settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/brotli internet-svcs.performance.read internet-svcs.brotli-setting.read \n Update brotli compression settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/brotli internet-svcs.performance.update internet-svcs.brotli-setting.update \n Get Email obfuscation settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/email_obfuscation internet-svcs.security.read internet-svcs.email-obfuscation-setting.read \n Update Email obfuscation settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/email_obfuscation internet-svcs.security.update internet-svcs.email-obfuscation-setting.update \n Get ciphers settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/ciphers internet-svcs.security.read internet-svcs.ciphers-setting.read \n Update ciphers settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/ciphers internet-svcs.security.update internet-svcs.ciphers-setting.update \n\n\n\n\n\n\n\n Bot Management \n\n\n\nTable 22. Bot Management\n\n Action Method IAM ACTION AT ACTION \n\n Get Bot Management settings. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_16286-1338-3308","score":18.0657647324,"text":"\nClick Next to begin app registration.\n\n\n\n\n\n App registration \n\n\n\n1. Go to the [Microsoft Azure portal](https:\/\/portal.azure.com\/), and log in with your admin credentials.\n2. On the App registrations page, click New registration.\n3. On the Register an application page, enter a name, select the multi-tenant option that applies to your app, and then click Register.\n4. Copy the application ID from the Overview page of your app, and paste it into the App registration field of your Watson Assistant Microsoft Teams integration.\n5. On the same Microsoft Azure Overview page, click the hyperlink Add a certificate or secret next to Client Credentials.\n6. On the Certificates & secrets page for token creation, click New client secret. Enter a description and then select Recommended 180 days. Click Add.\n7. Copy the string under Value and paste into Client secret value on the App registration page of your Watson Assistant Microsoft Teams integration. Note: You must generate a new value before the current one expires on day 180.\n8. Click Next to create your bot.\n\n\n\n\n\n\n\n Create your bot \n\n\n\n1. Go to the [Microsoft Bot Framework developer portal](https:\/\/dev.botframework.com\/bots\/new), and log in with your admin credentials.\n2. On the Tell us about your bot page, complete your bot profile.\n3. Copy the generated endpoint from the Create your bot page of your Watson Assistant Microsoft Teams integration and paste into the Messaging endpoint field of the Configuration section.\n4. Select Multi-Tenant as the app type.\n5. Copy and paste your app ID, and then click Register.\n6. On the Connect to channels page, click Configure Microsoft Teams channel in the Add a featured channel section.\n7. On the Configure Microsoft Teams page, specify options in the Messaging, Calling, and Publish tabs that fit your bot needs, and then click Save.\n8. In your Watson Assistant Microsoft Teams integration, click Next to create your Teams app.\n\n\n\n\n\n\n\n Create your Teams app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-microsoft-teams"},{"document_id":"ibmcld_04170-7-2189","score":17.9435401698,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-5067-6335","score":29.2168555332,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":28.6863234255,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04170-7-2189","score":27.4497663827,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04168-6066-7283","score":26.4398829927,"text":"\n* [Querying Edge Functions metrics with GraphQL](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-edge-func)\n* [Querying firewall events with GraphQL](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-firewall-events-example)\n\n\n\n* Working with alerts\n\n\n\n* [Configuring alert policies](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-policies)\n* [Configuring webhooks](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-webhooks)\n* [Creating alerts by type](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-create-alerts-by-type)\n\n\n\n* Working with Bot management\n\n\n\n* [About bot management](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt)\n* [Machine learning models](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models)\n* [JavaScript detections](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections)\n\n\n\n* Enhancing security\n\n\n\n* [Managing access for CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-iam-and-cis)\n* [Learning about CIS architecture and workload isolation](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-compute-isolation)\n* [Securing your data in CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mng-data)\n* [Auditing events for CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_events)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-http-concepts"},{"document_id":"ibmcld_04107-4464-6614","score":24.3412276395,"text":"\n* Specific URLs - For example, you can allow IP 1.2.3.4 access to directory example.com\/foo\/ and allow IP 5.6.7.8 access to directory example.com\/bar\/, but not allow the reverse.\n\n\n\nThis capability is useful when you need more granularity in your access rules because, with IP rules, you can either apply the block to all subdomains of the current domain, or all domains on your account. You cannot specify URIs.\n\n\n\n\n\n\n\n Firewall rules \n\nCreate rules that examine incoming HTTP traffic against a set of filters to block, challenge, log, or allow matching requests.\n\nIn general, firewall rules are designed for properties that are exposed in OSI Layer-7 (HTTP), such as request headers and body content characteristics. Therefore, firewall rules apply to HTTP\/HTTPS [Range](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-range) apps.\n\n\n\n\n\n Events \n\nView events that are triggered by an active web application firewall rule. For each event, you can change the triggered action based on the requesting IP address, or the requesting region as a whole.\n\n\n\n\n\n Range \n\nExtend the power of CIS DDoS, TLS, and IP firewall to your web servers and your TCP-based services by using Range applications, keeping them online and secure.\n\n\n\n\n\n Advanced security \n\nAdvanced security settings include the following features, which you can change, enable, or disable.\n\n\n\n* Browser integrity check - The browser integrity check looks for HTTP headers that are commonly abused by spammers. It denies traffic with those headers access to your page. It also blocks or challenges visitors that do not have a user agent, or who add a nonstandard user agent. This tactic is commonly used by abuse bots, crawlers, or APIs.\n* Challenge passage - Controls how long a visitor that passed a challenge (or JavaScript challenge) gains access to your site before they are challenged again. This challenge is based on the visitor's IP, and therefore does not apply to challenges presented by WAF rules because they are based on an action that the user performs on your site.\n* Security level - Sets the security level of your website to determine which visitors receive a challenge page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_04172-7-2047","score":23.665085486,"text":"\nAccessing log fields \n\nIf fields are not specified in the request, a limited set of default fields are returned. Find the full list of all available fields using the following request.\n\nibmcloud cis logpull DNS_DOMAIN_ID --available-fields\n\nFields are passed as a comma-separated list. For example, to have \"ZoneID\" and \"RayID\", use:\n\nibmcloud cis logpull DNS_DOMAIN_ID --start 2019-01-02T01:00:00+00:00 --end 2019-01-02T01:00:00+00:00 --fields ZoneId,RayID\n\n\n\n Available Fields \n\nThe following tables describe the fields available by log category.\n\n\n\n HTTP requests \n\nThis table contains the fields available for HTTP requests.\n\n\n\nTable 1. HTTP events\n\n Field Value Type \n\n BotScore Cloudflare Bot Score (available for Bot Management customers; please contact your account team to enable) int \n BotScoreSrc Underlying detection engine or source on where a Bot Score is calculated. Possible values are Not ComputedHeuristicsMachine LearningBehavioral AnalysisVerified Bot string \n CacheCacheStatus unknownmissexpiredupdatingstalehitignoredbypassrevalidated string \n CacheResponseBytes Number of bytes returned by the cache int \n CacheResponseStatus HTTP status code returned by the cache to the edge; all requests (including non-cacheable ones) go through the cache; also see CacheStatus field int \n CacheTieredFill Tiered Cache was used to serve this request bool \n ClientASN Client AS number int \n ClientCountry Country of the client IP address string \n ClientDeviceType Client device type string \n ClientIP IP address of the client string \n ClientIPClass unknowncleanbadHostsearchEnginewhitelistgreylistmonitoringServicesecurityScannernoRecordscanbackupServicemobilePlatformtor string \n ClientRequestBytes Number of bytes in the client request int \n ClientRequestHost Host requested by the client string \n ClientRequestMethod HTTP method of client request string \n ClientRequestPath URI path requested by the client string \n ClientRequestProtocol HTTP protocol of client request string \n ClientRequestReferer HTTP request referrer string","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-log-fields"},{"document_id":"ibmcld_04118-5438-6061","score":22.4424097425,"text":"\nAdvanced rate limiting No No Yes Yes Yes \n Bot management No No No Yes No \n\n\n\n\n\n Deprecated plans \n\nThe following plans are scheduled for deprecation or deprecated.\n\n\n\n* The Standard plan reached the end of marketing on 30 April 2023. End of support is not yet determined.\n* Enterprise Package, Enterprise GLB, and Enterprise Security plans will reach the end of marketing on 31 August, 2023. End of support is not yet determined.\n\n\n\nFor more information about changing to a new plan if you are currently on a deprecated plan, see [Transitioning to updated plans](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transition-plans).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-plan-comparison"},{"document_id":"ibmcld_04175-0-1274","score":22.049681313,"text":"\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models"},{"document_id":"ibmcld_04170-1738-2974","score":21.2169922396,"text":"\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed. Your CSP should allow scripts that are served from your origin domain (script-src self).\n* If your CSP uses a nonce for script tags, CIS adds these nonces to the scripts it injects by parsing your CSP response header.\n* If your CSP does not use nonce for script tags and JavaScript Detection is enabled, you might see a console error such as\n\nRefused to execute inline script because it violates the following Content Security Policy directive: \"script-src 'self'\". Either the 'unsafe-inline' keyword, a hash ('sha256-b123b8a70+4jEj+d6gWI9U6IilUJIrlnRJbRR\/uQl2Jc='), or a nonce ('nonce-...') is required to enable inline execution.\n* It is not recommended to use unsafe-inline. Instead, it is recommend that you use CSP nonces in script tags which are parsed and supported in the CDN.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04105-7-2225","score":20.900234739,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.5,"ndcg_cut_5":0.5,"ndcg_cut_10":0.5}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-5067-6335","score":30.6219569676,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":30.5530285815,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04170-7-2189","score":29.5442234838,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04168-6066-7283","score":28.4781502045,"text":"\n* [Querying Edge Functions metrics with GraphQL](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-edge-func)\n* [Querying firewall events with GraphQL](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-firewall-events-example)\n\n\n\n* Working with alerts\n\n\n\n* [Configuring alert policies](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-policies)\n* [Configuring webhooks](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-webhooks)\n* [Creating alerts by type](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-create-alerts-by-type)\n\n\n\n* Working with Bot management\n\n\n\n* [About bot management](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt)\n* [Machine learning models](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models)\n* [JavaScript detections](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections)\n\n\n\n* Enhancing security\n\n\n\n* [Managing access for CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-iam-and-cis)\n* [Learning about CIS architecture and workload isolation](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-compute-isolation)\n* [Securing your data in CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mng-data)\n* [Auditing events for CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_events)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-http-concepts"},{"document_id":"ibmcld_04172-7-2047","score":24.2648701338,"text":"\nAccessing log fields \n\nIf fields are not specified in the request, a limited set of default fields are returned. Find the full list of all available fields using the following request.\n\nibmcloud cis logpull DNS_DOMAIN_ID --available-fields\n\nFields are passed as a comma-separated list. For example, to have \"ZoneID\" and \"RayID\", use:\n\nibmcloud cis logpull DNS_DOMAIN_ID --start 2019-01-02T01:00:00+00:00 --end 2019-01-02T01:00:00+00:00 --fields ZoneId,RayID\n\n\n\n Available Fields \n\nThe following tables describe the fields available by log category.\n\n\n\n HTTP requests \n\nThis table contains the fields available for HTTP requests.\n\n\n\nTable 1. HTTP events\n\n Field Value Type \n\n BotScore Cloudflare Bot Score (available for Bot Management customers; please contact your account team to enable) int \n BotScoreSrc Underlying detection engine or source on where a Bot Score is calculated. Possible values are Not ComputedHeuristicsMachine LearningBehavioral AnalysisVerified Bot string \n CacheCacheStatus unknownmissexpiredupdatingstalehitignoredbypassrevalidated string \n CacheResponseBytes Number of bytes returned by the cache int \n CacheResponseStatus HTTP status code returned by the cache to the edge; all requests (including non-cacheable ones) go through the cache; also see CacheStatus field int \n CacheTieredFill Tiered Cache was used to serve this request bool \n ClientASN Client AS number int \n ClientCountry Country of the client IP address string \n ClientDeviceType Client device type string \n ClientIP IP address of the client string \n ClientIPClass unknowncleanbadHostsearchEnginewhitelistgreylistmonitoringServicesecurityScannernoRecordscanbackupServicemobilePlatformtor string \n ClientRequestBytes Number of bytes in the client request int \n ClientRequestHost Host requested by the client string \n ClientRequestMethod HTTP method of client request string \n ClientRequestPath URI path requested by the client string \n ClientRequestProtocol HTTP protocol of client request string \n ClientRequestReferer HTTP request referrer string","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-log-fields"},{"document_id":"ibmcld_04118-5438-6061","score":23.5479550216,"text":"\nAdvanced rate limiting No No Yes Yes Yes \n Bot management No No No Yes No \n\n\n\n\n\n Deprecated plans \n\nThe following plans are scheduled for deprecation or deprecated.\n\n\n\n* The Standard plan reached the end of marketing on 30 April 2023. End of support is not yet determined.\n* Enterprise Package, Enterprise GLB, and Enterprise Security plans will reach the end of marketing on 31 August, 2023. End of support is not yet determined.\n\n\n\nFor more information about changing to a new plan if you are currently on a deprecated plan, see [Transitioning to updated plans](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transition-plans).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-plan-comparison"},{"document_id":"ibmcld_04175-0-1274","score":23.4999560679,"text":"\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models"},{"document_id":"ibmcld_04105-7-2225","score":22.8991021285,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04170-1738-2974","score":22.866861271,"text":"\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed. Your CSP should allow scripts that are served from your origin domain (script-src self).\n* If your CSP uses a nonce for script tags, CIS adds these nonces to the scripts it injects by parsing your CSP response header.\n* If your CSP does not use nonce for script tags and JavaScript Detection is enabled, you might see a console error such as\n\nRefused to execute inline script because it violates the following Content Security Policy directive: \"script-src 'self'\". Either the 'unsafe-inline' keyword, a hash ('sha256-b123b8a70+4jEj+d6gWI9U6IilUJIrlnRJbRR\/uQl2Jc='), or a nonce ('nonce-...') is required to enable inline execution.\n* It is not recommended to use unsafe-inline. Instead, it is recommend that you use CSP nonces in script tags which are parsed and supported in the CDN.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04111-35313-36062","score":22.7294465063,"text":"\nGet Bot Management settings. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/score_source} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Timeseries. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/timeseries} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Top Attributes. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/top_ns} internet-svcs.security.read internet-svcs.bot-analytics.read","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04175-0-1274","score":53.4232755269,"text":"\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models"},{"document_id":"ibmcld_04105-5067-6335","score":51.3497872664,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04168-6066-7283","score":47.1769440458,"text":"\n* [Querying Edge Functions metrics with GraphQL](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-edge-func)\n* [Querying firewall events with GraphQL](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-firewall-events-example)\n\n\n\n* Working with alerts\n\n\n\n* [Configuring alert policies](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-policies)\n* [Configuring webhooks](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-webhooks)\n* [Creating alerts by type](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-create-alerts-by-type)\n\n\n\n* Working with Bot management\n\n\n\n* [About bot management](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt)\n* [Machine learning models](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models)\n* [JavaScript detections](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections)\n\n\n\n* Enhancing security\n\n\n\n* [Managing access for CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-iam-and-cis)\n* [Learning about CIS architecture and workload isolation](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-compute-isolation)\n* [Securing your data in CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mng-data)\n* [Auditing events for CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_events)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-http-concepts"},{"document_id":"ibmcld_04105-3403-5572","score":39.2854916599,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04170-7-2189","score":34.5668600026,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04136-7-2226","score":29.8370198527,"text":"\nDealing with Distributed Denial of Service attacks \n\nDistributed Denial of Service (DDoS) attacks are among the most common types of internet attacks that your website or host can encounter.\n\n\n\n What is a DDoS attack? \n\nA distributed denial of service (DDoS) attack is a malicious attempt to disrupt normal traffic of a server, service, or network by overwhelming the target or its surrounding infrastructure with a flood of internet traffic. DDoS attacks achieve effectiveness by utilizing many compromised computer systems as sources of attack traffic. Exploited machines can include computers and other networked resources such as IoT devices. From a high level, a DDoS attack is like a traffic jam clogging up a highway, preventing regular traffic from arriving at its destination.\n\n\n\n\n\n How DDoS attacks work \n\nAn attacker gains control of a network of online machines to carry out a DDoS attack. Computers and other machines (such as IoT devices) are infected with malware, turning each one into a bot (or zombie). The attacker controls the group of bots, which is called a botnet.\n\nAfter establishing a botnet, the attacker directs the machines by sending updated instructions to each bot using remote control. A targeted IP address can receive requests from a multitude of bots, causing the targeted server or network to overflow capacity. This creates a denial-of-service to normal traffic. Because each bot is a legitimate internet device, separating the attack traffic from normal traffic can be difficult.\n\n\n\n\n\n Common types of DDoS attacks \n\nDDoS attack vectors target varying components of a network connection. While nearly all DDoS attacks involve overwhelming a target device or network with traffic, attacks can be divided into three categories. An attacker can use one or multiple attack vectors, and might even cycle through these attack vectors based on countermeasures taken by the target.\n\nCommon types are:\n\n\n\n* Application layer attacks (Layer 7)\n* Protocol attacks (Layer 3 and Layer 4)\n* Volumetric attacks (amplification attacks)\n\n\n\n\n\n Application layer attacks \n\nAn application layer attack is sometimes referred to as a Layer-7 DDoS attack (in reference to the 7th layer of the OSI model).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-distributed-denial-of-service-ddos-attack-concepts"},{"document_id":"ibmcld_16516-12409-14637","score":27.9027136353,"text":"\nAnnotation tasks Assets & Tools > Documents > Tasks Machine Learning Model > Annotation Tasks \n Coreferences tab Document Annotation Machine Learning Model > Annotation Tasks > task > annotation set > document \n Dictionaries page (management) Assets & Tools > Pre-annotators > Manage Dictionaries Assets \n Dictionaries tab (mapping to classes for rule-based model) Document Annotation Rule-based Model > Rules \n Documents page Assets & Tools Assets \n Entity Types page Assets & Tools Assets \n Mentions tab Document Annotation Machine Learning Model > Annotation Tasks > task > annotation set > document \n Performance page Model Management Machine Learning Model \n Pre-annotators page Assets & Tools Machine Learning Model > Pre-annotation \n Regex tab Document Annotation Rule-based Model > Rules \n Relation Types page Assets & Tools Assets \n Relations tab Document Annotation Machine Learning Model > Annotation Tasks > task > annotation set > document \n Rules tab Document Annotation Rule-based Model \n Tasks tab Assets & Tools > Documents Machine Learning Model > Annotation Tasks \n Versions page (machine learning model) Model Management Machine Learning Model \n Versions page (rule-based model) Model Management Rule-based Model \n\n\n\n\n\n\n\n\n\n May 2018 \n\n\n\n New features and changes \n\nConfiguration issue fixed\n: A configuration issue was fixed that caused service instances in Sydney region to not appear in US South region.\n\nDeploy Model window support changes\n: In the Deploy Model window, if the region you're deploying to supports both IBM Cloud\u00ae Identity and Access Management resource groups and Cloud Foundry spaces, to see the list, you will need to choose the method of access management that your service instance uses.\n\nData collection setting added\n: Added the data collection setting on the Service Details page. For more information about data collection, see [Troubleshooting, support, and FAQs](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-troubleshootingcontent)\n\nSupport for Chinese (Traditional)\n: Added Chinese (traditional) language support.\n\nAdministrators can see number of workspaces\n: Users who have the Admin role can now see the number of workspaces that are used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-release-notes"},{"document_id":"ibmcld_16729-323776-325852","score":27.8342524561,"text":"\nA script and tool will assist you to simulate the transmission of web server log messages from a static file to Event Streams.\n\nObject Storage Event Streams\n\n+3\n\nAnalytics Engine,Data Engine,Key Protect\n\n\n\n* 3 hours\n* 2023-05-05\n\n\n\n[Enhance cloud security by applying context-based restrictions](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-cbr-enhanced-security)Enhance cloud security by applying context-based restrictions\n\nThis tutorial walks you through the process of implementing context-based restrictions (CBRs) in your IBM Cloud account. CBRs help you to secure the cloud environment further and move towards a zero trust security model.\n\nKubernetes service Object Storage\n\n+7\n\nActivity Tracker hosted event search,Container Registry,Secrets Manager,App ID,Cloudant,Key Protect,Log Analysis\n\n\n\n* 2 hours\n* 2023-06-28\n\n\n\n[Apply end to end security to a cloud application](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-cloud-e2e-security)Apply end to end security to a cloud application\n\nThis tutorial walks you through key security services available in the IBM Cloud\u00ae catalog and how to use them together. An application that provides file sharing will put security concepts into practice.\n\nKubernetes service Object Storage\n\n+8\n\nActivity Tracker hosted event search,Container Registry,Secrets Manager,App ID,Cloudant,Key Protect,Log Analysis,Cloud Internet Services (CIS)\n\n\n\n* 2 hours\n* 2023-05-05\n\n\n\n[Build, deploy, test and monitor a predictive machine learning model](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-create-deploy-retrain-machine-learning-model)Build, deploy, test and monitor a predictive machine learning model\n\nThis tutorial walks you through the process of building a predictive machine learning model, deploying the generated model as an API to be used in your applications and testing the model all of this happening in an integrated and unified self-service experience on IBM Cloud. You will then monitor the deployed model with IBM Watson OpenScale.\n\nObject Storage","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_16445-4-1979","score":27.524525422,"text":"\n{{{site.data.keyword.attribute-definition-list}}\n\n\n\n Using the machine learning model \n\nLeverage a machine learning model that you trained with Knowledge Studio for IBM Cloud Pak for Data by making it available to other Watson applications.\n\nYou can deploy or export a machine learning model. A dictionary can only be used to pre-annotate documents within Knowledge Studio.\n\nYou can also pre-annotate new documents with the machine learning model. See [Pre-annotating documents with the machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannotsire) for details.\n\n\n\n Exporting a machine learning model \n\nTo export a machine learning model as a .zip file, complete the following steps:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Versions.\n3. Choose the version of the model that you want to export, or select Export current model.\n\nIf there is only one working version of the model, create a snapshot of the current model. This versions the model, which enables you to deploy one version, while you continue to improve the current version. The option to deploy does not appear until you create at least one version.\n4. Click Export, and then click Export again to confirm.\n\n\n\n\n\n\n\n Deploying a machine learning model to IBM Watson Discovery for IBM Cloud Pak for Data \n\nWhen you are satisfied with the performance of the model, you can export a version to IBM Watson\u2122 Discovery for IBM Cloud Pak for Data. This feature enables your applications to use the deployed machine learning model to enrich the insights that you get from your data to include the recognition of entities and relations that are relevant to your domain.\n\n\n\n Before you begin \n\nYou must have administrative access to a [Discovery for IBM Cloud Pak for Data](https:\/\/cloud.ibm.com\/docs\/discovery-data) deployment.\n\n\n\n\n\n Procedure \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-publish-ml"},{"document_id":"ibmcld_16511-7-2162","score":27.3654264035,"text":"\nUsing the machine learning model \n\nLeverage a machine learning model that you trained with Knowledge Studio by making it available to other Watson applications.\n\nYou can deploy or export a machine learning model. A dictionary or Natural Language Understanding pre-annotator can only be used to pre-annotate documents within Knowledge Studio.\n\nBefore you can deploy a model for use by a service, you must have a subscription to the service. IBM Watson services are hosted on IBM Cloud\u00ae, which is the cloud platform for IBM. For more information about the platform, see [What is IBM Cloud?](https:\/\/cloud.ibm.com\/docs\/overview). To subscribe to one of the IBM Watson services, create an account from the [IBM Cloud](https:\/\/cloud.ibm.com\/) website.\n\nFor some of the services, you must know details about the service instance that you plan to deploy to, such as the IBM Cloud space name and service instance name. The space and instance name information is available from the IBM Cloud Services page.\n\nYou can also pre-annotate new documents with the machine learning model. See [Pre-annotating documents with the machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannotsire) for details.\n\n\n\n Deploying a machine learning model to IBM Watson Discovery \n\nWhen you are satisfied with the performance of the model, you can deploy a version of it to IBM Watson Discovery. This feature enables your applications to use the deployed machine learning model to enrich the insights that you get from your data to include the recognition of concepts and relations that are relevant to your domain.\n\n\n\n About this task \n\nWhen you deploy the machine learning model, you select the version of it that you want to deploy.\n\n\n\n\n\n Procedure \n\nTo deploy a machine learning model, complete the following steps:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Versions.\n3. Choose the version of the model that you want to deploy.\n\nIf there is only one working version of the model, create a snapshot of the current model.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-publish-ml"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-5067-6335","score":52.842988542,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04175-0-1274","score":49.2624443165,"text":"\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models"},{"document_id":"ibmcld_04168-6066-7283","score":47.5861117787,"text":"\n* [Querying Edge Functions metrics with GraphQL](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-edge-func)\n* [Querying firewall events with GraphQL](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-firewall-events-example)\n\n\n\n* Working with alerts\n\n\n\n* [Configuring alert policies](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-policies)\n* [Configuring webhooks](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-webhooks)\n* [Creating alerts by type](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-create-alerts-by-type)\n\n\n\n* Working with Bot management\n\n\n\n* [About bot management](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt)\n* [Machine learning models](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models)\n* [JavaScript detections](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections)\n\n\n\n* Enhancing security\n\n\n\n* [Managing access for CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-iam-and-cis)\n* [Learning about CIS architecture and workload isolation](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-compute-isolation)\n* [Securing your data in CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mng-data)\n* [Auditing events for CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_events)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-http-concepts"},{"document_id":"ibmcld_04105-3403-5572","score":37.923674451,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_16729-323776-325852","score":34.3908331564,"text":"\nA script and tool will assist you to simulate the transmission of web server log messages from a static file to Event Streams.\n\nObject Storage Event Streams\n\n+3\n\nAnalytics Engine,Data Engine,Key Protect\n\n\n\n* 3 hours\n* 2023-05-05\n\n\n\n[Enhance cloud security by applying context-based restrictions](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-cbr-enhanced-security)Enhance cloud security by applying context-based restrictions\n\nThis tutorial walks you through the process of implementing context-based restrictions (CBRs) in your IBM Cloud account. CBRs help you to secure the cloud environment further and move towards a zero trust security model.\n\nKubernetes service Object Storage\n\n+7\n\nActivity Tracker hosted event search,Container Registry,Secrets Manager,App ID,Cloudant,Key Protect,Log Analysis\n\n\n\n* 2 hours\n* 2023-06-28\n\n\n\n[Apply end to end security to a cloud application](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-cloud-e2e-security)Apply end to end security to a cloud application\n\nThis tutorial walks you through key security services available in the IBM Cloud\u00ae catalog and how to use them together. An application that provides file sharing will put security concepts into practice.\n\nKubernetes service Object Storage\n\n+8\n\nActivity Tracker hosted event search,Container Registry,Secrets Manager,App ID,Cloudant,Key Protect,Log Analysis,Cloud Internet Services (CIS)\n\n\n\n* 2 hours\n* 2023-05-05\n\n\n\n[Build, deploy, test and monitor a predictive machine learning model](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-create-deploy-retrain-machine-learning-model)Build, deploy, test and monitor a predictive machine learning model\n\nThis tutorial walks you through the process of building a predictive machine learning model, deploying the generated model as an API to be used in your applications and testing the model all of this happening in an integrated and unified self-service experience on IBM Cloud. You will then monitor the deployed model with IBM Watson OpenScale.\n\nObject Storage","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_04170-7-2189","score":33.6727395025,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04136-7-2226","score":30.2478379104,"text":"\nDealing with Distributed Denial of Service attacks \n\nDistributed Denial of Service (DDoS) attacks are among the most common types of internet attacks that your website or host can encounter.\n\n\n\n What is a DDoS attack? \n\nA distributed denial of service (DDoS) attack is a malicious attempt to disrupt normal traffic of a server, service, or network by overwhelming the target or its surrounding infrastructure with a flood of internet traffic. DDoS attacks achieve effectiveness by utilizing many compromised computer systems as sources of attack traffic. Exploited machines can include computers and other networked resources such as IoT devices. From a high level, a DDoS attack is like a traffic jam clogging up a highway, preventing regular traffic from arriving at its destination.\n\n\n\n\n\n How DDoS attacks work \n\nAn attacker gains control of a network of online machines to carry out a DDoS attack. Computers and other machines (such as IoT devices) are infected with malware, turning each one into a bot (or zombie). The attacker controls the group of bots, which is called a botnet.\n\nAfter establishing a botnet, the attacker directs the machines by sending updated instructions to each bot using remote control. A targeted IP address can receive requests from a multitude of bots, causing the targeted server or network to overflow capacity. This creates a denial-of-service to normal traffic. Because each bot is a legitimate internet device, separating the attack traffic from normal traffic can be difficult.\n\n\n\n\n\n Common types of DDoS attacks \n\nDDoS attack vectors target varying components of a network connection. While nearly all DDoS attacks involve overwhelming a target device or network with traffic, attacks can be divided into three categories. An attacker can use one or multiple attack vectors, and might even cycle through these attack vectors based on countermeasures taken by the target.\n\nCommon types are:\n\n\n\n* Application layer attacks (Layer 7)\n* Protocol attacks (Layer 3 and Layer 4)\n* Volumetric attacks (amplification attacks)\n\n\n\n\n\n Application layer attacks \n\nAn application layer attack is sometimes referred to as a Layer-7 DDoS attack (in reference to the 7th layer of the OSI model).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-distributed-denial-of-service-ddos-attack-concepts"},{"document_id":"ibmcld_16442-7-1837","score":30.1832088419,"text":"\nMachine learning model creation workflow \n\nCreate a machine learning model that trains a model you can use to identify entities, coreferences, and relationships of interest in new documents.\n\nUnderstand the typical workflow for creating a machine learning model in Knowledge Studio for IBM Cloud Pak for Data.\n\nAll the steps are performed by the project manager, except for the Annotate documents step, which is performed by the human annotator. Because human annotators are often subject matter experts, they might be consulted during the creation of workspace resources, such as the type system, also.\n\n![The workflow for developing a machine learning model](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/148d3bd95f946aa1bb53ea1540475f522e6b61c9\/watson-knowledge-studio-data\/images\/wks-checklist.svg) Figure 1. The workflow for developing a machine learning model\n\n\n\n Step Description \n\n Create a workspace See [Creating a workspace](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-create-project). A workspace contains the resources that are used to create the model, including: <br> <br>- Type system: Upload or create the type system, and define the entity types and relation types that human annotators can apply when annotating text. The model process manager typically works with subject matter experts for your domain to define the type system. See [Establishing a type system](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-typesystem) <br> <br>- Source documents: Create a corpus by uploading sample documents that are representative of your domain content into the workspace. See [Adding documents for annotation](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotation).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-ml_annotator"},{"document_id":"ibmcld_16505-7-1982","score":30.1373421794,"text":"\nMachine learning model creation workflow \n\nCreate a machine learning model that trains a model you can use to identify entities, coreferences, and relationships of interest in new documents.\n\nUnderstand the typical workflow for creating a machine learning model in Knowledge Studio.\n\nAll the steps are performed by the project manager, except for the Annotate documents step, which is performed by the human annotator. Because human annotators are often subject matter experts, they might be consulted during the creation of workspace resources, such as the type system, also.\n\n![The workflow for developing a machine learning model](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/50eddb8fd81f33092880335ff107a78ff5cd0f65\/watson-knowledge-studio\/images\/wks-checklist.svg) Figure 1. The workflow for developing a machine learning model\n\n\n\n Steps to create or refine a model \n\n\n\n Step Description \n\n Create a workspace See [Creating a workspace](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-create-project). A workspace contains the resources that are used to create the model, including: <br> <br>- Type system: Upload or create the type system, and define the entity types and relation types that human annotators can apply when annotating text. The model process manager typically works with subject matter experts for your domain to define the type system. See [Establishing a type system](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-typesystem) <br> <br>- Source documents: Create a corpus by uploading sample documents that are representative of your domain content into the workspace. See [Adding documents for annotation](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-documents-for-annotation). Partition the corpus into document sets, specify the percentage of documents that are shared among all document sets, and assign the document sets to human annotators.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-ml_annotator"},{"document_id":"ibmcld_16507-1455-3632","score":29.7687521118,"text":"\nThis choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\n\n\n\n\n Running multiple pre-annotators","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}],"retriever_scores":{}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-1672-3877","score":25.233168681,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":24.6838073938,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-7-2225","score":24.5522465796,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_03164-1607-3518","score":22.7368541869,"text":"\nFor more information about it, read the [Slack blog post](https:\/\/medium.com\/slack-developer-blog\/more-precision-less-restrictions-a3550006f9c3) about it.\n8. Assign bot token scopes to your Slack app. At a minimum, apply the following scopes:\n\n\n\n* app_mentions:read\n* chat:write\n* im:history\n* im:read\n* im:write\n\n\n\n9. Click Install App to Workspace, and then allow the installation when prompted.\n\nIf you are editing scopes for an existing application, reinstall it.\n10. From the Slack settings App Home page, enable the Always Show My Bot As Online setting.\n11. Go to the OAuth and Permissions page in Slack, copy the Bot User OAuth Access Token.\n12. From the Watson Assistant Slack integration configuration page, paste the token that you copied in the previous step into both the OAuth access token and Bot user OAuth access token fields.\n13. On the Slack app settings page, go to the Basic Information page, and then find the App Credentials section. Copy the app credential verification token.\n14. From the Watson Assistant Slack integration configuration page, paste the verification token that you copied in the previous step into the Verification token field.\n15. Click Generate request URL, and then copy the generated request URL.\n16. Return to the Slack app settings page. Open the Event Subscriptions page, and then turn on Enable Events. Paste the request URL that you copied in the previous step into the field.\n17. On the Event Subscriptions page in Slack, find the Subscribe to Bot Events section. Click Add Bot User Event, and then select the event types you want to subscribe to. You must select at least one of the following types:\n\n\n\n* message.im: Listens for message events that are posted in a direct message channel.\n* app_mention: Listens for only message events that mention your app or bot.\n\nChoose the app_mention entry in normal font, not the app_mention entry that is in bold font.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-slack"},{"document_id":"ibmcld_04170-7-2189","score":20.7868649321,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_16293-1303-3228","score":20.4193323642,"text":"\nOpen the Slack app in a new browser tab, so you can easily switch back and forth between the Slack app settings page and Watson Assistant Slack integration configuration page.\n6. From the settings page for your Slack app, open the App Home page.\n7. Add access scopes for your Slack app.\n\nThe button label might be Review Scopes to Add or Update scopes depending on whether you are creating a new app or editing an app that you created before February 2020.\n\nThe method for Slack access changed. For more information about it, read the [Slack blog post](https:\/\/medium.com\/slack-developer-blog\/more-precision-less-restrictions-a3550006f9c3) about it.\n8. Assign bot token scopes to your Slack app. At a minimum, apply the following scopes:\n\n\n\n* app_mentions:read\n* chat:write\n* im:history\n* im:read\n* im:write\n\n\n\n9. Click Install App to Workspace, and then allow the installation when prompted.\n\nIf you are editing scopes for an existing application, reinstall it.\n10. From the Slack settings App Home page, enable the Always Show My Bot As Online setting.\n11. Go to the OAuth and Permissions page in Slack, copy the Bot User OAuth Access Token.\n12. From the Watson Assistant Slack integration configuration page, paste the token that you copied in the previous step into both the OAuth access token and Bot user OAuth access token fields.\n13. On the Slack app settings page, go to the Basic Information page, and then find the App Credentials section. Copy the app credential verification token.\n14. From the Watson Assistant Slack integration configuration page, paste the verification token that you copied in the previous step into the Verification token field.\n15. Click Generate request URL, and then copy the generated request URL.\n16. Return to the Slack app settings page. Open the Event Subscriptions page, and then turn on Enable Events. Paste the request URL that you copied in the previous step into the field.\n17.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-slack"},{"document_id":"ibmcld_04111-35313-36062","score":20.2212606136,"text":"\nGet Bot Management settings. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/score_source} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Timeseries. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/timeseries} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Top Attributes. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/top_ns} internet-svcs.security.read internet-svcs.bot-analytics.read","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_04105-5067-6335","score":19.4831877745,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04111-34153-35639","score":18.529220488,"text":"\nGET \/v1\/{crn}\/zones\/{domain_id}\/setting\/origin_error_page_pass_thru internet-svcs.zones.update internet-svcs.origin-error-page-pass-thru-setting.update \n Get brotli compression settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/brotli internet-svcs.performance.read internet-svcs.brotli-setting.read \n Update brotli compression settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/brotli internet-svcs.performance.update internet-svcs.brotli-setting.update \n Get Email obfuscation settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/email_obfuscation internet-svcs.security.read internet-svcs.email-obfuscation-setting.read \n Update Email obfuscation settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/email_obfuscation internet-svcs.security.update internet-svcs.email-obfuscation-setting.update \n Get ciphers settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/ciphers internet-svcs.security.read internet-svcs.ciphers-setting.read \n Update ciphers settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/ciphers internet-svcs.security.update internet-svcs.ciphers-setting.update \n\n\n\n\n\n\n\n Bot Management \n\n\n\nTable 22. Bot Management\n\n Action Method IAM ACTION AT ACTION \n\n Get Bot Management settings. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_03403-26509-28185","score":18.2054235698,"text":"\n[Close](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/close.png) to close the edit view.\n\n\n\nNow, when you test, you can provide a set of number or a mix of numbers and text as input, and the dialog reminds you of the correct order number format. You have successfully tested your dialog, found a weakness in it, and corrected it.\n\nAnother way you can address this type of scenario is to add a node with slots. See the [Adding a node with slots to a dialog](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial-slots) tutorial to learn more about using slots.\n\n\n\n\n\n\n\n Step 5: Add the personal touch \n\nIf the user shows interest in the bot itself, you want the virtual assistant to recognize that curiosity and engage with the user in a more personal way. You might remember the General_About_You intent, which is provided with the General content catalog, that we considered using earlier, before you added your own custom about_restaurant intent. It is built to recognize just such questions from the user. Add a node that conditions on this intent. In your response, you can ask for the user's name and save it to a $username variable that you can use elsewhere in the dialog, if available.\n\n\n\n Add a node that handles questions about the bot \n\nAdd a dialog node that can recognize the user's interest in the bot, and respond.\n\n\n\n1. Click the Dialog tab.\n2. Find the Welcome node in the dialog tree.\n3. Click the More![More options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon on the Welcome node, and then select Add node below.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06881-7313-8859","score":15.212532542,"text":"\nUse the provided toggles to add or remove the vault integrations that you require as explained in [Managing IBM Cloud secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manage-secrets-ibm-cloud). This documentation gives you information on prerequisites and how to use a list of prescribed secret names that are otherwise known as hints. By using hints in a template, a toolchain can be automatically populated with preconfigured secrets without any need to manually select them from various vault integrations that are attached to the toolchain.\n\nThis tutorial uses IBM Secrets Manager as the vault for secrets. You might want to go with the secret management offering that you used during CI or CD toolchain setup.\n\nZoom\n\n![DevSecOps CC Toolchain secrets options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5eb88a2575e30e316dbb83829c7f4c8b1ddbc67c\/devsecops\/images\/devsecops-cc-toolchain-setup-Secrets-selection.png)\n\nFigure 3. DevSecOps secrets options\n\nUse [IBM Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-getting-started) to securely store and apply secrets like API keys, Image Signature, or HashiCorp Vault credentials that are part of your toolchain.\n\nZoom\n\n![DevSecOps IBM Secrets Manager](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5eb88a2575e30e316dbb83829c7f4c8b1ddbc67c\/devsecops\/images\/devsecops-cc-toolchain-setup-SM.png)\n\nFigure 4. DevSecOps IBM Secrets Manager\n\nMultiple repositories must be configured during the guided setup, as described in the next sections.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-tutorial-cc-toolchain"},{"document_id":"ibmcld_06828-8805-10601","score":14.7993408429,"text":"\nFigure 6. DevSecOps pipeline configuration\n\n\n\n\n\n Secrets \n\nSeveral tools in this toolchain require secrets to access privileged resources. An IBM Cloud API key is an example of such a secret. All secrets must be stored securely in a secrets vault and then referenced as required by the toolchain.\n\nWith IBM Cloud, you can choose from various secrets management and data protection offerings that help you to protect your sensitive data and centralize your secret. The Secrets step specifies which secret vault integrations are added to your toolchain. Use the provided toggles to add or remove the vault integrations that you require as explained in [Managing IBM Cloud secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manage-secrets-ibm-cloud). This documentation gives you information on prerequisites and how to use a list of prescribed secret names that are otherwise known as hints. By using hints in a template, a toolchain can be automatically populated with preconfigured secrets without any need to manually select them from various vault integrations that are attached to the toolchain.\n\nThis document uses IBM Secrets Manager as the vault for secrets.\n\nZoom\n\n![DevSecOps secrets options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5eb88a2575e30e316dbb83829c7f4c8b1ddbc67c\/devsecops\/images\/devsecops-secrets-options.png)\n\nFigure 7. DevSecOps secrets options\n\n\n\n\n\n IBM Key Protect \n\nUse [Key Protect](https:\/\/cloud.ibm.com\/catalog\/services\/key-protect) to securely store and apply secrets like API keys, Image Signature, or HashiCorp Vault credentials that are part of your toolchain. You must create a Key Protect Service Instance before you proceed further. If you already created a Key Protect Service Instance, you can link the same in this step.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-tekton-cd-compliance"},{"document_id":"ibmcld_16628-0-1541","score":14.6569930587,"text":"\n\n\n\n\n\n\n  About Visual Explain \n\nThe visual explain feature in IBM\u00ae watsonx.data shows the execution plan for a specified SQL query. This feature also validates the SQL query. The output results can be visualized in different formats, which can be rendered into a graph or a flow chart. Data exchange happens between single or multiple nodes within a fragment. Each fragment has a set of data that is distributed between the nodes.\n\nWith this visual explain feature, you can run the query and show the output in a distributed environment. You can output the results in different formats. When queries are run, they scan through the database. The queries retrieve table metadata to fetch the correct output.\n\nWith this visual explain feature, you can visualize the query in a graphical representation. When a query is run in the SQL editor and selects the Explain option, watsonx.data uses an EXPLAIN SQL statement on the query to create a corresponding graph. This graph can be used to analyze, fix, and improve the efficiency of your queries by saving time and cost.\n\nTo view the execution plans for a query that is run in watsonx.data SQL editor, follow the steps:\n\n\n\n1.  In the Query workspace page, enter the query and click Run on starter to get the results.\n2.  Click Explain on the screen to visualize the graphical representation of the query.\n\n\n\nOn the Explain window, click a stage to view the details on the right window. The details of each stage that is displayed are the estimate values for rows, CPU, memory, and network.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query"},{"document_id":"ibmcld_06881-6048-7948","score":14.5807808827,"text":"\n[DevSecOps CC toolchain name and region](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5eb88a2575e30e316dbb83829c7f4c8b1ddbc67c\/devsecops\/images\/devsecops-cc-toolchain-setup-toolchain-name-region.png)\n\nFigure 2. DevSecOps CC toolchain name and region\n\nYou can provide a CI toolchain already setup at this step. Using filter on the region where your CI toolchain resides helps you to find it easily.\n\nThe setup fetches the resource details such as pipeline configuration, repositories like inventory and incidence issues based on the CI toolchain provided. If you chose to not provide any details for the CI toolchain details, you need to manually provide the previous details in the later steps of the setup.\n\n\n\n\n\n Step 3: Set up CC tool integrations \n\n\n\n Secrets \n\nSeveral tools in this toolchain require secrets to access privileged resources. An IBM Cloud API key is an example of such a secret. All secrets must be stored securely in a secrets vault and then referenced as required by the toolchain.\n\nWith IBM Cloud, you can choose from various secrets management and data protection offerings that help you to protect your sensitive data and centralize your secret. In the Secrets step, you specify which secret vault integrations are added to your toolchain. Use the provided toggles to add or remove the vault integrations that you require as explained in [Managing IBM Cloud secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manage-secrets-ibm-cloud). This documentation gives you information on prerequisites and how to use a list of prescribed secret names that are otherwise known as hints. By using hints in a template, a toolchain can be automatically populated with preconfigured secrets without any need to manually select them from various vault integrations that are attached to the toolchain.\n\nThis tutorial uses IBM Secrets Manager as the vault for secrets.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-tutorial-cc-toolchain"},{"document_id":"ibmcld_06832-8119-9906","score":14.5687457977,"text":"\nHowever, if ibmcloud-api-key does not have access to git, git-token must be set.\n\n\n\n Configuring the secrets stores \n\nWith IBM Cloud, you can choose from various secrets management and data protection offerings that help you protect your sensitive data and centralize your secrets. You can choose between the vault integrations depending on your requirements as explained in [Managing IBM Cloud secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manage-secrets-ibm-cloud). This documentation provides information about prerequisites and how to use a list of prescribed secret names that are otherwise known as hints. By using hints in a template, a toolchain can be automatically populated with preconfigured secrets without any need to manually select them from various vault integrations that are attached to the toolchain.\n\nUse [IBM Cloud\u00ae Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-getting-started) to securely store and apply secrets like API keys, Image Signature, or HashiCorp Vault credentials that are part of your toolchain.\n\nZoom\n\n![Secrets Manager tool integration form](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5eb88a2575e30e316dbb83829c7f4c8b1ddbc67c\/devsecops\/images\/devsecops-secrets-manager.png)\n\nFigure 1. IBM Secrets Manager Tool Integration\n\nThe templates also come with a HashiCorp Vault tool integration like the following example:\n\nZoom\n\n![HashiCorp Vault Tool Integration form with required fields and example values](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5eb88a2575e30e316dbb83829c7f4c8b1ddbc67c\/devsecops\/images\/hc-tool-int.png)\n\nFigure 2. HashiCorp Vault Tool Integration\n\nTo use HashiCorp Vault, you must provide the following information:\n\n\n\n* Name: A name for this tool integration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-toolchains-secrets"},{"document_id":"ibmcld_12465-4-1958","score":14.4139133356,"text":"\n* UI\n* API\n* Terraform\n\n\n\n\n\n\n\n Organizing your secrets \n\nWhen you work with IBM Cloud\u00ae Secrets Manager, you can create groups to organize your secrets and control who on your team has access to them. Then, if you don't need them anymore, you can delete the groups.\n\nSimilar to the way that\n\nresource groupshelp to ensure correct policy enforcement at the platform level, you can create secret groups at the instance level to organize secrets.\n\nZoom\n\n![The image shows two examples of a secret group and how they're mapped to access groups. One where the reader role is assigned and one where the manager role is assigned. The content is explained fully in the surrounding text.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/991f60ddbe3ab0a9aa69481a07a0a73b359fa329\/secrets-manager\/\/images\/secret-group.svg)\n\nFigure 1. Assigning access to secret groups\n\nAs shown in the previous image, users with Reader access to a secret group can see that the group exists and understand which secrets are assigned to it. Users with Writer access can view and edit the secret group and secrets themselves. By design, the default secret group inherits all of the same permissions that are set for the instance.\n\nYou can choose to group your secrets by phase of development, specific to the type of roles that people on your team have, or in any way that might help you. Each secret can be mapped to one group only and the mapping occurs at the time of secret creation.\n\nTo learn about the suggested guidelines for using secret groups, check out [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n Before you begin \n\nBefore you begin, be sure that you have the required level of access. To create and manage secret groups, you need the [Manager service role](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam).\n\n\n\n\n\n Creating secret groups","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secret-groups"},{"document_id":"ibmcld_12439-7-1984","score":14.358604794,"text":"\nComparison between Secrets Manager and related IBM Cloud services \n\nWith IBM Cloud, you can choose from various secrets management and data protection offerings that help you to protect your sensitive data and centralize your secrets. If you need to integrate general-purpose secrets to authenticate your apps, you can use Secrets Manager to create\n\ndynamic secretsand manage their lifecycle. But for other application secrets, such as encryption keys, your business might require a higher level of control that relies on highly secure, customer-controlled cryptographic hardware.\n\nFor example, consider the following scenarios and how they map to secrets management offerings and data protection offerings in IBM Cloud.\n\nZoom\n\n![The image describes three use cases for secrets management and how they map to available services in IBM Cloud. The content is explained fully in the surrounding text.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/991f60ddbe3ab0a9aa69481a07a0a73b359fa329\/secrets-manager\/images\/secrets-mgmt-options.svg)\n\nFigure 1. Secrets management use cases\n\n\n\n Which data protection service is best for me? \n\nThe following table lists the different offerings that you can use with IBM Cloud to protect your application secrets.\n\n\n\nTable 1. Secrets management and data protection scenarios\n\n Scenario What to use \n\n As a DevOps team contributor, you need to create, lease, and manage API keys, credentials, database configurations, and other secrets for your services and applications. With [Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager), you can manage secrets of various types in a dedicated instance. \n You need to generate, renew, and manage SSL\/TLS certificates for your deployments. You can also manage your SSL\/TLS certificates and private keys in dedicated instance of [Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager). \n You need to create and manage encryption keys that are backed by FIPS 140-2 Level 3 validated hardware.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manage-secrets-ibm-cloud"},{"document_id":"ibmcld_13877-22396-24231","score":13.8021984623,"text":"\n* [Let's Encrypt](https:\/\/letsencrypt.org\/) to generate the TLS certificates.\n* IBM Cloud Secrets Manager to integrate with Let's Encrypt to generate the TLS certificate for secure-file-storage.example.com and securely store.\n* Kubernetes [External Secrets Operator](https:\/\/external-secrets.io\/v0.7.0\/) to pull the secret TLS certificate directly from Secrets Manager\n\n\n\n\n\n Provision a CIS and Secrets Manager instance \n\n\n\n* A [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) instance is required. Use an existing instance or create one from this [catalog entry](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services). A number of pricing plans are available, including a free trial. The provisioning process of a new CIS will explain how to configure your existing DNS registrar (perhaps not in IBM Cloud) to use the CIS-provided domain name servers. This tutorial uses example.com for the DNS name. Substitute your domain for example.com in all steps. Also export it in the shell:\n\nexport MYDOMAIN=example.com\n* A Secrets Manager instance is required. Use an existing instance or create a new one described in [Creating a Secrets Manager service instance](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-create-instance&interface=ui). If creating a new instance, name it secure-file-storage-sm. You can enhance the security of your secrets at rest by integrating with the Key Protect instance created earlier.\n\n\n\nCreate a DNS entry in the CIS instance using YOUR-CLUSTER Ingress subdomain as the alias.\n\n\n\n1. Open the CIS service instance, you can find it in the [Resource List](https:\/\/cloud.ibm.com\/resources).\n2. Click the Reliability tab on the left.\n3. Click the DNS tab on the top.\n4. Scroll down to the DNS Records section and click Add to create a new record:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tutorials?topic=solution-tutorials-cloud-e2e-security"},{"document_id":"ibmcld_06832-6601-8614","score":13.7582349835,"text":"\nServiceNow API Token servicenow-token Required: CD onlyUsed to access Service Now for change management operations \n HashiCorp Vault Role ID role-id Required: CI & CDUsed to authenticate with the HashiCorp Vault server \n HashiCorp Vault Secret ID secret-id Required: CI & CDUsed to authenticate with the HashiCorp Vault server \n IBM Cloud Object Storage Writer API Key cos-api-key Required: CI & CDUsed to authenticate with the Object Storage service - This key must have writer permission \n SonarQube password or authentication token sonarqube-password Optional: CIUsed to authenticate with the SonarQube source code analyzer \n\n\n\nIf you are using a HashiCorp Vault server, ensure that the HashiCorp Vault tool integration uses the [AppRole Auth Method](https:\/\/www.vaultproject.io\/docs\/auth\/approle) method. When you use the AppRole authentication method, you need role-id and secret-id to successfully integrate the HashiCorp Vault server with the toolchain. Because role-id and secret-id are secrets in themselves, it is recommended to store them by using a [IBM Key Protect tool integration](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-keyprotect) so that they can be securely retrieved and applied in the toolchain workflow. All other toolchain secrets should be stored and retrieved by using the HashiCorp Vault tool integration.\n\nIf the pipeline environment property git-token is not set, ibmcloud-api-key is used to retrieve the Git Repos and Issue Tracking Access Token by default. However, if ibmcloud-api-key does not have access to git, git-token must be set.\n\n\n\n Configuring the secrets stores \n\nWith IBM Cloud, you can choose from various secrets management and data protection offerings that help you protect your sensitive data and centralize your secrets. You can choose between the vault integrations depending on your requirements as explained in [Managing IBM Cloud secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manage-secrets-ibm-cloud).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-toolchains-secrets"},{"document_id":"ibmcld_06885-6467-8675","score":13.6290873877,"text":"\nThe recommended options are displayed by default, but you can click the Switch to advanced configuration toggle to see all of the configuration options available for the underlying Git integration. The default behavior of the toolchain is Use default sample that clones the sample application into an IBM-hosted Git Repos and Issue Tracking Repository.\n\nEnter a name for the IBM-hosted Git Repos and Issue Tracking repository that is created by the toolchain as your application repository.\n\nThe region of the repository remains the same as the region of the toolchain.\n\nIf you want to link an existing Application Repository for the toolchain, select the Bring your own application option, and provide it as input to Repository URL field. As noted earlier, the toolchain currently supports linking only to existing Git Repos and Issue Tracking repositories. If you want to know more about Bring your own application, see [Bringing your own app to DevSecOps](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-apps-byoa).\n\n\n\n\n\n Inventory \n\nThe inventory repository records details of artifacts that are built by the CI toolchains.\n\n\n\n\n\n Issues \n\nThe issues repository records issues that are found while the CI pipeline is running.\n\n\n\n\n\n Secrets \n\nSpecify the secret vault integrations to be added to your toolchain by using the provided toggles, as explained in [Managing IBM Cloud secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manage-secrets-ibm-cloud).\n\nThe CI toolchain supports Arbitrary secrets and IAM credentials secret types only.\n\nThis tutorial uses IBM Cloud\u00ae Secrets Manager as the vault for secrets. The Region, Resource group, and Service name fields are automatically populated based on available choices. Click the drop-down indicators to see the other choices.\n\n\n\n\n\n Evidence Storage \n\nThe evidence repository stores all the evidence and artifacts that are generated by the DevSecOps CI pipeline.\n\nToggle the COS bucket slider to also store all the evidence in a Cloud Object Storage bucket that can be configured on the next page.\n\n\n\n\n\n Cloud Object Storage bucket \n\nTo use this feature, you must have a Cloud Object Storage instance and a bucket.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-tutorial-ci-toolchain"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02776-3988-5695","score":19.5666979925,"text":"\n* To prevent or investigate possible wrongdoing in connection with development and testing activities\n* To protect the safety of Personal Data\n* To protect against legal liability\n\n\n\n\n\n\n\n\n\n Security Of Data \n\nDeveloper will strive to use appropriate means to protect all Personal Data used in performing the Permitted Uses of the Service.\n\n\n\n\n\n Service Providers \n\nDeveloper may employ third-party companies and individuals (\"Service Providers\") to facilitate Permitted Uses of the Service, including to perform development and testing, or to analyze development and testing activities.\n\nThese Service Providers have access to Personal Data only to perform these tasks on Developer\u2019s behalf and are obligated not to disclose or use it for any other purpose.\n\n\n\n\n\n Children's Privacy \n\nThe Permitted Use of the Service does not address anyone under the age of 18 (\"Children\").\n\nDeveloper does not knowingly collect Personal Data from anyone under the age of 18. If Developer becomes aware of the collection or processing of Personal Data from Children without verification of parental consent, Developer will take steps to remove that information from the default settings of App ID.\n\n\n\n\n\n Changes To This Privacy Policy \n\nThis Privacy Policy may be updated from time to time and any changes will be reflected by posting the new Privacy Policy on this page. Before the change becomes effective and updated, notification is made via prominent notice on our Service.\n\nThis Privacy Policy should be reviewed periodically for any changes. Changes to this Privacy Policy are effective when they are posted on this page.\n\n\n\n\n\n Contact Us \n\nFor any questions about this Privacy Policy, please contact the Developer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-privacy-policy"},{"document_id":"ibmcld_13616-13587-15670","score":18.7886588425,"text":"\n[https:\/\/www.ibm.com\/support\/customer\/zz\/en\/dpa.html](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/dpa.html)\n\n\n\n\n\n Data Privacy and Subject Rights \n\n\n\n* IBM Privacy Statement\n\n\n\nIBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https:\/\/www.ibm.com\/privacy\/us\/en\/](https:\/\/www.ibm.com\/privacy\/us\/en\/)\n\n\n\n* Right to Lodge a Complaint\n\n\n\nIn the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/](https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/)\n\n\n\n\n\n NIST \n\n\n\n* IBM TRIRIGA Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n\n\n Data Leakage Prevention \/ Data Loss Prevention (DLP) \n\n\n\n* IBM Cloud Delivery Services does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only. Database auditing is enabled and logs are retained for 365 days. Customers configure and manage the data their users can view, update and export within the TRIRIGA Application Suite applications, as well as determine which of their users is permitted direct read-only access to their database(s).\n* IBM purchases Professional Errors and Omissions including cyber risk insurance (see below) for IBM's liability arising out of actual or alleged breach of duty, neglect, error, misstatement, misleading statements or omission committed in the conduct of IBM\u2019s professional services. This includes coverage for loss of intangible property, such as customer data, due to IBM\u2019s negligence. This coverage is global in scope.\n\n\n\n\n\n\n\n DDoS Protection \n\n\n\n* IBM Cloud provides DDoS (Distributed Denial of Service) protection for its environment, designed to protect the entire network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tas-ms?topic=tas-ms-security"},{"document_id":"ibmcld_04997-3175-3972","score":18.3613022989,"text":"\nSee [IBM Cloud Docs: Enabling the HIPAA Supported setting](https:\/\/cloud.ibm.com\/docs\/account?topic=account-eu-hipaa-supportedenabling-hipaa) for additional information.\n\n\n\n\n\n General Data Protection Regulation (GDPR) readiness \n\nPlease visit [IBM's commitment to GDPR readiness](https:\/\/www.ibm.com\/data-responsibility\/gdpr\/) page to learn about IBM\u2019s GDPR readiness journey and our GDPR capabilities and offerings to support your compliance journey.\n\n\n\n* [IBM Data Processing Addendum (DPA)](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?cat=dpa)\n\n\n\n\n\n\n\n Privacy shield \n\nIBM Cloud Object Storage is privacy shield certified. For more information please visit [IBM Privacy Shield Privacy Policy for Certified IBM Cloud Services](https:\/\/www.ibm.com\/privacy\/details\/us\/en\/privacy_shield.html).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-compliance"},{"document_id":"ibmcld_12035-7-1995","score":18.0561092644,"text":"\nCompliance \n\nIBM Cloud\u00ae Schematics actively participates in several industry compliance programs. As compliance focal, you can use the Schematics goals to check that your organization is adhering to the external and internal standards for your industry. For more information about monitoring compliance, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nTo monitor your resources with Schematics, see [Managing security and compliance with Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-monitoring-instances).\n\n\n\n General Data Protection Regulation (GDPR) readiness \n\nAbout GDPR and how Schematics adheres to it, see [General Data Protection Regulation](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-data-protection-regulation-gdpr). View [IBM's commitment to GDPR readiness](https:\/\/www.ibm.com\/data-responsibility\/gdpr\/) to learn about IBM's GDPR readiness journey and the GDPR capabilities and offerings to support your compliance journey.\n\n\n\n\n\n Privacy shield \n\nSchematics is privacy shield that is certified. For more information, see the [IBM Privacy Shield Privacy Policy for Certified IBM Cloud Services](https:\/\/www.ibm.com\/us-en\/privacy\/privacy-shield).\n\n\n\n\n\n International Organization for Standardization (ISO) \n\nSchematics is audited by a Third-party security firm and meet ISO 27001, ISO 27017, ISO 27018, and ISO 27701 requirements. For more information, see the [Schematics Compliance page](https:\/\/www.ibm.com\/cloud\/compliance) for links to the certificates. The following descriptions on the Schematics compliance page cover the Schematics service and respective certifications:\n\n\n\n* IBM Cloud Services (PaaS and SaaS) certified cloud product listing\n* IBM Cloud Services (PaaS and SaaS) certificate - ISO 27001\n* IBM Cloud Services (PaaS and SaaS) certificate - ISO 27017\n* IBM Cloud Services (PaaS and SaaS) certificate - ISO 27018","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-compliance"},{"document_id":"ibmcld_09492-16883-18851","score":17.6851606066,"text":"\n[https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=Z126-7870&lc=en#detail-document](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=Z126-7870&lc=endetail-document)\n\n\n\n\n\n Data Privacy and Subject Rights \n\nIBM Privacy Statement IBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https:\/\/www.ibm.com\/privacy\/us\/en\/](https:\/\/www.ibm.com\/privacy\/us\/en\/)\n\nRight to Lodge a Complaint In the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/](https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/)\n\n\n\n\n\n NIST \n\nIBM Maximo Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n Data Leakage Prevention \/ Data Loss Prevention (DLP) \n\nIBM SRE team does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only. Database auditing is enabled and logs are retained for 365 days. Customers configure and manage the data their users can view, update and export within the Maximo Application Sutie applications, as well as determine which of their users is permitted direct read-only access to their database(s).\n\nIBM purchases Professional Errors and Omissions including cyber risk insurance (see below) for IBM's liability arising out of actual or alleged breach of duty, neglect, error, misstatement, misleading statements or omission committed in the conduct of IBM\u2019s professional services. This includes coverage for loss of intangible property, such as customer data, due to IBM\u2019s negligence. This coverage is global in scope.\n\n\n\n\n\n DDoS Protection","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-ms?topic=mas-ms-Security"},{"document_id":"ibmcld_12297-14875-16224","score":17.4894351081,"text":"\n* [Creating network zones by using the CBR UI](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-create-zone-ui)\n\n\n\n* [Understanding network rules](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-network-rules)\n\n\n\n* [Create network rules by using the CBR API](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-create-rules-api)\n* [Creating network rules by using the CBR UI](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-create-rules-ui)\n\n\n\n* [Next steps](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-next-steps)\n\n\n\n[Data privacy and governance](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-data-privacy-and-governancedata-privacy-and-governance)\n\n[General Data Protection Regulation (GDPR)](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-data-protection-regulation-gdprgeneral-data-protection-regulation-gdpr)\n\n\n\n* [How do you audit access to Schematics?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-data-protection-regulation-gdprhow-do-i-audit-access-to-ibm-schematics)\n* [Supporting classifications of personal data](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-data-protection-regulation-gdprsupported-classifications-of-personal-data)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sitemap"},{"document_id":"ibmcld_09513-12728-14481","score":17.3560002239,"text":"\nThis is applicable to EU-US and Swiss-US customers: [https:\/\/www.ibm.com\/privacy\/details\/us\/en\/privacy_shield.html](https:\/\/www.ibm.com\/privacy\/details\/us\/en\/privacy_shield.html)\n\nData Responsibility at IBM [https:\/\/www.ibm.com\/blogs\/policy\/dataresponsibility-at-ibm\/](https:\/\/www.ibm.com\/blogs\/policy\/dataresponsibility-at-ibm\/) If a government wants access to data held by IBM on behalf of a SaaS client, IBM would expect that government to deal directly with that client\n\nData Processing Addendum (GDPR)\n\n[https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=Z126-7870&lc=en#detail-document](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=Z126-7870&lc=endetail-document)\n\n\n\n\n\n Data Privacy and Subject Rights \n\nIBM Privacy Statement IBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https:\/\/www.ibm.com\/privacy\/us\/en\/](https:\/\/www.ibm.com\/privacy\/us\/en\/)\n\nRight to Lodge a Complaint In the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/](https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/)\n\n\n\n\n\n NIST \n\nIBM Maximo Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n Data Leakage Prevention \/ Data Loss Prevention (DLP) \n\nIBM Cloud Delivery Services does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-saas?topic=mas-saas-Security"},{"document_id":"ibmcld_09105-6159-7945","score":17.3270850536,"text":"\n<br> <br>When you set the return_preference variable to return=minimal, the service returns only the key metadata, such as the key name and ID value, in the response entity-body. When you set the variable to return=representation, the service returns both the key material and the key metadata. \n key_name Required. A unique, human-readable name for easy identification of your key. To protect your privacy, do not store your personal data as metadata for your key. \n alias_list Optional. One or more unique, human-readable aliases assigned to your key. <br> <br>Important: To protect your privacy, do not store your personal data as metadata for your key. <br> <br>Each alias must be alphanumeric, case sensitive, and cannot contain spaces or special characters other than - or _. The alias cannot be a UUID and must not be a Key Protect reserved name: allowed_ip, key, keys, metadata, policy, policies. registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. \n key_description Optional. An extended description of your key. To protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional. The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date. If the expirationDate attribute is omitted, the key does not expire. \n key_material Required. The base64-encoded key material, an existing key-wrapping key, that you want to store and manage in the service. For more information, check out [Base64 encoding your key material](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-import-root-keyshow-to-encode-root-key-material).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-import-root-keys"},{"document_id":"ibmcld_09060-4951-6938","score":17.0040376142,"text":"\nThe unique identifier of the target key ring that you would like the newly create key to be a part of. If unspecified, the header is automatically set to 'default' and the key will sit in the default key ring in the specified Key Protect service instance. For more information, see [Grouping keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-grouping-keys). \n correlation_ID Optional.The unique identifier that is used to track and correlate transactions. \n return_preference A header that alters server behavior for POST and DELETE operations. When you set the return_preference variable to return=minimal, the service returns only the key metadata, such as the key name and ID value, in the response entity-body. When you set the variable to return=representation, the service returns both the key material and the key metadata. \n key_name Required. A human-readable name for convenient identification of your key. To protect your privacy, do not store your personal data as metadata for your key. \n alias_list Optional.One or more unique, human-readable aliases assigned to your key. Important: To protect your privacy, do not store your personal data as metadata for your key. Each alias must be alphanumeric, case sensitive, and cannot contain spaces or special characters other than - or _. The alias cannot be a UUID and must not be a Key Protect reserved name: allowed_ip, key, keys, metadata, policy, policies, registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. Alias size can be between 2 - 90 characters (inclusive). \n key_description Optional.An extended description of your key. To protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional.The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-create-standard-keys"},{"document_id":"ibmcld_09059-7769-9779","score":16.8700239321,"text":"\nA human-readable name for convenient identification of your key. Important: To protect your privacy, do not store your personal data as metadata for your key. \n alias_list One or more unique, human-readable aliases assigned to your key. Important: To protect your privacy, do not store your personal data as metadata for your key. Each alias must be alphanumeric, case sensitive, and cannot contain spaces or special characters other than dashes (-) or underscores (_). The alias cannot be a version 4 UUID and must not be a Key Protect reserved name: allowed_ip, key, keys, metadata, policy, policies, registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. Alias size can be between 2 - 90 characters (inclusive). \n key_description An extended description of your key. Important: To protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional. The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date. If the expirationDate attribute is omitted, the key does not expire. \n key_type A boolean value that determines whether the key material can leave the service. When you set the extractable attribute to false, the service creates a root key that you can use for wrap or unwrap operations. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service.\n\nIf the expirationDate is provided in your create key request, the key will transition to the deactivated state within one hour past the key's expiration date.\n\nA successful POST api\/v2\/keys response returns the ID value for your key, along with other metadata. The ID is a unique identifier that is assigned to your key and is used for subsequent calls to the Key Protect API.\n\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-create-root-keys"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03966-3327-5475","score":19.2643947339,"text":"\n* Org admins: When you join a consortium that is hosted by an ordering service, you provide the signing certificates of identities that will become the administrators for your organization. You can use these identities to create or edit channels.\n* Peer or orderer admins: IBM Blockchain Platform nodes are deployed with the signing certificates of component administrators identities inside of them. These certificates allow the admins to operate the component from a remote client or by using the console.\n* Applications: Your applications need to sign their transactions before submitting them to be validated by the network. You need to create identities you can use to sign transactions from your client applications.\n\n\n\nYou can use the console to create these identities by using the [registration process](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identitiesibp-console-identities-register). After you register your admin identities, you need to issue each identity a signing certificate and private key, provide the signing certificate to your organization MSP definition, and add the identity to your console wallet. You can complete these steps for one admin identity when you [create your organization MSP](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-organizationsconsole-organizations-create-msp). You can use separate identities as org admins or node admins, or you can use one identity to do both tasks. The [Build a network tutorial](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-build-networkibp-console-build-network) uses one identity to be an admin for each organization created in the tutorial.\n\n\n\n\n\n Associating the identity of the CA admin \n\nBefore you can create identities, you need to associate the identity of the CA admin. Open your CA on the Nodes tab. If you are using the CA for the first time, you can click the Associate identity button to generate the CA admin identity and import it into your console wallet. On the Associate identity side panel, provide the Enroll ID and Enroll secret of the CA admin that you provided when you created the CA.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identities"},{"document_id":"ibmcld_03893-74275-75877","score":18.8816114122,"text":"\nConfigure an HSM client image[See Build a Docker image](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-hsm-build-docker).\n3. Configure the node to use HSM. From the APIs or the console, when you deploy a peer, CA, or ordering node, you can select the advanced option to use an HSM. See [Configure the node to use the HSM](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-cfg-hsm-node).\n\n\n\n\n\n\n\n Before you begin \n\n\n\n* The Kubernetes CLI is required to configure the HSM. If you are using a Kubernetes cluster on IBM Cloud see [Getting started with IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-getting-started) or [Installing the OpenShift CLI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-cli).\n* You need access to a container registry, such as Docker or the [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-started).\n\n\n\n\n\n\n\n Build a Docker image \n\nConfigure HSM on your blockchain network by publishing an HSM client image to a container registry, as described below.\n\nBuild an HSM client image\n\nNext we build a Docker file that contains the HSM client image. These instructions assume that you have successfully configured your HSM appliance and HSM client. Use these steps to generate an image that is consumable by the IBM Blockchain Platform operator.\n\n\n\n* Step one: Modify the HSM client configuration.\n* Step two: Build the HSM client image.\n* Step three: Push the Docker image to your container registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deployment"},{"document_id":"ibmcld_16281-0-376","score":18.8440019239,"text":"\n\n\n\n\n\n\n  Integrating with a custom client app \n\nIBM Cloud\n\nIf the available integration channels do not meet your needs, you can build your own client application as the interface between the assistant and your customers.\n\nFor more information, see [Building a custom client using the API](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-custom-app"},{"document_id":"ibmcld_02998-8791-9815","score":18.5204775549,"text":"\nYou created a simple conversation with two intents and a dialog to recognize them.\n\n\n\n\n\n\n\n Next steps \n\nThis tutorial is built around a simple example. For a real application, you need to define some more interesting intents, some entities, and a more complex dialog that uses them both. When you have a polished version of the assistant, you can make API calls to it from your client application.\n\n\n\n* Complete follow-on tutorials that build more advanced dialogs:\n\n\n\n* Add standard nodes with the [Building a complex dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial) tutorial.\n* Learn about slots with the [Adding a node with slots](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial-slots) tutorial.\n\n\n\n* Check out more [sample apps](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-sample-apps) to get ideas.\n\n\n\nWhen you're ready to deploy your assistant, see [Deploying](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-custom-app).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started"},{"document_id":"ibmcld_03982-9793-12132","score":18.1160347429,"text":"\nBecause an MSP is the representation of an organization in the network, you select the MSP definition when you deploy your nodes (identifying the organization the node belongs to), are joined to the consortium (by an ordering service admin), create a channel, join a channel, edit a channel, or perform any action where you have to specify the organization that is performing the action.\n\n\n\n\n\n Downloading a connection profile \n\nAfter you create an organization MSP definition and create peers with that organization MSP definition, you can download a connection profile that can be used by a client application to connect to your network via one or more gateway peers. The gateway peers are the peers that are specified in the connection profile, and they are used to perform service discovery to find all of the endorsing peers in the network that will endorse transactions.\n\nClick the Organization MSP tile for the organization that your client application interacts with. Click Create connection profile to open a side panel where you can build and download your connection profile.\n\n![Create connection profile panel](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/create-connx-profile.png)\n\nIf you plan to use the client application to register and enroll users with the organization CA, you need to include the Certificate Authority in the connection profile definition.\n\nSelect the peers to include in the connection profile definition. When a peer is not available to process requests from a client application, service discovery ensures that the request is automatically sent to a different peer. Therefore, to accommodate for peer downtime during a maintenance cycle for example, it is recommended that you select more than one peer for redundancy. In addition to peers created by using the console or APIs, imported peers that have been imported into the console are eligible to be selected as well.\n\nThe list of channels that the selected peers have joined is also provided for your information. If a channel is missing from the list, it is likely because the peer joined to it is currently unavailable.\n\nYou can then download the connection profile to your local file system and use it with your client application to generate certificates and invoke smart contracts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-organizations"},{"document_id":"ibmcld_05070-7-1814","score":17.8059749269,"text":"\nUsing Node.js \n\nThe IBM Cloud\u00ae Object Storage SDK for Node.js provides modern capabilities that make the most of IBM Cloud Object Storage.\n\n\n\n Installing the SDK \n\n[Node.js](https:\/\/cloud.ibm.com\/docs\/node?topic=node-getting-started) is an excellent way to build [web applications](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-mean-stack), and customize your instance of Object Storage for your end users. The preferred way to install the Object Storage SDK for Node.js is to use the [npm](https:\/\/www.npmjs.com) package manager for Node.js. Type the following command into a command line:\n\nnpm install ibm-cos-sdk\n\nTo download the SDK directly, the source code is hosted on [GitHub](https:\/\/github.com\/IBM\/ibm-cos-sdk-js).\n\nMore detail on individual methods and classes can be found in [the API documentation for the SDK](https:\/\/ibm.github.io\/ibm-cos-sdk-js\/).\n\n\n\n\n\n Getting Started \n\n\n\n Minimum requirements \n\nTo run the SDK, you need Node 4.x+.\n\n\n\n\n\n Creating a client and sourcing credentials \n\nTo connect to COS, a client is created and configured by providing credential information (API Key, Service Instance ID, and IBM Authentication Endpoint). These values can also be automatically sourced from a credentials file or from environment variables.\n\nAfter generating a [Service Credential](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/iam?topic=cloud-object-storage-service-credentials), the resulting JSON document can be saved to \/.bluemix\/cos_credentials. The SDK will automatically source credentials from this file unless other credentials are explicitly set during client creation. If the cos_credentials file contains HMAC keys the client authenticates with a signature, otherwise the client uses the provided API key to authenticate with a bearer token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-node"},{"document_id":"ibmcld_02680-7025-8620","score":17.7761153441,"text":"\nproperty.getCurrentValue(entityId, entityAttributes); \/\/ returns the stringified yaml (check above Table 1)\n\n\n\n* Force fetch the configurations from server.\n\nappConfiguration.fetchConfigurations()\n\n\n\n\n\n\n\n\n\n\n\n Integrating client SDK for Android app written in Java \n\nApp Configuration service provides Android client SDK to integrate with your Android application. You can evaluate the values of your property and feature flag by integrating the SDK.\n\n\n\n1. Install the SDK by using either one of the options:\n\n\n\n* [Download](https:\/\/github.com\/IBM\/appconfiguration-android-client-sdk) and import the package to your Android studio project.\n* Get the package through Gradle by adding:\n\n\n\n* Add App Configuration Android client SDK dependency to Project level build.gradle file.\n\nrepositories {\nmavenCentral()\n}\n* Add App Configuration Android client SDK dependency to Module level build.gradle file.\n\ndependencies {\nimplementation \"com.ibm.cloud:appconfiguration-android-sdk:0.3.1\"\n}\n\n\n\n\n\n2. Configure the AndroidManifest.xml file for internet permission.\n\n<uses-permission android:name=\"android.permission.INTERNET\"\/>\n3. Integrate Kotlin to your Java project with these steps:\n\n\n\n* Add the Kotlin Gradle plug-in to the Module level build.gradle\n\ndependencies {\nclasspath \"com.android.tools.build:gradle:4.1.1\"\nclasspath \"org.jetbrains.kotlin:kotlin-gradle-plugin:$kotlin_version\"\n}\n* Add kotlin-android plugin to the App level build.gradle\n\nplugins {\nid 'com.android.application'\nid 'kotlin-android'\n}\n\n\n\n4. Initialize the SDK.\n\nAppConfiguration appConfiguration = AppConfiguration.getInstance();","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-integrate-sdks-android"},{"document_id":"ibmcld_03916-19063-21128","score":17.7414177151,"text":"\nIf you manually built your organization MSP with certificates from an external CA, the connection profile will not include any information in the \"certificateAuthorities\": section.\n\n\n\n\n\n Service discovery \n\nService discovery allows your applications to dynamically find the peer and ordering endpoints of your network. If you do not use service discovery, you need to manually add the endpoint information of peer and ordering nodes on your channel to your connection profile or your application. You would need to edit your connection profile or update your application each time a node is added or removed from your network.\n\nBefore you can take advantage of the [Service Discovery](https:\/\/hyperledger-fabric.readthedocs.io\/en\/release-2.2\/discovery-overview.html) feature of Hyperledger Fabric, you must configure anchor peers on the channel. Service discovery allows your application to learn which peers on the channel outside your organization need to endorse a transaction. Without service discovery, you will need to get the endpoint information of these peers out of band from other organizations and add them to your connection profile. For more information, see [Configuring anchor peers](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-governibp-console-govern-channels-anchor-peers).\n\nLater in this topic, we use the connection profile to build a Fabric gateway that is configured for [service discovery](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-appibp-console-app-sd-cfg).\n\n\n\n\n\n Enrolling by using the SDK \n\nOnce the network operator provides the enroll ID and secret of the application identity and the network connection profile, an application developer can use the Fabric SDKs or the Fabric CA client to generate client-side certificates. You can use the following steps to enroll an application identity by using the [Fabric SDK for Node.js](https:\/\/hyperledger.github.io\/fabric-sdk-node\/release-2.2\/index.html).\n\n\n\n1. Save the connection profile to your local system and rename it connection.json.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-app"},{"document_id":"ibmcld_02998-7662-9256","score":17.4029079245,"text":"\n[An ending node was added to the dialog also.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-ending-node-added.png)\n\n\n\n\n\n Testing intent recognition \n\nYou built a simple dialog to recognize and respond to both greeting and ending inputs. Let's see how well it works.\n\n\n\n1. Click the ![Try it](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/try-it.png) icon to open the Try it out pane. There's that reassuring welcome message.\n2. In the text field, type Hello and press Enter. The output indicates that the General_Greetings intent was recognized, and the appropriate response (Good day to you.) is displayed.\n3. Try the following input:\n\n\n\n* bye\n* howdy\n* see ya\n* good morning\n* sayonara\n\n\n\n\n\nWatson can recognize your intents even when your input doesn't exactly match the examples that you included. The dialog uses intents to identify the purpose of the user's input regardless of the precise wording used, and then responds in the way you specify.\n\n\n\n\n\n Result of building a dialog \n\nThat's it. You created a simple conversation with two intents and a dialog to recognize them.\n\n\n\n\n\n\n\n Next steps \n\nThis tutorial is built around a simple example. For a real application, you need to define some more interesting intents, some entities, and a more complex dialog that uses them both. When you have a polished version of the assistant, you can make API calls to it from your client application.\n\n\n\n* Complete follow-on tutorials that build more advanced dialogs:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started"},{"document_id":"ibmcld_03916-39203-41294","score":17.2546701315,"text":"\nSuccessfully enrolled client \"user1\" and imported it into the wallet\n\nYou can find the wallet that was created in the identity folder of the magnetocorp directory.\n\n\n\n\n\n Step four: Use the connection profile to build a Fabric gateway \n\nThe Hyperledger Fabric [Transaction Flow](https:\/\/hyperledger-fabric.readthedocs.io\/en\/release-2.2\/txflow.html) spans multiple components, with the client applications playing a unique role. Your application needs to connect to the peers that need to endorse the transaction and needs to connect to the ordering service that will order the transaction and add it into a block. You can provide the endpoints of these nodes to your application by using your connection profile to construct a Fabric gateway. The gateway then conducts the low-level interactions with your Fabric network. To learn more, visit the [Fabric gateway](https:\/\/hyperledger-fabric.readthedocs.io\/en\/release-2.2\/developapps\/gateway.html) topic in the Fabric documentation.\n\nYou have already downloaded your connection profile and used it to connect to your organization's Certificate Authority. Now we use the connection profile to build a gateway.\n\nOpen the file issue.js in a text editor. Before you edit the file, notice that it imports the FileSystemWallet and Gateway classes from fabric-network library.\n\nconst { FileSystemWallet, Gateway } = require('fabric-network')\n\nYou will need to import the path class to build the gateway from the connection profile you downloaded from your console. Add the following line to the file to import the path class:\n\nconst path = require('path');\n\nThe Gateway class is used to construct a gateway that you will use to submit your transaction.\n\nconst gateway = new Gateway()\n\nThe FileSystemWallet class is used to load the wallet you created in the previous step. Edit the following line if you changed the location of the wallet on your file system.\n\nconst wallet = new FileSystemWallet('..\/identity\/user\/isabella\/wallet');\n\nAfter you import your wallet, use the following code to pass your connection profile and wallet to the new gateway.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-app"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2021073465,"ndcg_cut_10":0.3433743194}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16261-10613-12744","score":15.2849098917,"text":"\nBecause we need a way to end the conversation, the client app is also watching for the literal command quit to indicate that the program should exit.\n\nBut something still isn't right:\n\nWelcome to the Watson Assistant example. What's your name?\n>> Robert\nI'm afraid I don't understand. Please rephrase your question.\n>> I want to make an appointment.\nWhat day would you like to come in?\n>> Thursday\nI'm afraid I don't understand. Please rephrase your question.\n>>\n\nThe assistant is starting out with the correct greeting, but it doesn't understand when you tell it your name. And if you tell it you want to make an appointment, the correct action is triggered; but once again, it doesn't understand when you answer the follow-up question.\n\nThis is happening because we are using the stateless message method, which means that it is the responsibility of our client application to maintain state information for the conversation. Because we are not yet doing anything to maintain state, the assistant sees every round of user input as the first turn of a new conversation. Because it has no memory of asking a question, it tries to interpret your answer as a new question or request.\n\n\n\n\n\n Maintaining state \n\nState information for your conversation is maintained using the context. The context is an object that is passed back and forth between your application and the assistant, storing information that can be preserved and updated as the conversation goes on. Because we are using the stateless message method, the assistant does not store the context, so it is the responsibility of our client application to maintain it from one turn of the conversation to the next.\n\nThe context includes a session ID for each conversation, as well as a counter that is incremented with each turn of the conversation. The assistant updates the context and returns it with each response. But our previous version of the example did not preserve the context, so these updates were lost, and each round of input appeared to be the start of a new conversation. We can fix that by saving the context and sending it back to the assistant each time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client"},{"document_id":"ibmcld_10203-2544-4340","score":14.4384841285,"text":"\noc new-app --name <app_name> https:\/\/github.com\/<path_to_app_repo> [--context-dir=<subdirectory>]\n\nWhat does the new-app command do?\n: The new-app command creates a build configuration and app image from the source code, a deployment configuration to deploy the container to pods in your cluster, and a service to expose the app within the cluster. For more information about the build process and other sources besides Git, see the [Red Hat OpenShift documentation](https:\/\/docs.openshift.com\/container-platform\/4.11\/applications\/creating_applications\/odc-creating-applications-using-developer-perspective.html).\n\n\n\n\n\n\n\n Deploying apps to specific worker nodes by using labels \n\nWhen you deploy an app, the app pods indiscriminately deploy to various worker nodes in your cluster. Sometimes, you might want to restrict the worker nodes that the app pods to deploy to. For example, you might want app pods to deploy to only worker nodes in a certain worker pool because those worker nodes are on bare metal machines. To designate the worker nodes that app pods must deploy to, add an affinity rule to your app deployment.\n\nBefore you begin\n\n\n\n* [Access your Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster).\n* Make sure that you are assigned a [service access role](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-userschecking-perms) that grants the appropriate Kubernetes RBAC role so that you can work with Kubernetes resources in the Red Hat OpenShift project.\n* Optional: [Set a label for the worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersworker_pool_labels) that you want to run the app on.\n\n\n\nTo deploy apps to specific worker nodes,\n\n\n\n1. Get the ID of the worker pool that you want to deploy app pods to.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy_app"},{"document_id":"ibmcld_03184-3236-4998","score":14.4165649415,"text":"\nThe client application then stores the returned information in context variable specified in the action request ($weather_forecast).\n4. The client application sends another message to the service, including the updated context that contains the weather forecast information. From the dialog's perspective, this message is effectively the next round of user input, although the actual input text is blank.\n5. A child node of the #weather node is triggered by the presence of the $weather_forecast context variable. This node responds with text output that includes the weather forecast, which the client application displays to the user. (If the $weather_forecast variable is not set, another child node can handle this case and report an error.)\n\n\n\nIt is also possible to call an external Web service directly from a dialog node, without involving the client application, by defining a webhook. For more information about how to call an external service using a webhook, see [Making a programmatic call from a dialog node](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-webhooks).\n\n\n\n Procedure \n\nTo request a client action from a dialog node, complete the following steps:\n\n\n\n1. In the dialog node from which you want to request the client action, open the JSON editor for the node response.\n\n![Shows how to access the JSON editor associated with a standard noderesponse.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/contextvar-json-response.png)\n2. Use the following syntax to define the client action you want to request.\n\n{\n\"context\": {\n\"variable_name\" : \"variable_value\"\n},\n\"actions\": [\n{\n\"name\":\"<actionName>\",\n\"type\":\"client\",\n\"parameters\": {\n\"<parameter_name>\":\"<parameter_value>\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-actions-client"},{"document_id":"ibmcld_02872-10099-11736","score":14.3403863609,"text":"\n\"result_variable\": \"context.my_forecast\"\n}\n]\n}\n\nNormally, the service only returns to the client from a POST \/message request when new user input is required, such as after executing a parent and before executing one of its child nodes. However, if you add a client action to a node, then after evaluation, the service always returns to the client so that the result of the action call can be returned. To prevent waiting for user input when it should not, such as for a node that is configured to jump directly to a child node, the service adds the following value to the message context:\n\n{\n\"context\": {\n\"skip_user_input\": true\n}\n}\n\nIf you want the client to perform an action, but not get user input, then you can follow the same convention, and add the skip_user_input context variable to the parent node to communicate that to the client application.\n\nYour client application should always check for the skip_user_input variable on context. If present, then it knows not to request new input from the user, but instead execute the action, add its result into the message, and pass it back to the service. The new POST message request should include the message returned by the previous POST message response (namely, the context, input, intents, entities, and optionally the output section) and, instead of the JSON object that defines the programmatic call to make, it should include the result that was returned from the programmatic call.\n\nIn a child node that you jump to after this node, add the response to show the user:\n\n{\n\"output\": {\n\"text\": {\n\"values\": [\n\"It will be $my_forecast $date.literal in $location.literal.\"\n]\n}\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-actions-client"},{"document_id":"ibmcld_13144-9759-11433","score":14.2427034989,"text":"\nThe Pods, Builds, Services and Routes are visible.\n\nZoom\n\n![App Details](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution55-openshift-microservices\/ocp45-topo-app-details.png)\n\nApp Details\n\n\n\n* Pods: Your Node.js application containers\n* Builds: The auto-generated build that created a Docker image from your Node.js source code, deployed it to the Red Hat OpenShift container registry, and kicked off your deployment config\n* Services: Tells Red Hat OpenShift how to access your Pods by grouping them together as a service and defining the port to listen to\n* Routes: Exposes your services to the outside world using the LoadBalancer provided by the IBM Cloud network\n\n\n\n3. Click on View Logs next to your completed Build. This shows you the process that Red Hat OpenShift took to install the dependencies for your Node.js application and build\/push a Docker image. The last entry should looks like this:\n\nSuccessfully pushed image-registry.openshift-image-registry.svc:5000\/example-health\/patient-health-frontend@sha256:f9385e010144f36353a74d16b6af10a028c12d005ab4fc0b1437137f6bd9e20a\nPush successful\n4. Click back to the Topology and select your app again.\n5. Click on the URL under Routes to visit your application. Enter any string for username and password, for instance test:test because the app is running in demonstration mode.\n\n\n\nThe Node.js app has been deployed to Red Hat OpenShift Container Platform. To recap:\n\n\n\n* The \"Example Health\" Node.js application was deployed directly from GitHub into your cluster.\n* The application was examined in the Red Hat OpenShift on IBM Cloud console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-openshift-microservices"},{"document_id":"ibmcld_10439-12027-13877","score":14.147718608,"text":"\nA [pod](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/pods\/) is the smallest deployable unit that Kubernetes can manage. You put your container (or a group of containers) into a pod and use the pod configuration file to tell the pod how to run the container and share resources with other pods. All containers that you put into a pod run in a shared context, which means that they share the virtual or physical machine.\n\nWhat to put in a container\n: As you think about your application's components, consider whether they have significantly different resource requirements for things like CPU and memory. Could some components run at a best effort, where going down for a little while to divert resources to other areas is acceptable? Is another component customer-facing, so it's critical for it to stay up? Split them up into separate containers. You can always deploy them to the same pod so that they run together in sync.\n\nWhat to put in a pod\n: The containers for your app don't always have to be in the same pod. In fact, if you have a component that is stateful and difficult to scale, such as a database service, put it in a different pod that you can schedule on a worker node with more resources to handle the workload. If your containers work correctly if they run on different worker nodes, then use multiple pods. If they need to be on the same machine and scale together, group the containers into the same pod.\n\n\n\n\n\n So if I can use a pod, why do I need all these different types of objects? \n\nCreating a pod YAML file is easy. You can write one with just a few lines as follows.\n\napiVersion: v1\nkind: Pod\nmetadata:\nname: nginx\nspec:\ncontainers:\n- name: nginx\nimage: nginx\nports:\n- containerPort: 80\n\nBut you don't want to stop there. If the node that your pod runs on goes down, then your pod goes down with it and isn't rescheduled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_deploy"},{"document_id":"ibmcld_02953-3805-5544","score":14.019556213,"text":"\n* To find and resubmit a test utterance, you can press the Up key to cycle through your recent inputs.\n* To remove prior test utterances from the chat pane and start over, click the Clear link. Not only are the test utterances and responses removed, but this action also clears the values of any context variables that were set as a result of your interactions with the dialog. Context variable values that you explicitly set or change are not cleared.\n\n\n\n\n\n\n\n What to do next \n\nIf you determine that the wrong intents or entities are being recognized, you might need to modify your intent or entity definitions.\n\nIf the correct intents and entities are being recognized, but the wrong nodes are being triggered in your dialog, make sure your conditions are written properly.\n\nIf you are ready to put the conversation to work helping your users, call the assistant from a client application. See [Building a client application](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-api-client).\n\n\n\n\n\n\n\n Searching your dialog \n\nThe search capability was introduced with the 1.5.0 release.\n\nYou can search the dialog to find one or more dialog nodes that mention a given word or phrase.\n\n\n\n1. From the Dialog page header, click the Search icon ![Search icon in the Intents page header](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/search_icon.png).\n2. Enter a search term or phrase.\n\nThe first time you search, an index is created. You might be asked to wait for the text in your dialog nodes to be indexed and then resubmit your request.\n\n\n\nDialog nodes that contain your search term, with corresponding examples, are shown. Select a result to open it for editing.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tasks"},{"document_id":"ibmcld_03184-1586-3749","score":13.991534028,"text":"\nIt is the responsibility of the client application to carry out the requested action, store the result in the context, and send it back to the dialog with the next message.\n\nYou might call a client application to do the following types of things:\n\n\n\n* Validate information that you collected from the user.\n* Do calculations or string manipulations on user input that are too complex for supported SpEL expression methods to handle.\n* Get data from another application or service.\n\n\n\nThe following diagram illustrates how client actions work, using the example of an action to get a weather forecast.\n\n![Shows someone asking for a weather forecast and the dialog sending a request to a client app, which sends it to the external service and returns the result](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/forecast.png)\n\nThe flow of requests and responses follows this pattern:\n\n\n\n1. The client application sends a message containing user input that asks for a weather forecast (using the message or message_stateless method).\n2. The user input triggers a dialog node conditioned on a #weather intent. In its response to the client, this node specifies the get_weather client action, which is a name that the client application recognizes. (This is in addition to any text response, such as Checking the weather forecast....)\n3. When it receives this response, the client application recognizes that the get_weather action is being requested. It calls an external web service (\/weather) to get the actual forecast information, passing any specified parameters (such as the user's location). The client application then stores the returned information in context variable specified in the action request ($weather_forecast).\n4. The client application sends another message to the service, including the updated context that contains the weather forecast information. From the dialog's perspective, this message is effectively the next round of user input, although the actual input text is blank.\n5. A child node of the #weather node is triggered by the presence of the $weather_forecast context variable.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-actions-client"},{"document_id":"ibmcld_06004-7689-9633","score":13.9155796621,"text":"\nI thought that I needed to put my app in a container. Now what's all this stuff about pods? \n\nA [pod](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/pods\/) is the smallest deployable unit that Kubernetes can manage. You put your container (or a group of containers) into a pod and use the pod configuration file to tell the pod how to run the container and share resources with other pods. All containers that you put into a pod run in a shared context, which means that they share the virtual or physical machine.\n\nWhat to put in a container\n: As you think about your application's components, consider whether they have significantly different resource requirements for things like CPU and memory. Could some components run at a best effort, where going down for a little while to divert resources to other areas is acceptable? Is another component customer-facing, so it's critical for it to stay up? Split them up into separate containers. You can always deploy them to the same pod so that they run together in sync.\n\nWhat to put in a pod\n: The containers for your app don't always have to be in the same pod. In fact, if you have a component that is stateful and difficult to scale, such as a database service, put it in a different pod that you can schedule on a worker node with more resources to handle the workload. If your containers work correctly if they run on different worker nodes, then use multiple pods. If they need to be on the same machine and scale together, group the containers into the same pod.\n\n\n\n\n\n So if I can use a pod, why do I need all these different types of objects? \n\nCreating a pod YAML file is easy. You can write one with just a few lines as follows.\n\napiVersion: v1\nkind: Pod\nmetadata:\nname: nginx\nspec:\ncontainers:\n- name: nginx\nimage: nginx\nports:\n- containerPort: 80\n\nBut you don't want to stop there. If the node that your pod runs on goes down, then your pod goes down with it and isn't rescheduled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_deploy"},{"document_id":"ibmcld_02872-7-1746","score":13.816110974,"text":"\nCalling a client application ![BETA](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/beta.png) \n\nAdd a client action to your dialog node that pauses the dialog so a client-side process can run and return a result as part of the processing that occurs within a dialog turn.\n\nSupport for this feature was introduced with version 1.4.\n\nA client action defines a programmatic call in a standardized format that your external client application can understand. Your external client application must use the provided information to run the programmatic call or function, and then return the result to the dialog.\n\nThis action does not make a direct call itself. It basically tells the dialog to pause here and wait for an external client application to go do something. The program that the client application runs can be anything that you choose. Be sure to specify the call name and parameter details, and the error message variable name according to the JSON formatting rules that are outlined later in this topic.\n\nYou can call a client application to do the following types of things:\n\n\n\n* Validate information that you collected from the user.\n* Do calculations or string manipulations on user input that are too complex for supported SpEL expression methods to handle.\n* Get data from another application or service.\n\n\n\nFor information about how to call an external service, such as a Cloud Functions web action, see [Making a programmatic call from a dialog node](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-webhooks).\n\nThe following diagram illustrates how you can use a client call to get weather forecast information, and return it to the user.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-actions-client"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06279-70523-72321","score":9.0042181142,"text":"\nTo delete a persistent VPC load balancer, delete the Kubernetes LoadBalancer service definition that the VPC load balancer is associated with.\n\n\n\n\n\n Moving a VPC load balancer from one cluster to another \n\n[Persistent VPC load balancers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-lbaasvpc_lb_persist) can be detached from one VPC cluster and then attached to another. The new cluster must be within the same VPC as the original cluster.\n\n\n\n Detaching a VPC load balancer from a cluster \n\nVPC load balancers are linked to the Kubernetes LoadBalancer service definition that they were created with. To detach a persistent VPC load balancer from a cluster, you must break the link with the LoadBalancer service by [renaming the VPC load balancer](https:\/\/cloud.ibm.com\/docs\/vpc-infrastructure-cli-plugin?topic=vpc-infrastructure-cli-plugin-vpc-referenceload-balancer-update), or by removing the service.kubernetes.io\/ibm-load-balancer-cloud-provider-vpc-lb-name annotation from the original LoadBalancer service definition. You can also detach a persistent VPC load balancer from a cluster by [deleting the cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-remove).\n\nIf you remove the annotation, the original LoadBalancer service reverts and creates a non-persistent VPC load balancer in the original cluster. This non-persistent VPC load balancer follows the kube-<cluster_ID>-<kubernetes_lb_service_UID> naming convention.\n\n\n\n\n\n Attaching a VPC load balancer to a cluster \n\nAfter a persistent VPC load balancer is detached from a cluster, you can attach to a different cluster by creating a new Kubernetes LoadBalancer service definition that references the VPC load balancer, or by updating an existing Kubernetes LoadBalancer service that exists on the new cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-lbaas"},{"document_id":"ibmcld_10041-7462-8947","score":9.0024950192,"text":"\nGET\/v2\/getFlavors List available flavors types for a VPC zone (data center). N\/A N\/A \n GET\/v2\/getKMSInstances Get key management service (KMS) instances tied to an account containers-kubernetes.cluster.read N\/A \n GET\/v2\/getKubeconfig Get the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.read containers-kubernetes.account.get \n GET\/v2\/getOperatingSystems Get a list of available worker node operating systems. N\/A cluster-worker-pool-supported-operating-systems.get \n GET\/v2\/getRBACStatus Get the status of an RBAC. containers-kubernetes.cluster.view cluster-rbac.status \n GET\/v2\/vpc\/getCluster Get detailed information for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getClusters List the VPC clusters that you have access to. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getSubnets View subnets for a given VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPC View details of a VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPCs View available VPCs for the infrastructure provider. containers-kubernetes.cluster.read N\/A \n PATCH\/v1\/clusters\/{idOrName}\/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH\/v1\/clusters\/{idOrName}\/subnets\/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST\/v1\/clusters Create a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05567-7444-8929","score":9.0024950192,"text":"\nGET\/v2\/getFlavors List available flavors types for a VPC zone (data center). N\/A N\/A \n GET\/v2\/getKMSInstances Get key management service (KMS) instances tied to an account containers-kubernetes.cluster.read N\/A \n GET\/v2\/getKubeconfig Get the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.read containers-kubernetes.account.get \n GET\/v2\/getOperatingSystems Get a list of available worker node operating systems. N\/A cluster-worker-pool-supported-operating-systems.get \n GET\/v2\/getRBACStatus Get the status of an RBAC. containers-kubernetes.cluster.view cluster-rbac.status \n GET\/v2\/vpc\/getCluster Get detailed information for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getClusters List the VPC clusters that you have access to. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getSubnets View subnets for a given VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPC View details of a VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPCs View available VPCs for the infrastructure provider. containers-kubernetes.cluster.read N\/A \n PATCH\/v1\/clusters\/{idOrName}\/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH\/v1\/clusters\/{idOrName}\/subnets\/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST\/v1\/clusters Create a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_10686-70394-71984","score":8.9863457218,"text":"\n[Persistent VPC load balancers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-lbaasvpc_lb_persist) can be detached from one VPC cluster and then attached to another. The new cluster must be within the same VPC as the original cluster.\n\n\n\n Detaching a VPC load balancer from a cluster \n\nVPC load balancers are linked to the Kubernetes LoadBalancer service definition that they were created with. To detach a persistent VPC load balancer from a cluster, you must break the link with the LoadBalancer service by [renaming the VPC load balancer](https:\/\/cloud.ibm.com\/docs\/vpc-infrastructure-cli-plugin?topic=vpc-infrastructure-cli-plugin-vpc-referenceload-balancer-update), or by removing the service.kubernetes.io\/ibm-load-balancer-cloud-provider-vpc-lb-name annotation from the original LoadBalancer service definition. You can also detach a persistent VPC load balancer from a cluster by [deleting the cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-remove).\n\nIf you remove the annotation, the original LoadBalancer service reverts and creates a non-persistent VPC load balancer in the original cluster. This non-persistent VPC load balancer follows the kube-<cluster_ID>-<kubernetes_lb_service_UID> naming convention.\n\n\n\n\n\n Attaching a VPC load balancer to a cluster \n\nAfter a persistent VPC load balancer is detached from a cluster, you can attach to a different cluster by creating a new Kubernetes LoadBalancer service definition that references the VPC load balancer, or by updating an existing Kubernetes LoadBalancer service that exists on the new cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-lbaas"},{"document_id":"ibmcld_06282-17354-19397","score":8.9823862167,"text":"\nWhen you create your VPC cluster, you can also attach additional security groups alongside, or instead of, the default VPC security groups. The security groups applied to the workers in the cluster are a combination of the security groups applied when you create the cluster and [when you create the worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-groupvpc-sg-worker-pool). A total of five security groups can be applied to workers, including the default security groups and any security groups applied to the worker pool. Note that these security group options are only available in the CLI.\n\nThe security groups applied to a cluster cannot be changed once the cluster is created. You can [change the rules of the security groups](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-groupvpc-sg-create-rules) that are applied to the cluster, but you cannot add or remove security groups at the cluster level. If you apply the incorrect security groups at cluster create time, you must delete the cluster and create a new one.\n\n\n\n If you only want the default VPC and cluster security groups and no additional security groups \n\nVPC security group\n\nCluster security group\n\nNote that this is the default behavior at cluster create time.\n\nWhen you create your cluster, do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the default VPC and kube-<cluster-id> cluster security groups:\n\nibmcloud ks cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id>\n\nThe following security groups are applied:\n\n\n\n* Default VPC security group (randomly generated name)\n* kube-<cluster-id>\n\n\n\n\n\n\n\n If you only want the cluster security group and not the default VPC security group \n\nCluster security group\n\nWhen you create the cluster specify --cluster-security-group cluster. Do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the kube-<cluster-id> cluster security group:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-group"},{"document_id":"ibmcld_06284-17445-19501","score":8.9774736611,"text":"\nWhen you create your VPC cluster, you can also attach additional security groups alongside, or instead of, the default VPC security groups. The security groups applied to the workers in the cluster are a combination of the security groups applied when you create the cluster and [when you create the worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-group&interface=uivpc-sg-worker-pool). A total of five security groups can be applied to workers, including the default security groups and any security groups applied to the worker pool. Note that these security group options are only available in the CLI.\n\nThe security groups applied to a cluster cannot be changed once the cluster is created. You can [change the rules of the security groups](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-groupvpc-sg-create-rules) that are applied to the cluster, but you cannot add or remove security groups at the cluster level. If you apply the incorrect security groups at cluster create time, you must delete the cluster and create a new one.\n\n\n\n If you only want the default VPC and cluster security groups and no additional security groups \n\nVPC security group\n\nCluster security group\n\nNote that this is the default behavior at cluster create time.\n\nWhen you create your cluster, do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the default VPC and kube-<cluster-id> cluster security groups:\n\nibmcloud ks cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id>\n\nThe following security groups are applied:\n\n\n\n* Default VPC security group (randomly generated name)\n* kube-<cluster-id>\n\n\n\n\n\n\n\n If you only want the cluster security group and not the default VPC security group \n\nCluster security group\n\nWhen you create the cluster specify --cluster-security-group cluster. Do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the kube-<cluster-id> cluster security group:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-group&interface=ui"},{"document_id":"ibmcld_06282-4283-5732","score":8.97121861,"text":"\nKubernetes Service security group kube-<vpc-id> <br><br> * Automatically created and attached to any cluster-related VPE gateways in the VPC.<br> * Automatically created and attached to each VPC ALB that is created in the VPC.<br> * Allows traffic necessary for the cluster infrastructure to function.<br><br><br> \n\n\n\n\n\n\n\n\n\n Viewing VPC security groups in the CLI \n\nFollow the steps to view details about the VPC security groups.\n\n\n\n1. List your clusters and note the ID of the cluster that you are working in.\n\nTo check what VPC a cluster is in, run ibmcloud ks cluster get --cluster <cluster_name_or_id> and check the VPC ID in the output.\n\nibmcloud ks cluster ls --provider vpc-gen2\n2. List the security groups attached to the VPC that your cluster is in. The VPC security group is assigned a randomly generated name, such as trench-hexagon-matriarch-flower. The VPC cluster security group is named in the format of kube-<cluster-ID>. The Kubernetes Service security group is named in the format of kube-<vpc-ID>.\n\nibmcloud is sgs | grep <vpc_name>\n\nExample output.\n\nID Name Rules Network interfaces VPC Resource group\n\nr006-111aa1aa-1a1a-1a11-1111-a111aaa1a11a trench-hexagon-matriarch-flower 4 0 my-vpc default\nr006-222aa2aa-2a2a-2a22-2222-a222aaa2a22a kube-a111a11a11aa1aa11a11 4 0 my-vpc default\nr006-333aa3aa-3a3a-3a33-3333-a333aaa3a33a kube-r006-111a11aa-aaa1-1a1a-aa11-1a1a111aa11 4 0 my-vpc default\n3. Get the details of a security group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-group"},{"document_id":"ibmcld_06284-4309-5758","score":8.97121861,"text":"\nKubernetes Service security group kube-<vpc-id> <br><br> * Automatically created and attached to any cluster-related VPE gateways in the VPC.<br> * Automatically created and attached to each VPC ALB that is created in the VPC.<br> * Allows traffic necessary for the cluster infrastructure to function.<br><br><br> \n\n\n\n\n\n\n\n\n\n Viewing VPC security groups in the CLI \n\nFollow the steps to view details about the VPC security groups.\n\n\n\n1. List your clusters and note the ID of the cluster that you are working in.\n\nTo check what VPC a cluster is in, run ibmcloud ks cluster get --cluster <cluster_name_or_id> and check the VPC ID in the output.\n\nibmcloud ks cluster ls --provider vpc-gen2\n2. List the security groups attached to the VPC that your cluster is in. The VPC security group is assigned a randomly generated name, such as trench-hexagon-matriarch-flower. The VPC cluster security group is named in the format of kube-<cluster-ID>. The Kubernetes Service security group is named in the format of kube-<vpc-ID>.\n\nibmcloud is sgs | grep <vpc_name>\n\nExample output.\n\nID Name Rules Network interfaces VPC Resource group\n\nr006-111aa1aa-1a1a-1a11-1111-a111aaa1a11a trench-hexagon-matriarch-flower 4 0 my-vpc default\nr006-222aa2aa-2a2a-2a22-2222-a222aaa2a22a kube-a111a11a11aa1aa11a11 4 0 my-vpc default\nr006-333aa3aa-3a3a-3a33-3333-a333aaa3a33a kube-r006-111a11aa-aaa1-1a1a-aa11-1a1a111aa11 4 0 my-vpc default\n3. Get the details of a security group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-group&interface=ui"},{"document_id":"ibmcld_10689-4259-5732","score":8.95251754,"text":"\nRed Hat OpenShift on IBM Cloud security group kube-<vpc-id> <br><br> * Automatically created and attached to any cluster-related VPE gateways in the VPC.<br> * Automatically created and attached to each VPC ALB that is created in the VPC.<br> * Allows traffic necessary for the cluster infrastructure to function.<br><br><br> \n\n\n\n\n\n\n\n\n\n Viewing VPC security groups in the CLI \n\nFollow the steps to view details about the VPC security groups.\n\n\n\n1. List your clusters and note the ID of the cluster that you are working in.\n\nTo check what VPC a cluster is in, run ibmcloud oc cluster get --cluster <cluster_name_or_id> and check the VPC ID in the output.\n\nibmcloud oc cluster ls --provider vpc-gen2\n2. List the security groups attached to the VPC that your cluster is in. The VPC security group is assigned a randomly generated name, such as trench-hexagon-matriarch-flower. The VPC cluster security group is named in the format of kube-<cluster-ID>. The Red Hat OpenShift on IBM Cloud security group is named in the format of kube-<vpc-ID>.\n\nibmcloud is sgs | grep <vpc_name>\n\nExample output.\n\nID Name Rules Network interfaces VPC Resource group\n\nr006-111aa1aa-1a1a-1a11-1111-a111aaa1a11a trench-hexagon-matriarch-flower 4 0 my-vpc default\nr006-222aa2aa-2a2a-2a22-2222-a222aaa2a22a kube-a111a11a11aa1aa11a11 4 0 my-vpc default\nr006-333aa3aa-3a3a-3a33-3333-a333aaa3a33a kube-r006-111a11aa-aaa1-1a1a-aa11-1a1a111aa11 4 0 my-vpc default\n3. Get the details of a security group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-security-group"},{"document_id":"ibmcld_06294-2598-4239","score":8.9376818076,"text":"\nThis tutorial creates a cluster that runs version 1.26.\n\n\n\n\n\n\n\n Step 1: Create a cluster in VPC \n\nCreate an IBM Cloud Kubernetes Service cluster in your IBM Cloud Virtual Private Cloud (VPC) environment. For more information about VPC, see [Getting Started with Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-started).\n\n\n\n1. Log in to the account, resource group, and IBM Cloud region where you want to create your VPC environment. The VPC must be set up in the same multizone metro location where you want to create your cluster. In this tutorial you create a VPC in us-south. For other supported regions, see [Multizone metros for VPC clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-regions-and-zoneszones-vpc). If you have a federated ID, include the --sso option.\n\nibmcloud login -r us-south [-g <resource_group>] [--sso]\n2. Create a VPC for your cluster. For more information, see the docs for creating a VPC in the [console](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-a-vpc-using-the-ibm-cloud-console) or [CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-vpc-resources-with-cli-and-api&interface=clicreate-a-vpc-cli).\n\n\n\n1. Create a VPC called myvpc and note the ID in the output. VPCs provide an isolated environment for your workloads to run within the public cloud. You can use the same VPC for multiple clusters, such as if you plan to have different clusters host separate microservices that need to communicate with each other. If you want to separate your clusters, such as for different departments, you can create a VPC for each cluster.\n\nibmcloud is vpc-create myvpc\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc_ks_tutorial"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06155-0-1193","score":13.6298424235,"text":"\n\n\n\n\n\n\n  Why does binding a service to a cluster result in a same name error? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\n  What\u2019s happening \n\nWhen you run ibmcloud ks cluster service bind --cluster <cluster_name> --namespace <namespace> --service <service_instance_name>, you see the following message.\n\nMultiple services with the same name were found.\nRun 'ibmcloud service list' to view available Bluemix service instances...\n\n  Why it\u2019s happening \n\nMultiple service instances might have the same name in different regions.\n\n  How to fix it \n\nUse the service GUID instead of the service instance name in the ibmcloud ks cluster service bind command.\n\n\n\n1.  [Log in to the IBM Cloud region that includes the service instance to bind.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-regions-and-zonesbluemix_regions)\n2.  Get the GUID for the service instance.\n\nibmcloud service show <service_instance_name> --guid\n\nExample output\n\nInvoking 'cf service <service_instance_name> --guid'...\n<service_instance_GUID>\n3.  Bind the service to the cluster again.\n\nibmcloud ks cluster service bind --cluster <cluster_name> --namespace <namespace> --service <service_instance_GUID>\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-app-svc-bind-name"},{"document_id":"ibmcld_14510-16289-17562","score":12.5941720649,"text":"\nvSphere HA virtual machine failover failed Configure to send email one time when critical for critical appliances. [Creating and using vSphere HA Clusters](https:\/\/docs.vmware.com\/en\/VMware-vSphere\/6.7\/com.vmware.vsphere.avail.doc\/GUID-5432CA24-14F1-44E3-87FB-61D937831CF6.html) \n vSphere HA virtual machine monitoring action Configure to send email one time when critical for critical appliances. [Creating and using vSphere HA clusters](https:\/\/docs.vmware.com\/en\/VMware-vSphere\/6.7\/com.vmware.vsphere.avail.doc\/GUID-5432CA24-14F1-44E3-87FB-61D937831CF6.html) \n vSphere HA virtual machine monitoring error Configure to send email one time when critical for critical appliances. [Creating and using vSphere HA clusters](https:\/\/docs.vmware.com\/en\/VMware-vSphere\/6.7\/com.vmware.vsphere.avail.doc\/GUID-5432CA24-14F1-44E3-87FB-61D937831CF6.html) \n vSphere HA VM Component Protection could not power off a virtual machine Configure to send email one time when critical for critical appliances. [Creating and Using vSphere HA Clusters](https:\/\/docs.vmware.com\/en\/VMware-vSphere\/6.7\/com.vmware.vsphere.avail.doc\/GUID-5432CA24-14F1-44E3-87FB-61D937831CF6.html) \n License error * Not considered essential for notification. Alarm that is reviewed as part of proactive daily checks.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-opsprocs-alarms"},{"document_id":"ibmcld_14611-14869-16198","score":12.1781254521,"text":"\nFor more information, see [NSX-T Data Center Multisite](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.1\/administration\/GUID-5D7E3D43-6497-4273-99C1-77613C36AD75.html) and also [NSX-T Multi Location Design Guide](https:\/\/communities.vmware.com\/t5\/VMware-NSX-Documents\/NSX-T-Multi-Location-Design-Guide-Federation-Multisite\/ta-p\/2810327?attachment-id=107432).\n* Active-Active NSX-T data plane - This pattern is suitable for where the network latency between data centers is less than 10 ms, such as between availability zones in the same region. For more information, see [NSX-T Data Center Multisite](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.1\/administration\/GUID-5D7E3D43-6497-4273-99C1-77613C36AD75.html) and also [NSX-T Multi Location Design Guide](https:\/\/communities.vmware.com\/t5\/VMware-NSX-Documents\/NSX-T-Multi-Location-Design-Guide-Federation-Multisite\/ta-p\/2810327?attachment-id=107432).\n* Stretched L2 capable - It is possible to do the stretching of layer 2 NSX-T overlay segments across virtual data centers.\n* Single edge cluster Tier-0 gateway for workloads - The automation deploys a single NSX-T edge cluster, consisting of a pair of edge appliances, hosting an active standby Tier-0 gateway for use by the workload VMs. These VMs provide connection between the overlay and underlay networks.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-v2t-targets"},{"document_id":"ibmcld_14611-13743-15420","score":12.096463896,"text":"\nA manual deployment of a backup server must be done to enable backups of this server to be made available at the other site to enable recovery. During failure of vCenter, some management functions are not available. However, workload VMs are still accessible.\n* vCenter HA - vCenter High Availability (HA) protects vCenter against failures by using an active-passive architecture that uses a three-node cluster with active, passive, and witness nodes. For more information about the VMware architecture pattern that must be manually deployed, see [vCenter High Availability](https:\/\/docs.vmware.com\/en\/VMware-vSphere\/7.0\/com.vmware.vsphere.avail.doc\/GUID-4A626993-A829-495C-9659-F64BA8B560BD.html).\n* Single NSX-T Manager cluster - The automation deploys three NSX-T Manager appliances in a cluster with a Virtual IP address.\n* Distributed NSX-T Manager cluster - The initial single NSX-T Manager cluster that is deployed automatically must be modified.\n* Active-DR NSX-T data plane - This pattern is suitable for where the network latency between data centers is more than 10 ms but less than 150 ms, such as across regions. For more information, see [NSX-T Data Center Multisite](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.1\/administration\/GUID-5D7E3D43-6497-4273-99C1-77613C36AD75.html) and also [NSX-T Multi Location Design Guide](https:\/\/communities.vmware.com\/t5\/VMware-NSX-Documents\/NSX-T-Multi-Location-Design-Guide-Federation-Multisite\/ta-p\/2810327?attachment-id=107432).\n* Active-Active NSX-T data plane - This pattern is suitable for where the network latency between data centers is less than 10 ms, such as between availability zones in the same region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-v2t-targets"},{"document_id":"ibmcld_03921-1272-3363","score":12.0852479364,"text":"\nIt is a tool that you can use to deploy components into your cluster.\n\nWhether you deploy components to a paid or free Kubernetes cluster, pay close attention to the amount of available resources in your cluster when you choose to deploy nodes and create\n\nchannels. It is your responsibility to manage your Kubernetes cluster and deploy additional resources when necessary. While components will successfully deploy to an IBM Cloud free cluster, the more components you add, the slower your components will run. For more information about component sizings and how the console interacts with your Kubernetes cluster on IBM Cloud, see [Allocating resources](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-allocate-resources).\n\nIf you are using a Kubernetes cluster on IBM Cloud, it is recommended that you provision at least a 4CPU x 16GB RAM cluster to accommodate the components in this tutorial.\n\n\n\n Sample network tutorial series \n\nThis three-part tutorial series guides you through the process of creating and interconnecting a relatively simple, multi-node Hyperledger Fabric network by using the IBM Blockchain Platform console to deploy a network into your Kubernetes cluster and deploy a smart contract.\n\nNote that while this tutorial shows how this process works with a paid Kubernetes cluster on IBM Cloud, the same basic flow applies to free clusters, albeit with a few limitations (for example, you cannot size or resize nodes in a free cluster).\n\n\n\n* Build a network tutorial This tutorial guides you through the process of hosting a network by creating two organizations, one for your peer and another for your ordering service, and a channel. Use this tutorial if you want to form a blockchain consortium by creating an ordering service and adding organizations.\n* [Join a network tutorial](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-join-networkibp-console-join-network) guides you through the process of joining an existing network by creating a peer and joining it to an existing channel.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-build-network"},{"document_id":"ibmcld_13218-8246-9251","score":12.0193703849,"text":"\nFor more information, see [Deploy NSX Manager Nodes to Form a Cluster from the UI](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.1\/installation\/GUID-B89F5831-62E4-4841-BFE2-3F06542D5BF5.htmlGUID-B89F5831-62E4-4841-BFE2-3F06542D5BF5).\n5. Configure a Virtual IP Address for a Cluster. se the IP addresses provisioned in the [previous tutorial](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-nsx-t-hostsvpc-bm-vmware-nsx-t-vlannics).For more information, see [Configure a Virtual IP Address for a Cluster](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.1\/installation\/GUID-A8DF27CC-B3A6-45F2-856D-4278A7DBC98E.html?hWord=N4IghgNiBcIG4EsAOIC+Q).\n6. Create transport zones. For simplicity, you can use the default overlay and VLAN transport zones. For more information, see [Create Transport Zones](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.1\/installation\/GUID-F739DC79-4358-49F4-9C58-812475F33A66.htmlGUID-F739DC79-4358-49F4-9C58-812475F33A66).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-nsx-t-deploy"},{"document_id":"ibmcld_03972-1580-3576","score":11.9409819231,"text":"\nIf you have not already used the IBM Blockchain Platform console to deploy components to a Kubernetes cluster on IBM Cloud, see [Getting started with IBM Blockchain Platform for IBM Cloud](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-deploy-iksibp-v2-deploy-iks). Note that the console itself does not reside in your cluster. It is a tool that you can use to deploy components into your cluster.\n\nWhether you deploy components to a paid or free Kubernetes cluster, pay close attention to the resources at your disposal when you choose to deploy nodes and create channels. It is your responsibility to manage your Kubernetes cluster and deploy additional resources if necessary. While components will successfully deploy to an IBM Cloud free cluster, the more components you add, the slower your components will run. For more information about component sizings and how the console interacts with your Kubernetes cluster on IBM Cloud, see [Allocating resources](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-allocate-resources).\n\n\n\n Sample network tutorial series \n\nYou are currently on the second part of our three-part tutorial series. This tutorial guides you through the process of using the console to create and join a peer node to an existing IBM Blockchain Platform network. Note that while this tutorial shows how this process works with a paid Kubernetes cluster on IBM Cloud, the same basic flow applies to free clusters, albeit with a few limitations (for example, you cannot size or resize nodes in a free cluster).\n\n\n\n* [Build a network tutorial](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-build-networkibp-console-build-network) guides you through the process of hosting a network by creating an ordering service and a peer.\n* Join a network tutorial (Current tutorial) Guides you through the process of joining an existing network by creating a peer and joining it to a channel.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-join-network"},{"document_id":"ibmcld_14512-19015-20276","score":11.8634079283,"text":"\nEnable encryption For more information about using the KMIP for VMware service to enable encryption, see [KMIP for VMware overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-kmip_standalone_considerationskmip_standalone_considerations). For more information about enabling VM encryption, see [Virtual machine encryption](https:\/\/docs.vmware.com\/en\/VMware-vSphere\/6.7\/com.vmware.vsphere.security.doc\/GUID-E6C5CE29-CD1D-4555-859C-A0492E7CB45D.html). For more information about using data at rest encryption to protect data in your vSAN cluster, see [Using encryption on a vSAN cluster](https:\/\/docs.vmware.com\/en\/VMware-vSphere\/6.7\/com.vmware.vsphere.virtualsan.doc\/GUID-F3B2714F-3406-48E7-AC2D-3677355C94D3.html). \n Add vSAN storage For more information about adding more vSphere ESXi hosts to your existing vSAN cluster, see [Adding ESXi servers to vCenter Server instances](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_addingservers). The addition of more hosts increases CPU, RAM, and storage to your cluster. For more information about vSAN technology, see [Expanding a vSAN cluster](https:\/\/docs.vmware.com\/en\/VMware-vSphere\/6.7\/com.vmware.vsphere.virtualsan.doc\/GUID-666D9839-2726-4936-8C0F-94476ECE0606.html).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-opsprocs-configure"},{"document_id":"ibmcld_11642-7-1535","score":11.7645610956,"text":"\nDeploying your OpenShift cluster and jump host \n\nThis topic takes you through the steps for creating the Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster and the associated jump host.\n\n\n\n Before you begin \n\nWhen you create the Red Hat OpenShift on IBM Cloud cluster, it is important that the flavor meets SAP's sizing recommendations and your expected workload characteristics, as well as the expected data volumes. The following implementation scenario is based on [Minimum Sizing for SAP Data Intelligence](https:\/\/help.sap.com\/viewer\/835f1e8d0dde4954ba0f451a9d4b5f10\/latest\/en-US\/d771891d749d425ba92603ec9b0084a8.html) and therefore is appropriate for a very basic test environment, only. When planning to setup and deploy a production cluster you must carefully consult the [Sizing Guide for SAP Data Intelligence](https:\/\/help.sap.com\/viewer\/835f1e8d0dde4954ba0f451a9d4b5f10\/latest\/en-US\/633d429ff69441ae81fe57d912397903.html) and adapt the flavors that will meet your specific needs. Before creating your cluster, please refer to the most recent SAP documentation, like [Installation](https:\/\/help.sap.com\/viewer\/a8d90a56d61a49718ebcb5f65014bbe7\/latest\/en-US\/9f866d8ef9a94c30947f12e73eaf0dd9.html) and [Administration Guide](https:\/\/help.sap.com\/viewer\/b13b5722c8ff4bf9bb097251310031d0\/latest\/en-US\/884ffcd587784ed2a311b2c19feb8410.html). You may find more related information in [SAP's Community page](https:\/\/community.sap.com\/topics\/data-intelligence).\n\nPlease check that your IBM Cloud account is eligible to create clusters.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-rhos-di-set-up-cluster"},{"document_id":"ibmcld_13222-12697-14123","score":11.6160984682,"text":"\nFor more information on creating NSX-T segments, see [VMware Docs](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.1\/administration\/GUID-316E5027-E588-455C-88AD-A7DA930A4F0B.html).\n\nThe VLAN IDs are only local to the hosts, they are not visible in IBM Cloud VPC.\n\n\n\n\n\n Step 4: Create NSX-T Tier-0 logical router \n\nIn this step, you will create the Tier 0 logical router or gateway in the NSX-T edge cluster. As the name says, this logical router is a logical construct inside the edge cluster VMs and uses virtual routing and forwarding (VRF) technology to separate routing tables etc..\n\n\n\n1. Create NSX-T Tier 0 logical router in the created NSX-T edge cluster.\n2. Set high availability (HA) mode as active-standby.\n3. Create external interfaces using the IPs created in the previous steps for each required uplink. Use the created VLAN backed segments as the Connected To (Segment).\n\n\n\nFor more information on creating Tier 0 logical router, see [VMware Docs](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.1\/administration\/GUID-E9E62E02-C226-457D-B3A6-FE71E45628F7.html).\n\nNSX-T has a strict URPF rule by default on the external uplinks. Make sure that your routing is symmetric, or Tier 0 logical routers may discard the packets arriving from a \"wrong\" interface. See more in [VMware Docs](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.1\/administration\/GUID-7B0CD287-C5EB-493C-A57F-EEA8782A741A.html).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-nsx-t-routing"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-593375-595353","score":19.8481827613,"text":"\n* When are the new Terraform and Ansible versions added to Schematics?\n\nAfter new Terraform and Ansible versions are released by the community, the IBM team begins hardening and testing the release for Schematics. Availability of new versions depends on the results of these tests, community updates, security patches, and technology changes between versions. Make sure that your Terraform templates and Ansible playbooks are compatible with one of the supported versions so that you can run them in Schematics. For more information, see [Upgrading the Terraform template version](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-migrating-terraform-version) and [Schematics runtime tools](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sch-utilitiessch-runtime-tf-job).\n* Can I run Ansible playbooks with Schematics?\n\nYes, you can run Ansible playbooks against your IBM Cloud by using the Schematics Actions or Ansible provisioner in your Terraform configuration file. For example, use the Ansible provisioner to deploy software on IBM Cloud resources or set actions against your resources, such as shutting down a virtual server instance. For more information, see [sample Ansible playbook templates for Schematics Actions](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sample_actiontemplates).\n* What are the updates in the agent beta-1 release?\n\nThe following are the features in Agent beta-1 release.\n\n\n\n* Improvements to the agent deployment experience through CLI.\n* Support to run Ansible playbooks on the agent.\n* Dynamic assignment of workspace or action jobs to the agent.\n\n\n\n* What are the costs of installing and using Agents?\n\nThe following are the cost break-down for the Schematics Agent.\n\nPre-requisite: Agent infrastructure\n\n\n\n* Cost of VPC infrastructure elements such as, subnet, public gateways.\n* Cost of IBM Kubernetes Service (cluster) on VPC, with three-node worker pool.\n* Cost of IBM Cloud Object Storage\n\n\n\nAgent beta-1 service","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-593333-595311","score":19.8481827613,"text":"\n* When are the new Terraform and Ansible versions added to Schematics?\n\nAfter new Terraform and Ansible versions are released by the community, the IBM team begins hardening and testing the release for Schematics. Availability of new versions depends on the results of these tests, community updates, security patches, and technology changes between versions. Make sure that your Terraform templates and Ansible playbooks are compatible with one of the supported versions so that you can run them in Schematics. For more information, see [Upgrading the Terraform template version](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-migrating-terraform-version) and [Schematics runtime tools](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sch-utilitiessch-runtime-tf-job).\n* Can I run Ansible playbooks with Schematics?\n\nYes, you can run Ansible playbooks against your IBM Cloud by using the Schematics Actions or Ansible provisioner in your Terraform configuration file. For example, use the Ansible provisioner to deploy software on IBM Cloud resources or set actions against your resources, such as shutting down a virtual server instance. For more information, see [sample Ansible playbook templates for Schematics Actions](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sample_actiontemplates).\n* What are the updates in the agent beta-1 release?\n\nThe following are the features in Agent beta-1 release.\n\n\n\n* Improvements to the agent deployment experience through CLI.\n* Support to run Ansible playbooks on the agent.\n* Dynamic assignment of workspace or action jobs to the agent.\n\n\n\n* What are the costs of installing and using Agents?\n\nThe following are the cost break-down for the Schematics Agent.\n\nPre-requisite: Agent infrastructure\n\n\n\n* Cost of VPC infrastructure elements such as, subnet, public gateways.\n* Cost of IBM Kubernetes Service (cluster) on VPC, with three-node worker pool.\n* Cost of IBM Cloud Object Storage\n\n\n\nAgent beta-1 service","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_05171-28090-29651","score":18.4479186074,"text":"\nThe example ends (leaving out most of the code for now) telling the app to listen on the port that is assigned and an environment property, or 3000 by default. When successfully starting at the start, it prints a message with the server URL to the console.\n\nvar express = require('express');\nvar cfenv = require('cfenv');\nvar bodyParser = require('body-parser');\nvar app = express();\n\/\/...\n\n\/\/ start server on the specified port and binding host\nvar port = process.env.PORT || 3000;\napp.listen(port, function() {\nconsole.log(\"To view your app, open this link in your browser: http:\/\/localhost:\" + port);\n});\n\/\/...\n\nLet's see how to define a path and views. The first line of code tells the Express framework to use the public directory to serve our static files, which include any static images and stylesheets we use. The lines that follow tell the app where to find the templates for our views in the src\/views directory, and set our view engine to be EJS. In addition, the framework uses the body-parser middleware to expose incoming request data to the app as JSON. In the closing lines of the example, the express app responds to all incoming GET requests to our app URL by rendering the index.ejs view template.\n\n\/\/...\n\/\/ serve the files out of .\/public as our main files\napp.use(express.static('public'));\napp.set('views', '.\/src\/views');\napp.set('view engine', 'ejs');\napp.use(bodyParser.json());\n\nvar title = 'COS Image Gallery Web Application';\n\/\/ Serve index.ejs\napp.get('\/', function (req, res) {\nres.render('index', {status: '', title: title});\n});","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-web-application"},{"document_id":"ibmcld_11997-5537-6386","score":18.3022879188,"text":"\n* Future: scheduled ops, drift detection, cost estimation, policy compliance\n\n\n\n\n\n\n\n\n\n Next steps \n\nSo far you have learned a little about Schematics Blueprints. The following are some next steps to explore.\n\n\n\n* [Working with blueprints and environments](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-work-with-blueprints) to understand how to use blueprints to manage the lifecycle of deploying and managing cloud environments.\n* See [understanding blueprint templates and configuration](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-blueprint-templates) to dig into how to define cloud environments using blueprint templates and inputs of latest version.\n* [Beta code for Schematics Blueprints](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-beta-limitations) to provide your feedback and understand beta limitations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-blueprint-intro"},{"document_id":"ibmcld_12581-17606-19704","score":17.0529602052,"text":"\nIf you are validating a deployable architecture that references modules from the catalog, make sure that the modules were onboarded to the catalog.\n\n\n\n1. From the Validate version page, enter the name of your Schematics service, select a resource group, select a Schematics region, and click Next.\n\nIn the Tags field, you can enter a name of a specific tag to attach to your template. This tag is put on the IBM Cloud Schematics workspace. Tags provide a way to organize, track usage costs, and manage access to the resources in your account.\n2. From the input variables section, review your parameter values, and click Next.\n3. In the Validation version section, select I have read and agree to the following license agreements.\n4. Click Validate.\n\nTo monitor the progress of the validation process, click View logs.\n\n\n\n\n\n\n\n Validating a test deployment by using the CLI \n\nTo validate a version of your deployable architecture into an existing product, run the [ibmcloud catalog offering version validate](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-catalogs-pluginvalidate-offering) command:\n\nibmcloud catalog offering version validate --vl <VERSION_LOCATOR>\n\n\n\n\n\n Reviewing cost by using the CLI \n\nReview the cost of your deployable architecture by using the console. To view the steps, see [Reviewing or defining cost by using the console](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-onboard-custom&interface=uicustom-cost-ui).\n\n\n\n\n\n Reviewing or defining cost by using the console \n\nYou can review the estimated starting cost of your product. If you included the resource metadata in your source repository, the information is parsed during validation and pulled into a starting cost per hour (USD) summary table. The table is displayed in the catalog for customers to compare across variations of a deployable architecture or to get a general idea of what a base configuration of your deployable architecture might cost.\n\nThe summary table lists the resources that your product uses and their estimated costs. Starting cost is an estimate based on available data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-onboard-custom"},{"document_id":"ibmcld_08921-1291-2538","score":16.9633944226,"text":"\n\"name\": \"Schematic Dev Workspace\",\n\u00a0 \"type\": [\n\u00a0\u00a0\u00a0 \"terraform_v0.13.7\"\n\u00a0 ],\n\u00a0 \"location\": \"us-south\",\n\u00a0 \"description\": \"Schematic Dev Workspace\",\n\u00a0 \"tags\": [],\n\u00a0 \"template_repo\": {\n\u00a0\u00a0\u00a0 \"url\": \"<GitHub repo URL>\",\n\u00a0\u00a0\u00a0 \"githubtoken\": \"<github-token>\"\n\u00a0 }\n\n\n\n Example Python request for schematics_variables_update.py file \n\nThe following Python example request is for the example file, schematics_variables_update.py.\n\nimport logging, os, json\n\nlogging.basicConfig()\nlogging.root.setLevel(logging.NOTSET)\nlogging.basicConfig(level=logging.NOTSET)\n\nfrom schematics_env_class import HPCCEnvironmentValues\n\nlogging.info(\"Schematic Variable Update Started\")\n\nif __name__ == '__main__':\n\n\u00a0\u00a0\u00a0 json_files = os.path.join(os.path.abspath(\".\"), \"config.json\")\n\n\u00a0\u00a0\u00a0 with open(json_files, \"r\") as file:\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 config_data = json.load(file)\n\n\u00a0\u00a0\u00a0 api_key = config_data[\"template_data\"][\"variablestore\"][\"value\"]\n\n\u00a0\u00a0\u00a0 schematic_obj = HPCCEnvironmentValues(api_key)\n\n\u00a0\u00a0\u00a0 workspace_response = schematic_obj.schematics_service.get_workspace(w_id=\"<workspace id>\").get_result()\n\u00a0\u00a0\u00a0 schematic_obj.update_variables(w_id=\"<workspace id>\",\u00a0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 t_id=workspace_response[\"template_data\"][\"id\"],\u00a0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 variablestore=config_data[\"template_data\"][\"variablestore\"]\n\u00a0\u00a0\u00a0 )","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ibm-spectrum-lsf?topic=ibm-spectrum-lsf-update-variables"},{"document_id":"ibmcld_12008-4112-6332","score":16.7119464645,"text":"\nCorrect the Terraform config error at source and push a new release to its Git source repository.\n\nIf explicit version of the blueprint modules is used on specific branches. The blueprint template requires updating in its Git repository to specify the new release tag or branch for the module statement.\n\n\n\n* Update the blueprint module statements to specify the new module version.\n* Push the new release of the blueprint template to its Git source repository. With an updated release tag for the template if needed.\n\n\n\nFor modules, when no Git release is specified on the blueprint module statements and relaxed module version are used. No update to the blueprint template is needed. The current change to the module repository is pulled automatically by Schematics.\n\nRun the ibmcloud schematics blueprint update command to refresh the blueprint configuration that is stored by Schematics with the update to the blueprint template. With latest release, Schematics identifies the updated module Git repository and run the Pull-Latest to update any modules with the modified Terraform configurations.\n\nibmcloud schematics blueprint update -id <blueprint_ID>\u00a0\n\nIf explicit version is used with release tags for each blueprint template release, the blueprint configuration must be updated in Schematics with the new release tag.\n\nibmcloud schematics blueprint update --id <blueprint_ID> --bp-git-release x.y.z\u00a0\u00a0\n\nFinally, run the ibmcloud schematics blueprint apply command to rerun the failed Terraform Apply operation and to complete all operations against all modules.\n\nibmcloud schematics blueprint apply -id <blueprint_ID>\u00a0\n\n\n\n\n\n Blueprint apply failure due to Terraform timeouts or transient failures \n\n What\u2019s happening \n\nWhen you run the blueprint apply command, it fails with message that the install of module fails.\n\n Why it\u2019s happening \n\nAnalysis of the logs indicates that the modules Terraform apply operation that is timed out or a transient failure occurs.\n\n How to fix it \n\nNo user action must be necessary to recover and the apply operation can be retried.\n\nRun the ibmcloud schematics blueprint apply command to rerun the failed Terraform Apply operation and complete all operations against all modules.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-apply-fails"},{"document_id":"ibmcld_08295-130293-131214","score":16.5843858804,"text":"\n\"value\": \"n {n internal = 800n external = 83009n protocol = \"tcp\"n }n ] ! ! ! \",\n\"description\": \"\",\n\"name\": \"docker_ports\",\n\"type\": \"list(object({n internal = numbern external = numbern protocol = stringn }))\",\n\"use_default\":true\n},\nExample ibmcloud schematics workspace update --id myworkspace-a1aa1a1a-a11a-11 --file myfile.json --json\n<-- <\/section \"id=\"section-syntax_of_variablestore\" \"> --><-- <\/section \"id=\"section-schematics-workspace-update\" \"> --><-- <section \"id=\"section-schematics-workspace-upload\" \"> --> ibmcloud schematics workspace upload Provide your Terraform template by uploading a tape archive file (.tar) to your Schematics Workspace.Before you begin, make sure that you created your workspace]ibmcloud workspace new] without a link to a GitHub or GitLab repository.Syntax ibmcloud schematics workspace upload --id WORKSPACE_ID --file FILE_NAME --template TEMPLATE_ID --output OUTPUT]--json] ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-slurm?topic=hpc-slurm-schematics-cli-reference"},{"document_id":"ibmcld_12258-139533-140454","score":16.5843858804,"text":"\n\"value\": \"n {n internal = 800n external = 83009n protocol = \"tcp\"n }n ] ! ! ! \",\n\"description\": \"\",\n\"name\": \"docker_ports\",\n\"type\": \"list(object({n internal = numbern external = numbern protocol = stringn }))\",\n\"use_default\":true\n},\nExample ibmcloud schematics workspace update --id myworkspace-a1aa1a1a-a11a-11 --file myfile.json --json\n<-- <\/section \"id=\"section-syntax_of_variablestore\" \"> --><-- <\/section \"id=\"section-schematics-workspace-update\" \"> --><-- <section \"id=\"section-schematics-workspace-upload\" \"> --> ibmcloud schematics workspace upload Provide your Terraform template by uploading a tape archive file (.tar) to your Schematics Workspace.Before you begin, make sure that you created your workspace]ibmcloud workspace new] without a link to a GitHub or GitLab repository.Syntax ibmcloud schematics workspace upload --id WORKSPACE_ID --file FILE_NAME --template TEMPLATE_ID --output OUTPUT]--json] ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-schematics-cli-reference&interface=cli"},{"document_id":"ibmcld_04516-139667-140633","score":16.4944145749,"text":"\n\"value\": \"n {n internal = 800n external = 83009n protocol = \"tcp\"n }n ] ! ! ! \",\n\"description\": \"\",\n\"name\": \"docker_ports\",\n\"type\": \"list(object({n internal = numbern external = numbern protocol = stringn }))\",\n\"use_default\":true\n},\nExample ibmcloud schematics workspace update --id myworkspace-a1aa1a1a-a11a-11 --file myfile.json --json\n<-- <\/section \"id=\"section-syntax_of_variablestore\" \"> --><-- <\/section \"id=\"section-schematics-workspace-update\" \"> --><-- <section \"id=\"section-schematics-workspace-upload\" \"> --> ibmcloud schematics workspace upload Provide your Terraform template by uploading a tape archive file (.tar) to your Schematics Workspace. Initial support for files up to 4MB in size.Before you begin, make sure that you created your workspace]ibmcloud workspace new] without a link to a GitHub or GitLab repository.Syntax ibmcloud schematics workspace upload --id WORKSPACE_ID --file FILE_NAME --template TEMPLATE_ID --output OUTPUT]--json] ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-schematics-cli-reference"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15160-8509-10437","score":10.8648309658,"text":"\n* Hyper Protect Crypto Services - it can be used when the original back is encrypted by using the Hyper Protect Crypto Services service.\n\n\n\n\n\nTags are automatically copied over from the parent backup.\n6. Click Save.\n7. The Summary updates automatically with the selections that you made. For example, the plan might be \"Every Monday at -5:53 UTC (12:30 AM CDT) starting on 26 March 2022.\" The Plan status toggle is enabled by default.\n8. Click Create to save the new plan. The list of plans is updated in the policy details page. If you want to make any changes, click the pencil icon for that plan. If you want to delete the plan, click the delete icon.\n\n\n\n\n\n\n\n Estimating your expected usage and costs \n\nUse the cost estimator to see what your backups might cost based on the rate of expected change in your Block Storage for VPC volumes.\n\n\n\n1. After you [create your backup policy and plan](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-planbackup-policy-create-ui), on the side panel of Backup summary, click Add to estimate.\n2. On the Estimate side panel, enter your expected usage to the initial costs. The backup policy is without charge. You pay for the amount of backup storage that is used. Provide the following estimates:\n\n\n\n* Number of volumes you want to associate with the backup policy.\n* Average amount of data per volume (in GBs). For example, you might associate two volumes with a policy. The first volume has 4 GB of data and the second 20 GB. An average of the two would be 12 GB.\n* Number of backups per volume per month. You can take a maximum of 750 backup snapshots per volume.\n* Percent of incremental change after the initial backup. For example, 15 percent increase in size for each subsequent backup.\n\n\n\n3. When you're finished, click Calculate cost.\n\n\n\nThe cost estimate summary shows how the costs are calculated and breaks down the storage cost, providing a monthly estimate.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan"},{"document_id":"ibmcld_05076-6132-7534","score":10.4135512877,"text":"\n5 10 TB 10 TB 100% $1,139 $400 \n 6 10 TB 15 TB 150% $1,591 $652 \n Total $4,438 $2,652 \n\n\n\n\n\n\n\n Aggregation pricing example \n\nImagine a large enterprise account called \"Rainbow Co.\". It has a number of subsidiary accounts, such as \"Blue\", and \"Green\". Each of these accounts has dozens (or more) Object Storage instances spread out across different regions. Some have large volumes of storage that is rarely read, while others have smaller volumes but very high rates of egress.\n\nBlue (us-east, us-south):\n\n\n\n Metric Usage Standard Cost \n\n Storage 100 TB $2,300 \n Class A 100 $0 \n Class B 100 $0 \n Egress 100 GB $9 \n Total cost $2,309 \n\n\n\nGreen (eu-de, milO1):\n\n\n\n Metric Usage Standard Cost \n\n Storage 100 GB $2 \n Class A 11,000,000 $55 \n Class B 110,000,000 $44 \n Egress 120 TB $10,800 \n Total cost $10,901 \n\n\n\nRainbow Co. (Blue and Green):\n\n\n\n Metric Total usage Total Standard Cost Allowance Billable Quantity One Rate Cost \n\n Storage 100 TB $2,302 0 GB 100 TB $4,004 \n Class A 11,000,100 $55 10,010,000 990,100 $5 \n Class B 110,000,100 $44 100,100,000 9,900,100 $4 \n Egress 120 TB $10,809 100 TB 20 TB $1,000 \n Total cost $13,210 $5,013 \n\n\n\nNote that the One Rate cost is significantly lower due to the reduced cost for egress. Also note that rather than dozens of individual invoices (one for each service instance), there will only be four invoices - one for each location used.\n\n\n\n\n\n\n\n What next","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-onerate"},{"document_id":"ibmcld_09795-17883-19451","score":10.3697008653,"text":"\nNotice that since the Base cost per host time-series allotment was not completely used by the agents, 350 of the 500 platform metrics time-series were covered by the base tier. Only the additional 150 platform metrics time-series (500 - 350 = 150)have an additional cost.\n\n150 * 0.08 USD (Tier-1) = 12 USD\n\nThe total cost for time-series is 12 USD.\n\n\n\nThe total monitoring cost per month is 117 USD.\n\n108 USD + 12 USD = 120 USD\n\n\n\n\n\n Billing sample 5: Basic usage for Virtual Machine or Bare Metal servers running an agent for non-orchestrated environments \n\nConsider the following example where you have the following configuration:\n\n\n\n* 3 hosts running an agent for non-orchestrated environments\n\n\n\n* Host-1 generates 50 custom metrics time-series\n* Host-2 generates 100 custom metrics time-series\n* Host-3 generates 100 custom metrics time-series\n\n\n\n\n\nThe billing calculation for the month is calculated as follows:\n\n\n\n* Base cost per host\n\nThe base price per host per month is 9.36 USD.\n\nFor 3 hosts, the total base cost is 27 USD.\n\n3 * 9.36 USD = 28.08 USD\n* Time-series cost\n\nTime-series are priced based on the tiers. In this scenario you require 250 additional time-series.\n\n50 + 100 + 100 = 250\n\nThe result from adding the time series per host defines the tier that is applied for pricing.\n\n250 time-series corresponds to tier 1. The price per host is 0.08 USD for up to 100K time-series per month.\n\n250 * 0.08 USD = 20 USD\n\nThe total cost for additional time-series is 20 USD.\n\n\n\nThe total monitoring cost per month is 48 USD.\n\n28.08 USD + 20 USD = 48.08 USD","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-pricing_plans"},{"document_id":"ibmcld_04260-0-1777","score":10.3228604459,"text":"\n\n\n\n\n\n\n  Using the Pricing calculator to estimate your monthly cost per user per month \n\nThe pricing information for your system resources is shown on the side of the provisioining window and shows all of your equipment and physical resource costs. To view the cost estimates for your organization on a per user basis, use the pricing calculator. You can get estimates for different configurations before you begin provisioning. The pricing calculator is on the DaaS estimate tab on the main Citrix-DaaS product page.\n\n\n\n  What the pricing calculator does \n\nThe pricing calculator looks at several factors to estimate your cost and savings with different Citrix-DaaS configurations:\n\n\n\n1.  The geographic area and region where your resources are located.\n2.  The number of users that use your system.\n3.  The operating system that your system uses.\n4.  The boot volume size on your system.\n5.  The profile settings for your system, including the image to use, CPU, RAM, etc.\n\n\n\nThe calculator takes the inputs and creates a per user estimate for your configuration.\n\n\n\n\n\n  Calculating cost per user for your system \n\nTo calculate the cost per users for your Citrix-DaaS configuration:\n\n\n\n1.  From the Citrix-DaaS product page, select the DaaS estimate tab. The pricing calculator is shown.\n2.  Enter the geographic, user, OS, and boot volume information for your system.\n3.  Verify that the profile settings listed match your system or match the system that you are estimating. If they do not match, select Change Profile to enter the correct profile information.\n\n\n\nThe calculator shows you the cost estimate per user for your system.\n\nIf you want to see estimates for different profiles, or different numbers of users, modify the specific fields to see new estimates.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/citrix-daas?topic=citrix-daas-pricing-calculator-monthly-cost"},{"document_id":"ibmcld_15164-8548-10361","score":10.0887045218,"text":"\n* Hyper Protect Crypto Services - it can be used when the original back is encrypted by using the Hyper Protect Crypto Services service.\n\n\n\n\n\nTags are automatically copied over from the parent backup.\n6. Click Save.\n7. The Summary updates automatically with the selections that you made. For example, the plan might be \"Every Monday at -5:53 UTC (12:30 AM CDT) starting on 26 March 2022.\" The Plan status toggle is enabled by default.\n8. Click Create to save the new plan. The list of plans is updated in the policy details page. If you want to make any changes, click the pencil icon for that plan. If you want to delete the plan, click the delete icon.\n\n\n\n\n\n\n\n Estimating your expected usage and costs \n\nUse the cost estimator to see what your backups might cost based on the rate of expected change in your Block Storage for VPC volumes.\n\n\n\n1. After you [create your backup policy and plan](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=uibackup-policy-create-ui), on the side panel of Backup summary, click Add to estimate.\n2. On the Estimate side panel, enter your expected usage to the initial costs. The backup policy is without charge. You pay for the amount of backup storage that is used. Provide the following estimates:\n\n\n\n* Number of volumes you want to associate with the backup policy.\n* Average amount of data per volume (in GBs). For example, you might associate two volumes with a policy. The first volume has 4 GB of data and the second 20 GB. An average of the two would be 12 GB.\n* Number of backups per volume per month. You can take a maximum of 750 backup snapshots per volume.\n* Percent of incremental change after the initial backup. For example, 15 percent increase in size for each subsequent backup.\n\n\n\n3. When you're finished, click Calculate cost.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=ui"},{"document_id":"ibmcld_15161-8551-10365","score":10.0887045218,"text":"\n* Hyper Protect Crypto Services - it can be used when the original back is encrypted by using the Hyper Protect Crypto Services service.\n\n\n\n\n\nTags are automatically copied over from the parent backup.\n6. Click Save.\n7. The Summary updates automatically with the selections that you made. For example, the plan might be \"Every Monday at -5:53 UTC (12:30 AM CDT) starting on 26 March 2022.\" The Plan status toggle is enabled by default.\n8. Click Create to save the new plan. The list of plans is updated in the policy details page. If you want to make any changes, click the pencil icon for that plan. If you want to delete the plan, click the delete icon.\n\n\n\n\n\n\n\n Estimating your expected usage and costs \n\nUse the cost estimator to see what your backups might cost based on the rate of expected change in your Block Storage for VPC volumes.\n\n\n\n1. After you [create your backup policy and plan](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=apibackup-policy-create-ui), on the side panel of Backup summary, click Add to estimate.\n2. On the Estimate side panel, enter your expected usage to the initial costs. The backup policy is without charge. You pay for the amount of backup storage that is used. Provide the following estimates:\n\n\n\n* Number of volumes you want to associate with the backup policy.\n* Average amount of data per volume (in GBs). For example, you might associate two volumes with a policy. The first volume has 4 GB of data and the second 20 GB. An average of the two would be 12 GB.\n* Number of backups per volume per month. You can take a maximum of 750 backup snapshots per volume.\n* Percent of incremental change after the initial backup. For example, 15 percent increase in size for each subsequent backup.\n\n\n\n3. When you're finished, click Calculate cost.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=api"},{"document_id":"ibmcld_15162-8551-10365","score":10.0887045218,"text":"\n* Hyper Protect Crypto Services - it can be used when the original back is encrypted by using the Hyper Protect Crypto Services service.\n\n\n\n\n\nTags are automatically copied over from the parent backup.\n6. Click Save.\n7. The Summary updates automatically with the selections that you made. For example, the plan might be \"Every Monday at -5:53 UTC (12:30 AM CDT) starting on 26 March 2022.\" The Plan status toggle is enabled by default.\n8. Click Create to save the new plan. The list of plans is updated in the policy details page. If you want to make any changes, click the pencil icon for that plan. If you want to delete the plan, click the delete icon.\n\n\n\n\n\n\n\n Estimating your expected usage and costs \n\nUse the cost estimator to see what your backups might cost based on the rate of expected change in your Block Storage for VPC volumes.\n\n\n\n1. After you [create your backup policy and plan](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=clibackup-policy-create-ui), on the side panel of Backup summary, click Add to estimate.\n2. On the Estimate side panel, enter your expected usage to the initial costs. The backup policy is without charge. You pay for the amount of backup storage that is used. Provide the following estimates:\n\n\n\n* Number of volumes you want to associate with the backup policy.\n* Average amount of data per volume (in GBs). For example, you might associate two volumes with a policy. The first volume has 4 GB of data and the second 20 GB. An average of the two would be 12 GB.\n* Number of backups per volume per month. You can take a maximum of 750 backup snapshots per volume.\n* Percent of incremental change after the initial backup. For example, 15 percent increase in size for each subsequent backup.\n\n\n\n3. When you're finished, click Calculate cost.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=cli"},{"document_id":"ibmcld_15163-8569-10389","score":10.0887045218,"text":"\n* Hyper Protect Crypto Services - it can be used when the original back is encrypted by using the Hyper Protect Crypto Services service.\n\n\n\n\n\nTags are automatically copied over from the parent backup.\n6. Click Save.\n7. The Summary updates automatically with the selections that you made. For example, the plan might be \"Every Monday at -5:53 UTC (12:30 AM CDT) starting on 26 March 2022.\" The Plan status toggle is enabled by default.\n8. Click Create to save the new plan. The list of plans is updated in the policy details page. If you want to make any changes, click the pencil icon for that plan. If you want to delete the plan, click the delete icon.\n\n\n\n\n\n\n\n Estimating your expected usage and costs \n\nUse the cost estimator to see what your backups might cost based on the rate of expected change in your Block Storage for VPC volumes.\n\n\n\n1. After you [create your backup policy and plan](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=terraformbackup-policy-create-ui), on the side panel of Backup summary, click Add to estimate.\n2. On the Estimate side panel, enter your expected usage to the initial costs. The backup policy is without charge. You pay for the amount of backup storage that is used. Provide the following estimates:\n\n\n\n* Number of volumes you want to associate with the backup policy.\n* Average amount of data per volume (in GBs). For example, you might associate two volumes with a policy. The first volume has 4 GB of data and the second 20 GB. An average of the two would be 12 GB.\n* Number of backups per volume per month. You can take a maximum of 750 backup snapshots per volume.\n* Percent of incremental change after the initial backup. For example, 15 percent increase in size for each subsequent backup.\n\n\n\n3. When you're finished, click Calculate cost.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=terraform"},{"document_id":"ibmcld_00061-1110-1753","score":9.8692147453,"text":"\n[(2036943312, 33.7631862, -84.3939405),\n(3523447568, 33.7632666, -84.3939315),\n(2036943524, 33.7633273, -84.3939155)]\n4. Find the best route with minimal distance cost (the fastest route distance-wise):\n\n>>> best_distance_route = router.compute_route(start, end, method='distance')\n Check distance cost, in the unit of meters\n>>> best_distance_route.cost\n2042,4082601271236\n Check route path (only showing the first three points), which is a list of points in 3-tuple (osm_point_id, lat, lon)\n>>> best_distance_route.path[:3]\n[(2036943312, 33.7631862, -84.3939405),\n(3523447568, 33.7632666, -84.3939315),\n(2036943524, 33.7633273, -84.3939155)]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-routing-functions"},{"document_id":"ibmcld_09795-13315-15258","score":9.8200651643,"text":"\nEach host has a 1000 time-series allotment that are included in the base cost per host of 36 USD. If you have 3 hosts, you have 3000 time-series included. The remaining time-series are priced based on the tiers. The following shows the calculation of the 700 additional time-series.\n\n1200 + 1000 + 1500 - ( 31000 ) = 700\n\nThe result from adding the time series per host minus the allotment defines the tier that is applied for pricing.\n\n700 additional time-series corresponds to tier 1. The price per host is 0.08 USD for up to 100K time-series per month.\n\n700 * 0.08 USD = 56 USD\n\nThe total cost for additional time-series is 56 USD.\n\n\n\nThe total monitoring cost per month is 164 USD.\n\n108 USD + 56 USD = 164 USD\n\n\n\n\n\n Billing sample 2: Unused time-series allotment \n\nConsider the following example where you have the following configuration:\n\n\n\n* 2 Kubernetes or OpenShift clusters with a total of 5 worker nodes running agents for orchestrated environments\n\n\n\n* Host-1 generates 2000 custom metrics time-series\n* Host-2 generates 100 custom metrics time-series\n* Host-3 generates 500 custom metrics time-series\n* Host-4 generates 100 custom metrics time-series\n* Host-5 generates 200 custom metrics time-series\n\n\n\n\n\nThe billing calculation for the month is calculated as follows:\n\n\n\n* Base cost per host\n\nThe price per host per month is 36 USD which includes up to 1K time-series (includes Prometheus, JMX, appchecks, and StatsD metrics) and 50 containers.\n\nFor 5 hosts, the total base cost is 180 USD.\n\n5 * 36 USD = 180 USD\n* Additional time-series cost\n\nEach host has a 1000 time-series allotment. The remaining time-series are priced based on the tiers.\n\n2000 + 100 + 500 + 100 + 200 - ( 51000 ) = -1100\n\nThe result from adding the time series per host minus the allotment defines the tier that is applied for pricing.\n\nYou have 1100 more time-series available per your configuration.\n\nThe total cost for additional time-series is 0 USD.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-pricing_plans"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04031-6179-7910","score":20.1134513666,"text":"\n[Elements of pricing](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/elements-of-pricing.svg)\n\nFigure 1. Elements of pricing\n\n\n\n* IBM Blockchain Platform: Based on a flat rate of $0.29 USD\/VPC-hour. This fee represents the charge for your blockchain component VPC allocation in your Kubernetes cluster.\n* IBM Cloud Kubernetes Service: While you can link your IBM Blockchain Platform service instance to either an IBM Cloud Kubernetes service cluster or an OpenShift cluster, this pricing model is based on the usage of an IBM Cloud Kubernetes service cluster. The IBM Cloud Kubernetes service uses a tiered pricing model that is visible in IBM Cloud when you provision your paid cluster. This includes the charges for your compute, that is, CPU and memory. IBM Cloud Kubernetes Services are priced on a tiered model that is based on the number of hours of usage per month. Therefore, when you examine pricing plans, consider that 24x7 usage is equivalent to 720 hours per month. Refer to the table on the [Kubernetes Service Catalog page](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/about) for more details on cluster pricing. Customers who are interested in pricing OpenShift clusters can review [Red Hat OpenShift on IBM Cloud Pricing](https:\/\/www.ibm.com\/cloud\/openshift\/pricing).\n* Storage: Choose the storage plan that works for your needs. See [Understanding Kubernetes storage basics](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kube_conceptskube_concepts) to learn more about your storage class options and how much they [cost](https:\/\/www.ibm.com\/cloud\/file-storage\/pricing). The IBM Blockchain Platform nodes use the default storage class for the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_03994-15948-17676","score":18.9883667326,"text":"\nIf you do not want to use the default File Storage that is pre-selected for you when you provision a Kubernetes cluster in IBM Cloud, you can provision storage of your choice. See this topic on [Persistent storage considerations](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-deploy-iksibp-console-storage) to learn more.\n* If you decide to include IBM Cloud multi-zone support in your Kubernetes cluster on IBM Cloud, you must provision your own storage. See [Using Multizone (MZR) clusters with IBM Blockchain Platform](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-deploy-iksibp-console-mzr) for more details.\n* You can preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster. Performance will be limited by throughput, storage and functionality. IBM Cloud will delete your cluster after 30 days and you cannot migrate any nodes or data from a free cluster to a paid cluster. If you choose a paid Kubernetes cluster instead of the limited free cluster, you will incur charges for the Kubernetes service to your IBM Cloud account.\n* Kubernetes clusters that are configured with private VLANs are not supported.\n\n\n\n\n\n\n\n License and pricing \n\nIBM Blockchain Platform for IBM Cloud introduces a new hourly pricing model based on virtual processor core (VPC) usage. The simplified model is based on the amount of CPU (or VPC) that your IBM Blockchain Platform nodes consume on an hourly basis, at a flat rate of $0.29 USD\/VPC-hour, where 1 VPC = 1 CPU. See this topic on [Pricing](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing) for more details.\n\n\n\n\n\n Getting started","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-overview"},{"document_id":"ibmcld_07578-882118-884014","score":18.2302240313,"text":"\nYou can also [create stand-alone volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-block-storagecreate-standalone-vol) and later attach them to your instances.\n* How many instances can share a provisioned Block Storage for VPC volume?\n\n How many instances can share a provisioned Block Storage for VPC volume? \n\nA Block Storage for VPC volume can be attached to only one instance at a time. Instances cannot share a volume.\n* How many Block Storage for VPC secondary data volumes can be attached to an instance?\n\n How many Block Storage for VPC secondary data volumes can be attached to an instance? \n\nYou can create 12 Block Storage for VPC data volumes per instance, plus the boot volume.\n* How am I charged for usage?\n\n How am I charged for usage? \n\nCost for Block Storage for VPC is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The volume exists on the account until you delete the volume or you reach the end of a billing cycle, whichever comes first.\n\nPricing is also affected when you [expand volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile. For example, expanding volume capacity increases costs, and changing an IOPS profile from a 5-IOPS\/GB tier to a 3-IOPS\/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n* Are there limits on the number of volumes I can create?\n\n Are there limits on the number of volumes I can create?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-881995-883891","score":18.2302240313,"text":"\nYou can also [create stand-alone volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-block-storagecreate-standalone-vol) and later attach them to your instances.\n* How many instances can share a provisioned Block Storage for VPC volume?\n\n How many instances can share a provisioned Block Storage for VPC volume? \n\nA Block Storage for VPC volume can be attached to only one instance at a time. Instances cannot share a volume.\n* How many Block Storage for VPC secondary data volumes can be attached to an instance?\n\n How many Block Storage for VPC secondary data volumes can be attached to an instance? \n\nYou can create 12 Block Storage for VPC data volumes per instance, plus the boot volume.\n* How am I charged for usage?\n\n How am I charged for usage? \n\nCost for Block Storage for VPC is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The volume exists on the account until you delete the volume or you reach the end of a billing cycle, whichever comes first.\n\nPricing is also affected when you [expand volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile. For example, expanding volume capacity increases costs, and changing an IOPS profile from a 5-IOPS\/GB tier to a 3-IOPS\/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n* Are there limits on the number of volumes I can create?\n\n Are there limits on the number of volumes I can create?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-966486-968340","score":17.9380240063,"text":"\nSnapshots have their own lifecycle, independent of the Block Storage for VPC volume. You can separately manage the source volume. However, when you take a snapshot, you must wait for the snapshot creation process to complete before you detach or delete the volume.\n* How am I charged for usage?\n\nCost for snapshots is calculated based on GB capacity that is stored per month, unless the duration is less than one month. Because the snapshot is based on the capacity that was provisioned for the original volume, the snapshot capacity does not vary. Deleting snapshots reduces cost, so the fewer snapshots you retain the lower the cost becomes.\n\nPricing for snapshots is also set by region. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n\nWhen you use the [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) feature, your existing regional plan is adjusted. Billing for fast restore is based on instance hours. For more information about the cost of fast restore, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n\n\n\n Can I add tags to a Block Storage for VPC snapshot? \n\nDepending on the action that you're performing, you can add user tags and access management tags to your snapshots. User tags are used by the backup service to periodically create backup snapshots of the volume. Access management tags help organize access to your Block Storage for VPC snapshots. For more information, see [Tags for Block Storage for VPC snapshots](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots-about-tags).\n\n\n\n\n\n Can I use volume snapshot for disaster recovery? \n\nYou can use your snapshots and backups to create volumes in case of an emergency. You can also create copies of your snapshot in other regions and use them to create volumes there.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-966362-968216","score":17.9380240063,"text":"\nSnapshots have their own lifecycle, independent of the Block Storage for VPC volume. You can separately manage the source volume. However, when you take a snapshot, you must wait for the snapshot creation process to complete before you detach or delete the volume.\n* How am I charged for usage?\n\nCost for snapshots is calculated based on GB capacity that is stored per month, unless the duration is less than one month. Because the snapshot is based on the capacity that was provisioned for the original volume, the snapshot capacity does not vary. Deleting snapshots reduces cost, so the fewer snapshots you retain the lower the cost becomes.\n\nPricing for snapshots is also set by region. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n\nWhen you use the [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) feature, your existing regional plan is adjusted. Billing for fast restore is based on instance hours. For more information about the cost of fast restore, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n\n\n\n Can I add tags to a Block Storage for VPC snapshot? \n\nDepending on the action that you're performing, you can add user tags and access management tags to your snapshots. User tags are used by the backup service to periodically create backup snapshots of the volume. Access management tags help organize access to your Block Storage for VPC snapshots. For more information, see [Tags for Block Storage for VPC snapshots](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots-about-tags).\n\n\n\n\n\n Can I use volume snapshot for disaster recovery? \n\nYou can use your snapshots and backups to create volumes in case of an emergency. You can also create copies of your snapshot in other regions and use them to create volumes there.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_15111-1536-3423","score":17.8754625513,"text":"\nThe volume exists on the account until you delete the volume or you reach the end of a billing cycle, whichever comes first.\n\nPricing is also affected when you [expand volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile. For example, expanding volume capacity increases costs, and changing an IOPS profile from a 5-IOPS\/GB tier to a 3-IOPS\/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n\n\n\n\n\n Are there limits on the number of volumes I can create? \n\nYou can create up to 300 total Block Storage for VPC volumes (data and boot) per account in a region. To increase this [quota](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-quotasblock-storage-quotas), open a [support case](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-help) and specify the zone where you need more volumes.\n\n\n\n\n\n After a data volume is created with a specific capacity, can the capacity later be increased? \n\nYou can increase the capacity of data volumes that are attached to a virtual server instance. You can indicate capacity in GB increments up to 16,000 GB capacity, depending on your volume profile. For more information, see [Increasing Block Storage for VPC volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes).\n\n\n\n\n\n Can I increase capacity of a boot volume? \n\nBoot volume capacity can be increased during instance provisioning or later, by directly modifying the boot volume.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-vpc-faq"},{"document_id":"ibmcld_04031-7518-9418","score":17.6899437699,"text":"\n* Storage: Choose the storage plan that works for your needs. See [Understanding Kubernetes storage basics](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kube_conceptskube_concepts) to learn more about your storage class options and how much they [cost](https:\/\/www.ibm.com\/cloud\/file-storage\/pricing). The IBM Blockchain Platform nodes use the default storage class for the cluster. When you provision a Kubernetes cluster in IBM Cloud, it is preconfigured with [Gold File storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-file_storagefile_predefined_storageclass) as the persistent storage plug-in.\n* Advanced features: Options that are available for Production networks for increased security, disaster recovery, and health monitoring of the nodes. Costs vary depending on the options you choose.\n\n\n\nWhen you allocate VPCs (or CPU) to a blockchain node, the node consumes CPUs from your Kubernetes cluster allocation. Therefore the size of the Kubernetes cluster that is required directly depends on the size and quantity of the blockchain nodes that you deploy.\n\n\n\n\n\n Pricing examples \n\nThe following table provides two examples of pricing with [default resource allocations](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricingibp-saas-pricing-default) unless otherwise noted. Both examples assume an IBM Cloud Kubernetes service cluster and the default CouchDB database is used as the peer database. It also assumes peers are deployed with Fabric v2.x images instead of Fabric v1.4 images.\n\n\n\n* The Test network scenario is suitable for getting started with your first use case with IBM Blockchain and testing smart contracts.\n* The Join a network scenario includes two peers, and a Certificate Authority (CA) that is required for organization membership.\n\n\n\n* These peers can join a production IBM Blockchain Platform network that is hosted elsewhere.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_05666-6093-7968","score":17.4396452449,"text":"\nClassic clusters: When you create a standard cluster, a portable public subnet with 8 public IP addresses is ordered and charged to your account monthly. For pricing information, see the [Subnets and IPs](https:\/\/cloud.ibm.com\/docs\/subnets) documentation or estimate your costs in the [classic subnets console)](https:\/\/cloud.ibm.com\/classic\/network\/subnet\/provision). If you already have available portable public subnets in your infrastructure account, you can use these subnets instead. Create the cluster with the --no-subnets[flag](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_create), and then [reuse your subnets](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-subnetssubnets_custom).\n\nVPC clusters: For more information about charges for floating IPs and other networking costs, see [Pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\n\n\n\n\n Multizone load balancer \n\nWhen you create a multizone cluster or add zones to a single zone cluster, you must have a load balancer to health check Ingress and load balancer IP addresses in each zone, and forward requests to your apps across zones in the region.\n\nThe type of load balancer that is automatically created varies depending on the type of cluster.\n\n\n\n* Classic clusters: An Akamai MZLB is automatically created for each multizone cluster. You can view the hourly rate in the pricing summary when you create the cluster.\n* VPC clusters: A Load Balancer for VPC is automatically created in your VPC for your cluster. For cost information, see [Pricing for Load Balancer for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\n\n\n\n\n\n\n Storage \n\nWhen you provision storage, you can choose the storage type and storage class that is correct for your use case. Charges vary depending on the type of storage, the location, and the specs of the storage instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_05666-7536-9272","score":17.2320805761,"text":"\n* VPC clusters: A Load Balancer for VPC is automatically created in your VPC for your cluster. For cost information, see [Pricing for Load Balancer for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\n\n\n\n\n\n\n Storage \n\nWhen you provision storage, you can choose the storage type and storage class that is correct for your use case. Charges vary depending on the type of storage, the location, and the specs of the storage instance. Some storage solutions, such as file and block storage offer hourly and monthly rates that you can choose from.\n\nTo choose the correct storage solution, see [Planning highly available persistent storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan). For more information, see:\n\n\n\n* [File Storage for Classic](https:\/\/www.ibm.com\/products\/file-storage)\n* [Block Storage for Classic](https:\/\/www.ibm.com\/products\/block-storage)\n* [File Storage for VPC](https:\/\/www.ibm.com\/products\/file-storage)\n* [Block Storage for VPC](https:\/\/www.ibm.com\/products\/block-storage)\n* [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage)\n* [Portworx Enterprise pricing](https:\/\/cloud.ibm.com\/catalog\/services\/portworx-enterprise)\n\n\n\n\n\n\n\n IBM Cloud services \n\nEach service that you integrate with your cluster has its own pricing model. Review each product documentation and use the IBM Cloud console to [estimate costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\n\n\n\n\n Operators and other third-party integrations \n\nOperators and other [third-party integrations](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-supported_integrations) are a convenient way to add services to your cluster from community, third-party, your own, or other providers.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.25,"recall_5":0.5,"recall_10":0.75,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.3633175613,"ndcg_cut_10":0.4761627026}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-891912-893651","score":18.5640732839,"text":"\nThe first snapshot is a full backup of the volume. Subsequent snapshots of the same volume capture only the changes since the last snapshot. For more information, see [About Block Storage for VPC Snapshots for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about).\n* What is a backup snapshot?\n\n What is a backup snapshot? \n\nBackup snapshots, simply called \"backups\", are snapshots that are automatically created by the Backup for VPC service. For more information, see [About Backup for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about).\n* What can I do about data backups for disaster recovery?\n\n What can I do about data backups for disaster recovery? \n\nBlock Storage for VPC secures your data across redundant fault zones in your region. By using the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* What is restoring a volume from a snapshot?\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-891789-893528","score":18.5640732839,"text":"\nThe first snapshot is a full backup of the volume. Subsequent snapshots of the same volume capture only the changes since the last snapshot. For more information, see [About Block Storage for VPC Snapshots for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about).\n* What is a backup snapshot?\n\n What is a backup snapshot? \n\nBackup snapshots, simply called \"backups\", are snapshots that are automatically created by the Backup for VPC service. For more information, see [About Backup for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about).\n* What can I do about data backups for disaster recovery?\n\n What can I do about data backups for disaster recovery? \n\nBlock Storage for VPC secures your data across redundant fault zones in your region. By using the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* What is restoring a volume from a snapshot?\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_14984-13428-15314","score":18.5244623362,"text":"\nThe instance must be in a Running state.\n3. On the Instance details page, scroll to the list of Storage volumes and click Attach volumes. A side panel opens for you to define the volume attachment.\n4. From the Attach data volume panel, expand the list of Block volumes, and select Create a data volume.\n5. Select Import from snapshot. Expand the Snapshot list and select a backup snapshot.\n6. Optionally, increase the size of the volume within the specified range.\n7. Click Save. The side panel closes and messages indicate that the restored volume is being attached to the instance.\n\n\n\nThe new volume appears in the list of Storage volumes. Hover over the camera icon to see the name of the backup snapshot from which it was created.\n\n\n\n\n\n\n\n Restoring a volume from a snapshot from the CLI \n\nUse the CLI to create a boot or data volume from a backup snapshot. The commands are the same as the ones that are used to restore a volume from a manually created snapshot. For more information, see [Restore a volume from a snapshot with the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore&interface=clisnapshots-vpc-restore-CLI).\n\nFor more information about all backup service commands, see the [VPC CLI reference](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference).\n\n\n\n\n\n Restoring a volume from a backup snapshot with the API \n\nYou can restore boot and data volumes from a backup snapshot with the VPC API. To begin, make a GET \/snapshots request to see a list of snapshots. You can filter by resource group and source volume ID in the request.\n\n\n\n* To restore a boot volume from a bootable backup snapshot, specify the boot volume attachment and snapshot ID in the POST \/instances request.\n* To restore a data volume from a backup snapshot and attach it, specify the data volume attachment and snapshot ID in the POST \/instances request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore"},{"document_id":"ibmcld_14996-13519-15405","score":18.5244623362,"text":"\nThe instance must be in a Running state.\n3. On the Instance details page, scroll to the list of Storage volumes and click Attach volumes. A side panel opens for you to define the volume attachment.\n4. From the Attach data volume panel, expand the list of Block volumes, and select Create a data volume.\n5. Select Import from snapshot. Expand the Snapshot list and select a backup snapshot.\n6. Optionally, increase the size of the volume within the specified range.\n7. Click Save. The side panel closes and messages indicate that the restored volume is being attached to the instance.\n\n\n\nThe new volume appears in the list of Storage volumes. Hover over the camera icon to see the name of the backup snapshot from which it was created.\n\n\n\n\n\n\n\n Restoring a volume from a snapshot from the CLI \n\nUse the CLI to create a boot or data volume from a backup snapshot. The commands are the same as the ones that are used to restore a volume from a manually created snapshot. For more information, see [Restore a volume from a snapshot with the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore&interface=clisnapshots-vpc-restore-CLI).\n\nFor more information about all backup service commands, see the [VPC CLI reference](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference).\n\n\n\n\n\n Restoring a volume from a backup snapshot with the API \n\nYou can restore boot and data volumes from a backup snapshot with the VPC API. To begin, make a GET \/snapshots request to see a list of snapshots. You can filter by resource group and source volume ID in the request.\n\n\n\n* To restore a boot volume from a bootable backup snapshot, specify the boot volume attachment and snapshot ID in the POST \/instances request.\n* To restore a data volume from a backup snapshot and attach it, specify the data volume attachment and snapshot ID in the POST \/instances request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore&interface=ui"},{"document_id":"ibmcld_14996-2951-4749","score":18.4693971919,"text":"\nYou can restore a volume from a backup snapshot of a boot volume in multiple ways.\n\n\n\n* You can restore a boot volume when you provision an instance to start the new instance.\n* You can restore a boot volume as a stand-alone volume, and use it later to start a new instance. The restoration process starts when the boot volume is attached to the instance.\n\n\n\n\n\n\n\n Restoring from a nonbootable backup \n\nYou can restore a volume from a backup snapshot of a data volume in multiple ways.\n\n\n\n* You can restore a data volume when you provision an instance. During provisioning, you can select a nonbootable backup snapshot to create a data volume hat is then attached to the instance as auxiliary storage.\n* You can restore a data volume when you want to add more storage to an existing instance.\n* You can restore a data volume to create a stand-alone volume, which you can attach to an instance later.\n\n\n\n\n\n\n\n\n\n Restoring a volume from a backup snapshot in the UI \n\nRestoring a volume from a backup snapshot in the UI creates a fully provisioned boot or data volume. You can restore a volume from the list of Block storage snapshots and from the snapshot details page.\n\nYou can restore a volume from a backup snapshot in the following ways.\n\n\n\n* When you [provision an instance](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore&interface=uibaas-vpc-restore-vol-ui), specify a snapshot of a boot or data volume. Data volumes are automatically attached to the instance as auxiliary storage. Use the restored boot volume to start the new instance.\n* From a snapshot of a [previously created volume](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore&interface=uibaas-vpc-create-from-vol-ui). The created volume from snapshot is automatically attached to the instance as auxiliary storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore&interface=ui"},{"document_id":"ibmcld_14984-3011-4697","score":18.261098194,"text":"\n* You can restore a boot volume when you provision an instance to start the new instance.\n* You can restore a boot volume as a stand-alone volume, and use it later to start a new instance. The restoration process starts when the boot volume is attached to the instance.\n\n\n\n\n\n\n\n Restoring from a nonbootable backup \n\nYou can restore a volume from a backup snapshot of a data volume in multiple ways.\n\n\n\n* You can restore a data volume when you provision an instance. During provisioning, you can select a nonbootable backup snapshot to create a data volume hat is then attached to the instance as auxiliary storage.\n* You can restore a data volume when you want to add more storage to an existing instance.\n* You can restore a data volume to create a stand-alone volume, which you can attach to an instance later.\n\n\n\n\n\n\n\n\n\n Restoring a volume from a backup snapshot in the UI \n\nRestoring a volume from a backup snapshot in the UI creates a fully provisioned boot or data volume. You can restore a volume from the list of Block storage snapshots and from the snapshot details page.\n\nYou can restore a volume from a backup snapshot in the following ways.\n\n\n\n* When you [provision an instance](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restorebaas-vpc-restore-vol-ui), specify a snapshot of a boot or data volume. Data volumes are automatically attached to the instance as auxiliary storage. Use the restored boot volume to start the new instance.\n* From a snapshot of a [previously created volume](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restorebaas-vpc-create-from-vol-ui). The created volume from snapshot is automatically attached to the instance as auxiliary storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore"},{"document_id":"ibmcld_15034-3931-5816","score":18.2542239095,"text":"\nWhen you restore a volume from a snapshot, and the tags that are applied to the new volume match the tags in a backup policy, the new volume is backed up. But you can't directly back up a snapshot that has tags in a backup policy.\n\n\n\n\n\n How long are backups retained? \n\nYou can specify that backups be kept 1 - 30 days (default). The retention period can't be shorter than the backup frequency or it returns an error.\n\nYou can also specify the number of backups to retain, up to 750 per volume, after which the oldest backups are deleted.\n\n\n\n\n\n Are there limitations on how many backups I can take? \n\nYes. You can create 10 backup policies per account and up to 750 backups of a volume. For other limitations of this release, see [Limitations in this release](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about&interface=uibackup-service-limitations).\n\n\n\n\n\n How do I create a new volume from a backup? \n\nRestoring from a backup snapshot creates a volume with data from the snapshot. You can restore data from a backup by using the UI, the CLI, or the API. You can restore boot and data volumes during instance creation, when you modify an existing instance, or when you provision a stand-alone volume. When you restore data from a backup snapshot, the data is pulled from an Object Storage bucket. For best performance, you can enable backup snapshots for fast restore. By using the fast restore feature, you can restore a volume that is fully provisioned when the volume is created. When you use fast restore, the data is pulled from a cached backup snapshot in another zone of your VPC. For more information, see [About restoring from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Am I charged for usage? \n\nYes. Cost for backups is calculated based on GB capacity that is stored per month, unless the duration is less than one month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-vpc-faq"},{"document_id":"ibmcld_15007-13930-15825","score":18.1914421713,"text":"\nRestoring from a bootable snapshot is slower than using a regular boot volume.\n\nWhile the creation of the backup requires the volumes to be attached to a running virtual server instance, you can also restore a data volume from a snapshot of an unattached volume. Backups, like snapshots, have a lifecycle that is independent from the source Block Storage for VPC volume.\n\nThe restored volume has the same capacity and IOPS tier profile as the original volume. For more information, see [Restoring a volume from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Restoring a volume by using fast restore \n\nWhen you restore a volume by using fast restore, a fully hydrated volume is created.\n\nYou can create a [backup policy plan](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=uibackup-plan-ui) with fast restore zones, and add or remove zones later as needed. The fast restore feature caches one or more copies of a backup snapshot to the zones that you selected. Later, you can use these backup clones to create volumes in any zone within the same region.\n\nFor more information, see [Restoring a volume from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Cross-regional backup copies \n\nNew\n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. You can use and manage the cross-regional snapshot in the target region independently from the parent volume or the original snapshot.\n\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy.\n\nOnly one copy of the backup snapshot can exist in each region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about"},{"document_id":"ibmcld_15020-13969-15864","score":18.1914421713,"text":"\nRestoring from a bootable snapshot is slower than using a regular boot volume.\n\nWhile the creation of the backup requires the volumes to be attached to a running virtual server instance, you can also restore a data volume from a snapshot of an unattached volume. Backups, like snapshots, have a lifecycle that is independent from the source Block Storage for VPC volume.\n\nThe restored volume has the same capacity and IOPS tier profile as the original volume. For more information, see [Restoring a volume from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Restoring a volume by using fast restore \n\nWhen you restore a volume by using fast restore, a fully hydrated volume is created.\n\nYou can create a [backup policy plan](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=uibackup-plan-ui) with fast restore zones, and add or remove zones later as needed. The fast restore feature caches one or more copies of a backup snapshot to the zones that you selected. Later, you can use these backup clones to create volumes in any zone within the same region.\n\nFor more information, see [Restoring a volume from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Cross-regional backup copies \n\nNew\n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. You can use and manage the cross-regional snapshot in the target region independently from the parent volume or the original snapshot.\n\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy.\n\nOnly one copy of the backup snapshot can exist in each region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about&interface=ui"},{"document_id":"ibmcld_14996-1525-3435","score":18.1855257992,"text":"\nAfter the volume is hydrated (fully provisioned), you can use the new boot or data volume. For more information about how performance is affected during restoration, see [Performance impact when backup snapshots are used](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore&interface=uibaas-performance-considerations).\n\nFor best performance, use backups with fast restore. You can enable fast restore backup snapshots in multiple zones and use them to restore a volume that is fully provisioned when the volume is created. The fast restore feature can achieve a\n\nrecovery time objective(RTO) quicker than restoring from a regular backup snapshot. For more information, see [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore).\n\nTo restore a volume, the backup snapshot must be in a stable state.\n\nYou can't simultaneously restore a boot and a data volume.\n\n\n\n Restoring from a bootable backup \n\nWhen you restore from a bootable backup snapshot, you create a boot volume that you use to provision another instance. The boot volume uses a general-purpose profile and is limited to 250 GB. Because the bootable backup snapshot is not fully provisioned, in the beginning the performance is slower than when you use a regular boot volume. For more information, see [Performance impact](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore&interface=uibaas-boot-perf).\n\nYou can restore a volume from a backup snapshot of a boot volume in multiple ways.\n\n\n\n* You can restore a boot volume when you provision an instance to start the new instance.\n* You can restore a boot volume as a stand-alone volume, and use it later to start a new instance. The restoration process starts when the boot volume is attached to the instance.\n\n\n\n\n\n\n\n Restoring from a nonbootable backup \n\nYou can restore a volume from a backup snapshot of a data volume in multiple ways.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1175161048}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16024-9702-11722","score":14.520578577,"text":"\nFor more information, see [Creating Block Storage for VPC volumes with customer-managed encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-vpc-encryption). \n Encryption Instance Optional. A link to the provisioned KMS instance for a customer-managed encryption volume. \n Key Optional. The name and copiable ID of the root key that is used to encrypt the passphrase, which secures a customer-managed encryption volume. \n Backup policies The number of backup policies that are associated with the volume. Click the number link to go to the backup policies tab. \n Snapshots The number of snapshots that were created of the volume. Click the number link to go to the Snapshots and Backups tab. \n Attached virtual server Volumes attached to a virtual server instance are listed here. Click Attach to select an instance to attach this volume. For more information, see [Attaching a volume to an instance](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-attaching-block-storage). \n Status Tracks the overall lifecycle state of the volume, which ranges from volume creation to volume deletion. Attachment status, for example, attached when the volume is attached to an instance and attaching when in progress. \n Name Click the name of the virtual server instance to see instance details. \n Auto delete When enabled, the volume is automatically deleted when you delete the instance. Click the toggle to enable automatic deletion. \n Backup policies Shows backup policies that are associated with this volume. To associate backup policies, you can add a backup policy's tags for target resources to this volume. Click Apply to select a backup policy, then apply its tags for the target resource to the volume. \n\n\n\nTable 4 shows Actions menu options from the volume details page.\n\n\n\nTable 4. Actions menu options one the volume details page.\n\n Action Description \n\n Create snapshot Create a snapshot from a data volume or a \"bootable snapshot\" from a boot volume. Data volumes must be attached to a virtual server instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-viewing-block-storage&interface=ui"},{"document_id":"ibmcld_15007-15361-17281","score":14.2895731564,"text":"\nYou can use and manage the cross-regional snapshot in the target region independently from the parent volume or the original snapshot.\n\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy.\n\nOnly one copy of the backup snapshot can exist in each region. You can't create a copy of the backup snapshot in the source (local) region.\n\nCreating a cross-regional copy affects billing. You're charged for the data transfer and the storage consumption in the target region separately.\n\n\n\n\n\n\n\n User roles for backup policies \n\nDepending on your assigned role as a backup user, you can create and administer backup policies. Table 1 describes these capabilities.\n\n\n\nTable 1. Backup user roles for backup policies\n\n Backup user role What you can do: \n\n Viewer, Operator <br><br> * List all backup policies.<br> * View details of a backup policy.<br> * View a backup plan.<br><br><br> \n Editor, Administrator <br><br> * Organize and manage snapshots by using tags.<br> * Associate backup policies to volumes by using user tags.<br> * Create, update, and delete backup policies and plans.<br> * Specify CRON format to schedule snapshot creation.<br><br><br> \n\n\n\n\n\nTable 2. Volume user roles for backup policies\n\n Volume user role What you can do: \n\n Editor <br><br> * Create data volumes with user tags.<br> * View volume details with user tags.<br> * List volumes filtered by tag.<br> * Update user tags post volume creation.<br><br><br> \n\n\n\n\n\nTable 3. Snapshot user roles for backup policies\n\n Snapshot user role What you can do: \n\n Editor <br><br> * Create snapshots with user tags.<br> * View snapshot details with tags.<br> * List snapshots filtered by tag.<br> * Update user tags post snapshot creation.<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about"},{"document_id":"ibmcld_15020-15400-17320","score":14.2895731564,"text":"\nYou can use and manage the cross-regional snapshot in the target region independently from the parent volume or the original snapshot.\n\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy.\n\nOnly one copy of the backup snapshot can exist in each region. You can't create a copy of the backup snapshot in the source (local) region.\n\nCreating a cross-regional copy affects billing. You're charged for the data transfer and the storage consumption in the target region separately.\n\n\n\n\n\n\n\n User roles for backup policies \n\nDepending on your assigned role as a backup user, you can create and administer backup policies. Table 1 describes these capabilities.\n\n\n\nTable 1. Backup user roles for backup policies\n\n Backup user role What you can do: \n\n Viewer, Operator <br><br> * List all backup policies.<br> * View details of a backup policy.<br> * View a backup plan.<br><br><br> \n Editor, Administrator <br><br> * Organize and manage snapshots by using tags.<br> * Associate backup policies to volumes by using user tags.<br> * Create, update, and delete backup policies and plans.<br> * Specify CRON format to schedule snapshot creation.<br><br><br> \n\n\n\n\n\nTable 2. Volume user roles for backup policies\n\n Volume user role What you can do: \n\n Editor <br><br> * Create data volumes with user tags.<br> * View volume details with user tags.<br> * List volumes filtered by tag.<br> * Update user tags post volume creation.<br><br><br> \n\n\n\n\n\nTable 3. Snapshot user roles for backup policies\n\n Snapshot user role What you can do: \n\n Editor <br><br> * Create snapshots with user tags.<br> * View snapshot details with tags.<br> * List snapshots filtered by tag.<br> * Update user tags post snapshot creation.<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about&interface=ui"},{"document_id":"ibmcld_15163-28736-29823","score":13.5582024482,"text":"\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/backup_policies\/8758bd18-344b-486a-b606-5b8cb8cdd044\/plans?version=2023-05-09&generation=2\"\n-H \"Authorization: $iam_token\"\n-d '{\n\"active\": true,\n\"attach_user_tags\": [\n\"hourly-backups\"\n],\n\"copy_user_tags\": true,\n\"cron_spec\": \"0 \/2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 20,\n\"delete_over_count\": 20\n},\n\"remote_region_policies\": {\n\"delete_over_count\": 5,\n\"encryption_key\": [\n{\n\"CRN\": \"crn:v1:bluemix:public:kms:us-south:a\/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd617\"\n}\n],\n\"region\": [\n{\n\"name\":\"us-east\"\n}\n]\n},\n\"name\": \"my-hourly-plan-2\"\n}'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=terraform"},{"document_id":"ibmcld_15164-28701-29788","score":13.5582024482,"text":"\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/backup_policies\/8758bd18-344b-486a-b606-5b8cb8cdd044\/plans?version=2023-05-09&generation=2\"\n-H \"Authorization: $iam_token\"\n-d '{\n\"active\": true,\n\"attach_user_tags\": [\n\"hourly-backups\"\n],\n\"copy_user_tags\": true,\n\"cron_spec\": \"0 \/2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 20,\n\"delete_over_count\": 20\n},\n\"remote_region_policies\": {\n\"delete_over_count\": 5,\n\"encryption_key\": [\n{\n\"CRN\": \"crn:v1:bluemix:public:kms:us-south:a\/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd617\"\n}\n],\n\"region\": [\n{\n\"name\":\"us-east\"\n}\n]\n},\n\"name\": \"my-hourly-plan-2\"\n}'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=ui"},{"document_id":"ibmcld_15160-28636-29723","score":13.5582024482,"text":"\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/backup_policies\/8758bd18-344b-486a-b606-5b8cb8cdd044\/plans?version=2023-05-09&generation=2\"\n-H \"Authorization: $iam_token\"\n-d '{\n\"active\": true,\n\"attach_user_tags\": [\n\"hourly-backups\"\n],\n\"copy_user_tags\": true,\n\"cron_spec\": \"0 \/2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 20,\n\"delete_over_count\": 20\n},\n\"remote_region_policies\": {\n\"delete_over_count\": 5,\n\"encryption_key\": [\n{\n\"CRN\": \"crn:v1:bluemix:public:kms:us-south:a\/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd617\"\n}\n],\n\"region\": [\n{\n\"name\":\"us-east\"\n}\n]\n},\n\"name\": \"my-hourly-plan-2\"\n}'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan"},{"document_id":"ibmcld_15162-28726-29813","score":13.5582024482,"text":"\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/backup_policies\/8758bd18-344b-486a-b606-5b8cb8cdd044\/plans?version=2023-05-09&generation=2\"\n-H \"Authorization: $iam_token\"\n-d '{\n\"active\": true,\n\"attach_user_tags\": [\n\"hourly-backups\"\n],\n\"copy_user_tags\": true,\n\"cron_spec\": \"0 \/2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 20,\n\"delete_over_count\": 20\n},\n\"remote_region_policies\": {\n\"delete_over_count\": 5,\n\"encryption_key\": [\n{\n\"CRN\": \"crn:v1:bluemix:public:kms:us-south:a\/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd617\"\n}\n],\n\"region\": [\n{\n\"name\":\"us-east\"\n}\n]\n},\n\"name\": \"my-hourly-plan-2\"\n}'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=cli"},{"document_id":"ibmcld_15161-28756-29853","score":13.5382784053,"text":"\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/backup_policies\/8758bd18-344b-486a-b606-5b8cb8cdd044\/plans?version=2023-05-09&generation=2\"\n-H \"Authorization: $iam_token\"\n-d '{\n\"active\": true,\n\"attach_user_tags\": [\n\"hourly-backups\"\n],\n\"copy_user_tags\": true,\n\"cron_spec\": \"0 \/2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 20,\n\"delete_over_count\": 20\n},\n\"remote_region_policies\": {\n\"delete_over_count\": 5,\n\"encryption_key\": [\n{\n\"CRN\": \"crn:v1:bluemix:public:kms:us-south:a\/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd617\"\n}\n],\n\"region\": [\n{\n\"name\":\"us-east\"\n}\n]\n},\n\"name\": \"my-hourly-plan-2\"\n}'\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=api"},{"document_id":"ibmcld_15957-7-1803","score":13.4370158661,"text":"\nAvailability and Durability of VPC storage \n\nIn today's fast-paced economy, companies rely on data in their decision-making. They need secure and immediate access to their data on a moment's notice. Data integrity is of high priority because compromised or incomplete data is of no use. Not to mention the dangers that are presented if sensitive data goes missing. When you store your data in Block Storage for VPC volumes, snapshots, backups, or in File Storage for VPC shares, it's durable, highly available, and encrypted.\n\n\n\nTable 1. Block Storage for VPC Storage durability and availability chart.\n\n Block Storage for VPC Storage type Use Case Durability Availability Encryption \n\n 3 IOPS per GB tier It is designed for general-purpose workloads such as workloads that host small databases for web applications or store virtual machine disk images for a hypervisor. 99.999999999% <br>(11 9's) 99.999% <br>(5 9's) Provider-managed AES-256 encryption, Customer-managed encryption \n 5 IOPS per GB tier It is designed for high I\/O intensity workloads that are characterized by a large percentage of active data, such as transactional and other performance-sensitive databases. 99.999999999% <br>(11 9's) 99.999% <br>(5 9's) Provider-managed AES-256 encryption, Customer-managed encryption \n 10 IOPS per GB tier It is designed for demanding storage workloads such as data-intensive workloads created by NoSQL databases, data processing for video, machine learning, and analytics. 99.999999999% <br>(11 9's) 99.999% <br>(5 9's) Provider-managed AES-256 encryption, Customer-managed encryption \n custom Customers can specify capacity between 10 - 16000 MB with IOPS ranging 100 - 48000. 99.999999999% <br>(11 9's) 99.999% <br>(5 9's) Provider-managed AES-256 encryption, Customer-managed encryption","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-storageavailability"},{"document_id":"ibmcld_14984-4-2041","score":13.3756233685,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Restoring a volume from a backup snapshot \n\nRestoring from a backup snapshot creates a fully provisioned boot or data volume that you can use to boot an instance or attach as auxiliary storage. You can restore volumes during instance creation or when you want to create stand-alone boot or data volumes to be used later. You can restore a data volume to add more storage to an existing instance. You can use backup snapshots to restore volumes in a different region for business continuity purposes or geographic expansion. You can restore volumes from backup snapshots in the UI, from the CLI, with the API, or Terraform.\n\n\n\n About restoring a volume from a backup snapshot \n\nWhen you restore a volume from a backup, the service creates another volume. The restored volume inherits the same [profile](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profiles), capacity, data, and metadata as the original volume. However, you can choose a different profile and capacity if you prefer. If the source volume used [customer-managed encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutvpc-customer-managed-encryption), the new volume inherits that encryption.\n\nRestoring a volume from a backup snapshot creates a boot or data volume, depending on whether the snapshot is bootable or nonbootable. The volume appears first as pending while it's being created. During the restoration, your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC. After the volume is hydrated (fully provisioned), you can use the new boot or data volume. For more information about how performance is affected during restoration, see [Performance impact when backup snapshots are used](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restorebaas-performance-considerations).\n\nFor best performance, use backups with fast restore. You can enable fast restore backup snapshots in multiple zones and use them to restore a volume that is fully provisioned when the volume is created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1128451413}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14738-7598-10031","score":22.9545628387,"text":"\nThe first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Item IBM responsibilities Your responsibilities \n\n Encryption Provide secure SSL connections to administration portals and replication endpoints. Workload can be deployed by using AES 256-bit encrypted data stores with unique key per customer instance. Backups are encrypted uniquely per customer. Choose encrypted data stores when you are deploying workloads into the environment where appropriate. Use encrypted networking for workload to workload and workload to IBM Cloud Service connections. Use the IBM Cloud private network where appropriate. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilities for disaster recovery\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Item IBM responsibilities Your responsibilities \n\n Backup of management configuration data Conduct backups of the management component configurations. These backups include single-tenant vCenter Server, VMware NSX-T, VMware Cloud Director\u2122, and service configurations. Offsite immutable backup copies are enabled in an independent backup account and they run daily. \n Backup of workloads Enable backup services for customer workload. Choose and implement a backup provider for critical workloads. For more information, see [Understanding business continuity and disaster recovery](https:\/\/cloud.ibm.com\/docs\/vmware-service?topic=vmware-service-bc-dr). \n Recovery of configuration Conduct recovery in the original data center after the infrastructure is available. \n Recovery of workloads Restore capabilities are available in normal operations. For configuration restores, provide customer restore services after the infrastructure is available. If an offsite recovery is required, IBM works with the customer to help recover.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vmaas-understand-responsib"},{"document_id":"ibmcld_14598-9419-11893","score":22.7551892186,"text":"\nResponsibilities for security and regulation compliance for VMware Solutions offerings (other than VMware Shared)\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM responsibilities Your responsibilities \n\n Encryption Provide integration with Key Protect and Hyper Protect Crypto Services through KMIP service as an option for implementing data at-rest encryption. Configure and manage encryption for both data at rest and in transit, as needed. \n\n\n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as:\n\n\n\n* Providing dependencies on disaster recovery sites\n* Provision disaster recovery environments\n* Data and configuration backup\n* Replicating data and configuration to the disaster recovery environment\n* Fail over on disaster events\n\n\n\n\n\n Disaster recovery for VMware Shared \n\nThe following table describes the responsibilities that are related to disaster recovery for VMware Shared.\n\n\n\nTable 8. Responsibilities for disaster recovery for VMware Shared\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM responsibilities Your responsibilities \n\n Backup of configuration data Backups are conducted of the shared management components to include customer environment configurations. Offsite backup copies are enabled and they run daily. \n Backup of workload Backup services are enabled for customer workload. Configure individual backup jobs to include critical systems. Offsite copies can be enabled per request. \n Recovery of configuration Recovery will be conducted in the original data center after the infrastructure is available. If long-term outage occurs, offsite recovery is conducted. \n Recovery of workloads Restore capabilities are available in normal operations. For configuration restores, customer restore services will be provided after the infrastructure is available. If an offsite recovery is required, IBM works with the customer to help recover. Restore systems from the configured backup jobs. \n\n\n\n\n\n\n\n Disaster recovery for VMware Solutions offerings (other than VMware Shared)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-understand-responsib"},{"document_id":"ibmcld_01092-7-2034","score":21.8934525105,"text":"\nDisaster recovery \n\nDisaster recovery (DR) backups for IBM\u00ae Db2\u00ae Warehouse on Cloud are enabled by default and supplement daily snapshot backups. DR backups are used exclusively for system recovery purposes by IBM service operators if there is a disaster or system loss.\n\nIf a disaster event occurs at the data center where your Db2 Warehouse on Cloud instance is deployed, IBM service operators will work with you to stand up a new data warehouse in a different data center, by using the most recent disaster recovery backup. There is no additional charge for these backups.\n\nThe RPO (Recovery Point Objective) and RTO (Recovery Time Objective) for DR backups for each cloud provider are described in the following sections. On IBM Cloud, DR backups are geo-replicated by default. You can open a support ticket to not have your DR backups replicated to certain regions to comply with your data retention policies. On AWS, DR backups are stored in another Availability Zone in the same region and can also be geo-replicated at an additional cost.\n\nFor more information about DR and replication on Db2 Warehouse on Cloud, see [Replication](https:\/\/www.ibm.com\/support\/knowledgecenter\/SS6NHC\/com.ibm.swg.im.dashdb.idrca.doc\/overview\/ovu-db2woc.html).\n\n\n\n IBM Cloud \n\nWhen deployed on IBM Cloud, a full backup of the database is taken once a week for disaster recovery. This DR backup is encrypted and stored in IBM Cloud Object Storage (COS).\n\nIBM COS replicates each DR backup across multiple IBM Cloud regions to ensure availability if a single zone fails.\n\nDR backups of the last 2 weeks are retained by default. The RPO for DR backups on IBM Cloud is 1 week. The RTO if a disaster occurs is dependent upon the size of the database \u2013 1.5 hours per terabyte of data.\n\n\n\n\n\n Amazon Web Services \n\nWhen deployed on Amazon Web Services, a full backup of the database is taken once a day for disaster recovery. This DR backup is encrypted and stored in Amazon Web Services S3.\n\nDR backups of the last 7 days are retained by default.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2whc?topic=Db2whc-dr"},{"document_id":"ibmcld_15843-7468-9604","score":21.590259719,"text":"\nAudit records IBM provides audit records of the VPC resource lifecycle through IBM Cloud Activity Tracker. The Customer uses IBM Cloud Activity Tracker tooling to monitor audit records. \n Security groups and ACLs IBM provides the ability to restrict access to virtual server instances by using security groups and networks ACLs. The Customer uses security groups and network ACLs to secure their virtual server instances, such as restricting what IP addresses can SSH into the instance. \n Public Network Access IBM provides options to use a public gateway or floating IP addresses. The Customer chooses how to connect their workload to the public internet, if applicable, either through a public gateway or floating IP. \n Access restriction IBM provides security measures for customers to restrict access to resources and resource groups. The Customer restricts user access to the appropriate resources and resource groups. \n Activity tracker IBM provides logging and monitoring tools. The Customer integrates IBM Cloud Activity Tracker and IBM Cloud Monitoring data into their auditing and monitoring processes. \n Encryption IBM Cloud VPN for VPC supports encrypted traffic by using IKE\/IPsec policies. The Customer ensures that their connection is encrypted end-to-end, if required. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 6. Responsibilities for disaster recovery\n\n Task IBM Responsibilities Your Responsibilities \n\n Load balancer and VPN disaster recovery IBM Cloud Load Balancer and VPN for VPC have off-site storage and replication of configuration data in an out-of-region disaster recovery node with daily backups. This data is fully managed by IBM Cloud and no customer input is required to ensure service recovery, although there can be up to a 24-hour loss of configuration data. The Customer sets up their backup and recovery strategies for workload data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-responsibilities-vpc"},{"document_id":"ibmcld_08669-4740-6634","score":20.8222373167,"text":"\nYou are responsible for the security and compliance of your application data.\n\n\n\nTable 4. Responsibilities for security and regulation compliance\n\n Task IBM responsibilities Your responsibilities \n\n Applications Maintain controls that are commensurate to [various industry compliance standards](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-security-and-compliancecompliance-ready). Set up and maintain security and regulation compliance for your apps and data. For example, you can enable extra security settings to meet your compliance needs by choosing how and when to [import](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-importing-keysplan-ahead), [wrap](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-wrap-keys), [rotate](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-importing-keysplan-ahead), [rewrap](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-rewrap-keys), and [delete](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) keys. \n Encryption IBM is responsible for the encryption of keys. Keep your root of trust, the master key parts, on either your workstation or smart cards. \n Master key backups IBM never touches your master key. Backup your master key in a regular basis to your smart card or workstation. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events. IBM is responsible for the recovery of Hyper Protect Crypto Services components in case of disaster. You are responsible for the recovery of the workloads that run Hyper Protect Crypto Services and your application data.\n\n\n\nTable 5. Responsibilities for disaster recovery\n\n Task IBM responsibilities Your responsibilities","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-shared-responsibilities"},{"document_id":"ibmcld_07285-5829-8487","score":20.4488125517,"text":"\nIdentity and access IBM provides the function to restrict access to resources through the IBM Cloud console and REST APIs. The Customer is responsible for managing access to resources through IBM Cloud Identity and Access Management (IAM). \n\n\n\n\n\n\n\n Security and regulation compliance \n\nSecurity and regulation compliance includes tasks, such as security controls implementation and compliance certification.\n\n\n\nTable 5. Responsibilities for security and regulation compliance\n\n Task IBM Responsibilities Your Responsibilities \n\n Encryption IBM does not provide encryption capabilities. The Customer is responsible for encryption of data on disk, in motion, and in backups. The Customer is also responsible for choosing and managing appropriate additional security features. If the Customer uses Key Protect (Bring Your Own Key), or another form of encryption, the Customer is responsible for managing the service authorization and keys. \n Security IBM is responsible for ensuring the security of data on disk and data in motion within its infrastructure. The Customer is responsible for restricting user access to the appropriate resources and resource groups. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks, such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 6. Responsibilities for disaster recovery\n\n Task IBM Responsibilities Your Responsibilities \n\n Diversity IBM provides diverse network options for consumption. The Customer must ensure diversity of Direct Link is deployed. \n Redundancy IBM provides diverse network options for consumption. Direct Link is not a redundant service. The Customer is responsible for establishing redundancy, as needed, via BGP schema. The Customer must also understand that Direct Link is not a redundant service. While IBM Cloud supplies Diverse Router (XCR) options, failover must be built into the BGP scheme a customer deploys between multiple Direct Links. \n Host service in multiple regions IBM is responsible for hosting this service in multiple regions. The Customer is responsible for designing and deploying their workload in a way that achieves the wanted availability and Disaster Recovery capabilities by using provided tools. For example, deploy in different zones of a region, use at least two load balancers that are located in different zones, and either use DNS records to point to the load balancers, or ensure that your application can handle a list of IP addresses that it can connect to.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-dl-responsibilities"},{"document_id":"ibmcld_01092-1621-2411","score":20.0111785761,"text":"\nThe RPO for DR backups on IBM Cloud is 1 week. The RTO if a disaster occurs is dependent upon the size of the database \u2013 1.5 hours per terabyte of data.\n\n\n\n\n\n Amazon Web Services \n\nWhen deployed on Amazon Web Services, a full backup of the database is taken once a day for disaster recovery. This DR backup is encrypted and stored in Amazon Web Services S3.\n\nDR backups of the last 7 days are retained by default. The RPO for DR backups on Amazon Web Services is 24 hours. The RTO if a disaster occurs is 4 hours.\n\n\n\n\n\n Brazil: Supplementary Rule 14 (applies to systems provisioned for the Brazilian federal government) \n\nAt this time, the disaster recovery (DR) option for Db2 Warehouse on Cloud offerings is not available in Brazil for the federal government due to Supplementary Rule 14.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2whc?topic=Db2whc-dr"},{"document_id":"ibmcld_14774-27023-28718","score":19.8958338077,"text":"\nIf a local restore is needed, the VMware datastore encryption storage policy is used to reencrypt the VM by using an encryption key from the protected region HPCS instance through the KMIP for VMware service.\n5. Veeam network encryption is used for file and backup copy jobs to the recovery region.\n6. VM backup files are encrypted on disk in the recovery region Veeam Repository with Veeam encryption.\n7. If a restore is needed in the recovery region, the Veeam datastore encryption storage policy is used to reencrypt the VM by using an encryption key from the recovery region HPCS instance through the KMIP for VMware service.\n\n\n\nFor more information about Veeam encryption, see [Encryption standards](https:\/\/helpcenter.veeam.com\/docs\/backup\/vsphere\/encryption_standards.html?ver=100).\n\nIn the IBM Cloud for VMware\u00ae Regulated Workloads dual region design for SaaS Consumer key management, then the same encryption keys are required in the recovery region as used in the protected region. Currently, HPCS does not support the same encryption keys in two regions. If a failure of the first HPCS instance occurs, keys can be restored to another HPCS instance in another region.\n\nFor more information, see:\n\n\n\n* [HPCS cross-region disaster recovery](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-ha-drcross-region-disaster-recovery)\n* [Restoring your data from another region](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-data)\n\n\n\n\n\n\n\n Related links \n\n\n\n* [Caveonix integration](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vrw-caveonix)\n* [Veeam on IBM Cloud overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeamvm_overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vrw-dualregion-design"},{"document_id":"ibmcld_00471-1736-4209","score":19.6925982259,"text":"\nSee [IBM Cloudant backup and recovery](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recovery) documentation for recommended tooling. \n\n\n\n\n\n\n\n Change management \n\nChange management includes tasks such as deployment, configuration, upgrades, patching, configuration changes, and deletion.\n\n\n\nTable 2. Responsibilities for change management\nThe first column describes the task that the customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n Scaling IBM scales infrastructure to meet capacity selected by the customer. Customer chooses the provisioned throughput capacity for their IBM Cloudant instances. \n Upgrades IBM handles all upgrades and patches of the IBM Cloudant service for the customer. \n\n\n\n\n\n\n\n Security and regulation compliance \n\nSecurity and regulation compliance includes tasks such as security controls implementation and compliance certification.\n\n\n\nTable 3. Responsibilities for security and regulation compliance\nThe first column describes the task that the customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n At-rest encryption By default, IBM encrypts all disks by using IBM Cloudant-managed encryption keys. If the customer wants bring-your-own-key (BYOK) encryption, then the customer is required to use Key Protect to store the customer-managed encryption key. The customer must select an appropriate key management service instance, and select a disk encryption key option during provisioning of an IBM Cloudant Dedicated Hardware plan instance. \n Make data unreadable to IBM Cloudant Operators None, IBM does not render data unreadable to IBM Cloudant Operators. If you intend to store sensitive information in an IBM Cloudant database, you must use client-side encryption to render data unreadable to IBM Cloudant operators. For example, for PCI DSS compliance, you must encrypt the Primary Account Number (PAN) before sending a document that contains it to the database. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes the following tasks:\n\n\n\n* Provide dependencies on disaster recovery sites.\n* Provision disaster recovery environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-responsibilities"},{"document_id":"ibmcld_08669-6042-7847","score":19.6419401483,"text":"\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events. IBM is responsible for the recovery of Hyper Protect Crypto Services components in case of disaster. You are responsible for the recovery of the workloads that run Hyper Protect Crypto Services and your application data.\n\n\n\nTable 5. Responsibilities for disaster recovery\n\n Task IBM responsibilities Your responsibilities \n\n Instance backups Continuously perform in-region and cross-region backups of key resources and perform continuous testing of backups. Back up your master key; validate the backups and restore data when needed. \n Disaster recovery When an in-region disaster occurs, automatically recover and restart service components. When a regional disaster that affects all available zones occurs, ensure that all data except the master key is replicated to another region. IBM will also make additional crypto units available in a different region and manage routing requests to the new crypto units. When a regional disaster that affects all available zones occurs, load your master key to the new crypto units that IBM provisions in a different region for restoring data. You can also enable and initialize failover crypto units before a disaster occurs, which reduces the downtime. \n Availability Provide high availability capabilities, such as IBM-owned infrastructure in multizone regions, to meet local access and low latency requirements for each supported region. Use the list of [available regions](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-regions) to plan for and create new instances of the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-shared-responsibilities"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05171-28090-29651","score":12.5188488707,"text":"\nThe example ends (leaving out most of the code for now) telling the app to listen on the port that is assigned and an environment property, or 3000 by default. When successfully starting at the start, it prints a message with the server URL to the console.\n\nvar express = require('express');\nvar cfenv = require('cfenv');\nvar bodyParser = require('body-parser');\nvar app = express();\n\/\/...\n\n\/\/ start server on the specified port and binding host\nvar port = process.env.PORT || 3000;\napp.listen(port, function() {\nconsole.log(\"To view your app, open this link in your browser: http:\/\/localhost:\" + port);\n});\n\/\/...\n\nLet's see how to define a path and views. The first line of code tells the Express framework to use the public directory to serve our static files, which include any static images and stylesheets we use. The lines that follow tell the app where to find the templates for our views in the src\/views directory, and set our view engine to be EJS. In addition, the framework uses the body-parser middleware to expose incoming request data to the app as JSON. In the closing lines of the example, the express app responds to all incoming GET requests to our app URL by rendering the index.ejs view template.\n\n\/\/...\n\/\/ serve the files out of .\/public as our main files\napp.use(express.static('public'));\napp.set('views', '.\/src\/views');\napp.set('view engine', 'ejs');\napp.use(bodyParser.json());\n\nvar title = 'COS Image Gallery Web Application';\n\/\/ Serve index.ejs\napp.get('\/', function (req, res) {\nres.render('index', {status: '', title: title});\n});","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-web-application"},{"document_id":"ibmcld_16261-10613-12744","score":10.7675653636,"text":"\nBecause we need a way to end the conversation, the client app is also watching for the literal command quit to indicate that the program should exit.\n\nBut something still isn't right:\n\nWelcome to the Watson Assistant example. What's your name?\n>> Robert\nI'm afraid I don't understand. Please rephrase your question.\n>> I want to make an appointment.\nWhat day would you like to come in?\n>> Thursday\nI'm afraid I don't understand. Please rephrase your question.\n>>\n\nThe assistant is starting out with the correct greeting, but it doesn't understand when you tell it your name. And if you tell it you want to make an appointment, the correct action is triggered; but once again, it doesn't understand when you answer the follow-up question.\n\nThis is happening because we are using the stateless message method, which means that it is the responsibility of our client application to maintain state information for the conversation. Because we are not yet doing anything to maintain state, the assistant sees every round of user input as the first turn of a new conversation. Because it has no memory of asking a question, it tries to interpret your answer as a new question or request.\n\n\n\n\n\n Maintaining state \n\nState information for your conversation is maintained using the context. The context is an object that is passed back and forth between your application and the assistant, storing information that can be preserved and updated as the conversation goes on. Because we are using the stateless message method, the assistant does not store the context, so it is the responsibility of our client application to maintain it from one turn of the conversation to the next.\n\nThe context includes a session ID for each conversation, as well as a counter that is incremented with each turn of the conversation. The assistant updates the context and returns it with each response. But our previous version of the example did not preserve the context, so these updates were lost, and each round of input appeared to be the start of a new conversation. We can fix that by saving the context and sending it back to the assistant each time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client"},{"document_id":"ibmcld_15269-1502-3374","score":10.3663859276,"text":"\nThe image that we use is the official Ubuntu image from [DockerHub](https:\/\/hub.docker.com\/_\/ubuntu).\n2. Within the Docker Compose file, there is a command: instruction to tell Docker to run a Shell script that prints a line of plain text, and a line of encrypted message to the standard output. This example.sh file exists in the \/compose\/bin directory.\n3. A public key logging.pub is required for encrypting the log message. This file must exist in the \/compose folder. This tutorial will show an example of generating a key pair encrypted via AES with a passphrase using openssl.\n4. The volumes: instruction tells Docker to mount the compose volume with the public key and the simple logging application to \/var\/logging inside the container. The Ubuntu image will start as a container later and run example.sh as its main application.\n\n\n\nThe [contract](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-contract_se) is a YAML file to specify the Hyper Protect Virtual Server for VPC instance that you want to create. In this tutorial, a dedicated public and private key pair is used to encrypt and decrypt the selected log messages.\n\n\n\n* The private key is kept by you to decrypt the downloaded logs later.\n* The public key must be embedded into the contract, which is a special approach for our case. The public key logging.pub is stored under the \/example-files folder along with the docker-compose.yml file. As mentioned in the preparation of the [workload section](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-contract_sehpcr_contract_workload) of the contract, the archive subsection contains the base64 encoded TGZ file archive of docker-compose.yml. The logging.pub file in our example will undergo the same encoding and compression since it's stored in the same folder. As a result, the created instance will acquire the public key for subsequent log encryption.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-encrypt-log-messages-for-hyper-protect-virtual-servers-for-vpc"},{"document_id":"ibmcld_00432-7609-8368","score":10.1746420153,"text":"\nEdit topic\n\n\n\n\n\n\n\nFeedback\n\nFocus sentinel\n\n Give us your feedback \n\nTell us about your experience0\/1500\n\n\n\nDon't include any sensitive or personal information.\n\nHow satisfied are you with your experience?\n\nHow satisfied are you with your experience?\n\n1\n\n2\n\n3\n\n4\n\n5\n\ninfo icon\n\nYour feedback is carefully reviewed, but you won't be contacted in response. Need help? Try searching the docs or chatting with the Virtual Assistant in console.\n\nCancel\n\nSubmit\n\nFocus sentinel Cookie Preferences\n\nYour privacy choices\n\nYour privacy choices\n\n![0_ti_146001191_Ver_2_mid_edb404e7-7014-4a07-93e6-96c7494003bf_sid_cca51480229211eeac887b94c5a6c542_vid_cca50460229211ee874f7dc32b9b9a8d_vids_0_msclkid_N_pi_918639831_lg_en-US_sw_3840_sh_2160_sc_30_nwd_1_tl_Why_20can_t_20I","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-troubleshoot-cdn-cannot-connect-https"},{"document_id":"ibmcld_16471-192768-195041","score":10.102571712,"text":"\n* deterministic\/not deterministic\n\nThe optional deterministic\/not deterministic specifies whether the function is stateless. A deterministic function always returns the same value for the same set of input values.\n* return null on null input\n\nThe optional return null on null input specifies the function behavior when one or more of the input values are null. If return null on null input is specified, the system returns null on null input without invoking the UDF. If called on null input is specified, the UDF is invoked even for null input values.\n\n\n\n\n\n\n\n Usage notes for UDFs implemented in PMML \n\nFunctions that are created from PMML files take a single table that is called params as their argument and output a table. The implementation of the function maps input fields between the input and output schema declared in the create function statement and the schema that is specified in the PMML file. In other words, the DataDictionary section that describes the names and types of fields that can appear in the input and output records that the model produces and consumes, the MiningSchema section that tells which named files defined in the DataDictionary section are in each tuple that represents a feature vector ,and the Output section that tells which named fields defined in the DataDictionary section are present in each tuple of the external representation of the output of the model. These functions must be table functions; each row in the table is passed to the PMML model and produce an output row.\n\nThis schema information is necessary because the PMML and AQL type systems do not match perfectly. For example, PMML has several types to represent timestamps, while AQL currently requires users to encode timestamps as string values. The schema information also allows developers who know AQL but not PMML to understand the AQL rule set.\n\nThe AQL compiler checks the input schema against the input schema of the PMML file to ensure that the two schemas are compatible. If the two schemas contain fields with the same name but incompatible types, compilation fails with an appropriate error message. If the function\u2019s input or output schemas contain extra or missing columns, the resulting function ignores these columns and does not generate an error.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_07578-952861-955025","score":9.7987559746,"text":"\n15 is the maximum number of subnets that you can define with your ALB.\n* Is the load balancer horizontally scalable?\n\nYes. The Application Load Balancer for VPC automatically adjusts its capacity based on the load. When horizontal scaling takes place, the number of IP addresses associated with the application load balancer's DNS changes.\n* Why is my application load balancer in maintenance_pending state?\n\nThe application load balancer is in maintenance_pending state during various maintenance activities, such as:\n\n\n\n* Horizontal scaling activities\n* Recovery activities\n* Rolling upgrades to address vulnerabilities and apply security patches\n\n\n\n* Why do I need to choose multiple subnets during provisioning?\n\nThe Application Load Balancer for VPC (ALB) is Multi-Zone Region (MZR) ready. Load balancer appliances are deployed to the subnets you selected. To achieve higher availability and redundancy, deploy the application load balancer to subnets in different zones.\n* Do I need extra IPs in the subnet for application load balancer operations?\n\nIt is recommended to allocate 8 extra IPs per MZR to accommodate horizontal scaling and maintenance operations. If you provision your application load balancer with one subnet, allocate 16 extra IPs.\n* What are the default settings and allowed values for health check parameters?\n\n\n\n* Health check interval - Default is 5 seconds, and the range is 2 - 60 seconds.\n* Health check response timeout - Default is 2 seconds, and the range is 1 - 59 seconds.\n* Maximum retry attempts - Default is two retry attempts, and the range is 1-10 retries.\n\n\n\nThe health check response timeout value must be less than the health check interval value.\n* Are the ALB IP addresses fixed?\n\nApplication load balancer IP addresses are not guaranteed to be fixed. During system maintenance or horizontal scaling, you see changes in the available IPs associated with the FQDN of your load balancer.\n\nUse FQDN, rather than cached IP addresses.\n* Does the load balancer support layer 7 switching?\n\nYes, the load balancer supports layer 7 switching.\n* Why does HTTPS listener creation or update tell me that my certificate is invalid?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-952737-954901","score":9.7987559746,"text":"\n15 is the maximum number of subnets that you can define with your ALB.\n* Is the load balancer horizontally scalable?\n\nYes. The Application Load Balancer for VPC automatically adjusts its capacity based on the load. When horizontal scaling takes place, the number of IP addresses associated with the application load balancer's DNS changes.\n* Why is my application load balancer in maintenance_pending state?\n\nThe application load balancer is in maintenance_pending state during various maintenance activities, such as:\n\n\n\n* Horizontal scaling activities\n* Recovery activities\n* Rolling upgrades to address vulnerabilities and apply security patches\n\n\n\n* Why do I need to choose multiple subnets during provisioning?\n\nThe Application Load Balancer for VPC (ALB) is Multi-Zone Region (MZR) ready. Load balancer appliances are deployed to the subnets you selected. To achieve higher availability and redundancy, deploy the application load balancer to subnets in different zones.\n* Do I need extra IPs in the subnet for application load balancer operations?\n\nIt is recommended to allocate 8 extra IPs per MZR to accommodate horizontal scaling and maintenance operations. If you provision your application load balancer with one subnet, allocate 16 extra IPs.\n* What are the default settings and allowed values for health check parameters?\n\n\n\n* Health check interval - Default is 5 seconds, and the range is 2 - 60 seconds.\n* Health check response timeout - Default is 2 seconds, and the range is 1 - 59 seconds.\n* Maximum retry attempts - Default is two retry attempts, and the range is 1-10 retries.\n\n\n\nThe health check response timeout value must be less than the health check interval value.\n* Are the ALB IP addresses fixed?\n\nApplication load balancer IP addresses are not guaranteed to be fixed. During system maintenance or horizontal scaling, you see changes in the available IPs associated with the FQDN of your load balancer.\n\nUse FQDN, rather than cached IP addresses.\n* Does the load balancer support layer 7 switching?\n\nYes, the load balancer supports layer 7 switching.\n* Why does HTTPS listener creation or update tell me that my certificate is invalid?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_13903-1305-2795","score":9.7651374591,"text":"\nset vpn ipsec esp-group TestESP pfs disabl\u06easet vpn ipsec esp-group TestESP proposal 1 encryption aes128\u06easet vpn ipsec esp-group TestESP proposal 1 hash sha1\u06ea\n4. Set up the IPsec site-to-site encryption parameters. The following commands:\n\n\n\n* Specify the remote side IP and that the IPsec is using pre-shared secret.\n* Use the remote IP and the secret key TestPSK.\n* Set the default esp group for the tunnel to TestESP.\n* \"Tell\" the IPsec to use ike-group TestIKE, which was defined earlier\n\n\n\nset vpn ipsec site-to-site peer 169.54.254.117 authentication mode pre-shared-secret\u06easet vpn ipsec site-to-site peer 169.54.254.117 authentication pre-shared-secret TestPSK\u06easet vpn ipsec site-to-site peer 169.54.254.117 default-esp-group TestESP\u06easet vpn ipsec site-to-site peer 169.54.254.117 ike-group TestIKE\u06ea\n5. Create the mapping for the IPsec tunnel. Based on the example in the material, the following commands:\n\n\n\n* \"Tell\" the tunnel to map to the remote IP of 169.54.254.117 to the local IP address of bond1, 50.97.240.219.\n* Route only IP addresses with the subnet of 10.54.9.152\/29 that are on the local server interface to the remote server 169.54.254.117.\n* Route tunnel 1 remote traffic 169.54.254.117 to remote subnet of 192.168.1.2\/32.\n\n\n\nset vpn ipsec site-to-site peer 169.54.254.117 local-address \u06ea50.97.240.219set vpn ipsec site-to-site peer 169.54.254.117 tunnel 1 local prefix 10.54.9.152\/29set vpn ipsec site-to-site peer 169.54.254.117 tunnel 1 remote prefix 192.168.1.2\/32","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-configuring-ipsec-on-vyatta-5400"},{"document_id":"ibmcld_04275-10422-11567","score":9.0759682395,"text":"\nFrom the list DNS Virtual Server Name, select the previously-configured DNS virtual server, and set the Redirect option to Origin.\n\nThe Destination Virtual Server setting is used when outbound traffic is to be directed to the local cache server pool. Leave it empty when you want to direct all your outbound traffic to origin servers.\n7. Click OK followed by Done.\n\n\n\nContribute in GitHub\n\nOpen doc issue\n\nEdit topic\n\n\n\n\n\n\n\nFeedback\n\nFocus sentinel\n\n Give us your feedback \n\nTell us about your experience0\/1500\n\n\n\nDon't include any sensitive or personal information.\n\nHow satisfied are you with your experience?\n\nHow satisfied are you with your experience?\n\n1\n\n2\n\n3\n\n4\n\n5\n\ninfo icon\n\nYour feedback is carefully reviewed, but you won't be contacted in response. Need help? Try searching the docs or chatting with the Virtual Assistant in console.\n\nCancel\n\nSubmit\n\nFocus sentinel Cookie Preferences\n\nYour privacy choices\n\nYour privacy choices\n\n![0_ti_146001191_Ver_2_mid_0221f76f-495c-4b72-8f9a-5b8c8b0894f4_sid_cca51480229211eeac887b94c5a6c542_vid_cca50460229211ee874f7dc32b9b9a8d_vids_0_msclkid_N_pi_918639831_lg_en-US_sw_3840_sh_2160_sc_30_nwd_","title":"","source":"https:\/\/cloud.ibm.com\/docs\/citrix-netscaler-vpx?topic=citrix-netscaler-vpx-configure-cache-redirection-for-http-traffic"},{"document_id":"ibmcld_15596-3236-5418","score":9.063792028,"text":"\nThe health check response timeout value must be less than the health check interval value.\n\n\n\n\n\n Are the ALB IP addresses fixed? \n\nApplication load balancer IP addresses are not guaranteed to be fixed. During system maintenance or horizontal scaling, you see changes in the available IPs associated with the FQDN of your load balancer.\n\nUse FQDN, rather than cached IP addresses.\n\n\n\n\n\n Does the load balancer support layer 7 switching? \n\nYes, the load balancer supports layer 7 switching.\n\n\n\n\n\n Why does HTTPS listener creation or update tell me that my certificate is invalid? \n\nCheck for these possibilities:\n\n\n\n* The provided certificate CRN might not be valid.\n* The certificate instance in the Secrets Manager might not have an associated private key.\n\n\n\n\n\n\n\n What is the role of application load balancer front-end listeners? \n\nLoad balancer front-end listeners are the listening ports for the application. They act as proxies for back-end pools.\n\n\n\n\n\n Why are there only 2 IPs instead of 3? \n\nThe Application Load Balancer for VPC (ALB) operates in ACTIVE-ACTIVE mode, a configuration that makes it highly available. Horizontal scaling might further add extra appliances when your load increases. The recommendation is that you choose subnets in different zones to make your load balancers support MZR. This way, if a zone is negatively impacted, a new load balancer is provisioned in a different zone.\n\n\n\n\n\n If a pool is attached to an instance group, what is the maximum number of back-end members that I can have in a pool? \n\nThe maximum number of back-end members that are allowed in a pool is 50. So if an instance group is attached to a pool, the number of instances in the group can't scale up beyond this limit.\n\n\n\n\n\n Why is my listener not receiving traffic? \n\nMake sure that the security group rules that are attached to your load balancer allow incoming ingress and outgoing egress traffic on your listener's port. Security groups attached to your load balancer can be found on your load balancer's overview page. Locate the Attached security groups tab from the load balancer overview, then select the security groups that you want to view and modify their rules.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-load-balancer-faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09906-1621-3194","score":13.4681016763,"text":"\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --data '{\n\"url\": \"http:\/\/newsroom.ibm.com\/Guerbet-and-IBM-Watson-Health-Announce-Strategic-Partnership-for-Artificial-Intelligence-in-Medical-Imaging-Liver\",\n\"features\": {\n\"sentiment\": {},\n\"categories\": {},\n\"concepts\": {},\n\"entities\": {},\n\"keywords\": {}\n}\n}' \"{url}\/v1\/analyze?version=2019-07-12\"\n\nWindows users: This command might not run on Windows. Run the following command instead:\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --data \"{\"url\":\"http:\/\/newsroom.ibm.com\/Guerbet-and-IBM-Watson-Health-Announce-Strategic-Partnership-for-Artificial-Intelligence-in-Medical-Imaging-Liver\",\"features\":{\"sentiment\":{},\"categories\":{},\"concepts\":{},\"entities\":{},\"keywords\":{}}}\" \"{url}\/v1\/analyze?version=2019-07-12\"\n\nThe next step demonstrates how to specify options that customize the analysis for each feature.\n\n\n\n\n\n Step 2: Analyze target phrases and keywords \n\nNatural Language Understanding can analyze target phrases in context of the surrounding text for focused sentiment and emotion results. The targets option for sentiment in the following example tells the service to search for the targets \"apples\", \"oranges\", and \"broccoli\". Since \"apples\" and \"oranges\" are located in the text, sentiment scores are returned for those targets.\n\nYou can also get sentiment and emotion results for entities and keywords that are detected in your text. In the example, the emotion option for keywords tells the service to analyze each detected keyword for emotion results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-getting-started"},{"document_id":"ibmcld_16471-192768-195041","score":13.0322007301,"text":"\n* deterministic\/not deterministic\n\nThe optional deterministic\/not deterministic specifies whether the function is stateless. A deterministic function always returns the same value for the same set of input values.\n* return null on null input\n\nThe optional return null on null input specifies the function behavior when one or more of the input values are null. If return null on null input is specified, the system returns null on null input without invoking the UDF. If called on null input is specified, the UDF is invoked even for null input values.\n\n\n\n\n\n\n\n Usage notes for UDFs implemented in PMML \n\nFunctions that are created from PMML files take a single table that is called params as their argument and output a table. The implementation of the function maps input fields between the input and output schema declared in the create function statement and the schema that is specified in the PMML file. In other words, the DataDictionary section that describes the names and types of fields that can appear in the input and output records that the model produces and consumes, the MiningSchema section that tells which named files defined in the DataDictionary section are in each tuple that represents a feature vector ,and the Output section that tells which named fields defined in the DataDictionary section are present in each tuple of the external representation of the output of the model. These functions must be table functions; each row in the table is passed to the PMML model and produce an output row.\n\nThis schema information is necessary because the PMML and AQL type systems do not match perfectly. For example, PMML has several types to represent timestamps, while AQL currently requires users to encode timestamps as string values. The schema information also allows developers who know AQL but not PMML to understand the AQL rule set.\n\nThe AQL compiler checks the input schema against the input schema of the PMML file to ensure that the two schemas are compatible. If the two schemas contain fields with the same name but incompatible types, compilation fails with an appropriate error message. If the function\u2019s input or output schemas contain extra or missing columns, the resulting function ignores these columns and does not generate an error.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_05171-28090-29651","score":12.5188488707,"text":"\nThe example ends (leaving out most of the code for now) telling the app to listen on the port that is assigned and an environment property, or 3000 by default. When successfully starting at the start, it prints a message with the server URL to the console.\n\nvar express = require('express');\nvar cfenv = require('cfenv');\nvar bodyParser = require('body-parser');\nvar app = express();\n\/\/...\n\n\/\/ start server on the specified port and binding host\nvar port = process.env.PORT || 3000;\napp.listen(port, function() {\nconsole.log(\"To view your app, open this link in your browser: http:\/\/localhost:\" + port);\n});\n\/\/...\n\nLet's see how to define a path and views. The first line of code tells the Express framework to use the public directory to serve our static files, which include any static images and stylesheets we use. The lines that follow tell the app where to find the templates for our views in the src\/views directory, and set our view engine to be EJS. In addition, the framework uses the body-parser middleware to expose incoming request data to the app as JSON. In the closing lines of the example, the express app responds to all incoming GET requests to our app URL by rendering the index.ejs view template.\n\n\/\/...\n\/\/ serve the files out of .\/public as our main files\napp.use(express.static('public'));\napp.set('views', '.\/src\/views');\napp.set('view engine', 'ejs');\napp.use(bodyParser.json());\n\nvar title = 'COS Image Gallery Web Application';\n\/\/ Serve index.ejs\napp.get('\/', function (req, res) {\nres.render('index', {status: '', title: title});\n});","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-web-application"},{"document_id":"ibmcld_13352-8408-10431","score":11.9699714517,"text":"\nWhen you add a grammar file to a custom language model, the service parses the grammar to determine whether the grammar recognizes any words that are not already part of the service's base vocabulary. Such words are referred to as out-of-vocabulary (OOV) words. The service adds OOV words to the custom model's words resource. The purpose of the words resource is to define words that are not already present in the service's vocabulary.\n\nDefinitions in the words resource tell the service how to transcribe the OOV words. The information includes a sounds_like field that tells the service how the word is pronounced, a display_as field that tells the service how to display the word, and a source field that indicates how the word was added to the custom model. For more information about the words resource and OOV words, see [The words resource](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-corporaWordswordsResource).\n\nAfter you add a grammar to a custom model, it is good practice to examine the OOV words in the model's words resource to verify their sounds-like pronunciations. Not all grammars have OOV words, but verifying the words resource is generally a good idea. To check the words of the custom model after you add a grammar, use the following methods:\n\n\n\n* Use the GET \/v1\/customizations\/{customization_id}\/words method to list all of the words from a custom model. Pass the value grammars with the method's word_type parameter to list only words that were added from grammars.\n* Use the GET \/v1\/customizations\/{customization_id}\/words\/{word_name} method to view an individual word from a model.\n\n\n\nVerify that the sounds-like pronunciations of the words are accurate and correct. Also look for typographical and other errors in the words themselves. For more information about validating and correcting the words in a custom model, see [Validating a words resource for previous-generation models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-corporaWordsvalidateModel).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarAdd"},{"document_id":"ibmcld_09906-2727-4077","score":11.8689193523,"text":"\nThe targets option for sentiment in the following example tells the service to search for the targets \"apples\", \"oranges\", and \"broccoli\". Since \"apples\" and \"oranges\" are located in the text, sentiment scores are returned for those targets.\n\nYou can also get sentiment and emotion results for entities and keywords that are detected in your text. In the example, the emotion option for keywords tells the service to analyze each detected keyword for emotion results.\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --data '{\n\"text\": \"I love apples! I do not like oranges.\",\n\"features\": {\n\"sentiment\": {\n\"targets\": [\n\"apples\",\n\"oranges\",\n\"broccoli\"\n]\n},\n\"keywords\": {\n\"emotion\": true\n}\n}\n}' \"{url}\/v1\/analyze?version=2019-07-12\"\nShow more\n\nRunnable command for Windows users:\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --data \"{\"text\":\"I love apples! I do not like oranges.\",\"features\":{\"sentiment\":{\"targets\":[\"apples\",\"oranges\",\"broccoli\"]},\"keywords\":{\"emotion\":true}}}\" \"{url}\/v1\/analyze?version=2019-07-12\"\n\n\n\n\n\n Next steps \n\n\n\n* View the [API reference](https:\/\/cloud.ibm.com\/apidocs\/natural-language-understanding).\n* Learn how to identify [custom entities and relations](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-getting-started"},{"document_id":"ibmcld_13898-1476-2906","score":11.410667166,"text":"\n* Showing configuration information\n* Navigating through the configuration hierarchy\n\n\n\nWhen you log on to the system, the system is in operational mode. You must switch to configuration mode for the commands.\n\nYou can tell which mode that you are in based on the prompt. You are in operational mode if the prompt is #, and configuration mode if the prompt is $.\n\nFollow these steps to configure the private VLAN by using the CLI. Remember the values needed to configure the VLAN are:\n\n\n\n* VLAN name of the VLAN to be routed through Brocade 5400 vRouter device (2254)\n* Gateway and mask (CIDR format) of the VLAN to be routed (10.52.69.201\/29)\n* Private bond name of the Brocade 5400 vRouter Device (bond0)\n\n\n\n\n\n1. SSH into your Brocade 5400 vRouter (public or private IP address) by using vyatta as the Username. Supply the password when prompted.\n\nYou should create a new user within Brocade 5400 vRouter and disable the default initial user vyatta.\n2. Configure the vif:\n\n\n\n* Type configure at the command prompt to enter configuration mode.\n* Type set interfaces bonding bond0 vif 2254 address 10.52.69.201\/29 at the command prompt to set the vif.\n* Type commit at the command prompt to commit the settings.\n* Type save to save the settings.\n* Type exit to switch back to operation mode.\n\n\n\n3. Type show interfaces to check the settings that you committed.\n4. Route any remaining VLANs through the Brocade 5400 vRouter device.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-basic-configuration-of-vyatta-5400"},{"document_id":"ibmcld_05367-2825-4556","score":11.1042814386,"text":"\nAfter you create and run your Function, you can also update your Function by using any of the preceding ways, independent of how you created or previously updated your Function.\n\n\n\n\n\n Requests and responses \n\nFunctions are invoked with the HTTP protocol. When you invoke your Function, you can specify the custom request parameters, custom request body and headers, as well as the HTTP method. The request parameters are made available to the Function code as input parameters. The Function code can set the response body, response headers, and response code, which are returned to the caller from the Functions endpoint.\n\n\n\n Example 1: Generating an HTML response from a Function \n\nThe following example illustrates how to generate an HTML response from a Function.\n\nfunction main(params) {\nvar msg = 'You did not tell me who you are.';\nif (params.name) {\nmsg = Hello, ${params.name}!\n} else {\nmsg = Hello, FaaS on CodeEngine!\n}\nreturn {\nheaders: { 'Content-Type': 'text\/html; charset=utf-8' },\nbody: <html><body><h3>${msg}<\/h3><\/body><\/html>\n}\n}\n\nmodule.exports.main = main;\n\n\n\n\n\n Example 2: Setting a response code and response header \n\nYour Function can set a specific response code and header flags. The following example illustrates how you can set a response code and response header to add a redirect to a different URL.\n\nfunction main(params) {\nreturn {\nheaders: { location: 'https:\/\/cloud.ibm.com\/docs\/codeengine' },\nstatusCode: 302\n}\n}\n\n\n\n\n\n Example 3: Generating a plain text response from a Function \n\nThe following example illustrates how to generate a plain text response from a Function.\n\nfunction main(params) {\nvar msg = 'You did not tell me who you are.';\nif (params.name !== \"\") {\nmsg = Hello, ${params.name}!\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-fun-work"},{"document_id":"ibmcld_16261-10613-12744","score":11.0679411772,"text":"\nBecause we need a way to end the conversation, the client app is also watching for the literal command quit to indicate that the program should exit.\n\nBut something still isn't right:\n\nWelcome to the Watson Assistant example. What's your name?\n>> Robert\nI'm afraid I don't understand. Please rephrase your question.\n>> I want to make an appointment.\nWhat day would you like to come in?\n>> Thursday\nI'm afraid I don't understand. Please rephrase your question.\n>>\n\nThe assistant is starting out with the correct greeting, but it doesn't understand when you tell it your name. And if you tell it you want to make an appointment, the correct action is triggered; but once again, it doesn't understand when you answer the follow-up question.\n\nThis is happening because we are using the stateless message method, which means that it is the responsibility of our client application to maintain state information for the conversation. Because we are not yet doing anything to maintain state, the assistant sees every round of user input as the first turn of a new conversation. Because it has no memory of asking a question, it tries to interpret your answer as a new question or request.\n\n\n\n\n\n Maintaining state \n\nState information for your conversation is maintained using the context. The context is an object that is passed back and forth between your application and the assistant, storing information that can be preserved and updated as the conversation goes on. Because we are using the stateless message method, the assistant does not store the context, so it is the responsibility of our client application to maintain it from one turn of the conversation to the next.\n\nThe context includes a session ID for each conversation, as well as a counter that is incremented with each turn of the conversation. The assistant updates the context and returns it with each response. But our previous version of the example did not preserve the context, so these updates were lost, and each round of input appeared to be the start of a new conversation. We can fix that by saving the context and sending it back to the assistant each time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client"},{"document_id":"ibmcld_00580-6386-8382","score":10.7194745134,"text":"\nIt has only a small provisioned capacity and a fixed storage size, but it's fine for testing the IBM Cloudant service.\n\nIBM Cloudant is often referred to as a \"schemaless\" database - but we have to be careful how we define that term.\n\nIt's true to say that you don't need to define your schema (field names, types, constraints, and relationships) ahead of time in an IBM Cloudant database. You can simply write a JSON document of your own design to a database.\n\nDevelopers like this flexibility because they can design their data in their code, turn it into JSON, and write it to the database.\n\nIt's still important to think about the shape of your data, especially in terms of how you are going to query and index it, as we see later.\n\nData design is still required, but strictly speaking that database doesn't need to know about your schema.\n\nLet's say we want to create a database of US presidents. We can simply devise our \"model\" of the data in our app, turn it into JSON, and write it to the database. In this case, we are using a common CouchDB convention: the \"type\" field indicates the data type of the document.\n\nIf at a future date we decide we want to add more data to our \"schema\", we can simply write a new object to the database with no complaints from IBM Cloudant. We could decide to add the \"address\" object only to the following documents:\n\n\n\n* Documents that are created from now on.\n* Only documents that we have addresses for.\n\n\n\nIn other words, documents of the same type can have fields present or missing.\n\nYour database's schema can evolve over time to match your application's needs. You don't (necessarily) need to tell the database about the schema change - write new documents in the new format.\n\nWe can even store multiple document \"types\" in the same database. In this case, people, books, and places reside in the same database. We know which is which because of the \"type\" field (this field is a convention and not something that means anything to IBM Cloudant).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00580-7918-10060","score":10.6576225945,"text":"\nYour database's schema can evolve over time to match your application's needs. You don't (necessarily) need to tell the database about the schema change - write new documents in the new format.\n\nWe can even store multiple document \"types\" in the same database. In this case, people, books, and places reside in the same database. We know which is which because of the \"type\" field (this field is a convention and not something that means anything to IBM Cloudant).\n\nAn alternative to this configuration is to have three databases people, books, and places and keep each data type in its own database. Both approaches are fine. You can choose to have multiple types together in the same database if you need to perform queries across types or if you need to replicate all data types together. Otherwise, the separate databases approach might be better.\n\nTo summarize, although IBM Cloudant is \"schemaless\", this fact doesn't absolve you of the need to do detailed data design to get the best performance.\n\nThese tips are especially relevant if you have some relational database experience.\n\n\n\n* Avoid thinking in joins - an IBM Cloudant document must contain everything that you need about that object so that it can be retrieved in one API call.\n* Normalization goes out of the window in JSON store, some repeated values can be tolerated if it makes data retrieval more efficient.\n* Although we have a 1 MB limit on document size, your documents must be much smaller - a few KB is typical.\n* If your application can embrace a \"write only\"* design pattern, where data is only ever added to a database, then it can make your life easier. You must definitely avoid patterns that rely on updating the same document over and over in a small time window.\n\n\n\nThat's the end of this part. The next part is called The Document ID.\n\n\n\n\n\n\n\n The _id video \n\nLearn how _ids work in IBM Cloudant, how they are different from relational databases, and how you can define your own _id.\n\n\n\n* The _id video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12561-12509-13465","score":15.6827768427,"text":"\nIdentify the departments within your company that correspond with the account groups.\n\nIf the contacts that are assigned to your account groups are associated with the department that you want to recover costs from, finding the contact is one way to find this information. Go to Manage > Enterprise and select Accounts. The contact for each account group is listed in the table.\n\nHowever, billing practices vary by company. For example, the account group contact might be a technical focal that's not associated with the department that you want to charge. Always verify the correct department according to your company's accounting processes.\n\nIf your company uses billing codes to charge back costs to departments, add the billing code to the account group name to easily identify the code. For example,Sales - A2B3.\n3. Pair the usage costs for each account group with the identified department, and follow your company's processes to submit the charges.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-usage"},{"document_id":"ibmcld_12561-10740-13065","score":15.3823895315,"text":"\nWhen recurse=true, the usage in the Enterprise Resource Usage section is aggregated by each metric of a service plan and it's broken down by child accounts. Each row represents the total usage of a service plan metric in some child account. When recurse=false, the usage is aggregated by each metric of a service plan and each row represents the total usage of a service plan metric of all the sub-accounts or child-accounts in the requested entity hierarchy. In the Hierarchy section, recurse=true shows all the child entities of the requested entity, and for recurse=false, it shows only the direct children of the requested entity.\n\n\n\n\n\n\n\n Recovering costs for enterprise usage \n\nAn enterprise consolidates billing from all of its accounts and account groups to a single invoice, which simplifies billing management. You can recover the costs from resource usage in the enterprise by charging the usage costs for each account group or account to the associated department or team.\n\nTo view your enterprise hierarchy and any usage, you need an access policy with the Editor or Administrator role on the Enterprise service for the entire enterprise. The following steps use the IBM Cloud console as an example, but you can also perform these steps by using the CLI or API.\n\n\n\n1. Find the usage costs for each department by going to Manage > Usage in the enterprise account. From the Time frame menu, select the previous month to view the usage that is included in the latest invoice.\n\nThe costs for your account groups are listed in the table. These costs include all charges except any tax that's charged in your billing region. If you want a further breakdown of usage costs, click the account group name to view the accounts and account groups that it contains.\n2. Identify the departments within your company that correspond with the account groups.\n\nIf the contacts that are assigned to your account groups are associated with the department that you want to recover costs from, finding the contact is one way to find this information. Go to Manage > Enterprise and select Accounts. The contact for each account group is listed in the table.\n\nHowever, billing practices vary by company. For example, the account group contact might be a technical focal that's not associated with the department that you want to charge.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-usage"},{"document_id":"ibmcld_15160-8509-10437","score":14.5830227431,"text":"\n* Hyper Protect Crypto Services - it can be used when the original back is encrypted by using the Hyper Protect Crypto Services service.\n\n\n\n\n\nTags are automatically copied over from the parent backup.\n6. Click Save.\n7. The Summary updates automatically with the selections that you made. For example, the plan might be \"Every Monday at -5:53 UTC (12:30 AM CDT) starting on 26 March 2022.\" The Plan status toggle is enabled by default.\n8. Click Create to save the new plan. The list of plans is updated in the policy details page. If you want to make any changes, click the pencil icon for that plan. If you want to delete the plan, click the delete icon.\n\n\n\n\n\n\n\n Estimating your expected usage and costs \n\nUse the cost estimator to see what your backups might cost based on the rate of expected change in your Block Storage for VPC volumes.\n\n\n\n1. After you [create your backup policy and plan](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-planbackup-policy-create-ui), on the side panel of Backup summary, click Add to estimate.\n2. On the Estimate side panel, enter your expected usage to the initial costs. The backup policy is without charge. You pay for the amount of backup storage that is used. Provide the following estimates:\n\n\n\n* Number of volumes you want to associate with the backup policy.\n* Average amount of data per volume (in GBs). For example, you might associate two volumes with a policy. The first volume has 4 GB of data and the second 20 GB. An average of the two would be 12 GB.\n* Number of backups per volume per month. You can take a maximum of 750 backup snapshots per volume.\n* Percent of incremental change after the initial backup. For example, 15 percent increase in size for each subsequent backup.\n\n\n\n3. When you're finished, click Calculate cost.\n\n\n\nThe cost estimate summary shows how the costs are calculated and breaks down the storage cost, providing a monthly estimate.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan"},{"document_id":"ibmcld_15164-8548-10361","score":13.8885357466,"text":"\n* Hyper Protect Crypto Services - it can be used when the original back is encrypted by using the Hyper Protect Crypto Services service.\n\n\n\n\n\nTags are automatically copied over from the parent backup.\n6. Click Save.\n7. The Summary updates automatically with the selections that you made. For example, the plan might be \"Every Monday at -5:53 UTC (12:30 AM CDT) starting on 26 March 2022.\" The Plan status toggle is enabled by default.\n8. Click Create to save the new plan. The list of plans is updated in the policy details page. If you want to make any changes, click the pencil icon for that plan. If you want to delete the plan, click the delete icon.\n\n\n\n\n\n\n\n Estimating your expected usage and costs \n\nUse the cost estimator to see what your backups might cost based on the rate of expected change in your Block Storage for VPC volumes.\n\n\n\n1. After you [create your backup policy and plan](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=uibackup-policy-create-ui), on the side panel of Backup summary, click Add to estimate.\n2. On the Estimate side panel, enter your expected usage to the initial costs. The backup policy is without charge. You pay for the amount of backup storage that is used. Provide the following estimates:\n\n\n\n* Number of volumes you want to associate with the backup policy.\n* Average amount of data per volume (in GBs). For example, you might associate two volumes with a policy. The first volume has 4 GB of data and the second 20 GB. An average of the two would be 12 GB.\n* Number of backups per volume per month. You can take a maximum of 750 backup snapshots per volume.\n* Percent of incremental change after the initial backup. For example, 15 percent increase in size for each subsequent backup.\n\n\n\n3. When you're finished, click Calculate cost.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=ui"},{"document_id":"ibmcld_15161-8551-10365","score":13.8885357466,"text":"\n* Hyper Protect Crypto Services - it can be used when the original back is encrypted by using the Hyper Protect Crypto Services service.\n\n\n\n\n\nTags are automatically copied over from the parent backup.\n6. Click Save.\n7. The Summary updates automatically with the selections that you made. For example, the plan might be \"Every Monday at -5:53 UTC (12:30 AM CDT) starting on 26 March 2022.\" The Plan status toggle is enabled by default.\n8. Click Create to save the new plan. The list of plans is updated in the policy details page. If you want to make any changes, click the pencil icon for that plan. If you want to delete the plan, click the delete icon.\n\n\n\n\n\n\n\n Estimating your expected usage and costs \n\nUse the cost estimator to see what your backups might cost based on the rate of expected change in your Block Storage for VPC volumes.\n\n\n\n1. After you [create your backup policy and plan](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=apibackup-policy-create-ui), on the side panel of Backup summary, click Add to estimate.\n2. On the Estimate side panel, enter your expected usage to the initial costs. The backup policy is without charge. You pay for the amount of backup storage that is used. Provide the following estimates:\n\n\n\n* Number of volumes you want to associate with the backup policy.\n* Average amount of data per volume (in GBs). For example, you might associate two volumes with a policy. The first volume has 4 GB of data and the second 20 GB. An average of the two would be 12 GB.\n* Number of backups per volume per month. You can take a maximum of 750 backup snapshots per volume.\n* Percent of incremental change after the initial backup. For example, 15 percent increase in size for each subsequent backup.\n\n\n\n3. When you're finished, click Calculate cost.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=api"},{"document_id":"ibmcld_15162-8551-10365","score":13.8885357466,"text":"\n* Hyper Protect Crypto Services - it can be used when the original back is encrypted by using the Hyper Protect Crypto Services service.\n\n\n\n\n\nTags are automatically copied over from the parent backup.\n6. Click Save.\n7. The Summary updates automatically with the selections that you made. For example, the plan might be \"Every Monday at -5:53 UTC (12:30 AM CDT) starting on 26 March 2022.\" The Plan status toggle is enabled by default.\n8. Click Create to save the new plan. The list of plans is updated in the policy details page. If you want to make any changes, click the pencil icon for that plan. If you want to delete the plan, click the delete icon.\n\n\n\n\n\n\n\n Estimating your expected usage and costs \n\nUse the cost estimator to see what your backups might cost based on the rate of expected change in your Block Storage for VPC volumes.\n\n\n\n1. After you [create your backup policy and plan](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=clibackup-policy-create-ui), on the side panel of Backup summary, click Add to estimate.\n2. On the Estimate side panel, enter your expected usage to the initial costs. The backup policy is without charge. You pay for the amount of backup storage that is used. Provide the following estimates:\n\n\n\n* Number of volumes you want to associate with the backup policy.\n* Average amount of data per volume (in GBs). For example, you might associate two volumes with a policy. The first volume has 4 GB of data and the second 20 GB. An average of the two would be 12 GB.\n* Number of backups per volume per month. You can take a maximum of 750 backup snapshots per volume.\n* Percent of incremental change after the initial backup. For example, 15 percent increase in size for each subsequent backup.\n\n\n\n3. When you're finished, click Calculate cost.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=cli"},{"document_id":"ibmcld_15163-8569-10389","score":13.8885357466,"text":"\n* Hyper Protect Crypto Services - it can be used when the original back is encrypted by using the Hyper Protect Crypto Services service.\n\n\n\n\n\nTags are automatically copied over from the parent backup.\n6. Click Save.\n7. The Summary updates automatically with the selections that you made. For example, the plan might be \"Every Monday at -5:53 UTC (12:30 AM CDT) starting on 26 March 2022.\" The Plan status toggle is enabled by default.\n8. Click Create to save the new plan. The list of plans is updated in the policy details page. If you want to make any changes, click the pencil icon for that plan. If you want to delete the plan, click the delete icon.\n\n\n\n\n\n\n\n Estimating your expected usage and costs \n\nUse the cost estimator to see what your backups might cost based on the rate of expected change in your Block Storage for VPC volumes.\n\n\n\n1. After you [create your backup policy and plan](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=terraformbackup-policy-create-ui), on the side panel of Backup summary, click Add to estimate.\n2. On the Estimate side panel, enter your expected usage to the initial costs. The backup policy is without charge. You pay for the amount of backup storage that is used. Provide the following estimates:\n\n\n\n* Number of volumes you want to associate with the backup policy.\n* Average amount of data per volume (in GBs). For example, you might associate two volumes with a policy. The first volume has 4 GB of data and the second 20 GB. An average of the two would be 12 GB.\n* Number of backups per volume per month. You can take a maximum of 750 backup snapshots per volume.\n* Percent of incremental change after the initial backup. For example, 15 percent increase in size for each subsequent backup.\n\n\n\n3. When you're finished, click Calculate cost.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=terraform"},{"document_id":"ibmcld_11522-0-1801","score":13.600143008,"text":"\n\n\n\n\n\n\n  View the cost \n\nAt any time, you can see how much cost has been incurred by jobs associated with an instance.\n\n\n\n  View instance cost \n\nTo determine how much has been billed to an instance during the current billing cycle, from the [Instances page](https:\/\/cloud.ibm.com\/quantum\/instances), click the instance to open its details page.\n\nThese are the fields relevant to cost:\n\n\n\n*  Billing cycle usage: Qiskit Runtime usage by this instance during the current billing cycle. This usage is the time counted by Qiskit Runtime to process a job, and is determined by the use of internal resources.\n*  Billing cycle cost: The total cost of running jobs during the current billing cycle.\n*  Total usage: Qiskit Runtime usage by this instance since it was created.\n*  Total cost: The total cost of running jobs on this instance since it was created. Only administrators can set this value.\n\n\n\nYou can view your billing cycle on the [IBM Cloud Billing and usage page](https:\/\/cloud.ibm.com\/billing).\n\n\n\n\n\n  View job cost \n\nTo determine how much has been billed to each job associated with an instance, from the [Instances page](https:\/\/cloud.ibm.com\/quantum\/instances), click the instance to open its details page. Next, on the left side, click Jobs.\n\nThese are the columns relevant to cost:\n\n\n\n*  Usage: Qiskit Runtime used by this job. This usage is the time counted by Qiskit Runtime to process a job, and is determined by the use of internal resources.\n*  Cost: The total cost of running this job.\n\n\n\n\n\n\n\n  Next steps \n\nTo learn about how costs are incurred, see [Qiskit Runtime plans](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-plans).\n\nTo learn how to limit costs, see [Manage costs](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-view-cost"},{"document_id":"ibmcld_02597-4595-6892","score":12.9925211552,"text":"\nThrough the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.\n\nAs well as controlling which APIs a customer can use, different Plans can be used to implement rate limits. A rate limit can be implemented as a default rate across an entire Plan, or for specific operations of an API within that Plan, exempting them from the Plan rate limit. Different Plans can have differing rate limits, both between operations and for the overall limit. Applying rate limits to Plans makes it easy to offer different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute while a \"Full Plan\" might permit up to 1000 calls per minute.\n\nFinally, different Plans can be used to assign a billing cost. A Plan can be set as a free Plan, or as a Plan with billing. Plans with billing can be used with rate limits to set different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute for a cost of $5 per month, while a \"Full Plan\" might permit up to 1000 calls per minute for a cost of $20 per month.\n\nNote: Applying a rate limit at the Plan level, creates a default rate limit that applies to each operation within the Plan. If you need to set specific rate limits for specific operations, you must set them within the operations themselves and this setting overrides the setting at the Plan level.\n\nIBM API Connect also supports the implementation of multiple versions of Products. You can choose version numbers and use them to aid the development of your Products and Plans.\n\nNote: The version for a Product is distinct from the version of any APIs that are contained in the associated Plans. Plans cannot themselves have their own version, they use the version of their parent Product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-about_apic_overview"},{"document_id":"ibmcld_09336-7-2133","score":12.7914717346,"text":"\nManaging volume spike protection and costs \n\nConfigure index rates alerts in your IBM\u00ae Log Analysis instance to monitor and be alerted of unexpected spikes in your data volumes. Use the index rate to analyze and predict costs associated with storage of searchable data.\n\nIndex rates are calculated based on data that is ingested over the last 30 days and collected in 5 minute intervals.\n\nData collection commences on January 31, 2022 for existing instances. For new instances, data collection starts from the day that the instance is provisioned.\n\nThe standard hourly index rate is used to identify spikes or deviations in data volumes. The standard deviation is calculated by comparing the average hourly index rate with the average of the same hour over a rolling 30 day period. The severity of a spike is measured in standard deviations.\n\nThe z-score represents the count of standard deviations. You can use it to predict costs associated with storage of searchable data.\n\n\n\n How are index rates calculated \n\nThe number of log lines that are indexed, that is, the number of log lines that are available for search, are collected every 5 minutes.\n\nA day is based on a 24 hour period that is based on UTC time zone.\n\nTo calculate the daily average index rate, the following formula is applied:\n\n\n\n1. The total number of indexed lines for the past hour, that is, the number of log lines over 1 hour rolling period, is collected.\n2. The total number of indexed lines per hour is then divided by 60 to get the average of log lines per minute.\n3. The average log lines per minute is then divided by 60 to get the average of log lines per second.\n4. The index rate is calculated as the average value of all index rates that are calculated over 24 hours.\n\n\n\nTo calculate the hourly average index rate, also known as the standard hourly index rate, the following formula is applied:\n\n\n\n1. The total number of indexed lines for the past hour, that is, the number of log lines over 1 hour rolling period, is collected.\n2. The total number of indexed lines per hour is then divided by 60 to get the average of log lines per minute.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-control_usage_index_rate"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00482-3319-4702","score":14.9671652171,"text":"\nWhen you have such a view, you can use it to find and resolve conflicts as needed. Alternatively, you might query the view after each replication to identify and resolve conflicts immediately.\n\n\n\n\n\n How to resolve conflicts \n\nAfter you find a conflict, you can resolve it by following the four steps that are described next.\n\n\n\n* Get\n* Merge\n* Upload\n* Delete\n\n\n\nSee the following example document of the first version:\n\n{\n\"_id\": \"74b2be56045bed0c8c9d24b939000dbe\",\n\"_rev\": \"1-7438df87b632b312c53a08361a7c3299\",\n\"name\": \"Samsung Galaxy S4\",\n\"description\": \"\",\n\"price\": 650\n}\n\nLet's consider a scenario for this example. Suppose you have a database of products for an online shop. The first version of a document might look like the example provided.\n\nSee the following second version (first revision) of the document that adds a description:\n\n{\n\"_id\": \"74b2be56045bed0c8c9d24b939000dbe\",\n\"_rev\": \"2-61ae00e029d4f5edd2981841243ded13\",\n\"name\": \"Samsung Galaxy S4\",\n\"description\": \"Latest smartphone from Samsung\",\n\"price\": 650\n}\n\nThe document doesn't have a description yet, so someone might add one.\n\nSee the following alternative second version that introduces a price reduction data change to the first version of the document:\n\n{\n\"_id\": \"74b2be56045bed0c8c9d24b939000dbe\",\n\"_rev\": \"2-f796915a291b37254f6df8f6f3389121\",\n\"name\": \"Samsung Galaxy S4\",\n\"description\": \"\",\n\"price\": 600\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-conflicts"},{"document_id":"ibmcld_07085-17981-19542","score":14.7742389068,"text":"\nThe field that is used to create the histogram must have a number data type, such as integer, float, double, or date.Nonnumber types such as string are not supported. For example, \"price\": 1.30 is a number value that works, and \"price\": \"1.30\" is a string, so it doesn\u2019t work.Use the interval argument to define the size of the sections for the results to be split into. Interval values must be whole, nonnegative numbers. Choose a value that makes sense for segmenting the typical values from the field.Histograms can process decimal values that are specified in a field, but the interval must be a whole number.You can optionally include a custom name by including a name parameter.<-- <\/section \"id=\"section-histogram-syntax\" \"> --><-- <section \"id=\"section-histogram-example\" \"> --> Example For example, if your data set includes the price of several items, like: \u201cprice\u201d: 1.30, \u201cprice\u201d: 1.99, and \u201cprice\u201d: 2.99, you might use intervals of 1, so that you see everything that is grouped in the range 1 - 2, and 2 and 3. You do not want to use an interval of 100 because then all of the data ends up in the same segment. histogram(product_price,interval:1)\n<-- <\/section \"id=\"section-histogram-example\" \"> --><-- <\/section \"id=\"section-histogram\" \"> --><-- <section \"id=\"section-max\" \"> --> max Returns the highest value in the specified field across all matching documents.<-- <section \"id=\"section-max-syntax\" \"> --> Syntax max(field)\n<-- <\/section \"id=\"section-max-syntax\" \"> --><-- <section \"id=\"section-max-example\" \"> --> Example <-- <table> -->Table 2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-aggregations"},{"document_id":"ibmcld_12897-3170-4661","score":14.5908589055,"text":"\nTo find conflicts for multiple documents in a database, write a view.\n\nThe following map function is an example that emits all conflicting revisions for every document that has a conflict.\n\nSee the following example of a map function to find documents with a conflict:\n\nfunction (doc) {\nif (doc._conflicts) {\nemit(null, [doc._rev].concat(doc._conflicts));\n}\n}\n\nYou might regularly query this view and resolve conflicts as needed, or query the view after each replication.\n\n\n\n\n\n Steps to resolve conflicts \n\nAfter you find a conflict, you can resolve it in four steps: get, merge, upload, and delete, as shown later.\n\nLet's consider an example of how to resolve a conflict. Suppose that you have a database of products for an online shop. The first version of a document might look like the following example:\n\n{\n\"_id\": \"74b2be56045bed0c8c9d24b939000dbe\",\n\"_rev\": \"1-7438df87b632b312c53a08361a7c3299\",\n\"name\": \"Samsung Galaxy S4\",\n\"description\": \"\",\n\"price\": 650\n}\n\nAs the document doesn't have a description yet, someone might add one.\n\nSee the second version of the document, which is created by adding a description:\n\n{\n\"_id\": \"74b2be56045bed0c8c9d24b939000dbe\",\n\"_rev\": \"2-61ae00e029d4f5edd2981841243ded13\",\n\"name\": \"Samsung Galaxy S4\",\n\"description\": \"Latest smartphone from Samsung\",\n\"price\": 650\n}\n\nAt the same time, someone else - working with a replicated database - reduces the price.\n\nSee a different revision, conflicting with the previous one because of different price value:\n\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvcc"},{"document_id":"ibmcld_07177-1378-3200","score":14.3404765136,"text":"\nThe field used to create the histogram must be of number (integer, float, double, or date) type. Non-number types such as string are not supported. For example, \"price\": 1.30 is a number value that works, and \"price\": \"1.30\" is a string, so it wouldn\u2019t work. Use the interval argument to define the size of the sections the results are split into. Interval values must be whole, non-negative numbers, and are set to make sense for segmenting your possible field values. For example, if your data set includes the price of several items, like: \u201cprice\u201d: 1.30, \u201cprice\u201d: 1.99, and \u201cprice\u201d: 2.99, you might use intervals of 1, so that you see everything grouped between 1 and 2, and 2 and 3. You would probably not use an interval of 100, because then all the data would end up in the same segment. Histograms can process decimal values, but intervals have to be whole numbers. The syntax is histogram(<field>,<interval>), as shown in the following example.\n\nFor example:\n\nhistogram(product.price,interval:1)\n\n\n\n\n\n timeslice \n\nA specialized histogram that uses dates to create interval segments. Valid date interval values are second\/secondsminute\/minutes, hour\/hours, day\/days, week\/weeks, month\/months, and year\/years. The syntax is timeslice(<field>,<interval>,<time_zone>). To use timeslice, the time fields in your documents must be of the date data type and in [UNIX time](http:\/\/en.wikipedia.org\/wiki\/Unix_time) format. Unless both of these requirements are met, the timeslice parameter does not work correctly. You can create a timeslice if your documents contain date fields with values such as 1496228512. The value must be in a numeric format (for example, float or double) and not enclosed in quotation marks. The service treats dates in text and dates in ISO 8601 format as data type string, not as data type date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-aggregations"},{"document_id":"ibmcld_03282-7502-9528","score":14.1865516816,"text":"\nFor example, to check if an entity or context variable contains the name O'Reilly, you must surround the name with parentheses.\n\n@person:(O'Reilly) and $person:(O'Reilly)\n\nYour assistant converts these shorthand references into these full SpEL expressions:\n\nentities['person']?.contains('O''Reilly') and context['person'] == 'O''Reilly'\n\nSpEL uses a second apostrophe to escape the single apostrophe in the name.\n* Checking for multiple values: If you want to check for more than one value, you can create a condition that uses OR operators (||) to list multiple values in the condition. For example, to define a condition that is true if the context variable $state contains the abbreviations for Massachusetts, Maine, or New Hampshire, you can use this expression:\n\n$state:MA || $state:ME || $state:NH\n* Checking for number values: When comparing numbers, first make sure the entity or variable you are checking has a value. If the entity or variable does not have a number value, it is treated as having a null value (0) in a numeric comparison.\n\nFor example, you want to check whether a dollar value that a user specified in user input is less than 100. If you use the condition @price < 100, and the @price entity is null, then the condition is evaluated as true because 0 is less than 100, even though the price was never set. To prevent this type of inaccurate result, use a condition such as @price AND @price < 100. If @price has no value, then this condition correctly returns false.\n* Checking for intents with a specific intent name pattern: You can use a condition that looks for intents that match a pattern. For example, to find any detected intents with intent names that start with 'User_', you can use a syntax like this in the condition:\n\nintents[0].intent.startsWith(\"User_\")\n\nHowever, when you do so, all of the detected intents are considered, even those with a confidence lower than 0.2. Also check that intents which are considered irrelevant by Watson based on their confidence score are not returned.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tips"},{"document_id":"ibmcld_02961-7089-9230","score":13.9108560241,"text":"\n* Checking for number values: When comparing numbers, first make sure the entity or variable you are checking has a value. If the entity or variable does not have a number value, it is treated as having a null value (0) in a numeric comparison.\n\nFor example, you want to check whether a dollar value that a user specified in user input is less than 100. If you use the condition @price < 100, and the @price entity is null, then the condition is evaluated as true because 0 is less than 100, even though the price was never set. To prevent this type of inaccurate result, use a condition such as @price AND @price < 100. If @price has no value, then this condition correctly returns false.\n* Checking for intents with a specific intent name pattern: You can use a condition that looks for intents that match a pattern. For example, to find any detected intents with intent names that start with 'User_', you can use a syntax like this in the condition:\n\nintents[0].intent.startsWith(\"User_\")\n\nHowever, when you do so, all of the detected intents are considered, even those with a confidence lower than 0.2. Also check that intents which are considered irrelevant by Watson based on their confidence score are not returned. To do so, change the condition as follows:\n\n!irrelevant && intents[0].intent.startsWith(\"User_\")\n* How fuzzy matching impacts entity recognition: If you use an entity as the condition and fuzzy matching is enabled, then @entity_name evaluates to true only if the confidence of the match is greater than 30%. That is, only if @entity_name.confidence > .3.\n\n\n\n\n\n\n\n Storing and recognizing entity pattern groups in input \n\nTo store the value of a pattern entity in a context variable, append .literal to the entity name. Using this syntax ensures that the exact span of text from user input that matched the specified pattern is stored in the variable.\n\n\n\n Variable Value \n\n email \n\n\n\nTo store the text from a single group in a pattern entity with groups defined, specify the array number of the group that you want to store. For example, assume that the entity pattern is defined as follows for the @phone_number entity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tips"},{"document_id":"ibmcld_00215-9904-11016","score":13.4533250759,"text":"\n* URL - https:\/\/USERNAME:APIKEY@api.softlayer.com\/rest\/v3.1\/SoftLayer_Product_Order\/placeOrder\n* Type - POST\n* Request body -\n\n{\n\"parameters\":[{\n\"complexType\": \"SoftLayer_Container_Product_Order_Network_Storage_AsAService\",\n\"packageId\": 531,\n\"duplicateOriginVolumeId\":<PrimaryId>,\n\"isDependentDuplicateFlag\": 0,\n\"prices\": {\"id\": 19497}, {\"id\": 16479}, {\"id\": 12931}, {\"id\": 15749}, {\"id\":10407}],\n\"quantity\": 1,\n\"osFormatType\":{\n\"keyName\": \"LINUX\"\n},\n\"location\": 2,\n\"volumeSize\":23\n}]\n}\n\n\n\nTo order a dependent duplicate for a Performance (custom IOPS) volume, make a POST \/SoftLayer_Product_Order\/placeOrder call like the following REST API example.\n\n\n\n* URL - https:\/\/USERNAME:APIKEY@api.softlayer.com\/rest\/v3.1\/SoftLayer_Product_Order\/placeOrder\n* Type - POST\n* Request body -\n\n{\n\"parameters\":[{\n\"complexType\": \"SoftLayer_Container_Product_Order_Network_Storage_AsAService\",\n\"packageId\": 531,\n\"duplicateOriginVolumeId\":1327277,\n\"isDependentDuplicateFlag\": 1,\n\"prices\": {\"id\": 15751}, {\"id\": 19487}, {\"id\": 18983}, {\"id\": 15749}, {\"id\":10407}],\n\"quantity\": 1,\n\"iops\":454,\n\"osFormatType\":{\n\"keyName\": \"LINUX\"\n},","title":"","source":"https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-duplicatevolume"},{"document_id":"ibmcld_00472-31899-33668","score":11.9805905276,"text":"\nThe drilldown option is only available when you make global queries.\n\nYou can restrict results to documents with a dimension equal to the specified label. Restrict the results by adding drilldown=[\"dimension\",\"label\"] to a search query. You can include multiple drilldown parameters to restrict results along multiple dimensions.\n\nUsing a drilldown parameter is similar to using key:value in the q parameter, but the drilldown parameter returns values that the analyzer might skip.\n\nFor example, if the analyzer didn't index a stop word like \"a\", the drilldown parameter returns it when you specify drilldown=[\"key\",\"a\"].\n\n\n\n\n\n Ranges \n\nThe ranges option is only available when you make global queries.\n\nThe range facet syntax reuses the standard Lucene syntax for ranges to return counts of results that fit into each specified category. Inclusive range queries are denoted by brackets ([, ]). Exclusive range queries are denoted by curly brackets ({, }).\n\nThe indexed values can't be mixed types. For example, if 100 strings are indexed, and one number, then the index can't be used for range operations. You can check the type by using the typeof operator, and convert it by using the parseInt, parseFloat, or .toString() functions.\n\nSee the following example of a request that uses faceted search for matching ranges:\n\n?q=:&ranges={\"price\":{\"cheap\":\"[0 TO 100]\",\"expensive\":\"{100 TO Infinity}\"}}\n\nSee the following example results after a ranges check on a faceted search:\n\n{\n\"total_rows\":100000,\n\"bookmark\":\"g...\",\n\"rows\":[...],\n\"ranges\": {\n\"price\": {\n\"expensive\": 278682,\n\"cheap\": 257023\n}\n}\n}\n\n\n\n\n\n\n\n Geographical searches \n\nIn addition to searching by the content of textual fields, you can also sort your results by their distance from a geographic coordinate.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-search"},{"document_id":"ibmcld_12815-5234-7392","score":11.7764473487,"text":"\nFirst, add the Export Control Classification Number and the United Nations Standard Products and Services Code that applies to your product. Next, define your pricing plan. Currently, you can choose a free or usage-based pricing plan. If you\u2019d like, you can add multiple plans for your product. [Click Pricing then click Add ECCN to add your Export Control Classification Number. Click Add UNSPSC to add the United Nations Standard Products and Services Code for your product. Click Add plan, select the plan type, add a name, select how resource instances should be deployed, and click Save.]\n\nFor usage-based plans, you must submit your tax and EFT information to set up and receive payment disbursements for usage. You\u2019ll also want to add metrics to determine how customers are charged, and submit your updates for approval. [The Payments to me page is highlighted. Click Add metrics to add your metrics to the pricing plan. In the Metering approval section, click Request approval.]\n\nBuilding one or more service brokers is needed to manage the lifecycle of your service and metering integration. A broker must be added to complete your pricing plan. Your technical team member can get started with our sample broker. Add your broker by entering a name, a URL, a username, and a password. Or, you can import brokers from your account. After you add your broker, link it to your pricing plan. [Click Brokers. In the Onboard brokers to IBM Cloud section, click OK to open the sample reference broker. Click Add broker to add your broker. Click Pricing, click the actions icon for your pricing plan, and click Edit plan to link your broker to your pricing plan.]\n\nNow that you\u2019ve defined your pricing model, review how customers would understand and experience it. After your metering updates are approved, validate that your metered plans are correctly configured by enabling and submitting a usage test. This usage test includes creating your metering JSON, calling the Usage Metering API, and submitting metering evidence. [Click Add metrics for the pricing plan you added. Click Test estimation and metering to submit your metering evidence for review.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-get-started"},{"document_id":"ibmcld_03729-7965-9641","score":11.3403254853,"text":"\nTier 3: 2001 - 3000 $0.75 USD \n Tier 4: 3001 - 4000 $0.60 USD \n Tier 5: > 4000 $0.40 USD \n\n\n\nThe following table illustrates how much you pay with a plan that is based on a graduated tier pricing model:\n\n\n\nTable 5. Charge calculation by using the graduated tier pricing model\n\n Quantity of Items Charge Calculation Total Price \n\n 500 500 \u00d7 1 (unit price for Tier 1) = 500 $500 USD \n 1500 (1000 \u00d7 1 (unit price for Tier 1)) + (500 \u00d7 0.90 (unit price for Tier 2)) = 1450 $1450 USD \n 2500 (1000 \u00d7 1 (unit price for Tier 1)) + (1000 \u00d7 0.90 (unit price for Tier 2)) + (500 \u00d7 0.75 (unit price for Tier 3)) = 2275 $2275 USD \n ... ... ... \n 5200 (1000 \u00d7 1 (unit price for Tier 1)) + (1000 \u00d7 0.90 (unit price for Tier 2)) + (1000 \u00d7 0.75 (unit price for Tier 3)) + (1000 \u00d7 0.60 (unit price for Tier 4)) + (1200 \u00d7 0.40 (unit price for Tier 5)) = 3730 $3730 USD \n\n\n\n\n\n\n\n Block tier \n\nIn the block tier model, the price is a set charge for the quantity you use within a usage level. The total price is the charge for your level of usage regardless of your actual usage. Each successive tier provides a lower price to quantity ratio. For example:\n\n\n\nTable 6. Block tier pricing table\n\n Quantity of Items Total Price for All Items \n\n Tier 1: <= 1000 $1000 USD \n Tier 2: <= 2000 $1900 USD \n Tier 3: <= 3000 $2800 USD \n Tier 4: <= 4000 $3500 USD \n Tier 5: <= 10000 $5000 USD \n\n\n\nThe following table illustrates how much you pay with a plan that is based on a block tier pricing model:\n\n\n\nTable 7. Charge calculation by using the block tier pricing model\n\n Quantity of Items Charge Calculation Total Price \n\n 500 The number of items falls into Tier 1, so the total price is $1000 USD. $1000 USD","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09647-1993-2943","score":11.0607841155,"text":"\nThe list of eligible server applications includes Microsoft SQL Server database software, Microsoft Exchange Server, Microsoft SharePoint Server, Microsoft Skype for Business Server, Microsoft System Center servers, and Microsoft Dynamics 365 Server for Customer Service and Sales applications. (Note: For SQL Server customers with core-based licensing and Software Assurance coverage, broader benefits are available under [Azure Hybrid Benefit](https:\/\/azure.microsoft.com\/en-us\/pricing\/hybrid-benefit\/) rights. For more information, see Azure Hybrid Benefit. The steps described below do not apply to Azure Hybrid Benefit use.) The Windows Server operating system licenses remain assigned to customers\u2019 on-premises hardware with their applicable license terms. For additional information and a full list of eligible products, please refer to the [Microsoft Product Terms](https:\/\/www.microsoft.com\/en-us\/licensing\/product-licensing\/products?rtc=1).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/microsoft?topic=microsoft-microsoft-license-mobility"},{"document_id":"ibmcld_12861-3661-6097","score":9.1409321975,"text":"\nLogging and monitoring Products that support storing, searching, analyzing, and monitoring log data and events. And, products that support reviewing and managing the operational workflow and processes being logged. \n Mobile Products with specific or special utility for users creatings things to be used on mobile devices. \n Networking Products that support or augment the linking of computers so they can operate interactively. \n Security Products that provide the protection of stored data from theft, leakage, and deletion. \n Storage Products that support data to be created, read, updated, and deleted. \n\n\n\n\n\n\n\n\n\n Adding search keywords \n\nAdd relevant keywords that enable your product to appear in search results when users search the catalog.\n\n\n\n1. Click Enter words, phrases, and other key search terms associated with the product.\n2. Enter one or more keywords for your product, and click Save.\n\n\n\n\n\n\n\n\n\n Defining your product page by using the console \n\nWhen users select your product from the catalog, they are directed to additional details, including a list of features and supporting media. These details are displayed on the About tab within your product page.\n\n\n\n Providing a list of product features \n\nProvide a list of features that highlights your product's attributes and benefits for users.\n\nUse a descriptive title and 1-2 sentences for each feature. You want the information to be visually scannable for users.\n\n\n\n\n\n Providing a detailed description about your product \n\nYour detailed description explains the value of your product and what users gain by using it. The detailed description is displayed at the beginning of your product page in the catalog. You can expand on the short description for your catalog entry, but don't repeat the information you already provided.\n\n\n\n\n\n Providing media \n\nProvide links to high-quality images or videos to help illustrate what your product is, its value, and user benefits. The supported media types are images, videos in MP4 or WebM file format, and videos hosted on YouTube or Vimeo.\n\nSome examples of effective media include an introductory walkthrough of your product, an explanation of what your product is and why users might want to use it, or a comparison of certain features.\n\n\n\n\n\n Providing your documentation link \n\nYour documentation link is used to direct users to your product's warranted documentation.\n\n\n\n\n\n\n\n Defining your catalog entry by using the API","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-sw-catalog-details"},{"document_id":"ibmcld_06104-1746-3854","score":8.2426597352,"text":"\nFor example, WordPress is optimized to store data in a MySQL database. In these cases, the type of storage is selected for you.\n\nDetermine the type of data that you want to store.\n: Structured data: Data that you can store in a relational database where you have a table with columns and rows. Data in tables can be connected by using keys and is usually easy to access due to the pre-defined data model. Examples are phone numbers, account numbers, Social Security numbers, or postal codes.\n: Semi-structured data: Data that does not fit into a relational database, but that comes with some organizational properties that you can use to read and analyze this data more easily. Examples are markup language files such as CSV, XML, or JSON.\n: Unstructured data: Data that does not follow an organizational pattern and that is so complex that you can't store it in a relational database with pre-defined data models. To access this data, you need advanced tools and software. Examples are e-mail messages, videos, photos, audio files, presentations, social media data, or web pages.\n\nIf you have structured and unstructured data, try to store each data type separately in a storage solution that is designed for this data type. Using an appropriate storage solution for your data type eases up access to your data and gives you the benefits of performance, scalability, durability, and consistency.\n\nAnalyze how you want to access your data. Storage solutions are usually designed and optimized to support read or write operations.\n: Read-only: You don't want to write or change your data. Your data is read-only.\n: Read and write: You want to read, write, and change your data. For data that is read and written, it is important to understand if the operations are read-heavy, write-heavy, or balanced.\n\nDetermine the frequency that your data is accessed.\n: Hot data: Data that is accessed frequently. Common use cases are web or mobile apps.\n: Cool or warm data: Data that is accessed infrequently, such as once a month or less. Common use cases are archives, short-term data retention, or disaster recovery.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan"},{"document_id":"ibmcld_10545-1750-3858","score":8.2426597352,"text":"\nFor example, WordPress is optimized to store data in a MySQL database. In these cases, the type of storage is selected for you.\n\nDetermine the type of data that you want to store.\n: Structured data: Data that you can store in a relational database where you have a table with columns and rows. Data in tables can be connected by using keys and is usually easy to access due to the pre-defined data model. Examples are phone numbers, account numbers, Social Security numbers, or postal codes.\n: Semi-structured data: Data that does not fit into a relational database, but that comes with some organizational properties that you can use to read and analyze this data more easily. Examples are markup language files such as CSV, XML, or JSON.\n: Unstructured data: Data that does not follow an organizational pattern and that is so complex that you can't store it in a relational database with pre-defined data models. To access this data, you need advanced tools and software. Examples are e-mail messages, videos, photos, audio files, presentations, social media data, or web pages.\n\nIf you have structured and unstructured data, try to store each data type separately in a storage solution that is designed for this data type. Using an appropriate storage solution for your data type eases up access to your data and gives you the benefits of performance, scalability, durability, and consistency.\n\nAnalyze how you want to access your data. Storage solutions are usually designed and optimized to support read or write operations.\n: Read-only: You don't want to write or change your data. Your data is read-only.\n: Read and write: You want to read, write, and change your data. For data that is read and written, it is important to understand if the operations are read-heavy, write-heavy, or balanced.\n\nDetermine the frequency that your data is accessed.\n: Hot data: Data that is accessed frequently. Common use cases are web or mobile apps.\n: Cool or warm data: Data that is accessed infrequently, such as once a month or less. Common use cases are archives, short-term data retention, or disaster recovery.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-plan"},{"document_id":"ibmcld_06459-1498-2185","score":7.9670960712,"text":"\nLarger disks have higher performance with baseline input\/output operations per second (IOPS) of 10 IOPS for each GB. etcd relies on writing data to disk to maintain its consensus algorithm, so exceeding your IOPS deployment's limits can cause cluster instability. Scaling your deployment's disk resources increases the IOPS available to your deployment.\n\n\n\n\n\n Memory Usage \n\netcd uses memory to cache data and can benefit from increasing the amount of memory to at least the size of the data set. Memory is also used to maintain the watchers, so if your use-case requires thousands of watchers, you can benefit from increasing the amount of RAM available to your deployment ever further.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-performance"},{"document_id":"ibmcld_07085-25935-27639","score":7.3408590494,"text":"\nYou can use relevancy to get a score that indicates the level of relevancy between the term and keywords in the query. This parameter is false by default. If set to true, the following fields are returned also:\n<-- <ul> -->\n\n* total_matching_documents: Number of documents in the collection where the term is mentioned in the specified field.\n* estimated_matching_results: Number of documents that are estimated to have the term in the specified field in the set of documents that are returned by the query.\n\n<-- <\/ul> -->\n\n<-- <\/ul> --><-- <\/section \"id=\"section-term-syntax\" \"> --><-- <section \"id=\"section-term-example\" \"> --> Example The following example returns the text from the recognized entities in the document, and specifies to return a maximum of 10 terms.For example: term(enriched_text.entities.text,count:10)\nWhen relevancy is set to true, a relevancy score is shown in the results. Relevancy measures the level of uniqueness of the frequency count compared to other documents that match your query. If the relevancy shows 2.0, it means that the number of times that the two data points intersect is 2 times larger than expected.For more examples, see Grouping documents]] and Combining aggregation types]] ! ! ! ! ! .<-- <\/section \"id=\"section-term-example\" \"> --><-- <\/section \"id=\"section-term\" \"> --><-- <section \"id=\"section-timeslice\" \"> --> timeslice A specialized histogram that uses dates to create interval segments.<-- <section \"id=\"section-timeslice-syntax\" \"> --> Syntax The syntax is timeslice({field},{interval},{time_zone}).<-- <ul> --> * The field that you specify must have a date data type. For more information about date field, see How dates are handled]] ! ! ! ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-aggregations"},{"document_id":"ibmcld_09647-7-2622","score":7.1500437593,"text":"\nLicensed Mobility through Microsoft Software Assurance Overview \n\n\n\n Overview \n\nOrganizations around the world are benefitting from the power, flexibility, and efficiency of cloud computing. Whether you want to deploy server applications in a traditional customer on- premises environment, through a partner or a Microsoft cloud-hosted model, or a combination of all three, Microsoft gives you the flexibility to choose what is right for you, on your terms and on your schedule.\n\n\n\n\n\n License mobility through Microsoft Software Assurance \n\nWith more businesses adopting Infrastructure as a Service (IaaS), customers moving server workloads and applications to the cloud want to take advantage of their existing licensing investments as part of their IT strategy.\n\nLicense Mobility through Microsoft Software Assurance gives Microsoft Volume Licensing customers the flexibility to deploy certain server applications with active Software Assurance on-premises or in the cloud, without having to buy additional licenses. As a result, customers can take advantage of the lowest and flexible cost infrastructure for changing business priorities. Because of this new Software Assurance benefit, customers do not need to purchase new Microsoft Client Access Licenses (CALs), and no associated mobility fees exist.\n\n\n\n\n\n Products eligible for License mobility through Software Assurance \n\nFor specific Microsoft server products, [License Mobility through Software Assurance](https:\/\/www.microsoft.com\/en-us\/licensing\/licensing-programs\/software-assurance-license-mobility?rtc=1tab=3) gives customers enhanced flexibility. A customer can assign their application server licenses with active Software Assurance to run server instances on shared hardware via Microsoft Azure or a License Mobility through Software Assurance Partner\u2019s data center. Although sharing hardware, such server instances (virtual machines) must be dedicated to a single customer and are not shared with other customers.\n\nThe list of eligible server applications includes Microsoft SQL Server database software, Microsoft Exchange Server, Microsoft SharePoint Server, Microsoft Skype for Business Server, Microsoft System Center servers, and Microsoft Dynamics 365 Server for Customer Service and Sales applications. (Note: For SQL Server customers with core-based licensing and Software Assurance coverage, broader benefits are available under [Azure Hybrid Benefit](https:\/\/azure.microsoft.com\/en-us\/pricing\/hybrid-benefit\/) rights. For more information, see Azure Hybrid Benefit. The steps described below do not apply to Azure Hybrid Benefit use.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/microsoft?topic=microsoft-microsoft-license-mobility"},{"document_id":"ibmcld_16278-7-2318","score":6.9916322869,"text":"\nComparing actions and dialog \n\nChoose the right type of conversation for your use case.\n\n\n\n Actions benefits \n\nUsing actions is the best choice when you want to approach the assistant with a focus on content. Actions offers the following benefits:\n\n\n\n* The process of creating a conversational flow is easier. People who have expertise with customer care can write the words that your assistant says. With a simplified process anyone can build a conversation. You don't need knowledge about machine learning or programming.\n* Actions provide better visibility into the customer's interaction and satisfaction with the assistant. Because each task is discrete and has a clear beginning and ending, you can track user progress through a task and identify snags.\n* The conversation designer doesn't need to manage data collected during the conversation. By default, your assistant collects and stores information for the duration of the current action. You don't need to take extra steps to delete saved data or reset the conversation. But if you want, you can store certain types of information, such as the customer's name, for the duration of a conversation.\n* Many people can work at the same time in separate, self-contained actions. The order of actions within a conversation doesn't matter. Only the order of steps within an action matters. And the action author can use drag and drop to reorganize steps in the action for optimal flow.\n\n\n\n\n\n\n\n Dialog benefits \n\nA dialog-based conversation is the best choice when you want greater control over the logic of the flow. The dialog editor exposes more of the underlying artifacts (such as intents and entities) used to build the AI models. The dialog flow uses an if-then-else style structure that might be familiar to developers, but not to content designers or customer-care experts.\n\n\n\n\n\n How actions are different from dialog \n\nIf you are already familiar with dialog-based conversations, learn more about how actions compares.\n\n\n\nConversational flow skill feature support\nThis table has row and column headers. The row headers identify features. The column headers identify the different skill types. To understand which features are supported by a skill, go to the row that describes the feature, and find the columns for the skill you are interested in.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-comparing-actions-dialog"},{"document_id":"ibmcld_02932-2728-4915","score":6.9857372666,"text":"\nIf there are misspelled terms that you expected your assistant to correct, but it did not, then review the rules that your assistant uses to decide whether to correct a word to see if the word falls into the category of words that your assistant intentionally does not change.\n\n\n\n\n\n Autocorrection rules \n\nTo avoid overcorrection, your assistant does not correct the spelling of the following types of input:\n\n\n\n* Capitalized words\n* Emojis\n* Location entities, such as states and street addresses\n* Numbers and units of measurement or time\n* Proper nouns, such as common first names or company names\n* Text within quotation marks\n* Words containing special characters, such as hyphens (-), asterisks (*), ampersands (&), or at signs (@), including those used in email addresses or URLs.\n* Words that belong in this skill, meaning words that have implied significance because they occur in entity values, entity synonyms, or intent user examples.\n\nMentions of a contextual entity can be corrected inadvertently. That's because terms that function as contextual entity mentions are fluid; they cannot be predetermined and avoided by the spell checker function in the way a list of dictionary-based terms can be.\n\n\n\nIf the word that is not corrected is not obviously one of these types of input, then it might be worth checking whether the entity has fuzzy matching enabled for it.\n\n\n\n How is spelling autocorrection related to fuzzy matching? \n\nFuzzy matching helps your assistant recognize dictionary-based entity mentions in user input. It uses a dictionary lookup approach to match a word from the user input to an existing entity value or synonym in the skill's training data. For example, if the user enters boook, and your training data contains a @reading_material entity with a book value, then fuzzy matching recognizes that the two terms (boook and book) mean the same thing.\n\nWhen you enable both autocorrection and fuzzy matching, the fuzzy matching function runs before autocorrection is triggered. If it finds a term that it can match to an existing dictionary entity value or synonym, it adds the term to the list of words that belong to the skill, and does not correct it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-spell-check"},{"document_id":"ibmcld_07578-565403-567284","score":6.9544569269,"text":"\nFor more information, see the [End of Service announcement](https:\/\/cloud.ibm.com\/docs\/dns?topic=dns-resellone-eos).\n* What are the benefits of migrating to Hover?\n\n What are the benefits of migrating to Hover? \n\nAs a Hover customer, you\u2019ll benefit from a clean and intuitive domain management control panel. You'll also get an expanded selection of premium top-level domains, and great customer support.\n* What are the benefits of migrating to OpenSRS?\n\n What are the benefits of migrating to OpenSRS? \n\nAs a direct OpenSRS reseller, you\u2019ll be able to fully manage your domains with greater ease. You'll get a greater selection of premium top-level domains and be able to offer your customers an expanded selection to automate your domain management experience. Post migration, you\u2019ll benefit from improved availability of your business-critical domain services and additional features, including:\n\n\n\n* Brandable end-user communications\n* Scalability\n* Exceptional reliability\n* Flexible integration\n\n\n\n* What service agreement do I follow after migration to Hover?\n\n What service agreement do I follow after migration to Hover? \n\nAfter migration, you are automatically transitioned to Tucows\u2019 retail domains brand Hover's [Terms Of Service](https:\/\/www.hover.com\/tos).\n* What service agreement do I follow after migration to a Tucows OpenSRS Reseller account?\n\n What service agreement do I follow after migration to a Tucows OpenSRS Reseller account? \n\nAfter migration, you are automatically transitioned to the OpenSRS\/Tucows\u2019 Inc. Master Services Agreement. You can find this from the [OpenSRS website](https:\/\/opensrs.com\/wp-content\/uploads\/Master_Services_Agreement.html).\n\nAdditional resources can be found in [OpenSRS Documentation](https:\/\/opensrs.com\/resources\/documentation\/).\n* If I have more questions, who can I contact?\n\n If I have more questions, who can I contact?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02597-4595-6892","score":22.7215588283,"text":"\nThrough the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.\n\nAs well as controlling which APIs a customer can use, different Plans can be used to implement rate limits. A rate limit can be implemented as a default rate across an entire Plan, or for specific operations of an API within that Plan, exempting them from the Plan rate limit. Different Plans can have differing rate limits, both between operations and for the overall limit. Applying rate limits to Plans makes it easy to offer different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute while a \"Full Plan\" might permit up to 1000 calls per minute.\n\nFinally, different Plans can be used to assign a billing cost. A Plan can be set as a free Plan, or as a Plan with billing. Plans with billing can be used with rate limits to set different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute for a cost of $5 per month, while a \"Full Plan\" might permit up to 1000 calls per minute for a cost of $20 per month.\n\nNote: Applying a rate limit at the Plan level, creates a default rate limit that applies to each operation within the Plan. If you need to set specific rate limits for specific operations, you must set them within the operations themselves and this setting overrides the setting at the Plan level.\n\nIBM API Connect also supports the implementation of multiple versions of Products. You can choose version numbers and use them to aid the development of your Products and Plans.\n\nNote: The version for a Product is distinct from the version of any APIs that are contained in the associated Plans. Plans cannot themselves have their own version, they use the version of their parent Product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-about_apic_overview"},{"document_id":"ibmcld_03166-23681-24372","score":21.8355069181,"text":"\nFor Lite plans, usage is measured by the number of \/message calls (API) are sent to the assistant from the web chat integration. For all other plans, usage is measured by the number of monthly active users (MAU) that the web chat interacts with. The maximum number of allowed MAUs differs depending on your Watson Assistant plan type.\n\n\n\nPlan details\n\n Plan Maximum usage \n\n Enterprise Unlimited MAU \n Premium (legacy) Unlimited MAU \n Plus Unlimited MAU \n Trial 5,000 MAU \n Lite 10,000 API (approximately 1,000 MAU) \n\n\n\nFor more information about how the web chat widget tracks MAUs, see [Billing](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basicsweb-chat-basics-billing).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_03798-0-2240","score":21.4674248907,"text":"\n\n\n\n\n\n\n  Understanding my invoice \n\nBillable accounts receive a monthly invoice for the usage charges and other fees that are incurred. At any time, you can view your invoice or expected invoiced charges by going to the [Invoices](https:\/\/cloud.ibm.com\/billing\/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console.\n\nIf your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices. To sign up and view your invoices, you must provide your IBM customer number. If you don't know your customer number, contact IBM Cloud Support by calling 1-866-325-0045 and selecting the third option.\n\nIn this situation, go to [Invoices@IBM](http:\/\/ibm.com\/invoices) to review your upcoming invoice, past invoices, or details about service charges.\n\n\n\n  Invoicing for different account types \n\nDepending on your account type, your usage is incurred and reflected differently on your invoice. Review the following differences for billing based on your account type:\n\n\n\n*  Subscription: The billed interval is contractual and depends on a negotiated payment for usage credits.\n*  Pay-As-You-Go: An estimation of your charges is found on the [Usage](https:\/\/cloud.ibm.com\/billing\/usage) page. Charges from platform and classic infrastructure services are included if your account uses both types. Infrastructure as a Service (IaaS) charges aren't included.\n\n\n\nThird-party services, such as SendGrid, don't bill for their service through IBM Cloud if you signed up for their service outside of IBM Cloud.\n\nAn IBM Cloud service might provide a free allocation before the start of your billing period. To determine whether your service instance provides a free allocation, go to the [Resources list](https:\/\/cloud.ibm.com\/resources) in the IBM Cloud console. Click the service name, and then click Plan. Review the feature description for each plan to see whether the service offers free allocations. Free allocations are applied to the account level and not the organization level.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-understand-invoices"},{"document_id":"ibmcld_03107-4-1607","score":21.2671432881,"text":"\nThis documentation for the classic Watson Assistant experience has moved. For the most up-to-date version, see [Managing your plan](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-plan). To see all documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Managing your plan \n\nThis topic provides:\n\n\n\n* A [plan information](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-planadmin-managing-plan-information) reference\n* Steps on [upgrading your plan](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-planadmin-managing-plan-upgrade)\n\n\n\n\n\n Plan information \n\nBilling for the use of Watson Assistant is managed through your IBM Cloud\u00ae account.\n\nThe metrics that are used for billing purposes differ based on your plan type. You can be billed based on the number of API calls made to a service instance or on the number of active users who interact with the instance.\n\nFor answers to common questions about subscriptions, see [How you're charged](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges).\n\nExplore the Watson Assistant [service plan options](https:\/\/www.ibm.com\/cloud\/watson-assistant\/pricing\/).\n\n\n\n Paid plan features \n\nThe following features are available only to users of a Plus or Enterprise plan. ![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/plus.png)\n\n\n\n* [Phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-plan"},{"document_id":"ibmcld_16252-7-1601","score":20.969682001,"text":"\nManaging your plan \n\nThis topic provides:\n\n\n\n* A [plan information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-information) reference\n* Steps on [upgrading your plan](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-upgrade)\n\n\n\n\n\n Plan information \n\nBilling for the use of Watson Assistant is managed through your IBM Cloud\u00ae account.\n\nThe metrics that are used for billing purposes differ based on your plan type. You can be billed based on the number of API calls made to a service instance or on the number of active users who interact with the instance.\n\nFor answers to common questions about subscriptions, see [How you're charged](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges).\n\nExplore the Watson Assistant [service plan options](https:\/\/www.ibm.com\/cloud\/watson-assistant\/pricing\/).\n\n\n\n Paid plan features \n\nThe following features are available only to users of a Plus or Enterprise plan. ![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/plus.png)\n\n\n\n* [Phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone)\n* [Private endpoints](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-securingsecurity-private-endpoints)\n* [Search](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-add)\n* [v2 Logs API](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2listlogs)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-plan"},{"document_id":"ibmcld_16365-15662-16934","score":20.140360711,"text":"\nOn Apple devices, the Intelligent Tracking Prevention feature automatically deletes any client-side cookie after 7 days. This means that if an anonymous customer accesses your website and then visits again two weeks later, the two visits are treated as two different MAUs. For information about how to avoid this problem, see [Managing user identity information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid).\n\nFor information about how to customize the handling of user identity information for billing purposes, see [Managing user identity information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid).\n\nThe usage is measured differently depending on the plan type. For Lite plans, usage is measured by the number of \/message calls (API) are sent to the assistant from the web chat integration. For all other plans, usage is measured by the number of monthly active users (MAU) that the web chat interacts with. The maximum number of allowed MAUs differs depending on your Watson Assistant plan type.\n\n\n\nPlan details\n\n Plan Maximum usage \n\n Enterprise Unlimited MAU \n Premium (legacy) Unlimited MAU \n Plus Unlimited MAU \n Trial 5,000 MAU \n Lite 10,000 API (approximately 1,000 MAU)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03704-1531-3564","score":19.959513208,"text":"\nWhat's the difference between a Pay-As-You-Go and Subscription account? \n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\n\n\n\n\n What happens if my Lite plan instance reaches the monthly quota? \n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n\n\n\n\n\n Can I use PayPal as a payment method? \n\nAs of March 31, 2023, PayPal is no longer accepted.\n\n\n\n\n\n Can I update my credit card? \n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1042894-1044946","score":19.6929751736,"text":"\nContact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to request a quote for additional server bandwidth.\n* What's the difference between a Pay-As-You-Go and Subscription account?\n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n* What happens if my Lite plan instance reaches the monthly quota?\n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n* Can I use PayPal as a payment method?\n\nAs of March 31, 2023, PayPal is no longer accepted.\n* Can I update my credit card?\n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1042765-1044817","score":19.6929751736,"text":"\nContact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to request a quote for additional server bandwidth.\n* What's the difference between a Pay-As-You-Go and Subscription account?\n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n* What happens if my Lite plan instance reaches the monthly quota?\n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n* Can I use PayPal as a payment method?\n\nAs of March 31, 2023, PayPal is no longer accepted.\n* Can I update my credit card?\n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_02597-3131-5174","score":19.4094523755,"text":"\nPlans can share APIs, but whether subscription approval is required depends upon the Plan itself. Additionally, you can enforce rate limits through Plans or through operations within a Plan's APIs that override the Plan's rate limit.\n\nPlans can also specify billing costs for customers who use your Products. For example, you can define three different Plans for a single Product. Each Plan can have a different subscription cost and a different rate limit that targets different customers.\n\n\n\n\n\n Products \n\nPlans and APIs are grouped in Products. Through Products, you can manage the availability and visibility of APIs and Plans. Use the API Designer to create, edit, and stage your Product. Use the API Manager to manage the lifecycle of your Product.\n\nThe following diagram demonstrates how Products, Plans, and APIs relate to one another. Note how Plans belong to only one Product, can possess different APIs to other Plans within the same Product, and can share APIs with Plans from any Product. Figure to show the hierarchy of Products, Plans, and APIs. ![Figure to show the hierarchy of Products, Plans, and APIs.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/78bb71851d95d7580503eb9ba10cf3ae31490ade\/apiconnect\/images\/plan_product_hierarchy.png)\n\nYou can create Plans only within Products, and these Products are then published in a Catalog. A lifecycle manager can then control the availability and visibility of APIs and Plans through the API Manager. Through the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-about_apic_overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.3333333333}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03735-7-1918","score":24.3583566096,"text":"\nEstimating your costs \n\nYou can use the cost estimator to estimate the cost of IBM Cloud\u00ae products by customizing plans that fit your business needs. Your account type doesn't affect your estimates. Explore the catalog to find available products to add to an estimate.\n\nEstimates can now be saved to an account. Make sure you're in the account that you want to save the estimate to. If you have existing estimates, they must be converted to a saved estimate that is attached to an account.\n\n\n\n Creating a new estimate \n\n\n\n1. In the IBM Cloud console, go to Cost estimator icon![Cost estimator icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/calculator.svg). From here, you are directed to Estimating your costs page.\n2. Click Create new estimate.\n3. Enter a name and description for the estimate.\n4. Click Create\n5. From here, you are directed to the estimate details page. Click Go to catalog to add products to the estimate.\n6. Select the product that you are interested in.\n\nDepending on the product, an interim informational page might be displayed. For example, if you select Bare Metal Servers, an informational page that describes various features is displayed. Click Continue.\n7. Select your pricing plan and enter other configuration details if needed. Then, click Add to estimate.\n\nSome products might require that you log in to add them to an estimate.\n8. Enter your estimated usage, and click Calculate Cost. You can adjust the estimated usage and recalculate the cost to see how different usage levels affect the overall cost.\n\n\n\nBy default, the estimator shows the pricing and billing currency set for your account. Pricing can vary by region. If you're estimating costs for a different location or currency, you might have to select the appropriate currency on the order summary page for the product or change the currency on your account.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost"},{"document_id":"ibmcld_12539-0-2074","score":23.8559861314,"text":"\n\n\n\n\n\n\n  Estimating architecture costs in a project \n\nCost estimation is available for deployable architectures in the IBM Cloud catalog. Depending on the deployable architecture, a starting cost is estimated based on the available data. This estimate is meant to be a starting point to help you determine how much your account could be charged for deploying an architecture. This estimated amount is subject to change as the architecture is customized within a project, and it does not include all resources, usage, licenses, fees, discounts, or taxes.\n\n\n\n  Viewing the starting cost for your deployable architecture \n\nDepending on the deployable architecture that you select from the catalog, there is an estimated starting cost.\n\nTo view the estimated starting cost, complete the following steps:\n\n\n\n1.  Go to the catalog details page for the deployable architecture.\n2.  Next, click the Starting at amount for additional details about the cost summary.\n\n\n\nAfter you add the deployable architecture to your project, you can configure the input values. By doing so, you can tailor the architecture to match your needs. Adjusting the configuration input might adjust the estimated cost.\n\n\n\n1.  Go to the Projects page, and select a project.\n2.  Go to Configurations, and select a configuration of the deployable architecture.\n3.  Enter the input values to configure the deployable architecture, and click Save. For more information about configuring and deploying, see [Configuring and deploying a deployable architecture](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-config-project).\n4.  After saving, the validation checks are run and a new cost estimate is computed. This might take a few minutes. After the validation is complete, you can view the estimated cost for the configured architecture on the validation modal in the Cost estimate successful section.\n\n\n\nThis estimated amount is subject to change as the architecture is customized and deployed, and it does not include all resources, usage, licenses, fees, discounts, or taxes.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-cost-estimate-project"},{"document_id":"ibmcld_04260-0-1777","score":23.5265716324,"text":"\n\n\n\n\n\n\n  Using the Pricing calculator to estimate your monthly cost per user per month \n\nThe pricing information for your system resources is shown on the side of the provisioining window and shows all of your equipment and physical resource costs. To view the cost estimates for your organization on a per user basis, use the pricing calculator. You can get estimates for different configurations before you begin provisioning. The pricing calculator is on the DaaS estimate tab on the main Citrix-DaaS product page.\n\n\n\n  What the pricing calculator does \n\nThe pricing calculator looks at several factors to estimate your cost and savings with different Citrix-DaaS configurations:\n\n\n\n1.  The geographic area and region where your resources are located.\n2.  The number of users that use your system.\n3.  The operating system that your system uses.\n4.  The boot volume size on your system.\n5.  The profile settings for your system, including the image to use, CPU, RAM, etc.\n\n\n\nThe calculator takes the inputs and creates a per user estimate for your configuration.\n\n\n\n\n\n  Calculating cost per user for your system \n\nTo calculate the cost per users for your Citrix-DaaS configuration:\n\n\n\n1.  From the Citrix-DaaS product page, select the DaaS estimate tab. The pricing calculator is shown.\n2.  Enter the geographic, user, OS, and boot volume information for your system.\n3.  Verify that the profile settings listed match your system or match the system that you are estimating. If they do not match, select Change Profile to enter the correct profile information.\n\n\n\nThe calculator shows you the cost estimate per user for your system.\n\nIf you want to see estimates for different profiles, or different numbers of users, modify the specific fields to see new estimates.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/citrix-daas?topic=citrix-daas-pricing-calculator-monthly-cost"},{"document_id":"ibmcld_03735-1425-3233","score":23.1090580177,"text":"\nEnter your estimated usage, and click Calculate Cost. You can adjust the estimated usage and recalculate the cost to see how different usage levels affect the overall cost.\n\n\n\nBy default, the estimator shows the pricing and billing currency set for your account. Pricing can vary by region. If you're estimating costs for a different location or currency, you might have to select the appropriate currency on the order summary page for the product or change the currency on your account.\n\n\n\n1. Click Save and select the estimate that you'd like to add the product to, and then add the calculated cost to your estimate by clicking Save.\n2. When you're done adding products to your estimate, review the product details, and click View estimate.\n\n\n\n\n\n\n\n Updating an existing estimate \n\nYou can always update the name and description of an estimate as your needs change. To edit an estimate, complete the following steps:\n\n\n\n1. From the View Estimate page, identify the estimate that you want to edit.\n2. Click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Edit.\n3. Enter the updated name and description.\n4. Click Save\n\n\n\n\n\n\n\n Saving and sharing your estimate \n\nWhen you create an estimate, you can save each estimate's unique link to share or revisit directly through your browser. To share an estimate, complete the following steps:\n\n\n\n1. From the View Estimate page, identify the estimate that you want to share.\n2. Click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Share.\n3. Click Copy link and share the link with users in your account.\n\n\n\n\n\n\n\n Creating quotes for classic infrastructure services","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost"},{"document_id":"ibmcld_15160-8509-10437","score":22.3150938774,"text":"\n* Hyper Protect Crypto Services - it can be used when the original back is encrypted by using the Hyper Protect Crypto Services service.\n\n\n\n\n\nTags are automatically copied over from the parent backup.\n6. Click Save.\n7. The Summary updates automatically with the selections that you made. For example, the plan might be \"Every Monday at -5:53 UTC (12:30 AM CDT) starting on 26 March 2022.\" The Plan status toggle is enabled by default.\n8. Click Create to save the new plan. The list of plans is updated in the policy details page. If you want to make any changes, click the pencil icon for that plan. If you want to delete the plan, click the delete icon.\n\n\n\n\n\n\n\n Estimating your expected usage and costs \n\nUse the cost estimator to see what your backups might cost based on the rate of expected change in your Block Storage for VPC volumes.\n\n\n\n1. After you [create your backup policy and plan](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-planbackup-policy-create-ui), on the side panel of Backup summary, click Add to estimate.\n2. On the Estimate side panel, enter your expected usage to the initial costs. The backup policy is without charge. You pay for the amount of backup storage that is used. Provide the following estimates:\n\n\n\n* Number of volumes you want to associate with the backup policy.\n* Average amount of data per volume (in GBs). For example, you might associate two volumes with a policy. The first volume has 4 GB of data and the second 20 GB. An average of the two would be 12 GB.\n* Number of backups per volume per month. You can take a maximum of 750 backup snapshots per volume.\n* Percent of incremental change after the initial backup. For example, 15 percent increase in size for each subsequent backup.\n\n\n\n3. When you're finished, click Calculate cost.\n\n\n\nThe cost estimate summary shows how the costs are calculated and breaks down the storage cost, providing a monthly estimate.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan"},{"document_id":"ibmcld_11163-81224-83154","score":22.2372347105,"text":"\n: To help you decide and analyze what services you'd like to purchase, you can use the cost estimator. Now, you can go through the console and select each service you'd like to have, and add all of the costs in an easy to use tool. You can even enter projected data usages, lookups per second, writes per second, and queries per second to get a more accurate estimation of your monthly expenditures. You can use the cost estimator with each catalog service you select, or you can click the Cost Estimator icon ![Cost Estimator icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/adcecdbe4e86955f88aac7f3c1e7ec3ff44992ef\/overview\/icons\/calculator.svg) in the console menu to get a summary of your estimated costs. For more information, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\n\n\n\n\n 01 November 2018 \n\nUpdated global location names\n: As IBM Cloud continues to expand our global availability footprint, we\u2019re updating our location naming structure to better support an understandable, consistent hierarchy of geographies, regions, and data centers around the world. If you\u2019re familiar with our current global regions, you\u2019ll recognize names like US South and Sydney. We\u2019re aligning these location names to the names of the city in which the data centers physically exist.\n\nFor now, the programmatic IDs are not changing, so there\u2019s no impact from an API perspective. The following table shows the old and new location names. For more information and a comprehensive list of data centers and regions, see [Service availability](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-services_region).\n\n\n\nTable 1. New location names\n\n Previous Location Display Name New Location Display Name Code \n\n US South Dallas us-south \n US East Washington DC us-east \n United Kingdom London eu-gb \n Germany Frankfurt eu-de \n Sydney Sydney au-syd \n AP North Tokyo jp-tok \n\n\n\n\n\n\n\n\n\n October 2018","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-whatsnew"},{"document_id":"ibmcld_07578-806120-808288","score":22.2174660704,"text":"\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-805993-808161","score":22.2174660704,"text":"\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_11857-1988-2975","score":22.0755348658,"text":"\nSatellite-enabled IBM Cloud services \n\nEach IBM Cloud service instance that you create in your Satellite location incurs charges. For more information, see [Supported Satellite-enabled IBM Cloud services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-managed-services).\n\n\n\n\n\n Can I estimate my costs? \n\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n\n\n\n\n\n Can I view and control my current usage? \n\nSee [View your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat-pricing"},{"document_id":"ibmcld_01623-6277-8255","score":21.8241203917,"text":"\nAfter you verify your identity, you set up and provide details for your authentication factor.\n\n\n\n\n\n Step 3: Estimate your costs \n\nComplete the following steps to get an estimate of how much your usage might cost:\n\n\n\n1. Go to the [catalog](https:\/\/cloud.ibm.com\/catalog), and select Services.\n2. Select a service that you're interested in.\n3. Select a pricing plan, enter other configuration details if needed, and click Add to estimate.\n\nBy default, the estimator shows the pricing and billing currency for your location. Pricing can vary by region. If you're estimating costs for a different location, select the correct region to view accurate pricing.\n4. Add the calculated cost to your estimate by clicking Save.\n5. When you're done adding products to your estimate, click Review estimate to a detailed view of your estimate.\n\nYou can download a CSV, XSLX, or PDF of the estimate by clicking Download.\n\n\n\n\n\n\n\n Step 4: Manage your invoices and payment methods \n\nBefore you start working with resources in your account, familiarize yourself with where you can manage your payment method and access your invoices.\n\n\n\n Managing your payment method \n\n\n\n* To manage your payment method for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Payments.\n* To manage your payment method for an account that's billed in non-USD currency, go to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).\n\n\n\n\n\n\n\n Accessing your invoices \n\n\n\n* To access an invoice for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices.\n* To access an invoice for an account that's billed in non-USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices. Then, click IBM Invoices.\n\n\n\n\n\n\n\n\n\n Step 5: Set preferences for receiving notifications \n\nComplete the following steps to set your preferences for receiving various types of notifications:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-started"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.8772153153,"ndcg_cut_10":0.8772153153}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12746-0-1760","score":31.925131346,"text":"\n\n\n\n\n\n\n  How does Security and Compliance Center calculate pricing? \n\nPricing for IBM Cloud\u00ae Security and Compliance Center is based on the number of evaluations performed. An evaluation is the check of one assessment against one resource.\n\nFor the most up-to-date pricing information, you can create a cost estimate by clicking Add to estimate from either the [provisioning](https:\/\/cloud.ibm.com\/security-compliance\/catalog) or [plan page](https:\/\/cloud.ibm.com\/security-compliance\/plan).\n\n\n\n  Plan types \n\nThe service offers two pricing plans.\n\nTrial\n:   To try out the service, you can enroll in a Trial period where you have access the full capabilities of the Posture Management component for 30 days at no charge. You can create profiles, set up credentials, and configure your account to evaluate your resources, among other things. Each account can have 1 instance of the trial service for the lifetime of the account.\n\nStandard\n:   With a Standard plan, you are able to access the full capabilities of the service without limitations. However, you are charged per evaluation.\n\n\n\n\n\n  When am I charged? \n\nYou are charged if an evaluation produces a result of pass or fail. You are not charged for the evaluation if the check cannot be performed or is not applicable. Each scan that is run provides you with the number of billable evaluations in the results UI.\n\n\n\n\n\n  How do I stop getting charged for Security and Compliance Center? \n\nYou are charged when an evaluation takes place. If you no longer want to be charged for a specific evaluation, stop the scan or scans that you do not want to be charged for from running by deleting your attachment. This does not remove your historical results, but it does stop future scans from being run.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-scc-pricing"},{"document_id":"ibmcld_02775-4830-5961","score":30.6107307062,"text":"\nFor a complete list of the options and setup information, see [Advanced password management](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strengthcd-advanced-password). \n\n\n\nThese features are available only to those instances that are on the graduated tier pricing plan and that were created after 15 March 2018.\n\n\n\n\n\n When am I charged? \n\nYour first 1000 authentication events and 1000 authorized users per service instance are free of charge. You are charged monthly for any additional authentication events and authorized users, as well as any advanced security features that are enabled for each service instance.\n\n\n\n\n\n How do I stop getting charged for App ID? \n\nIf you no longer want to be charged for authentication events and authorized users, you need to ensure that no user can authenticate by using App ID. You must remove the App ID configuration from your app code or confirm that your users are not able to use the configuration to log in to your app. To stop getting charged for advance security features, you must disable them on the Manage Authentication > Authentication Settings page of the service dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-pricing"},{"document_id":"ibmcld_08474-1435-3113","score":30.1530158013,"text":"\nOperational crypto unit 2 $1533.6 (30x24x2.13) \n Failover crypto unit 1 $1533.6 (30x24x2.13) \n Failover crypto unit 2 $1533.6 (30x24x2.13) \n 10 KMS key rings and 12 GREP11 keystores $3795 (5x0+15x225+2x210) \n Total charge $9929.4 \n\n\n\n\n\n\n\n How am I charged for my use of Hyper Protect Crypto Services with Unified Key Orchestrator? \n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. After you connect to an external keystore of any type, the Unified Key Orchestrator base price of $5.00 USD\/hour is charged.\n\nThe first 5 internal keystores and the very first external keystore are free of charge. Each additional internal or external keystore is charged with a tiered pricing starting at $225 USD or $70 USD per month, respectively. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https:\/\/cloud.ibm.com\/catalog\/services\/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units in the service instance, and creates 22 internal keystores and 15 external keystores. The first 5 internal keystores and the first external keystore are free of charge.\n\n\n\nTable 2. A Unified Key Orchestrator billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours) \n\n Operational crypto unit 1 $1533.6 (30x24x2.13) \n Operational crypto unit 2 $1533.6 (30x24x2.13) \n 22 internal keystores $3795 (5x0+15x225+2x210) \n 15 external keystores $980 (1x0+14x70) \n Unified Key Orchestrator connection $3600 (30x24x5.00) \n Total charge $11442.2","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricing"},{"document_id":"ibmcld_07578-1183252-1185036","score":29.858797021,"text":"\nThe user enables two operational crypto units and two failover crypto units for cross-region high availability. The user also creates 10 KMS keystores and 12 GREP11 keystores. The first five keystores, including both KMS key rings and GREP11 keystores, are free of charge.\n\n\n\nTable 1. A standard plan billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours) \n\n Operational crypto unit 1 $1533.6 (30x24x2.13) \n Operational crypto unit 2 $1533.6 (30x24x2.13) \n Failover crypto unit 1 $1533.6 (30x24x2.13) \n Failover crypto unit 2 $1533.6 (30x24x2.13) \n 10 KMS key rings and 12 GREP11 keystores $3795 (5x0+15x225+2x210) \n Total charge $9929.4 \n\n\n\n* How am I charged for my use of Hyper Protect Crypto Services with Unified Key Orchestrator?\n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. After you connect to an external keystore of any type, the Unified Key Orchestrator base price of $5.00 USD\/hour is charged.\n\nThe first 5 internal keystores and the very first external keystore are free of charge. Each additional internal or external keystore is charged with a tiered pricing starting at $225 USD or $70 USD per month, respectively. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https:\/\/cloud.ibm.com\/catalog\/services\/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units in the service instance, and creates 22 internal keystores and 15 external keystores. The first 5 internal keystores and the first external keystore are free of charge.\n\n\n\nTable 2. A Unified Key Orchestrator billing example of 30 days","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1185885-1187669","score":29.858797021,"text":"\nThe user enables two operational crypto units and two failover crypto units for cross-region high availability. The user also creates 10 KMS keystores and 12 GREP11 keystores. The first five keystores, including both KMS key rings and GREP11 keystores, are free of charge.\n\n\n\nTable 1. A standard plan billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours) \n\n Operational crypto unit 1 $1533.6 (30x24x2.13) \n Operational crypto unit 2 $1533.6 (30x24x2.13) \n Failover crypto unit 1 $1533.6 (30x24x2.13) \n Failover crypto unit 2 $1533.6 (30x24x2.13) \n 10 KMS key rings and 12 GREP11 keystores $3795 (5x0+15x225+2x210) \n Total charge $9929.4 \n\n\n\n* How am I charged for my use of Hyper Protect Crypto Services with Unified Key Orchestrator?\n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. After you connect to an external keystore of any type, the Unified Key Orchestrator base price of $5.00 USD\/hour is charged.\n\nThe first 5 internal keystores and the very first external keystore are free of charge. Each additional internal or external keystore is charged with a tiered pricing starting at $225 USD or $70 USD per month, respectively. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https:\/\/cloud.ibm.com\/catalog\/services\/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units in the service instance, and creates 22 internal keystores and 15 external keystores. The first 5 internal keystores and the first external keystore are free of charge.\n\n\n\nTable 2. A Unified Key Orchestrator billing example of 30 days","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_08671-108191-109525","score":28.932282498,"text":"\n[FAQs: Pricing](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricingfaq-pricing)\n\n\n\n* [How am I charged for my use of Hyper Protect Crypto Services standard plan?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricingfaq-how-charge-hpcs)\n* [How am I charged for my use of Hyper Protect Crypto Services with Unified Key Orchestrator?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricingfaq-how-charge-hpcs-uko)\n* [Is there a free trial for Hyper Protect Crypto Services?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricingfaq-free-trial)\n\n\n\n[FAQs: Provisioning and operations](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-provisioning-operationsfaq-provisioning-operations)\n\n\n\n* [Are there any prerequisites for using Hyper Protect Crypto Services?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-provisioning-operationsfaq-hpcs-prerequisites)\n* [How to initialize Hyper Protect Crypto Services service instances?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-provisioning-operationsfaq-how-to-initialize)\n* [Can I initialize my service instance through the TKE CLI plug-in by using a proxy?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-provisioning-operationsfaq-tke-proxy)\n* [Are there any recommendations on how to set up smart cards?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"},{"document_id":"ibmcld_08474-7-1664","score":28.2085420563,"text":"\nFAQs: Pricing \n\nRead to get answers for questions about IBM Cloud\u00ae Hyper Protect Crypto Services pricing.\n\n\n\n How am I charged for my use of Hyper Protect Crypto Services standard plan? \n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. If you also enable [failover crypto units](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-understand-conceptscrypto-unit-concept), each failover crypto unit is also charged the same as the operational crypto unit.\n\nThe first 5 keystores, including KMS key rings and EP11 keystores, are free of charge. Each additional key ring or EP11 keystore is charged with a tiered pricing starting at $225 USD per month. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https:\/\/cloud.ibm.com\/catalog\/services\/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units and two failover crypto units for cross-region high availability. The user also creates 10 KMS keystores and 12 GREP11 keystores. The first five keystores, including both KMS key rings and GREP11 keystores, are free of charge.\n\n\n\nTable 1. A standard plan billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours) \n\n Operational crypto unit 1 $1533.6 (30x24x2.13) \n Operational crypto unit 2 $1533.6 (30x24x2.13) \n Failover crypto unit 1 $1533.6 (30x24x2.13) \n Failover crypto unit 2 $1533.6 (30x24x2.13) \n 10 KMS key rings and 12 GREP11 keystores $3795 (5x0+15x225+2x210) \n Total charge $9929.4","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricing"},{"document_id":"ibmcld_03794-0-812","score":27.7596531495,"text":"\n\n\n\n\n\n\n  Why am I getting a charge limit error when I try to make a payment? \n\nYou can't make a full payment on your invoice because of a charge limit.\n\n  What\u2019s happening \n\nYou try to make a payment on an invoice that is over $1,000.00 USD, but you get the following error message:\n\n> Manual payment request cannot be processed. Payment amount is higher than the limit allowed.\n\n  Why it\u2019s happening \n\nBy default, credit card payments in US Dollars cannot exceed $1,000.00 USD, which might cause you to make multiple payments to pay your invoice.\n\n  How to fix it \n\nYou can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) to request an increase in this maximum credit card payment limit. All requests are considered based on the payment and invoice history of the account.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-charge-limit"},{"document_id":"ibmcld_08671-107301-108547","score":27.6615092489,"text":"\n(https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-what-do-with-hpcs)\n* [How do I know whether Hyper Protect Crypto Services is right for my company?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-choose-hs-crypto)\n* [How does Hyper Protect Crypto Services work?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-how-hpcs-work)\n* [What crypto card does Hyper Protect Crypto Services use?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-crypto-card)\n* [Which IBM regions are Hyper Protect Crypto Services available in?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-hpcs-regions)\n* [I have workloads in a data center where Hyper Protect Crypto Services is not available. Can I still subscribe to this service?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-basicsfaq-data-center)\n\n\n\n[FAQs: Pricing](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricingfaq-pricing)\n\n\n\n* [How am I charged for my use of Hyper Protect Crypto Services standard plan?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricingfaq-how-charge-hpcs)\n* [How am I charged for my use of Hyper Protect Crypto Services with Unified Key Orchestrator?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"},{"document_id":"ibmcld_02775-3372-5498","score":27.4930293607,"text":"\nYou incur an extra charge when you enable them. For example, if you obtain 10,000 access tokens, then you turn on password policy management and obtain 10,000 more. You would pay for 20,000 authentication events and 10,000 advanced security events. If you disable all the advanced features, your account reverts to the original-cost policy.\n\n\n\nTable 1. Description of the benefits that are gained with advanced authentication events\n\n Feature Benefit \n\n Multi-factor authentication With [MFA for Cloud Directory](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-mfacd-mfa), you can confirm a user\u2019s identity by requiring them to enter a one time passcode that is sent to their email or SMS after they enter their email and password. \n Runtime authentication activity tracking By integrating Activity Tracker with App ID, you can track different types of authentication events at run time. For example, a password reset request, authentication failures, or a user logout. For more information, see [Viewing runtime events](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-at-eventsat-monitor-runtime). \n Password policy management As an account owner, you can enforce more secure passwords for Cloud Directory by configuring a set of rules that user passwords must conform to. Examples include, the number of attempted sign-ins before lockout, expiration times, minimum time span between password updates, or the number of times that a password can't be repeated. For a complete list of the options and setup information, see [Advanced password management](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strengthcd-advanced-password). \n\n\n\nThese features are available only to those instances that are on the graduated tier pricing plan and that were created after 15 March 2018.\n\n\n\n\n\n When am I charged? \n\nYour first 1000 authentication events and 1000 authorized users per service instance are free of charge. You are charged monthly for any additional authentication events and authorized users, as well as any advanced security features that are enabled for each service instance.\n\n\n\n\n\n How do I stop getting charged for App ID?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-pricing"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03729-4932-7001","score":21.5160872192,"text":"\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges\n: You select a plan and pay on a flat rate basis. For example, the Bare Metal Servers are charged at a flat-rate.\n\nMetered charges\n: You pay based on your runtime and service consumption. For example, with the Push service, any usage over the free monthly allowance is charged.\n\nReserved charges\n: As the account owner of a Pay As You Go account or a Subscription account, you can reserve a service instance, with a long-term commitment, for a discounted price. For example, you can reserve the standard large Db2 on Cloud offering for 12 months.\n: Some IBM Cloud services offer reserved plans. You can request a reserved plan from the IBM Cloud catalog by clicking the tile of the service. Then, select the service plan that best meets your needs. If a reserved plan is available, click Request, and follow the prompts to send your request. You receive an email that contains the price information of the reserved plan. An IBM Cloud sales representative also contacts you soon to complete the purchase.\n\nTiered charges\n: Similar to metered charges, you pay based on your runtime and service consumption. However, tiered charges add more pricing tiers, often offering discounted charges in tiers with larger consumption. Tiered pricing is offered in simple, graduated, or block.\n\n\n\n Simple tier \n\nIn the simple tier model, the unit price is determined by the tier that the quantity of your usage falls into. The total price is your quantity that is multiplied by the unit price in that tier, for example:\n\n\n\nTable 2. Simple tier pricing table\n\n Quantity of Items Unit Price for All Items","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_05666-7-2151","score":20.5296870769,"text":"\nUnderstanding costs for your clusters \n\nWith IBM Cloud\u00ae, you can plan for, estimate, review, and modify your cluster environment to control costs. Just by using a managed service like IBM Cloud\u00ae Kubernetes Service, you are saving many expenses that are associated with managing, updating, and maintaining an infrastructure environment.\n\n\n\n Understanding costs by component \n\nWith IBM Cloud Kubernetes Service clusters, you can use IBM Cloud infrastructure compute, networking, and storage resources with platform services such as Watson AI or Compose Database-as-a-Service. Each resource might entail its own charges that can be [fixed, metered, tiered, or reserved](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargescharges) and billed by various incremental rates such as monthly or hourly.\n\nMonthly resources are billed based on the first of the month for usage in the preceding month. If you order a monthly resource in the middle of the month, you are charged a prorated amount for that month. However, if you cancel a resource in the middle of the month, you are still charged the full amount for the monthly resource.\n\n\n\n Worker nodes \n\nClusters can have two main types of worker nodes: virtual or physical (bare metal) machines. Flavor (machine type) availability and pricing varies by the zone that you deploy your cluster to.\n\nWhen do worker nodes begin to incur charges?**\n: Worker nodes begin to incur charges after they complete the provisioning state and continue until you delete the worker nodes and they complete the deleting state. For more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_10116-7-2157","score":20.4650377707,"text":"\nUnderstanding costs for your clusters \n\nWith IBM Cloud\u00ae, you can plan for, estimate, review, and modify your cluster environment to control costs. Just by using a managed service like Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae, you are saving many expenses that are associated with managing, updating, and maintaining an infrastructure environment.\n\n\n\n Understanding costs by component \n\nWith Red Hat OpenShift on IBM Cloud clusters, you can use IBM Cloud infrastructure compute, networking, and storage resources with platform services such as Watson AI or Compose Database-as-a-Service. Each resource might entail its own charges that can be [fixed, metered, tiered, or reserved](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargescharges) and billed by various incremental rates such as monthly or hourly.\n\nMonthly resources are billed based on the first of the month for usage in the preceding month. If you order a monthly resource in the middle of the month, you are charged a prorated amount for that month. However, if you cancel a resource in the middle of the month, you are still charged the full amount for the monthly resource.\n\n\n\n Worker nodes \n\nClusters can have two main types of worker nodes: virtual or physical (bare metal) machines. Flavor (machine type) availability and pricing varies by the zone that you deploy your cluster to.\n\nWhen do worker nodes begin to incur charges?**\n: Worker nodes begin to incur charges after they complete the provisioning state and continue until you delete the worker nodes and they complete the deleting state. For more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_01131-3050-4105","score":20.298661687,"text":"\nIf there is not enough unreserved storage to satisfy the topic operation, it is rejected with a PolicyViolation error that explains the reason.\n\nThe reserved size calculation can change in the future if Kafka storage requirements are updated.\n\n\n\n\n\n Examples \n\nA nonobvious effect is that Kafka can reserve more storage than expected depending on your topic configurations. See the following examples.\n\n\n\n1. A topic with retention.bytes of 1 GB, and with a log segment size of 512 MB:\n\nWith one partition, it would reserve about 1.5 GB of storage.\nIn this case, the reserved size is significantly larger than the retention size.\n2. A topic with retention.bytes of 50 GB, and with a log segment size of 512 MB:\n\nWith one partition, it would reserve about 50.5 GB of storage.\n\nIn this case, the reserved size is very close to the retention size.\n3. A topic with retention.bytes of 1 GB, and with a log segment size of 128 MB:\n\nWith one partition, it would reserve about 1.1 GB of storage.\n\nIn this case, the reserved size is very close to the retention size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-ES_understanding_reserved_disk_usage"},{"document_id":"ibmcld_14546-4405-6573","score":19.5600351228,"text":"\nThis value includes public outbound traffic. \n\n\n\n\n\n\n\n VMware Shared Solutions Reserved billing plan \n\nVMware Shared Solutions Reserved virtual data center resources are preallocated and guaranteed. Pricing is monthly based on the allocation size of the virtual data center.\n\nThe standard storage policy pricing is the same as the 4-IOPS\/GB storage policy. The number of IOPS\/GB for the standard storage policy is not guaranteed.\n\nStorage policy availability can vary by region and deployment topology. On the VMware Shared order page, select the About tab to view available storage policy offerings.\n\nGeneral metrics\n\nStorage metrics\n\nOperating system metrics\n\n\n\nTable 3. VMware Shared Solutions Reserved billing plan - General metrics\n\n Metric Frequency Description \n\n MAX_VCPU Monthly The peak vCPU allocation for the virtual data center over the period of one month. The peak vCPU metric is determined by the largest vCPU reservation value that is selected by the customer over a one month period. \n MAX_RAM_GB Monthly The peak memory allocation for the virtual data center over the period of one month. The peak vCPU metric is determined by the largest memory reservation value that is selected by the customer over a one month period. \n TOTAL_EGRESS_GB Usage The total outbound public traffic is charged per GB transferred over the period of one month. This value includes the outbound traffic through the virtual data center NSX edge to the public internet. \n\n\n\n\n\n\n\n Private network endpoint billing plan \n\nPrivate network endpoint usage incurs charges as part of the on-demand or reserved virtual data center plan. On the VMware Shared order page, select the About tab to view the pricing plan details.\n\n\n\nTable 4. Billing plan for private network endpoints\n\n Metric Frequency Description \n\n MAX_PRIVATE_NETWORK_ONE_G_COST Monthly Charge for private network endpoint at 1 GB uplink over a period of one month. \n MAX_PRIVATE_NETWORK_TEN_G_COST Monthly Charge for private network endpoint at 10 GB uplink over a period of one month. \n\n\n\n\n\n\n\n Licenses and fees for Veeam Availability Suite and Zerto \n\nVeeam\u00ae and Zerto usage incurs the following on-demand charges.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_pricing"},{"document_id":"ibmcld_03729-1672-3956","score":19.3225601343,"text":"\nServices For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged. \n Tiered In this pricing model, you get a volumed-based discount according to your actual usage. Tiered pricing is typically used for charge metrics that are expected to have high quantities per month, such as API calls. Services might offer simple, graduated, or block tier pricing plans. Services For API Connect, one of the tiered plans charges $10,000 for the first 25 million monthly API calls and $40.00 USD per 100,000 API calls per month thereafter. \n Reserved Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment. Services Db2 on Cloud has reserved plans. \n\n\n\n\n\n Understanding monthly and hourly tags \n\nOn the usage dashboard, your products and resources can be labeled with Monthly, Hourly, or a combination of both tags to signify how often charges are updated.\n\nThe Monthly tag signifies that resources within your account have a fixed cost. These charge show up immediately after purchase and are prorated in proportion to how many days are left in the month. Any recurring monthly fixed costs are then shown at the first of every month.\n\nThe Hourly tag signifies that resources within your account have variable costs. These resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_14007-0-1917","score":19.0905523112,"text":"\n\n\n\n\n\n\n  FAQs: Reserved capacity and instances \n\n\n\n  Which virtual server instance types can be reserved? \n\nOnly SAN-backed balanced, memory, and compute family sizes can be reserved.\n\n\n\n\n\n  Can I combine different CPUxRAM sizes or change the sizes later? \n\nYou cannot combine different CPUxRAM sizes or change the sizes later. The set of virtual server instances that you provision to your reserved capacity must be the same size as your reservation.\n\n\n\n\n\n  Is my payment upfront or monthly? \n\nReserved capacity and instances are purchased for a 1 or 3-year term. After that point, you're committed to a monthly payment.\n\n\n\n\n\n  What happens at the end of my contract? \n\nDepending on whether you choose hourly or monthly billing, the billing price for the CPU and RAM converts to the current list price, with any account discounts applied. Contact your sales representative, who in turn works with your global sales manager to determine end-of-contract options such as renewal or restructuring of your contract provisions. For more information about pricing, see [Build your virtual server](https:\/\/www.ibm.com\/cloud\/virtual-servers).\n\n\n\n\n\n  What happens if I don't need my reserved virtual server instances anymore? \n\nYou can reclaim reserved virtual server instances, but you cannot cancel reserved capacity.\n\n\n\n\n\n  Does the reservation include everything that I configured into my virtual server instance? \n\nOnly CPU and RAM are included in your reservation. Primary disk and no-additional charge network or storage products are not included in your reservation. More network bandwidth, storage capacity, OS, and third-party software are charged on an hourly or monthly basis, which depends on the instance type.\n\n\n\n\n\n  Why do I need to choose hourly or monthly billing on the virtual server instance? \n\nYour additional software, storage, and network selections need to be billed either hourly or monthly.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-faqs-reserved-capacity-and-instances"},{"document_id":"ibmcld_16252-10129-10965","score":18.952702221,"text":"\nAn Enterprise with Data Isolation plan instance must be provisioned for you first.\n* When you upgrade from a legacy Standard plan, you change the metrics that are used for billing purposes. Instead of basing billing on API usage, the Plus plan bases billing on the number of monthly active users. If you built a custom app to deploy your assistant, you might need to update the app. Ensure that the API calls from the app include user ID information. For more information, see [User-based plans explained](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-user-based).\n* You cannot change from a Trial plan to a Lite plan.\n\n\n\n\n\nFor answers to common questions about subscriptions, see the [How you're charged](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-plan"},{"document_id":"ibmcld_14537-7-2256","score":18.597945399,"text":"\nOrdering virtual data centers \n\nIBM Cloud\u00ae for VMware Solutions Shared offers either a standardized or customizable deployment option of VMware\u00ae virtual data center environments. Choose the On-demand or Reserved option.\n\n\n\n Requirements for virtual data centers \n\nIf you are ordering a virtual data center for the first time, ensure that you completed the tasks in the Before you begin section on the ordering page. For more information, see [Setting up your environment for your first order](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-completing_checklist).\n\n\n\n\n\n System settings \n\nYou must specify the following system settings when you order a VMware Shared virtual data center.\n\n\n\n Pricing plans \n\nThe pricing plan is based on your selection of On-demand or Reserved.\n\n\n\n On-demand \n\nFor the On-demand offering, virtual data center virtual CPU (vCPU) and RAM are allocated as needed. The amount of time that the allocation takes depends on global usage of the virtual data center vCPU and RAM.\n\n\n\n* The limits that are established for the amount of vCPU and RAM are maximum values that can be used at any time.\n* You can increase and decrease the vCPU and RAM resources on a virtual data center later as required.\n* The price is calculated hourly and it is based on the resource usage in the virtual data center.\n* The amount of storage that can be allocated and used in the virtual data center is limited to 200 TB for each storage policy. Charges are calculated per hour and are based on GB of allocated storage.\n* The amount of inbound and outbound public networking is unlimited. Public outbound bandwidth is charged per GB.\n\n\n\n\n\n\n\n Reserved \n\nFor the Reserved offering, the vCPU and RAM virtual data center reservations are pre-allocated and their availability is guaranteed.\n\n\n\n* The price is calculated monthly for the full reservation and it is based on the allocation size of the virtual data center.\n* vCPU and RAM resources can be increased and decreased later as required.\n* The amount of storage that can be allocated and used in the virtual data center is unlimited. Charges are calculated per hour and are based on GB of allocated storage.\n* The amount of inbound and outbound public networking is unlimited.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_ordering"},{"document_id":"ibmcld_07578-335595-337885","score":18.3834732967,"text":"\nEach device has a unique SSH key, so the key for the newly provisioned or reloaded device is different from the image. However, SSH keys that are associated with either a Flex Image or a standard image templates are associated with the device when it is provisioned or reloaded. You can also add keys during the setup process.\n* Which virtual server instance types can be reserved?\n\nOnly SAN-backed balanced, memory, and compute family sizes can be reserved.\n* Can I combine different CPUxRAM sizes or change the sizes later?\n\nYou cannot combine different CPUxRAM sizes or change the sizes later. The set of virtual server instances that you provision to your reserved capacity must be the same size as your reservation.\n* Is my payment upfront or monthly?\n\nReserved capacity and instances are purchased for a 1 or 3-year term. After that point, you're committed to a monthly payment.\n* What happens at the end of my contract?\n\nDepending on whether you choose hourly or monthly billing, the billing price for the CPU and RAM converts to the current list price, with any account discounts applied. Contact your sales representative, who in turn works with your global sales manager to determine end-of-contract options such as renewal or restructuring of your contract provisions. For more information about pricing, see [Build your virtual server](https:\/\/www.ibm.com\/cloud\/virtual-servers).\n* What happens if I don't need my reserved virtual server instances anymore?\n\nYou can reclaim reserved virtual server instances, but you cannot cancel reserved capacity.\n* Does the reservation include everything that I configured into my virtual server instance?\n\nOnly CPU and RAM are included in your reservation. Primary disk and no-additional charge network or storage products are not included in your reservation. More network bandwidth, storage capacity, OS, and third-party software are charged on an hourly or monthly basis, which depends on the instance type.\n* Why do I need to choose hourly or monthly billing on the virtual server instance?\n\nYour additional software, storage, and network selections need to be billed either hourly or monthly.\n* What types of virtual servers are available for use?\n\nIBM Cloud\u00ae offers a couple types of virtual servers within its Classic Infrastructure.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.636439181}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02665-3418-5653","score":27.8024090898,"text":"\nFor server-side entities like microservices, when the state of a feature flag or property changes in the App Configuration, a websocket connection notifies the SDK in the microservice that a state change occurred. The microservice then calls back into the App Configuration to retrieve the update. This action is an API call.\n\nAn API call also occurs on startup to the retrieve the initial configuration state. For client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n\n\n\n\n\n How to view usage metrics for App Configuration? \n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https:\/\/cloud.ibm.com\/billing\/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console.\n\n\n\n\n\n How to predict App Configuration cost? \n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage"},{"document_id":"ibmcld_03776-5228-7163","score":27.4047862098,"text":"\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_12815-5234-7392","score":26.7326670216,"text":"\nFirst, add the Export Control Classification Number and the United Nations Standard Products and Services Code that applies to your product. Next, define your pricing plan. Currently, you can choose a free or usage-based pricing plan. If you\u2019d like, you can add multiple plans for your product. [Click Pricing then click Add ECCN to add your Export Control Classification Number. Click Add UNSPSC to add the United Nations Standard Products and Services Code for your product. Click Add plan, select the plan type, add a name, select how resource instances should be deployed, and click Save.]\n\nFor usage-based plans, you must submit your tax and EFT information to set up and receive payment disbursements for usage. You\u2019ll also want to add metrics to determine how customers are charged, and submit your updates for approval. [The Payments to me page is highlighted. Click Add metrics to add your metrics to the pricing plan. In the Metering approval section, click Request approval.]\n\nBuilding one or more service brokers is needed to manage the lifecycle of your service and metering integration. A broker must be added to complete your pricing plan. Your technical team member can get started with our sample broker. Add your broker by entering a name, a URL, a username, and a password. Or, you can import brokers from your account. After you add your broker, link it to your pricing plan. [Click Brokers. In the Onboard brokers to IBM Cloud section, click OK to open the sample reference broker. Click Add broker to add your broker. Click Pricing, click the actions icon for your pricing plan, and click Edit plan to link your broker to your pricing plan.]\n\nNow that you\u2019ve defined your pricing model, review how customers would understand and experience it. After your metering updates are approved, validate that your metered plans are correctly configured by enabling and submitting a usage test. This usage test includes creating your metering JSON, calling the Usage Metering API, and submitting metering evidence. [Click Add metrics for the pricing plan you added. Click Test estimation and metering to submit your metering evidence for review.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-get-started"},{"document_id":"ibmcld_08067-0-1736","score":26.690244615,"text":"\n\n\n\n\n\n\n  Viewing your support costs \n\nIf you have Advanced or Premium support, you can keep track of your monthly support costs from the Support costs page in the IBM Cloud\u00ae console.\n\n\n\n  How you're charged for support \n\nEach [IBM Cloud support plan](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans) has a minimum monthly price for providing support for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost. For details about your purchased support plan, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n  Viewing support costs \n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n\nIn the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. You can view your support plan and relevant cost details:\n\n\n\n*  If your support costs are billed monthly, you can view your costs for the current month. These costs include the starting price for the plan and any additional costs from your resource usage. After each billing cycle, these charges are added to your monthly invoice.\n*  If you have a support subscription, you can view the remaining credit in your active subscriptions and any overages for the current month. Overage is charged if you run out of credit in your active subscriptions. You can also view upcoming support subscriptions, which are subscriptions that you bought but are not yet valid.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support"},{"document_id":"ibmcld_07578-506456-508701","score":26.2338120446,"text":"\nFor client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n* How to view usage metrics for App Configuration?\n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https:\/\/cloud.ibm.com\/billing\/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console.\n* How to predict App Configuration cost?\n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-506398-508643","score":26.2338120446,"text":"\nFor client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n* How to view usage metrics for App Configuration?\n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https:\/\/cloud.ibm.com\/billing\/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console.\n* How to predict App Configuration cost?\n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_02665-5090-7240","score":25.6755403438,"text":"\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID. You are not charged for entities that do not call App Configuration during the month. If your pricing plan includes a free allotment of Active Entity IDs, then you are not charged until the allotment is exceeded.\n\nActive Entity ID cost can be difficult to predict so you need to closely monitor your historical activity. See [How to view usage metrics for App Configuration?](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usagefaq-ac-metrics) Rely on your own domain knowledge, business metrics, and usage forecasts to predict Active Entity ID cost.\n\nThe API Call cost is based on the number of API calls sent or received by App Configuration during the month over all your entities combined. Check section - [What are the charges to use App Configuration?](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usagefaq-ac-charges) to determine what constitutes an API call.\n\nIf your pricing plan includes a free allotment of API calls, then you are not charged until the allotment is exceeded. Closely monitor your historical activity and check out [How to view usage metrics for App Configuration?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage"},{"document_id":"ibmcld_12850-1472-3281","score":25.4837948824,"text":"\n[Enter the United Nations Standard Products and Services Code (UNSPSC)](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-service-pricing-infoservice-unspsc)\n4. [Add a paid pricing plan](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-service-pricing-infoadd-plan-paid)\n5. [Confirm the digital platform reseller agreement](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-service-pricing-infodra)\n\n\n\n\n\n\n\n Adding metrics to your pricing plan \n\nIf you offer a paid integrated product and add a paid pricing plan that requires customers to pay for their usage, you must add metrics to your pricing plan to aggregate your product's usage. After you add metrics to your plan, you must request an initial metering approval, so you can submit your resource usage and start reviewing your metrics.\n\nTo add metrics to your pricing plan, complete the following steps:\n\n\n\n1. In the IBM Cloud console, click the Navigation Menu icon ![Navigation Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ff5860bfede49db3197c4bbba7f7123769bdc068\/icons\/icon_hamburger.svg) > Partner Center > Sell > My products.\n2. Select the product that you're onboarding, and click Pricing.\n3. Select a usage-based plan from the table and click Add metrics.\n4. In the Usage metrics section, click Add metrics.\n5. Complete the required fields.\n6. Click Done.\n7. To submit your pricing plan and metering for review, click Request approval in the Metering approval section.\n\n\n\n\n\n\n\n Submitting resource usage to the IBM Cloud Usage Metering API \n\nTo review how customers understand and experience your pricing plan, and validate that your metered plans are correctly configured, you must submit your resource usage. Submitting your resource usage includes creating your metering JSON, calling the Usage Metering API, and providing the evidence of your testing.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-submitusage"},{"document_id":"ibmcld_03729-1672-3956","score":25.2360060344,"text":"\nServices For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged. \n Tiered In this pricing model, you get a volumed-based discount according to your actual usage. Tiered pricing is typically used for charge metrics that are expected to have high quantities per month, such as API calls. Services might offer simple, graduated, or block tier pricing plans. Services For API Connect, one of the tiered plans charges $10,000 for the first 25 million monthly API calls and $40.00 USD per 100,000 API calls per month thereafter. \n Reserved Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment. Services Db2 on Cloud has reserved plans. \n\n\n\n\n\n Understanding monthly and hourly tags \n\nOn the usage dashboard, your products and resources can be labeled with Monthly, Hourly, or a combination of both tags to signify how often charges are updated.\n\nThe Monthly tag signifies that resources within your account have a fixed cost. These charge show up immediately after purchase and are prorated in proportion to how many days are left in the month. Any recurring monthly fixed costs are then shown at the first of every month.\n\nThe Hourly tag signifies that resources within your account have variable costs. These resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_12918-3224-4645","score":25.2303554059,"text":"\nUse the slider to select the number of blocks of provisioned throughput capacity based on the maximum limit of either reads per second, writes per second, or global queries per second as required for your application. For example, if your application requires 1,000 reads per second, use the slider to select the capacity that offers 1,000 reads per second, 500 writes per second, and 50 global queries per second. Select this capacity even if you don't need the corresponding number of writes or global queries.\n\n\n\n\n\n Data usage pricing \n\nWhat about pricing for data overage? How does that work?\n\n\n\nTable 1. Pricing for data overage\n\n Plan Storage included Overage limit \n\n Lite 1 GB Your account is blocked from writing new data until you delete enough data to be under the 1-GB limit, or upgrade to a higher plan. \n Standard 20 GB Extra storage costs charged per GB per hour, for each GB over the included 20 GB. \n\n\n\n\n\n\n\n IBM Cloud Usage Dashboard \n\nHow does data populate the IBM Cloud Usage Dashboard?\n\nCurrent and historical usage bills can be seen in the IBM Cloud Dashboard, under Manage > Billing and usage > Usage. This view shows the totals for usage that are accrued during a particular month at the service, plan, or instance level. The Estimated Total reflects the bill so far for the month or for past complete months. It shows only the hourly costs that are accrued up to that point for the current month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-pricing"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05428-7-1872","score":30.0295782624,"text":"\nPricing for Code Engine \n\nIBM Cloud\u00ae Code Engine is different from traditional cloud computing technologies, you pay for only the resources that you use. You are billed for the memory and vCPU that your workloads consume, as well as any incoming HTTP calls. If your app scales to zero or your job or build isn't running, you are not consuming resources and so you are not charged.\n\nCode Engine includes a free tier so that you can experiment with Code Engine before you commit.\n\nYou are billed for the following entities,\n\n\n\n* [Applications](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-pricingapp-pricing)\n* [Job runs](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-pricingjob-pricing)\n* [Build runs](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-pricingbuild-pricing)\n\n\n\nEntities such as [projects](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-manage-project) do not incur charges, but instead serve as a folder for your entities. Entities such as secrets, bindings, or subscriptions do not incur charges, but do contribute to the overall limits of your project. For more information, see [Limits and quotas for Code Engine](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-limits).\n\nThe costs that are provided in this topic are guidelines and do not represent actual costs. They represent a starting point for estimates of costs that are incurred in environments with a similar configuration. Actual costs can vary by geography. For the most up-to-date prices, see [Code Engine pricing](https:\/\/www.ibm.com\/cloud\/code-engine\/pricing).\n\n\n\n Application pricing \n\nWhen you deploy an application, charges apply for HTTP requests and for the CPU and memory resources that are consumed by running instances of the application. Incoming HTTP calls are billed by the number of HTTP calls that are received by your application.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-pricing"},{"document_id":"ibmcld_11857-7-2422","score":29.5827266462,"text":"\nPricing \n\nIBM Cloud Satellite provides a convenient way for you to consume IBM Cloud services in any location that you want, with visibility across your locations.\n\nFlexible consumption\n: No charges are incurred for hosts that are attached to a location, but not assigned to a resource. You can have as many hosts waiting in your location without being charged for future growth. As soon as you unassign a host from a resource, you are no longer charged for that host. Keep in mind that hosts might be automatically assigned to services, depending on your setup.\n\nApplication and networking capabilities at no additional charge\n: You do not have separate charges for Satellite management capabilities for the locations, hosts, such as endpoints, configuration versions and subscriptions, or other Satellite resources.\n\n\n\n Satellite locations \n\nReview the following table for pricing details. For more information, see the detailed [Pricing model](https:\/\/cloud.ibm.com\/satellite\/overview)\n\n\n\nSatellite location control plane charges.\n\n Type of charge Locations created after 15 November 2022 Locations created before 15 November 2022 What the charge covers \n\n Location management fee A flat monthly fee for the location, charged hourly. Per vCPU hour of the hosts that are attached to the location. The benefits of IBM Cloud Satellite, such as to create the cluster on any compatible infrastructure that you want; tooling to consistently deploy apps, storage drivers, and endpoints across the location; integration with IBM Cloud platform tooling such as IAM; continuous monitoring by IBM Site Reliability Engineers; access to IBM Cloud support; and more. \n Infrastructure fee Varies by provider Varies by provider The underlying infrastructure that you bring to Satellite is your own, and might have its own charges. Consult your infrastructure provider for more details, such as about the storage, compute, and networking of the hosts in a cloud or on-prem environment. \n\n\n\n\n\n\n\n Satellite-enabled IBM Cloud services \n\nEach IBM Cloud service instance that you create in your Satellite location incurs charges. For more information, see [Supported Satellite-enabled IBM Cloud services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-managed-services).\n\n\n\n\n\n Can I estimate my costs? \n\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat-pricing"},{"document_id":"ibmcld_11857-1988-2975","score":29.2871519624,"text":"\nSatellite-enabled IBM Cloud services \n\nEach IBM Cloud service instance that you create in your Satellite location incurs charges. For more information, see [Supported Satellite-enabled IBM Cloud services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-managed-services).\n\n\n\n\n\n Can I estimate my costs? \n\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n\n\n\n\n\n Can I view and control my current usage? \n\nSee [View your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat-pricing"},{"document_id":"ibmcld_05666-7-2151","score":28.7517515173,"text":"\nUnderstanding costs for your clusters \n\nWith IBM Cloud\u00ae, you can plan for, estimate, review, and modify your cluster environment to control costs. Just by using a managed service like IBM Cloud\u00ae Kubernetes Service, you are saving many expenses that are associated with managing, updating, and maintaining an infrastructure environment.\n\n\n\n Understanding costs by component \n\nWith IBM Cloud Kubernetes Service clusters, you can use IBM Cloud infrastructure compute, networking, and storage resources with platform services such as Watson AI or Compose Database-as-a-Service. Each resource might entail its own charges that can be [fixed, metered, tiered, or reserved](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargescharges) and billed by various incremental rates such as monthly or hourly.\n\nMonthly resources are billed based on the first of the month for usage in the preceding month. If you order a monthly resource in the middle of the month, you are charged a prorated amount for that month. However, if you cancel a resource in the middle of the month, you are still charged the full amount for the monthly resource.\n\n\n\n Worker nodes \n\nClusters can have two main types of worker nodes: virtual or physical (bare metal) machines. Flavor (machine type) availability and pricing varies by the zone that you deploy your cluster to.\n\nWhen do worker nodes begin to incur charges?**\n: Worker nodes begin to incur charges after they complete the provisioning state and continue until you delete the worker nodes and they complete the deleting state. For more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_10116-7-2157","score":28.6886393155,"text":"\nUnderstanding costs for your clusters \n\nWith IBM Cloud\u00ae, you can plan for, estimate, review, and modify your cluster environment to control costs. Just by using a managed service like Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae, you are saving many expenses that are associated with managing, updating, and maintaining an infrastructure environment.\n\n\n\n Understanding costs by component \n\nWith Red Hat OpenShift on IBM Cloud clusters, you can use IBM Cloud infrastructure compute, networking, and storage resources with platform services such as Watson AI or Compose Database-as-a-Service. Each resource might entail its own charges that can be [fixed, metered, tiered, or reserved](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargescharges) and billed by various incremental rates such as monthly or hourly.\n\nMonthly resources are billed based on the first of the month for usage in the preceding month. If you order a monthly resource in the middle of the month, you are charged a prorated amount for that month. However, if you cancel a resource in the middle of the month, you are still charged the full amount for the monthly resource.\n\n\n\n Worker nodes \n\nClusters can have two main types of worker nodes: virtual or physical (bare metal) machines. Flavor (machine type) availability and pricing varies by the zone that you deploy your cluster to.\n\nWhen do worker nodes begin to incur charges?**\n: Worker nodes begin to incur charges after they complete the provisioning state and continue until you delete the worker nodes and they complete the deleting state. For more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_11483-1714-3878","score":27.8757361776,"text":"\nThe time your job takes (and therefore, its cost) depends on how many iterations you make in a session and how many shots are run in each iteration. Thus, you can manage your cost by running only as many iterations and shots as you need.\n\nAdditionally, an instance administrator can limit how much is spent. To set cost limits, navigate to the [IBM Cloud Instances page](https:\/\/cloud.ibm.com\/quantum\/instances) then click the instance and set the Cost limit.\n\nThe instance's cost limit refers to the total cost of all jobs run with this instance since it was created, and it will always be greater than or equal to the Total cost. After the instance reaches the specified limit, no further jobs can be run and no more cost is incurred.\n\nThe cost limit is always specified in US dollars (USD), then converted to runtime seconds. However, for monthly billing purposes, you are charged in your local currency, specified on your IBM Cloud account. Because currency exchange rates can fluctuate, the cost for X runtime seconds might be different when initially calculated in USD than when you're actually charged in your local currency. As a result, if your local currency is not USD, the total amount charged for the number of seconds specified in this field could vary from the dollar amount you specify.\n\n\n\n\n\n How to remove a cost limit \n\nAn instance administrator can remove the cost limit. To do so, navigate to the [IBM Cloud Instances page](https:\/\/cloud.ibm.com\/quantum\/instances), then open the instance and click the edit button by the Cost limit. Delete the value and click Save.\n\n\n\n What happens when the cost limit is reached \n\nWhen the instance's cost limit is reached, the currently running job is stopped. Its status is set to Cancelled with a reason of Ran too long. Any available partial results are kept.\n\nNo further jobs can be submitted by using this instance until the cost limit is increased.\n\n\n\n\n\n\n\n How to see what you're being charged \n\nYou are sent a monthly invoice that provides details about your resource charges. You can check how much has been spent at any time on the [IBM Cloud Billing and usage page](https:\/\/cloud.ibm.com\/billing).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cost"},{"document_id":"ibmcld_14546-6172-8106","score":27.6041592547,"text":"\nMetric Frequency Description \n\n MAX_PRIVATE_NETWORK_ONE_G_COST Monthly Charge for private network endpoint at 1 GB uplink over a period of one month. \n MAX_PRIVATE_NETWORK_TEN_G_COST Monthly Charge for private network endpoint at 10 GB uplink over a period of one month. \n\n\n\n\n\n\n\n Licenses and fees for Veeam Availability Suite and Zerto \n\nVeeam\u00ae and Zerto usage incurs the following on-demand charges. You can view the charges on the IBM Cloud billing and usage view along with the usage and charges from all other IBM Cloud services.\n\nIn the IBM Cloud Usage view, locate the VMware Solutions service type. Locate the Organization plan to find the Veeam and Zerto usage across all virtual data centers in that organization. The virtual data center usage is located in a separate plan for either VMware Shared on-demand or VMware Shared Reserved.\n\nVeeam\n\nZerto\n\n\n\nTable 5. Licenses and fees for Veeam\n\n Metric Frequency Description \n\n MAX_VEEAM_LICENSES Monthly Veeam license charge for every VM under backup. The monthly charge is for the highest number of VMs under backup at any time period in the month. \n TOTAL_VEEAM_BLOCK_STORAGE_GB_HOURS Hourly Charge per GB of block storage used for all backups. \n TOTAL_VEEAM_OBJECT_STORAGE_GB_HOURS Hourly Charge per GB of object storage used for all backups. \n\n\n\nNo additional Veeam or Zerto usage charges for VMware Shared are incurred.\n\nFor the Veeam service, initially, all backups go to the block storage that is closest to their VM workloads. Backups that are a part of an inactive backup chain are immediately moved to Cloud Object Storage. The restore speed for these inactive backups might be impacted.\n\nYou can change how fast the inactive backup chains are moved to Cloud Object Storage by opening an IBM Cloud for VMware Solutions service ticket.\n\n\n\n\n\n Related links \n\n\n\n* [VMware Shared overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_pricing"},{"document_id":"ibmcld_09275-35999-37614","score":26.7524398952,"text":"\n[Checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f61dbc5d84bf0c89e477a05cab04c72f429e1b7a\/log-analysis\/images\/checkmark-icon.svg) ![Checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f61dbc5d84bf0c89e477a05cab04c72f429e1b7a\/log-analysis\/images\/checkmark-icon.svg) ![Checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f61dbc5d84bf0c89e477a05cab04c72f429e1b7a\/log-analysis\/images\/checkmark-icon.svg) \n Long-term retention policy NO NO NO NO \n\n\n\n[7]: Standard is used for active workloads. No charge incurs for data that is retrieved (other than the cost of the operational request itself and public outbound bandwidth).\n\n[8]: Vault is used for cool workloads where data isn't accessed frequently, but a retrieval charge applies for reading data. The service includes a threshold for object size and storage period consistent with the intended use of this service for cooler, less-active data.\n\n[9]: Cold Vault is used for cold workloads where data is primarily archived (accessed every 90 days or less) - a larger retrieval charge applies for reading data. The service includes a threshold for object size and storage period consistent with the intended use of this service: storing cold, inactive data.\n\n[10]: Flex is used for dynamic workloads where access patterns are more difficult to predict. Depending on usage, if the cost of cooler storage that is combined with retrieval charges exceeds a cap value, then the storage charge increases and no any retrieval charges apply. If the data isn't accessed frequently, Flex storage can be more cost effective than Standard storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-adoption"},{"document_id":"ibmcld_12610-10871-13073","score":26.6623442443,"text":"\nSecrets Manager can also be used to store API keys that are used to authorize a project to deploy resources into an account, although there are other options too. For more information, see [Using an API key or secret to authorize a project to deploy an architecture](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-authorize-project).\n\n\n\n\n\n Project costs \n\nWhile there is no charge for a project, there can be costs for any resources created by a deployable architecture. These resources are billed as normal within IBM Cloud. As you customize the configuration for your deployable architecture, a starting cost is estimated based on the available data. For more information about project cost estimation, see [Cost estimation](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-cost-estimate-project).\n\nYou're not charged while customizing a deployable architecture. You begin to incur charges after it is deployed.\n\n\n\n\n\n Needs attention items \n\nProjects monitor configurations by checking to ensure that it passes various automated tests, receives approval, and is updated when new versions are available from the catalog. When the project needs attention from the user for one of these reasons, the key operational information is displayed on the project dashboard as a needs attention item. For more information on how to address each type of needs attention notification, see [Viewing needs attention items](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-needs-attention-projects).\n\nProjects support sending the needs attention notifications to the IBM Cloud\u00ae Event Notifications service, allowing them to be filtered and routed as wanted to Slack, email, and other systems.\n\n\n\n\n\n\n\n Getting started with projects \n\nNow that you've learned about the basics of a project, check out how to [Configure and deploy a deployable architecture](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-config-project) to start building and review the [Enterprise account architecture](https:\/\/cloud.ibm.com\/docs\/enterprise-account-architecture) white paper to ensure that your account is set up according to IBM Cloud best practices.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-understanding-projects"},{"document_id":"ibmcld_07079-4689-6411","score":26.4531852711,"text":"\nAdvanced rules models are not counted as custom models.\n\nDiscovery entity extractor models that are trained and published as an enrichment count toward the model limit for the plan. The entity extractor enrichment is what incurs charges, not the workspace or model. The entity extractor enrichment incurs charges whether or not it is applied to a collection.\n\n\n\n\n\n Premium \n\nPremium plans offer developers and organizations a single tenant instance of one or more Watson services for better isolation and security. These plans offer compute-level isolation on the existing shared platform, as well as end-to-end encrypted data while in transit and at rest.\n\nFor more information, or to purchase a Premium plan, contact [Sales](https:\/\/ibm.biz\/contact-wdc-premium).\n\n\n\n\n\n Other plans \n\nFeatures and limitations are similar between instances that you deploy on installed deployments in IBM Cloud Pak for Data and Premium plan instances that are managed by IBM Cloud.\n\n\n\n\n\n Additional information \n\n\n\n* For more information about how queries are counted, see [Query limits](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-conceptsquery-limits).\n* For more information about pricing or to create a service instance, see the [IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog\/services\/watson-discovery).\n\n\n\nIBM Cloud resources:\n\n\n\n* [How you're charged](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges).\n* [IBM Cloud Cost estimator](https:\/\/cloud.ibm.com\/estimator\/review)\n* [IBM Cloud Services terms](https:\/\/www-03.ibm.com\/software\/sla\/sladb.nsf\/sla\/saas?OpenDocument)\n* For more information about IBM Cloud security, see [IBM terms](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-pricing-plans"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03765-5710-7263","score":23.4001309487,"text":"\nClick Manual Payment and complete the fields in the one-time payment section. One-time payments are reviewed and processed each day. The account balance is updated after the payment is accepted. If a late fee is assessed and you have submitted a one-time payment, contact the [IBM Cloud Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n\n\n Managing your payment method outside of the console \n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/) and log in with your IBMid and password. You are also required to enter the temporary passcode that's emailed to you.\n\nTo add a payment method, complete the following steps:\n\n\n\n1. Go to [ibm.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your payment information, and click Register. A temporary passcode is emailed to you after the registration process is complete.\n\n\n\nAfter you register a payment method, when you click Manage payment method, you can view the Manage my wallet page to update or delete your payment methods by clicking the Edit icon ![Edit icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/edit-tagging.svg).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage"},{"document_id":"ibmcld_07578-1044428-1046278","score":23.3239962646,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1044299-1046149","score":23.3239962646,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03704-3030-4892","score":23.2454734991,"text":"\nIn the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n\n\n\n\n\n How do I change my payment method? \n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n\n\n\n\n\n Why didn't my credit card process? \n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_03765-4100-6125","score":22.9328807279,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n2. Click Payment method.\n3. In the Add Payment Method section, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\n\n\nSome payment methods aren't accepted as recurring payment methods. You must manually submit the payment each month.\n\n\n\n\n\n India-based customers with accounts that are billed in US Dollars \n\nDue to current banking regulations, recurring credit card transactions might be unsuccessful for India-based customers with accounts that are billed in US Dollars. You can use one of the following methods to make a payment:\n\n\n\n* [Make a one-time payment](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagemakepayment)\n* Request to migrate your account to be billed in India Rupees. To make a request, provide a credit card that is billed in India Rupees on the [Payment Method](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. Specify that India Rupees are in the Payment Currency section. Additional information might be requested through a Support case during the migration process.\n\n\n\n\n\n\n\n Making a one-time payment \n\nYou can use a credit card to make a one-time payment at any time for any amount, whether it's for the full balance or a partial sum. The details that you enter for the one-time payment aren't recorded for future use, and aren't populated with a default amount.\n\nTo make a one-time payment, in the IBM Cloud console, go to Manage > Billing and usage, and select Payments. Click Manual Payment and complete the fields in the one-time payment section. One-time payments are reviewed and processed each day. The account balance is updated after the payment is accepted. If a late fee is assessed and you have submitted a one-time payment, contact the [IBM Cloud Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n\n\n Managing your payment method outside of the console","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage"},{"document_id":"ibmcld_03713-6236-8279","score":22.6392200814,"text":"\nFor more information, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> There was an error in the payment process: We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is the transaction already processed? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Transaction already processed.\n\n Why it\u2019s happening \n\nOur payment system has detected multiple similar payments within a short period of time. IBM Cloud is attempting to avoid unintentional duplicate payments.\n\n How to fix it \n\nWait 3-4 hours for the manual payment to be processed and posted to your IBM Cloud} account. Verify your account balance on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n\n\n\n\n Why can't I upgrade my account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your account couldn't be upgraded. Click Upgrade account to try again.\n\n Why it\u2019s happening \n\nIBM Cloud} was unable to process your transaction.\n\n How to fix it \n\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03765-2725-4571","score":22.3231889922,"text":"\n[Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Set as default.\n2. Confirm that you want to make this payment method the default. The default payment method is charged for recurring payments\n\n\n\n\n\n\n\n Managing payment methods for all other accounts \n\nThe steps to update your credit card apply to the following types of accounts:\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n2. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nAmerican Express can't be used as a payment method for India, Singapore, and South Africa based accounts that are billed in US dollars.\n\n\n\n Updating your payment methods \n\nIf you're using a payment method that's not a credit card, complete the following steps to switch to your payment method:\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n2. Click Payment method.\n3. In the Add Payment Method section, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\n\n\nSome payment methods aren't accepted as recurring payment methods. You must manually submit the payment each month.\n\n\n\n\n\n India-based customers with accounts that are billed in US Dollars","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage"},{"document_id":"ibmcld_03776-5228-7163","score":21.5897613764,"text":"\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_03793-7-1857","score":21.1757854954,"text":"\nHow do I add a credit card when the option isn't available through the console? \n\nIf your payments are managed outside of the console, you can't use [Billing and usage](https:\/\/cloud.ibm.com\/billing) to add a credit card.\n\n What\u2019s happening \n\nYou want to enter a credit card to pay for IBM Cloud services, but the option doesn't appear.\n\nWhen you try to enter your credit card information, you see the following message:\n\nYour payments are managed through IBM.com. To view your payments and maintain your billing, you can visit the IBM.com portal which contains everything for your IBMid account.\n\nYou click Explore to access the ibm.com website, but you don't see a location to enter your credit card information.\n\n Why it\u2019s happening \n\nCredit card transactions are securely processed through the IBM Cloud console. However, in some countries, extra steps are taken to ensure the integrity of the credit card data. Those credit card requests are completed through the IBM.com website. Both methods ensure that your credit card information is securely processed.\n\n How to fix it \n\nTo provide your credit card information for payment, complete the following steps:\n\n\n\n1. Go to [IBM.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your credit card information, and click Register.\n\n\n\nThe information is verified and added to your IBM Cloud account as your payment method for any charges.\n\nTo replace an existing credit card, complete the following steps:\n\n\n\n1. Go to [ibm.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm"},{"document_id":"ibmcld_03704-4411-6289","score":21.0228386139,"text":"\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https:\/\/cloud.ibm.com\/unifiedsupport\/cases) page in the IBM Cloud console to view the status of your request.\n\n\n\n\n\n Can I delete my credit card? \n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n\n\n How do I change the invoice currency from US Dollars to my local currency? \n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.156426242}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03764-2220-3440","score":22.5676491681,"text":"\n[Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) and select the invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet.\n\n\n\n\n\n Is paperless invoicing available? \n\nYes, you can switch to paperless invoices by submitting a request on the [IBM Customer Support site](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/selectcountrylang.html). For more information, see [Requesting paperless invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesrequest-paperless-invoices).\n\n\n\n\n\n What are the adjustments that are shown on my invoice? \n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n\n\n\n\n\n How do I know if my invoice is paid? \n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-invoice-faq"},{"document_id":"ibmcld_07578-1065299-1067188","score":22.2911750287,"text":"\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1066874-1068548","score":22.2386893816,"text":"\n[Download icon](https:\/\/cloud.ibm.com\/icons\/download.svg) and choose an invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet. In some cases, you are redirected to the [IBM Invoices website](https:\/\/www.ibm.com\/invoices) where you can download your invoices. From the Invoices page, click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/icons\/action-menu-icon.svg) and select the invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet.\n* Is paperless invoicing available?\n\nYes, you can switch to paperless invoices by submitting a request on the [IBM Customer Support site](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/selectcountrylang.html). For more information, see [Requesting paperless invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesrequest-paperless-invoices).\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03771-1594-3365","score":21.6391137029,"text":"\nThe charges on your invoice are consistent with the usage dashboard. On the Invoices page in the console, click View usage to be directed to your usage dashboard. From there, you can select a timeframe and view billing and usage information that aligns directly with the details in your invoice.\n\n\n\n Checking your invoice status \n\nYou can check the status of your invoice on the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices):\n\n\n\n* Invoiced: You received the latest invoice from IBM Cloud.\n* Paid: Your payment for the charges on your latest invoice was received.\n* Unpaid: The charges on your latest invoice have not been paid.\n* Pending: Your payment for your latest charges has not been applied due to a payment processing error. In this case, you can contact IBM Cloud Support for more details about the error.\n\n\n\nTurning a resource \"off\" doesn't cancel the resource in your account. You will receive invoices for resources in your account until you cancel them. For more information, see [Cancelling your billing items](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cancel-billing-items).\n\n\n\n\n\n Viewing and downloading your invoice \n\nView and download your invoice from the IBM console by clicking the Download icon ![Download icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/download.svg)> PDF invoice next to each invoice. For some accounts, invoices are available through the [Invoices@IBM](http:\/\/ibm.com\/invoices) website. See the [Viewing and downloading invoices for all other accounts](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesviewing-external-invoices) section for more information.\n\n\n\n\n\n\n\n Viewing and downloading invoices for all other accounts","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices"},{"document_id":"ibmcld_07578-1064084-1065746","score":21.5413314405,"text":"\nFor more information, see [Managing migrated SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).\n* How can I download my invoice?\n\nTo download your invoice, go to Manage > Billing and usage, and select Invoices. Then, click the Download icon ![Download icon](https:\/\/cloud.ibm.com\/icons\/download.svg) and choose an invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet. In some cases, you are redirected to the [IBM Invoices website](https:\/\/www.ibm.com\/invoices) where you can download your invoices. From the Invoices page, click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/icons\/action-menu-icon.svg) and select the invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet.\n* Is paperless invoicing available?\n\nYes, you can switch to paperless invoices by submitting a request on the [IBM Customer Support site](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/selectcountrylang.html). For more information, see [Requesting paperless invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesrequest-paperless-invoices).\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03771-7-2029","score":21.4333949543,"text":"\nViewing your invoices \n\nTo manage and view your invoices, visit the [Invoices](https:\/\/cloud.ibm.com\/billing\/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console. If your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices.\n\nIn these situations, visit the [Invoices@IBM](http:\/\/ibm.com\/invoices) website to see your invoices.\n\n\n\n Before you begin \n\nTo view your invoices, you need to be assigned the operator role or higher on the billing account management service. For more information, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services).\n\n\n\n\n\n Viewing invoices for new US-based Pay-As-You-Go accounts with credit card billing \n\nNew IBM Cloud Pay-As-You-Go accounts for US customers with credit card billing can now view all classic infrastructure and platform services on one invoice. In the IBM Cloud console, go to Manage > Billing and usage, and select Invoices.\n\nThe new invoice hierarchy highlights the most important details. By showcasing when the usage is measured, you can view each invoice\u2019s billing period in a clarified and comprehensive manner. The adjustments section on your invoice provides details about credits and adjustments from previous billing periods that might be included on an invoice from a different month.\n\nThe charges on your invoice are consistent with the usage dashboard. On the Invoices page in the console, click View usage to be directed to your usage dashboard. From there, you can select a timeframe and view billing and usage information that aligns directly with the details in your invoice.\n\n\n\n Checking your invoice status \n\nYou can check the status of your invoice on the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices):","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices"},{"document_id":"ibmcld_16727-1068047-1069909","score":21.3130203249,"text":"\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n* Can I spend more or less than my monthly commitment?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03771-5687-6513","score":18.2226223823,"text":"\nDepending on which region your account is located in, you can switch to paperless invoicing by submitting a request in writing through the IBM Customer Support site. Paperless invoicing isn't available in all regions.\n\n\n\n1. Go to [IBM Customer Support](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/selectcountrylang.html), and select your region.\n2. Click Contact us.\n3. Click Email us in the Invoice, payment section.\n4. Provide your IBM customer number in your request to switch to paperless billing. Click Save.\n\nIf you don't know your customer number, contact IBM Cloud Support by calling 1-866-325-0045 and selecting the third option, or contact the [eCustomer Care team](https:\/\/www-112.ibm.com\/software\/howtobuy\/passportadvantage\/paocustomer\/docs\/en_US\/ecare.html).\n5. To track the status your request, click My Requests.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices"},{"document_id":"ibmcld_01623-6277-8255","score":17.7373461067,"text":"\nAfter you verify your identity, you set up and provide details for your authentication factor.\n\n\n\n\n\n Step 3: Estimate your costs \n\nComplete the following steps to get an estimate of how much your usage might cost:\n\n\n\n1. Go to the [catalog](https:\/\/cloud.ibm.com\/catalog), and select Services.\n2. Select a service that you're interested in.\n3. Select a pricing plan, enter other configuration details if needed, and click Add to estimate.\n\nBy default, the estimator shows the pricing and billing currency for your location. Pricing can vary by region. If you're estimating costs for a different location, select the correct region to view accurate pricing.\n4. Add the calculated cost to your estimate by clicking Save.\n5. When you're done adding products to your estimate, click Review estimate to a detailed view of your estimate.\n\nYou can download a CSV, XSLX, or PDF of the estimate by clicking Download.\n\n\n\n\n\n\n\n Step 4: Manage your invoices and payment methods \n\nBefore you start working with resources in your account, familiarize yourself with where you can manage your payment method and access your invoices.\n\n\n\n Managing your payment method \n\n\n\n* To manage your payment method for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Payments.\n* To manage your payment method for an account that's billed in non-USD currency, go to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).\n\n\n\n\n\n\n\n Accessing your invoices \n\n\n\n* To access an invoice for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices.\n* To access an invoice for an account that's billed in non-USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices. Then, click IBM Invoices.\n\n\n\n\n\n\n\n\n\n Step 5: Set preferences for receiving notifications \n\nComplete the following steps to set your preferences for receiving various types of notifications:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-started"},{"document_id":"ibmcld_03797-1449-2926","score":16.9458481089,"text":"\nYou can find your recurring invoice on the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices).\n* [Figure 3](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-reconcile-invoicenew-charges): A view of the invoice tab in the console with the new and one-time charges from 20 February to 19 March.\n\n\n\n\n\n Step 1: Review the totals on the final invoice \n\nYou receive an IaaS and PaaS invoice each month.\n\nFor this example, reference Figure 1. The IaaS invoice total is $324,245.93 USD and the PaaS invoice total is $5566.81 USD. To understand what these totals represent, you must view the recurring console invoice. The recurring invoice in the console provides a line item breakdown of each charge.\n\nZoom\n\n![An image of IaaS and PaaS invoice for the month](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/official-march-invoice.png)\n\nFigure 1.IaaS and PaaS invoice for the month of March.\n\nZoom\n\n![An image of IaaS and PaaS invoice for the month](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/official-invoice-2.png)\n\nFigure 1.IaaS and PaaS invoice for the month of March.\n\n\n\n\n\n Step 2: Identify the recurring charges \n\nFigure 2 represents the recurring charges. To locate these recurring charges, complete the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Invoices.\n2. Click the invoice number.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.25,"recall_5":0.5,"recall_10":0.75,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.3633175613,"ndcg_cut_10":0.5023737408}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03786-7-2105","score":23.6680692977,"text":"\nApplying subscription codes \n\nAfter you buy a subscription for platform or support credit, you must add the credit to your account by applying a subscription code to an existing account or a new account when you register. Applying the code ensures that the credit is added to your account and you don't have unexpected overage charges.\n\nIf you set up your first subscription through the [Subscriptions page](https:\/\/cloud.ibm.com\/billing\/subscriptions), the credit for this subscription is automatically added to your account - no code required.\n\nAfter IBM Cloud Sales places the order, an email with the subscription code for each subscription and support line item is sent to the appropriate contact.\n\nOnly the account owner, enterprise account owner, or a user with the Editor or Administrator role on the Billing account management service can apply the subscription code. If you don't have access to apply subscription codes, the account owner or administrator can provide access. For more information, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services). Applying the subscription code through the IBM Cloud\u00ae console is essential to ensure that your account is migrated appropriately.\n\n\n\n1. Open the email with the subscription code.\n\nIf you bought a subscription and didn't receive your subscription code, [contact us](https:\/\/www.ibm.com\/cloud?contactmodule) or email Sales at [CloudDigitalSales@us.ibm.com](mailto:CloudDigitalSales@us.ibm.com) to request for it to be sent again.\n2. Click Add subscription to add it to an existing account.\n3. Sign in to the console with your IBMid and password.\n4. From the modal, choose the account you'd like to add the subscription to, select I understand, and then click Add.\n\n\n\nTo manually apply the subscription code to an existing account, complete the following steps:\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings.\n2. Click Apply code.\n\nEach code can be redeemed only one time, and the codes must be redeemed before their expiration date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code"},{"document_id":"ibmcld_12597-0-804","score":23.6611570251,"text":"\n\n\n\n\n\n\n  Why can't I apply a subscription code to my account in an enterprise? \n\nA subscription code can't be added to the account because of specific access that is required.\n\n  What\u2019s happening \n\nYou can't add a subscription code to your IBM Cloud\u00ae account because you don't have the correct access.\n\n  Why it\u2019s happening \n\nBecause your account is a child account on the enterprise, you can't apply subscription codes. Subscription codes must be applied at the enterprise level.\n\n  How to fix it \n\nContact the owner or the administrator of the enterprise to add the subscription code. When the subscription code is added, it applies to all accounts in the enterprise. For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-troubleshoot-promo-enterprise"},{"document_id":"ibmcld_03786-1684-3421","score":23.5676362253,"text":"\nFrom the modal, choose the account you'd like to add the subscription to, select I understand, and then click Add.\n\n\n\nTo manually apply the subscription code to an existing account, complete the following steps:\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings.\n2. Click Apply code.\n\nEach code can be redeemed only one time, and the codes must be redeemed before their expiration date. Ensure that you add the code to the correct account because the subscription credits can't be removed after the code is applied. After you add the subscription code, you might see that the status of the subscription as IN_PROCESS. Contact IBM Cloud Sales to review the account.\n3. Enter the subscription code, and click Apply.\n\nIf you have separate codes for platform and support credit, apply the platform subscription code first, then apply the support subscription code.\n\n\n\nTo manually apply the subscription code to a new account, complete the following steps:\n\n\n\n1. Go [create an IBM Cloud account](https:\/\/cloud.ibm.com\/registration), and enter the required information.\n2. Click Register with a code instead of entering your credit card information.\n3. Click Create account.\n\n\n\nIf you don't know your seller, the codes are applied in the wrong order, or you experience issues with applying the codes, [contact IBM Cloud Support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n\nFor information about other codes and credits that can be applied to different account types, see [Applying feature codes to a Lite account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) or [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code"},{"document_id":"ibmcld_03785-7-2010","score":23.410308981,"text":"\nFAQs for subscription accounts \n\nFAQs for subscription accounts include entries about subscription credit, subscription terms, and other subscription-related self-help information.\n\n\n\n How do I add subscription credit to my account? \n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n\n\n\n\n\n What does the IN_PROGRESS status mean when I apply a subscription code? \n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n\n\n\n\n\n Can I pay the total spending commitment up-front or quarterly? \n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n Can I spend more or less than my monthly commitment? \n\nYes, what you spend monthly is up to you! You can spend any amount of the total commitment each month.\n\n\n\n\n\n What happens if I spend my entire subscription amount before my term ends? \n\nYou're required to continue paying your monthly charges until the end of your term.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription-account"},{"document_id":"ibmcld_16727-1068047-1069909","score":22.9703425894,"text":"\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n* Can I spend more or less than my monthly commitment?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1065299-1067188","score":22.8789940998,"text":"\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03710-0-838","score":22.6376368292,"text":"\n\n\n\n\n\n\n  Why can't I apply a subscription code? \n\nTo successfully apply a subscription code, make sure the code is valid and you have the required access.\n\n  What\u2019s happening \n\nWhen you try to apply a subscription code, you see an error that states that the code cannot be applied.\n\n  Why it\u2019s happening \n\nYou might see this error if you don't have the required access in the account or the code expired.\n\n  How to fix it \n\nUse the following options:\n\n\n\n*  Verify that you have access to apply the code. To apply any code, you must have an Editor role or higher on all account management services. To view or change roles, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services).\n*  Contact the person who provided the code for help with reissuing an expired code.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cannot-apply-subscription-code"},{"document_id":"ibmcld_03787-5002-7004","score":22.0834830788,"text":"\nA subscription is inactive if its term expires or all of its credit is spent.\n\n\n\nYou can use the spending and usage information on the Subscriptions page to evaluate whether your subscriptions suit your usage needs. For example, if you consistently have overages, you might increase your monthly spending commitment to save money on that usage. To buy new subscriptions or change future subscription amounts, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n Support subscriptions \n\nTo view support subscription usage, in the console, go to Manage > Billing and usage, and select Support costs. You can view the remaining credit in your active support subscriptions and any upcoming subscriptions that aren't yet valid. For more information, see [Viewing your support costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-support).\n\n\n\n\n\n\n\n Subscription credit \n\nAfter you buy a subscription for platform or support credit, you add the credit to your account by applying a subscription code. Applying the code ensures that the credit is added to your account and you don't have unexpected overage charges.\n\nFor more information, see [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\n\n\n\n\n Expiring subscriptions \n\nYou are notified by email 60, 30, 14, and 1 day before the expiration date of the last subscription on the account. After the subscription expires, your account is converted to a Pay-As-You Go account, which means you pay only for billable services that you use with no contracts or commitments. The discounts that are associated with the subscription account won't apply to the Pay-As-You-Go account. The IBM Sales team is happy to help extend your subscription before you reach its expiration date. If you extend your subscription within 30 days from the expiration date, you won't get charged at the Pay-As-You-Go account rate. After 30 days, you are invoiced as a Pay-As-You-Go account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions"},{"document_id":"ibmcld_03704-8977-10890","score":21.1363849804,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n\n\n\n\n\n Why did I get invoiced when I have remaining promotion credits? \n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1050413-1052321","score":21.1363849804,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n* Why did I get invoiced when I have remaining promotion credits?\n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.3333333333}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>10","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03709-0-1479","score":17.2583201513,"text":"\n\n\n\n\n\n\n  Why can't I apply a feature code? \n\nTo successfully apply a feature code, make sure the code is valid and that you have the correct account type.\n\n  What\u2019s happening \n\nWhen you try to apply a feature code, you see an error that states that the code cannot be applied.\n\n  Why it\u2019s happening \n\nYou might see this error for any of the following reasons:\n\n\n\n*  Your account doesn't meet the requirements for the feature code.\n*  You don't have the required access in the account.\n*  The code expired.\n\n\n\n  How to fix it \n\nUse the following steps to successfully apply a feature code:\n\n\n\n*  Verify that you have the correct account type. For example, some feature codes for educational promotions are only for Lite accounts. To view your account type, in the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n*  Verify that you have access to apply the code. To apply any code, you must have an Editor role or higher on all account management services. To view or change roles, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services).\n*  Contact the person who provided the code for help with reissuing an expired code.\n*  If you are unable to apply a feature code that you received from an educational provider, contact that educational provider for further assistance.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cannot-apply-feature-code"},{"document_id":"ibmcld_03411-1652-3604","score":16.3227011838,"text":"\nAdding a good description will help you to distinguish multiple versions from one another later.\n\nAdd the date you deploy the version to its description to make it easier to filter logs by version from the Analytics page later. For more information, see [Picking a data source](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logslogs-pick-data-source).\n2. Click Save.\n\n\n\nA snapshot is taken of the current skill and saved as a new version. You remain in the development version of the skill. Any changes you make continue to be applied to the development version, not the version you saved. To access the version you saved, go to the Versions page.\n\nIf you have trouble creating the version, check that your skill does not have any entities with large numbers of values (such as 10,000 or more synonyms for a single entity). If it does, try to break the entity into many, more categorized entities, or consider using a contextual entity instead.\n\n\n\n\n\n Deploying a skill version \n\n\n\n1. From the skill menu, click Versions.\n2. Click the ![Click to view actions](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon from the version you want to deploy, and then choose Assign.\n\nA list of assistants to which you can link this version is displayed. The list is limited to those assistants that don't have any skills associated with them, or that are associated with a different version of this skill.\n3. Click the checkbox for one or more of the assistants, and then click Assign.\n\n\n\nKeep track of when this version is deployed to an assistant and for how long. It is likely that you will want to analyze user conversations that occur between users and this specific version of the skill. You can get this information from the Analytics page. However, when you pick a data source, versions are not listed. You must choose the name of the assistant to which you deployed this version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-versions"},{"document_id":"ibmcld_04147-7-1937","score":16.2280032652,"text":"\nHow do I generate a HAR file? \n\nWhen troubleshooting IBM Cloud Internet Services, it can be helpful to generate an HTTP Archive (HAR) file. The HAR file is a record of all web browser requests including the request and response headers, the body content, and the page load time.\n\n Why it\u2019s happening \n\nYou have an issue using CIS and need to generate a HAR file for Support.\n\nA HAR file can include sensitive details such as passwords, payment information, and private keys. Manually remove sensitive information from HAR files using a text editor before you provide the file to Support.\n\n How to fix it \n\nUse the following sections to generate HAR files in Firefox, Chrome, or Safari browsers.\n\n\n\n How to generate a HAR file in Firefox \n\n\n\n1. In Firefox, go to the page within CIS where you are experiencing trouble.\n2. Select the Firefox menu (three horizontal parallel lines) at the upper-right of your browser window, then select Developer > Network.\n3. The Developer Network Tools open as a docked panel at the side or bottom of the browser window. Click the Network tab.\n4. The recording starts automatically after you start performing actions in the browser.\n5. Refresh the CIS page that you are on, or go through the steps to reproduce the problem you've been experiencing while Firefox is recording activity.\n6. After you have reproduced the issue, right-click anywhere under the File column in the docked panel and click Save All As HAR.\n7. Save the HAR file in a location you choose, and send the file to Support.\n\n\n\n\n\n\n\n How to generate a HAR file in Chrome \n\n\n\n1. In Chrome, go to the page within CIS where you are experiencing trouble.\n2. Select the Chrome menu (three vertical dots) at the top-right of your browser window, then select Tools > Developer Tools.\n3. The Developer Tools open as a docked panel at the side or bottom of the browser window. Click on the Network tab.\n4. Select the option Preserve log.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-generate-har-files"},{"document_id":"ibmcld_03785-7-2010","score":15.2288825747,"text":"\nFAQs for subscription accounts \n\nFAQs for subscription accounts include entries about subscription credit, subscription terms, and other subscription-related self-help information.\n\n\n\n How do I add subscription credit to my account? \n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n\n\n\n\n\n What does the IN_PROGRESS status mean when I apply a subscription code? \n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n\n\n\n\n\n Can I pay the total spending commitment up-front or quarterly? \n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n Can I spend more or less than my monthly commitment? \n\nYes, what you spend monthly is up to you! You can spend any amount of the total commitment each month.\n\n\n\n\n\n What happens if I spend my entire subscription amount before my term ends? \n\nYou're required to continue paying your monthly charges until the end of your term.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription-account"},{"document_id":"ibmcld_07082-1735-3442","score":15.1885709759,"text":"\nOtherwise, choose None of the above and a Custom project type is created for you.\n3. If you choose a Document Retrieval project type and your data sources are in English, decide whether to enable the Content Intelligence feature.\n\nIf your data source contains contracts, enable the feature by selecting Apply contracts enrichment. Scroll to see the checkbox, if necessary.\n4. Click Next.\n5. Choose and configure a data source or connect to an existing collection.\n\nFor more information about supported data sources, see [Creating collections](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collections).\n\n\n\nTake advantage of the following resources that are available from the page header:\n\n\n\n* To open the product documentation, click the Help icon ![Help icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/help.svg).\n* To see all of your projects, click My projects.\n\n\n\n\n\n\n\n Project types \n\nChoose a project type to get the correct set of enrichments applied to your documents automatically. The improvement tools that are available differ by project type, as do the deployment methods, which are optimized for each use case.\n\nThe following project types are available:\n\n\n\n* [Document Retrieval](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-projectsdoc-retrieval)\n* [Document Retrieval for Contracts](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-projectsdoc-retrieval-contracts)\n* [Conversational Search](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-projectsconversational)\n* [Content Mining](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-projectsmining)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-projects"},{"document_id":"ibmcld_00523-7-2476","score":15.1299958149,"text":"\nDisaster recovery and backup for IBM Cloudant \n\nYour data is important and valuable. You want to protect your data to help ensure it's secure, available, and maintains integrity. IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae provides several ways to protect your data and help keep your applications operational.\n\nSome of these protection features are automatic. For other forms of protection, IBM Cloudant provides you with supported tools that help you to create your own high availability and disaster recovery capabilities.\n\nThe IBM Cloud\u00ae Service has Business Continuity plans in place to provide for the recovery of the Cloud Service within hours if a disaster occurs. You are responsible for your data backup, and associated recovery of your content.\n\nThis document provides an overview of the automatic capabilities and supported tools that are offered by IBM Cloudant.\n\n\n\n Types and levels of protection \n\nThe type of protection you might want depends on the problem you're trying to solve.\n\nFor example, you might want to have a high level of data availability so that you can still access your data, even if a limited amount of hardware within the system failed. This requirement is necessary for \"High Availability\" (HA). It means that you provide the best possible continuous data availability after a hardware failure. Different HA techniques tolerate different levels of failure before operations are affected.\n\nYou might want to have quick and easy ways of backing up and restoring data. For example, after a severe or extensive hardware failure, you want the ability to make all the data available on an alternative system as quickly as possible. This requirement is necessary for \"Disaster Recovery\" (DR). A disaster generally means that a database is no longer available in one or more locations. For example, a power outage might cause all systems in a database cluster to fail. Or a large-scale network failure might mean systems in a cluster can't be contacted, even though they continue to work correctly.\n\nAddressing your HA or DR requirements often begins by simplifying the problem into more generic requirements. When you identify your requirements, you can apply the tools and features that help solve the generic needs. Together, the tools and features can address your HA or DR requirements.\n\nDifferent tools and features provide different levels of protection. The different features might be more or less suitable for your specific HA or DR requirement.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup"},{"document_id":"ibmcld_02796-0-1599","score":14.9392835802,"text":"\n\n\n\n\n\n\n  How can I debug my SAML connection? \n\nYou encounter bugs in your SAML connection. Check out some following helpful tips for debugging your SAML connection.\n\n\n\n  How do I capture my SAML authentication request and response? \n\nThere are several options for browser plug-ins such as [Firefox](https:\/\/addons.mozilla.org\/en-US\/firefox\/addon\/saml-tracer\/) and [Chrome](https:\/\/chrome.google.com\/webstore\/detail\/saml-tracer\/mpdajninpobndbfcldcmbpnnbhibjmch?hl=en) that can be used to capture your SAML requests and responses. Don't want to use a plug-in? No problem. Atlassian provides instructions for a more [manual extraction approach](https:\/\/confluence.atlassian.com\/jirakb\/how-to-view-a-saml-responses-in-your-browser-for-troubleshooting-872129244.html).\n\n\n\n\n\n  I don't understand the messages! How can I decode them? \n\nIf you're still having trouble after using your SAML debug tool, try using the [SAML developer tools](https:\/\/www.samltool.com\/online_tools.php) for more help decoding your messages. Don't forget! Depending on where you intercept your SAML messages, your request might be [URL encoded](https:\/\/www.samltool.com\/online_tools.php), [base 64 encoded and deflated](https:\/\/www.samltool.com\/decode.php), or [encrypted](https:\/\/www.samltool.com\/decrypt.php).\n\nDo not use online tools for decrypting SAML messages like your SAML response. The tools need access to the encryption private key to decrypt the information. The key should be kept private and access controlled. The decryption tool that is mentioned in this section must be used for debugging purposes only.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-ts-saml-debug-connection"},{"document_id":"ibmcld_03369-52023-54183","score":14.5912478656,"text":"\nSupport for every language!\n: You now can build an assistant in any language you want to support. If a dedicated language model is not available for your target language, create a skill that uses the universal language model. The universal model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from training data written in the target language that you add to it.\n\nThe universal model is available as a beta feature. For more information, see [Understanding the universal language model](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-languageassistant-language-universal).\n\nActions skill improvement\n: Now you can indicate whether or not to ask for a number when you apply a number reply constraint to a step. Test how changes to this setting might help speed up a customer's interaction. Under the right circumstances, it can be useful to let a number mention be recognized and stored without having to explicitly ask the customer for it.\n\n\n\n\n\n 1 March 2021 \n\nIntroducing the Enterprise plan!\n: The Enterprise plan includes all of the market differentiating features of the Plus plan, but with higher capacity limits, additional security features, custom onboarding support to get you going, and a lower overall cost at higher volumes.\n\nTo have a dedicated environment provisioned for your business, request the Enterprise with Data Isolation plan. To submit a request online, go to [http:\/\/ibm.biz\/contact-wa-enterprise](http:\/\/ibm.biz\/contact-wa-enterprise).\n\nThe Enterprise plan is replacing the Premium plan. The Premium plan is being retired today. Existing Premium plan users are not impacted. They can continue to work in their Premium instances and create instances up to the 30-instance limit. New users do not see the Premium plan as an option when they create a service instance.\n\nFor more information, see the [Pricing](https:\/\/www.ibm.com\/cloud\/watson-assistant\/pricing\/) page.\n\nOther plan changes\n: Our pricing has been revised to reflect the features we've added that help you build an assistant that functions as a powerful omnichannel SaaS application.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_07578-217757-219947","score":14.5496935826,"text":"\nThe worker_node_min_count variable specifies the number of worker nodes that are provisioned at the time that the cluster is created, which will exist throughout the life of the cluster. The delta between those two variables specifies the maximum number of worker nodes that can either be created or destroyed by the Symphony Host Factory auto-scaling feature.\n\nThe Spectrum Symphony offering supports both bare metal worker nodes and Spectrum Scale storage nodes. The following combinations of values are supported:\n\n\n\n* If worker_node_type is set as baremetal, a maximum of 16 bare metal nodes are supported.\n* If spectrum_scale_enabled is set to true and storage_type is set as persistent, a maximum of 10 bare metal nodes are supported.\n\n\n\nFor more information, see [Deployment values](https:\/\/cloud.ibm.com\/docs\/hpc-spectrum-symphony?topic=hpc-spectrum-symphony-deployment-values).\n\nWhen creating or deleting a cluster with many worker nodes, you might encounter VPC resource provisioning or deletion failures. In those cases, running the Schematics apply or destroy operation again might result in the remaining resources being successfully provisioned or deleted. If you continue to see errors, see [Getting help and support](https:\/\/cloud.ibm.com\/docs\/hpc-spectrum-symphony?topic=hpc-spectrum-symphony-getting-help-and-support).\n* Why are there two different resource group parameters that can be specified in the IBM Cloud catalog tile?\n\nThe first resource group parameter entry in the Configure your workspace section in the IBM Cloud catalog applies to the resource group where the Schematics workspace is provisioned on your IBM Cloud account. The value for this parameter can be different than the one used for the second entry in the Parameters with default values section in the catalog. The second entry applies to the resource group where VPC resources are provisioned. As specified in the description for this second resource_group parameter, note that only the default resource group is supported for use of the Symphony Host Factory auto-scaling feature.\n* Can I use the Spectrum Symphony Host Factory feature for auto scaling on any cluster deployed with this offering?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-217731-219921","score":14.5496935826,"text":"\nThe worker_node_min_count variable specifies the number of worker nodes that are provisioned at the time that the cluster is created, which will exist throughout the life of the cluster. The delta between those two variables specifies the maximum number of worker nodes that can either be created or destroyed by the Symphony Host Factory auto-scaling feature.\n\nThe Spectrum Symphony offering supports both bare metal worker nodes and Spectrum Scale storage nodes. The following combinations of values are supported:\n\n\n\n* If worker_node_type is set as baremetal, a maximum of 16 bare metal nodes are supported.\n* If spectrum_scale_enabled is set to true and storage_type is set as persistent, a maximum of 10 bare metal nodes are supported.\n\n\n\nFor more information, see [Deployment values](https:\/\/cloud.ibm.com\/docs\/hpc-spectrum-symphony?topic=hpc-spectrum-symphony-deployment-values).\n\nWhen creating or deleting a cluster with many worker nodes, you might encounter VPC resource provisioning or deletion failures. In those cases, running the Schematics apply or destroy operation again might result in the remaining resources being successfully provisioned or deleted. If you continue to see errors, see [Getting help and support](https:\/\/cloud.ibm.com\/docs\/hpc-spectrum-symphony?topic=hpc-spectrum-symphony-getting-help-and-support).\n* Why are there two different resource group parameters that can be specified in the IBM Cloud catalog tile?\n\nThe first resource group parameter entry in the Configure your workspace section in the IBM Cloud catalog applies to the resource group where the Schematics workspace is provisioned on your IBM Cloud account. The value for this parameter can be different than the one used for the second entry in the Parameters with default values section in the catalog. The second entry applies to the resource group where VPC resources are provisioned. As specified in the description for this second resource_group parameter, note that only the default resource group is supported for use of the Symphony Host Factory auto-scaling feature.\n* Can I use the Spectrum Symphony Host Factory feature for auto scaling on any cluster deployed with this offering?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>11","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03713-1710-3705","score":38.4101076633,"text":"\nWhy do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the update wasn't successful.\n\n How to fix it \n\nGo to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n Why was there a general decline of my credit card? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card inactive or not authorized? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-7896-8949","score":38.3960172946,"text":"\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved. Please try another card.\n\n Why it\u2019s happening \n\nYour card information was incorrect.\n\n How to fix it \n\nUse a different credit card to process your transaction.\n\n\n\n\n\n Why was my credit card declined? \n\n What\u2019s happening \n\nAn issue occurred that caused your credit card to decline. This error might prompt the following message:\n\n> Your payment was declined for invoice number\u2026\n\n Why it\u2019s happening \n\nYou have a credit card on file and it was declined.\n\n How to fix it \n\nUpdate your credit card information on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments). Credit card transactions are automatically retried within 24 hours after you update the information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-7-2194","score":37.9833834109,"text":"\nCredit Card error messages \n\nAn issue might occur when you try to update, add, or remove a credit card. Review the following credit card error messages for detailed self-help information.\n\n\n\n Why was my credit card transaction rejected? \n\nProtecting your identity is a priority and IBM Cloud takes credit card verification seriously.\n\n What\u2019s happening \n\nAn issue occurred that caused the transaction to fail. For example, the name and address on file with IBM Cloud doesn't match the information on file with the company that issued your credit card. This error might prompt the following message:\n\n> Error: Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the transaction wasn't successful.\n\n How to fix it \n\nTo ensure that your credit card verification is successful, complete the following steps:\n\n\n\n1. Verify that the name and address for your IBM Cloud account matches the name and address on file with your credit card issuer.\n2. Verify that the country associated with a VAT or tax identification number matches the country in your IBM Cloud account. For example, a VAT ID registered in France can't be associated with an IBM Cloud account that is registered in Finland.\n3. Verify that you are creating a business account and not a personal account if you are specifying a VAT ID or tax identification number.\n4. Review the error message that was displayed. If your transaction was rejected and an email address was not provided, contact your credit card issuer.\n5. Contact us by calling 1-866-325-0045 and selecting the third option.\n\n\n\n\n\n\n\n Why do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-6236-8279","score":36.6830732507,"text":"\nFor more information, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> There was an error in the payment process: We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is the transaction already processed? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Transaction already processed.\n\n Why it\u2019s happening \n\nOur payment system has detected multiple similar payments within a short period of time. IBM Cloud is attempting to avoid unintentional duplicate payments.\n\n How to fix it \n\nWait 3-4 hours for the manual payment to be processed and posted to your IBM Cloud} account. Verify your account balance on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n\n\n\n\n Why can't I upgrade my account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your account couldn't be upgraded. Click Upgrade account to try again.\n\n Why it\u2019s happening \n\nIBM Cloud} was unable to process your transaction.\n\n How to fix it \n\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03782-0-720","score":36.4960641639,"text":"\n\n\n\n\n\n\n  Why do I get a section error when I try to provide credit card information? \n\nYou are unable to complete the registration of a new account or to update the credit card information on an existing account because the Credit Card information section can\u2019t be loaded.\n\n  What\u2019s happening \n\nThe following error appears in the Credit Card information section of the form:\n\n> This section can\u2019t be loaded.\n\n  Why it\u2019s happening \n\nA network issue might affect the loading of this section of the form.\n\n  How to fix it \n\nYou can troubleshoot potential network problems by using a private or incognito window, by trying without a VPN or with a different VPN, or by using a browser on a different computer or device.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-section-error"},{"document_id":"ibmcld_03704-3030-4892","score":35.5190720033,"text":"\nIn the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n\n\n\n\n\n How do I change my payment method? \n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n\n\n\n\n\n Why didn't my credit card process? \n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1044428-1046278","score":35.4394930141,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1044299-1046149","score":35.4394930141,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03713-3269-5168","score":35.215798949,"text":"\nProblem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card not authorized to place an order? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is IBM Cloud unable to process my order request? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected. Please contact Cloud Trust Enablement at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n Why it\u2019s happening \n\nIBM Cloud\u00ae was unable to process your transaction.\n\n How to fix it \n\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_01660-7-1957","score":34.9669824731,"text":"\nFAQs about accounts \n\nFAQs for your IBM Cloud\u00ae account might include questions about upgrading an account, reassigning users, resolving account errors, or tagging resources in an account. To find all FAQs for IBM Cloud, see our [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n How do I create an IBM Cloud account? \n\nYou can create an account by [registering](https:\/\/cloud.ibm.com\/registration) your email address. For identity verification, a credit card is required when you create a new account. New accounts are created as Pay-As-You-Go accounts, except purchased subscriptions. For more information, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\nFeature codes aren't supported in some countries. For more information, see [personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n\n\n\n\n\n How is my credit card authorized? \n\nA credit card is required to create a new IBM Cloud account unless you have a subscription or feature code. As part of the authorization process, you might see a temporary hold on your credit card for verification and security when creating an account. This credit card hold is reversed within 24 to 72 hours. In many cases, a credit card isn't accepted because your credit card issuer didn't authorize it. For more information about issues with credit card authorization, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\n\n\n\n\n How do I get help with issues with creating an account? \n\nIf you are able to log in to an IBM Cloud account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and choose one of the following options.\n\n\n\n* If you have advanced or premium support, click Chat with IBM to talk to an IBM Cloud support representative.\n* Create a support case by clicking Create a case from the Need more help? section.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.75,"recall_5":0.75,"recall_10":0.75,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":0.8318724637,"ndcg_cut_10":0.8318724637}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>12","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03713-3269-5168","score":91.0685041758,"text":"\nProblem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card not authorized to place an order? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is IBM Cloud unable to process my order request? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected. Please contact Cloud Trust Enablement at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n Why it\u2019s happening \n\nIBM Cloud\u00ae was unable to process your transaction.\n\n How to fix it \n\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-1710-3705","score":82.5684410356,"text":"\nWhy do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the update wasn't successful.\n\n How to fix it \n\nGo to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n Why was there a general decline of my credit card? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card inactive or not authorized? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-7-2194","score":76.6937711289,"text":"\nCredit Card error messages \n\nAn issue might occur when you try to update, add, or remove a credit card. Review the following credit card error messages for detailed self-help information.\n\n\n\n Why was my credit card transaction rejected? \n\nProtecting your identity is a priority and IBM Cloud takes credit card verification seriously.\n\n What\u2019s happening \n\nAn issue occurred that caused the transaction to fail. For example, the name and address on file with IBM Cloud doesn't match the information on file with the company that issued your credit card. This error might prompt the following message:\n\n> Error: Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the transaction wasn't successful.\n\n How to fix it \n\nTo ensure that your credit card verification is successful, complete the following steps:\n\n\n\n1. Verify that the name and address for your IBM Cloud account matches the name and address on file with your credit card issuer.\n2. Verify that the country associated with a VAT or tax identification number matches the country in your IBM Cloud account. For example, a VAT ID registered in France can't be associated with an IBM Cloud account that is registered in Finland.\n3. Verify that you are creating a business account and not a personal account if you are specifying a VAT ID or tax identification number.\n4. Review the error message that was displayed. If your transaction was rejected and an email address was not provided, contact your credit card issuer.\n5. Contact us by calling 1-866-325-0045 and selecting the third option.\n\n\n\n\n\n\n\n Why do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-4689-6647","score":62.5051689348,"text":"\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nYour credit card number was not recognized by your credit card issuer.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why was my change request rejected because of a VAT ID? \n\n What\u2019s happening \n\nYou tried to complete a change request IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Failed to complete the Change Request process due to the following error: VAT ID is a required field for ...\n\n Why it\u2019s happening \n\nYour VAT ID, CST or other tax identification number cannot be validated.\n\n How to fix it \n\n\n\n1. Verify that tax identification number is valid.\n2. Verify that the tax identification number is associated with the same country as the physical country of residence in your IBM Cloud profile.\n3. Verify whether a VAT ID is required to create an IBM Cloud account in your country of residence. For more information, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-6236-8279","score":51.217766659,"text":"\nFor more information, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> There was an error in the payment process: We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is the transaction already processed? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Transaction already processed.\n\n Why it\u2019s happening \n\nOur payment system has detected multiple similar payments within a short period of time. IBM Cloud is attempting to avoid unintentional duplicate payments.\n\n How to fix it \n\nWait 3-4 hours for the manual payment to be processed and posted to your IBM Cloud} account. Verify your account balance on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n\n\n\n\n Why can't I upgrade my account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your account couldn't be upgraded. Click Upgrade account to try again.\n\n Why it\u2019s happening \n\nIBM Cloud} was unable to process your transaction.\n\n How to fix it \n\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03782-0-720","score":38.6931590558,"text":"\n\n\n\n\n\n\n  Why do I get a section error when I try to provide credit card information? \n\nYou are unable to complete the registration of a new account or to update the credit card information on an existing account because the Credit Card information section can\u2019t be loaded.\n\n  What\u2019s happening \n\nThe following error appears in the Credit Card information section of the form:\n\n> This section can\u2019t be loaded.\n\n  Why it\u2019s happening \n\nA network issue might affect the loading of this section of the form.\n\n  How to fix it \n\nYou can troubleshoot potential network problems by using a private or incognito window, by trying without a VPN or with a different VPN, or by using a browser on a different computer or device.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-section-error"},{"document_id":"ibmcld_03713-7896-8949","score":37.8192650085,"text":"\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved. Please try another card.\n\n Why it\u2019s happening \n\nYour card information was incorrect.\n\n How to fix it \n\nUse a different credit card to process your transaction.\n\n\n\n\n\n Why was my credit card declined? \n\n What\u2019s happening \n\nAn issue occurred that caused your credit card to decline. This error might prompt the following message:\n\n> Your payment was declined for invoice number\u2026\n\n Why it\u2019s happening \n\nYou have a credit card on file and it was declined.\n\n How to fix it \n\nUpdate your credit card information on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments). Credit card transactions are automatically retried within 24 hours after you update the information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_04083-36368-38197","score":34.5139960848,"text":"\nTo re-establish communications between the node and the proxy, restart the failing node by deleting the pod associated with the node. A new pod will be created and the connection with the PKCS #11 proxy is restored. Use the following steps to restart the failing node:\n\n\n\n* List the pods: kubectl get pods -n <NAMESPACE>\n* Delete the pod: kubectl delete pod -n <NAMESPACE> <PODNAME>\n\n\n\nReplace:\n\n\n\n* <NAMESPACE> with the namespace where the associated pods are deployed. To find the namespace, open any CA node in your console and click the Settings icon. View the value of the Certificate Authority endpoint URL. For example: https:\/\/n2734d0-paorg10524.ibpv2-cluster.us-south.containers.appdomain.cloud:7054. The namespace is the first part of the URL beginning with the letter n and followed by a random string of six alphanumeric characters. So in this example, the value of the namespace is n2734d0.\n* <PODNAME> with the Name of the failing pod that is visible in the list of pods returned by the previous command.\n\n\n\n\n\n\n\n Why are my transactions returning an endorsement policy error: signature set did not satisfy policy? \n\n What\u2019s happening \n\nWhen I invoke a smart contract to submit a transaction, the transaction returns the following endorsement policy failure:\n\nreturned error: VSCC error: endorsement policy failure, err: signature set did not satisfy policy\n\n Why it\u2019s happening \n\nIf you have recently joined a channel and installed the smart contract, this error occurs if you have not added your organization to the endorsement policy. Because your organization is not on the list of organizations who can endorse a transaction from the smart contract, the endorsement from your peers is rejected by the channel. If you encounter this problem, you can change the endorsement policy by upgrading the smart contract.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshooting"},{"document_id":"ibmcld_03837-3210-5419","score":33.128799107,"text":"\nCertificate Authorities (CAs) \n\nYou can think of a blockchain network as a series of managed interactions between nodes to serve a defined business use case. For these interactions to be verifiable (to ensure, in other words, who is who) requires identities and a system of permissions that can be checked during each interaction. You can think of the kind of identity that is needed as being similar to a credit card in that it identifies someone within a particular context. Credit cards identify an individual in terms of banking transactions, while Fabric identities allow users to be identified in a blockchain context.\n\nIn Hyperledger Fabric, as well as the IBM Blockchain Platform, this component is the Certificate Authority (CA), which creates identities in the form of x509 certificates as well defining of an organization through the creation of a Membership Services Provider (MSP), which defines the permissions of identities at a component and channel level. These identities can include attributes about them, for example, by linking them to a particular organization or organizational unit (OU).\n\nAn organization MSP, for example, has an MSP subfolder called admins. Any user whose certificate is inside that admin folder is an admin of the organization. Because this MSP defines the organization, it is listed in the configuration on every channel of which the organization is a member. As a result, whenever an admin of the organization tries to perform an action, the signing certificate of the admin (which is attached to all of its interactions) is checked against the certificates listed in the MSP. Does the certificate match the one listed in the channel configuration? If it does, the other organizations will validate it and the action can be performed. If not, the request to execute the transaction is rejected.\n\nIBM Blockchain Platform CAs are based on the [Hyperledger Fabric CA](https:\/\/hyperledger-fabric-ca.readthedocs.io\/en\/release-1.4\/), though it is possible to use another CA if it uses a PKI based on x.509 certificates. Because non-Fabric CAs are not configured to create properly formatted MSPs, users who want to use this kind of CA must create the MSP for themselves.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-blockchain-component-overview"},{"document_id":"ibmcld_09192-7-1931","score":32.4999930225,"text":"\nTroubleshooting \n\nGeneral problems with using IBM\u00ae Key Protect for IBM Cloud\u00ae might include providing the correct headers or credentials when you interact with the API. In many cases, you can recover from these problems by following a few easy steps.\n\n\n\n Unable to create keys \n\nWhen you access the Key Protect user interface, the option to add a key to the Key Protect instance is disabled.\n\n What\u2019s happening \n\nFrom the IBM Cloud dashboard, you select your instance of the Key Protect service.\n\nYou can see a list of keys, but you're unable to select the option to add a key.\n\n Why it\u2019s happening \n\nYou do not have the correct authorization to perform Key Protect actions.\n\n How to fix it \n\nVerify with an administrator that you are assigned the correct role in the applicable Key Protect instance. For more information about roles, see [Roles and permissions](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-accessmanage-access-roles).\n\n\n\n\n\n Unable to authenticate through the API \n\nWhen you call the Key Protect API, the system returns a 401 Unauthorized error, and you're unable to make the API request.\n\n What\u2019s happening \n\nYou call any Key Protect API method. You see an error response similar to the following JSON object:\n\n{\n\"metadata\": {\n\"collectionType\": \"application\/vnd.ibm.kms.error+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"errorMsg\": \"Unauthorized: The user does not have access to the specified resource\"\n}\n]\n}\n\n Why it\u2019s happening \n\nYou do not have the correct authorization to perform Key Protect actions in the specified service instance.\n\n How to fix it \n\nVerify with an administrator that you are assigned the correct platform and service access roles in the applicable Key Protect instance. For more information about roles, see [Roles and permissions](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-accessmanage-access-roles).\n\n\n\n\n\n Unable to view or list keys","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-troubleshooting"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06926-3212-5298","score":18.0568112854,"text":"\n* The customer VRF is a connectivity service that provides isolation among tenants. Any additional controls that are needed within a tenancy must be provisioned separately by using a gateway, security groups, or host-based controls.\n\n\n\n\n\n\n\n Benefits of moving to VRF \n\nMoving to VRF includes the following primary benefits:\n\n\n\n* Industry-proven and widely accepted multiple isolation separation technologies. Many cloud customers find the Level-3 VPN approach more palatable than ACLs to their auditors and compliance officers.\n* IBM Cloud customers can extend or migrate the reach of their network significantly, due to addition of new sites or applications throughout the IBM network.\n* Tenant-specific routing tables narrow the aperture for IP address overlap, without the risk of overlap with other tenants' subnets or other parts of the network that are not applicable.\n\n\n\nCompared to the older ACL model, there are a few minor tradeoffs to take into account:\n\n\n\n* Converting to a customer VRF requires a maintenance window, which causes a brief disruption of backbone traffic flows.\n* Remote access by using the managed VPN services (SSL, IPsec) is limited to just SSL VPN into a data center; however, the shared ACL over the backbone allows global access from any entry point from either service.\n* VLAN spanning is a feature of the shared tenancy model and is not available in a VRF; this will be disabled upon conversion to the Customer VRF.\n* IPsec VPN managed service on IBM Cloud classic infrastructure remote access is not available.\n\n\n\nMany IBM Cloud customers currently operate with a shared tenancy model on the IBM Cloud network. During conversion, your shared tenancy is converted to use a customer VRF, most commonly with a new Direct Link subscription.\n\nFor specific information about how to initiate a VRF conversion for your account, refer to the conversion instructions for your IBM Cloud offering. For example:\n\n\n\n* [Direct Link conversion instructions](https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-what-happens-during-the-account-conversion-process)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-overview-of-virtual-routing-and-forwarding-vrf-on-ibm-cloud"},{"document_id":"ibmcld_03180-11118-12801","score":17.4999578193,"text":"\nIf the customer is on the Returns page, you might want to route the chat transfer to agents who know how to help customers return merchandise.\n\nFor more information, see [Web chat: Accessing browser information](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrationsdialog-integrations-chat-browser-info).\n\n\n\n\n\n Routing by topic \n\nYou can specify a routing preference for specific topics of conversation in your dialog. When specified, the chat is transferred to the department that you designate. You can choose a department that you know has agents who are best able to address the topic.\n\nBefore you perform this procedure, determine which department you want users to be routed to.\n\nTo add custom routing logic, complete the following steps:\n\n\n\n1. From the Dialog page, find the root dialog node for the branch of the conversation that you want to route to a specific Zendesk department.\n2. Find the dialog node in the branch where you want the transfer to take place, and then add the Connect to human agent response type as the dialog node response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. After you add the response type and customize the transfer messages, select Zendesk from the Service desk routing field.\n4. In the Department field, add the department to which you want the assistant to transfer customers who want to discuss this topic. For example, sales.\n\nBe sure to specify the exact right syntax for the department name. The value is not validated by the service as you add it to your dialog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-zendesk"},{"document_id":"ibmcld_03162-10976-13038","score":17.4502232021,"text":"\nThe routing rules identify the queue of agents to which messages from the assistant are transferred by default.\n\nThe code that you add to the setup page when you configure the service desk integration shares the following required information with Watson Assistant:\n\n\n\n* organization_id: Unique ID of the organization. A company can have more than one organization set up in Salesforce.\n* chat_api_endpoint: Salesforce API endpoint that is used by the integration to communicate with Salesforce.\n* deployment_id: Unique ID of the deployment. An organization can have multiple deployments.\n* button_id: Unique ID of a button, which defines the specific routing rules for incoming messages. Each deployment can have multiple buttons associated with it.\n\n\n\nTo override the default routing rules, you must specify a new value for the button_id. Before you perform this procedure, find out the ID of the Salesforce button implementation with the alternative routing rules that you want to use.\n\nTo add custom routing logic, complete the following steps:\n\n\n\n1. From the Dialog page, find the root dialog node for the branch of the conversation that you want to route to a specific group of Salesforce agents which is distinct from the default group.\n2. Find the dialog node in the branch where you want the transfer to take place, and then add the Connect to human agent response type as the dialog node response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. After you add the response type and customize the transfer messages, select Salesforce from the Service desk routing field.\n4. In the Button ID field, add the button_id value for the alternate routing destination that you want the assistant to use for conversations about only this topic. For example, 5733i0000008yGz.\n\nBe sure to specify the exact right syntax for the button_id value. The value is not validated by the service as you add it to your dialog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-salesforce"},{"document_id":"ibmcld_16258-7-1952","score":17.0126293102,"text":"\nReview customer conversations \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nEach timestamp represents a single conversation. The Actions column shows you how many actions, search queries, or unrecognized requests are included in that conversation. The Requests column includes the questions or requests the user entered that initiated an action, started a search query, or weren't recognized.\n\nIf you have activated dialog in your assistant, the Actions column is replaced by a Topics column.\n\n![Conversations page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations.png)\n\n\n\n Choosing the environment and time period \n\nTo get started, choose the [environment](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overviewenvironments) and date range you want to analyze. All conversations reflect data based on the environment and the date range you select. When you change the environnment or the date range, the conversations on the page update to reflect the new date range. You can also use Refresh ensure the latest data is shown.\n\n![Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_16258-1324-3123","score":17.0033383372,"text":"\n[Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_02844-1555-3643","score":16.938558628,"text":"\nconversation.counterexample.update edits a counterexample. \n conversation.data.update does a bulk action, such as importing a CSV file of intents or entities to the skill, or deleting multiple training data items, such as multiple entities or intents. \n conversation.entity.create creates an entity. \n conversation.entity.delete deletes an entity. \n conversation.entity.update edits an entity. \n conversation.example.create adds a user input example to an intent. \n conversation.example.delete deletes a user example from an intent. \n conversation.example.update edits a user example that is associated with an intent. \n conversation.intent.create creates an intent. \n conversation.intent.delete deletes an intent. \n conversation.intent.update edits an intent. \n conversation.log.create corrects an intent that was inaccurately categorized by the skill from the Analytics>User conversations page. \n conversation.node.create creates a dialog node. \n conversation.node.delete deletes a dialog node. \n conversation.node.update edits a dialog node. \n conversation.skill.create creates a skill, either dialog or search. \n conversation.skill.delete deletes a skill. \n conversation.skill.update updates a skill. \n conversation.skill_reference.create adds a specific skill to an assistant. \n conversation.skill_reference.delete removes a specific skill from an assistant. \n conversation.skill_reference.update updates a specific skill that is associated with an assistant. \n conversation.snapshot.create creates a version of a dialog skill. \n conversation.snapshot.delete deletes a version of a dialog skill. \n conversation.synonym.create creates a synonym for an entity value. \n conversation.synonym.delete deletes a synonym that is associated with an entity value. \n conversation.synonym.update edits a synonym that is associated with an entity value. \n conversation.userdata.delete deletes data that was created by a specified customer. \n conversation.value.create creates an entity value. \n conversation.value.delete deletes an entity value. \n conversation.value.update edits an entity value.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-audit-events"},{"document_id":"ibmcld_16338-2788-4628","score":16.7478386901,"text":"\n* [Confidence scores](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-reviewreview-debug-confidence)\n* [Step locator](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-reviewreview-debug-step-locator)\n* [Follow along](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-reviewreview-debug-follow-along)\n\n\n\n\n\n Start and end of an action \n\nThe assistant marks the spots in the conversation when a customer enters an input that fits within an action. The assistant also marks when an action completes, and how it completes.\n\nCompletion options include ending:\n\n\n\n* With an end step\n* Without an end step\n* With a human agent escalation\n* With a search to a knowledge base\n\n\n\n\n\n\n\n Action confidence score \n\nEvery input that you enter that can start a new topic shows a confidence score icon. Hover over this icon to see a list of actions with different confidence scores.\n\nThese scores represent the assistant\u2019s confidence that the sentence or phrase that you entered can be solved by the steps that are built into a specific action.\n\nZoom\n\n![Debug mode](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/rn-debug-confidence.png)\n\nDebug mode\n\nThe top score in green represents the action with the highest confidence and the one the assistant used.\n\nThe remaining two are actions that were considered because of their confidence score, but weren't used because thee confidence scores were lower.\n\nIf no action scores higher than 20% confidence, you see the built-in action No action matches.\n\n\n\n\n\n Step locator \n\nSometimes you might find an error in the middle of a test conversation, and need to find which step and action is involved. A locator icon next to each assistant response lets you find the associated steps in the editor.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-review"},{"document_id":"ibmcld_16338-4145-6019","score":15.8256384716,"text":"\nThe remaining two are actions that were considered because of their confidence score, but weren't used because thee confidence scores were lower.\n\nIf no action scores higher than 20% confidence, you see the built-in action No action matches.\n\n\n\n\n\n Step locator \n\nSometimes you might find an error in the middle of a test conversation, and need to find which step and action is involved. A locator icon next to each assistant response lets you find the associated steps in the editor.\n\nClick the icon, and the editor shows the corresponding step in the background.\n\nZoom\n\n![Step locator](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/review-step-locator.png)\n\nStep locator\n\n\n\n\n\n Follow along \n\nFollow along connects what you are seeing in Preview with what you built in the action. As you interact with your assistant, the debug mode automatically opens each step in the background. That means you can fix an error as soon as you see it, because the editor is already open to the corresponding step.\n\n\n\n\n\n\n\n Variable values in Preview \n\nAs you test your conversation in Preview, you can check that each variable is set correctly. Click Variable values to see the values stored in each variable during the conversation. The Variable values pane has two tabs, one for action variables and one for session variables. If you are using dialog, you can see session variables for both actions and dialog on the Session variables tab.\n\nZoom\n\n![Variable values](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/variable-values-preview.png)\n\nVariable values\n\nTo learn more about variables, see [Managing information during the conversation](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-manage-info).\n\n\n\n\n\n Extension inspector in Preview","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-review"},{"document_id":"ibmcld_06926-4859-5591","score":15.8076728202,"text":"\nDuring conversion, your shared tenancy is converted to use a customer VRF, most commonly with a new Direct Link subscription.\n\nFor specific information about how to initiate a VRF conversion for your account, refer to the conversion instructions for your IBM Cloud offering. For example:\n\n\n\n* [Direct Link conversion instructions](https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-what-happens-during-the-account-conversion-process)\n* [VPC conversion instructions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-setting-up-access-to-classic-infrastructure&interface=uihow-you-can-initiate-the-conversion)\n* [IBM Cloud service endpoints conversion instructions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-vrf-service-endpoint)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-overview-of-virtual-routing-and-forwarding-vrf-on-ibm-cloud"},{"document_id":"ibmcld_10143-7-2020","score":15.7491766621,"text":"\nWhy can't I view or work with my cluster? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\n What\u2019s happening \n\nYou are not able to find a cluster. When you run ibmcloud oc cluster ls, the cluster is not listed in the output.\n\nOr, you are not able to work with a cluster. When you run ibmcloud oc cluster config or other cluster-specific commands, the cluster is not found.\n\n Why it\u2019s happening \n\nIn IBM Cloud, each resource must be in a resource group. For example, cluster mycluster might exist in the default resource group.\n\nWhen the account owner gives you access to resources by assigning you an IBM Cloud IAM platform access role, the access can be to a specific resource or to the resource group. When you are given access to a specific resource, you don't have access to the resource group. In this case, you don't need to target a resource group to work with the clusters you have access to. If you target a different resource group than the group that the cluster is in, actions against that cluster can fail. Conversely, when you are given access to a resource as part of your access to a resource group, you must target a resource group to work with a cluster in that group. If you don't target your CLI session to the resource group that the cluster is in, actions against that cluster can fail.\n\nIf you can't find or work with a cluster, you might be experiencing one of the following issues:\n\n\n\n* You have access to the cluster and the resource group that the cluster is in, but your CLI session is not targeted to the resource group that the cluster is in.\n* You have access to the cluster, but not as part of the resource group that the cluster is in. Your CLI session is targeted to this or another resource group.\n* You don't have access to the cluster.\n\n\n\n How to fix it \n\nTo check your user access permissions:\n\n\n\n1. List all your user permissions.\n\nibmcloud iam user-policies <your_user_name>\n2. Check if you have access to the cluster and to the resource group that the cluster is in.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cluster_access"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16258-1324-3123","score":21.069397697,"text":"\n[Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_16258-7-1952","score":21.0320916448,"text":"\nReview customer conversations \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nEach timestamp represents a single conversation. The Actions column shows you how many actions, search queries, or unrecognized requests are included in that conversation. The Requests column includes the questions or requests the user entered that initiated an action, started a search query, or weren't recognized.\n\nIf you have activated dialog in your assistant, the Actions column is replaced by a Topics column.\n\n![Conversations page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations.png)\n\n\n\n Choosing the environment and time period \n\nTo get started, choose the [environment](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overviewenvironments) and date range you want to analyze. All conversations reflect data based on the environment and the date range you select. When you change the environnment or the date range, the conversations on the page update to reflect the new date range. You can also use Refresh ensure the latest data is shown.\n\n![Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_03162-10976-13038","score":19.9773553516,"text":"\nThe routing rules identify the queue of agents to which messages from the assistant are transferred by default.\n\nThe code that you add to the setup page when you configure the service desk integration shares the following required information with Watson Assistant:\n\n\n\n* organization_id: Unique ID of the organization. A company can have more than one organization set up in Salesforce.\n* chat_api_endpoint: Salesforce API endpoint that is used by the integration to communicate with Salesforce.\n* deployment_id: Unique ID of the deployment. An organization can have multiple deployments.\n* button_id: Unique ID of a button, which defines the specific routing rules for incoming messages. Each deployment can have multiple buttons associated with it.\n\n\n\nTo override the default routing rules, you must specify a new value for the button_id. Before you perform this procedure, find out the ID of the Salesforce button implementation with the alternative routing rules that you want to use.\n\nTo add custom routing logic, complete the following steps:\n\n\n\n1. From the Dialog page, find the root dialog node for the branch of the conversation that you want to route to a specific group of Salesforce agents which is distinct from the default group.\n2. Find the dialog node in the branch where you want the transfer to take place, and then add the Connect to human agent response type as the dialog node response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. After you add the response type and customize the transfer messages, select Salesforce from the Service desk routing field.\n4. In the Button ID field, add the button_id value for the alternate routing destination that you want the assistant to use for conversations about only this topic. For example, 5733i0000008yGz.\n\nBe sure to specify the exact right syntax for the button_id value. The value is not validated by the service as you add it to your dialog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-salesforce"},{"document_id":"ibmcld_02844-1555-3643","score":19.8378798368,"text":"\nconversation.counterexample.update edits a counterexample. \n conversation.data.update does a bulk action, such as importing a CSV file of intents or entities to the skill, or deleting multiple training data items, such as multiple entities or intents. \n conversation.entity.create creates an entity. \n conversation.entity.delete deletes an entity. \n conversation.entity.update edits an entity. \n conversation.example.create adds a user input example to an intent. \n conversation.example.delete deletes a user example from an intent. \n conversation.example.update edits a user example that is associated with an intent. \n conversation.intent.create creates an intent. \n conversation.intent.delete deletes an intent. \n conversation.intent.update edits an intent. \n conversation.log.create corrects an intent that was inaccurately categorized by the skill from the Analytics>User conversations page. \n conversation.node.create creates a dialog node. \n conversation.node.delete deletes a dialog node. \n conversation.node.update edits a dialog node. \n conversation.skill.create creates a skill, either dialog or search. \n conversation.skill.delete deletes a skill. \n conversation.skill.update updates a skill. \n conversation.skill_reference.create adds a specific skill to an assistant. \n conversation.skill_reference.delete removes a specific skill from an assistant. \n conversation.skill_reference.update updates a specific skill that is associated with an assistant. \n conversation.snapshot.create creates a version of a dialog skill. \n conversation.snapshot.delete deletes a version of a dialog skill. \n conversation.synonym.create creates a synonym for an entity value. \n conversation.synonym.delete deletes a synonym that is associated with an entity value. \n conversation.synonym.update edits a synonym that is associated with an entity value. \n conversation.userdata.delete deletes data that was created by a specified customer. \n conversation.value.create creates an entity value. \n conversation.value.delete deletes an entity value. \n conversation.value.update edits an entity value.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-audit-events"},{"document_id":"ibmcld_03180-11118-12801","score":19.2910789431,"text":"\nIf the customer is on the Returns page, you might want to route the chat transfer to agents who know how to help customers return merchandise.\n\nFor more information, see [Web chat: Accessing browser information](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrationsdialog-integrations-chat-browser-info).\n\n\n\n\n\n Routing by topic \n\nYou can specify a routing preference for specific topics of conversation in your dialog. When specified, the chat is transferred to the department that you designate. You can choose a department that you know has agents who are best able to address the topic.\n\nBefore you perform this procedure, determine which department you want users to be routed to.\n\nTo add custom routing logic, complete the following steps:\n\n\n\n1. From the Dialog page, find the root dialog node for the branch of the conversation that you want to route to a specific Zendesk department.\n2. Find the dialog node in the branch where you want the transfer to take place, and then add the Connect to human agent response type as the dialog node response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. After you add the response type and customize the transfer messages, select Zendesk from the Service desk routing field.\n4. In the Department field, add the department to which you want the assistant to transfer customers who want to discuss this topic. For example, sales.\n\nBe sure to specify the exact right syntax for the department name. The value is not validated by the service as you add it to your dialog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-zendesk"},{"document_id":"ibmcld_07068-2140-4064","score":19.0256542145,"text":"\nList fields across collections [GET \/v1\/environments\/{environment_id}\/fields](https:\/\/cloud.ibm.com\/apidocs\/discoverylistfields) [GET \/v2\/projects\/{project_id}\/fields](https:\/\/cloud.ibm.com\/apidocs\/discovery-datalistfields) \n\n\n\n\n\n\n\n Configurations \n\nThe v2 API does not have an endpoint that is dedicated to configurations. Instead, configuration settings for projects, collections, and queries are specified directly in the API for those objects. Not all of the configuration parameters that are available in v1 are available or applicable in v2.\n\nIn the [v1 configuration API](https:\/\/cloud.ibm.com\/apidocs\/discoverycreateconfiguration), the JSON object that is used to specify a configuration object contains several parameters that are either available in different formats from other v2 endpoints or are not available in v2. The following table describes how to find related parameters in v2.\n\nYou cannot customize the conversion of documents during the ingestion process in v2 as you can in v1.\n\n\n\nConfiguration setting details\n\n v1 configuration parameter v2 API \n\n \"conversions.html\": { ... } Not available \n \"conversions.image_text_recognition\": { ... } Not available from the API. However, you can enable optical character recognition (OCR) for a collection from the product user interface to extract text from images. OCR has other benefits, too. For example, if a page in a document can't be processed, OCR converts the page into an image and scans it to ensure that the document is uploaded successfully. \n \"conversions.json_normalizations\": { ... } Moved to the [Collections API](https:\/\/cloud.ibm.com\/apidocs\/discovery-datalistcollections). \n \"conversions.pdf\": { ... } Not available. If you used special parameters to extract text from images in PDFs, enable optical character recognition (OCR) from the product user interface for the collection that contains the PDFs instead. \n \"conversions.segment\": { ...","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2-api"},{"document_id":"ibmcld_03043-1537-3553","score":18.8553934181,"text":"\nTo train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.\n* [Dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-build): A dialog is a branching conversation flow that defines how your application responds when it recognizes the defined intents and entities. You use the dialog editor in the tool to create conversations with users, providing responses based on the intents and entities that you recognize in their input.\n\n![Diagram of a basic implementation that uses intent and dialog only.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/basic-impl.png)\n\n\n\nTo enable your dialog skill to handle more nuanced questions, define entities and reference them from your dialog.\n\n\n\n* [Entities](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-entities); An entity represents a term or object that is relevant to your intents and that provides a specific context for an intent. For example, an entity might represent a city where the user wants to find a business location, or the amount of a bill payment. In the tool, the name of an entity is always prefixed with the @ character.\n\nYou can train the skill to recognize your entities by providing entity term values and synonyms, entity patterns, or by identifying the context in which an entity is typically used in a sentence. To fine tune your dialog, go back and add nodes that check for entity mentions in user input in addition to intents.\n\n\n\n![Diagram of a more complex implementation that uses intent, entity, and dialog.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add"},{"document_id":"ibmcld_10143-7-2020","score":18.7730193651,"text":"\nWhy can't I view or work with my cluster? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\n What\u2019s happening \n\nYou are not able to find a cluster. When you run ibmcloud oc cluster ls, the cluster is not listed in the output.\n\nOr, you are not able to work with a cluster. When you run ibmcloud oc cluster config or other cluster-specific commands, the cluster is not found.\n\n Why it\u2019s happening \n\nIn IBM Cloud, each resource must be in a resource group. For example, cluster mycluster might exist in the default resource group.\n\nWhen the account owner gives you access to resources by assigning you an IBM Cloud IAM platform access role, the access can be to a specific resource or to the resource group. When you are given access to a specific resource, you don't have access to the resource group. In this case, you don't need to target a resource group to work with the clusters you have access to. If you target a different resource group than the group that the cluster is in, actions against that cluster can fail. Conversely, when you are given access to a resource as part of your access to a resource group, you must target a resource group to work with a cluster in that group. If you don't target your CLI session to the resource group that the cluster is in, actions against that cluster can fail.\n\nIf you can't find or work with a cluster, you might be experiencing one of the following issues:\n\n\n\n* You have access to the cluster and the resource group that the cluster is in, but your CLI session is not targeted to the resource group that the cluster is in.\n* You have access to the cluster, but not as part of the resource group that the cluster is in. Your CLI session is targeted to this or another resource group.\n* You don't have access to the cluster.\n\n\n\n How to fix it \n\nTo check your user access permissions:\n\n\n\n1. List all your user permissions.\n\nibmcloud iam user-policies <your_user_name>\n2. Check if you have access to the cluster and to the resource group that the cluster is in.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cluster_access"},{"document_id":"ibmcld_05690-7-2020","score":18.7730193651,"text":"\nWhy can't I view or work with my cluster? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\n What\u2019s happening \n\nYou are not able to find a cluster. When you run ibmcloud ks cluster ls, the cluster is not listed in the output.\n\nOr, you are not able to work with a cluster. When you run ibmcloud ks cluster config or other cluster-specific commands, the cluster is not found.\n\n Why it\u2019s happening \n\nIn IBM Cloud, each resource must be in a resource group. For example, cluster mycluster might exist in the default resource group.\n\nWhen the account owner gives you access to resources by assigning you an IBM Cloud IAM platform access role, the access can be to a specific resource or to the resource group. When you are given access to a specific resource, you don't have access to the resource group. In this case, you don't need to target a resource group to work with the clusters you have access to. If you target a different resource group than the group that the cluster is in, actions against that cluster can fail. Conversely, when you are given access to a resource as part of your access to a resource group, you must target a resource group to work with a cluster in that group. If you don't target your CLI session to the resource group that the cluster is in, actions against that cluster can fail.\n\nIf you can't find or work with a cluster, you might be experiencing one of the following issues:\n\n\n\n* You have access to the cluster and the resource group that the cluster is in, but your CLI session is not targeted to the resource group that the cluster is in.\n* You have access to the cluster, but not as part of the resource group that the cluster is in. Your CLI session is targeted to this or another resource group.\n* You don't have access to the cluster.\n\n\n\n How to fix it \n\nTo check your user access permissions:\n\n\n\n1. List all your user permissions.\n\nibmcloud iam user-policies <your_user_name>\n2. Check if you have access to the cluster and to the resource group that the cluster is in.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_cluster_access"},{"document_id":"ibmcld_16259-1485-3642","score":18.3488120999,"text":"\nUnique user is anyone who interacts with your assistant. User ID identifies each user, using a unique label to track the level of service usage. A unique user can have multiple conversations, but a conversation never has more than one unique user.\n\nConversation is a set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back. Conversations can have multiple requests within a single conversation, but a single request doesn't span more than 1 conversation.\n\nRequest is a root-level utterance, such as an initial question or request, that signals the start of a specific flow. A user can initiate multiple requests. Requests are meant to represent the core concepts or topics your users are asking about. A request can have multiple steps within it, for example I want to order a pizza is a request. Delivery\/takeout, Small\/Medium\/Large, Cheese\/Pepperoni\/Mushrooms\/Peppers are all steps within the request of ordering a pizza.\n\n\n\n\n\n Completion and recognition \n\nThe completion and recognition charts provide information about the actions in your assistant.\n\n![Completion and recognition](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-completion-recognition-2.png)\n\n\n\n Completion \n\nCompletion is the measurement of how often users are able to successfully get through all steps of an action.\n\nYour assistant measures when someone reaches the final step of an action. The completion chart provides an overview of all the actions you have built and how many of these are being completed or not.\n\nCompletion is only applicable when a user question or request matched to an action, and the action starts.\n\nOne action can be triggered multiple times, so to better understand individual action performance, click Action completion to understand each action in more detail.\n\n\n\n\n\n Recognition \n\nRecognition is the measurement of how many requests are being recognized by the assistant and routed into starting an action.\n\nThe recognition chart provides you with a view into how many requests are matched to actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02737-16787-18553","score":14.8154832064,"text":"\nCloud Directory change password appid.cloud-dir-user-credentials.update success 200 [appid user CRN] cloud_directory:[GUID] appid\/cloud_dir\/user \n Cloud Directory change password failure appid.cloud-dir-user-credentials.update failure 400 crn:unknown cloud_directory:unknown \n Revoke user tokens appid.user-tokens.revoke success 200 appid user CRN idp:[GUID] appid\/user \n Revoke user tokens failure appid.user-tokens.revoke failure 400 appid user CRN idp:[GUID] appid\/user \n Cloud Directory user SSO logout appid.cloud-dir-user.set-off success 200 appid user CRN idp:[GUID] appid\/user \n View user profile attributes appid.user-profile-attributes.read success 200 crn:profiles:[User-ID] profiles:[User-ID] appid-user-profiles\/attributes \n Update user profile attribute appid.user-profile-attributes.update success 200 crn:profiles:[User-ID] profiles:[User-ID] appid-user-profiles\/attribute\/[Attribute-name] \n Delete user profile attribute appid.user-profile-attributes.delete success 200 crn:profiles:[User-ID] profiles:[User-ID] appid-user-profiles\/attribute\/[Attribute-name] \n\n\n\n\n\n\n\n Analyzing runtime events \n\nA user that generates a runtime event is identified as a GUID rather than by name or email. As the account owner, you can use the GUID to identify a specific user and then you can search to see all the events that the user triggered.\n\nThe following scenario works only for Cloud Directory users. If the user is defined by an external IdP such as Google or Facebook, only that identity provider can interpret the GUID.\n\n\n\n Extracting user information from the GUID \n\nAn event in the Activity Tracker console contains the following fields.\n\n\n\nTable 3. Example fields that can be found in an event from the Activity Tracker console\n\n Field Value Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-at-events"},{"document_id":"ibmcld_04377-7-1819","score":14.4558090126,"text":"\nManaging accounts and users (ibmcloud account) \n\nUse the following commands from the IBM Cloud\u00ae Command Line Interface to manage accounts and users in an account.\n\n\n\n ibmcloud account orgs \n\nList all organizations:\n\nibmcloud account orgs [-r REGION_NAME] [--guid] [-c ACCOUNT_ID] [-u ACCOUNT_OWNER]\n\n\n\n Command options \n\n-r REGION_NAME\n: Region name. List the organizations in the region specified. Default to current region if not specified. If set to 'all', list the organizations in all regions.\n\n--guid\n: Display the guid of the organizations. This option is exclusive with --output.\n\n-c ACCOUNT_ID\n: Account ID. List the organizations under the account. Default to current account if not specified. If set to all, list organizations under all accounts. This option is exclusive with -u.\n\n-u ACCOUNT_OWNER\n: Account owner name. List the organizations under the accounts that are owned by the user. Default to current account if not specified. If set to 'all', list organizations under all accounts. This option is exclusive with -c.\n\n\n\n\n\n Examples \n\nList all the organizations in region us-south with the GUID displayed:\n\nibmcloud account orgs -r us-south --guid\n\nList all the organizations in JSON format:\n\nibmcloud account orgs --output JSON\n\n\n\n\n\n\n\n ibmcloud account org \n\nShow the information of the specified organization:\n\nibmcloud account org ORG_NAME [-r REGION] [--guid]\n\n\n\n Command options \n\nORG_NAME (required)\n: The name of the organization.\n\n-r REGION\n: Region name. If not specified, the default is current region. If set to all, orgs with the given name in all regions are listed.\n\n--guid\n: Retrieve and display the org's guid. All other output for the org is suppressed. This option is exclusive with --output.\n\n\n\n\n\n Examples \n\nShow the information of organization IBM with the GUID displayed:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_account"},{"document_id":"ibmcld_02737-17991-19654","score":14.0712211039,"text":"\nAs the account owner, you can use the GUID to identify a specific user and then you can search to see all the events that the user triggered.\n\nThe following scenario works only for Cloud Directory users. If the user is defined by an external IdP such as Google or Facebook, only that identity provider can interpret the GUID.\n\n\n\n Extracting user information from the GUID \n\nAn event in the Activity Tracker console contains the following fields.\n\n\n\nTable 3. Example fields that can be found in an event from the Activity Tracker console\n\n Field Value Description \n\n initiator.id cb967e0d-43c1-454a-968d-0efa24766846 The tenant ID. \n target.name cloud_directory:34e1ea6d-cc02-4941-9462-7e9c5a40b360 The user ID. \n\n\n\nTo find the user information that aligns with the event GUID, use the following steps.\n\n\n\n1. In the Credentials tab of the App ID dashboard, copy, and save the information in the apiKey and tenantID fields. The tenant ID should match the ID of the event. If no credentials exist, create a set.\n2. Obtain an IAM token for the apiKey by inserting the key into the following command:\n\ncurl -k -X POST --header \"Content-Type: application\/x-www-form-urlencoded\" --header \"Accept: application\/json\" --data-urlencode \"grant_type=urn:ibm:params:oauth:grant-type:apikey\" --data-urlencode \"apikey=<apiKey>\" \"https:\/\/iam.cloud.ibm.com\/identity\/token\"\n3. Copy the IAM token from the access_token field in the response.\n4. Select a region. Learn more about the [available regions](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-regions-endpoints).\n5. Insert the IAM token, the tenant ID, and the user ID, into the following command to obtain the user information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-at-events"},{"document_id":"ibmcld_16582-11984-13516","score":14.0555845245,"text":"\nibmcloud watson-query primary-catalog\n\n\n\n\n\n\n\n ibmcloud watson-query primary-catalog-set \n\nInsert primary catalog ID into table DVSYS.INSTANCE_INFO.\n\nibmcloud watson-query primary-catalog-set --guid GUID\n\n\n\n Command options \n\n--guid (string)\n: Primary catalog ID. Required.\n\n\n\n\n\n Examples \n\nInsert primary catalog ID into table DVSYS.INSTANCE_INFO\n\nibmcloud watson-query primary-catalog-set --guid d77fc432-9b1a-4938-a2a5-9f37e08041f6\n\n\n\n\n\n\n\n ibmcloud watson-query primary-catalog-delete \n\nRemove the setting of the primary catalog for enforced publication.\n\nibmcloud watson-query primary-catalog-delete --guid GUID\n\n\n\n Command options \n\n--guid (string)\n: The watson query user name, if the value is PUBLIC, it means revoke access privilege from all watson query users. Required.\n\n\n\n\n\n\n\n\n\n Publish objects \n\nPublish virtualized table to WKC.\n\n\n\n ibmcloud watson-query virtualized-table-publish \n\nPublish virtualized tables to WKC.\n\nibmcloud watson-query virtualized-table-publish --catalog-id CATALOG-ID --allow-duplicates ALLOW-DUPLICATES --assets ASSETS\n\n\n\n Command options \n\n--catalog-id (string)\n: Catalog ID. Required.\n\n--allow-duplicates (bool)\n: Whether duplicated asset allowd. Required.\n\n--assets ([CatalogPublishParametersAssetsItem[]](https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugin?topic=watson-query-cli-plugin-CLI-namecli-catalog-publish-parameters-assets-item-example-schema))\n: Asset description. Example: \"[{\"schema\": \"db2inst1\",\"table\": \"employee\"}]\". Required.\n\n\n\n\n\n Examples \n\nPublish virtualized tables to WKC","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugin?topic=watson-query-cli-plugin-CLI-name"},{"document_id":"ibmcld_11618-6258-7984","score":13.8840600357,"text":"\n* [How to create an SAP S-user ID](https:\/\/www.youtube.com\/watch?v=4wICiRTP8u0) Note that only super administrators or S-users with the required authorization are allowed to create S-user IDs for your company's SAP Customer Number (SCN)\n* The [Guide Finder for SAP NetWeaver and ABAP Platform](https:\/\/help.sap.com\/viewer\/nwguidefinder) to search for SAP NetWeaver-related documentation, including installation guides.\n* Applicable [installation guides](https:\/\/support.sap.com\/en\/my-support\/software-downloads.html); requires an SAP S-user ID.\n* SAP release notes, which can be found in the application help of the relevant SAP product documentation on the [SAP Help Portal](https:\/\/help.sap.com\/viewer\/index); requires an SAP S-user ID.\n* [SAP HANA Help](https:\/\/help.sap.com\/viewer\/product\/SAP_HANA_PLATFORM)\n* [SAP NetWeaver Help](https:\/\/help.sap.com\/viewer\/product\/SAP_NETWEAVER\/ALL\/en-US)\n* [SAP HANA Installation Guide](https:\/\/www.sap.com\/products\/hana\/technical.html)\n* [SAP Product Availability Matrix (PAM)](https:\/\/support.sap.com\/en\/release-upgrade-maintenance.htmlsection_1969201630); requires an SAP S-user ID.\n* [SAP Notes](https:\/\/support.sap.com\/en\/my-support\/knowledge-base.html); requires an SAP S-user ID.\n* Third-party documentation\n\n\n\n\n\n\n\n Selecting your SAP-certified infrastructure \n\nThe below expands on the introducton [Comparing the different SAP-certified IaaS offerings](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-overviewiaas-offerings-compare-summary), which summarises the benefits of each different Infrastructure option.\n\nYou are ready to define the number of host servers and size of those hosts after:\n\n\n\n* the business has defined their requirements\n* decided which SAP applications to use","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-planning-your-system-landscape"},{"document_id":"ibmcld_02737-13858-15787","score":13.8597488749,"text":"\n5. From the Observability > Activity Tracker tab in the console navigation, verify the information for the instance that you created.\n6. Click Open Dashboard. When the dashboard loads, you see an overall view of all the activity in your account. You can use the search operators to filter your results by tags, sources, apps, or levels. You can also search for specific events or jump to a specific timeframe.\n7. From the All Apps drop-down, select the instance of App ID that you want to track events for.\n\n\n\n\n\n\n\n\n\n List of runtime events \n\nCheck out the following table for a list of the runtime events that are sent to Activity Tracker.\n\nBe sure that you turned on Runtime Activity to see these events.\n\n\n\nTable 2. Actions that can be tracked as authentication events at runtime\n\n Description Action Outcome reason. reasonCode target.id target.name target.typeURI \n\n Cloud Directory authentication success appid.user.authenticate success 200 [appid user CRN] cloud_directory:[GUID] appid\/user \n Cloud Directory authentication failure appid.user.authenticate failure 401 [appid user CRN] cloud_directory:[GUID] appid\/user \n Facebook authentication success appid.user.authenticate success 200 [appid user CRN] facebook:[GUID] appid\/user \n Facebook authentication failure appid.user.authenticate failure 401 crn:unknown facebook:unknown appid\/user \n Google authentication success appid.user.authenticate success 200 [appid user CRN] google:[GUID] appid\/user \n Google authentication failure appid.user.authenticate failure 401 crn:unknown google:unknown appid\/user \n SAML authentication success appid.user.authenticate success 200 [appid user CRN] SAML:[GUID] appid\/user \n SAML authentication failure appid.user.authenticate failure 401 crn:unknown SAML:unknown appid\/user \n Client Credentials authentication success appid.application.authenticate success 200 [appid application CRN] client_credentials:client_id appid\/application","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-at-events"},{"document_id":"ibmcld_02737-15318-17156","score":13.5677954718,"text":"\nGoogle authentication failure appid.user.authenticate failure 401 crn:unknown google:unknown appid\/user \n SAML authentication success appid.user.authenticate success 200 [appid user CRN] SAML:[GUID] appid\/user \n SAML authentication failure appid.user.authenticate failure 401 crn:unknown SAML:unknown appid\/user \n Client Credentials authentication success appid.application.authenticate success 200 [appid application CRN] client_credentials:client_id appid\/application \n Client Credentials authentication failure appid.application.authenticate failure 401 crn:undefined client_credentials:undefined appid\/application \n Cloud Directory sign up appid.cloud-dir-user.create success 200 [appid user CRN] cloud_directory:[GUID] appid\/cloud_dir\/user \n Cloud Directory signup failure appid.cloud-dir-user.create failure 400 crn:unknown cloud_directory:unknown appid\/cloud_dir\/user \n Cloud Directory signup confirmation appid.cloud-dir-user.allow success 200 [appid user CRN] cloud_directory:[GUID] appid\/cloud_dir\/user \n Cloud Directory signup confirmation failure appid.cloud-dir-user.allow failure 400 crn:unknown cloud_directory:unknown appid\/cloud_dir\/user \n Cloud Directory reset or renew password appid.cloud-dir-user-credentials.renew success 200 [appid user CRN] cloud_directory:[GUID] appid\/cloud_dir\/user \n Cloud Directory reset or renew password failure appid.cloud-dir-user-credentials.renew failure 400 crn:unknown cloud_directory:unknown appid\/cloud_dir\/user \n Cloud Directory change password appid.cloud-dir-user-credentials.update success 200 [appid user CRN] cloud_directory:[GUID] appid\/cloud_dir\/user \n Cloud Directory change password failure appid.cloud-dir-user-credentials.update failure 400 crn:unknown cloud_directory:unknown \n Revoke user tokens appid.user-tokens.revoke success 200 appid user CRN idp:[GUID] appid\/user","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-at-events"},{"document_id":"ibmcld_12571-18291-19924","score":13.407221361,"text":"\nibmcloud iam user-policy-create name@example.com --roles Viewer --service-name is --attributes \"instanceId=\"\n\n\n\n\n\n\n\n ibmcloud iam user-policy-update \n\nUpdate an access policy for the specified user in the current account:\n\nibmcloud iam user-policy-update USER_NAME POLICY_ID {--file JSON_FILE | [--roles ROLE_NAME1,ROLE_NAME2...] [--service-name SERVICE_NAME] [--service-instance SERVICE_INSTANCE_GUID] [--region REGION] [--resource-type RESOURCE_TYPE] [--resource RESOURCE] [--resource-group-name RESOURCE_GROUP_NAME] [--resource-group-id RESOURCE_GROUP_ID] [--account-management] [--attributes name=value,name=value...]} [--output FORMAT] [-q, --quiet] [--api-version v1 | v2]\n\n\n\n Command options \n\nUSER_NAME (required)\n: User name to whom the policy belongs to.\n\nPOLICY_ID (required)\n: ID of the policy to update. --file FILE (optional)\n: JSON file of policy definition.\n\n--roles ROLE_NAME1,ROLE_NAME2... (optional)\n: Role names of the policy definition. For supported roles of a specific service, run ibmcloud iam roles --service SERVICE_NAME option. This option is exclusive with the --file option.\n\n--service-name SERVICE_NAME (optional)\n: Service name of the policy definition. This option is exclusive with the --file option.\n\n--service-instance SERVICE_INSTANCE_GUID (optional)\n: GUID of service instance of the policy definition. This option is exclusive with the --file option.\n\n--region REGION (optional)\n: Region of the policy definition. This option is exclusive with the --file option.\n\n--resource-type RESOURCE_TYPE (optional)\n: Resource type of the policy definition. This option is exclusive with the --file option.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-ibmcloud_commands_iam"},{"document_id":"ibmcld_05647-6456-7791","score":13.1549133079,"text":"\nTo modify the way the ALB matches the request URI against the app path, use the following Kubernetes Ingress resource [annotation](https:\/\/kubernetes.github.io\/ingress-nginx\/user-guide\/nginx-configuration\/annotations\/use-regex).\n\nnginx.ingress.kubernetes.io\/use-regex: \"true\"\n\nFor more info, see [this blog](https:\/\/kubernetes.github.io\/ingress-nginx\/user-guide\/ingress-path-matching\/ingress-path-matching).\n\n\n\n\n\n Adding custom location block configurations \n\nTo add a custom location block configuration for a service, use the following Kubernetes Ingress resource [annotation](https:\/\/kubernetes.github.io\/ingress-nginx\/user-guide\/nginx-configuration\/annotations\/configuration-snippet).\n\nnginx.ingress.kubernetes.io\/configuration-snippet: \nmore_set_headers \"Request-Id: $req_id\";\n\n\n\n\n\n Configuring mutual authentication \n\nTo configure mutual authentication for the ALB, use the following Kubernetes Ingress resource [annotations](https:\/\/kubernetes.github.io\/ingress-nginx\/user-guide\/nginx-configuration\/annotations\/client-certificate-authentication). Note that mutual authentication can't be applied to custom ports and must be applied to the HTTPS port.\n\nnginx.ingress.kubernetes.io\/auth-tls-verify-client: \"on\"\nnginx.ingress.kubernetes.io\/auth-tls-secret: \"default\/ca-secret\"\nnginx.ingress.kubernetes.io\/auth-tls-verify-depth: \"1\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-comm-ingress-annotations"},{"document_id":"ibmcld_16567-12215-13777","score":13.0786676887,"text":"\nibmcloud watson-query primary-catalog-set --guid d77fc432-9b1a-4938-a2a5-9f37e08041f6\n\n\n\n\n\n\n\n ibmcloud watson-query primary-catalog-delete \n\nRemove the setting of the primary catalog for enforced publication.\n\nibmcloud watson-query primary-catalog-delete --guid GUID\n\n\n\n Command options \n\n--guid (string)\n: The watson query user name, if the value is PUBLIC, it means revoke access privilege from all watson query users. Required.\n\n\n\n\n\n\n\n\n\n Publish objects \n\nPublish virtualized table to WKC.\n\n\n\n ibmcloud watson-query virtualized-table-publish \n\nPublish virtualized tables to WKC.\n\nibmcloud watson-query virtualized-table-publish --catalog-id CATALOG-ID --allow-duplicates ALLOW-DUPLICATES --assets ASSETS\n\n\n\n Command options \n\n--catalog-id (string)\n: Catalog ID. Required.\n\n--allow-duplicates (bool)\n: Whether duplicated asset allowd. Required.\n\n--assets ([CatalogPublishParametersAssetsItem[]](https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugincli-catalog-publish-parameters-assets-item-example-schema))\n: Asset description. Example: \"[{\"schema\": \"db2inst1\",\"table\": \"employee\"}]\". Required.\n\n\n\n\n\n Examples \n\nPublish virtualized tables to WKC\n\nibmcloud watson-query virtualized-table-publish --catalog-id 12c60f7e-c366-4cda-ba3a-bfbb577a5f56 --allow-duplicates true --virtualized-schema DV_IBMID_6610020D12 --virtualized-table EMPLOYEE\n\n\n\n\n\n\n\n\n\n Schema examples \n\nThe following schema examples represent the data that you need to specify for a command option. These examples model the data structure and include placeholder values for the expected value type.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugin"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07765-0-1628","score":23.9516665374,"text":"\n\n\n\n\n\n\n  IA-5 (4) - Automated Support for Password Strength Determination \n\n\n\n  Control requirements \n\nIA-5 (4) - 0\n:   The organization employs automated tools to determine if password authenticators are sufficiently strong to satisfy [Assignment: organization-defined requirements].\n\n\n\n\n\n  IBM Cloud for Financial Services profile \n\nThe rules related to this control that follow are part of the IBM Cloud for Financial Services v1.2.0 profile in [IBM Cloud\u00ae Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\n\n\n*  Check whether App ID advanced password policies are enabled\n*  IBMid employs automated tools to determine if password authenticators satisfy IBMid password requirements\n*  Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n*  Check whether App ID password strength regex is configured\n*  Check whether IBMid password policy policy contains spaces or any of the following characters: ;:(\"?)<>\n*  Check whether VPN for VPC authentication is configured with a strong pre-shared key with at least # characters\n*  Check whether IBMid password policy requires at least one uppercase letter\n*  Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n\n\n\n\n\n\n\n  NIST supplemental guidance \n\nThis control enhancement focuses on the creation of strong passwords and the characteristics of such passwords (e.g., complexity) prior to use, the enforcement of which is carried out by organizational information systems in IA-5 (1).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ia-5.4"},{"document_id":"ibmcld_07787-0-1608","score":19.2271576006,"text":"\n\n\n\n\n\n\n  MA-4 - Nonlocal Maintenance \n\n\n\n  Control requirements \n\nThe organization:\n\nMA-4 (a)\n:   Approves and monitors nonlocal maintenance and diagnostic activities;\n\nMA-4 (b)\n:   Allows the use of nonlocal maintenance and diagnostic tools only as consistent with organizational policy and documented in the security plan for the information system;\n\nMA-4 (c)\n:   Employs strong authenticators in the establishment of nonlocal maintenance and diagnostic sessions;\n\nMA-4 (d)\n:   Maintains records for nonlocal maintenance and diagnostic activities; and\n\nMA-4 (e)\n:   Terminates session and network connections when nonlocal maintenance is completed.\n\n\n\n\n\n  NIST supplemental guidance \n\nNonlocal maintenance and diagnostic activities are those activities conducted by individuals communicating through a network, either an external network (e.g., the Internet) or an internal network. Local maintenance and diagnostic activities are those activities carried out by individuals physically present at the information system or information system component and not communicating across a network connection. Authentication techniques used in the establishment of nonlocal maintenance and diagnostic sessions reflect the network access requirements in IA-2. Typically, strong authentication requires authenticators that are resistant to replay attacks and employ multifactor authentication. Strong authenticators include, for example, PKI where certificates are stored on a token protected by a password, passphrase, or biometric. Enforcing requirements in MA-4 is accomplished in part by other controls.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ma-4"},{"document_id":"ibmcld_02746-7-1681","score":17.9239658218,"text":"\nDefining password policies \n\nPassword policies, such as strength requirements, help you to enforce more secure applications. By defining advanced policies, you can define the rules that a user must conform to when they set their password or attempt to sign in to your app. For example, you can set the number of times that a user can try to sign in before they are locked out of their account.\n\n\n\n Policy: password strength \n\nA strong password makes it difficult, or even improbable for someone to guess the password in either a manual or automated way. To set requirements for the strength of a user's password, you can use the following steps.\n\nTo set this configuration by using the GUI:\n\n\n\n1. Go to the Cloud Directory > Password policies tab of the App ID dashboard.\n2. In the Define password strength box, click Edit. A screen opens.\n3. Enter a valid regex string in the Password strength box.\n\nExamples:\n\n\n\n* Must be at least 8 characters. (^.{8,}$)\n* Must have one number, one lowercase letter, and one capital letter. (^(?:(?=.d)(?=.[a-z])(?=.[A-Z]).)$)\n* Must have only English letters and numbers. (^[A-Za-z0-9]$)\n* Must have at least one unique character. (^(w)w?(?!1)w+$)\n\n\n\n4. Click Save.\n\n\n\nPassword strength can be set in the Cloud Directory settings page in the App ID dashboard, or by using [the management APIs](https:\/\/us-south.appid.cloud.ibm.com\/swagger-ui\/\/Management%20API%20-%20Config\/mgmt.set_cloud_directory_password_regex).\n\n\n\n Setting a custom error message \n\nIf you set your own password regex policy and a user chooses a password that does not meet your requirements, the default message is The password doesn't meet the strength requirements.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strength"},{"document_id":"ibmcld_00708-54925-56282","score":17.771681692,"text":"\nrule-e76a3a81-b0d0-41fc-947d-13dc9cfff379 - Check whether IBMid password policy prevents password reuse below the minimum of \nrule-759d504b-9eed-4602-8b5b-7244bf3f5690 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\nrule-bcbd57e1-3cdc-4b6d-820b-2c63bc777e19 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"?)<>\nrule-fa06f6f2-b98e-49ac-aa55-d57de9e320d3 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\nrule-548a3321-6a39-400c-9c2d-0df9a13afd02 - Check whether IAM roles are used to create IAM policies for IBM resources\nrule-726ec899-505e-4de9-ac1b-9578ef62f89f - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\nrule-962e2bde-2a4f-4e07-a352-ce17708b1e85 - Check whether API keys are not created in IAM during the initial setup of IAM users\nrule-61fa114a-2bb9-43fd-8068-b873b48bdf79 - Check whether IAM users are attached to at least one access group\nrule-4d86c074-097e-4ff3-a763-ccff128388e2 - Check whether multifactor authentication (MFA) is enabled at the account level\nrule-0704e840-e443-4781-b9be-ec57469d09c1 - Check whether permissions for API key creation are limited and configured in IAM settings for the account owner","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cra-cli-plugin"},{"document_id":"ibmcld_00684-54925-56282","score":17.771681692,"text":"\nrule-e76a3a81-b0d0-41fc-947d-13dc9cfff379 - Check whether IBMid password policy prevents password reuse below the minimum of \nrule-759d504b-9eed-4602-8b5b-7244bf3f5690 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\nrule-bcbd57e1-3cdc-4b6d-820b-2c63bc777e19 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"?)<>\nrule-fa06f6f2-b98e-49ac-aa55-d57de9e320d3 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\nrule-548a3321-6a39-400c-9c2d-0df9a13afd02 - Check whether IAM roles are used to create IAM policies for IBM resources\nrule-726ec899-505e-4de9-ac1b-9578ef62f89f - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\nrule-962e2bde-2a4f-4e07-a352-ce17708b1e85 - Check whether API keys are not created in IAM during the initial setup of IAM users\nrule-61fa114a-2bb9-43fd-8068-b873b48bdf79 - Check whether IAM users are attached to at least one access group\nrule-4d86c074-097e-4ff3-a763-ccff128388e2 - Check whether multifactor authentication (MFA) is enabled at the account level\nrule-0704e840-e443-4781-b9be-ec57469d09c1 - Check whether permissions for API key creation are limited and configured in IAM settings for the account owner","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd-configure-cra-repos"},{"document_id":"ibmcld_04341-54906-56263","score":17.771681692,"text":"\nrule-e76a3a81-b0d0-41fc-947d-13dc9cfff379 - Check whether IBMid password policy prevents password reuse below the minimum of \nrule-759d504b-9eed-4602-8b5b-7244bf3f5690 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\nrule-bcbd57e1-3cdc-4b6d-820b-2c63bc777e19 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"?)<>\nrule-fa06f6f2-b98e-49ac-aa55-d57de9e320d3 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\nrule-548a3321-6a39-400c-9c2d-0df9a13afd02 - Check whether IAM roles are used to create IAM policies for IBM resources\nrule-726ec899-505e-4de9-ac1b-9578ef62f89f - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\nrule-962e2bde-2a4f-4e07-a352-ce17708b1e85 - Check whether API keys are not created in IAM during the initial setup of IAM users\nrule-61fa114a-2bb9-43fd-8068-b873b48bdf79 - Check whether IAM users are attached to at least one access group\nrule-4d86c074-097e-4ff3-a763-ccff128388e2 - Check whether multifactor authentication (MFA) is enabled at the account level\nrule-0704e840-e443-4781-b9be-ec57469d09c1 - Check whether permissions for API key creation are limited and configured in IAM settings for the account owner","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cra-cli-plugin"},{"document_id":"ibmcld_00708-32460-34303","score":17.1194247208,"text":"\n\"no_pre_shared_key_characters\": 30,\n\"dns_port\": 60,\n\"vm_nic_count\": 1,\n\"no_of_admins_for_container_registry \": 3,\n\"no_of_service_id_admins_for_container_registry\": 3,\n\"no_of_managers_for_container_registry\": 0,\n\"no_of_service_id_managers_for_container_registry\": 0,\n\"access_tokens_expire\": 120\n}\n}\nShow more\n\n\n\n\n\n\n\n Security and Compliance Center goals \n\nThe Terraform Analyzer supports the following Security and Compliance Center goals:\n\n3000001 - Check whether IBMid password policy requires at least one uppercase letter\n3000002 - Check whether IBMid password policy requires at least one lowercase letter\n3000003 - Check whether IBMid password policy requires at least one number\n3000004 - Check whether IBMid password policy requires minimum length of 12 characters\n3000005 - Check whether IBMid password policy prevents password reuse below the minimum of \n3000006 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n3000007 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"\"?)<>\"\n3000008 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n3000009 - Check whether IAM roles are used to create IAM policies for IBM resources\n3000010 - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\n3000011 - Check whether API keys are not created in IAM during the initial setup of IAM users\n3000015 - Check whether IAM users are attached to at least one access group\n3000016 - Check whether IAM policies for users are attached only to groups or roles\n3000030 - Check whether IAM policies for service IDs are attached only to groups or roles\n3000017 - Check whether multifactor authentication (MFA) is enabled at the account level","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cra-cli-plugin"},{"document_id":"ibmcld_00684-32460-34303","score":17.1194247208,"text":"\n\"no_pre_shared_key_characters\": 30,\n\"dns_port\": 60,\n\"vm_nic_count\": 1,\n\"no_of_admins_for_container_registry \": 3,\n\"no_of_service_id_admins_for_container_registry\": 3,\n\"no_of_managers_for_container_registry\": 0,\n\"no_of_service_id_managers_for_container_registry\": 0,\n\"access_tokens_expire\": 120\n}\n}\nShow more\n\n\n\n\n\n\n\n Security and Compliance Center goals \n\nThe Terraform Analyzer supports the following Security and Compliance Center goals:\n\n3000001 - Check whether IBMid password policy requires at least one uppercase letter\n3000002 - Check whether IBMid password policy requires at least one lowercase letter\n3000003 - Check whether IBMid password policy requires at least one number\n3000004 - Check whether IBMid password policy requires minimum length of 12 characters\n3000005 - Check whether IBMid password policy prevents password reuse below the minimum of \n3000006 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n3000007 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"\"?)<>\"\n3000008 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n3000009 - Check whether IAM roles are used to create IAM policies for IBM resources\n3000010 - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\n3000011 - Check whether API keys are not created in IAM during the initial setup of IAM users\n3000015 - Check whether IAM users are attached to at least one access group\n3000016 - Check whether IAM policies for users are attached only to groups or roles\n3000030 - Check whether IAM policies for service IDs are attached only to groups or roles\n3000017 - Check whether multifactor authentication (MFA) is enabled at the account level","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd-configure-cra-repos"},{"document_id":"ibmcld_04341-32441-34284","score":17.1194247208,"text":"\n\"no_pre_shared_key_characters\": 30,\n\"dns_port\": 60,\n\"vm_nic_count\": 1,\n\"no_of_admins_for_container_registry \": 3,\n\"no_of_service_id_admins_for_container_registry\": 3,\n\"no_of_managers_for_container_registry\": 0,\n\"no_of_service_id_managers_for_container_registry\": 0,\n\"access_tokens_expire\": 120\n}\n}\nShow more\n\n\n\n\n\n\n\n Security and Compliance Center goals \n\nThe Terraform Analyzer supports the following Security and Compliance Center goals:\n\n3000001 - Check whether IBMid password policy requires at least one uppercase letter\n3000002 - Check whether IBMid password policy requires at least one lowercase letter\n3000003 - Check whether IBMid password policy requires at least one number\n3000004 - Check whether IBMid password policy requires minimum length of 12 characters\n3000005 - Check whether IBMid password policy prevents password reuse below the minimum of \n3000006 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n3000007 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"\"?)<>\"\n3000008 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n3000009 - Check whether IAM roles are used to create IAM policies for IBM resources\n3000010 - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\n3000011 - Check whether API keys are not created in IAM during the initial setup of IAM users\n3000015 - Check whether IAM users are attached to at least one access group\n3000016 - Check whether IAM policies for users are attached only to groups or roles\n3000030 - Check whether IAM policies for service IDs are attached only to groups or roles\n3000017 - Check whether multifactor authentication (MFA) is enabled at the account level","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cra-cli-plugin"},{"document_id":"ibmcld_03638-1509-3624","score":16.7874386201,"text":"\nYou can record these details for both an individual device and for all devices associated with your account:\n\n\n\n* View individual device IPs from the Device List.\n* View individual device root passwords in the Snapshot View for the device.\n* View multiple device IPs by using the Download CSV option from the Device List. Then, select Download CSV from the Settings cog to download a full list of devices and details in spreadsheet format.\n\n\n\n4. Update the credentials for operating systems and other software. All of the software that was loaded onto your device during the provisioning process was assigned temporary credentials. You can view and manage these credentials on the Passwords tab of each device in the IBM Cloud\u00ae console. Use these temporary credentials to access your software for the first time. Then, change the password to your software by following strong password practices. Create a password that consists of a combination of letters, numbers, and symbols. Optionally, you can store password updates on the Passwords tab for each device. However, when you store passwords, any person with access to the account and appropriate permissions can view the passwords that are stored on the Passwords screen.\n5. Access your server on the private network. You can use the IBM Cloud infrastructure private network to interact with your devices through remote desktop (RDP) by using SSH and KVM over IP. You can use the VPN Access tool for private network connection to either the closest SSL VPN endpoint or to the endpoint of your choice. VPN access is also required to interact with several services. To access the private network, edit the user\u2019s VPN access from the User List. To access the User List, click Account > Users > User list. Use the [Virtual Private Network](https:\/\/www.ibm.com\/cloud\/vpn-access) page to connect to one of the various VPN options.\n6. After you have your infrastructure and environments up and running, you are ready to set up your monitoring service. IBM Cloud Monitoring gives you insight into the performance and health of your applications, services, and platforms.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/bare-metal?topic=bare-metal-bm-set-up"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.5,"ndcg_cut_5":0.5,"ndcg_cut_10":0.5}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03354-4-1897","score":20.2359593515,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Improve your skill \n\nThe Analytics page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nTo open a list of individual messages between customers and the assistant that uses this dialog skill, select User conversations in the navigation bar.\n\nWhen you open the User conversations page, the default view lists inputs that were submitted to the assistant for the last day, with the newest results first. The top intent (#intent) and any recognized entity (@entity) values used in a message, and the message text are available. For intents that are not recognized, the value shown is Irrelevant. If an entity is not recognized, or has not been provided, the value shown is No entities found.\n\n![Logs default page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/logs_page1.png)\n\nThe User conversations page displays the total number of messages between customers and your assistant. A message is a single utterance that a user sends to the assistant. A conversation typically consists of multiple messages. Therefore, the number of results on the User conversations page is different from the number of conversations that are shown on the Overview page.\n\n\n\n Log limits \n\nThe length of time for which messages are retained depends on your Watson Assistant service plan:\n\nService plan | Chat message retention\n------------------------------------ | ------------------------------------\nEnterprise with Data Isolation | Last 90 days\nEnterprise | Last 30 days\nPremium (legacy) | Last 90 days\nPlus | Last 30 days","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs"},{"document_id":"ibmcld_01178-22864-25119","score":19.4006907718,"text":"\nSegment By Service instance, Service instance name \n\n\n\n\n\n\n\n Number of under in-sync replica partitions \n\nThe number of partitions with fewer than two in-sync replicas.\n\n\n\nTable 18. Number of under in-sync replica partitions metric metadata\n\n Metadata Description \n\n Metric Name ibm_eventstreams_kafka_under_minisr_partitions \n Metric Type gauge \n Value Type none \n Segment By Service instance \n\n\n\nIdeally this value should be zero. A nonzero value might highlight a temporary issue with the cluster.\n\n\n\n\n\n Produce message conversion time \n\nIndicates that the accumulated time spent performing message conversion from clients that are producing by using older protocol versions.\n\n\n\nTable 19. Produce message conversion time metric metadata\n\n Metadata Description \n\n Metric Name ibm_eventstreams_instance_produce_conversions_time_quantile \n Metric Type gauge \n Value Type second \n Segment By Service instance, Quantile, Service instance name \n\n\n\nIdeally zero. A consistent growth in this indicates that some clients are down-level and should be upgraded. Ensure that all clients are at the latest levels.\n\n\n\n\n\n Rebalancing consumer groups \n\nThe number of rebalancing consumer groups in an Event Streams instance.\n\n\n\nTable 20. Rebalancing consumer groups metric metadata\n\n Metadata Description \n\n Metric Name ibm_eventstreams_instance_rebalancing_consumergroups \n Metric Type gauge \n Value Type none \n Segment By Service instance, Service instance name \n\n\n\nWhile it is expected that this figure is occasionally >0 (as broker restarts happen frequently,) sustained high levels suggest that consumers might be restarting frequently and leaving or rejoining the consumer groups. Check you client logs.\n\n\n\n\n\n Reserved disk space percentage \n\nThe percentage of reserved disk space that is required for all allocated partitions if fully used.\n\n\n\nTable 21. Reserved disk space percentage metric metadata\n\n Metadata Description \n\n Metric Name ibm_eventstreams_instance_reserved_disk_space_percent \n Metric Type gauge \n Value Type percent \n Segment By Service instance, Service instance name \n\n\n\nShows the percentage of disk space that would be used if your topics were filled to the extent of their configured retention size.\n\n\n\n\n\n Schema greatest version percentage","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-metrics"},{"document_id":"ibmcld_09994-4281-6432","score":18.9758485486,"text":"\nBETWEEN <TIMESTAMP EXPRESSION 1> AND <TIMESTAMP EXPRESSION 2> Includes all the rows that were valid at any time between TIMESTAMP EXPRESSION 1 and TIMESTAMP EXPRESSION 2 (inclusive), whose insert timestamp is less than or equal to TIMESTAMP EXPRESSION 2 and whose delete timestamp is NULL or is greater than TIMESTAMP EXPRESSION 1. If TIMESTAMP EXPRESSION 1 or TIMESTAMP EXPRESSION 2 is less than the table\u2019s retention start timestamp, an error is returned. If TIMESTAMP EXPRESSION 1 is greater than TIMESTAMP EXPRESSION 2, the query produces no rows. \n\n\n\n\n\n\n\n\n\n Timestamps in time travel queries \n\n\n\n Retention time interval and retention time period \n\nA table\u2019s retention time interval defines the number of days past their delete timestamps that historical (deleted) rows are available for time travel queries. At any given time, the retention time period ends at the current timestamp (date and time) and extends back the given number of days. This is a sliding time window that advances as the current system time advances.\n\n\n\n\n\n Retention lower bound \n\nFor the most part, a table\u2019s retention lower bound is the date and time when the table was defined to be a temporal table. This could have been when you ran the CREATE TABLE command, or the last time you altered the table\u2019s DATA_VERSION_RETENTION_TIME from zero to non-zero.\n\n\n\n\n\n Retention start timestamp \n\nAt the time of defining a table to be temporal (when the retention lower bound is defined), there are no historical rows available over the retention time period. To capture the notion of how far back historical rows are actually available (visible to time travel queries), a table\u2019s retention start timestamp is defined. The retention start timestamp is the larger of the following values:\n\n\n\n* The beginning of the retention time period (the current date\/time minus the retention interval).\n* The retention lower bound.\n\n\n\nA table\u2019s retention start timestamp comes into play in the following operations:\n\n\n\n* Time travel queries (SELECT and sub-SELECT)\n\nIf you attempt to run queries for historical rows that were deleted before the retention start timestamp, an error is returned.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-runningqueries_tt"},{"document_id":"ibmcld_09956-7-2100","score":18.9578586367,"text":"\nManaging the default retention time interval for the system and viewing retention time intervals \n\nBefore you set retention time interval for all tables in a schema or database, consider the cost of storage for temporal tables, which could be significant. See [Managing time travel space usage](https:\/\/cloud.ibm.com\/docs\/docs\/netezza?topic=netezza-managing_tt).\n\n\n\n Setting the retention time interval for the system \n\nTo set the default DATA_VERSION_RETENTION_TIME to a specific value for the system, run the SET SYSTEM DEFAULT command.\n\nBefore you set DATA_VERSION_RETENTION_TIME for all tables in a schema or database, consider the cost of storage for temporal tables, which could be significant. See [Managing time travel space usage](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-managing_tt).\n\nSET SYSTEM DEFAULT DATA_VERSION_RETENTION_TIME TO <NUMBER OF DAYS>\n\nExample:\n\nSET SYSTEM DEFAULT DATA_VERSION_RETENTION_TIME TO 30\n\nThe value of the property at the system level determines the default value inherited by a subsequent CREATE DATABASE statement that does not explicitly specify this property.\n\nTo set DATA_VERSION_RETENTION_TIME for a specific object, you can run the ALTER or CREATE command.\n\n\n\n\n\n Viewing the retention time interval with the command-line \n\n\n\n Viewing the default retention time interval for the system with the command-line \n\nTo view DATA_VERSION_RETENTION_TIME for the system, run the SHOW SYSTEM DEFAULT command.\n\nSHOW SYSTEM DEFAULT DATA_VERSION_RETENTION_TIME\n\nIf you did not set the retention time previously, the default is 0.\n\n\n\n\n\n Viewing the retention time interval for tables, schemas, and databases with the command-line \n\nTo view DATA_VERSION_RETENTION_TIME for a specific object, run one of these commands. The commands display DATA_VERSION_RETENTION_TIME only if it is a nonzero value.\n\nd <table_name>\n\nSHOW SCHEMA <schema_name>\n\nl+ <all databases, with detail>\n\nRetention time interval and retention lower bound for an object are available in the dataverretntime and dataverretnlowerbound columns of the following system views:\n\n\n\n* _v_table","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-dataretentioninterval_tt"},{"document_id":"ibmcld_15164-5536-7411","score":18.8752934536,"text":"\n* For a Daily plan, enter the starting time (UTC) in hours and minutes, Coordinated Universal Time. For example, 12 noon is 12:00. Local time conversion is automatically provided on the screen, for example, 12 PM Central Daylight Time.\n\n\n\n* Weekly\n\n\n\n* For a Weekly plan, select the days of the week that you want backups to run. For example, you can select Monday, Wednesday, and Friday. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Monthly\n\n\n\n* For a Monthly plan, select the day of the month that you want backups to run. For example, \"1\" schedules a backup every first of the month. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Specify by using cron expression\n\n\n\n* Under Cron expression (UTC), enter the backup creation frequency in cron-spec format: minute, hour, day, month, and weekday. For example, to create a backup every day at 5:30 PM, you need to enter 30 17 * * .\n\n\n\n\n\nThe Backup destination shows the Block Storage for VPC volume's region. The Backup resource group is the resource group that is associated with the volume.\n3. Specify a Retention type for the backups. You can specify either how long to keep them by number of days or the total number to retain.\n\n\n\n* For Age, specify the number of days that you want to retain the backups. A default value for the maximum number of days to keep a backup is not provided.\n* For Count, provide the number of backups that you want to keep.\n\n\n\nTo keep costs down, set a retention period or snapshots count adequate to your needs. For example, setting \"7\" for Age retains a week's worth of backups.\n4. Under Optional, you can configure two options.\n\n\n\n* Fast snapshot restore - When you enable this feature, you must specify the zone or zones where you want [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) enabled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=ui"},{"document_id":"ibmcld_15161-5539-7414","score":18.8752934536,"text":"\n* For a Daily plan, enter the starting time (UTC) in hours and minutes, Coordinated Universal Time. For example, 12 noon is 12:00. Local time conversion is automatically provided on the screen, for example, 12 PM Central Daylight Time.\n\n\n\n* Weekly\n\n\n\n* For a Weekly plan, select the days of the week that you want backups to run. For example, you can select Monday, Wednesday, and Friday. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Monthly\n\n\n\n* For a Monthly plan, select the day of the month that you want backups to run. For example, \"1\" schedules a backup every first of the month. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Specify by using cron expression\n\n\n\n* Under Cron expression (UTC), enter the backup creation frequency in cron-spec format: minute, hour, day, month, and weekday. For example, to create a backup every day at 5:30 PM, you need to enter 30 17 * * .\n\n\n\n\n\nThe Backup destination shows the Block Storage for VPC volume's region. The Backup resource group is the resource group that is associated with the volume.\n3. Specify a Retention type for the backups. You can specify either how long to keep them by number of days or the total number to retain.\n\n\n\n* For Age, specify the number of days that you want to retain the backups. A default value for the maximum number of days to keep a backup is not provided.\n* For Count, provide the number of backups that you want to keep.\n\n\n\nTo keep costs down, set a retention period or snapshots count adequate to your needs. For example, setting \"7\" for Age retains a week's worth of backups.\n4. Under Optional, you can configure two options.\n\n\n\n* Fast snapshot restore - When you enable this feature, you must specify the zone or zones where you want [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) enabled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=api"},{"document_id":"ibmcld_15162-5539-7414","score":18.8752934536,"text":"\n* For a Daily plan, enter the starting time (UTC) in hours and minutes, Coordinated Universal Time. For example, 12 noon is 12:00. Local time conversion is automatically provided on the screen, for example, 12 PM Central Daylight Time.\n\n\n\n* Weekly\n\n\n\n* For a Weekly plan, select the days of the week that you want backups to run. For example, you can select Monday, Wednesday, and Friday. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Monthly\n\n\n\n* For a Monthly plan, select the day of the month that you want backups to run. For example, \"1\" schedules a backup every first of the month. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Specify by using cron expression\n\n\n\n* Under Cron expression (UTC), enter the backup creation frequency in cron-spec format: minute, hour, day, month, and weekday. For example, to create a backup every day at 5:30 PM, you need to enter 30 17 * * .\n\n\n\n\n\nThe Backup destination shows the Block Storage for VPC volume's region. The Backup resource group is the resource group that is associated with the volume.\n3. Specify a Retention type for the backups. You can specify either how long to keep them by number of days or the total number to retain.\n\n\n\n* For Age, specify the number of days that you want to retain the backups. A default value for the maximum number of days to keep a backup is not provided.\n* For Count, provide the number of backups that you want to keep.\n\n\n\nTo keep costs down, set a retention period or snapshots count adequate to your needs. For example, setting \"7\" for Age retains a week's worth of backups.\n4. Under Optional, you can configure two options.\n\n\n\n* Fast snapshot restore - When you enable this feature, you must specify the zone or zones where you want [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) enabled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=cli"},{"document_id":"ibmcld_15163-5557-7432","score":18.8752934536,"text":"\n* For a Daily plan, enter the starting time (UTC) in hours and minutes, Coordinated Universal Time. For example, 12 noon is 12:00. Local time conversion is automatically provided on the screen, for example, 12 PM Central Daylight Time.\n\n\n\n* Weekly\n\n\n\n* For a Weekly plan, select the days of the week that you want backups to run. For example, you can select Monday, Wednesday, and Friday. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Monthly\n\n\n\n* For a Monthly plan, select the day of the month that you want backups to run. For example, \"1\" schedules a backup every first of the month. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Specify by using cron expression\n\n\n\n* Under Cron expression (UTC), enter the backup creation frequency in cron-spec format: minute, hour, day, month, and weekday. For example, to create a backup every day at 5:30 PM, you need to enter 30 17 * * .\n\n\n\n\n\nThe Backup destination shows the Block Storage for VPC volume's region. The Backup resource group is the resource group that is associated with the volume.\n3. Specify a Retention type for the backups. You can specify either how long to keep them by number of days or the total number to retain.\n\n\n\n* For Age, specify the number of days that you want to retain the backups. A default value for the maximum number of days to keep a backup is not provided.\n* For Count, provide the number of backups that you want to keep.\n\n\n\nTo keep costs down, set a retention period or snapshots count adequate to your needs. For example, setting \"7\" for Age retains a week's worth of backups.\n4. Under Optional, you can configure two options.\n\n\n\n* Fast snapshot restore - When you enable this feature, you must specify the zone or zones where you want [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) enabled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=terraform"},{"document_id":"ibmcld_09956-1678-3537","score":18.8688999802,"text":"\nTo view DATA_VERSION_RETENTION_TIME for a specific object, run one of these commands. The commands display DATA_VERSION_RETENTION_TIME only if it is a nonzero value.\n\nd <table_name>\n\nSHOW SCHEMA <schema_name>\n\nl+ <all databases, with detail>\n\nRetention time interval and retention lower bound for an object are available in the dataverretntime and dataverretnlowerbound columns of the following system views:\n\n\n\n* _v_table\n* _v_schema\n* _v_database\n\n\n\n\n\n\n\n\n\n Viewing the retention time interval with the web console \n\n\n\n Viewing the default retention time interval for the system with the web console \n\n\n\n1. Log in to the web console as described in [Getting started with the web console](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-getstarted-console).\n2. Go to Databases. The retention time interval for the system is displayed in the Retention time interval section at the top of the page.\n\n\n\n\n\n\n\n Viewing the retention time interval for tables, schemas, and databases with the web console \n\n\n\n1. Log in to the web console as described in [Getting started with the web console](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-getstarted-console).\n2. View the retention time interval:\n\n\n\n* For a table:\n\n\n\n\n\n1. Go to Databases.\n2. Select the database and schema in which the table that you want to view the retention interval is located.\n3. Ensure that you are in the DB Objects > Tables tab.\n4. Identify the table for which you want to view the retention interval.\n\nThe retention interval is displayed in the Retention time interval (days) column.\n\n\n\n\n\n* For a schema:\n\n\n\n\n\n1. Go to Databases.\n2. Select the database in which the schema that you want to view the retention interval is located.\n3. Identify the schema for which you want to view the retention interval.\n\nThe retention interval is displayed in the Retention time interval (days) column.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-dataretentioninterval_tt"},{"document_id":"ibmcld_15160-5628-7463","score":18.6851474931,"text":"\nLocal time conversion is automatically provided on the screen, for example, 12 PM Central Daylight Time.\n\n\n\n* Weekly\n\n\n\n* For a Weekly plan, select the days of the week that you want backups to run. For example, you can select Monday, Wednesday, and Friday. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Monthly\n\n\n\n* For a Monthly plan, select the day of the month that you want backups to run. For example, \"1\" schedules a backup every first of the month. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Specify by using cron expression\n\n\n\n* Under Cron expression (UTC), enter the backup creation frequency in cron-spec format: minute, hour, day, month, and weekday. For example, to create a backup every day at 5:30 PM, you need to enter 30 17 * * .\n\n\n\n\n\nThe Backup destination shows the Block Storage for VPC volume's region. The Backup resource group is the resource group that is associated with the volume.\n3. Specify a Retention type for the backups. You can specify either how long to keep them by number of days or the total number to retain.\n\n\n\n* For Age, specify the number of days that you want to retain the backups. A default value for the maximum number of days to keep a backup is not provided.\n* For Count, provide the number of backups that you want to keep.\n\n\n\nTo keep costs down, set a retention period or snapshots count adequate to your needs. For example, setting \"7\" for Age retains a week's worth of backups.\n4. Under Optional, you can configure two options.\n\n\n\n* Fast snapshot restore - When you enable this feature, you must specify the zone or zones where you want [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) enabled. You can also specify the maximum number of fast restore snapshots that you want to retain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02844-1555-3643","score":17.6550698905,"text":"\nconversation.counterexample.update edits a counterexample. \n conversation.data.update does a bulk action, such as importing a CSV file of intents or entities to the skill, or deleting multiple training data items, such as multiple entities or intents. \n conversation.entity.create creates an entity. \n conversation.entity.delete deletes an entity. \n conversation.entity.update edits an entity. \n conversation.example.create adds a user input example to an intent. \n conversation.example.delete deletes a user example from an intent. \n conversation.example.update edits a user example that is associated with an intent. \n conversation.intent.create creates an intent. \n conversation.intent.delete deletes an intent. \n conversation.intent.update edits an intent. \n conversation.log.create corrects an intent that was inaccurately categorized by the skill from the Analytics>User conversations page. \n conversation.node.create creates a dialog node. \n conversation.node.delete deletes a dialog node. \n conversation.node.update edits a dialog node. \n conversation.skill.create creates a skill, either dialog or search. \n conversation.skill.delete deletes a skill. \n conversation.skill.update updates a skill. \n conversation.skill_reference.create adds a specific skill to an assistant. \n conversation.skill_reference.delete removes a specific skill from an assistant. \n conversation.skill_reference.update updates a specific skill that is associated with an assistant. \n conversation.snapshot.create creates a version of a dialog skill. \n conversation.snapshot.delete deletes a version of a dialog skill. \n conversation.synonym.create creates a synonym for an entity value. \n conversation.synonym.delete deletes a synonym that is associated with an entity value. \n conversation.synonym.update edits a synonym that is associated with an entity value. \n conversation.userdata.delete deletes data that was created by a specified customer. \n conversation.value.create creates an entity value. \n conversation.value.delete deletes an entity value. \n conversation.value.update edits an entity value.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-audit-events"},{"document_id":"ibmcld_02844-3227-3811","score":17.3859559363,"text":"\nconversation.synonym.delete deletes a synonym that is associated with an entity value. \n conversation.synonym.update edits a synonym that is associated with an entity value. \n conversation.userdata.delete deletes data that was created by a specified customer. \n conversation.value.create creates an entity value. \n conversation.value.delete deletes an entity value. \n conversation.value.update edits an entity value. \n conversation.workspace.create creates a workspace. \n conversation.workspace.delete deletes a workspace. \n conversation.workspace.update makes changes to a workspace.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-audit-events"},{"document_id":"ibmcld_02844-4-2018","score":15.8726980235,"text":"\n{{site.data.content.newlink}}\n\n\n\n Audit events \n\nAs a security officer, auditor, or manager, you can use the [IBM Cloud Pak for Data audit service](https:\/\/www.ibm.com\/docs\/en\/cloud-paks\/cp-data\/latest?topic=considerations-auditing-cloud-pak-data) to track how users and applications interact with Watson Assistant.\n\nIBM Cloud Pak for Data audit service records user-initiated activities that change the state of a service in Watson Assistant. You can use this service to investigate abnormal activity and critical actions and to comply with regulatory audit requirements. For more information about exporting audit records to your security information and event management (SIEM) solutions, see [Auditing Cloud Pak for Data](https:\/\/www.ibm.com\/docs\/en\/cloud-paks\/cp-data\/latest?topic=considerations-auditing-cloud-pak-data).\n\n\n\n List of events \n\nThe following table lists the Watson Assistant activities that generate events.\n\n\n\nTable 1. Activities that generate events\n\n Action Triggered when someone... \n\n conversation.assistant.create creates an assistant. \n conversation.assistant.delete deletes an assistant. \n conversation.assistant.update updates an assistant. For example, renames the skill, changes the session timeout, or changes its associated skills. \n conversation.counterexample.create marks test user input in the Try it out pane as being irrelevant or corrects the categorization of a user input that was incorrectly assigned to an intent by marking it as irrelevant. \n conversation.counterexample.delete deletes a counterexample. \n conversation.counterexample.update edits a counterexample. \n conversation.data.update does a bulk action, such as importing a CSV file of intents or entities to the skill, or deleting multiple training data items, such as multiple entities or intents. \n conversation.entity.create creates an entity. \n conversation.entity.delete deletes an entity. \n conversation.entity.update edits an entity. \n conversation.example.create adds a user input example to an intent.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-audit-events"},{"document_id":"ibmcld_03112-7441-8509","score":14.1921580056,"text":"\n}\n}\n}\n}\n}\nShow more\n\n\n\n\n\n Restoring conversation state \n\nIn some situations, you might want the ability to restore a conversation to a previous state.\n\nYou can use the export option on stateful message requests to specify that you want the context object in the response to include complete session state data. If you specify true for this option, the returned skill context includes an encoded state property that represents the current conversation state.\n\nIf you are using the stateful message API, the service stores conversation state data only for the life of the session. However, if you save this context data (including state) and send it back to the service with a subsequent message request, you can restore the conversation to the same state, even if the original session has expired or has been deleted.\n\nIf you are using the stateless message API, the state property is always included in responses (along with the rest of context). Although stateless sessions do not expire, you can still use this state data to reset a conversation to a previous state.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-client-get-context"},{"document_id":"ibmcld_16262-6573-7996","score":13.5787087112,"text":"\n{\n\"output\": {\n\"generic\": [!\n{\n\"response_type\": \"text\",\n\"text\": \"Welcome to the Watson Assistant example\"\n}\n],\n\"intents\": [\n{\n\"intent\": \"hello\",\n\"confidence\": 1\n}\n],\n\"entities\": []\n},\n\"user_id\": \"my_user_id\",\n\"context\": {\n\"global\": {\n\"system\": {\n\"turn_count\": 1,\n\"user_id\": \"my_user_id\"\n}\n},\n\"skills\": {\n\"main skill\": {\n\"user_defined\": {\n\"account_number\": \"123456\"\n}\n}\n}\n}\n}\nShow more\n\n\n\n\n\n Restoring conversation state \n\nIn some situations, you might want the ability to restore a conversation to a previous state.\n\nYou can use the export option on stateful message requests to specify that you want the context object in the response to include complete session state data. If you specify true for this option, the returned skill context includes an encoded state property that represents the current conversation state.\n\nIf you are using the stateful message API, the service stores conversation state data only for the life of the session. However, if you save this context data (including state) and send it back to the service with a subsequent message request, you can restore the conversation to the same state, even if the original session expired or was deleted.\n\nIf you are using the stateless message API, the state property is always included in responses (along with the rest of context). Although stateless sessions do not expire, you can still use this state data to reset a conversation to a previous state.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client-get-context"},{"document_id":"ibmcld_16278-7-2318","score":13.4983181714,"text":"\nComparing actions and dialog \n\nChoose the right type of conversation for your use case.\n\n\n\n Actions benefits \n\nUsing actions is the best choice when you want to approach the assistant with a focus on content. Actions offers the following benefits:\n\n\n\n* The process of creating a conversational flow is easier. People who have expertise with customer care can write the words that your assistant says. With a simplified process anyone can build a conversation. You don't need knowledge about machine learning or programming.\n* Actions provide better visibility into the customer's interaction and satisfaction with the assistant. Because each task is discrete and has a clear beginning and ending, you can track user progress through a task and identify snags.\n* The conversation designer doesn't need to manage data collected during the conversation. By default, your assistant collects and stores information for the duration of the current action. You don't need to take extra steps to delete saved data or reset the conversation. But if you want, you can store certain types of information, such as the customer's name, for the duration of a conversation.\n* Many people can work at the same time in separate, self-contained actions. The order of actions within a conversation doesn't matter. Only the order of steps within an action matters. And the action author can use drag and drop to reorganize steps in the action for optimal flow.\n\n\n\n\n\n\n\n Dialog benefits \n\nA dialog-based conversation is the best choice when you want greater control over the logic of the flow. The dialog editor exposes more of the underlying artifacts (such as intents and entities) used to build the AI models. The dialog flow uses an if-then-else style structure that might be familiar to developers, but not to content designers or customer-care experts.\n\n\n\n\n\n How actions are different from dialog \n\nIf you are already familiar with dialog-based conversations, learn more about how actions compares.\n\n\n\nConversational flow skill feature support\nThis table has row and column headers. The row headers identify features. The column headers identify the different skill types. To understand which features are supported by a skill, go to the row that describes the feature, and find the columns for the skill you are interested in.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-comparing-actions-dialog"},{"document_id":"ibmcld_03117-5698-7668","score":13.4954317202,"text":"\nAfter a conversation ends, use the v2 [Delete session](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2deletesession) method to delete the session.\n\n\n\nservice .deleteSession({ assistant_id: assistantId, session_id: sessionId, })\n\n {: codeblock python}\nservice.delete_session(\nassistant_id = assistant_id,\nsession_id = session_id\n)\n\n {: codeblock java}\n\nDeleteSessionOptions deleteSessionOptions = new DeleteSessionOptions.Builder(assistantId, sessionId .build(); service.deleteSession(deleteSessionOptions).execute();\n\nIf you do not explicitly delete the session, it will be automatically deleted after the configured timeout interval. (The timeout duration depends on your plan; for more information, see [Session limits](\/docs\/assistant?topic=assistant-assistant-settingsassistant-settings-session-limits).)\n\nTo see examples of the v2 APIs in the context of a simple client application, see [Building a client application](\/docs\/assistant?topic=assistant-api-client).\n\n Handle the v2 response format\n\nYour application might need to be updated to handle the v2 runtime response format, depending on which parts of the response your application needs to access:\n\n- Output for all response types (such as text and option) are still returned in the output.generic object. Application code for handling these responses should work without modification.\n\n- Detected intents and entities are now returned as part of the output object, rather than at the root of the response JSON.\n\n- The conversation context is now organized into two objects:\n\n- The global context contains system-level context data shared by all skills used by the assistant.\n\n- The skill context contains any user-defined context variables used by your dialog skill.\n\nHowever, keep in mind that state data, including conversation context, is now maintained by the assistant, so your application might not need to access the context at all (see [Let the assistant maintain state](api-migration-state)).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-migration"},{"document_id":"ibmcld_07578-74047-75977","score":12.9037757589,"text":"\nYou can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.\n* If accessing the page by using a private browsing window doesn't fix the issue, then try deleting the API key for the instance and creating a new one.\n\n\n\n* Why am I being asked to log in repeatedly?\n\nIf you keep getting messages, such as you are getting redirected to login, it might be due to one of the following things:\n\n\n\n* The Lite plan that you were using expired. Lite plans expire if they are not used within a 30-day span. To begin again, log in to IBM Cloud and create a new service instance of Watson Assistant.\n* An instance is locked when you exceed the plan limits for the month. To log in successfully, wait until the start of the next month when the plan limit totals are reset.\n\n\n\n* Why don't I see the Analytics page?\n\nTo view the Analytics page, you must have a service role of Manager and a platform role of at least Viewer. For more information about access roles and how to request an access role change, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-access-control).\n* Why am I unable to view the API details, API key, or service credentials?\n\nIf you cannot view the API details or service credentials, it is likely that you do not have Manager access to the service instance in which the resource was created. Only people with Manager access to the instance can use the service credentials.\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the conversation page. However, you can use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [V2 API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2listlogs). Or, you can use a Python script to export logs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-74022-75952","score":12.9037757589,"text":"\nYou can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.\n* If accessing the page by using a private browsing window doesn't fix the issue, then try deleting the API key for the instance and creating a new one.\n\n\n\n* Why am I being asked to log in repeatedly?\n\nIf you keep getting messages, such as you are getting redirected to login, it might be due to one of the following things:\n\n\n\n* The Lite plan that you were using expired. Lite plans expire if they are not used within a 30-day span. To begin again, log in to IBM Cloud and create a new service instance of Watson Assistant.\n* An instance is locked when you exceed the plan limits for the month. To log in successfully, wait until the start of the next month when the plan limit totals are reset.\n\n\n\n* Why don't I see the Analytics page?\n\nTo view the Analytics page, you must have a service role of Manager and a platform role of at least Viewer. For more information about access roles and how to request an access role change, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-access-control).\n* Why am I unable to view the API details, API key, or service credentials?\n\nIf you cannot view the API details or service credentials, it is likely that you do not have Manager access to the service instance in which the resource was created. Only people with Manager access to the instance can use the service credentials.\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the conversation page. However, you can use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [V2 API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2listlogs). Or, you can use a Python script to export logs.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03269-3433-5472","score":12.5410760756,"text":"\n(https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog-start.png)\n\nThis design results in a dialog that works like this:\n\n\n\n* Whatever the integration type, the conversation_start node is processed, which means any context variables that you define in it are initialized.\n* In integrations where the assistant starts the dialog flow, the Welcome node is triggered and its text response is displayed.\n* In integrations where the user starts the dialog flow, the user's first input is evaluated and then processed by the node that can provide the best response.\n\n\n\n\n\n\n\n\n\n Ending the conversation gracefully \n\nThe Anything else node is designed to recognize the anything_else special condition, which understands when user input does not match any of the intents that are used as conditions in a dialog's nodes.\n\nDon't delete the Anything else node.\n\nYou might not recognize its value at first, but it serves some important functions. If you did delete it, don't panic. You can add it back. Just add a dialog node to the end of your dialog tree, and add the anything_else special condition to its If assistant recognizes field.\n\nThe Anything else node provides the following benefits:\n\n\n\n* It prevents your assistant from ever going silent and failing to respond at all to your customers. The Anything else node is what enables your assistant to (if nothing else) say, I'm sorry, I didn't understand. or I can't help you with that.\n* The skill's analytics feature uses this node to learn about the topics that your dialog can't address. The coverage metric looks for occurrences of nodes with the anything_else condition being processed in the user conversation logs. It uses this information to determine the frequency with which your dialog is able to match user requests to intents that can address them. The node is registered by the metric if it conditions on anything_else alone or when it's used in combination with another condition, such as anything_else && positive_feedback.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-start"}],"retriever_scores":{}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03113-4-2033","score":18.8143619633,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Modifying a dialog using the API \n\nThe Watson Assistant REST API supports modifying your dialog programmatically, without using the Watson Assistant tool. You can use the \/dialog_nodes API to create, delete, or modify dialog nodes.\n\nRemember that the dialog is a tree of interconnected nodes, and that it must conform to certain rules in order to be valid. This means that any change you make to a dialog node might have cascading effects on other nodes, or on the structure of your dialog. Before using the \/dialog_nodes API to modify your dialog, make sure you understand how your changes will affect the rest of the dialog. You can make a backup copy of the current dialog by exporting the conversational skill in which it resides. See [Downloading a skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-tasksskill-tasks-download) for details.\n\nA valid dialog always satisfies the following criteria:\n\n\n\n* Each dialog node has a unique ID (the dialog_node property).\n* A child node is aware of its parent node (the parent property). However, a parent node is not aware of its children.\n* A node is aware of its immediate previous sibling, if any (the previous_sibling property). This means that all siblings that share the same parent form a linked list, with each node pointing to the previous node.\n* Only one child of a given parent can be the first sibling (meaning that its previous_sibling is null).\n* A node cannot point to a previous sibling that is a child of a different parent.\n* Two nodes cannot point to the same previous sibling.\n* A node can specify another node that is to be executed next (the next_step property).\n* A node cannot be its own parent or its own sibling.\n* A node must have a type property that contains one of the following values. If no type property is specified, then the type is standard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_03270-3352-5135","score":18.3448834351,"text":"\nAdd a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.\n\n![Screen capture of the field in the node edit view where you add the node purpose summary.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/disambig-node-purpose.png)\n\nEvery dialog branch can be processed by the assistant while it chats with a customer, including branches with root nodes in folders.\n4. If a child node in any dialog branch conditions on a request or question that you do not want the assistant to handle, add a Connect to human agent response type to the child node.\n\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point.\n\n\n\nYour dialog is now ready to support transfers from your assistant to a service desk agent.\n\nFor more information about different service desk solutions, see the following resources:\n\n\n\n* [Adding service desk support to the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-haa)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-support"},{"document_id":"ibmcld_03113-6206-7586","score":18.1075293342,"text":"\n[Example dialog](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_1.png)\n\nWe can create a new node by making a POST request to \/dialog_nodes with the following body:\n\n{\n\"dialog_node\": \"node_8\"\n}\n\nThe dialog now looks like this:\n\n![Example dialog 2](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_2.png)\n\nBecause node_8 was created without specifying a value for parent or previous_sibling, it is now the first node in the dialog. Note that in addition to creating node_8, the service also modified node_1 so that its previous_sibling property points to the new node.\n\nYou can create a node somewhere else in the dialog by specifying the parent and previous sibling:\n\n{\n\"dialog_node\": \"node_9\",\n\"parent\": \"node_2\",\n\"previous_sibling\": \"node_5\"\n}\n\nThe values you specify for parent and previous_node must be valid:\n\n\n\n* Both values must refer to existing nodes.\n* The specified parent must be the same as the parent of the previous sibling (or null, if the previous sibling has no parent).\n* The parent cannot be a node of type response_condition or event_handler.\n\n\n\nThe resulting dialog looks like this:\n\n![Example dialog 3](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_3.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_03113-4996-6502","score":18.071851733,"text":"\n[UI location where the code that is triggered by named event handlers is authored](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/api-event-handlers.png)\n* A node of type event_handler with an event_name of generic can have a parent of type slot or frame.\n* A node of type event_handler with an event_name of focus, input, filled, or nomatch must have a parent of type slot.\n* If more than one event_handler with the same event_name is associated with the same parent node, then the order of the siblings reflects the order in which the event handlers will be executed.\n* For event_handler nodes with the same parent slot node, the order of execution is the same regardless of the placement of the node definitions. The events are triggered in this order by event_name:\n\n\n\n1. focus\n2. input\n3. filled\n4. generic*\n5. nomatch\n\n\n\n*If an event_handler with the event_name generic is defined for this slot or for the parent frame, then it is executed between the filled and nomatch event_handler nodes.\n\n\n\nThe following examples show how various modifications might cause cascading changes.\n\n\n\n Creating a node \n\nConsider the following simple dialog tree:\n\n![Example dialog](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_1.png)\n\nWe can create a new node by making a POST request to \/dialog_nodes with the following body:\n\n{\n\"dialog_node\": \"node_8\"\n}\n\nThe dialog now looks like this:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_02882-27313-29495","score":18.0661672205,"text":"\nThis response type only returns a valid response if the assistant to which you added this dialog skill also has a search skill associated with it.\n\n\n\n2. Click Add response to add another response type to the current response.\n\nYou might want to add multiple response types to a single response to provide a richer answer to a user query. For example, if a user asks for store locations, you could show a map and display a button for each store location that the user can click to get address details. To build that type of response, you can use a combination of image, options, and text response types. Another example is using a text response type before a pause response type so you can warn users before pausing the dialog.\n\nYou cannot add more than 5 response types to a single response. Meaning, if you define three conditional responses for a dialog node, each conditional response can have no more than 5 response types added to it.\n\nA single dialog node cannot have more than one Connect to human agent or more than one Search skill response.\n3. If you added more than one response type, you can click the Move up or down arrows to arrange the response types in the order you want your assistant to process them.\n\n\n\n\n\n\n\n\n\n Conditional responses \n\nA single dialog node can provide different responses, each one triggered by a different condition. Use this approach to address multiple scenarios in a single node.\n\nThe node still has a main condition, which is the condition for using the node and processing the conditions and responses that it contains.\n\nIn this example, your assistant uses information that it collected earlier about the user's location to tailor its response, and provide information about the store nearest the user. See [Context variables](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-variables) for more information about how to store information collected from the user.\n\n![Shows a node that shows a user ask, Where are you located, and the dialog has three different responses depending on conditions that use info from the $state context variable to specify locations in those states.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_02952-3289-5462","score":18.0030590955,"text":"\nAdd meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.\n\n![Screen capture of the field in the node edit view where you add the node purpose summary.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/disambig-node-purpose.png)\n\nEvery dialog branch can be processed by the assistant while it chats with a customer, including branches with root nodes in folders.\n4. If a child node in any dialog branch conditions on a request or question that you do not want the assistant to handle, add a Connect to human agent response type to the child node.\n\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point.\n\n\n\nYour dialog is now ready to support transfers from your assistant to a service desk agent.\n\n\n\n\n\n Measuring containment \n\nFrom the Analytics page, you can measure conversation containment. Containment is the rate at which your assistant is able to satisfy a customer's request without human intervention per conversation.\n\nTo measure containment accurately, the metric must be able to identify when a human intervention occurs. The metric primarily uses the Connect to human agent response type as an indicator. If a user conversation log includes a call to a Connect to human agent response type, then the conversation is considered to be not contained.\n\nHowever, not all human interventions are transacted by using a Connect to human agent response type. If you use an alternate method to deliver additional support, you must take additional steps to register the fact that the customer's need was not fulfilled by the assistant. For example, you might direct customers to your call center phone number or to an online support ticket form URL.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support"},{"document_id":"ibmcld_03273-11911-13556","score":17.981031003,"text":"\n[More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon on the folder, and then select Add node to folder.\n\nThe dialog node is added to the end of the dialog tree within the folder.\n\n\n\n\n\n\n\n\n\n Deleting a folder \n\nYou can delete either a folder alone or the folder and all of the dialog nodes in it.\n\nTo delete a folder, complete the following steps:\n\n\n\n1. From the tree view of the Dialog tab, find the folder that you want to delete.\n2. Click the More![More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon on the folder, and then select Delete.\n3. Do one of the following things:\n\n\n\n* To delete the folder only, and keep the dialog nodes that are in the folder, deselect the Delete the nodes inside the folder checkbox, and then click Yes, delete it.\n* To delete the folder and all of the dialog nodes in it, click Yes, delete it.\n\n\n\n\n\nIf you deleted the folder only, then the nodes that were in the folder are displayed in the dialog tree in the spot where the folder used to be.\n\n\n\n\n\n\n\n Dialog node limits \n\nThe number of dialog nodes you can create per skill depends on your plan type.\n\n\n\nPlan details\n\n Plan Dialog nodes per skill \n\n Enterprise 100,000 \n Premium (legacy) 100,000 \n Plus 100,000 \n Trial 25,000 \n Lite 25,000 \n\n\n\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\n\n\n\n\n Finding a dialog node by its node ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks"},{"document_id":"ibmcld_03188-1732-3801","score":17.9314802651,"text":"\n* To add an entire dialog branch that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.chat, to the If assistant recognizes field of the dialog root node.\n* To add a single dialog node that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.zendesk, to the If assistant recognizes field of the dialog child node.\n* To add slightly different responses for a single dialog node based on the integration type, complete the following steps:\n\n\n\n* From the node's edit view, click Customize and then set the Multiple conditioned responses switch to On. Click Apply.\n* In the dialog node response section, add the appropriate condition and corresponding response for each custom response type.\n\n\n\nThe following examples show how to specify a hypertext link in the best format for the integration where the text response will be displayed. For the Web chat integration, which supports Markdown formatting, you can include a link label in the response text to make the response look nicer. For the SMS with Twilio integration, you can skip the formatting that makes sense in a web page, and add the straight URL.\n\n\n\nCustom conditioned responses\n\n Integration type Condition Sample text response \n\n SMS with Twilio `$integrations.text_messaging` `For more information, go to https:\/\/www.ibm.com.` \n Web chat `$integrations.chat` `For more information, go to [the ibm.com site](https:\/\/www.ibm.com).` \n Response to show if no other conditions are met. `true` `For more information, go to ibm.com.` \n\n\n\n\n\nThe rich response types often behave differently when they are displayed in different built-in integrations or in the assistant preview. For more information about these unique behaviors, see the following topics:\n\n\n\n* [Web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-dialog)\n\n\n\n\n\n* [Phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-dialog)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrations"},{"document_id":"ibmcld_02952-1632-3754","score":17.825478302,"text":"\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.\n\nFor example, an insurance company might want questions about bereavement benefits always to be handled by a person. Or, if a customer wants to close an account, you might want to transfer the conversation to a respresentative who is authorized to offer incentives to keep the customer's business.\n* When the assistant repeatedly fails to understand a customer's request. Instead of asking the customer to retry or rephrase the question over and over, your assistant can offer to transfer the customer to a human agent.\n\n\n\nTo design a dialog that can transfer the conversation, complete the following steps:\n\n\n\n1. Add an intent to your skill that can recognize a user's request to speak to a human.\n\nYou can create your own intent or add the prebuilt intent named General_Connect_to_Agent that is provided with the General content catalog.\n2. Add a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support"},{"document_id":"ibmcld_03054-27011-29125","score":17.8050935312,"text":"\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition with a search skill response type.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:\n\nintents[0].confidence > 0.5\n\nThis condition is applied to all of the nodes in the folder. The condition tells your assistant to process the nodes in the folder only if your assistant is at least 50% confident that it knows the user's intent.\n3. Move any dialog nodes that you do not want your assistant to process often into the folder.\n\n\n\nAfter changing the dialog, test the assistant to make sure the search skill is triggered as often as you want it to be.\n\nAn alternative approach is to teach the dialog about topics to ignore. To do so, you can add utterances that you want the assistant to send to the search skill immediately as test utterances in the dialog skill's Try it out pane. You can then select the Mark as irrevlant option within the Try it out pane to teach the dialog not to respond to this utterance or others like it.\n\n\n\n\n\n Disabling search \n\nYou can disable the search skill from being triggered.\n\nYou might want to do so temporarily, while you are setting up the integration. Or you might want to only ever trigger a search for specific user queries that you can identify within the dialog, and use a search skill response type to answer.\n\nTo prevent the search skill from being triggered, complete the following steps:\n\n\n\n1. From the Assistants page, click the menu for your assistant, and then choose Settings.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1845756968}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03373-2953-4766","score":21.3534609614,"text":"\nAfter you identify the list of steps, you can then focus on writing engaging content to turn each interaction into a positive experience for your customer.\n\n![Diagram of a simple exchange between a customer and an actions skill step.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/action-skill-explained.png)\n\n\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. The name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.\n* [Dialog](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-build): A dialog is a branching conversation flow that defines how your application responds when it recognizes the defined intents and entities. You use the dialog editor to create conversations with users, providing responses based on the intents and entities that you recognize in their input.\n\n![Diagram of a basic implementation that uses intent and dialog only.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add"},{"document_id":"ibmcld_16234-7082-9512","score":20.4439231461,"text":"\nUse with Logs Reader to provide access to Analytics. \n Writer Create and edit within a resource. \n Manager Manage everything in a resource. \n Logs Reader Use Logs Reader in combination with the Reader or Writer role to provide access to Analytics. \n Version Maker Create or delete versions of an assistant. Doesn't provide publish access. \n\n\n\nThis table explains the minimum service roles that are required for common tasks in an assistant.\n\n\n\nMinimum service role details\n\n Task Resource Minimum service role required \n\n Assistant \n Create assistant Service instance Writer \n View assistant settings Assistant Writer \n View assistant ID Assistant Writer \n Update assistant settings Assistant Writer \n Enable or disable dialog Assistant Writer \n Delete assistant Service instance Writer \n Actions \n Create action Action skill Writer \n Update action Action skill Writer \n Delete action Action skill Writer \n Download actions JSON file Action skill Reader \n Upload actions JSON file Action skill Writer \n Copy action Action skill (in destination assistant) Writer \n Publish \n Publish version Environment Writer \n Create version without publishing Assistant Writer or Version Maker \n Delete unpublished version Assistant Writer or Version Maker \n Download version Assistant Reader \n Environments \n Create environment (Enterprise plan only) Assistant Writer \n Update environment settings Environment Writer \n Delete environment (Enterprise plan only) Service instance Writer \n Integrations \n Add integration Service instance Writer \n Update integration Service instance Writer \n Delete integration Service instance Writer \n Dialog \n Create intent Dialog skill Writer \n Update intent Dialog skill Writer \n Delete intent Dialog skill Writer \n Import intents Dialog skill Writer \n Export intents Dialog skill Reader \n Create entity Dialog skill Writer \n Update entity Dialog skill Writer \n Delete entity Dialog skill Writer \n Download intents and entities Dialog skill Reader \n\n\n\n\n\n\n\n Example of limiting access to one assistant \n\nThis example explains how to follow the steps in [Adding users from the Manage menu](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-access-controlaccess-control-add-users) and set specific resources that limit a user to building and publishing actions in one assistant. For each user, you need to add three access policies that identify the service instance, assistant ID, and skill ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-access-control"},{"document_id":"ibmcld_03026-7-2040","score":19.5013759736,"text":"\nDefining what's irrelevant \n\nTeach your dialog skill to recognize when a user asks about topics that it is not designed to answer.\n\nTo teach your assistant about subjects it should ignore, you can review your user conversation logs to mark utterances that discuss off-topic subjects as irrelevant.\n\nIntents that are marked as irrelevant are saved as counterexamples in the JSON workspace, and are included as part of the training data. They teach your assistant to explicitly not answer utterances of this type.\n\nWhile testing your dialog, you can mark an intent as irrelevant directly from the Try it out pane.\n\n![Mark as irrelevant screen capture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/irrelevant.png)\n\nBe certain before you designate an input as irrelevant.\n\n\n\n* There is no way to access or change the inputs from the user interface later.\n* The only way to reverse the identification of an input as being irrelevant is to use the same input in a test integration channel, and then explicitly assign it to an intent.\n\n\n\nOften there are subjects that you expect customers to ask and that you want your assistant to address eventually, but that you aren't ready to fully implement yet. Instead of adding those topics as counterexamples which can be hard to find later, capture the customer input examples as new intents. But, don't link dialog nodes to the intents until you're ready. If customers ask about one of these topics in the meantime, the anything_else node is triggered to explain that the assistant can't help with the current request, but can help them with other things.\n\n\n\n Irrelevance detection \n\nA new irrelevance detection algorithm was introduced with version 1.5.0. The irrelevance detection model helps your dialog skill recognize subjects that you do not want it to address, even if you haven't explicitly taught it about what to ignore. This enhanced model helps your skill recognize irrelevant inputs earlier in the development process.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-irrelevance-detection"},{"document_id":"ibmcld_03350-4-2142","score":19.3003209201,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Defining what's irrelevant \n\nTeach your dialog skill to recognize when a user asks about topics that it is not designed to answer.\n\nTo teach your assistant about subjects it should ignore, you can review your user conversation logs to mark utterances that discuss off-topic subjects as irrelevant.\n\nIntents that are marked as irrelevant are saved as counterexamples in the JSON workspace, and are included as part of the training data. They teach your assistant to explicitly not answer utterances of this type.\n\nWhile testing your dialog, you can mark an intent as irrelevant directly from the Try it out pane.\n\n![Mark as irrelevant screen capture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/irrelevant.png)\n\nBe certain before you designate an input as irrelevant.\n\n\n\n* There is no way to access or change the inputs from the user interface later.\n* The only way to reverse the identification of an input as being irrelevant is to use the same input in a test integration channel, and then explicitly assign it to an intent.\n\n\n\nOften there are subjects that you expect customers to ask and that you want your assistant to address eventually, but that you aren't ready to fully implement yet. Instead of adding those topics as counterexamples which can be hard to find later, capture the customer input examples as new intents. But don't link dialog nodes to the intents until you're ready. If customers ask about one of these topics in the meantime, the anything_else node is triggered to explain that the assistant can't help with the current request, but can help them with other things.\n\n\n\n Irrelevance detection \n\nThe irrelevance detection feature helps your dialog skill recognize subjects that you do not want it to address, even if you haven't explicitly taught it about what to ignore. This feature helps your skill recognize irrelevant inputs earlier in the development process.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-irrelevance-detection"},{"document_id":"ibmcld_03350-1645-3623","score":18.5740132484,"text":"\nIf customers ask about one of these topics in the meantime, the anything_else node is triggered to explain that the assistant can't help with the current request, but can help them with other things.\n\n\n\n Irrelevance detection \n\nThe irrelevance detection feature helps your dialog skill recognize subjects that you do not want it to address, even if you haven't explicitly taught it about what to ignore. This feature helps your skill recognize irrelevant inputs earlier in the development process.\n\nTo test irrelevance detection in the \"Try it out\" pane, submit one or more utterances that have absolutely nothing to do with your training data. Irrelevance deteciton helps your skill to correctly recognize that the test utterances do not map to any of the intents defined in your training data, and classifies them as being Irrelevant.\n\nThe algorithmic models that help your assistant understand what your users say are built from two key pieces of information:\n\n\n\n* Subjects you want the assistant to address. For example, questions about order shipments for an assistant that manages product orders.\n\nYou teach your assistant about these subjects by defining intents and providing lots of sample user utterances that articulate the intents so your assistant can recognize these and similar requests as examples of input for it to handle.\n* Subjects you want the assistant to ignore. For example, questions about politics for an assistant that makes pet grooming appointments exclusively.\n\nYou teach your assistant about subjects to ignore by marking utterances that discuss subjects which are out of scope for your application as being irrelevant. Such utterances become counterexamples for the model.\n\n\n\nThe best way to build an assistant that understands your domain and the specific needs of your customers is to take the time to build good training data.\n\n\n\n\n\n Counterexample limits \n\nThe maximum number of counterexamples that you can create for any plan type is 25,000.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-irrelevance-detection"},{"document_id":"ibmcld_03026-1465-3773","score":17.4901448325,"text":"\nIf customers ask about one of these topics in the meantime, the anything_else node is triggered to explain that the assistant can't help with the current request, but can help them with other things.\n\n\n\n Irrelevance detection \n\nA new irrelevance detection algorithm was introduced with version 1.5.0. The irrelevance detection model helps your dialog skill recognize subjects that you do not want it to address, even if you haven't explicitly taught it about what to ignore. This enhanced model helps your skill recognize irrelevant inputs earlier in the development process.\n\nTo learn more about the benefits of the new algorithm, read the [Why Zero-Effort Irrelevance is Relevant](https:\/\/medium.com\/ibm-watson\/enhanced-offtopic-90b2dadf0ef1) blog post.\n\nThe new algorithm is enabled automatically for any English-language skills that you import or create.\n\nTo test the new detection mechanism in the Try it out pane, submit one or more utterances that have absolutely nothing to do with your training data. The new mechanism helps your skill to correctly recognize that the test utterances do not map to any of the intents defined in your training data, and classifies them as being Irrelevant.\n\n\n\n\n\n How irrelevance detection works \n\nThe algorithmic models that help your assistant understand what your users say are built from two key pieces of information:\n\n\n\n* Subjects you want the assistant to address. For example, questions about order shipments for an assistant that manages product orders.\n\nYou teach your assistant about these subjects by defining intents and providing lots of sample user utterances that articulate the intents so your assistant can recognize these and similar requests as examples of input for it to handle.\n* Subjects you want the assistant to ignore. For example, questions about politics for an assistant that makes pet grooming appointments exclusively.\n\nYou teach your assistant about subjects to ignore by marking utterances that discuss subjects which are out of scope for your application as being irrelevant. Such utterances become counterexamples for the model.\n\n\n\nThe best way to build an assistant that understands your domain and the specific needs of your customers is to take the time to build good training data, especially data that includes counterexamples.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-irrelevance-detection"},{"document_id":"ibmcld_16628-0-1541","score":15.0588806337,"text":"\n\n\n\n\n\n\n  About Visual Explain \n\nThe visual explain feature in IBM\u00ae watsonx.data shows the execution plan for a specified SQL query. This feature also validates the SQL query. The output results can be visualized in different formats, which can be rendered into a graph or a flow chart. Data exchange happens between single or multiple nodes within a fragment. Each fragment has a set of data that is distributed between the nodes.\n\nWith this visual explain feature, you can run the query and show the output in a distributed environment. You can output the results in different formats. When queries are run, they scan through the database. The queries retrieve table metadata to fetch the correct output.\n\nWith this visual explain feature, you can visualize the query in a graphical representation. When a query is run in the SQL editor and selects the Explain option, watsonx.data uses an EXPLAIN SQL statement on the query to create a corresponding graph. This graph can be used to analyze, fix, and improve the efficiency of your queries by saving time and cost.\n\nTo view the execution plans for a query that is run in watsonx.data SQL editor, follow the steps:\n\n\n\n1.  In the Query workspace page, enter the query and click Run on starter to get the results.\n2.  Click Explain on the screen to visualize the graphical representation of the query.\n\n\n\nOn the Explain window, click a stage to view the details on the right window. The details of each stage that is displayed are the estimate values for rows, CPU, memory, and network.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query"},{"document_id":"ibmcld_02900-23378-25261","score":14.3090812367,"text":"\nIn this example, the eCommerce_Cancel_Product_Order intent has a close confidence score of 46%.As a result, when the user input is i must cancel it today, both dialog nodes are likely to be considered viable candidates to respond. To determine which dialog node to process, the assistant asks the user to pick one. And to help the user choose between them, the assistant provides a short summary of what each node does. The summary text is extracted directly from the external node name information that is specified for each node.!]Notice that your assistant recognizes the term today in the user input as a date, a mention of the @sys-date entity. If your dialog tree contains a node that conditions on the @sys-date entity, then it is also included in the list of disambiguation choices. This image shows it included in the list as the Capture date information option.!]The following video explains the benefits of using disambiguation. A few things have changed since the video was created:<-- <ul> --> * You enable dismabiguation from the Options page instead of a Settings link from the Dialog page. * You can also set a maximum number of options to display in the disambiguation list.<-- <\/ul> --><-- <\/section \"id=\"section-dialog-runtime-disambig-example\" \"> --><-- <section \"id=\"section-dialog-runtime-disambig-enable\" \"> --> Enabling disambiguation To enable disambiguation, complete the following steps:<-- <ol> -->1. From the Skills menu of the dialog skill where you want to enable disabmiguation, click Options.2. On the Disambiguation page, switch the toggle to On.3. In the Disambiguation message field, add text to show before the list of dialog node options. For example, What do you want to do?4. In the Anything else field, add text to display as an additional option that users can pick if none of the other dialog node options reflect what the user wants to do.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime"},{"document_id":"ibmcld_02988-8862-10727","score":14.1160971964,"text":"\nThe confidence property is a decimal percentage that represents your assistant's confidence in the recognized intent.\n\nWhile testing your dialog, you can see details of the intents that are recognized in user input by specifying this expression in a dialog node response:\n\n<? intents ?>\n\nFor the user input, Hello now, your assistant finds an exact match with the #greeting intent. Therefore, it lists the #greeting intent object details first. The response also includes the 10 other intents that are defined in the skill regardless of their confidence score. (In this example, its confidence in the other intents is set to 0 because the first intent is an exact match.) The top 10 intents are returned because the Try it out pane sends the alternate_intents:true parameter with its request. If you are using the API directly and want to see the top 10 results, be sure to specify this parameter in your call. If alternate_intents is false, which is the default value, only intents with a confidence above 0.2 are returned in the array.\n\n[!{\"intent\":\"greeting\",\"confidence\":1},\n{\"intent\":\"yes\",\"confidence\":0},\n{\"intent\":\"pizza-order\",\"confidence\":0}]\n\nThe following examples show how to check for an intent value:\n\n\n\n* intents[0] == 'Help'\n* intent == 'Help'\n\n\n\nintent == 'help' differs from intents[0] == 'help' because intent == 'help' does not throw an exception if no intent is detected. It is evaluated as true only if the intent confidence exceeds a threshold. If you want to, you can specify a custom confidence level for a condition, for example, intents.size() > 0 && intents[0] == 'help' && intents[0].confidence > 0.1\n\n\n\n\n\n Accessing input \n\nThe input JSON object contains one property only: the text property. The text property represents the text of the user input.\n\n\n\n Input property usage examples \n\nThe following example shows how to access input:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-expression-language"},{"document_id":"ibmcld_03310-10261-12004","score":14.0880866869,"text":"\nThe response also includes the top 10 other intents that are defined in the skill regardless of their confidence score. (In this example, its confidence in the other intents is set to 0 because the first intent is an exact match.) The top 10 intents are returned because the \"Try it out\" pane sends the alternate_intents:true parameter with its request. If you are using the API directly and want to see the top 10 results, be sure to specify this parameter in your call. If alternate_intents is false, which is the default value, only intents with a confidence above 0.2 are returned in the array.\n\n[!{\"intent\":\"greeting\",\"confidence\":1},\n{\"intent\":\"yes\",\"confidence\":0},\n{\"intent\":\"pizza-order\",\"confidence\":0}]\n\nIf you want to include text in the response, use the toJson() method in the expression to cast the returned intents list into a JSON object. For example:\n\nRecognized intents are: <? intents.toJson() ?>\n\nThe following examples show how to check for an intent value:\n\n\n\n* intents[0] == 'Help'\n* intent == 'Help'\n\n\n\nintent == 'help' differs from intents[0] == 'help' because intent == 'help' does not throw an exception if no intent is detected. It is evaluated as true only if the intent confidence exceeds a threshold. If you want to, you can specify a custom confidence level for a condition, for example, intents.size() > 0 && intents[0] == 'help' && intents[0].confidence > 0.1\n\n\n\n\n\n Accessing input \n\nThe input JSON object contains one property only: the text property. The text property represents the text of the user input.\n\n\n\n Input property usage examples \n\nThe following example shows how to access input:\n\n\n\n* To execute a node if the user input is \"Yes\", add this expression to the node condition: input.text == 'Yes'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-expression-language"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03113-6206-7586","score":16.8651402123,"text":"\n[Example dialog](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_1.png)\n\nWe can create a new node by making a POST request to \/dialog_nodes with the following body:\n\n{\n\"dialog_node\": \"node_8\"\n}\n\nThe dialog now looks like this:\n\n![Example dialog 2](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_2.png)\n\nBecause node_8 was created without specifying a value for parent or previous_sibling, it is now the first node in the dialog. Note that in addition to creating node_8, the service also modified node_1 so that its previous_sibling property points to the new node.\n\nYou can create a node somewhere else in the dialog by specifying the parent and previous sibling:\n\n{\n\"dialog_node\": \"node_9\",\n\"parent\": \"node_2\",\n\"previous_sibling\": \"node_5\"\n}\n\nThe values you specify for parent and previous_node must be valid:\n\n\n\n* Both values must refer to existing nodes.\n* The specified parent must be the same as the parent of the previous sibling (or null, if the previous sibling has no parent).\n* The parent cannot be a node of type response_condition or event_handler.\n\n\n\nThe resulting dialog looks like this:\n\n![Example dialog 3](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_3.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_02953-11701-13401","score":16.6220103427,"text":"\n[More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kabob.png) icon on the folder, and then select Add node to folder.\n\nThe dialog node is added to the end of the dialog tree within the folder.\n\n\n\n\n\n\n\n\n\n Deleting a folder \n\nYou can delete either a folder alone or the folder and all of the dialog nodes in it.\n\nTo delete a folder, complete the following steps:\n\n\n\n1. From the tree view of the Dialog tab, find the folder that you want to delete.\n2. Click the More![More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kabob.png) icon on the folder, and then select Delete.\n3. Do one of the following things:\n\n\n\n* To delete the folder only, and keep the dialog nodes that are in the folder, deselect the Delete the nodes inside the folder checkbox, and then click Yes, delete it.\n* To delete the folder and all of the dialog nodes in it, click Yes, delete it.\n\n\n\n\n\nIf you deleted the folder only, then the nodes that were in the folder are displayed in the dialog tree in the spot where the folder used to be.\n\n\n\n\n\n\n\n Dialog node limits \n\nThe number of dialog nodes you can create per skill is 100,000.\n\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\nYou can see the number of dialog nodes in a dialog skill from the assistant tile. If the skill is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tasks"},{"document_id":"ibmcld_02990-7468-9182","score":16.6091895356,"text":"\nFor more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v1listlogs) and the [Filter query reference](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-reference).\n\n\n\n\n\n Can I export and import dialog nodes? \n\nNo, you cannot export and import dialog nodes from the product user interface.\n\nIf you want to copy dialog nodes from one skill into another skill, follow these steps:\n\n\n\n1. Download as JSON files both the dialog skill that you want to copy the dialog nodes from and the dialog skill that you want to copy the nodes to.\n2. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes from.\n3. Find the dialog_nodes array, and copy it.\n4. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes to, and then paste the dialog_nodes array into it.\n5. Import the JSON file that you edited in the previous step to create a new dialog skill with the dialog nodes you wanted.\n\n\n\n\n\n\n\n How long are log files kept for a workspace? \n\nMessages are retained for 90 days. For more information, see [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-limits).\n\n\n\n\n\n How do I create a webhook? \n\nTo define a webhook and add its details, open the skill where you want to add the webhook. Open the Options page, and then click Webhooks to add details about your webhook. To invoke the webhook, call it from one or more of your dialog nodes. For more information, see [Making a programmatic call from dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-webhooks).\n\n\n\n\n\n Can I have more than one entry in the URL field for a webhook?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-faqs"},{"document_id":"ibmcld_03273-11911-13556","score":16.6004769748,"text":"\n[More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon on the folder, and then select Add node to folder.\n\nThe dialog node is added to the end of the dialog tree within the folder.\n\n\n\n\n\n\n\n\n\n Deleting a folder \n\nYou can delete either a folder alone or the folder and all of the dialog nodes in it.\n\nTo delete a folder, complete the following steps:\n\n\n\n1. From the tree view of the Dialog tab, find the folder that you want to delete.\n2. Click the More![More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon on the folder, and then select Delete.\n3. Do one of the following things:\n\n\n\n* To delete the folder only, and keep the dialog nodes that are in the folder, deselect the Delete the nodes inside the folder checkbox, and then click Yes, delete it.\n* To delete the folder and all of the dialog nodes in it, click Yes, delete it.\n\n\n\n\n\nIf you deleted the folder only, then the nodes that were in the folder are displayed in the dialog tree in the spot where the folder used to be.\n\n\n\n\n\n\n\n Dialog node limits \n\nThe number of dialog nodes you can create per skill depends on your plan type.\n\n\n\nPlan details\n\n Plan Dialog nodes per skill \n\n Enterprise 100,000 \n Premium (legacy) 100,000 \n Plus 100,000 \n Trial 25,000 \n Lite 25,000 \n\n\n\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\n\n\n\n\n Finding a dialog node by its node ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks"},{"document_id":"ibmcld_03113-4-2033","score":16.5317322066,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Modifying a dialog using the API \n\nThe Watson Assistant REST API supports modifying your dialog programmatically, without using the Watson Assistant tool. You can use the \/dialog_nodes API to create, delete, or modify dialog nodes.\n\nRemember that the dialog is a tree of interconnected nodes, and that it must conform to certain rules in order to be valid. This means that any change you make to a dialog node might have cascading effects on other nodes, or on the structure of your dialog. Before using the \/dialog_nodes API to modify your dialog, make sure you understand how your changes will affect the rest of the dialog. You can make a backup copy of the current dialog by exporting the conversational skill in which it resides. See [Downloading a skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-tasksskill-tasks-download) for details.\n\nA valid dialog always satisfies the following criteria:\n\n\n\n* Each dialog node has a unique ID (the dialog_node property).\n* A child node is aware of its parent node (the parent property). However, a parent node is not aware of its children.\n* A node is aware of its immediate previous sibling, if any (the previous_sibling property). This means that all siblings that share the same parent form a linked list, with each node pointing to the previous node.\n* Only one child of a given parent can be the first sibling (meaning that its previous_sibling is null).\n* A node cannot point to a previous sibling that is a child of a different parent.\n* Two nodes cannot point to the same previous sibling.\n* A node can specify another node that is to be executed next (the next_step property).\n* A node cannot be its own parent or its own sibling.\n* A node must have a type property that contains one of the following values. If no type property is specified, then the type is standard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_02953-12940-14393","score":16.4780924717,"text":"\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\nYou can see the number of dialog nodes in a dialog skill from the assistant tile. If the skill is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant. The trained data section lists the number of dialog nodes.\n\nIf the total seems larger than you expected, it might be because the dialog that you build from the application is translated into a JSON object. Some fields that appear to be part of a single node are actually structured as separate dialog nodes in the underlying JSON object.\n\n\n\n* Each node and folder is represented as its own node.\n* Each conditional response that is associated with a single dialog node is represented as an individual node.\n* For a node with slots, each slot, slot found response, slot not found response, slot handler, and if set, the prompt for everything response is an individual node. In effect, one node with three slots might be equivalent to eleven dialog nodes.\n\n\n\nPrevious topic:[Controlling the dialog flow](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime)\n\nNext topic:[Dialog building tips](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tips)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tasks"},{"document_id":"ibmcld_02882-33778-35796","score":16.4314359678,"text":"\nFor example, you might want to first check whether the input contains an intent, such as turn_on, and if it does, you might want to check whether the input contains entities, such as @lights, @radio, or @wipers. Chaining conditions helps to structure larger dialog trees.\n\nAvoid choosing this option when configuring a jump-to from a conditional response that goes to a node situated before the current node in the dialog tree. Otherwise, you can create an infinite loop. If your assistant jumps to the earlier node and checks its condition, it is likely to return false because the same user input is being evaluated that triggered the current node last time through the dialog. Your assistant will go to the next sibling or back to root to check the conditions on those nodes, and will likely end up triggering this node again, which means the process will repeat itself.\n* Response: If the statement targets the response section of the selected dialog node, it is run immediately. That is, the system does not evaluate the condition of the selected dialog node; it processes the response of the selected dialog node immediately.\n\nTargeting the response is useful for chaining several dialog nodes together. The response is processed as if the condition of this dialog node is true. If the selected dialog node has another Jump to action, that action is run immediately, too.\n* Wait for user input: Waits for new input from the user, and then begins to process it from the node that you jump to. This option is useful if the source node asks a question, for example, and you want to jump to a separate node to process the user's answer to the question.\n\n\n\n\n\n\n\n\n\n Next steps \n\n\n\n* Be sure to test your dialog as you build it. For more information, see [Testing the dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tasks).\n* For more information about ways to address common use cases, see [Dialog building tips](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tips).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_03313-12458-14207","score":16.3975750325,"text":"\nFollow the steps in the [Getting started with Watson Assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-getting-started) tutorial for a product introduction and to get help creating your first assistant.\n\n\n\n\n\n Can I export the user conversations from the Analytics page? \n\nYou cannot directly export conversations from the User conversation page. You can, however, use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1listlogs) and the [Filter query reference](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-filter-reference). Or, you can use a Python script to export logs. For more information, see [export_logs_py](https:\/\/github.com\/watson-developer-cloud\/community\/blob\/master\/watson-assistant\/export_logs_py.py).\n\n\n\n\n\n Can I export and import dialog nodes? \n\nNo, you cannot export and import dialog nodes from the product user interface.\n\nIf you want to copy dialog nodes from one skill into another skill, follow these steps:\n\n\n\n1. Download as JSON files both the dialog skill that you want to copy the dialog nodes from and the dialog skill that you want to copy the nodes to.\n2. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes from.\n3. Find the dialog_nodes array, and copy it.\n4. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes to, and then paste the dialog_nodes array into it.\n5. Import the JSON file that you edited in the previous step to create a new dialog skill with the dialog nodes you wanted.\n\n\n\n\n\n\n\n Is it possible to recover a deleted skill?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-faqs"},{"document_id":"ibmcld_07578-85554-87392","score":16.3817808838,"text":"\nFollow the steps in the [Getting started with Watson Assistant](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started) tutorial for a product introduction and to get help creating your first assistant.\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the User conversation page. You can, however, use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v1listlogs) and the [Filter query reference](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-reference).\n* Can I export and import dialog nodes?\n\nNo, you cannot export and import dialog nodes from the product user interface.\n\nIf you want to copy dialog nodes from one skill into another skill, follow these steps:\n\n\n\n1. Download as JSON files both the dialog skill that you want to copy the dialog nodes from and the dialog skill that you want to copy the nodes to.\n2. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes from.\n3. Find the dialog_nodes array, and copy it.\n4. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes to, and then paste the dialog_nodes array into it.\n5. Import the JSON file that you edited in the previous step to create a new dialog skill with the dialog nodes you wanted.\n\n\n\n* How long are log files kept for a workspace?\n\nMessages are retained for 90 days. For more information, see [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-limits).\n* How do I create a webhook?\n\nTo define a webhook and add its details, open the skill where you want to add the webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-85529-87367","score":16.3817808838,"text":"\nFollow the steps in the [Getting started with Watson Assistant](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started) tutorial for a product introduction and to get help creating your first assistant.\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the User conversation page. You can, however, use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v1listlogs) and the [Filter query reference](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-reference).\n* Can I export and import dialog nodes?\n\nNo, you cannot export and import dialog nodes from the product user interface.\n\nIf you want to copy dialog nodes from one skill into another skill, follow these steps:\n\n\n\n1. Download as JSON files both the dialog skill that you want to copy the dialog nodes from and the dialog skill that you want to copy the nodes to.\n2. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes from.\n3. Find the dialog_nodes array, and copy it.\n4. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes to, and then paste the dialog_nodes array into it.\n5. Import the JSON file that you edited in the previous step to create a new dialog skill with the dialog nodes you wanted.\n\n\n\n* How long are log files kept for a workspace?\n\nMessages are retained for 90 days. For more information, see [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-limits).\n* How do I create a webhook?\n\nTo define a webhook and add its details, open the skill where you want to add the webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16276-22117-23327","score":7.4702349372,"text":"\n[Delete icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/remove-response-icon.png) icon. Removing a saved response from a step affects only the step that you are editing. It does not delete the saved response or remove it from any other steps.\n\nTo edit a saved response from a step, click Edit response. Keep in mind that if you edit a saved response, your changes affect all steps that use the response. If you want to edit the response only for the step you are editing, click the Unlink from saved response![Unlink from saved response icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/unlink-response-icon.png) icon. After you unlink a response, any edits you make affect only the step you are editing; they do not affect any other steps, nor are they applied to the saved response.\n\nAfter you unlink a response, you cannot relink it. If you want to return to the saved response without your edits, delete the response, and then read the original saved response. If you want to make your edited version of the response available for reuse, save it as a new saved response.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-collect-info"},{"document_id":"ibmcld_16353-1180-3143","score":7.3985203236,"text":"\n* [Search for the answer](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-step-what-nextsearch-for-answer)\n* [Connect to agent](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-step-what-nextconnect-to-agent)\n* [End the action](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-step-what-nextend-action)\n\n\n\n\n\n Continue to next step \n\nThis option processes the next step in the steps list. As always, the conditions for the next step are evaluated first to determine whether to show the step's response to the customer. This is the default selection.\n\n\n\n\n\n Re-ask previous step(s) \n\nThis option repeats one or more steps that are listed earlier in the current action. These might be steps that the customer already completed, or steps that were skipped previously based on their step conditions.\n\nYou can use this option to handle situations where the customer has made a mistake and asks to go back to a previous point in the conversation. For example, you might include a confirmation step at the end of a process that asks the user whether the collected information is correct; if the user says no, you can return to the beginning of the process. This option is only available from a step that comes third or later in the steps list.\n\nTo repeat previous steps:\n\n\n\n1. In the And then field, select Re-ask previous step(s).\n2. In the Settings window, click to select any previous steps you want to repeat. You can select any step that precedes the step you are editing.\n\nNote that only the selected steps will repeat, regardless of their And then settings. Therefore, if you want to repeat the entire action up to this point, you must select all of the previous steps.\n\nThe current step you are editing is automatically included in the list of steps to be repeated. To avoid an infinite loop, use step conditions to ensure that this step only executes when it is appropriate for previous steps to be repeated.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-step-what-next"},{"document_id":"ibmcld_16353-2640-4846","score":7.2753751906,"text":"\nYou can select any step that precedes the step you are editing.\n\nNote that only the selected steps will repeat, regardless of their And then settings. Therefore, if you want to repeat the entire action up to this point, you must select all of the previous steps.\n\nThe current step you are editing is automatically included in the list of steps to be repeated. To avoid an infinite loop, use step conditions to ensure that this step only executes when it is appropriate for previous steps to be repeated. For example, you might have a step that repeats previous steps only if the user answered No to a confirmation question; this way, if the user answers Yes, nothing is repeated and the action continues.\n3. Click Apply.\n\n\n\nAny session variable values that were defined based on choices that the customer made in the repeated steps are cleared and replaced with the new responses.\n\nThere is no option to jump to a later step. Instead of jumping directly to a later step, control the flow through the intervening steps with step conditions or skipping steps.\n\n\n\n\n\n Go to a subaction \n\nAn action that is called from another action is referred to as a subaction. This option switches the conversation flow to another action. If you have an action flow that can be applied across multiple actions, you can use a subaction to build it once and then call it from each action that needs it. For example, as part of an action to place an order, you might call a subaction that enables a new customer to create an account.\n\nTo call a subaction:\n\n\n\n1. In the And then field, select Go to a subaction.\n2. In the Settings window, click the Go to field and select the action that you want to call.\n3. If you do not want to continue with the current action, click End this action after the other action is completed. You might use this option in cases where the customer decides to do something different; in this case, you want the conversation flow to switch to the subaction and not return.\n\nBy default, the assistant returns to the current action after the subaction completes. Any action variables or session variables that are defined in the subaction are accessible from subsequent steps in the calling action.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-step-what-next"},{"document_id":"ibmcld_09764-7-1837","score":7.0088608226,"text":"\nConfiguring the authentication method of a Monitoring instance \n\nYou can configure the authentication token that is allowed in a Monitoring instance when you use Python scripts or the Monitoring REST API to manage resources. By default, you can use an IAM token or a Monitor API token . However, you can restrict the Monitoring instance to only allow IAM tokens.\n\n\n\n Prereqs \n\nComplete the following steps:\n\n\n\n1. [Install the IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-install-ibmcloud-cli). If the CLI is installed, continue with the next step.\n2. Log in to the region and resource group in the IBM Cloud where the Monitoring instance is available. Run the following command: [ibmcloud login](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_cliibmcloud_login)\n\n\n\n\n\n\n\n Step 1. Get information on the Monitoring instance \n\nTo get information about the Monitoring instance, run the following command:\n\nibmcloud resource service-instance MONITORING_INSTANCE_NAME --output JSON\n\nThe output includes a parameters section with the following information:\n\n\"parameters\": {\n\"default_receiver\": false,\n\"external_api_auth\": \"IAM_ONLY\"\n}\n\nThe external_api_auth field indicates the types of tokens that are allowed to work with the Monitoring instance.\n\n\n\n* When the value is set to IAM_ONLY, you can only use IAM tokens to authenticate.\n* When the value is set to ANY, you can use IAM tokens and Monitor API tokens to authenticate.\n\n\n\nCheck the external_api_auth to find out what tokens are allowed for authentication.\n\n\n\n\n\n Step 2. Reset the Monitor API token for each team \n\nComplete this step if you are configuring your monitoring instance to authenticate with IAM tokens only.\n\nWhen you reset a Monitor API token , you disable the current Monitor API token that users might be using. There is 1 Monitor API token per team.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-iam_instance_auth"},{"document_id":"ibmcld_09764-1347-2793","score":6.8993700421,"text":"\n* When the value is set to ANY, you can use IAM tokens and Monitor API tokens to authenticate.\n\n\n\nCheck the external_api_auth to find out what tokens are allowed for authentication.\n\n\n\n\n\n Step 2. Reset the Monitor API token for each team \n\nComplete this step if you are configuring your monitoring instance to authenticate with IAM tokens only.\n\nWhen you reset a Monitor API token , you disable the current Monitor API token that users might be using. There is 1 Monitor API token per team.\n\nFor each team in the Monitoring instance, [Reset the Monitor API token](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-api_monitoring_tokenapi_token_reset).\n\n\n\n\n\n Step 3. Configure the Monitoring instance to only allow IAM tokens \n\nRun the following command to update a Monitoring instance so that only IAM tokens are allowed when you use Python scripts or the monitoring REST API to manage resources:\n\nibmcloud resource service-instance-update NAME -p '{\"external_api_auth\": \"IAM_ONLY\"}'\n\nWhere\n\nNAME is the name of the Monitoring instance.\n\nAPI_AUTH is set to the authorization model that is enabled to authenticate with the IBM Cloud Monitoring service when you use Python scripts or the monitoring REST API. By default, it is set to ANY. Valid values are: ANY and IAM_ONLY.\n\nFor example, to modify an instance, run the following command:\n\nibmcloud resource service-instance-create monitoring-instance-01 -p '{\"external_api_auth\": \"IAM_ONLY\"}'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-iam_instance_auth"},{"document_id":"ibmcld_09087-48400-49482","score":6.8500964539,"text":"\n$ ibmcloud kp key delete $KEY_ID -i $KP_INSTANCE_ID\n\nDeleting key: 'e631925f-affb-457e-886d-57cb2a5f565b', from instance: 'a192d603-0b8d-452f-aac3-f9e1f95e7411'...\nOK\nDeleted Key\ne631925f-affb-457e-886d-57cb2a5f565b\n\n step 3 - sleep 30 seconds\n$ sleep 30\n\n step 4 - create a key material\n$ KEY_MATERIAL=$(openssl rand -base64 32)\n\n$ echo $KEY_MATERIAL\n\nlZM\/guRnn\/VklwRBoNOP\/AUdCtpDNSo3+xXXhwrnO7c=\n\n step 5 - this CLI request fails because you can only restore keys\n that were imported (created with a key material or an import token)\n$ ibmcloud kp key restore $KEY_ID -i $KP_INSTANCE_ID --key-material $KEY_MATERIAL\n\nRestoring key: 'e631925f-affb-457e-886d-57cb2a5f565b', in instance: 'a192d603-0b8d-452f-aac3-f9e1f95e7411'...\nFAILED\nkp.Error:\ncorrelation_id='6d000f60-47f2-4a49-ba72-f02a8efa2945',\nmsg='Bad Request:\nKey could not be restored.\nPlease see reasons for more details.',\nreasons='[KEY_IMPT_REQ_ERR:\nOnly imported keys may be restored. -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/apidocs\/key-protect]'\n\n step 5 - this API request fails because you can only restore keys","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-error-messages"},{"document_id":"ibmcld_09508-6300-7933","score":6.7216956815,"text":"\n* Any outages caused by the execution of the script and time to recover will not be counted as an SLA breach.\n\n\n\n\n\n\n\n How to Access IBM COS (Cloud Object Storage) Buckets \n\n\n\n* To access IBM COS bucket you have to configure Rclone. Rclone is the utility via which you can access IBM COS bucket(s) and upload\/download the content.\n* To configure Rclone please use steps below. You will need this information while configuring Rclone.\n* A separate Rclone config is needed for each bucket as the access credentials for each bucket are unique.\n* Some buckets are read-only which means you can only download data from that bucket while some are read\/write meaning you can upload and download data.\n\n\n\nThe below steps can only be performed by the client once they have received their Welcome Letter.\n\n\n\n Rclone Config for COS file Upload and Download - Step-by-Step Guide \n\n\n\n\n\n Pre-requisite Steps: \n\n\n\n1. Installation of Rclone - [https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-rclone](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-rclone)\n2. Your Welcome Letter from the MAS MS Provision Team with the following details:\n\n\n\n\n\n* Public Endpoint (ie. s3.us-east.cloud-object-storage.appdomain.cloud ==> us-east or s3.eu-de.cloud-object-storage.appdomain.cloud ==> eu-de)\n* Access_key_id\n* Secret_access_key\n* Bucket Name\n\n\n\n\n\n\n\n Terminal Steps: \n\n\n\n1. Run rclone config and select n for a new remote\n2. Enter a name for the configuration\n3. Enter \"5\" for Storage (IBM COS)\n4. Enter \"10\" for Provider (IBMCOS)\n5. Press Enter for env_auth (false)\n6. Enter access_key_id from above\n7.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-ms?topic=mas-ms-support"},{"document_id":"ibmcld_00610-1558-3117","score":6.7109978281,"text":"\nFor more information, see [Creating service credentials](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-to-iam-onlycreating-service-credentials) for further instructions.\n\n\n\n\n\n\n\n Step 2: Updating applications \n\n\n\n1. Update all applications to use IAM access tokens when you authenticate with the IBM Cloudant instance.\n\n\n\n\n\n\n\n Step 3: Migrating to IAM only \n\nThis operation cannot be undone. Make sure all applications that access the instance are using IAM to authenticate before you start this step.\n\n\n\n1. Go to [IBM Cloud](https:\/\/cloud.ibm.com\/resources).\n2. Find your IBM Cloudant instance on the list of resources and open it.\n\nZoom\n\n![Select your instance.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/tutorials\/images\/img0011.png)\n\nFigure 1. Resource list\n3. Click the Migrate to IAM Only button under the Authentication methods section. If you do not see the button, your instance is already IAM Only.\n\nZoom\n\n![Migrate to IAM Only.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/tutorials\/images\/authentication_methods_root_credential.png)\n\nFigure 2. Authentication methods\n4. Click OK to confirm your action on the dialog window to proceed. If the instance URL-style credential is still enabled, the confirmation box differs. You still click OK to confirm your action on the dialog window to proceed.\n5. When the operation completes successfully, the Authentication methods row shows only IBM Cloud IAM.\n\nZoom\n\n![Migration complete.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-to-iam-only"},{"document_id":"ibmcld_06992-1594-3643","score":6.6966837675,"text":"\nIn addition to the [data source requirements](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collection-typesrequirements) for all installed deployments, your Box data source must meet the following requirement:\n\n\n\n* You must obtain any required service licenses for the data source that you want to connect to. For more information about licenses, contact the system administrator of the data source.\n\n\n\n\n\n\n\n Prerequisite steps \n\nIf you want to enable document-level security, you must take some steps to set it up. For more information, see [About document-level security](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collection-typesconfiguredls).\n\nYou must create a custom application in Box before you can connect to Box from Discovery. Anyone can create the custom app, but only a Box administrator can authorize it.\n\nTo create a custom application, complete the following steps:\n\n\n\n1. Make sure you have a [Box account](https:\/\/www.box.com\/). During this process, you get the configuration file and the client ID.\n2. Next, create a custom app that uses Server Authentication with JWT as its authentication method.\n\nFor detailed steps, see [Setup with JWT](https:\/\/developer.box.com\/guides\/authentication\/jwt\/jwt-setup\/) in the Box Developer Documentation.\n\nFollow these guidelines when you create the app:\n\n\n\n1. During the setup procedure, choose to use the Server Authentication with JWT method to verify application identity with a key pair.\n2. Choose the appropriate access level for the Box content that you want to crawl:\n\n\n\n* Box files that are shared with managed users: App access plus Enterprise access\n* Box files which are shared with the service account: App access only\n* Box files which are shared with the service account and its app users: App access only\n\n\n\nSupport for configuring the Box level access with App access only was added with the 4.6 release.\n3. Configure the access level by following the appropriate steps for your app access level type:\n\n\n\n* App access plus Enterprise access","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-connector-box-cp4d"},{"document_id":"ibmcld_00610-7-2079","score":6.6905120923,"text":"\nMigrating an instance with legacy credentials and IAM Authentication to IAM Only Authentication \n\nWhen you create a new service credential by using the IBM Cloud Dashboard or the IBM Cloud CLI, it always produces a new username and password combination. This method applies to legacy credentials as well as a new IAM API key. This tutorial guides you through migrating your instance from generating new legacy credentials and IAM API keys to generating new IAM API keys only.\n\nThis tutorial is only applicable to IBM Cloudant instances within resource groups with legacy credentials that are enabled.\n\nSee the effects of this tutorial on existing legacy credentials:\n\n\n\n* New format legacy credentials (usernames that start with apikey-v2-) continue to function until the service credential is deleted.\n* URL style legacy credentials if still active are revoked. If you would like to revoke them separately, follow the [Revoking credential that is tied to your instance URL](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-revoke-instance-url-style-credential) steps before you complete this tutorial.\n\n\n\n\n\n Objectives \n\n\n\n1. Update your applications to use IAM credentials instead of legacy credentials.\n2. Disable creation of new legacy credentials.\n\n\n\n\n\n\n\n Step 1: Generating new IBM Cloudant IAM Credentials \n\n\n\n1. Use the IBM Cloud Dashboard or the IBM Cloud CLI to [generate new service credentials](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudantcreating-service-credentials) for your IBM Cloudant instance. For more information, see [Creating service credentials](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-to-iam-onlycreating-service-credentials) for further instructions.\n\n\n\n\n\n\n\n Step 2: Updating applications \n\n\n\n1. Update all applications to use IAM access tokens when you authenticate with the IBM Cloudant instance.\n\n\n\n\n\n\n\n Step 3: Migrating to IAM only \n\nThis operation cannot be undone. Make sure all applications that access the instance are using IAM to authenticate before you start this step.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-to-iam-only"}],"retriever_scores":{}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03085-4-2046","score":26.5391273252,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Managing access \n\nYou can give other people access to your Watson Assistant resources, and control the level of access they get.\n\nMaybe you want one development team to have access to a test assistant and another development team to have access to a production assistant. And you want data scientists to be able to view analytics for user conversation logs from both assistants. And maybe you want a writer to be able to author the dialogue that is used by your assistant to converse with your customers. To manage who can do what with your skills and assistants, you can assign different access roles to different people.\n\n\n\n Before you grant access to others \n\nFor each person to whom you grant access to your Watson Assistant service instance, decide whether you want to give the person a role with instance-level or resource-level access. Instance-level access applies to all of the assistants and skills in a single service instance. Resource-level access applies to individual skills and assistants within a service instance only.\n\n\n\n\n\n Granting users access to your resources \n\n\n\n1. If you plan to give a user access to a single skill or assistant in your service instance, get the ID for the skill or assistant. You need to provide the ID in a later step.\n\n\n\n* To get the assistant ID, go to the Assistants page. Click the overflow menu for the assistant, and then click Settings > API Details. Copy the assistant ID and paste it somewhere that you can access it from later.\n* To get the skill ID, go to the Skills page. Click the overflow menu for the skill, and then click View API Details. Copy the skill ID and paste it somewhere that you can access it from later.\n\n\n\n2. Click the User ![User](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/user-icon2.png) icon in the page header.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-access-control"},{"document_id":"ibmcld_03043-4515-6369","score":13.0982384085,"text":"\nIf you already have Discovery for IBM Cloud Pak for Data installed and an instance provisioned, you can mine your existing data collections for source material that you can share with customers to address their questions.\n\nThe following diagram illustrates how user input is processed when both a dialog skill and a search skill are added to an assistant. Any questions that the dialog is not designed to answer are sent to the search skill, which finds a relevant response from a Discovery data collection.\n\n![Diagram of how a question is sent to the Discovery service from a search skill.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/search-skill-diagram.png)\n\nFor help creating a search skill, see [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add).\n\n\n\n\n\n Create the skill \n\nYou can add one skill of each skill type to an assistant.\n\n\n\n* [Dialog Skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add)\n* [Search Skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add)\n\n\n\n\n\n\n\n Skill limits \n\n\n\nSkill limit details\n\n Skills per service instance \n\n 50 \n\n\n\nSkill versions do not count toward the skill limit.\n\n\n\n\n\n Deleting a skill \n\nYou can delete any skill that you can access, unless it is being used by an assistant. If it is in use, you must remove it from the assistant that is using it before you can delete it.\n\nBe sure to check with anyone else who might be using the skill before you delete it.\n\nTo delete a skill, complete the following steps:\n\n\n\n1. Find out whether the skill is being used by any assistants. From the Skills page, find the tile for the skill that you want to delete. The Assistants field lists the assistants that currently use the skill.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add"},{"document_id":"ibmcld_03049-7-1790","score":13.0982384085,"text":"\nAdding a dialog skill \n\nThe natural-language processing for the Watson Assistant service is defined in a dialog skill, which is a container for all of the artifacts that define a conversation flow.\n\nYou can add one dialog skill to an assistant.\n\n\n\n Create the dialog skill \n\nYou can create a skill from scratch, use a sample skill that is provided by IBM, or import a skill from a JSON file.\n\nTo add a skill, complete the following steps:\n\n\n\n1. Click the Skills icon ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-skills-icon.png).\n\nv1.3: Click the Skills tab. If you don't see the Skills tab, click the breadcrumb link in the page header.\n2. Click Create skill.\n3. Select the dialog skill option, and then click Next.\n4. Take one of the following actions:\n\n\n\n* To create a skill from scratch, click Create skill.\n* To add a sample skill that is provided with the product as a starting point for your own skill or as an example to explore before you create one yourself, click Use sample skill, and then click the sample you want to use.\n\nThe sample skill is added to your list of skills. It is not associated with any assistants. Skip the remaining steps in this procedure.\n* To add an existing skill to this service instance, you can import it as a JSON file. Click Import skill, and then click Choose JSON File, and select the JSON file you want to import.\n\nImportant:\n\n\n\n* The imported JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding.\n* The maximum size for a skill JSON file is 10MB. If you need to import a larger skill, consider importing the intents and entities separately after you have imported the skill. (You can also import larger skills using the REST API.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_03049-3966-5647","score":13.0835345663,"text":"\nYou might need to remove the @sys-person and @sys-location entities from your training data, and any references to them from dialog nodes, for example.\n3. Try again to import the edited skill.\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-ass-icon.png) to open the Assistants page.\n\nv1.3: Click the Assistants tab.\n2. Click to open the tile for the assistant to which you want to add the skill.\n3. Click Add Dialog Skill.\n4. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nWhen you add a dialog skill from here, you get the development version. If you want to add a specific skill version, add it from the skill's Versions tab instead.\n\n\n\n\n\n\n\n Downloading a dialog skill \n\nYou can download a dialog skill in JSON format. You might want to download a skill if you want to use the same dialog skill in a different instance of the Watson Assistant service, for example. You can download it from one instance and import it to another instance as a new dialog skill.\n\nTo download a dialog skill, complete the following steps:\n\n\n\n1. Find the dialog skill tile on the Skills page or on the configuration page of an assistant that uses the skill.\n2. Click the !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_03373-7076-8670","score":13.0030366442,"text":"\nYou can then create a collection from a data source and configure your search skill to search this collection for answers to customer queries.\n\nThe following diagram illustrates how user input is processed when both a dialog skill and a search skill are added to an assistant. Any questions that the dialog is not designed to answer are sent to the search skill, which finds a relevant response from a Discovery data collection.\n\n![Diagram of how a question gets routed to the search skill.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/search-skill-diagram.png)\n\n\n\n\n\n Creating a skill \n\nYou can add one conversation skill (actions or dialog) and one search skill to an assistant.\n\n\n\n Conversation \n\n\n\n* [Actions skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-actions-add)\n* [Dialog Skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add)\n\n\n\n\n\n\n\n Search \n\n\n\n* [Search Skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add)\n\n\n\n\n\n\n\n\n\n Skill limits \n\nThe number of skills you can create depends on your Watson Assistant plan type. Any sample dialog skills that are available for you to use do not count toward your limit unless you use them. A skill version does not count as a skill.\n\n\n\nPlan details\n\n Plan Maximum number of skills of each type per service instance \n\n Enterprise 100 \n Premium (legacy) 100 \n Plus 50 \n Standard (legacy) 20 \n Lite, Trial 5 \n\n\n\n* After 30 days of inactivity, an unused skill in a Lite plan service instance might be deleted to free up space.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add"},{"document_id":"ibmcld_03106-4717-6754","score":12.981120171,"text":"\nnode.delete deletes a dialog node \n node.update edits a dialog node \n notifier.create creates a notifier \n notifier.delete deletes a notifier \n notifier.update updates a notifier \n processor.create creates a processor \n processor.delete deletes a processor \n processor.update updates a processor \n recommendationfile.create uploads a CSV file of utterances to a skill from which Watson can derive intent recommendations \n recommendationfile.delete deletes a CSV file of utterances that is used to derive intent recommendations from a skill. \n recommendationsources.update updates a CSV file or assistant log that is being used as the source for intent recommendations \n release.create create a version from content in the draft environment \n release.delete delete a version \n release.deploy publish a version to an environment \n skill.create creates a skill \n skill.delete deletes a skill \n skill.update updates a skill \n skill_reference.create adds a specific skill to an assistant \n skill_reference.delete removes a specific skill from an assistant \n skill_reference.update updates a specific skill that is associated with an assistant \n skill_variable.create create a skill variable \n skill_variable.delete delete a skill variable \n skill_variable.update update a skill variable \n skills.export export a skill \n skills.import import a skill \n snapshot.create creates a version of a dialog skill \n snapshot.delete deletes a version of a dialog skill \n snapshot.update updates a version of a dialog skill \n step.create adds a step to an action \n step.delete deletes a step from an action \n step.update updates a step in an action \n step_handler.create create a step handler \n step_handler.delete delete a step handler \n step_handler.update update a step handler \n synonym.create creates a synonym for an entity value \n synonym.delete deletes a synonym that is associated with an entity value \n synonym.update edits a synonym that is associated with an entity value \n userdata.delete deletes data that was created by a specified customer","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-auditing"},{"document_id":"ibmcld_16248-4582-6619","score":12.981120171,"text":"\nnode.delete deletes a dialog node \n node.update edits a dialog node \n notifier.create creates a notifier \n notifier.delete deletes a notifier \n notifier.update updates a notifier \n processor.create creates a processor \n processor.delete deletes a processor \n processor.update updates a processor \n recommendationfile.create uploads a CSV file of utterances to a skill from which Watson can derive intent recommendations \n recommendationfile.delete deletes a CSV file of utterances that is used to derive intent recommendations from a skill. \n recommendationsources.update updates a CSV file or assistant log that is being used as the source for intent recommendations \n release.create create a version from content in the draft environment \n release.delete delete a version \n release.deploy publish a version to an environment \n skill.create creates a skill \n skill.delete deletes a skill \n skill.update updates a skill \n skill_reference.create adds a specific skill to an assistant \n skill_reference.delete removes a specific skill from an assistant \n skill_reference.update updates a specific skill that is associated with an assistant \n skill_variable.create create a skill variable \n skill_variable.delete delete a skill variable \n skill_variable.update update a skill variable \n skills.export export a skill \n skills.import import a skill \n snapshot.create creates a version of a dialog skill \n snapshot.delete deletes a version of a dialog skill \n snapshot.update updates a version of a dialog skill \n step.create adds a step to an action \n step.delete deletes a step from an action \n step.update updates a step in an action \n step_handler.create create a step handler \n step_handler.delete delete a step handler \n step_handler.update update a step handler \n synonym.create creates a synonym for an entity value \n synonym.delete deletes a synonym that is associated with an entity value \n synonym.update edits a synonym that is associated with an entity value \n userdata.delete deletes data that was created by a specified customer","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-auditing"},{"document_id":"ibmcld_03385-2475-4140","score":12.9649544786,"text":"\n[open and close list of options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon, and then choose Delete. Confirm the deletion.\n\n\n\n\n\n\n\n Downloading a skill \n\nYou can download a dialog or actions skill in JSON format. You might want to download a skill if you want to use the same skill in a different instance of the Watson Assistant service. You can download a dialog skill from one instance and upload it to another instance as a new skill, for example.\n\nYou cannot download a search skill.\n\nTo download a skill, complete the following steps:\n\n\n\n1. Find the skill tile on the Skills page or on the configuration page of an assistant that uses the skill.\n2. Click the ![open and close list of options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon, and then choose Download.\n3. Specify a name for the JSON file and where to save it, and then click Save.\n\n\n\nFor dialog skills only:\n\n\n\n* You can download a dialog skill by using the API also. Include the export=true parameter with the request. See the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1getworkspace) for more details.\n* For information about how to download a specific dialog skill version, see [Downloading a skill version](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-versionsversions-export).\n\n\n\n\n\n\n\n Overwriting a skill \n\nTo overwrite or replace an existing skill, upload the new version of the skill as a JSON file into the existing skill.\n\nYou can overwrite a dialog or actions skill. You cannot overwrite a search skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-tasks"},{"document_id":"ibmcld_13055-2475-4140","score":12.9649544786,"text":"\n[open and close list of options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon, and then choose Delete. Confirm the deletion.\n\n\n\n\n\n\n\n Downloading a skill \n\nYou can download a dialog or actions skill in JSON format. You might want to download a skill if you want to use the same skill in a different instance of the Watson Assistant service. You can download a dialog skill from one instance and upload it to another instance as a new skill, for example.\n\nYou cannot download a search skill.\n\nTo download a skill, complete the following steps:\n\n\n\n1. Find the skill tile on the Skills page or on the configuration page of an assistant that uses the skill.\n2. Click the ![open and close list of options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon, and then choose Download.\n3. Specify a name for the JSON file and where to save it, and then click Save.\n\n\n\nFor dialog skills only:\n\n\n\n* You can download a dialog skill by using the API also. Include the export=true parameter with the request. See the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1getworkspace) for more details.\n* For information about how to download a specific dialog skill version, see [Downloading a skill version](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-versionsversions-export).\n\n\n\n\n\n\n\n Overwriting a skill \n\nTo overwrite or replace an existing skill, upload the new version of the skill as a JSON file into the existing skill.\n\nYou can overwrite a dialog or actions skill. You cannot overwrite a search skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-tasks"},{"document_id":"ibmcld_03385-4-1596","score":12.9478838994,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Working with skills \n\nPerform common tasks, such as renaming or deleting a skill.\n\n\n\n Renaming a skill \n\nYou can change the name of a skill and its associated description after you create the skill.\n\nTo rename a skill, follow these steps:\n\n\n\n1. From the Skills page, find the skill that you want to rename.\n2. Click the ![open and close list of options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon, and then choose Rename.\n3. Edit the name, and then click Save.\n\n\n\n\n\n\n\n Duplicating a skill \n\nYou can duplicate a skill to make a copy of it.\n\nTo duplicate a skill, follow these steps:\n\n\n\n1. From the Skills page, find the skill that you want to duplicate.\n2. Click the ![open and close list of options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon, and then choose Duplicate. The copied skill has the word copy added to the end of its name.\n\n\n\n\n\n\n\n Deleting a skill \n\nYou can delete any skill that you can access, unless it is being used by an assistant. If it is in use, you must remove it from the assistant that is using it before you can delete it.\n\nBe sure to check with anyone else who might be using the skill before you delete it.\n\nTo delete a skill, complete the following steps:\n\n\n\n1. Find out whether the skill is being used by any assistants.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-tasks"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.296081911,"ndcg_cut_10":0.296081911}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02953-12940-14393","score":16.4780924717,"text":"\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\nYou can see the number of dialog nodes in a dialog skill from the assistant tile. If the skill is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant. The trained data section lists the number of dialog nodes.\n\nIf the total seems larger than you expected, it might be because the dialog that you build from the application is translated into a JSON object. Some fields that appear to be part of a single node are actually structured as separate dialog nodes in the underlying JSON object.\n\n\n\n* Each node and folder is represented as its own node.\n* Each conditional response that is associated with a single dialog node is represented as an individual node.\n* For a node with slots, each slot, slot found response, slot not found response, slot handler, and if set, the prompt for everything response is an individual node. In effect, one node with three slots might be equivalent to eleven dialog nodes.\n\n\n\nPrevious topic:[Controlling the dialog flow](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime)\n\nNext topic:[Dialog building tips](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tips)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tasks"},{"document_id":"ibmcld_03113-6206-7586","score":16.3468448461,"text":"\n[Example dialog](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_1.png)\n\nWe can create a new node by making a POST request to \/dialog_nodes with the following body:\n\n{\n\"dialog_node\": \"node_8\"\n}\n\nThe dialog now looks like this:\n\n![Example dialog 2](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_2.png)\n\nBecause node_8 was created without specifying a value for parent or previous_sibling, it is now the first node in the dialog. Note that in addition to creating node_8, the service also modified node_1 so that its previous_sibling property points to the new node.\n\nYou can create a node somewhere else in the dialog by specifying the parent and previous sibling:\n\n{\n\"dialog_node\": \"node_9\",\n\"parent\": \"node_2\",\n\"previous_sibling\": \"node_5\"\n}\n\nThe values you specify for parent and previous_node must be valid:\n\n\n\n* Both values must refer to existing nodes.\n* The specified parent must be the same as the parent of the previous sibling (or null, if the previous sibling has no parent).\n* The parent cannot be a node of type response_condition or event_handler.\n\n\n\nThe resulting dialog looks like this:\n\n![Example dialog 3](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_3.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_02953-11701-13401","score":16.3173186504,"text":"\n[More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kabob.png) icon on the folder, and then select Add node to folder.\n\nThe dialog node is added to the end of the dialog tree within the folder.\n\n\n\n\n\n\n\n\n\n Deleting a folder \n\nYou can delete either a folder alone or the folder and all of the dialog nodes in it.\n\nTo delete a folder, complete the following steps:\n\n\n\n1. From the tree view of the Dialog tab, find the folder that you want to delete.\n2. Click the More![More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kabob.png) icon on the folder, and then select Delete.\n3. Do one of the following things:\n\n\n\n* To delete the folder only, and keep the dialog nodes that are in the folder, deselect the Delete the nodes inside the folder checkbox, and then click Yes, delete it.\n* To delete the folder and all of the dialog nodes in it, click Yes, delete it.\n\n\n\n\n\nIf you deleted the folder only, then the nodes that were in the folder are displayed in the dialog tree in the spot where the folder used to be.\n\n\n\n\n\n\n\n Dialog node limits \n\nThe number of dialog nodes you can create per skill is 100,000.\n\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\nYou can see the number of dialog nodes in a dialog skill from the assistant tile. If the skill is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tasks"},{"document_id":"ibmcld_03273-13172-14845","score":16.3080363019,"text":"\nPlan Dialog nodes per skill \n\n Enterprise 100,000 \n Premium (legacy) 100,000 \n Plus 100,000 \n Trial 25,000 \n Lite 25,000 \n\n\n\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\n\n\n\n\n Finding a dialog node by its node ID \n\nYou can search for a dialog node by its node ID. Enter the full node ID into the search field. You might want to find the dialog node that is associated with a known node ID for any of the following reasons:\n\n\n\n* You are reviewing logs, and the log refers to a section of the dialog by its node ID.\n* You want to map the node IDs listed in the nodes_visited property of the API message output to nodes that you can see in your dialog tree.\n* A dialog runtime error message informs you about a syntax error, and uses a node ID to identify the node you need to fix.\n\n\n\nAnother way to discover a node based on its node ID is by following these steps:\n\n\n\n1. From the Dialog page, select any node in your dialog tree.\n2. Close the edit view if it is open for the current node.\n3. In your web browser's location field, a URL should display that has syntax similar to the following:\n\nhttps:\/\/{location}.assistant.watson.cloud.ibm.com\/{location}\/{instance-id}\/skills\/{skill-id}\/build\/dialognode={node-id}\n4. Edit the URL by replacing the current {node-id} value with the ID of the node you want to find, and then submit the new URL.\n5. If necessary, highlight the edited URL again, and resubmit it.\n\n\n\nThe page refreshes, and shifts focus to the dialog node with the node ID that you specified.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks"},{"document_id":"ibmcld_03273-11911-13556","score":16.2995947675,"text":"\n[More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon on the folder, and then select Add node to folder.\n\nThe dialog node is added to the end of the dialog tree within the folder.\n\n\n\n\n\n\n\n\n\n Deleting a folder \n\nYou can delete either a folder alone or the folder and all of the dialog nodes in it.\n\nTo delete a folder, complete the following steps:\n\n\n\n1. From the tree view of the Dialog tab, find the folder that you want to delete.\n2. Click the More![More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon on the folder, and then select Delete.\n3. Do one of the following things:\n\n\n\n* To delete the folder only, and keep the dialog nodes that are in the folder, deselect the Delete the nodes inside the folder checkbox, and then click Yes, delete it.\n* To delete the folder and all of the dialog nodes in it, click Yes, delete it.\n\n\n\n\n\nIf you deleted the folder only, then the nodes that were in the folder are displayed in the dialog tree in the spot where the folder used to be.\n\n\n\n\n\n\n\n Dialog node limits \n\nThe number of dialog nodes you can create per skill depends on your plan type.\n\n\n\nPlan details\n\n Plan Dialog nodes per skill \n\n Enterprise 100,000 \n Premium (legacy) 100,000 \n Plus 100,000 \n Trial 25,000 \n Lite 25,000 \n\n\n\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\n\n\n\n\n Finding a dialog node by its node ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks"},{"document_id":"ibmcld_03196-55745-57714","score":16.2900750729,"text":"\nIf your assistant jumps to the earlier node and checks its condition, it is likely to return false because the same user input is being evaluated that triggered the current node last time through the dialog. Your assistant will go to the next sibling or back to root to check the conditions on those nodes, and will likely end up triggering this node again, which means the process will repeat itself.\n* Response: If the statement targets the response section of the selected dialog node, it is run immediately. That is, the system does not evaluate the condition of the selected dialog node; it processes the response of the selected dialog node immediately.\n\nTargeting the response is useful for chaining several dialog nodes together. The response is processed as if the condition of this dialog node is true. If the selected dialog node has another Jump to action, that action is run immediately, too.\n* Wait for user input: Waits for new input from the user, and then begins to process it from the node that you jump to. This option is useful if the source node asks a question, for example, and you want to jump to a separate node to process the user's answer to the question.\n\n\n\n\n\n\n\n Next steps \n\n\n\n* Be sure to test your dialog as you build it. For more information, see [Testing the dialog](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks).\n* For more information about ways to address common use cases, see [Dialog building tips](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tips).\n* For more information about the expression language that you can use to improve your dialog, such as methods that reformat dates or text, see [Expression language methods](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-methods).\n\n\n\nYou can also use the API to add nodes or otherwise edit a dialog. See [Modifying a dialog using the API](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview"},{"document_id":"ibmcld_03113-4-2033","score":16.2458615161,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Modifying a dialog using the API \n\nThe Watson Assistant REST API supports modifying your dialog programmatically, without using the Watson Assistant tool. You can use the \/dialog_nodes API to create, delete, or modify dialog nodes.\n\nRemember that the dialog is a tree of interconnected nodes, and that it must conform to certain rules in order to be valid. This means that any change you make to a dialog node might have cascading effects on other nodes, or on the structure of your dialog. Before using the \/dialog_nodes API to modify your dialog, make sure you understand how your changes will affect the rest of the dialog. You can make a backup copy of the current dialog by exporting the conversational skill in which it resides. See [Downloading a skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-tasksskill-tasks-download) for details.\n\nA valid dialog always satisfies the following criteria:\n\n\n\n* Each dialog node has a unique ID (the dialog_node property).\n* A child node is aware of its parent node (the parent property). However, a parent node is not aware of its children.\n* A node is aware of its immediate previous sibling, if any (the previous_sibling property). This means that all siblings that share the same parent form a linked list, with each node pointing to the previous node.\n* Only one child of a given parent can be the first sibling (meaning that its previous_sibling is null).\n* A node cannot point to a previous sibling that is a child of a different parent.\n* Two nodes cannot point to the same previous sibling.\n* A node can specify another node that is to be executed next (the next_step property).\n* A node cannot be its own parent or its own sibling.\n* A node must have a type property that contains one of the following values. If no type property is specified, then the type is standard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_02990-7468-9182","score":16.2068623354,"text":"\nFor more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v1listlogs) and the [Filter query reference](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-reference).\n\n\n\n\n\n Can I export and import dialog nodes? \n\nNo, you cannot export and import dialog nodes from the product user interface.\n\nIf you want to copy dialog nodes from one skill into another skill, follow these steps:\n\n\n\n1. Download as JSON files both the dialog skill that you want to copy the dialog nodes from and the dialog skill that you want to copy the nodes to.\n2. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes from.\n3. Find the dialog_nodes array, and copy it.\n4. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes to, and then paste the dialog_nodes array into it.\n5. Import the JSON file that you edited in the previous step to create a new dialog skill with the dialog nodes you wanted.\n\n\n\n\n\n\n\n How long are log files kept for a workspace? \n\nMessages are retained for 90 days. For more information, see [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-limits).\n\n\n\n\n\n How do I create a webhook? \n\nTo define a webhook and add its details, open the skill where you want to add the webhook. Open the Options page, and then click Webhooks to add details about your webhook. To invoke the webhook, call it from one or more of your dialog nodes. For more information, see [Making a programmatic call from dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-webhooks).\n\n\n\n\n\n Can I have more than one entry in the URL field for a webhook?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-faqs"},{"document_id":"ibmcld_02882-33778-35796","score":16.1455652774,"text":"\nFor example, you might want to first check whether the input contains an intent, such as turn_on, and if it does, you might want to check whether the input contains entities, such as @lights, @radio, or @wipers. Chaining conditions helps to structure larger dialog trees.\n\nAvoid choosing this option when configuring a jump-to from a conditional response that goes to a node situated before the current node in the dialog tree. Otherwise, you can create an infinite loop. If your assistant jumps to the earlier node and checks its condition, it is likely to return false because the same user input is being evaluated that triggered the current node last time through the dialog. Your assistant will go to the next sibling or back to root to check the conditions on those nodes, and will likely end up triggering this node again, which means the process will repeat itself.\n* Response: If the statement targets the response section of the selected dialog node, it is run immediately. That is, the system does not evaluate the condition of the selected dialog node; it processes the response of the selected dialog node immediately.\n\nTargeting the response is useful for chaining several dialog nodes together. The response is processed as if the condition of this dialog node is true. If the selected dialog node has another Jump to action, that action is run immediately, too.\n* Wait for user input: Waits for new input from the user, and then begins to process it from the node that you jump to. This option is useful if the source node asks a question, for example, and you want to jump to a separate node to process the user's answer to the question.\n\n\n\n\n\n\n\n\n\n Next steps \n\n\n\n* Be sure to test your dialog as you build it. For more information, see [Testing the dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tasks).\n* For more information about ways to address common use cases, see [Dialog building tips](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tips).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_03185-5335-7134","score":16.0676358566,"text":"\nIf none of the conditions evaluates to true, then the response from the last node in the tree, which typically has a special anything_else condition that always evaluates to true, is returned.\n\nYou can disrupt the standard first-to-last flow in the following ways:\n\n\n\n* By customizing what happens after a node is processed. For example, you can configure a node to jump directly to another node after it is processed, even if the other node is positioned earlier in the tree. See [Defining what to do next](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-jump-to) for more information.\n* By configuring conditional responses to jump to other nodes. See [Conditional responses](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-multiple) for more information.\n* By configuring digression settings for dialog nodes. Digressions can also impact how users move through the nodes at run time. If you enable digressions away from most nodes and configure returns, users can jump from one node to another and back again more easily. See [Digressions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-digressions) for more information.\n\n\n\n\n\n\n\n Sample dialog \n\nThis diagram shows a mockup of a dialog tree that is built with the graphical user interface dialog editor.\n\n![A sample dialog tree with example content](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog-depiction-full.png)\n\nThe dialog tree in this diagram contains two root dialog nodes. A typical dialog tree would likely have many more nodes, but this depiction provides a glimpse of what a subset of nodes might look like.\n\n\n\n* The first root node conditions on an intent value.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-build"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16358-20798-22437","score":23.3818971357,"text":"\n[Shows another preview of the assistant where the test question is answered](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/tut-neural-answer2.png)\n\nFigure 20. Web chat returns a detailed answer\n5. Optionally ask the assistant other questions.\n\nIf the assistant doesn't know the answer, reword the question to include \u201cin Watson Discovery\u201d to make it clearer that you are asking about how something works in Discovery specifically.\n\n\n\nCongratulations! You successfully created an assistant that can answer questions about Discovery by retrieving information from the product documentation by way of the NeuralSeek service.\n\n\n\n Summary \n\nIn this tutorial, you created a Watson Discovery Document Retrieval project with uploaded PDF files that contain the Discovery product documentation. Separately, you created a Watson Assistant virtual assistant with a single action that can recognize user questions about Discovery. You added a custom extension to your assistant that connects to a third-party service called NeuralSeek that gets the correct answer from Discovery and rewords the response. Finally, you tested your virtual assistant by asking a question and getting an accurate and well-written response.\n\n\n\n\n\n Next steps \n\nThe assistant that you created is available from the draft environment. Next, you can publish your assistant to a production environment and deploy it. You can deploy the assistant in various ways. For more information, see [Overview: Previewing and publishing](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overview).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-tutorial-neuralseek"},{"document_id":"ibmcld_03379-0-2495","score":17.8878835596,"text":"\n\n\n\n\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n  Automatic retrain of old skills and workspaces \n\nWatson Assistant was released as a service in July 2016. Since then, users have been creating and updating skills to meet their virtual assistant needs. Behind the scenes, Watson Assistant creates machine learning (ML) models to perform a variety of tasks on the user's behalf.\n\nThe primary ML models deal with action recognition, intent classification, and entity detection. For example, the model might detect what a user intends when saying I want to open a checking account, and what type of account the user is talking about.\n\nThese ML models rely on a sophisticated infrastructure. There are many intricate components that are responsible for analyzing what the user has said, breaking down the user's input, and processing it so the ML model can more easily predict what the user is asking.\n\nSince Watson Assistant was first released, the product team has been making continuous updates to the algorithms that generate these sophisticated ML models. Older models have continued to function while running in the context of newer algorithms. Historically, the behavior of these existing ML model did not change unless the skill was updated, at which point the skill was retrained and a new model generated to replace the older one. This meant that many older models never benefited from improvements in our ML algorithms.\n\nWatson Assistant uses continuous retraining. The Watson Assistant service continually monitors all ML models, and automatically retrains those models that have not been retrained in the previous 6 months. Watson Assistant retrains using the selected algorithm version. If the version you had selected is no longer supported, Watson Assistant retrains using the version labeled as Previous. This means that your assistant will automatically have the supported technologies applied. Assistants that have been modified during the previous 6 months will not be affected. For more information, see [Algorithm version](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-algorithm-version).\n\nIn most cases, this retraining will be seamless from an end-user point of view. The same inputs will result in the same actions, intents, and entities being detected. In some cases, the retraining might cause changes in accuracy.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-auto-retrain"},{"document_id":"ibmcld_03026-7-2040","score":16.819672576,"text":"\nDefining what's irrelevant \n\nTeach your dialog skill to recognize when a user asks about topics that it is not designed to answer.\n\nTo teach your assistant about subjects it should ignore, you can review your user conversation logs to mark utterances that discuss off-topic subjects as irrelevant.\n\nIntents that are marked as irrelevant are saved as counterexamples in the JSON workspace, and are included as part of the training data. They teach your assistant to explicitly not answer utterances of this type.\n\nWhile testing your dialog, you can mark an intent as irrelevant directly from the Try it out pane.\n\n![Mark as irrelevant screen capture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/irrelevant.png)\n\nBe certain before you designate an input as irrelevant.\n\n\n\n* There is no way to access or change the inputs from the user interface later.\n* The only way to reverse the identification of an input as being irrelevant is to use the same input in a test integration channel, and then explicitly assign it to an intent.\n\n\n\nOften there are subjects that you expect customers to ask and that you want your assistant to address eventually, but that you aren't ready to fully implement yet. Instead of adding those topics as counterexamples which can be hard to find later, capture the customer input examples as new intents. But, don't link dialog nodes to the intents until you're ready. If customers ask about one of these topics in the meantime, the anything_else node is triggered to explain that the assistant can't help with the current request, but can help them with other things.\n\n\n\n Irrelevance detection \n\nA new irrelevance detection algorithm was introduced with version 1.5.0. The irrelevance detection model helps your dialog skill recognize subjects that you do not want it to address, even if you haven't explicitly taught it about what to ignore. This enhanced model helps your skill recognize irrelevant inputs earlier in the development process.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-irrelevance-detection"},{"document_id":"ibmcld_03270-1613-3746","score":16.6853644182,"text":"\nIf you deploy your assistant with an integration that has built-in service desk support, you can use the special Connect to human agent response type in your dialog response to initiate a transfer.\n\n\n\n Adding chat transfer support \n\nDesign your dialog so that it can transfer customers to human agents. Consider adding support for initiating a transfer in the following scenarios:\n\n\n\n* Any time a user asks to speak to a person.\n\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.\n\nFor example, an insurance company might want questions about bereavement benefits always to be handled by a person. Or, if a customer wants to close an account, you might want to transfer the conversation to a respresentative who is authorized to offer incentives to keep the customer's business.\n* When the assistant repeatedly fails to understand a customer's request. Instead of asking the customer to retry or rephrase the question over and over, your assistant can offer to transfer the customer to a human agent.\n\n\n\nTo design a dialog that can transfer the conversation, complete the following steps:\n\n\n\n1. Add an intent to your skill that can recognize a user's request to speak to a human.\n\nYou can create your own intent or add the prebuilt intent named General_Connect_to_Agent that is provided with the General content catalog.\n2. Add a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-support"},{"document_id":"ibmcld_02952-1632-3754","score":15.9432931456,"text":"\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.\n\nFor example, an insurance company might want questions about bereavement benefits always to be handled by a person. Or, if a customer wants to close an account, you might want to transfer the conversation to a respresentative who is authorized to offer incentives to keep the customer's business.\n* When the assistant repeatedly fails to understand a customer's request. Instead of asking the customer to retry or rephrase the question over and over, your assistant can offer to transfer the customer to a human agent.\n\n\n\nTo design a dialog that can transfer the conversation, complete the following steps:\n\n\n\n1. Add an intent to your skill that can recognize a user's request to speak to a human.\n\nYou can create your own intent or add the prebuilt intent named General_Connect_to_Agent that is provided with the General content catalog.\n2. Add a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support"},{"document_id":"ibmcld_03110-1523-3759","score":15.6177882928,"text":"\n2. Click Algorithm Version.\n3. Choose a version.\n\n\n\nThe latest and previous versions have date labels such as Latest (01-Jun-2022) or Previous (01-Jan-2022). See the [Watson Assistant release notes](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes) for details about each algorithm version release.\n\nAlgorithm version choices are currently available for Arabic, Chinese (Simplified), Chinese (Traditional), Czech, Dutch, English, French, German, Japanese, Korean, Italian, Portuguese, and Spanish. The universal language model uses a default algorithm.\n\n\n\n Automatic retraining \n\nIBM Cloud\n\nWatson Assistant was released as a service in July 2016. Since then, users have been creating and updating skills to meet their virtual assistant needs. Behind the scenes, Watson Assistant creates machine learning (ML) models to perform a variety of tasks on the user's behalf.\n\nThe primary ML models deal with action recognition, intent classification, and entity detection. For example, the model might detect what a user intends when saying I want to open a checking account, and what type of account the user is talking about.\n\nThese ML models rely on a sophisticated infrastructure. There are many intricate components that are responsible for analyzing what the user has said, breaking down the user's input, and processing it so the ML model can more easily predict what the user is asking.\n\nSince Watson Assistant was first released, the product team has been making continuous updates to the algorithms that generate these sophisticated ML models. Older models have continued to function while running in the context of newer algorithms. Historically, the behavior of these existing ML model did not change unless the skill was updated, at which point the skill was retrained and a new model generated to replace the older one. This meant that many older models never benefited from improvements in our ML algorithms.\n\nWatson Assistant uses continuous retraining. The Watson Assistant service continually monitors all ML models, and automatically retrains those models that have not been retrained in the previous 6 months. Watson Assistant retrains using the selected algorithm version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-algorithm-version"},{"document_id":"ibmcld_03350-4-2142","score":15.5197393177,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Defining what's irrelevant \n\nTeach your dialog skill to recognize when a user asks about topics that it is not designed to answer.\n\nTo teach your assistant about subjects it should ignore, you can review your user conversation logs to mark utterances that discuss off-topic subjects as irrelevant.\n\nIntents that are marked as irrelevant are saved as counterexamples in the JSON workspace, and are included as part of the training data. They teach your assistant to explicitly not answer utterances of this type.\n\nWhile testing your dialog, you can mark an intent as irrelevant directly from the Try it out pane.\n\n![Mark as irrelevant screen capture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/irrelevant.png)\n\nBe certain before you designate an input as irrelevant.\n\n\n\n* There is no way to access or change the inputs from the user interface later.\n* The only way to reverse the identification of an input as being irrelevant is to use the same input in a test integration channel, and then explicitly assign it to an intent.\n\n\n\nOften there are subjects that you expect customers to ask and that you want your assistant to address eventually, but that you aren't ready to fully implement yet. Instead of adding those topics as counterexamples which can be hard to find later, capture the customer input examples as new intents. But don't link dialog nodes to the intents until you're ready. If customers ask about one of these topics in the meantime, the anything_else node is triggered to explain that the assistant can't help with the current request, but can help them with other things.\n\n\n\n Irrelevance detection \n\nThe irrelevance detection feature helps your dialog skill recognize subjects that you do not want it to address, even if you haven't explicitly taught it about what to ignore. This feature helps your skill recognize irrelevant inputs earlier in the development process.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-irrelevance-detection"},{"document_id":"ibmcld_16256-1345-3721","score":15.5091181024,"text":"\nSee the [Watson Assistant release notes](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes) for details about each algorithm version release.\n\nAlgorithm version choices are currently available for Arabic, Chinese (Simplified), Chinese (Traditional), Czech, Dutch, English, French, German, Japanese, Korean, Italian, Portuguese, and Spanish. The universal language model uses a default algorithm.\n\n\n\n Automatic retraining \n\nIBM Cloud\n\nWatson Assistant was released as a service in July 2016. Since then, users have been creating and updating skills to meet their virtual assistant needs. Behind the scenes, Watson Assistant creates machine learning (ML) models to perform a variety of tasks on the user's behalf.\n\nThe primary ML models deal with action recognition, intent classification, and entity detection. For example, the model might detect what a user intends when saying I want to open a checking account, and what type of account the user is talking about.\n\nThese ML models rely on a sophisticated infrastructure. There are many intricate components that are responsible for analyzing what the user has said, breaking down the user's input, and processing it so the ML model can more easily predict what the user is asking.\n\nSince Watson Assistant was first released, the product team has been making continuous updates to the algorithms that generate these sophisticated ML models. Older models have continued to function while running in the context of newer algorithms. Historically, the behavior of these existing ML model did not change unless the skill was updated, at which point the skill was retrained and a new model generated to replace the older one. This meant that many older models never benefited from improvements in our ML algorithms.\n\nWatson Assistant uses continuous retraining. The Watson Assistant service continually monitors all ML models, and automatically retrains those models that have not been retrained in the previous 6 months. Watson Assistant retrains using the selected algorithm version. If the version you had selected is no longer supported, Watson Assistant retrains using the version labeled as Previous. This means that your assistant will automatically have the supported technologies applied. Assistants that have been modified during the previous 6 months will not be affected.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-algorithm-version"},{"document_id":"ibmcld_03040-43198-45083","score":15.074948885,"text":"\nRich response types support\n: Rich response types are now supported in a dialog node with slots. You can display a list of options for a user to choose from as the prompt for a slot, for example. For more information, see [Gathering information with slots](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots).\n\nImproved Entities, Dialog, and Intents page responsiveness\n: The Entities, Dialog, and Intents pages were updated to use a new JavaScript library that increases the page responsiveness. As a result, the look of some graphical user interface elements, such as buttons, changed slightly, but the function did not.\n\nCreating contextual entities is easier\n: The process you use to annotate entity mentions from intent user examples was improved. You can now put the intent page into annotation mode to more easily select and label mentions. For more information, see [Adding contextual entities](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-entitiesentities-create-annotation-based).\n\nWebhook callouts are available\n: Add webhooks to dialog nodes to make programmatic calls to an external application as part of the conversational flow. This capability is being introduced as a beta feature. For more details, see [Making a programmatic call from dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-webhooks).\n\nTesting improvement\n: You can now see the top three intents that were recognized in a test user input from the Try it out pane. For more details, see [Testing your dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tasksdialog-tasks-test).\n\n\n\n\n\n 3 September 2019 \n\nIBM Watson\u00ae Assistant for IBM Cloud Pak\u00ae for Data version 1.3 is available\n: Watson Assistant for IBM Cloud Pak\u00ae for Data version 1.3 is compatible with IBM Cloud Pak\u00ae for Data versions 2.1.0.1 and 2.1.0.2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-release-notes"},{"document_id":"ibmcld_02873-1543-3356","score":14.9979458211,"text":"\nIt might also be an entity type, an entity value, or a context variable value. See [Conditions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-builddialog-overview-conditions) for more information.\n* Response: The utterance that your assistant uses to respond to the user. The response can also be configured to show an image or a list of options, or to trigger programmatic actions. See [Responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-builddialog-overview-responses) for more information.\n\n\n\nYou can think of the node as having an if\/then construction: if this condition is true, then return this response.\n\nFor example, the following node is triggered if the natural language processing function of your assistant determines that the user input contains the cupcake-menu intent. As a result of the node being triggered, your assistant responds with an appropriate answer.\n\n![Shows the user asking about cupcake flavors. the If condition is #cupcake-menu and the Then response is a list of cupcake flavors.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/node1-simple.png)\n\nA single node with one condition and response can handle simple user requests. But, more often than not, users have more sophisticated questions or want help with more complex tasks. You can add child nodes that ask the user to provide any additional information that your assistant needs.\n\n![Shows that the first node in the dialog asks which type of cupcake the user wants, gluten-free or regular, and has two child nodes that provide a different response depending on the user's answer.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/node1-children.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-build"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03126-3707-6008","score":30.0830828379,"text":"\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform.\n\n\n\n\n\n What languages does your assistant speak? \n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language).\n\n\n\n\n\n Does your assistant see the glass as half full? \n\nIs your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Choose a personality for your assistant, and then write conversations that reflect that personality. Don't overdo it. Don't sacrifice usability for the sake of keeping your assistant in character. But strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chat bots to identify themselves as chat bots.\n\n\n\n\n\n Who will build your assistant? \n\nAssemble a team with people who understand your customers and their needs, people who know how to interact with customers to reach the best outcomes. These subject matter experts can focus on designing an engaging conversational flow. In fact, the actions skill is designed with this type of expert in mind. The team can simultaneously build a conversational flow by defining discrete actions.\n\nIf you have data scientists or team members with programming skills, you can take advantage of some advanced capabilities that require varying levels of development expertise. This set of users might prefer to build the conversational flow with a dialog skill because there is greater visibility into the individual components that make up the training data.\n\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants"},{"document_id":"ibmcld_03118-1768-3298","score":28.2663369912,"text":"\n(Search skills are a beta feature available only to Plus or Premium plan users.)\n\n\n\nFor details about the v2 API, see the Watson Assistant [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2).\n\nNote: The Watson Assistant v1 API still supports the legacy \/message method that sends user input directly to the workspace used by a dialog skill. The v1 runtime API is supported primarily for backward compatibility purposes. If you use the v1 \/message method, you must implement your own state management, and you cannot take advantage of versioning or any of the other features of an assistant.\n\n\n\n\n\n Authoring applications \n\nThe v1 API provides methods that enable an application to create or modify dialog skills, as an alternative to building a skill graphically using the Watson Assistant user interface. An authoring application uses the API to create and modify skills, intents, entities, dialog nodes, and other artifacts that make up a dialog skill. For more information, see the [v1 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1).\n\nNote: The v1 authoring methods create and modify workspaces rather than skills. A workspace is a container for the dialog and training data (such as intents and entities) within a dialog skill. If you create a new workspace using the API, it will appear as a new dialog skill in the Watson Assistant user interface.\n\nFor a list of the available API methods, see [API methods summary](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-methods).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-overview"},{"document_id":"ibmcld_03293-18722-20426","score":28.1098123533,"text":"\nAnnotation-based entites are those for which you annotate occurrences of the entity in sample sentences to teach your assistant about the context in which the entity is typically used.\n\nIn order to train a contextual entity model, you can take advantage of your intent examples, which provide readily-available sentences to annotate.\n\nThis feature is generally available in English-language dialog skills and is available as a beta feature in French-langage dialog skills. For more information about language support, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\nUsing an intent's user examples to define contextual entities does not affect the classification of that intent. However, entity mentions that you label are also added to that entity as synonyms. And intent classification does use synonym mentions in intent user examples to establish a weak reference between an intent and an entity.\n\n\n\n1. From your dialog skill, click the Intents tab.\n2. Click an intent to open it.\n\nFor this example, the intent buy_supplies defines the order function for an online retailer.\n\n![Select the #buy_supplies intent](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oe-intent.png)\n3. Click Annotate entities, and then review the intent examples for potential entity mentions.\n\n![Shows the Annotate entities toggle](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oe-annotate.png)\n4. Click any word, words, or punctuation that is part of a single entity mention from the intent examples.\n\nIn this example, mobile phones is the entity mention.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entities"},{"document_id":"ibmcld_16364-67629-69709","score":28.0248763277,"text":"\n: We have added step-by-step documentation for connecting to [Genesys](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone-genesys) and [Twilio Flex](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone-flex) over the phone. Easily hand off to your live agents when your customers require telephony support from your service team. Watson Assistant deploys on the phone via SIP, so most phone based service desks can easily be integrated via SIP trunking standards.\n\n\n\n\n\n 23 August 2021 \n\nIntent detection updates\n: Intent detection for the English language has been updated with the addition of new word-piece algorithms. These algorithms improve tolerance for out-of-vocabulary words and misspelling. This change affects only English-language assistants, and only if the enhanced intent recognition model is enabled. (For more information about the enhanced intent recognition model, and how to determine whether it is enabled, see [Improved intent recognition](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intent-detection).)\n\nAutomatic retraining of old skills and workspaces\n: As of August 23, 2021, Watson Assistant enabled automatic retraining of existing skills in order to take advantage of updated algorithms. The Watson Assistant service will continually monitor all ML models, and will automatically retrain those models that have not been retrained within the previous 6 months. For more information, see [Automatic retraining of old skills and workspaces](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-auto-retrain).\n\n\n\n\n\n 19 August 2021 \n\nActions preview now includes debug mode and variable values\n: When previewing your actions, you can use debug mode and variable values to ensure your assistant is working the way you expect.\n\nDebug mode allows you to go to the corresponding step by clicking on a step locator next to each message. It shows you the confidence score of top three possible action when the input triggers an action. You can also follow the step in the action editor along with the conversation flow.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03369-31953-34073","score":27.924899491,"text":"\nDeploy your assistant on the phone in minutes\n: We have partnered with [IntelePeer](https:\/\/intelepeer.com\/) to enable you to generate a phone number for free within the phone integration. Simply choose to generate a free number when following the prompts to create a phone integration, finish the setup, and a number is assigned to your assistant. These numbers are robust and ready for production.\n\nConnect to your existing service desks\n: We have added step-by-step documentation for connecting to [Genesys](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone-genesys) and [Twilio Flex](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone-flex) over the phone. Easily hand off to your live agents when your customers require telephony support from your service team. Watson Assistant deploys on the phone via SIP, so most phone based service desks can easily be integrated via SIP trunking standards.\n\n\n\n\n\n 23 August 2021 \n\nIntent detection updates\n: Intent detection for the English language has been updated with the addition of new word-piece algorithms. These algorithms improve tolerance for out-of-vocabulary words and misspelling. This change affects only English-language assistants, and only if the enhanced intent recognition model is enabled.\n\nAutomatic retraining of old skills and workspaces\n: As of August 23, 2021, Watson Assistant enabled automatic retraining of existing skills in order to take advantage of updated algorithms. The Watson Assistant service will continually monitor all ML models, and will automatically retrain those models that have not been retrained within the previous 6 months. For more information, see [Automatic retraining of old skills and workspaces](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-auto-retrain).\n\n\n\n\n\n 19 August 2021 \n\nActions preview now includes debug mode and variable values\n: When previewing your actions, you can use debug mode and variable values to ensure your assistant is working the way you expect.\n\nDebug mode allows you to go to the corresponding step by clicking on a step locator next to each message.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_02970-17020-19106","score":27.540307607,"text":"\nYou can also define an English entity value\/synonym, and fuzzy matching will match only your defined entity value\/synonym. For example, fuzzy matching may match the term unsure with insurance; but if you have unsure defined as a value\/synonym for an entity like @option, then unsure will always be matched to @option, and not to insurance.\n\nYour fuzzy matching setting has no impact on synonym recommendations. Even if fuzzy matching is enabled, synonyms are suggested for the exact value you specify only, not the value and slight variations of the value.\n\nTo understand how fuzzy matching and autocorrection are related to one another, see the [autocorrection documentation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-spell-checkdialog-runtime-spell-check-vs-fuzzy-matching).\n\n\n\n\n\n\n\n Adding contextual entities \n\nIf you are using version 1.3 of the product, see [Adding contextual entities in v1.3](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-entitiesentities-create-annotation-based-v130) instead. The way you annotate entity mentions changed between releases.\n\nAnnotation-based entites are those for which you annotate occurrences of the entity in sample sentences to teach your assistant about the context in which the entity is typically used.\n\nIn order to train a contextual entity model, you can take advantage of your intent examples, which provide readily-available sentences to annotate.\n\nThis feature is generally available in English-language dialog skills and is available as a beta feature in French-langage dialog skills. For more information about language support, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support).\n\nUsing an intent's user examples to define contextual entities does not affect the classification of that intent. However, entity mentions that you label are also added to that entity as synonyms. And intent classification does use synonym mentions in intent user examples to establish a weak reference between an intent and an entity.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-entities"},{"document_id":"ibmcld_03054-18427-20301","score":27.2386522126,"text":"\nFor details about how to add a search skill response type, see [Adding rich responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia-add).\n\nFor more tips about improving results, read the [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/) blog post.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. Open the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-ass-icon.png) to open the Assistants page.\n\nv1.3: Click the Assistants tab.\n2. Click to open the tile for the assistant to which you want to add the skill.\n3. Click Add Search Skill.\n4. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nAfter you add a search skill to an assistant, it is automatically enabled for the assistant as follows:\n\n\n\n* If the assistant has only a search skill, any user input that is submitted to one of the assistant's integration channels triggers the search skill.\n* If the assistant has both a dialog skill and a search skill, any user input triggers the dialog skill first.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_03118-4-2208","score":26.9714758106,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Watson Assistant API overview \n\nYou can use the Watson Assistant REST APIs, and the corresponding SDKs, to develop applications that interact with the service.\n\n\n\n Client applications \n\nTo build a virtual assistant or other client application that communicates with an assistant at run time, use the new v2 API. By using this API, you can develop a user-facing client that can be deployed for production use, an application that brokers communication between an assistant and another service (such as a chat service or back-end system), or a testing application.\n\nBy using the v2 runtime API to communicate with your assistant, your application can take advantage of the following features:\n\n\n\n* Automatic state management. The v2 runtime API manages each session with an end user, storing and maintaining all of the context data your assistant needs for a complete conversation.\n* Ease of deployment using assistants. In addition to supporting custom clients, an assistant can be easily deployed to popular messaging channels such as Slack and Facebook Messenger.\n* Versioning. With dialog skill versioning, you can save a snapshot of your skill and link your assistant to that specific version. You can then continue to update your development version without affecting the production assistant.\n* Search capabilities. The v2 runtime API can be used to receive responses from both dialog skills and search skills. When a query is submitted that your dialog skill cannot answer, the assistant can use a search skill to find the best answer from the configured data sources. (Search skills are a beta feature available only to Plus or Premium plan users.)\n\n\n\nFor details about the v2 API, see the Watson Assistant [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2).\n\nNote: The Watson Assistant v1 API still supports the legacy \/message method that sends user input directly to the workspace used by a dialog skill. The v1 runtime API is supported primarily for backward compatibility purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-overview"},{"document_id":"ibmcld_16364-82764-84754","score":26.9026443676,"text":"\n* For a Phone integration, if you connect to existing speech service instances, make sure those speech services use credentials that were generated with the latest endpoint syntax (a URL that starts with https:\/\/api.{location}.speech-to-text.watson.cloud.ibm.com\/).\n* For a search skill, if you connect to an existing Discovery service instance, make sure the Discovery service uses credentials that were generated with the supported syntax (a URL that starts with https:\/\/api.{location}.discovery.watson.cloud.ibm.com\/).\n* If you are using [Jupyter notebooks](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resourceslogs-resources-jupyter-logs) to do advanced analytics, check your Jupyter notebook files to make sure they don't specify URLs with the old watsonplatform.net syntax. If so, update your files.\n* No action is required for the following integration types:\n\n\n\n* Intercom\n* SMS with Twilio\n* WhatsApp with Twilio\n* Zendesk service desk connection from web chat\n\n\n\n\n\n\n\n\n\n 23 March 2021 \n\nActions skill improvement\n: Actions have a new toolbar making it easier to send feedback, access settings, save, and close.\n\n\n\n\n\n 17 March 2021 \n\nChannel transfer response type\n: Dialog skills now include a channel transfer response type. If your assistant uses multiple integrations to support different channels for interaction with users, there might be some situations when a customer begins a conversation in one channel but then needs to transfer to a different channel. The most common such situation is transferring a conversation to the web chat integration, to take advantage of web chat features such as service desk integration. For more information, see [Adding a Channel transfer response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-channel-transfer).\n\nIntercom and WhatsApp integrations now available in Lite plan\n: The integrations for Intercom and WhatsApp are now available in the Lite plan for Watson Assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03383-17365-19519","score":26.8338713873,"text":"\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03054-24418-26156","score":14.9462103644,"text":"\nYou will specify this value as the {url}.\n3. Copy the bearer token also. You will need to pass the token when you make an API call.\n4. From the dialog builder in the user interface, add a search skill response type to a dialog node.\n5. Make a note of the unique ID of the assistant to which you added the dialog that you edited in the previous step.\n\n\n\n* To get the ID for an assistant from the user interface, click the more menu on the tile for the assistant, and then click Settings. Click API Details.\n\n\n\n6. Start a session, which is kind of like a new conversation, in which you will make the user input request.\n\nUse a POST request like this to create the session, and pass an empty body with the request:\n\ncurl -H \"Authorization: Bearer {token}\" -X POST \"{url}\/v2\/assistants\/{assistant_id}\/sessions?version=2020-04-01 -k\"\n\n\n\n* {token} is the token you copied earlier.\n* {assistant_id} is the assistant ID you copied earlier.\n\n\n\n7. Now, send a user input request that triggers the dialog node with the search skill response type.\n\nFor example, to test a search that is initiated from the greeting node, you might use a POST request like this:\n\ncurl -H \"Authorization: Bearer {token}\" -H \"Content-Type:application\/json\" -X POST -d \"{\"input\": {\"text\": \"Hello\"}}\" \"https:\/\/{my-cluster-hostname}\/assistant\/api\/v2\/assistants\/{assistant_id}\/sessions\/{session_id}\/message?version=2019-02-28\"\n\n\n\n* {token} is the token that is generated in Step 3.\n* {assistant_id} is the assistant ID you copied in Step 2.\n* {session_id} is the ID of the session that you created in the previous step.\n\n\n\n8. Review the response to make sure it includes the search results that you expect.\n9. Repeat this procedure to submit queries that trigger the search.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_03054-27011-29125","score":14.7710329314,"text":"\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition with a search skill response type.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:\n\nintents[0].confidence > 0.5\n\nThis condition is applied to all of the nodes in the folder. The condition tells your assistant to process the nodes in the folder only if your assistant is at least 50% confident that it knows the user's intent.\n3. Move any dialog nodes that you do not want your assistant to process often into the folder.\n\n\n\nAfter changing the dialog, test the assistant to make sure the search skill is triggered as often as you want it to be.\n\nAn alternative approach is to teach the dialog about topics to ignore. To do so, you can add utterances that you want the assistant to send to the search skill immediately as test utterances in the dialog skill's Try it out pane. You can then select the Mark as irrevlant option within the Try it out pane to teach the dialog not to respond to this utterance or others like it.\n\n\n\n\n\n Disabling search \n\nYou can disable the search skill from being triggered.\n\nYou might want to do so temporarily, while you are setting up the integration. Or you might want to only ever trigger a search for specific user queries that you can identify within the dialog, and use a search skill response type to answer.\n\nTo prevent the search skill from being triggered, complete the following steps:\n\n\n\n1. From the Assistants page, click the menu for your assistant, and then choose Settings.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_16342-4330-5240","score":14.4926330006,"text":"\nThis failure rarely happens with the Google custom search extension, but it might happen if you are searching a site with large volumes of metadata that is returned by Google custom search. If you think that this might be a problem, try running the query in an API testing tool like curl, [Insomnia](https:\/\/insomnia.rest\/), or [Postman](https:\/\/www.postman.com\/). Check how many bytes of data you are getting as search results. If the total is at or near 100 kb, you might be able to work around the issue by reducing num_of_results and getting fewer results for each query or by excluding sites or pages with large volumes of metadata.\n\nFor more information, see [Limit on Size of Search Results](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/blob\/master\/integrations\/extensions\/starter-kits\/watson-discovery\/README.mdlimit-on-size-of-search-results) in a starter kit for IBM Watson\u00ae Discovery.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-extension-google"},{"document_id":"ibmcld_13115-10177-12181","score":14.2181686497,"text":"\nYou can also type app:app-log-analysis in the Search... field.\n3. To see logs of specific log level(s), Click on Levels and select multiple levels like Error, info, warning etc.,\n\n\n\n\n\n\n\n\n\n Step 5: Search and filter logs \n\nThe Log Analysis UI, by default, shows all available log entries(Everything). Most recent entries are shown on the bottom through an automatic refresh. In this section, you will modify what and how much is displayed and save this as a View for future use.\n\n\n\n Search logs \n\n\n\n1. In the Search input box located at the bottom of the page in the Log Analysis UI,\n\n\n\n* you can search for lines that contain a specific text like This is my first log entry or 500 internal server error.\n* or a specific log level by entering level:info where level is a field that accepts string value.\n\n\n\nFor more search fields and help, click the syntax help icon next to the search input box\n2. To jump to a specific timeframe, enter 5 mins ago in the Jump to timeframe input box. Click the icon next to the input box to find the other time formats within your retention period.\n3. To highlight the terms, click on Toggle Viewer Tools icon.\n4. Type error as your highlight term in the first input box and hit Enter on your keyboard. Check the highlighted lines with the terms.\n5. Type container as your highlight term in the second input box and hit Enter on your keyboard. Check the highlighted lines with the terms.\n6. Click on Toggle Timeline icon to see lines with logs at a specific time of a day.\n\n\n\n\n\n\n\n Filter logs \n\nYou can filter logs by tags, sources, apps or levels.\n\n\n\n1. On the top bar, click Sources and select the name of the host (worker node) you are interested in checking the logs. Works well if you have multiple worker nodes in your cluster.\n2. To check other container or file logs, click app-log-analysis or Apps and select the checkbox(s) you are interested in seeing the logs.\n\n\n\n\n\n\n\n Create a view \n\nViews are saved shortcuts to a specific set of filters and search queries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-application-log-analysis"},{"document_id":"ibmcld_00634-4405-6200","score":14.0781090652,"text":"\n{\"tokens\":[\"four\",\"score\",\"seven\",\"year\",\"ago\",\"our\",\"father\",\"brought\",\"forth\",\"contin\",\"new\",\"nation\",\"conceiv\",\"liberti\",\"dedic\",\"proposit\",\"all\",\"men\",\"creat\",\"equal\"]}\n\n\n\n\n\n\n\n Which analyzer must I pick? \n\nIt depends on your data. If your data is structured (email addresses, postal codes, names, and so on) in separate fields, then select an analyzer that retains the data you need to search.\n\nOnly index the fields that you need. Keeping the index small helps to improve performance.\n\nConsider the common data sources and look at the best analyzer choices.\n\n\n\n Names \n\nIt's likely that name fields must use an analyzer that doesn't stem words. The White space analyzer keeps the words' case (meaning the search terms must be full, case-sensitive matches) and leaves double-barreled names intact. If you want to split up double-barreled names, then the Standard analyzer can do the job.\n\n\n\n\n\n Email addresses \n\nThe built-in email analyzer serves this purpose, which changes everything to lowercase and then behaves like the Keyword analyzer.\n\n\n\n\n\n Unique ID \n\nOrder numbers, payment references, and UUIDs such as \"A1324S\", \"PayPal0000445\", and \"ABC-1412-BBG\" must be kept without any pre-processing, so the Keyword analyzer is preferred.\n\n\n\n\n\n Country codes \n\nCountry codes like \"UK\" must also use the Keyword analyzer to prevent the removal of \"stopwords\" that match the country codes, for example, \"IN\" for India. The Keyword analyzer is case-sensitive.\n\n\n\n\n\n Text \n\nIt is best to process a block of free-form text with a language-specific analyzer, such as the English analyzer, or in a more general case, the Standard analyzer.\n\n\n\n\n\n\n\n Which option is best? \n\nWhen IBM Cloudant returns data from a search, you can choose between the following options: store: true or include_docs=true.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-search-analyzers"},{"document_id":"ibmcld_00472-37491-38856","score":13.8527991477,"text":"\n8.530665755719783,\n18\n],\n\"fields\": {\n\"city\": \"New York, N.Y.\",\n\"lat\": 40.78333333333333,\n\"lon\": -73.96666666666667\n}\n},\n{\n\"id\": \"city177\",\n\"order\":\n13.756343205985946,\n17\n],\n\"fields\": {\n\"city\": \"Newark, N.J.\",\n\"lat\": 40.733333333333334,\n\"lon\": -74.16666666666667\n}\n},\n{\n\"id\": \"city178\",\n\"order\":\n113.53603438866077,\n26\n],\n\"fields\": {\n\"city\": \"New Haven, Conn.\",\n\"lat\": 41.31666666666667,\n\"lon\": -72.91666666666667\n}\n}\n]\n}\nShow more\n\n\n\n\n\n Highlighting search terms \n\nSometimes it is useful to get the context in which a search term was mentioned so that you can show more emphasized results to a user.\n\nTo get more emphasized results, add the highlight_fields parameter to the search query. Specify the field names for which you would like excerpts, with the highlighted search term returned.\n\nBy default, the search term is placed in <em> tags to highlight it, but the highlight can be overridden by using the highlights_pre_tag and highlights_post_tag parameters.\n\nThe length of the fragments is 100 characters by default. A different length can be requested with the highlights_size parameter.\n\nThe highlights_number parameter controls the number of fragments that are returned, and defaults to 1.\n\nIn the response, a highlights field is added, with one subfield per field name.\n\nFor each field, you receive an array of fragments with the search term highlighted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-search"},{"document_id":"ibmcld_03383-20671-22804","score":13.756751138,"text":"\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane. The search skill is configured separately and attached to an assistant. The dialog skill has no way of knowing the details of the search, and therefore cannot show search results in its \"Try it out\" pane.\n\nConfigure at least one integration channel to test the search skill. In the channel, enter queries that trigger the search. If you initiate any type of search from your dialog, test the dialog to ensure that the search is triggered as expected. If you are not using search response types, test that a search is triggered only when no existing dialog nodes can address the user input. And any time a search is triggered, ensure that it returns meaningful results.\n\n\n\n\n\n Sending more requests to the search skill \n\nIf you want the dialog skill to respond less often and to send more queries to the search skill instead, you can configure the dialog to do so.\n\nYou must add both a dialog skill and search skill to your assistant for this approach to work.\n\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_13042-20707-22840","score":13.756751138,"text":"\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane. The search skill is configured separately and attached to an assistant. The dialog skill has no way of knowing the details of the search, and therefore cannot show search results in its \"Try it out\" pane.\n\nConfigure at least one integration channel to test the search skill. In the channel, enter queries that trigger the search. If you initiate any type of search from your dialog, test the dialog to ensure that the search is triggered as expected. If you are not using search response types, test that a search is triggered only when no existing dialog nodes can address the user input. And any time a search is triggered, ensure that it returns meaningful results.\n\n\n\n\n\n Sending more requests to the search skill \n\nIf you want the dialog skill to respond less often and to send more queries to the search skill instead, you can configure the dialog to do so.\n\nYou must add both a dialog skill and search skill to your assistant for this approach to work.\n\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_16344-7-2142","score":13.6964119475,"text":"\nAdding search \n\nPut your subject matter expertise to work by adding search. Search gives your assistant access to corporate data collections that it can mine for answers.\n\nYour assistant can route complex customer inquiries as a search query. It finds information that is relevant to the query from an external data source and returns it to the assistant.\n\nAdd search to your assistant to prevent the assistant from having to say things like, I'm sorry. I can't help you with that. Instead, the assistant can query existing company documents or data to see whether any useful information can be found and shared with the customer.\n\nYou have two options to add search to your assistant:\n\n\n\n* The search integration for IBM Watson\u00ae Discovery. For more information, see [Add the search integration for IBM Watson\u00ae Discovery](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-overviewsearch-overview-integration).\n* A search extension for Coveo, Google, or NeuralSeek. For more information, see [Add a search extension](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-overviewsearch-overview-extension).\n\n\n\n\n\n Add the search integration for IBM Watson\u00ae Discovery \n\nPlus and Enterprise plans include a built-in search integration. You can embed your existing help content by integrating your assistant with search that is provided by IBM Watson\u00ae Discovery. This gives your assistant access to your organization's data collections that it can mine for answers. Customer questions are used as search queries to find relevant answers for your users.\n\nFor instructions on adding the built-in search integration, see [IBM Watson\u00ae Discovery search integration setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant\/?topic=watson-assistant-search-add).\n\n\n\n\n\n Add a search extension \n\nWith a search extension, you can \"bring your own search\" and use content from your website, knowledge base, or content management system.\n\nFor instructions on adding a search extension, see:\n\n\n\n* [Coveo search extension setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-extension-coveo)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-overview"},{"document_id":"ibmcld_03383-4-1728","score":13.6121267692,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Use a search skill to embed existing help content ![Plus or higher plan only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/plus.png) \n\nPut your subject matter expertise to work by adding a search skill. The search skill gives your assistant access to corporate data collections that it can mine for answers.\n\nWhen a search skill is added, your assistant can route complex customer inquiries to the IBM Watson\u00ae Discovery service. Discovery treats the user input as a search query. It finds information that is relevant to the query from an external data source and returns it to the assistant.\n\nThis feature is available only to paid plan users.\n\nAdd a search skill to your assistant to prevent the assistant from having to say things like, I'm sorry. I can't help you with that. Instead, the assistant can query existing company documents or data to see whether any useful information can be found and shared with the customer.\n\n![Shows a search result in the Preview](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/search-preview-example.png)\n\nTo show the exact answer highlighted in bold font, enable the Emphasize the answer feature that is available with Discovery v2 instances.\n\nWatch a 4-minute video that provides an overview of the search skill:\n\nTo learn more about how search skill can benefit your business, [read this blog post](https:\/\/medium.com\/ibm-watson\/adding-search-to-watson-assistant-99e4e81839e5).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.3044671975}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05838-12220-14151","score":15.5924373187,"text":"\nYou can't undo a deletion. After the cluster is deleted, you can no longer check the master state because the cluster is completely removed. \n delete_failed The master failed to delete. IBM Support is notified and works to resolve the issue. You can't resolve the issue by trying to delete the cluster again. Instead, check the Master Status field for more information, or wait for the cluster to delete. You can also [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). \n scaled_down The master resources have been scaled down to zero replicas. This is a temporary state that occurs while etcd is being restored after a backup. You cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud ks cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitor"},{"document_id":"ibmcld_10189-3187-5240","score":15.5179648837,"text":"\nYou cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud oc cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud oc versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n Understanding the impact of a master outage","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_master"},{"document_id":"ibmcld_05754-3185-5238","score":15.5179648837,"text":"\nYou cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud ks cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud ks versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n Understanding the impact of a master outage","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_master"},{"document_id":"ibmcld_10290-70537-72315","score":15.4186019775,"text":"\nibmcloud oc cluster master refresh \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nApply configuration changes for the Kubernetes master that are requested with the ibmcloud oc cluster master commands. The highly available Kubernetes master components are restarted in a rolling restart. Your worker nodes, apps, and resources are not modified and continue to run.\n\nThe apiserver-refresh and cluster-refresh aliases for this command are deprecated.\n\nibmcloud oc cluster master refresh --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n\n\n ibmcloud oc cluster master update \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite\n\nUpdate the Kubernetes master and API server. During the update, you can't access or change the cluster. Worker nodes, apps, and resources that were deployed are not modified and continue to run.\n\nYou might need to change your YAML files for future deployments. Review this [release note](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions) for details.\n\nThe cluster-update alias for this command is deprecated.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--version MAJOR.MINOR.PATCH\n: Optional: The Kubernetes version of the cluster. If you don't specify a version, the Kubernetes master is updated to the default API version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"},{"document_id":"ibmcld_10642-1365-3347","score":15.4141501946,"text":"\nThen, [update the worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker_node) in your cluster.\n\nWorker nodes can run later patch versions than the master, such as patch versions that are specific to worker nodes for security updates.\n\nHow are patch updates applied?\n: By default, patch updates for the master are applied automatically over the course of several days, so a master patch version might show up as available before it is applied to your master. The update automation also skips clusters that are in an unhealthy state or have operations currently in progress. Occasionally, IBM might disable automatic updates for a specific master fix pack, such as a patch that is only needed if a master is updated from one minor version to another. In any of these cases, you can [check the versions change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions) for any potential impact and choose to safely use the ibmcloud oc cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update) yourself without waiting for the update automation to apply.\n\nUnlike the master, you must update your workers for each patch version.\n\nWhat happens during the master update?\n: Your master is highly available with three replica master pods. The master pods have a rolling update, during which only one pod is unavailable at a time. Two instances are up and running so that you can access and change the cluster during the update. Your worker nodes, apps, and resources continue to run.\n\nCan I roll back the update?\n: No, you can't roll back a cluster to a previous version after the update process takes place. Be sure to use a test cluster and follow the instructions to address potential issues before you update your production master.\n\nWhat process can I follow to update the master?\n: The following diagram shows the process that you can take to update your master.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_10189-1607-3670","score":15.3496743317,"text":"\nThe status includes a timestamp of how long the master has been in the same state, such as Ready (1 month ago). The Master State reflects the lifecycle of possible operations that can be performed on the master, such as deploying, updating, and deleting. Each state is described in the following table.\n\n\n\nMaster states\n\n Master state Description \n\n deployed The master is successfully deployed. Check the status to verify that the master is Ready or to see if an update is available. \n deploying The master is currently deploying. Wait for the state to become deployed before working with your cluster, such as adding worker nodes. \n deploy_failed The master failed to deploy. IBM Support is notified and works to resolve the issue. Check the Master Status field for more information, or wait for the state to become deployed. \n deleting The master is currently deleting because you deleted the cluster. You can't undo a deletion. After the cluster is deleted, you can no longer check the master state because the cluster is completely removed. \n delete_failed The master failed to delete. IBM Support is notified and works to resolve the issue. You can't resolve the issue by trying to delete the cluster again. Instead, check the Master Status field for more information, or wait for the cluster to delete. You can also [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). \n scaled_down The master resources have been scaled down to zero replicas. This is a temporary state that occurs while etcd is being restored after a backup. You cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_master"},{"document_id":"ibmcld_05754-1605-3668","score":15.3496743317,"text":"\nThe status includes a timestamp of how long the master has been in the same state, such as Ready (1 month ago). The Master State reflects the lifecycle of possible operations that can be performed on the master, such as deploying, updating, and deleting. Each state is described in the following table.\n\n\n\nMaster states\n\n Master state Description \n\n deployed The master is successfully deployed. Check the status to verify that the master is Ready or to see if an update is available. \n deploying The master is currently deploying. Wait for the state to become deployed before working with your cluster, such as adding worker nodes. \n deploy_failed The master failed to deploy. IBM Support is notified and works to resolve the issue. Check the Master Status field for more information, or wait for the state to become deployed. \n deleting The master is currently deleting because you deleted the cluster. You can't undo a deletion. After the cluster is deleted, you can no longer check the master state because the cluster is completely removed. \n delete_failed The master failed to delete. IBM Support is notified and works to resolve the issue. You can't resolve the issue by trying to delete the cluster again. Instead, check the Master Status field for more information, or wait for the cluster to delete. You can also [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). \n scaled_down The master resources have been scaled down to zero replicas. This is a temporary state that occurs while etcd is being restored after a backup. You cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_master"},{"document_id":"ibmcld_05891-71325-73333","score":15.3175603449,"text":"\nExample cluster master public-service-endpoint disable command \n\nibmcloud ks cluster master public-service-endpoint disable --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master public-service-endpoint enable \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nEnable the [public cloud service endpoint](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_basicsworkeruser-master) to make your cluster master publicly accessible.\n\nAfter you run this command, you must refresh the API server to use the service endpoint by following the prompt in the CLI.\n\nibmcloud ks cluster master public-service-endpoint enable --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n-y\n: Optional: Refresh the cluster master with no user prompts.\n\n\n\n Example cluster master public-service-endpoint enable command \n\nibmcloud ks cluster master public-service-endpoint enable --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master refresh \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nApply configuration changes for the Kubernetes master that are requested with the ibmcloud ks cluster master commands. The highly available Kubernetes master components are restarted in a rolling restart. Your worker nodes, apps, and resources are not modified and continue to run.\n\nThe apiserver-refresh and cluster-refresh aliases for this command are deprecated.\n\nibmcloud ks cluster master refresh --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n\n\n ibmcloud ks cluster master update \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_04489-72055-74063","score":15.3175603449,"text":"\nExample cluster master public-service-endpoint disable command \n\nibmcloud ks cluster master public-service-endpoint disable --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master public-service-endpoint enable \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nEnable the [public cloud service endpoint](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_basicsworkeruser-master) to make your cluster master publicly accessible.\n\nAfter you run this command, you must refresh the API server to use the service endpoint by following the prompt in the CLI.\n\nibmcloud ks cluster master public-service-endpoint enable --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n-y\n: Optional: Refresh the cluster master with no user prompts.\n\n\n\n Example cluster master public-service-endpoint enable command \n\nibmcloud ks cluster master public-service-endpoint enable --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master refresh \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nApply configuration changes for the Kubernetes master that are requested with the ibmcloud ks cluster master commands. The highly available Kubernetes master components are restarted in a rolling restart. Your worker nodes, apps, and resources are not modified and continue to run.\n\nThe apiserver-refresh and cluster-refresh aliases for this command are deprecated.\n\nibmcloud ks cluster master refresh --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n\n\n ibmcloud ks cluster master update \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"},{"document_id":"ibmcld_10246-14143-16190","score":15.3166190995,"text":"\nCheck the status to verify that the master is Ready or to see if an update is available. \n deploying The master is currently deploying. Wait for the state to become deployed before working with your cluster, such as adding worker nodes. \n deploy_failed The master failed to deploy. IBM Support is notified and works to resolve the issue. Check the Master Status field for more information, or wait for the state to become deployed. \n deleting The master is currently deleting because you deleted the cluster. You can't undo a deletion. After the cluster is deleted, you can no longer check the master state because the cluster is completely removed. \n delete_failed The master failed to delete. IBM Support is notified and works to resolve the issue. You can't resolve the issue by trying to delete the cluster again. Instead, check the Master Status field for more information, or wait for the cluster to delete. You can also [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). \n scaled_down The master resources have been scaled down to zero replicas. This is a temporary state that occurs while etcd is being restored after a backup. You cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-monitor"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10070-7-1616","score":33.945371722,"text":"\nCIS Kubernetes Benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations.\n\nWhen a new Kubernetes version is released as part of a [supported Red Hat OpenShift version](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions), IBM engineers compare the default configuration of a cluster that runs that Kubernetes version against the benchmark and publishes the results in this documentation. You can review how specific versions of your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters meet the CIS Kubernetes Benchmark.\n\n\n\n Available benchmark versions \n\nUse the list to find CIS Kubernetes Benchmark results for available versions.\n\n\n\n* [Version 4.12](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-412)\n* [Version 4.11](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-411)\n* [Version 4.10](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410)\n* [Version 4.9](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-49)\n* [Version 4.8](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-48)\n\n\n\n\n\n\n\n Using the benchmark \n\nAs a security administrator or auditor, you might want to compare your company's internal standards and external regulatory requirements with the CIS Kubernetes Benchmark. The benchmark recommendations are provided by the Center for Internet Security, not by IBM.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark"},{"document_id":"ibmcld_05608-7-1899","score":33.8082108989,"text":"\nCIS Kubernetes Benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations.\n\nWhen a new [Kubernetes version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions) is released, IBM engineers compare the default configuration of a cluster that runs that Kubernetes version against the benchmark and publishes the results in this documentation. You can review how specific versions of your IBM Cloud\u00ae Kubernetes Service clusters meet the CIS Kubernetes Benchmark.\n\n\n\n Available benchmark versions \n\nUse the list to find CIS Kubernetes Benchmark results for available versions.\n\n\n\n* [Version 1.27](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-127)\n* [Version 1.26](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-126)\n* [Version 1.25](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-125)\n* [Version 1.24](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124)\n* [Version 1.23](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-123)\n\n\n\n\n\n\n\n Using the benchmark \n\nAs a security administrator or auditor, you might want to compare your company's internal standards and external regulatory requirements with the CIS Kubernetes Benchmark. The benchmark recommendations are provided by the Center for Internet Security, not by IBM. IBM might not configure default settings in a way that meets every recommendation, but documents whether the recommendation is met to help you in your review. For example, you might use the benchmark in an audit to confirm that basic security measures are in place, and to identify areas where you might enhance your security.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark"},{"document_id":"ibmcld_10510-20784-22884","score":33.1643249932,"text":"\nWorker node setup in Red Hat OpenShift on IBM Cloud excluding network security\n\nCIS-compliant RHEL image\n: Every worker node is set up with a Red Hat Enterprise Linux operating system that implements the benchmarks that are published by the Center of Internet Security (CIS). The user or the owner of the machine can't change this operating system to another operating system. To review the current RHEL version, run oc get nodes -o wide. IBM works with internal and external security advisory teams to address potential security compliance vulnerabilities. Security updates and patches for the operating system are made available through Red Hat OpenShift on IBM Cloud and must be installed by the user to keep the worker node secure. Red Hat OpenShift on IBM Cloud uses a Red Hat Enterprise Linux kernel for worker nodes. You can run containers based on any Linux distribution in Red Hat OpenShift on IBM Cloud. Check with your container image vendor to verify that your container images can run on a Red Hat Enterprise kernel.\n\nContinuous monitoring by Site Reliability Engineers (SREs)\n: The image that is installed on your worker nodes is continuously monitored by IBM Site Reliability Engineers (SREs) to detect vulnerabilities and security compliance issues. To address vulnerabilities, SREs create security patches and fix packs for your worker nodes. Make sure to apply these patches when they are available to ensure a secure environment for your worker nodes and the apps that you run on them.\n\nCIS Kubernetes worker node benchmark\n: To configure Red Hat OpenShift on IBM Cloud, IBM engineers follow relevant cybersecurity practices from the Kubernetes worker node benchmark that is published by the [Center of Internet Security (CIS)](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/). You can review the compliance of worker nodes against [CIS Kubernetes benchmark](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkcis-worker-test) and [Red Hat OpenShift benchmark](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-benchmark-comparison) standards.\n\nCompute isolation","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"},{"document_id":"ibmcld_16261-10613-12744","score":32.8084462355,"text":"\nBecause we need a way to end the conversation, the client app is also watching for the literal command quit to indicate that the program should exit.\n\nBut something still isn't right:\n\nWelcome to the Watson Assistant example. What's your name?\n>> Robert\nI'm afraid I don't understand. Please rephrase your question.\n>> I want to make an appointment.\nWhat day would you like to come in?\n>> Thursday\nI'm afraid I don't understand. Please rephrase your question.\n>>\n\nThe assistant is starting out with the correct greeting, but it doesn't understand when you tell it your name. And if you tell it you want to make an appointment, the correct action is triggered; but once again, it doesn't understand when you answer the follow-up question.\n\nThis is happening because we are using the stateless message method, which means that it is the responsibility of our client application to maintain state information for the conversation. Because we are not yet doing anything to maintain state, the assistant sees every round of user input as the first turn of a new conversation. Because it has no memory of asking a question, it tries to interpret your answer as a new question or request.\n\n\n\n\n\n Maintaining state \n\nState information for your conversation is maintained using the context. The context is an object that is passed back and forth between your application and the assistant, storing information that can be preserved and updated as the conversation goes on. Because we are using the stateless message method, the assistant does not store the context, so it is the responsibility of our client application to maintain it from one turn of the conversation to the next.\n\nThe context includes a session ID for each conversation, as well as a counter that is incremented with each turn of the conversation. The assistant updates the context and returns it with each response. But our previous version of the example did not preserve the context, so these updates were lost, and each round of input appeared to be the start of a new conversation. We can fix that by saving the context and sending it back to the assistant each time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client"},{"document_id":"ibmcld_05713-327998-329386","score":32.2502739678,"text":"\n* [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types)\n* [Release lifecycle](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsrelease_lifecycle)\n* [Preparing to update](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsprep-up)\n* [Archive](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsk8s_version_archive)\n\n\n\n[Kubernetes version change logs](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelogchangelog)\n\n\n\n* [Overview](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelogchangelog_overview)\n* [Version change logs](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelogchange-logs-by-version)\n\n\n\n[CIS Kubernetes Benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmarkcis-benchmark)\n\n\n\n* [Available benchmark versions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmarkcis-benchmark-versions)\n* [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmarkcis-benchmark-use)\n\n\n\n* [What does the benchmark cover?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmarkbenchmark-scope)\n* [What do the benchmark recommendations mean?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmarkbenchmark-meaning)\n* [What parts of the benchmark am I responsible for?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_05713-358399-359785","score":31.9615748178,"text":"\n* [5.1 RBAC and service accounts](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124cis-benchmark-51-124)\n* [5.2 Pod Security Policies](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124cis-benchmark-52-124)\n* [5.3 Network policies and CNI](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124cis-benchmark-53-124)\n* [5.4 Secrets management](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124cis-benchmark-54-124)\n* [5.5 Extensible admission control](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124cis-benchmark-55-124)\n* [5.6 General policies](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124cis-benchmark-56-124)\n\n\n\n* [IBM remediations and explanations](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124cis-benchmark-remediations-124)\n\n\n\n\n\n\n\n\n\n Add-on version history \n\n[Supported cluster add-on versions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-supported-cluster-addon-versionssupported-cluster-addon-versions)\n\n[Ingress ALB and Fluentd version change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-add-ons-changelogcluster-add-ons-changelog)\n\n\n\n* [Kubernetes Ingress image change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-add-ons-changelogkube_ingress_changelog)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_05612-7-1934","score":31.696788035,"text":"\nVersion 1.21 CIS Kubernetes benchmark \n\nKubernetes version 1.21 becomes unsupported on 14 September 2022. Update your cluster to at least [version 1.22](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions_122) as soon as possible.\n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.21. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-121"},{"document_id":"ibmcld_05653-161734-163200","score":31.4815193114,"text":"\n: Added more information about [how the IBM Cloud Kubernetes Service API key is used](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access-credsapi_key_about).\n\nBenchmark for Kubernetes 1.19\n: Review the [1.5 CIS Kubernetes benchmark results](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-119) for clusters that run Kubernetes version 1.19.\n\nHuge pages\n: In clusters that run Kubernetes 1.19 or later, you can [enable Kubernetes HugePages scheduling on your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kernelhuge-pages).\n\nIstio add-on\n: Version [1.6.12](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istio-changelog1612) of the Istio managed add-on is released.\n\n\n\n\n\n 16 October 2020 \n\nGateway firewalls and Calico policies\n: For classic clusters in Dallas, updated the required IP addresses and ports that you must open in a [public gateway firewall device](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-firewallfirewall_outbound), [private gateway device firewall](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-firewallfirewall_private), or [Calico network isolation policies](https:\/\/github.com\/IBM-Cloud\/kube-samples\/tree\/master\/calico-policies).\n\nIngress classes\n: Added information about [specifying Ingress classes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-managed-ingress-aboutmanaged-ingress-class) to apply Ingress resources to specific ALBs.\n\nObject Storage","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-containers-relnotes"},{"document_id":"ibmcld_10534-327288-328620","score":31.4762951261,"text":"\n* [Clusters in Satellite locations without CoreOS enabled](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versionsos-satellite-without-coreos)\n\n\n\n* [Checking a cluster's Kubernetes server version](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versionsopenshift_server_version)\n* [Release lifecycle](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versionsrelease_lifecycle)\n* [Archive](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versionsversion-archive)\n\n\n\n[CIS Kubernetes Benchmark](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkcis-benchmark)\n\n\n\n* [Available benchmark versions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkcis-benchmark-versions)\n* [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkcis-benchmark-use)\n\n\n\n* [What does the benchmark cover?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkbenchmark-scope)\n* [What do the benchmark recommendations mean?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkbenchmark-meaning)\n* [What parts of the benchmark am I responsible for?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkbencmark-resp)\n* [What if some part of the service fails to comply with a recommendation?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_05713-329078-330562","score":31.2111138208,"text":"\n* [What does the benchmark cover?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmarkbenchmark-scope)\n* [What do the benchmark recommendations mean?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmarkbenchmark-meaning)\n* [What parts of the benchmark am I responsible for?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmarkbencmark-resp)\n* [What if some part of the service fails to comply with a recommendation?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmarkbencmark-service-compliance)\n* [What else can I do to increase the security and compliance of my cluster?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmarkbenchmark-what-else)\n\n\n\n* [Running the worker node CIS Kubernetes benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmarkcis-worker-test)\n\n\n\n\n\n Version 1.27 \n\n[1.27 version information and update actions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions_127cs_versions_127)\n\n\n\n* [Release timeline](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions_127release_timeline_127)\n* [Preparing to update](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions_127prep-up-127)\n\n\n\n* [Update before master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions_127before_127)\n\n\n\n\n\n[Kubernetes version 1.27 change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog_127changelog_127)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.765360637}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13498-7173-9446","score":19.5539023851,"text":"\nWhen specified in combination with PARTITIONED BY, it sorts the rows within each partition by the sort order that is specified in the SORT BY clause. When specified in combination with PARTITIONED INTO, the same is done, which is often referred to as clustering the rows by the specified columns into the fixed number of partitions specified by PARTITIONED INTO. When specified without the PARTITIONED clause, it is equivalent to an ORDER BY clause specified at the top level of the SQL SELECT statement. If PARTITIONED INTO is specified, the ORDER BY clause is ignored.\n\n\n\n Partition by columns \n\nWhen you use the PARTITIONED BY (column-list) clause without specifying INTO x BUCKETS\/OBJECTS, you can store the query result by using Hive-style partitioning, which is to create partitions that contain only rows that have certain values for one or more columns. Choose this physical layout if the stored object is further analyzed by using SQL queries that specify predicates on the partition columns.\n\nFor example, a result object that contains worldwide order data has a column country to represent the country that the order is initiated from. Partitioning the result object by the column PARTITIONED BY (country), would create a result object with a partition for each country present in the query result.\n\nWhen the result object is stored this way on Cloud Object Storage, each SQL query that contains a predicate, such as country = 'USA' or country in ('MALTA', 'ITALY', 'VATICAN CITY'), benefits from this physical layout. The reason is that during SQL query execution partitions must be read only if they contain data for the countries of interest. This layout tremendously cuts down the I\/O traffic of the SQL query.\n\nSee the following extra remarks on Hive-style partitioning.\n\n\n\n* Hive-style partitions have an eye-catching naming scheme because the column names that are used for partitioning are part of the partition object prefix, for example, \/order\/COUNTRY=USA\/part-m-00000.snappy.parquet.\n* Hive-style partitions do not contain any values for partition columns since their values are stored in the object prefix of the partition. Thus, if you copy a HIVE-style partition and rename the object prefix by removing the partition column values, you lose data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_13480-4908-6825","score":17.3240714411,"text":"\nIncorrect column name specification results in an empty column, that is, the column seems to contain no data. To solve such a problem, use the automatic schema detection, reorder the columns, or omit some columns.\n\nThe SHOW TABLES statement provides you with an overview of the existing tables in your instance. This statement allows an optional search filter to limit the number of results:\n\nSHOW TABLES LIKE 'cus'\n\nIt is not possible to use a different namespace than default.\n\nTo clean up catalog entries for unused data, use the DROP TABLE statement. This statement removes the table definition from the catalog without affecting the actual data on Object Storage:\n\nDROP TABLE customers\n\n\n\n\n\n Partitioned tables \n\nYou can manage a table in the catalog that references data that is organized in multiple partitions on Object Storage. The naming of the objects must adhere to the Hive-style partition naming convention: The object names must include the structure \/columm=value\/. The column must be a column name that is included in the schema definition of the CREATE TABLE statement. You can also have more than one partitioning columns in the object names, such as \/columm1=value\/column2=value\/.\n\nFollowing is an example list of object names on Object Storage that is partitioned on the country column with the Hive-style partition naming convention:\n\ncustomers_partitioned.csv\/country=Germany\/cust-1.csv\ncustomers_partitioned.csv\/country=Germany\/cust-2.csv\ncustomers_partitioned.csv\/country=Spain\/cust-1.csv\ncustomers_partitioned.csv\/country=Austria\/cust-1.csv\ncustomers_partitioned.csv\/country=Austria\/cust-2.csv\ncustomers_partitioned.csv\/country=USA\/cust-1.csv\ncustomers_partitioned.csv\/country=USA\/cust-2.csv\ncustomers_partitioned.csv\/country=USA\/cust-3.csv\ncustomers_partitioned.csv\/country=Sweden\/cust-1.csv\n\nTo query partitioned tables, you must perform two mandatory steps:\n\n\n\n Step 1: Register the table","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog"},{"document_id":"ibmcld_13480-6528-8270","score":16.2084032969,"text":"\ncustomers_partitioned.csv\/country=USA\/cust-1.csv\ncustomers_partitioned.csv\/country=USA\/cust-2.csv\ncustomers_partitioned.csv\/country=USA\/cust-3.csv\ncustomers_partitioned.csv\/country=Sweden\/cust-1.csv\n\nTo query partitioned tables, you must perform two mandatory steps:\n\n\n\n Step 1: Register the table \n\nThis data partitioning is reflected in the PARTITIONED BY clause of the following CREATE TABLE statement:\n\nCREATE TABLE customers (\ncustomerID string,\ncompanyName string,\ncontactName string,\ncontactTitle string,\naddress string,\nregion string,\npostalCode string,\ncountry string,\nphone string,\nfax string\n)\nUSING CSV\nPARTITIONED BY (country)\nLOCATION cos:\/\/us-geo\/sql\/customers_partitioned.csv\n\nAutomatic schema detection also recognizes partitioned tables from the structure of the object names, so the same table definition is created from the following statement:\n\nCREATE TABLE customers\nUSING CSV\nLOCATION cos:\/\/us-geo\/sql\/customers_partitioned.csv\n\nIf your data on Object Storage does not adhere to this naming convention, you can convert it to a Hive-partitioned layout by using Data Engine in a data preparation step. Use SELECT * to copy the data to a new location and specify [PARTITION BY](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencepartitionedClause) in the INTO clause:\n\nSELECT * FROM cos:\/\/us-geo\/sql\/customers.csv\nINTO cos:\/\/us-geo\/mybucket\/customers_partitioned.csv\nPARTITIONED BY (country)\n\n\n\n\n\n Step 2: Attach table partitions \n\nAfter you defined a partitioned table, it is initially empty and you must attach the partitions to it explicitly. A convenient way to add all partitions that exist on Object Storage, is to use the following RECOVER PARTITIONS clause.\n\nALTER TABLE customers RECOVER PARTITIONS","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog"},{"document_id":"ibmcld_00576-8941-10714","score":15.809219443,"text":"\nThe maximum document size is 1 MB, but documents must be much smaller than that size, typically a few KB.\n\nFor more information, see the following blog posts:\n\n\n\n* [Optimal IBM Cloudant Indexing](https:\/\/blog.cloudant.com\/2019\/05\/10\/Optimal-Cloudant-Indexing.html)\n* [Time-series Data Storage](https:\/\/blog.cloudant.com\/2019\/04\/08\/Time-series-data-storage.html)\n* [Partitioned databases - data design](https:\/\/blog.cloudant.com\/2019\/03\/05\/Partition-Databases-Data-Design.html)\n\n\n\n\n\n\n\n Making the most of the primary index \n\nIBM Cloudant has a primary index on the document's _id attribute. This index allows documents to be retrieved by _id (GET \/db\/id) or a range of _ids (GET \/db\/_all_docs?startkey=\"a\"&endkey=\"z\"). By storing data in the primary key and ensuring that each _id is unique, the primary index can be used to fetch documents and ranges of documents without secondary indexing. See the following list of ideas:\n\n\n\n* If you have something unique in your object that would be useful to query against, use it as your _id field, for example, bob.smith@gmail.com, isbn9780241265543, or oakland,ca.\n* If your objects contain a hierarchy, model that in your _id: usa:ca:oakland or books:fiction:9780241265543. The hierarchy goes from largest to smallest, so you can use the primary index to find all the cities in usa or all the cities in usa:ca, without secondary indexing.\n* If you're storing time-series data, encoding time at the start of your _id sorts the primary index by time, for example, 001j40Ox1b2c1B2ubbtm4CsuLB4L35wQ.\n* Partitioned databases group documents that share a partition key together. A partition key must have many values and must not include hot spots to avoid directing a large proportion of your application's traffic to a few partitions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basics"},{"document_id":"ibmcld_00381-3303-3948","score":15.0538268929,"text":"\nSierra Leone,\nSan Marino,\nSenegal,\nSomalia,\nSuriname,\nSao Tome and Principe,\nEl Salvador,\nSint Maarten,\nSyrian Arab Republic,\nSwaziland,\nTurks and Caicos Islands,\nChad,\nFrench Southern Territories,\nTogo,\nThailand,\nTajikistan,\nTokelau,\nTurkmenistan,\nTunisia,\nTonga,\nEast Timor,\nTurkey,\nTrinidad and Tobago,\nTuvalu,\nTaiwan,\nTanzania, United Republic of,\nUkraine,\nUganda,\nUSA Minor Outlying Islands,\nUnited States,\nUruguay,\nUzbekistan,\nVatican City State,\nSt Vincent and the Grenadines,\nVenezuela,\nVirgin Islands, British,\nVirgin Islands, U.S.,\nViet Nam,\nVanuatu,\nWallis and Futuna,\nSamoa,\nYemen,\nMayotte,\nSouth Africa,\nZambia,\nZimbabwe\n]\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-geoblocking-class"},{"document_id":"ibmcld_13118-27377-28138","score":14.3672984016,"text":"\nnull 7634piweba3y.prodigy.comGET \/shuttle\/miss... 20001\/Jul\/1995:04:1...\n null25218 ntigate.nt.comGET \/software\/win... 20001\/Jul\/1995:04:1...\n null 4441 ntigate.nt.comGET \/software\/win... 20001\/Jul\/1995:04:1...\n null 1414 ntigate.nt.comGET \/images\/const... 20001\/Jul\/1995:04:1...\n null45308line03.pm1.abb.mi...GET \/shuttle\/miss... 20001\/Jul\/1995:04:1...\n null 669 source.iconz.co.nzGET \/images\/WORLD... 20001\/Jul\/1995:04:1...\n null 234 source.iconz.co.nzGET \/images\/USA-l... 20001\/Jul\/1995:04:1...\n null 363 source.iconz.co.nzGET \/images\/MOSAI... 20001\/Jul\/1995:04:1...\n null13372 ntigate.nt.comGET \/software\/win... 20001\/Jul\/1995:04:1...\n+---------------------------+-----+--------------------+--------------------+------------+--------------------+\n\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-big-data-log-analytics"},{"document_id":"ibmcld_11602-17406-18830","score":14.0993648838,"text":"\n[IBM Cloud compliance programs](https:\/\/www.ibm.com\/cloud\/compliance) provide compliance and trust certifications, which reaffirm IBM's commitment to protection of customer data and applications. These compliance programs are for regulations, standards, and frameworks across Global, Government, Industry, and Regional.\n\nMore supplementary information to the IBM Cloud compliance programs is available on [IBM Cloud service offering descriptions and terms](https:\/\/www-03.ibm.com\/software\/sla\/sladb.nsf\/sla\/bm?OpenDocument) which contain links to individual Data Processing and Protection data sheets for IBM Cloud offerings.\n\nEach IBM Cloud\u00ae for SAP offering uses different infrastructure configurations and approaches to providing the service and will therefore be certified independent of each other. These certifications can be checked on the previous links or clarified by contacting IBM Cloud or your IBM representative. Following is a small extract from the full list of recognized compliance, certifications, attestations, or reports available across the various IBM Cloud\u00ae for SAP offerings:\n\n\n\n* ISO 27001\n* ISO 27017\n* ISO 27018\n* EU-US Privacy Shield Policy\n* GDPR Ready\n* Germany Federal Office for Information Security (BSI) C5\n* HIPAA for Healthcare USA\n* ITAR Compliant\n* PCI-DSS for Payment Card Industry USA\n* Singapore Multi-Tier Cloud Security Standard (MTCS)\n* SOC1 Type 2\n* SOC2 Type 2\n* SOC3\n* ...more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-iaas-offerings"},{"document_id":"ibmcld_00530-9526-10355","score":13.1261378979,"text":"\n\"Person_name\": \"Robert De Niro\",\n\"Movie_year\": map[string][]interface{}{\n\"$in\": []interface{}{1978, 2009},\n},\n},\n)\n\nfindResult, _, err := service.PostFind(postFindOptions)\nif err != nil {\npanic(err)\n}\n\nb, _ := json.MarshalIndent(findResult, \"\", \" \")\nfmt.Println(string(b))\n\nThe previous Go example requires the following import block:\n\nimport (\n\"encoding\/json\"\n\"fmt\"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n)\n\nSee the following example result from the search:\n\n{\n\"docs\": [\n{\n\"_id\": \"d9e6a7ae2363d6cfe81af75a392eb9f2\",\n\"_rev\": \"1-9faa75d7ea524448b1456a6c69a4391a\",\n\"Movie_runtime\": 183,\n\"Movie_rating\": \"R\",\n\"Person_name\": \"Robert De Niro\",\n\"Movie_genre\": \"DW\",\n\"Movie_name\": \"Deer Hunter, The\",\n\"Person_pob\": \"New York, New York, USA\",\n\"Movie_year\": 1978,\n\"Person_dob\": \"1943-08-17\"\n}\n],\n\"bookmark\": \"g2w ... c2o\"\n}\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-example-movies-demo-database"},{"document_id":"ibmcld_00530-4127-5130","score":12.7458545222,"text":"\nservice = CloudantV1.new_instance()\n\nresponse = service.post_find(\ndb='my-movies',\nselector={'Person_name': 'Zoe Saldana'}\n).get_result()\n\nprint(response)\n\npostFindOptions := service.NewPostFindOptions(\n\"my-movies\",\nmap[string]interface{}{\n\"Person_name\": \"Zoe Saldana\",\n},\n)\n\nfindResult, _, err := service.PostFind(postFindOptions)\nif err != nil {\npanic(err)\n}\n\nb, _ := json.MarshalIndent(findResult, \"\", \" \")\nfmt.Println(string(b))\n\nThe previous Go example requires the following import block:\n\nimport (\n\"encoding\/json\"\n\"fmt\"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n)\n\nSee the following example result from the search:\n\n{\n\"docs\": [\n{\n\"_id\": \"d9e6a7ae2363d6cfe81af75a3941110b\",\n\"_rev\": \"1-556aec0e89fa13769fbf59d651411528\",\n\"Movie_runtime\": 162,\n\"Movie_rating\": \"PG-13\",\n\"Person_name\": \"Zoe Saldana\",\n\"Movie_genre\": \"AVYS\",\n\"Movie_name\": \"Avatar\",\n\"Movie_earnings_rank\": \"1\",\n\"Person_pob\": \"New Jersey, USA\",\n\"Movie_year\": 2009,\n\"Person_dob\": \"1978-06-19\"\n}\n],\n\"bookmark\": \"g2wA ... Omo\"\n}\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-example-movies-demo-database"},{"document_id":"ibmcld_10067-2911-4724","score":12.6231176122,"text":"\nibmcloud cbr zone-create --addresses 129.XX.XX.XX --description \"Allow only client IP\" --name allow-client-ip\n2. Verify the network zone was created.\n\nibmcloud cbr zones\n\n\n\n\n\n\n\n Step 2: Creating your CBR rule \n\n\n\n1. After you create your network zone (allowlist), create a CBR rule and add the network zone you created in the previous step. The following example creates a rule that uses the cluster API type. Replace NETWORK-ZONE-ID with the ID of the allow-client-ip network zone that you created in step 1.\n\nibmcloud cbr rule-create --api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster --description \"privateAccess=allowAll, publicAccess=oneIP\" --service-name containers-kubernetes --service-instance CLUSTER-ID --context-attributes endpointType=private --context-attributes endpointType=public,networkZoneId=NETWORK-ZONE-ID\n\nUnderstanding the command options.\n\n--api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster\n: Set the crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster API to allow only resources in the network zone you created earlier to access only the cluster APIs, which include the APIs for various oc commands.\n\n--service-instance CLUSTER-ID\n: Scope the rule to a single cluster so that only resources in the network zone you created earlier can access only the CLUSTER-ID.\n\n--context-attributes endpointType=private\n: Set the context attribute endpointType=private without associating a network zone allows all private traffic to the cluster.\n\n--context-attributes endpointType=public,networkZoneId=all-client-ip\n: Set the context attribute endpointType=public and associate the networkZoneId=allow-client-ip that you created earlier to allow only the resources in the allow-client-ip zone to access the cluster over the public network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cbr-tutorial"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07030-1613-3572","score":23.2566430975,"text":"\n* [Extracting Text Patterns with User Highlights with Pattern Induction](https:\/\/towardsdatascience.com\/pattern-induction-what-is-a-pattern-part-1-79ee1bd5adc6)\n* [Pattern Induction: Best Practices for Extracting Text Patterns](https:\/\/maeda-han.medium.com\/pattern-induction-best-practices-for-extracting-text-patterns-part-3-2c0ee6481a3c)\n\n\n\nTo define a pattern, complete the following steps:\n\n\n\n1. From the Teach domain concepts section of the Improvement tools panel, choose Patterns.\n2. Click New.\n3. Pick how you want to choose documents.\n\n\n\n* Allow Discovery to choose 10 random documents for you.\n* Choose the documents yourself (up to 20 can be selected).\n\nEach document must be under 5,000 characters in length. Documents that exceed the limit are truncated to 5,000 characters.\n\n\n\n4. Click Next.\n5. Start selecting example words or phrases that fit the pattern you want to define.\n\nFor example, if you have a collection of articles that discuss ISO standards, you might start highlighting the numbers of the standards in each document.\n\nIf you annotate something, and then change your mind, hover over the selection, and then click x to delete it.\n6. Continue selecting examples.\n\nAfter you identify enough examples, Discovery shows a list of suggested examples for you to review and determine to be valid or not valid examples. Suggested examples are taken from the field that is configured to be used in search results. If the source of result content is configured to be passages, the text field is used. For more information, see [Changing the result content](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-resultsquery-results-content).\n7. Choose Yes or No for each suggestion.\n\nClick the Preview document icon if you want to see the example in context before you make a choice.\n8. Continue highlighting examples and validating suggestions until a message is displayed to inform you that you identified enough examples.\n9.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-domain-pattern"},{"document_id":"ibmcld_03114-7576-9214","score":22.2507582619,"text":"\n\"response_type\": \"option\",\n\"title\": \"Available options\",\n\"description\": \"Please select one of the following options:\",\n\"preference\": \"button\",\n\"options\":\n{\n\"label\": \"Option 1\",\n\"value\": {\n\"input\": {\n\"text\": \"option 1\"\n}\n}\n},\n{\n\"label\": \"Option 2\",\n\"value\": {\n\"input\": {\n\"text\": \"option 2\"\n}\n}\n}\n]\n}\n]\n},\n\"user_id\": \"faf4a112-f09f-4a95-a0be-43c496e6ac9a\"\n}\nShow more\n\nYour app can display the specified options using any suitable user-interface control (for example, a set of buttons or a drop-down list). The optional preference property indicates the preferred type of control your app should use (button or dropdown), if supported. For the best user experience, a good practice is to present three or fewer options as buttons, and more than three options as a drop-down list.\n\nFor each option, the label property specifies the label text that should appear for the option in the UI control. The value property specifies the input that should be sent back to the assistant (using the \/message API) when the user selects the corresponding option.\n\nFor an example of implementing option responses in a simple client application, see [Example: Implementing option responses](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-responsesapi-dialog-option-example).\n\n\n\n\n\n Suggestion \n\nThis feature is available only to users with a paid plan.\n\nThe suggestion response type is used by the disambiguation feature to suggest possible matches when it isn't clear what the user wants to do. A suggestion response includes an array of suggestions, each one corresponding to a possible matching dialog node:\n\n{\n\"output\": {\n\"generic\": [\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-responses"},{"document_id":"ibmcld_07030-7-2012","score":21.7496470807,"text":"\nUse patterns to find terms \n\nRecognize terms that are mentioned in sentences that match a syntactic pattern that you teach Discovery to recognize.\n\nIBM Cloud\n\nPatterns is a beta feature that is available in managed deployments only. The feature is available for English-language documents only.\n\nAdd a Patterns resource to teach Discovery to recognize patterns in your data. The Patterns feature uses pattern induction, which generates extraction patterns from examples that you provide as training data. After you specify a few examples, Discovery suggests more rules that you can review and accept to complete the pattern.\n\nPatterns produces a model by using a human-in-the-loop process. You aren't asked to build a large set of training data up front. Instead, you provide a few examples, and then participate in an interactive process to define the training data. You passively accept or reject smart suggestions that are proposed by the system.\n\nPattern recognition works best on text with consistent structure in casing, length, text, or numeric values. Examples of patterns you can teach Discovery to identify in your documents:\n\n\n\n* Standards numbers, such as ISO 45001, ISO 22000.\n* Currency references, such as $50.5 million, $29 million.\n* Date references, such as 8 September 2019, 12 June 2020.\n\n\n\nIf you need to identify specific terms or text, such as product names, add a [dictionary](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-domain-patterndictionary).\n\nPatterns cannot be used in a Content Mining application.\n\nFor more information, read the following blog posts:\n\n\n\n* [Extracting Text Patterns with User Highlights with Pattern Induction](https:\/\/towardsdatascience.com\/pattern-induction-what-is-a-pattern-part-1-79ee1bd5adc6)\n* [Pattern Induction: Best Practices for Extracting Text Patterns](https:\/\/maeda-han.medium.com\/pattern-induction-best-practices-for-extracting-text-patterns-part-3-2c0ee6481a3c)\n\n\n\nTo define a pattern, complete the following steps:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-domain-pattern"},{"document_id":"ibmcld_05125-6585-7916","score":21.0374787104,"text":"\nI find that the optimal value for this option is around 50 MB. COS best practices suggest using requests that are multiples of 4 MB, and thus the recommendation is to set this option to 52 (MB).\n6. parallel_count=30 sets the maximum number of requests sent concurrently to COS, per single file read\/write operation. By default, this is set to 5. For very large objects, you can get more throughput by increasing this value. As with the previous option, keep this value low if you only read a small amount of data of each file.\n7. multireq_max=30 When listing a directory, an object metadata request (HEAD) is sent per each object in the listing (unless the metadata is found in cache). This option limits the number of concurrent such requests sent to COS, for a single directory listing operation. By default it is set to 20. Note that this value must be greater or equal to the parallel_count option above.\n8. dbglevel=warn sets the debug level to warn instead of the default (crit) for logging messages to \/var\/log\/syslog.\n\n\n\n\n\n\n\n Limitations \n\nIt is important to remember that s3fs may not be suitable for all applications, as object storage services have high-latency for time to first byte and lack random write access. Workloads that only read big files, like deep learning workloads, can achieve good throughput using s3fs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-s3fs"},{"document_id":"ibmcld_12453-9092-11379","score":20.6165560796,"text":"\nWhen you update a root CA certificate, the change impacts your entire public-key infrastructure. To minimize impact, it is recommended that you set a long validity period for your root CA certificate. In Secrets Manager, the default TTL for root certificates is 10 years.\n\n\n\n\n\n\n\n Choosing an algorithm for generating keys \n\nBefore you create a certificate authority in Secrets Manager, you must choose a key algorithm for generating the public and private keys for your CA. The public and private key-pair is used to authenticate an SSL\/TLS connection. If you're not sure where to start, you can use the following suggested guide for selecting a key algorithm.\n\n\n\n1. Choose an algorithm family.\n\nThe key algorithm that you select determines the encryption algorithm and key size to use to generate keys and sign certificates. As a best practice, use the same algorithm family for all certificates that belong to a certificate chain. Secrets Manager supports the following families of algorithms.\n\n\n\nTable 2. Supported algorithm families and key sizes\n\n Algorithm family Description Supported key sizes \n\n RSA Widely used and compatible with most browsers and servers, RSA is the industry standard for public-key cryptography. 2048 bits <br>4096 bits \n Elliptic curve (EC) Generates stronger keys and smaller certificates. For example, a 256-bit EC key is equivalent in encryption strength to a 3072-bit RSA key. 224 bits <br>256 bits <br>384 bits <br>521 bits \n\n\n\n2. Choose a key size.\n\nThe key size or length that you select determines the encryption strength. The larger the key size for an algorithm family, the more difficult it is to break. Keep in mind that longer key lengths results in more data to store and transmit, which can impact the performance of your certificate. As a best practice, choose a key size that is appropriate for the TTL or validity period of your certificate.\n\nFor longer living certificates, it is recommended to use longer key lengths to provide more encryption protection.\n\n\n\n\n\n\n\n\n\n Using certificate authority unauthenticated endpoints \n\nIf you're using leaf certificates that are issued by a CA in Secrets Manager for your applications, use the following API calls to gain access to the issuing CA Certificate Revocation List (CRL) and CA certificate.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-prepare-create-certificates"},{"document_id":"ibmcld_12389-7-2298","score":20.3097462839,"text":"\nBest practices for rotating and locking secrets \n\nWith IBM Cloud\u00ae Secrets Manager, you can design a strategy for rotating your secrets and sensitive data. Review the following suggested guidelines for implementing best practices around your secrets management.\n\n\n\n Define your rotation strategy \n\nAs you use Secrets Manager to design your secrets management strategy, consider how often you want to rotate your secrets based on the internal guidelines for your organization. Determine ahead of time which users or service IDs require access to rotate secrets, and how those secrets can be rotated manually to avoid interruptions to your applications.\n\n\n\n1. Determine a frequency of rotation for your secrets.\n\nAfter you store a secret in Secrets Manager, you decide the frequency of its rotation. You might want to rotate secrets due to personnel turnover, process malfunction, or according to your organization's internal guidelines. Rotate your secrets regularly, for example every 90 days, to meet best practices around secrets management.\n2. Test out rotation workflows for each type of secret that you manage in Secrets Manager.\n\nThe way in which Secrets Manager evaluates a request to rotate a secret differs depending on the type of secret. For example, some secrets are replaced immediately with the data that you provide on rotation, whereas other secrets, such as public certificates, move into an extra validation step. For more information about how Secrets Manager handles rotation requests, see [Manually rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotationmanual-rotate-by-type).\n3. Establish a process for deploying the newest secret versions to your applications.\n\nUse an automated flow to obtain and deploy the latest version of your secret after it is rotated. For more information, see [Avoid application outages by locking your secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-rotate-secretsbest-practices-lock-secrets).\n\n\n\n\n\n\n\n Set up alerts for expiring secrets \n\nConnect to the Event Notifications service so that Secrets Manager can notify you in advance when your secrets or certificates are about to expire.\n\n\n\n1. Set up alerts for your instance by enabling event notifications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-rotate-secrets"},{"document_id":"ibmcld_12016-7-2052","score":19.8218514966,"text":"\nBest practices for securing the Schematics objects \n\nIBM Cloud\u00ae Schematics uses open source projects, including Terraform, Ansible, Red Hat OpenShift on IBM Cloud, Operators, and Helm, delivered to you as a managed service. Rather than installing each open source project on your local system, and learning the API or CLI. You can declare the tasks that you want to run in IBM Cloud\u00ae and watch Schematics run these tasks for you.\n\nTake time to review the suggested practices to reduce the security risks for all production, staging, and test servers in your cloud infrastructure. This list is an excellent starting point to increase the security of your cloud infrastructure.\n\n\n\n Best practices for creating Terraform Templates or modules in Git repositories \n\n\n\n What are the best practices that you must follow in developing the Terraform templates, and publishing the same in the Git repositories? \n\nFollow these practices in developing and publishing the Terraform template in the Git repositories.\n\n\n\n* Create Terraform template by using Terraform version1.0 or higher and current [IBM Cloud provider](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest).\n* Create environment variables for all your credentials.\n* Check whether pre-commit hooks are run to inspect your code meets Terraform standards, see [sample repository that contains pre-commit hook](https:\/\/github.com\/terraform-ibm-modules\/terraform-ibm-iam\/blob\/main\/.pre-commit-config.yaml).\n* Check whether your repository uses Terratest framework to validate your Terraform resources and data source to provision, see [sample validated Terraform repository](https:\/\/github.com\/terraform-ibm-modules\/terraform-ibm-iam\/blob\/main\/.github\/workflows\/validate_terraform.yml) to run Terratest.\n* Check whether your repository contains gitignore for any files that are not tracked by Git remain untracked.\n* Add the license file for your template.\n* Do not set your sensitive variable as default in the configuration files.\n* Check your secured variables or output as sensitive.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-secure-objects"},{"document_id":"ibmcld_15050-7-2246","score":19.4755753058,"text":"\nBest practices for backups \n\nTo ensure that you're using the VPC Backup Service most effectively and economically, consider following these best practices.\n\n\n\n General best practices \n\n\n\n* Assess the type of data that you have before you create backup policies. Critical data that changes more often might require more frequent backups than static data. Ask which data is most critical and which is to be archived.\n* Keep costs down by retaining backups for only while you need them to prevent data loss. Plan timely backups to restore data that might be deleted or corrupted. Think about the type of events that might happen. Ask how much data you can afford to lose. The answers can help you decide on a backup interval.\n* Ask how quickly you need to recover the data. Frequent backups that cover smaller incremental changes to your data afford quicker restoration. Run a test failover and volume restore to get an idea of the time it can take.\n* For best performance, stagger your backup jobs by creating backup plans with different intervals. You can have up to four different backup plans per backup policy.\n* For large volumes, consider a shorter retention period so that you don't exceed the 10 TB limit for all volume backups.\n* If you have volumes in different regions, create separate backup policies for each region. You're limited to 10 backup policies per account in a region.\n* Ensure that the volumes that you tagged for backups are attached to a virtual server instance. You can't back up detached volumes.\n* Provide a unique name for your backup policy. If you have a convention for naming volumes, you might name a backup policy by using a similar convention. Backups that are created by a policy can also follow the convention. As the number of backups grow, a good naming convention can make them more identifiable.\n\n\n\n\n\n\n\n Best practices for user actions \n\n\n\n* Organize tags that you apply to volumes and specify in backup policies. Ensure that multiple policies aren't using the same tags for target resources because that might trigger duplicate volume backups. You need only one tag to match to trigger a backup.\n* Determine what tags are already assigned to a volume from the list of Block Storage for VPC volumes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backups-vpc-best-practices"},{"document_id":"ibmcld_12437-0-1660","score":19.2539913991,"text":"\n\n\n\n\n\n\n  Why did my locked certificate move to the Destroyed state? \n\nYou have an SSL\/TLS certificate that you manage in IBM Cloud\u00ae Secrets Manager, but it still expires even though it is locked.\n\n  What\u2019s happening \n\nYou want to prevent an SSL\/TLS certificate in your Secrets Manager service instance from expiring, so you attach one or more locks to it. But, when your certificate reaches its expiration date, it still moves to the Destroyed state.\n\n  Why it\u2019s happening \n\nA lock on an SSL\/TLS certificate can prevent you or an authorized user from deleting the certificate from your instance, for example during a security audit. But, a lock can't prevent a certificate from reaching its defined expiration date.\n\nThe validity period of an X.509 certificate can't be changed or modified, even if the certificate is associated with one or more locks in Secrets Manager. When your certificate passes its defined expiration date, it is no longer valid. In Secrets Manager, a secret that is no longer valid moves to the Destroyed state.\n\n  How to fix it \n\nTo avoid downtime in your applications that results from an expired certificate, be sure to [set up Event Notifications](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-event-notifications) to alert you when certificates are about to expire. Then, rotate your certificates and deploy the new versions to your SSL\/TLS termination points. For suggested guidelines around periodic rotation of certificates, see [Best practices for rotating and locking secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-rotate-secretsbest-practices-lock-secrets).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-locked-certificates"},{"document_id":"ibmcld_15848-0-2092","score":19.222068644,"text":"\n\n\n\n\n\n\n  Security best practices for z\/OS virtual server instances \n\nTo secure your z\/OS virtual server instance and identify any security vulnerabilities, you must refer to the following security information and industry standard security reports.\n\nProducts and services in the z\/OS stock images are periodically reviewed and updated. IBM continues to follow the standard security guidance and provides differentiating technologies in security and data privacy, focusing on but not limited to the following areas:\n\n\n\n*  Security patch management\n*  Firmware currency\n*  Setup of suggested products and services\n*  Configuration of hardware and software (operating systems, middleware, third-party applications, open source, network cards, and so on)\n*  Integration and monitoring of software, hardware, and end-points\n*  Cybersecurity:\n\n\n\n*  Least access privilege\n*  Separation of duties\n*  Defense-in-depth\n*  Authentication strength\n*  End-to-end encryption\n\n\n\n\n\nFor this release, you need to follow the security best practices for your z\/OS virtual server instance:\n\n\n\n*  If you want to apply the latest service for your instance, it is suggested that you wait until the next month\u2019s refresh stock image to provision a new z\/OS virtual server instance.\n*  Ensure that you follow the password policy, see [Configuring the password](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vsi_is_connecting_zosconfigure-password).\n*  For more information about various security topics, see the following references:\n\n\n\n*  [What is zero trust?](https:\/\/www.ibm.com\/topics\/zero-trust)\n*  [NIST Special Publication Security & Privacy Controls for Information Systems & Organizations](https:\/\/doi.org\/10.6028\/NIST.SP.800-53r5)\n*  [IBM X-Force Threat Intelligence Report](https:\/\/www.ibm.com\/security\/data-breach\/threat-intelligence\/)\n*  [IBM on Enterprise Security](https:\/\/www.ibm.com\/it-infrastructure\/z\/capabilities\/enterprise-security)\n*  [PCI DSS v4.0](https:\/\/www.pcisecuritystandards.org\/documents\/PCI-DSS-v4_0.pdf)\n*  [CIS Benchmarks for IBM Z](https:\/\/workbench.cisecurity.org\/files\/3877)\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-security-best-practices-zos"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13121-13350-15059","score":19.8479160293,"text":"\nTo learn about activities and to handle them correctly with CBR rules, a test phase in reporting mode of at least a month is recommended. This allows for an iterative approach towards the desired set of network zones and context rules.\n\nFor this tutorial, we are going to define the following network zones:\n\n\n\n* a zone for each of the deployed services which are supported as service reference for originating traffic\n* a zone for each for the Kubernetes cluster\n* for an IP range with the addresses of a home network (corporate or bastion) to serve as homezone\n* a zone for each of the CBR-enabled platform services\n\n\n\nThereafter, we are going to define context rules as follows:\n\n\n\n* for the access to the [Key Protect instance](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-access-control-with-cbr)\n* for the access to the [Object Storage instance and its bucket](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-setting-a-firewall)\n* for the access to the [Container Registry and the namespace with the container image](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamiam_cbr)\n* for the access to the [Kubernetes Service cluster and its management API](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cbrprotect-api-types-cbr)\n\n\n\nAll the above zones and rules can be deployed in either report-only or enforced mode with a single Terraform command. Note that the rules are not meant for production use, but as a sample to investigate usage and traffic in report-only mode.\n\nThe documentation has a [list of resources which are supported as service references](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-whatisservice-attribute).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-cbr-enhanced-security"},{"document_id":"ibmcld_03403-23070-24576","score":19.3620697135,"text":"\n(https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-ass-test-cancel-order-number-provided.png)\n\nNow, try it when you don't know the order number.\n4. Click Clear in the \"Try it out\" pane to start over. Enter, I want to cancel my order.\n\nYour assistant recognizes the cancel_order intent, and responds with, If the pickup time is more than 48 hours from now, you can cancel your order. What is the order number?\n5. Enter, I don't know.\n\nYour assistant responds with, I need the order number to cancel the order for you. If you don't know the order number, please call us at 958-234-3456 to cancel over the phone.\n\n![Shows the Try it out pane test of the cancel order number node when the user doesn't know the order number.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-ass-test-cancel-order-number-unknown.png)\n\n\n\n\n\n\n\n Add nodes to clarify order number format \n\nIf you do more testing, you might find that the dialog isn't very helpful in scenarios where the user does not remember the order number format. The user might include only the numbers or the letters too, but forget that they are meant to be uppercase. So, it would be a nice touch to give them a hint in such cases, correct? If you want to be kind, add another node to the dialog tree that checks for numbers in the user input.\n\n\n\n1. Find the @order_number node that is a child of the Ask order number node.\n2. Click the More!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial"},{"document_id":"ibmcld_03069-23117-24622","score":19.3126655775,"text":"\n(https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-ass-test-cancel-order-number-provided.png)\n\nNow, try it when you don't know the order number.\n4. Click Clear in the Try it out pane to start over. Enter, I want to cancel my order.\n\nYour assistant recognizes the cancel_order intent, and responds with, If the pickup time is more than 48 hours from now, you can cancel your order. What is the order number?\n5. Enter, I don't know.\n\nYour assistant responds with, I need the order number to cancel the order for you. If you don't know the order number, please call us at 958-234-3456 to cancel over the phone.\n\n![Shows the Try it out pane test of the cancel order number node when the user doesn't know the order number.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-ass-test-cancel-order-number-unknown.png)\n\n\n\n\n\n\n\n Add nodes to clarify order number format \n\nIf you do more testing, you might find that the dialog isn't very helpful in scenarios where the user does not remember the order number format. The user might include only the numbers or the letters too, but forget that they are meant to be uppercase. So, it would be a nice touch to give them a hint in such cases. If you want to be kind, add another node to the dialog tree that checks for numbers in the user input.\n\n\n\n1. Find the @order_number node that is a child of the Ask order number node.\n2. Click the More!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial"},{"document_id":"ibmcld_13121-14635-16508","score":19.0620502345,"text":"\nAll the above zones and rules can be deployed in either report-only or enforced mode with a single Terraform command. Note that the rules are not meant for production use, but as a sample to investigate usage and traffic in report-only mode.\n\nThe documentation has a [list of resources which are supported as service references](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-whatisservice-attribute). You can also retrieve the list using the [CLI command service-ref-targets](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cbr-plugincbr-cli-service-ref-targets-command) or the related API function [List available service reference targets](https:\/\/cloud.ibm.com\/apidocs\/context-based-restrictionslist-available-serviceref-targets).\n\n\n\n\n\n Step 6: Use Terraform to configure context-based restrictions \n\nInstead of manually creating the network zones and context rules for a project, it is recommended to automate the deployment. Context-based restrictions can be deployed utilizing Infrastructure as Code (IaC) - namely [Terraform code](https:\/\/cloud.ibm.com\/docs\/ibm-cloud-provider-for-terraform). You can first deploy the zones and rules with rules in report-only mode for testing. Then, after thorough tests, switch to enforced mode by updating the deployed configuration.\n\n\n\n Terraform resources for zones and rules \n\nIn the following, you will deploy the Terraform code to create a basic set of network zones and context rules. The code for zones is using the [ibm_cbr_zone](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/resources\/cbr_zone) resource. The following shows a zone specification which identifies the Kubernetes cluster. Such a cluster is one of the [supported service references](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-whatisservice-attribute).\n\nresource \"ibm_cbr_zone\" \"cbr_zone_k8s\" {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-cbr-enhanced-security"},{"document_id":"ibmcld_16242-7-2224","score":18.5518016763,"text":"\nResponse modes \n\nIBM Cloud\n\nYou can choose a response mode for each action to set how it behaves. The modes are clarifying and confident.\n\nClarifying mode: Start here. In the clarifying mode, your assistant is eager to ask questions so you can ensure that your customer gets to the action they need. An assistant is more likely to ask questions to be sure an action matches what a customer is asking. A new or untested action gets the training that it needs.\n\nConfident mode: Take the next step. After you use analytics to improve your assistant, use the confident mode. Your assistant solves customer issues with authority and accuracy. An assistant is less likely to ask questions and is more likely to trigger actions that match. Use confident mode after you test and train actions.\n\nResponse modes are a beta feature that is available for evaluation and testing purposes on IBM Cloud only.\n\n\n\n Settings \n\nSettings for the two modes are in the global settings. For more information, see [Global settings for actions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-global-settings).\n\nYou can choose what mode to use when you create a new action. Clarifying mode is the default and is designed for use with new, untested actions that need training.\n\nThe settings are:\n\nClarify when one action matches: If an assistant prioritizes one action that it thinks matches the customer's request, it can clarify the match by asking the customer to confirm. This clarification helps you ensure that the action is the right one and allows the customer to give input before proceeding. For example, if the assistant thinks that a single action named Pay Bill is the right one, it can clarify the choice by asking the customer Did you mean: Pay Bill.\n\nClarify when more than one action matches: When your assistant finds that more than one action might fulfill a customer's request, it can automatically ask for clarification. Instead of guessing which action to use, your assistant shows a list of the possible actions to the customer and asks the customer to pick the right one.\n\nOffer support option when asking a clarifying question: The assistant can include a choice to connect to other support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-action-response-modes"},{"document_id":"ibmcld_16242-1610-3614","score":18.006937842,"text":"\nFor example, if the assistant thinks that a single action named Pay Bill is the right one, it can clarify the choice by asking the customer Did you mean: Pay Bill.\n\nClarify when more than one action matches: When your assistant finds that more than one action might fulfill a customer's request, it can automatically ask for clarification. Instead of guessing which action to use, your assistant shows a list of the possible actions to the customer and asks the customer to pick the right one.\n\nOffer support option when asking a clarifying question: The assistant can include a choice to connect to other support. If the customer picks this choice, the assistant uses your Fallback action.\n\nStep validation attempts before offering support: If a customer provides invalid answers for a step in an action, the assistant can offer to connect to other support in the Fallback action. The step validation count measures how many invalid answers can occur before the assistant provides this choice.\n\nThis table shows the default settings for each mode.\n\n\n\nDefault settings\n\n Clarifying Confident \n\n Clarify when one action matches More often Sometimes \n Clarify when more than one action matches More often Sometimes \n Offer support option when asking a clarifying question More often Sometimes \n Step validation attempts before offering support 1 time 3 times \n\n\n\n\n\n\n\n Choosing a mode for individual actions \n\nWhen you edit an action, you can see the mode that it uses and change it if you need to.\n\n\n\n1. Click the Action response mode icon ![Action response mode icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/response-mode-icon.svg). The mode in use is checked.\n\nZoom\n\n![Action response mode](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/response-mode-modal.png)\n\nAction response mode\n2. Click the other mode if you want to change it, and then click Save response mode.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-action-response-modes"},{"document_id":"ibmcld_02934-24362-26111","score":17.9036612639,"text":"\nShould I go ahead? Your pizza is on its way! see *Complex response* \n\n\n\nComplex response Because users might include affirmative or negative statements at other times during the dialog (Oh yes, we want the pizza delivered at 5pm) or (no guests tonight, let's make it a small), use the slot_in_focus property to make it clear in the slot condition that you are looking for a Yes or No response to the prompt for this slot only.\n\n(yes || no) && slot_in_focus\n\nThe slot_in_focus property always evaluates to a Boolean (true or false) value. Only include it in a condition for which you want a boolean result. Do not use it in slot conditions that checks for an entity type and then save the entity value, for example.\n\nIn the Not found prompt, clarify that you are expecting the user to provide a Yes or No answer.\n\n{\n\"output\":{\n\"text\": {\n\"values\": [\n\"Respond with Yes to indicate that you want the order to\nbe placed as-is, or No to indicate that you do not.\"\n]\n}\n}\n}\n\nIn the Found prompt, add a condition that checks for a No response (#no). When found, ask for the information all over again and reset the context variables that you saved earlier.\n\n{\n\"conditions\": \"no\",\n\"output\":{\n\"text\": {\n\"values\": [\n\"Let's try this again. Tell me what size pizza\nyou want and the time...\"\n]\n}\n},\n\"context\":{\n\"size\": null,\n\"time\": null,\n\"confirmation\": null\n}\n}\nShow more\n\n\n\n\n\n Replacing a slot context variable value \n\nIf, at any time before the user exits a node with slots, the user provides a new value for a slot, then the new value is saved in the slot context variable, replacing the previously-specified value. Your dialog can acknowledge explicitly that this replacement has occurred by using special properties that are defined for the Found condition:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots"},{"document_id":"ibmcld_16243-1218-3072","score":17.6056044817,"text":"\n* [Upload\/Download](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-global-settingsactions-global-settings-upload-download)\n\n\n\n\n\n Clarifying questions \n\nOn the Clarifying questions tab, you can customize how an action asks clarifying questions.\n\nIn the Ask clarifying questions section, you can:\n\n\n\n* Enable or disable if your assistant disambiguates (asks a clarifying question).\n* Modify the text that your assistant uses to introduce the clarification list or when no action matches.\n* Enable or disable response modes, and modify the text that your assistant uses with a response mode. If you enable response modes, you can use the Customize modes section to choose a response mode for each action to set how it behaves.\n\n\n\nFor more information, see [Customizing clarifying questions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questionsunderstand-questions-disambiguation-config) and [Response modes](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-action-response-modes).\n\n\n\n\n\n Change conversation topic \n\nThe Change conversation topic feature enables your assistant to handle digressions, dynamically responding to the user by changing the conversation topic as needed. For more information, see [Allowing your customers to change the topic of the conversation](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-change-topic).\n\nIf necessary, you can disable changing the topic for all actions:\n\n\n\n1. On the Change conversation topic tab, set the switch to Off.\n2. Click Save, and then click Close.\n\n\n\n\n\n Allow change of topic between actions and dialog \n\nIf you are using actions and dialog, you can ensure that customers can change topics between an action and a dialog node.\n\nThis setting is available if you activate dialog in Assistant settings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-global-settings"},{"document_id":"ibmcld_16359-8409-10354","score":17.5923881683,"text":"\nYou can change it to something else, such as I need something else or These aren't what I want. Or, you can remove the text to omit offering this choice. \n\n\n\n3. If you enable response modes, you can modify this text:\n\n\n\nResponse modes settings\n\n Field Default text Description \n\n One action matches Something else If an assistant prioritizes one action that it thinks matches the customer need, it can clarify the match by asking the customer to confirm. This choice accompanies the single action in case the customer needs something else. You can change it to something else, such as I need something else or This isn't what I want. \n Connection to support Connect to support The assistant can include a choice to connect to other support in the list of clarifying questions. If the customer picks this choice, the assistant uses your Fallback action. You can change it to something else, such as Talk to a live agent or Search for the answer. \n\n\n\n4. Click Save, and then click Close.\n5. Publish a new version of your assistant to the live environment to apply the customizations. For more information, see [Publishing your content](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish).\n\n\n\n\n\n\n\n Disabling clarifying questions \n\nYou can disable clarifying questions for all actions.\n\nTo disable clarification for all actions:\n\n\n\n1. From the Actions page of the assistant, click Global settings![Gear icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/settings.svg).\n2. On the Clarifying questions tab, ensure that the Response modes switch is set to Off.\n3. Set the Enable disambiguation switch to Off.\n4. Click Save, and then click Close.\n5. Publish a new version of your assistant to the live environment to disable clarification. For more information, see [Publishing your content](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish).\n\n\n\n\n\n\n\n Excluding an action from clarifying questions","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questions"},{"document_id":"ibmcld_03406-18621-20036","score":17.5828449053,"text":"\n[Edit response](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/edit-slot.png) icon for the conditional response you just added. From the Options![Advanced response](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) menu, click Open JSON editor. Add a context block that sets the slot context variables to null, as shown.\n\n{\n\"output\":{\n\"text\": {\n\"values\": [\n\"Alright. Let's start over. I'll try to keep up this time.\"\n]\n}\n},\n\"context\":{\n\"date\": null,\n\"time\": null,\n\"guests\": null\n}\n}\n4. Click Back, and then click Save.\n5. Click the Edit slot![Edit slot](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/edit-slot.png) icon for the confirmation slot again. In the Not found prompt, clarify that you are expecting the user to provide a Yes or No answer. Add a response with the following values.\n\n\n\nNot found response details\n\n Condition Response \n\n `true` Respond with Yes to indicate that you want the reservation to be made as-is, or No to indicate that you do not. \n\n\n\n6. Click Save.\n7. Now that you have confirmation responses for slot values, and you ask for everything at once, you might notice that the individual slot responses are displayed before the confirmation slot response is displayed, which can appear repetitive to users.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial-slots-complex"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05342-35727-36837","score":10.0768393456,"text":"\n_) \/ \/( (_ )( \/ \/ ) _)\n(____)_)__) ___\/(__)_)__)(____)\n\nSome Env Vars:\n--------------\nHOME=\/root\nHOSTNAME=myjobrunresubmit2-2-0\nJOB_INDEX=2\nKUBERNETES_PORT=tcp:\/\/172.21.0.1:443\nKUBERNETES_PORT_443_TCP=tcp:\/\/172.21.0.1:443\nKUBERNETES_PORT_443_TCP_ADDR=172.21.0.1\nKUBERNETES_PORT_443_TCP_PORT=443\nKUBERNETES_PORT_443_TCP_PROTO=tcp\nKUBERNETES_SERVICE_HOST=172.21.0.1\nKUBERNETES_SERVICE_PORT=443\nKUBERNETES_SERVICE_PORT_HTTPS=443\nPATH=\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin\nPWD=\/\nSHLVL=1\nTARGET=My new big literal secret\n\n\n\nTo summarize, you completed basic scenarios to demonstrate how to use secrets with a job by referencing an existing full secret and updating keys within a secret.\n\n\n\n\n\n Referencing secrets that are not yet defined with the CLI \n\nIf a secret does not exist before it is referenced, an app will not deploy successfully, and a job will not run successfully until the referenced secret is created.\n\nIf you are working with an app or a job and the referenced secret is not yet defined, use the --force option to avoid verification of the existence of the referenced secret.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-configmap-secret"},{"document_id":"ibmcld_05436-35667-36777","score":10.0768393456,"text":"\n_) \/ \/( (_ )( \/ \/ ) _)\n(____)_)__) ___\/(__)_)__)(____)\n\nSome Env Vars:\n--------------\nHOME=\/root\nHOSTNAME=myjobrunresubmit2-2-0\nJOB_INDEX=2\nKUBERNETES_PORT=tcp:\/\/172.21.0.1:443\nKUBERNETES_PORT_443_TCP=tcp:\/\/172.21.0.1:443\nKUBERNETES_PORT_443_TCP_ADDR=172.21.0.1\nKUBERNETES_PORT_443_TCP_PORT=443\nKUBERNETES_PORT_443_TCP_PROTO=tcp\nKUBERNETES_SERVICE_HOST=172.21.0.1\nKUBERNETES_SERVICE_PORT=443\nKUBERNETES_SERVICE_PORT_HTTPS=443\nPATH=\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin\nPWD=\/\nSHLVL=1\nTARGET=My new big literal secret\n\n\n\nTo summarize, you completed basic scenarios to demonstrate how to use secrets with a job by referencing an existing full secret and updating keys within a secret.\n\n\n\n\n\n Referencing secrets that are not yet defined with the CLI \n\nIf a secret does not exist before it is referenced, an app will not deploy successfully, and a job will not run successfully until the referenced secret is created.\n\nIf you are working with an app or a job and the referenced secret is not yet defined, use the --force option to avoid verification of the existence of the referenced secret.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secret"},{"document_id":"ibmcld_05557-5511-7293","score":9.4648927198,"text":"\nIn Kubernetes cluster versions 1.21 and later, Konnectivity replaced the OpenVPN solution. If you have cluster version 1.21 and later, and your webhook uses the ClusterIP, you must update your webhook to use a Kubernetes service instead.\n\nYou can configure a webhook by referencing the webhook app as a Kubernetes service, or by referencing the webhook app as an IP address or publicly registered DNS name.\n\nExample configuration for referencing the webhook app as a Kubernetes service\n\n {: codeblock}\nclientConfig:\ncaBundle: CA_BUNDLE_BASE64\nservice:\nname: admission-webhook\nnamespace: default\npath: \/validate\nport: 443\n\nExample configuration for referencing the webhook app as an IP address or publicly registered DNS name\n\n {: codeblock}\nclientConfig:\ncaBundle: CA_BUNDLE_BASE64\nurl: https:\/\/WEBHOOK_URL:443\/validate\n\nShow more\n\nNote the following limitations for referencing the webhook app as an IP address or DNS name:\n\n\n\n* If the URL is a DNS, then this DNS must be a publicly registered DNS name. Private DNS configurations are not supported.\n* If the URL is an external IP address, which means the webhook service is outside of the cluster, the control plane network is used to connect to the service. The control plane must be able to reach the IP address. If, for example, the IP address is from an on-premises network and the control plane can't reach the IP address, the webhook service does not work.\n* If the URL is a cluster IP address, which means the webhook service is inside of the cluster, the Kubernetes API needs to connect to cluster network. If you have cluster version 1.21 and later, and your webhook uses the cluster IP address, you must update your webhook to use a Kubernetes service instead.\n\n\n\n\n\n\n\n\n\n I need help with a broken webhook. What can I do?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_webhooks"},{"document_id":"ibmcld_11886-2994-4812","score":9.4516431853,"text":"\nFor more information, see the [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/authorization\/).\n\nIf you choose a custom access option, some Satellite Config components might not work. For example, if you grant access to view only certain resources, you cannot use subscriptions to create Kubernetes resources in your cluster group. To view an inventory of your Kubernetes resources in a cluster, Satellite Config must have an appropriate role that is bound to the razee-viewer service account. To deploy Kubernetes resources to a cluster by using subscriptions, Satellite Config must have an appropriate role that is bound to the razee-editor service account.\n\n\n\n\n\n Cluster admin access \n\nGrant the Satellite Config service accounts access to the cluster admin role.\n\nkubectl create clusterrolebinding razee-cluster-admin --clusterrole=razee-cluster-admin --serviceaccount=razeedeploy:razee-viewer --serviceaccount=razeedeploy:razee-editor --serviceaccount=razeedeploy:razee-satcon\n\n\n\n\n\n Custom access, cluster-wide \n\nCreate custom RBAC policies to grant Satellite Config access to the actions and Kubernetes resources that you want for the cluster.\n\n\n\n1. Create a cluster role with the actions and resources that you want to grant. For example, the following command creates a viewer role so that Satellite Config can list all the Kubernetes resources in a cluster, but cannot modify them.\n\nkubectl create clusterrole razee-viewer --verb=get,list,watch --resource=\".\"\n\n\n\nUnderstanding this command's components\n\n Component Description \n\n razee-viewer The name of the cluster role, such as razee-viewer. \n --verb=get,list,watch A comma-separated list of actions that the role authorizes. In this example, the action verbs are for roles typical for a viewer or auditor, get,list,watch.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfig"},{"document_id":"ibmcld_02683-2805-4831","score":9.2953487101,"text":"\nFor your application and SDK to continue operations during the unlikely scenario of an App Configuration service downtime, across your application restarts, you can configure the SDK to work by using a persistent cache. The SDK uses the persistent cache to store the App Configuration data that is available across your application restarts.\n\n\/\/ 1. default (without persistent cache)\nappConfigClient.setContext(collectionId, environmentId);\n\n\/\/ 2. optional (with persistent cache)\nConfigurationOptions configOptions = new ConfigurationOptions();\nconfigOptions.setPersistentCacheDirectory(\"\/var\/lib\/docker\/volumes\/\");\nappConfigClient.setContext(collectionId, environmentId, configOptions);\n\nWhere:\n\n\n\n* persistentCacheDirectory: Absolute path to a directory that has read and write permission for the user. The SDK creates a file - appconfiguration.json in the specified directory, and it is used as the persistent cache to store the App Configuration service information.\n\n\n\nWhen persistent cache is enabled, the SDK keeps the last known good configuration at the persistent cache. If the App Configuration server being unreachable, the latest configurations at the persistent cache are loaded to the application to continue working.\n\nEnsure that the cache file is not lost or deleted in any case. For example, consider the case when a kubernetes pod is restarted and the cache file (appconfiguration.json) was stored in ephemeral volume of the pod. As pod gets restarted, kubernetes destroys the ephermal volume in the pod, as a result the cache file gets deleted. So, make sure that the cache file created by the SDK is always stored in persistent volume by providing the correct absolute path of the persistent directory.\n\n\n\n\n\n Offline options \n\nThe SDK is also designed to serve configurations, and perform feature flag and property evaluations without being connected to App Configuration service.\n\nConfigurationOptions configOptions = new ConfigurationOptions();\nconfigOptions.setBootstrapFile(\"saflights\/flights.json\");","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-java"},{"document_id":"ibmcld_06123-1617-3175","score":8.8078384592,"text":"\nRPO (Recovery Point Objective) and RTO (Recovery Time Objective) for this configuration is less than 60 seconds.\n* [Asynchronous DR](https:\/\/docs.portworx.com\/portworx-install-with-kubernetes\/disaster-recovery\/2-asynchronous-dr-nodes-are-across-different-regions-datacenters): Your Kubernetes clusters are deployed in different regions, such as us-south and us-east. Each cluster has its own Portworx installation and uses a separate Portworx key-value store that is not shared. To replicate data between clusters, you must set up scheduled replication between these clusters. Because of the higher latency and scheduled replication times, the RPO for this scenario might be up to 15 minutes.\n\n\n\nTo include your cluster in a Portworx disaster recovery configuration:\n\n\n\n1. [Choose the disaster recovery configuration that works for your cluster setup](https:\/\/docs.portworx.com\/portworx-install-with-kubernetes\/disaster-recovery\/).\n2. Review the prerequisites for the [Metro DR](https:\/\/docs.portworx.com\/portworx-install-with-kubernetes\/disaster-recovery\/px-metro\/1-install-px\/prerequisites) and [Asynchronous DR](https:\/\/docs.portworx.com\/portworx-install-with-kubernetes\/disaster-recovery\/async-dr\/pre-requisites) configuration.\n3. Configure disaster recovery for your cluster. Metro DR:\n\n\n\n1. Choose at least two Kubernetes clusters that are located in the same metro location. If you have one cluster only, you can still configure this cluster for metro disaster recovery, but Portworx can't do a proper failover until a second cluster is configured.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage_portworx_recovery"},{"document_id":"ibmcld_06004-14210-16020","score":8.4979170452,"text":"\nPods that are managed by a daemon set are automatically scheduled when a worker node is added to a cluster. Typical use cases include log collectors, such as logstash or prometheus, that collect logs from every worker node to provide insight into the health of a cluster or an app. \n [Job](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/controllers\/job\/) A job ensures that one or more pods run successfully to completion. You might use a job for queues or batch jobs to support parallel processing of separate but related work items, such as specific frames to render, emails to send, and files to convert. To schedule a job to run at certain times, use a [CronJob](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/controllers\/cron-jobs\/). \n\n\n\n\n\n\n\n What if I want my app configuration to use variables? How do I add these variables to the YAML? \n\nTo add variable information to your deployments instead of hardcoding the data into the YAML file, you can use a Kubernetes [ConfigMap](https:\/\/kubernetes.io\/docs\/tasks\/configure-pod-container\/configure-pod-configmap\/) or [Secret](https:\/\/kubernetes.io\/docs\/concepts\/configuration\/secret\/) object.\n\nTo consume a ConfigMap or secret, you need to mount it to the pod. The ConfigMap or secret is combined with the pod just before the pod is run. You can reuse a deployment spec and image across many apps, but then swap out the customized configmaps and secrets. Secrets in particular can take up a lot of storage on the local node, so plan accordingly.\n\nBoth resources define key-value pairs, but you use them for different situations.\n\nConfigmap\n: Provide non-sensitive configuration information for workloads that are specified in a deployment. You can use configmaps in three main ways.\n\n\n\n* File system: You can mount an entire file or a set of variables to a pod.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_deploy"},{"document_id":"ibmcld_10439-18453-20263","score":8.4979170452,"text":"\nPods that are managed by a daemon set are automatically scheduled when a worker node is added to a cluster. Typical use cases include log collectors, such as logstash or prometheus, that collect logs from every worker node to provide insight into the health of a cluster or an app. \n [Job](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/controllers\/job\/) A job ensures that one or more pods run successfully to completion. You might use a job for queues or batch jobs to support parallel processing of separate but related work items, such as specific frames to render, emails to send, and files to convert. To schedule a job to run at certain times, use a [CronJob](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/controllers\/cron-jobs\/). \n\n\n\n\n\n\n\n What if I want my app configuration to use variables? How do I add these variables to the YAML? \n\nTo add variable information to your deployments instead of hardcoding the data into the YAML file, you can use a Kubernetes [ConfigMap](https:\/\/kubernetes.io\/docs\/tasks\/configure-pod-container\/configure-pod-configmap\/) or [Secret](https:\/\/kubernetes.io\/docs\/concepts\/configuration\/secret\/) object.\n\nTo consume a ConfigMap or secret, you need to mount it to the pod. The ConfigMap or secret is combined with the pod just before the pod is run. You can reuse a deployment spec and image across many apps, but then swap out the customized configmaps and secrets. Secrets in particular can take up a lot of storage on the local node, so plan accordingly.\n\nBoth resources define key-value pairs, but you use them for different situations.\n\nConfigmap\n: Provide non-sensitive configuration information for workloads that are specified in a deployment. You can use configmaps in three main ways.\n\n\n\n* File system: You can mount an entire file or a set of variables to a pod.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_deploy"},{"document_id":"ibmcld_07578-534510-536520","score":8.4805021457,"text":"\nThe multiple worker agents are now listed in the private worker integration UI and jobs are scheduled on those agents based on the cluster load at pipeline run request time.\n* How do I view the status of private workers on multiple clusters by using the CLI?\n\nYou can use the following command within a script that traverses all of the clusters that private workers are installed on.\n\nkubectl get workeragent -ojson | jq '.items[] | .status.versionStatus.state'\n\nConsider upgrading any private workers that return results that are not OK.\n* Which attributes can I use for private worker agents?\n\nThe following attributes are available for private worker agents:\n\n\n\n* NAME: The name that was specified when the agent was registered. This name appears on the Private Worker integration page.\n* SERVICEID: The work queue ID from which this agent processes work requests.\n* AGENT: A value of OK indicates that the agent can process work requests.\n* REGISTERED: A value of Succeeded indicates that the agent successfully registered with the regional private worker service.\n* VERSION: A value of OK indicates whether the version of the agent is current.\n* AUTH: A value of OK indicates whether the agent apikey is valid.\n* CONSTRAINED: A value of false indicates that enough cluster resources are available for the agent to run tasks. A value of True specifies that the cluster is resource-constrained.\n* PAUSED: A value of false indicates that the agent is operational and can run tasks. A value of true specifies that the agent is paused and cannot run any tasks. One reason that an agent might be paused is for cluster maintenance.\n\n\n\n* How do I set my ClusterImagePolicy so that I can access Tekton images?\n\nBecause Delivery Pipeline private workers depend on the Tekton and tekton-pipelines infrastructure, they must pull tekton-releases images from icr.io (icr.io\/continuous-delivery\/pipeline\/). You might need to define a specific Kubernetes ClusterImagePolicy to pull images from these container registries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-534464-536474","score":8.4805021457,"text":"\nThe multiple worker agents are now listed in the private worker integration UI and jobs are scheduled on those agents based on the cluster load at pipeline run request time.\n* How do I view the status of private workers on multiple clusters by using the CLI?\n\nYou can use the following command within a script that traverses all of the clusters that private workers are installed on.\n\nkubectl get workeragent -ojson | jq '.items[] | .status.versionStatus.state'\n\nConsider upgrading any private workers that return results that are not OK.\n* Which attributes can I use for private worker agents?\n\nThe following attributes are available for private worker agents:\n\n\n\n* NAME: The name that was specified when the agent was registered. This name appears on the Private Worker integration page.\n* SERVICEID: The work queue ID from which this agent processes work requests.\n* AGENT: A value of OK indicates that the agent can process work requests.\n* REGISTERED: A value of Succeeded indicates that the agent successfully registered with the regional private worker service.\n* VERSION: A value of OK indicates whether the version of the agent is current.\n* AUTH: A value of OK indicates whether the agent apikey is valid.\n* CONSTRAINED: A value of false indicates that enough cluster resources are available for the agent to run tasks. A value of True specifies that the cluster is resource-constrained.\n* PAUSED: A value of false indicates that the agent is operational and can run tasks. A value of true specifies that the agent is paused and cannot run any tasks. One reason that an agent might be paused is for cluster maintenance.\n\n\n\n* How do I set my ClusterImagePolicy so that I can access Tekton images?\n\nBecause Delivery Pipeline private workers depend on the Tekton and tekton-pipelines infrastructure, they must pull tekton-releases images from icr.io (icr.io\/continuous-delivery\/pipeline\/). You might need to define a specific Kubernetes ClusterImagePolicy to pull images from these container registries.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-380995-382843","score":22.8274467171,"text":"\n* What options do I have to secure my cluster?\n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecurity).\n* What access policies do I give my cluster users?\n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_reference) or in the following table's links. For steps to assign policies, see [Granting users access to your cluster through IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\n\n\nTypes of roles you might assign to meet different use cases.\n\n Use case Example roles and scope","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-380969-382817","score":22.8274467171,"text":"\n* What options do I have to secure my cluster?\n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecurity).\n* What access policies do I give my cluster users?\n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_reference) or in the following table's links. For steps to assign policies, see [Granting users access to your cluster through IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\n\n\nTypes of roles you might assign to meet different use cases.\n\n Use case Example roles and scope","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_12665-0-2848","score":22.775947533,"text":"\n\n\n\n\n\n\n  Database Privileges \n\nIn this section, you can find the details about minimum required database privileges for encryption using Data Security Broker.\n\n\n\n  Database privileges for encryption and migration \n\nTo carry out encryption and migration, Data Security Broker Shield requires certain user permissions on the database. It is recommended that you create a new user on your database for Data Security Broker Shield to use.\n\n\n\n\n\n  Database privileges required for PostgreSQL 12 \n\n\n\nTable 1. Database privileges required for PostgreSQL 12 in Data Security Broker Manager caption-side=\n\n Operation                                                                        Details                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Queries used by Shield                                                              Minimum required grants                                                                            Additional information     \n\n Proxy normal operation: Support implicit inserts, and Obtain column information  Access information_schema to get information about columns. This is needed to support queries such as implicit inserts (inserts that don\u2019t have column names specified explicitly). [Per database or per schema or per table that is defined in Data Security Broker] select ordinal_position, column_name, data_type from information_schema .COLUMNS where table_catalog=Database Name and table_schema=Schema Name, and table_name=TableName order by ordinal_position                Select grant is required for all tables that are defined in Data Security Broker.   If a new database, schema or column is added to your protection plan, ensure the grant is applied \n CheckProxyPort                                                                   Check if the port specified for the Shield is responsive                                                                                                                                                                                                                                                                                                                                                                                                                                 Select 1                                                                            Select grant                                                                                      \n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-broker?topic=security-broker-sb_db_priveleges"},{"document_id":"ibmcld_09579-1630-3133","score":22.7409862903,"text":"\n--location ${LOCATION_ID}\n--name ${OPERATORCONFIGNAME}\n--template-name 'netapp-trident'\n--template-version '20.07'\n* SAN configuration:\n\nibmcloud sat storage config create\n--location ${LOCATION_ID}\n--name ${SANCONFIGNAME}\n--template-name 'netapp-ontap-san'\n--template-version '20.07'\n--param \"dataLIF=${DATALIF}\"\n--param \"managementLIF=${MGMLIF}\"\n--param \"svm=${SVM}\"\n--param \"username=${USERNAME}\"\n--param \"password=${PASSWORD}\"\n--param \"limitVolumeSize=1100Gi\"\n\n\n\n\n\n\n\n\n\n\n\n Step 2: Grant a service authorization \n\nBegin by configuring IAM Authorizations:\n\n\n\n* Configure your IAM Authorizations under the Manage tab.\n* Choose the Authorizations tab from the left menu.\n* Click create to allow a service instance access to another service instance.\n\n\n\n* The source service is the service that is granted access to the target service. The roles that you select define the level of access for this service. The target service is the service that you are granting permission to be accessed by the source service based on the assigned roles.\n* In the Source Service field, select Databases for < DATABASE TYPE >.\n* In the Target Service field, select Satellite.\n* Select all options:\n\n\n\n* Satellite Cluster Creator\n* Satellite Link Administrator\n* Satellite Link Source Access Controller\n\n\n\n* Then, Authorize.\n\n\n\n\n\n\n\n\n\n Step 3: Ensure location readiness \n\nYour location needs to report Normal before you provision your ICD Satellite Deployment. This status can be confirmed in the UI, as shown here:\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-satellite-on-prem"},{"document_id":"ibmcld_06468-1630-3133","score":22.7409862903,"text":"\n--location ${LOCATION_ID}\n--name ${OPERATORCONFIGNAME}\n--template-name 'netapp-trident'\n--template-version '20.07'\n* SAN configuration:\n\nibmcloud sat storage config create\n--location ${LOCATION_ID}\n--name ${SANCONFIGNAME}\n--template-name 'netapp-ontap-san'\n--template-version '20.07'\n--param \"dataLIF=${DATALIF}\"\n--param \"managementLIF=${MGMLIF}\"\n--param \"svm=${SVM}\"\n--param \"username=${USERNAME}\"\n--param \"password=${PASSWORD}\"\n--param \"limitVolumeSize=1100Gi\"\n\n\n\n\n\n\n\n\n\n\n\n Step 2: Grant a service authorization \n\nBegin by configuring IAM Authorizations:\n\n\n\n* Configure your IAM Authorizations under the Manage tab.\n* Choose the Authorizations tab from the left menu.\n* Click create to allow a service instance access to another service instance.\n\n\n\n* The source service is the service that is granted access to the target service. The roles that you select define the level of access for this service. The target service is the service that you are granting permission to be accessed by the source service based on the assigned roles.\n* In the Source Service field, select Databases for < DATABASE TYPE >.\n* In the Target Service field, select Satellite.\n* Select all options:\n\n\n\n* Satellite Cluster Creator\n* Satellite Link Administrator\n* Satellite Link Source Access Controller\n\n\n\n* Then, Authorize.\n\n\n\n\n\n\n\n\n\n Step 3: Ensure location readiness \n\nYour location needs to report Normal before you provision your ICD Satellite Deployment. This status can be confirmed in the UI, as shown here:\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-satellite-on-prem"},{"document_id":"ibmcld_06660-1630-3133","score":22.7409862903,"text":"\n--location ${LOCATION_ID}\n--name ${OPERATORCONFIGNAME}\n--template-name 'netapp-trident'\n--template-version '20.07'\n* SAN configuration:\n\nibmcloud sat storage config create\n--location ${LOCATION_ID}\n--name ${SANCONFIGNAME}\n--template-name 'netapp-ontap-san'\n--template-version '20.07'\n--param \"dataLIF=${DATALIF}\"\n--param \"managementLIF=${MGMLIF}\"\n--param \"svm=${SVM}\"\n--param \"username=${USERNAME}\"\n--param \"password=${PASSWORD}\"\n--param \"limitVolumeSize=1100Gi\"\n\n\n\n\n\n\n\n\n\n\n\n Step 2: Grant a service authorization \n\nBegin by configuring IAM Authorizations:\n\n\n\n* Configure your IAM Authorizations under the Manage tab.\n* Choose the Authorizations tab from the left menu.\n* Click create to allow a service instance access to another service instance.\n\n\n\n* The source service is the service that is granted access to the target service. The roles that you select define the level of access for this service. The target service is the service that you are granting permission to be accessed by the source service based on the assigned roles.\n* In the Source Service field, select Databases for < DATABASE TYPE >.\n* In the Target Service field, select Satellite.\n* Select all options:\n\n\n\n* Satellite Cluster Creator\n* Satellite Link Administrator\n* Satellite Link Source Access Controller\n\n\n\n* Then, Authorize.\n\n\n\n\n\n\n\n\n\n Step 3: Ensure location readiness \n\nYour location needs to report Normal before you provision your ICD Satellite Deployment. This status can be confirmed in the UI, as shown here:\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-satellite-on-prem"},{"document_id":"ibmcld_06722-1630-3133","score":22.7409862903,"text":"\n--location ${LOCATION_ID}\n--name ${OPERATORCONFIGNAME}\n--template-name 'netapp-trident'\n--template-version '20.07'\n* SAN configuration:\n\nibmcloud sat storage config create\n--location ${LOCATION_ID}\n--name ${SANCONFIGNAME}\n--template-name 'netapp-ontap-san'\n--template-version '20.07'\n--param \"dataLIF=${DATALIF}\"\n--param \"managementLIF=${MGMLIF}\"\n--param \"svm=${SVM}\"\n--param \"username=${USERNAME}\"\n--param \"password=${PASSWORD}\"\n--param \"limitVolumeSize=1100Gi\"\n\n\n\n\n\n\n\n\n\n\n\n Step 2: Grant a service authorization \n\nBegin by configuring IAM Authorizations:\n\n\n\n* Configure your IAM Authorizations under the Manage tab.\n* Choose the Authorizations tab from the left menu.\n* Click create to allow a service instance access to another service instance.\n\n\n\n* The source service is the service that is granted access to the target service. The roles that you select define the level of access for this service. The target service is the service that you are granting permission to be accessed by the source service based on the assigned roles.\n* In the Source Service field, select Databases for < DATABASE TYPE >.\n* In the Target Service field, select Satellite.\n* Select all options:\n\n\n\n* Satellite Cluster Creator\n* Satellite Link Administrator\n* Satellite Link Source Access Controller\n\n\n\n* Then, Authorize.\n\n\n\n\n\n\n\n\n\n Step 3: Ensure location readiness \n\nYour location needs to report Normal before you provision your ICD Satellite Deployment. This status can be confirmed in the UI, as shown here:\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-satellite-on-prem"},{"document_id":"ibmcld_04577-1630-3133","score":22.7409862903,"text":"\n--location ${LOCATION_ID}\n--name ${OPERATORCONFIGNAME}\n--template-name 'netapp-trident'\n--template-version '20.07'\n* SAN configuration:\n\nibmcloud sat storage config create\n--location ${LOCATION_ID}\n--name ${SANCONFIGNAME}\n--template-name 'netapp-ontap-san'\n--template-version '20.07'\n--param \"dataLIF=${DATALIF}\"\n--param \"managementLIF=${MGMLIF}\"\n--param \"svm=${SVM}\"\n--param \"username=${USERNAME}\"\n--param \"password=${PASSWORD}\"\n--param \"limitVolumeSize=1100Gi\"\n\n\n\n\n\n\n\n\n\n\n\n Step 2: Grant a service authorization \n\nBegin by configuring IAM Authorizations:\n\n\n\n* Configure your IAM Authorizations under the Manage tab.\n* Choose the Authorizations tab from the left menu.\n* Click create to allow a service instance access to another service instance.\n\n\n\n* The source service is the service that is granted access to the target service. The roles that you select define the level of access for this service. The target service is the service that you are granting permission to be accessed by the source service based on the assigned roles.\n* In the Source Service field, select Databases for < DATABASE TYPE >.\n* In the Target Service field, select Satellite.\n* Select all options:\n\n\n\n* Satellite Cluster Creator\n* Satellite Link Administrator\n* Satellite Link Source Access Controller\n\n\n\n* Then, Authorize.\n\n\n\n\n\n\n\n\n\n Step 3: Ensure location readiness \n\nYour location needs to report Normal before you provision your ICD Satellite Deployment. This status can be confirmed in the UI, as shown here:\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-satellite-on-prem"},{"document_id":"ibmcld_12590-4381-6429","score":22.2209854851,"text":"\nFor more information, see [Required access for managing service ID API keys](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceidapikeys&interface=uirequired-access-serviceid-keys)\n3. Create a policy that grants the trusted profile access to deploy the deployable architecture.\n\nYou can choose from a couple of approaches to grant the service ID access to authorize deployments in your account. See [Granting wide-ranging access](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-tp-projectserviceid-access-wide)[Granting specific access](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-tp-projectserviceid-access-specific) for more information.\n4. Click Add.\n\n\n\n\n\n\n\n Granting wide-ranging access \n\nGrant the trusted profile Administrator access to everything in the account by assigning two policies. Consider this option if you plan to deploy many deployable architectures to the same target account. You can use the same trusted profile for different deployable architectures across projects, eliminating the need to continuously update the trusted profile's access policies.\n\nIt's secure and convenient to give the trusted profile a wide range of access because projects have many [governance checks](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-understanding-projectsproject-use) already in place, including pre-deployment validation and a required approval process. By granting Administrator access now, you don't need to update the policy for the multiple deployable architectures that you might use that require different levels of access.\n\n\n\n1. To create the first policy, select All Identity and Access enabled services and click Next.\n\n\n\n1. Select All resources and click Next.\n2. For the resource group access, select the Administrator role and click Next.\n3. Select the Manager service role and the Administrator platform role.\n4. Click Add.\n\n\n\n2. For the second policy, select All Account Management services and click Next.\n\n\n\n1. Select the Administrator role.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-tp-project"},{"document_id":"ibmcld_05777-8738-10765","score":21.9498636767,"text":"\nThis setup is called a [multizone cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmz-clusters) and ensures that your app is accessible, even if a worker node or an entire zone is not available.\n\nTo protect against an entire region failure, create [multiple clusters and spread them across IBM Cloud regions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmultiple-clusters-glb). By setting up a network load balancer (NLB) for your clusters, you can achieve cross-region load balancing and cross-region networking for your clusters.\n\nIf you have data that must be available, even if an outage occurs, make sure to store your data on [persistent storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan).\n\nFor more information about how to achieve high availability for your cluster, see [High availability for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-haha).\n\n\n\n\n\n What options do I have to secure my cluster? \n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecurity).\n\n\n\n\n\n What access policies do I give my cluster users? \n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqs"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04156-0-1820","score":20.2599652893,"text":"\n\n\n\n\n\n\n  Getting help and support for CIS \n\nIf you experience an issue or have questions when using CIS, you can use the following resources before you open a support case.\n\n\n\n*  Review [FAQs](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-faq) in the product documentation.\n*  Review [Troubleshooting](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-troubleshoot-your-cis-network-connection) to diagnose and resolve common issues.\n*  Check the status of the IBM Cloud platform and resources by going to the [Status page](https:\/\/cloud.ibm.com\/status).\n*  Review [Stack Overflow](https:\/\/stackoverflow.com\/search?q=cis+ibm-cloud) to see whether other users ran into the same problem. If you're using the forum to ask a question, tag your question with ibm-cloud and cis so that it is seen by the IBM Cloud development teams.\n\n\n\nIf you still can't resolve the problem, you can open a support case. For more information, see [Creating support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case).\n\n\n\n  Providing support case details for CIS \n\nTo ensure that the support team has all of the details for investigating your issue to provide a timely resolution, you must provide detailed information about your issue. Review the following tips about the type of information to include in your support case for issues with CIS.\n\nProvide the following details:\n\n\n\n1.  Provide your CRN:\n\n\n\n*  In the UI, go to the Overview page\n*  In the CLI, run ibmcloud resource service-instances --long\n\n\n\n2.  Provide your Domain name or ID.\n3.  Depending on the issue the following information might also be helpful:\n\n\n\n*  Account ID: Log into [https:\/\/cloud.ibm.com](https:\/\/cloud.ibm.com) and go to View Profile > Billing\n*  Instance ID: Run the CLI command ibmcloud resource service-instances --long\n*  Geo location\n\n\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-gettinghelp"},{"document_id":"ibmcld_00384-0-1839","score":19.466520512,"text":"\n\n\n\n\n\n\n  Getting help and support for CDN \n\nIf you experience an issue or have questions when using CDN, you can use the following resources before you open a support case.\n\n\n\n*  Review [FAQs](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-faqs) in the product documentation.\n*  Review [Troubleshooting](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-troubleshoot-cdn-working) to diagnose and resolve common issues.\n*  Check the status of the IBM Cloud platform and resources by going to the [Status page](https:\/\/cloud.ibm.com\/status).\n*  Review [Stack Overflow](https:\/\/stackoverflow.com\/search?q=cdn+ibm-cloud) to see whether other users ran into the same problem. If you're using the forum to ask a question, tag your question with ibm-cloud and cdn so that it is seen by the IBM Cloud development teams.\n\n\n\nIf you still can't resolve the problem, you can open a support case. For more information, see [Creating support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case).\n\n\n\n  Providing support case details for CDN \n\nTo ensure that the support team has all of the details for investigating your issue to provide a timely resolution, you must provide detailed information about your issue. Review the following tips about the type of information to include in your support case for issues with CDN.\n\nProvide the following details:\n\n\n\n1.  Go to the [All CDNs page](https:\/\/cloud.ibm.com\/cdn).\n2.  From the UI, provide the following information:\n\n\n\n*  (Required) Hostname, for example, example.testingcdn.net\n*  CNAME, for example, example.cdn.appdomain.cloud\n*  HTTPS status, for example, Yes (Wildcard)\n*  Status, for example, Running\n\n\n\nFrom the API, run listDomainMappings or listDomainMappingByUniqueId to get the following domain mapping information:\n\n\n\n*  (Required) domain\n*  cname\n*  protocol\n*  status\n\n\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-gettinghelp"},{"document_id":"ibmcld_14241-0-1025","score":18.604225861,"text":"\n\n\n\n\n\n\n  Contacting IBM Support \n\nIf you need help with IBM Cloud\u00ae for VMware as a Service, create a case from the IBM Cloud Support Center to get assistance.\n\n\n\n  Procedure to create a case for VMware as a Service \n\n\n\n1.  Go to the [IBM Cloud Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n2.  Log in with your IBMid account.\n3.  Select All Products and type VMware as a Service where prompted for the product name, then click IBM Cloud for VMware as a Service.\n4.  Review the various solutions offered. If you do not see an answer to your problem, click Create a case.\n5.  On the New support case page, provide the following information:\n\n\n\n1.  Enter a subject for your issue.\n2.  Describe your issue in detail, such as the error messages, steps to re-create, and the URL that you are accessing.\n3.  Under Add attachments, upload screen captures of the issue.\n4.  If you want to be notified of updates on the issue, select the Email me updates about this case checkbox.\n\n\n\n6.  Click Submit.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmware-service?topic=vmware-service-support"},{"document_id":"ibmcld_13830-7-2040","score":18.4251301714,"text":"\nGetting help and support for Transit Gateway \n\nIf you experience an issue or have questions when using IBM Cloud\u00ae Transit Gateway, you can use the following resources before you open a support case.\n\n\n\n* Review [FAQs](https:\/\/cloud.ibm.com\/docs\/transit-gateway?topic=transit-gateway-faqs-for-transit-gateway) in the product documentation.\n* Review [Troubleshooting](https:\/\/cloud.ibm.com\/docs\/transit-gateway?topic=transit-gateway-troubleshooting) to diagnose and resolve common issues.\n* Check the status of the IBM Cloud platform and resources by going to the [Status page](https:\/\/cloud.ibm.com\/status).\n* Review [Stack Overflow](https:\/\/stackoverflow.com\/search?q=transit-gateway+ibm-cloud) to see whether other users ran into the same problem. If you're using the forum to ask a question, tag your question with ibm-cloud and transit-gateway so that it is seen by the IBM Cloud development teams.\n\n\n\nIf you still can't resolve the problem, you can open a support case. For more information, see [Creating support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case).\n\n\n\n Providing support case details for Transit Gateway \n\nTo ensure that the support team has all of the details for investigating your issue to provide a timely resolution, you must provide detailed information about your issue. Review the following tips about the type of information to include in your support case for issues with Transit Gateway.\n\nProvide the following details:\n\n\n\n1. Provide your transit gateway ID:\n\n\n\n* Run ibmcloud tg gateways to get the Transit Gateway ID for the transit gateway in question from the output, and then collect the output of these commands ibmcloud tg gateway GATEWAY_ID and ibmcloud tg connections GATEWAY_ID.\n* In the output of the previous command, get the connection IDs for the connections to the relevant VPCs, and if relevant, the classic infrastructure connection. Also, collect the output of the following command against each connection ID: ibmcloud tg connection GATEWAY_ID CONNECTION_ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/transit-gateway?topic=transit-gateway-getting-help-and-support"},{"document_id":"ibmcld_07395-7-1761","score":18.1135136951,"text":"\nGetting help and support for DNS Services \n\nIf you experience an issue or have questions when using IBM Cloud\u00ae DNS Services, you can use the following resources before you open a support case.\n\n\n\n* Review [FAQs](https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-frequently-asked-questions) in the product documentation.\n* Review [Troubleshooting](https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-troubleshoot-nxdomain) to diagnose and resolve common issues.\n* Check the status of the IBM Cloud platform and resources by going to the [Status page](https:\/\/cloud.ibm.com\/status).\n* Review [Stack Overflow](https:\/\/stackoverflow.com\/search?q=dns-svcs+ibm-cloud) to see whether other users ran into the same problem. If you're using the forum to ask a question, tag your question with ibm-cloud and dns-svcs so that it is seen by the IBM Cloud development teams.\n\n\n\nIf you still can't resolve the problem, you can open a support case. For more information, see [Creating support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case).\n\n\n\n Providing support case details for DNS Services \n\nTo ensure that the support team has all of the details for investigating your issue to provide a timely resolution, you must provide detailed information about your issue. Review the following tips about the type of information to include in your support case for issues with DNS Services.\n\nProvide the following details:\n\n\n\n1. The specific IDs of affected VPCs.\n2. The IDs of the DNS Services private resource records (if any).\n3. The IDs of zones that have affected private resource records (if any).\n4. The DNS queries made. If possible, give the details on DNS queries related to the issue, including DNS message ID and timestamp for each.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-gettinghelp"},{"document_id":"ibmcld_10771-0-1225","score":17.8706124196,"text":"\n\n\n\n\n\n\n  Getting help and support \n\nIf you have problems or questions about IBM Cloud\u00ae Functions, you can get help by joining the IBM Cloud\u00ae Functions community in Slack, asking questions through a forum, or opening an IBM Cloud support case.\n\n\n\n*  To see whether IBM Cloud is available, [check the IBM Cloud status page](https:\/\/cloud.ibm.com\/status?selected=status).\n*  Review the forums to see whether other users ran into the same issue. When you use the forums to ask a question, tag your question so that it is seen by the IBM Cloud development teams.\n\n\n\n*  If you have technical questions about developing functions with IBM Cloud\u00ae Functions, post your question on [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud-functions) and tag your question with ibm-cloud-functions.\n\n\n\n*  See [Getting help](https:\/\/cloud.ibm.com\/docs\/get-support) for more details about using the forums.\n*  Contact IBM Support by opening a case. To learn about opening an IBM support case, or about support levels and case severities, see [Contacting support](https:\/\/cloud.ibm.com\/docs\/get-support).\n\n\n\nWhen you report an issue, include your activation ID. To get an activation ID, run ibmcloud fn activation list.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-gettinghelp"},{"document_id":"ibmcld_00041-7-1878","score":17.8623712539,"text":"\nGetting help and support for IBM Analytics Engine \n\nIf you experience an issue or have questions when using IBM Analytics Engine, you can use the following resources before you open a support case.\n\n\n\n* Review the [FAQs](https:\/\/test.cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-faqs-serverless) in the product documentation.\n* Review the [troubleshooting documentation](https:\/\/test.cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-troubleshooting-serverless) to troubleshoot and resolve common issues.\n* Check the status of the IBM Cloud platform and resources by going to the [Status page](https:\/\/cloud.ibm.com\/status).\n* Review [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud) to see whether other users experienced the same problem. When you ask a question, tag the question with ibm-cloud and service-Name, so that it's seen by the IBM Cloud development teams.\n\n\n\nIf you still can't resolve the problem, you can open a support case. For more information, see [Creating support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case). And, if you're looking to provide feedback, see [Submitting feedback](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-feedback).\n\n\n\n Providing support case details \n\nTo ensure that the support team can start investigating your case to provide a timely resolution, you must include detailed information along with steps to re-create the issue, if applicable. Review the following types of information to include in your support case for issues with IBM Analytics Engine.\n\n\n\n* The INSTANCE_ID for which the issue occured. For more information about retrieving the INSTANCE_ID, see [Retrieving details of a serverless instance](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-instance-details)\n* The APPLICATION_ID for which the issue occured.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-help-and-support"},{"document_id":"ibmcld_08052-7-2152","score":17.8481823046,"text":"\nCustomer Incident Report \n\nIBM Cloud\u00ae works hard to maintain high availability of infrastructure and cloud services. If you're impacted by any event that disrupts your service delivery, a Customer Incident Report (CIR) can be provided. A CIR provides information about how services are impacted and how an issue is getting resolved.\n\nAfter you create a support case, you can view updates about your impacting event from the Manage cases page. For more information, see [Managing your support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-managing-support-cases). If the scope of an impacting event is of a larger enterprise-wide scope, a CIR is provided upon request.\n\n\n\n Details about the Customer Incident Report (CIR) \n\nA CIR is provided for larger, enterprise-level issues. They are updates that provide a Root Cause Analysis (RCA) which is the process for determining the underlying cause of a Customer Impacting Event (CIE). Smaller issues that don't affect IBM Cloud at an enterprise level don't provide an RCA or CIR. The Advanced Customer Support (ACS) team that mitigates the issue still provides updates, but they're not a formal RCA.\n\nLarger enterprise-wide issues are events that typically impact multiple user environments or regions. Due to the scope and impact of enterprise issues, IBM Cloud requires a thorough RCA and the CIR is a summary report for the findings of the investigation.\n\nRCA investigations are complex and involve program review, feedback from product specialists, multiple inter-related cloud services, and vendor discussions. If the CIR can't be delivered within the Service Level Objective (SLO), an interim CIR is provided within the five business day SLO. For more information about SLO, see [Case severity and initial response times](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-case-severity).\n\nThe CIR is a point-in-time document that is intended to convey a specific set of information about an impacting incident. The interim CIR document provides the current findings of the ongoing RCA, the next investigative steps, and a timeline for the next expected update.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-cir"},{"document_id":"ibmcld_03839-5438-7096","score":17.8430003103,"text":"\nEnsure that the ticket severity is assigned based on the published criteria that is defined in [Case severity and response times](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-case-severity). For more information, see [IBM Cloud support plan offerings](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-planssupport-plans).\n* If you do not purchase support, your IBM Cloud Pay-As-You-Go or Subscription account comes with a free Basic Support plan. In this case, your support case is automatically registered as Sev-4.\n\n\n\nBefore you open a support ticket, you need to [gather your logs](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-manage-consoleibp-console-manage-logs).\n\nFollow these steps to submit a support case.\n\n\n\n1. Log in to [IBM Cloud Service Portal](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) with your IBM ID.\n2. Under Need more help? on the right of the page, click Create a Case.\n3. Fill the Create Case form with your information at least for the following fields.\n\n\n\n* Choose Technical as your case type.\n* In the Category drop-down list, select Blockchain.\n* In the Subject field enter a summary of your issue.\n* In the Description field, describe your issue.\n* Attach any relevant logs or files to demonstrate your issue.\n* Click Email me updates to receive updates on the status of the ticket.\n\n\n\n4. Click the Submit button. You will receive an email notification in a few minutes for this case.\n\n\n\nYou can find your previously submitted cases by clicking My Cases in the IBM Cloud Service Portal. Click and open a case to check its status or provide additional information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-blockchain-support"},{"document_id":"ibmcld_02604-7-2037","score":17.7863961648,"text":"\nUsing the Support Center \n\nNeed help with your API Connect service instance? Visit the IBM Cloud [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) to file a case.\n\n\n\n1. On the Support Center page, look in the \"Contact support\" section and click Create a case.\n2. On the Create a Case page, look in the \"Services\" list and click API Connect.\n\nIt's important to create your case with the correct service so that IBM Support can track the case and assign the appropriate people to help you. The list of services depends on your IBM Cloud account. If you don't see API Connect in the \"Services\" list, you can locate it as follows:\n\n\n\n* Locate the \"What do you need help with?\" section.\n* Review the text in that section and click the view all services link.\n* In the complete list of services, locate API Connect and click it (services are listed in alphabetic order).\n\n\n\n3. Describe your problem.\n\nUse the fields on the \"Create a Case\" page to explain your problem. The following list describes important information that assists us with resolving issues that you are having in API Connect.\n\nImportant: Do not include your private key in the support request.\n\n\n\n* For all issues, include the following information:\n\n\n\n* Region and customer service instance impacted\n* Component impacted: API Manager, API calls, Portal\n* URL where error is being seen\n* For Dedicated, identify the customer environment\n* For Reserved plan, use a prefix in the Subject field to indicate the version (such as v5, v2018 or v10) and provider-org. For example: [v10 - providerOrg].\n\n\n\n* For API Manager UI-based issues, additionally include:\n\n\n\n* All error codes returned\n* Time (including time zone) that the problem occurred\n\n\n\n* For Portal-based issues, additionally include the user name of person who encountered the problem\n* For issues with invoking APIs, additionally include:\n\n\n\n* Full API URL impacted - the host name should contain apiconnect.ibmcloud.com\n* HTTP method used\n* Frequency and time (with time zone) of the issue","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-get_help"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00512-1696-3972","score":18.0055686439,"text":"\nDocuments with similar document IDs are unlikely to be placed onto the same shard.\n\nA non-partitioned database offers only global querying, described in more detail later.\n\n\n\n\n\n Partitioned databases \n\nA partitioned database is the newest type of IBM Cloudant database. Within a partitioned database, documents are formed into logical partitions by use of a partition key. The partition key is part of the document ID for documents within a partitioned database. All documents are assigned to a partition, and many documents are typically given the same partition key. A partition's primary JSON data and its indexes end up colocated, meaning that the database can query data within a partition more efficiently.\n\nA partitioned database offers both partitioned and global querying. Partitioned querying takes advantage of the data layout within the database cluster to deliver improved and more scalable query performance. Partition queries are also often cheaper than global queries.\n\nAs partitioned databases offer the advantages of both global and partition querying, IBM Cloudant recommends that new applications take advantage of them.\n\n\n\n\n\n What makes a good partition key? \n\nIf you're thinking of using IBM Cloudant's new partitioned database feature, then the choice of a partition key is important. A partition key must have:\n\n\n\n* Many values - lots of small partitions are better than a few large ones. A million partitions are perfectly fine, but keep each partition under 10 GB in total size.\n* No hot spots - avoid designing a system that makes one partition handle a high proportion of the workload. If the work is evenly distributed around the partitions, the database performs more smoothly.\n* Repeating - If each partition key is unique, one document per partition exists. To get the best out of partitioned databases, multiple documents per partition must exist - documents that logically belong together.\n\n\n\nLet's look at some use cases and some good and bad choices for a partition key.\n\n\n\nTable 1. Good and bad choices for a partition key\n\n Use Case Description Partition Key Effectiveness \n\n E-commerce system - orders One document per order order_id Neutral - one document per partition is fine, but it doesn't provide the benefits of Partition Queries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_00513-7-2197","score":17.3768074438,"text":"\nDatabase overview \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases contain JSON objects. These JSON objects are called [documents](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-documentsdocuments).\n\nAll documents must be contained in a database. For more information, see [partitioned databases](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-databasespartitioned-databases-database).\n\nThe [Grouping related documents together in IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-grouping-related-documents-together-in-ibm-cloudantgrouping-related-documents-together-in-ibm-cloudant) guide provides an example of how documents for an e-commerce application might be used within an IBM Cloudant database.\n\n\n\n Partitioned databases \n\nIBM Cloudant supports two types of databases:\n\n\n\n* Partitioned\n* Nonpartitioned\n\n\n\nA partitioned database offers significant query performance and cost advantages but requires you to specify a logical partitioning of your data. The partitioning is specified as part of each document's ID. A partitioned database provides both global and partition queries. Partition queries target queries at a single, given document partition, meaning they need to process less data to return results. Therefore, partition queries offer significant performance advantages, and also often provide cost advantages over global queries. Global queries target the entire database, which leads to extra complexity, slower performance, and increased cost, but offers results that draw from all data.\n\nAlternatively, a nonpartitioned database might be created. This type of database can be less complex to work with since no partitioning scheme needs to be defined, but you can create only global secondary indexes.\n\nIBM Cloudant strongly encourages you to use a partitioned database for best long-term database performance where the data model allows for logical partitioning of documents.\n\nThe partitioning type of a database is set at database creation time. When you create a database, use the partitioned query string parameter to set whether the database is partitioned. The default for partitioned is false, maintaining compatibility with an earlier version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-databases"},{"document_id":"ibmcld_00512-7-2158","score":16.7040682363,"text":"\nDatabase partitioning \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae supports two types of databases:\n\n\n\n* Partitioned\n* Non-partitioned\n\n\n\nA partitioned database offers significant performance and cost advantages but requires you to specify a logical partitioning of your data. This process is described more in the following text.\n\nAlternatively, you can create a non-partitioned database. This type of database might be easier to work with as no partitioning scheme needs to be defined, but only global secondary indexes can be created.\n\nIBM Cloudant strongly recommends that you use a partitioned database for best long-term database performance where the data model allows for logical partitioning of documents.\n\nYou can decide whether to partition at database creation time. When you create a database, use the partitioned query string parameter to set whether the database is partitioned. The default for partitioned is false, maintaining compatibility with an earlier version.\n\nThe partitioning type can't be changed for an existing database.\n\n\n\n Database shards \n\nBefore you read this document, you must understand the [sharding concept](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-is-data-stored-in-ibm-cloudant-how-is-data-stored-in-ibm-cloudant-) within IBM Cloudant.\n\n\n\n\n\n Non-partitioned databases \n\nA non-partitioned database is the older type of IBM Cloudant database, and the one that is familiar if you used CouchDB or IBM Cloudant previously.\n\nWithin a non-partitioned database, documents are distributed to shards in an arbitrary manner based on a transformation of their document ID. Therefore, no real relation exists between a document's ID and the shard it ends up on. Documents with similar document IDs are unlikely to be placed onto the same shard.\n\nA non-partitioned database offers only global querying, described in more detail later.\n\n\n\n\n\n Partitioned databases \n\nA partitioned database is the newest type of IBM Cloudant database. Within a partitioned database, documents are formed into logical partitions by use of a partition key. The partition key is part of the document ID for documents within a partitioned database.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_00576-7385-9302","score":14.9856944927,"text":"\nIBM Cloudant doesn't have the concept of joins like a relational database, so data isn't normalized. However, data can repeat across objects. For example, an order document can include a subset of the product documents that were purchased.\n\nIt's common to store several object types in the same database: a convention is that a type attribute is used to denote the object type. This option is a good one if you need to perform queries that return several object types or if a database needs to be replicated to another location altogether. Otherwise, separate databases, for example, users, orders, products, might be better so that secondary indexes are specific to each object type.\n\nIf you're storing arrays of objects within a document, consider whether the array items must really be their own document. For example, a product and each product review must be stored in separate documents, but a user and each of that user's orders must have their own document.\n\nIf you have an ever-growing data set, then you probably don't want to store data in a single, ever-growing database. Data is best stored in time-boxed databases that allow older data to be archived and deleted cleanly. Deleting an IBM Cloudant document leaves a tombstone document behind, so don't rely on deleting documents to recover disk space. Instead, you must rely on deleting whole databases.\n\nJSON doesn't offer a native way to store dates or timestamps. Choose your [date format](https:\/\/blog.cloudant.com\/2018\/05\/24\/Date-formats.html) carefully if you intend to query it later.\n\nThe maximum document size is 1 MB, but documents must be much smaller than that size, typically a few KB.\n\nFor more information, see the following blog posts:\n\n\n\n* [Optimal IBM Cloudant Indexing](https:\/\/blog.cloudant.com\/2019\/05\/10\/Optimal-Cloudant-Indexing.html)\n* [Time-series Data Storage](https:\/\/blog.cloudant.com\/2019\/04\/08\/Time-series-data-storage.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basics"},{"document_id":"ibmcld_00580-20968-23077","score":14.9061645749,"text":"\nTo open an IBM Cloudant service's Dashboard, log in to IBM Cloud, find your IBM Cloudant service, and click Launch IBM Cloudant Dashboard button. A new window opens, logging you into your IBM Cloudant Dashboard.\n\nIf you leave the dashboard window unattended for a length of time, you find yourself logged out (for security purposes) and must click Launch again.\n\nThe dashboard has a number of tabs. Its default tab, Databases, lists the databases that you created in groups of 20. Each database is shown with the number of documents that it is storing and how much disk space is being used. Click a database name to examine its contents.\n\nTo create a database, click Create Database and supply the name of the database to create.\n\nWe now have a new empty database. The database's documents would be listed here in ID order. However, since this database is new, no documents exist. To add a document, click Create Document.\n\nThe IBM Cloudant Dashboard created a template document for you with a pre-generated _id. Complete the rest of the attributes yourself to complete the JSON document, and click Create Document to save.\n\nNow it's time for another practical exercise. Create a database called books, and in that database, create three or more documents with fields: title, author, date, publisher, and ISBN - each representing a book of your choice.\n\nOnce created, edit one of the documents, modifying the publication date.\n\nThen, delete one of the documents.\n\nTo summarize, the IBM Cloudant Dashboard is a web app that is built into the IBM Cloudant service and is part of the CouchDB open source offering. It is used to manage databases, documents, indexes, queries, and replication jobs. It can also be used to monitor service throughput. The Dashboard is simply an API client - anything that can be achieved with the dashboard can be scripted by you using the HTTP API.\n\nThat's the end of this part. The next part is called HTTP API Basics.\n\n\n\n\n\n\n\n HTTP API Basics video \n\nLearn how to use the command line to make HTTP requests and to add, edit, and delete documents.\n\n\n\n* HTTP API Basics video script","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00589-25445-26913","score":14.6332467909,"text":"\nGET \/$DATABASE\/_design\/$DOCUMENT_ID\/_search_disk_size\/$FURTHER_PATH_PARTS cloudantnosqldb.any-document.read \n GET \/$DATABASE\/_design\/$DOCUMENT_ID\/_search_info\/$FURTHER_PATH_PARTS cloudantnosqldb.any-document.read \n GET\/HEAD \/$DATABASE\/_index\/$FURTHER_PATH_PARTS cloudantnosqldb.any-document.read \n GET \/$DATABASE\/_design_docs cloudantnosqldb.any-document.read \n GET \/$DATABASE\/_design\/$DOCUMENT_ID cloudantnosqldb.any-document.read \n GET\/HEAD \/$DATABASE\/_design\/$DOCUMENT_ID\/$ATTACHMENT cloudantnosqldb.any-document.read \n PUT \/$DATABASE\/_design\/$DOCUMENT_ID cloudantnosqldb.design-document.write \n COPY \/$DATABASE\/_design\/$DOCUMENT_ID cloudantnosqldb.design-document.write \n DELETE \/$DATABASE\/_design\/$DOCUMENT_ID cloudantnosqldb.design-document.write \n PUT \/$DATABASE\/_design\/$DOCUMENT_ID\/$ATTACHMENT cloudantnosqldb.design-document.write \n DELETE \/$DATABASE\/_design\/$DOCUMENT_ID\/$ATTACHMENT cloudantnosqldb.design-document.write \n POST\/DELETE \/$DATABASE\/_index\/$FURTHER_PATH_PARTS cloudantnosqldb.design-document.write \n GET\/HEAD \/$DATABASE\/_security cloudantnosqldb.database-security.read \n PUT \/$DATABASE\/_security cloudantnosqldb.database-security.write \n GET\/HEAD \/$DATABASE\/_shards cloudantnosqldb.database-shards.read \n COPY (Depends on write document type.) \/$DATABASE\/$DOCUMENT_ID cloudantnosqldb.any-document.read + cloudantnosqldb.design-document.write either or both cloudantnosqldb.local-document.write either or both cloudantnosqldb.data-document.write","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant"},{"document_id":"ibmcld_00612-7-2163","score":14.4867081201,"text":"\nMigration overview \n\nThe [IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae](https:\/\/www.ibm.com\/cloud\/cloudant) database-as-a-service offering is a JSON document store that runs on multi-tenant clusters. The service is available with a choice of geographical locations with predictable costs, scalability, and a service-level agreement (SLA).\n\nYou can migrate to an IBM Cloudant Lite or Standard plan instance on IBM Cloud from one of the following plans:\n\n\n\nTable 1. IBM Cloudant migration paths\n\n Plan Description \n\n IBM Cloudant Enterprise Dedicated, single-tenant clusters \n Apache CouchDB The self-hosted, open source database on which IBM Cloudant is based. \n\n\n\n\n\n Benefits of the IBM Cloudant Lite and Standard plans \n\nWith the Standard plan, you can reserve throughput capacity for your database service, that is, to specify how much throughput your application's database is going to need to handle demand. The Standard plan also charges for the amount of storage you use. Capacity is measured with the following metrics:\n\n\n\nTable 2. Capacity metrics\n\n Metric Description \n\n Reads per second The rate when simple document fetches are performed, for example, retrieving a document by its _id, or querying against a partitioned database that uses a partition key. \n Writes per second The rate when data is written to the database. API calls dealing with document creation, update, or deletion count as \"writes\". \n Global Queries per second The rate when the database is queried by global indices, typically by accessing the _find endpoint, secondary MapReduce, or search indices. \n Storage The amount of disk space occupied by your JSON data, attachments, and secondary indices. \n\n\n\nAs an example, the Lite plan offers 20 reads per second, 10 writes per second, 5 global queries per second, and 1 GB of storage for free. This plan is ideal when you're evaluating the product and during product development. When your application goes into QA or production, switch to the Standard plan to scale the instance. The Standard plan's smallest capacity has 100 reads per second, 50 writes per second, 5 global queries per second, and 20 GB of storage for USD$76.65 per month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-to-ibm-cloudant-on-ibm-cloud"},{"document_id":"ibmcld_06633-1299-3259","score":14.4802058108,"text":"\nYou can extend high-availability further by adding [PostgreSQL members](https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-horizontal-scaling) to the instance, for greater in-region redundancy, or by provisioning [read-only replicas](https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-read-only-replicas) for cross-regional failover or read offloading.\n\nDatabases for PostgreSQL is designed and built to provide a robust, resilient, and performant Database as a Service offering. Review the PostgreSQL documentation on [replication techniques](https:\/\/www.postgresql.org\/docs\/current\/wal-async-commit.html) to understand the constraints and tradeoffs that are associated with the asynchronous replication strategy that is deployed by default with Databases for PostgreSQL.\n\nIn scenarios where a database becomes critically unhealthy, such as a server crash on the leader, Databases for PostgreSQL attempts a failover. This auto failover capability is capped at 16 MB of data lag from leader to follower (a few rows of data once accounting for more PostgreSQL data overhead) and is not performed if the lag threshold is exceeded. If the potential for 16 MB of data loss is intolerable for the application, horizontally scale your Databases for PostgreSQL instance to three members and configure Databases for PostgreSQL to use a synchronous replication strategy on a per user or per database basis.\n\n\n\n Synchronous replication \n\nBy default, streaming replication is asynchronous. If the primary server crashes, some transactions that were committed might not have been replicated to the standby server, causing data loss. Cloud Databases ensures that data loss is kept to a minimum substantial data loss; however, synchronous replication offers the ability to confirm that all changes were made by a transaction have been transferred to a synchronous member, ensuring consistency across a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-high-availability"},{"document_id":"ibmcld_00550-7-2005","score":14.4731913165,"text":"\nGrouping related documents together in IBM Cloudant \n\nTraditionally, e-commerce systems are built with relational databases. These databases typically use a number of tables joined to record sales, customer details, purchased products, and delivery tracking information.\n\nRelational databases offer high consistency, which means that application developers can build their applications to a database's strengths. This practice includes joins between collections, enumerations to record the state of an object, and database transactions to guarantee atomic operations.\n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae favors availability over consistency. It's a high-availability, fault-tolerant, distributed database that is eventually consistent. A distributed database means the customer's shopping service is always available and scalable enough to cope with many users who make purchases at the same time. With that in mind, your application can leverage IBM Cloudant's strengths and not treat it like a relational database.\n\nThis discussion outlines some of the factors that are involved in building an e-commerce system that takes advantage of IBM Cloudant's strengths. IBM Cloudant uses concepts that are applicable to many other domains, such as:\n\n\n\n* Using multiple documents to represent the state of a purchase, rather than frequently updating a single document.\n* Storing copies of related objects in order instead of joining to another collection.\n* Creating views to collate documents by order_id to reflect the current state of a purchase.\n\n\n\nFor example, you might create a purchase document that includes details such as the items ordered, customer information, cost, and delivery information.\n\nSee the following example document that describes a purchase:\n\n{\n\"_id\": \"023f7a21dbe8a4177a2816e4ad1ea27e\",\n\"type\": \"purchase\",\n\"order_id\": \"320afa89017426b994162ab004ce3383\",\n\"basket\": [\n{\n\"product_id\": \"A56\",\n\"title\": \"Adele - 25\",\n\"category\": \"Audio CD\",\n\"price\": 8.33,\n\"tax\": 0.2,\n\"quantity\": 2\n},\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-grouping-related-documents-together-in-ibm-cloudant"},{"document_id":"ibmcld_09521-7-2114","score":14.2927608813,"text":"\nLimitations & Exclusions \n\nMaximo Application Suite SaaS is implemented using a defined set of technologies and operates within a security profile designed to ensure our client's data is secure and the applications operate efficiently and effectively. As a result of the decisions made regarding technologies and to meet the high security standards, there are differences between what is available using the Managed Services and what a client could do if they hosted and operated the Suite themselves.\n\nThe following items are not included or allowed in the Maximo Application Suite SaaS offering:\n\n\n\n Databases \n\nThe following are database limitations of the MAS-SaaS offering:\n\n\n\n* Only IBM DB2 Warehouse is supported. Oracle and SQLServer are not supported. Conversion services are available.\n* If converting from Oracle to DB2, Oracle compatibility mode is not supported.\n* Customers are not allowed direct access to MAS-SaaS database(s). If direct database access is needed, customer should look into the [MAS-Dedicated](https:\/\/cloud.ibm.com\/docs\/mas-ms) offering.\n* DB2 Text Search is not supported.\n* Running SQL statements (update\/insert\/delete) directly on the database is not allowed and IBM SRE team will not be able to execute those statements for you. DBC scripts are not allowed. Customers should carry out these changes using the Maximo UI via [Automation Scripts](https:\/\/ibm-maximo-dev.github.io\/maximo-autoscript-documentation\/introduction\/whatisautoscript) or the [Maximo Integration Framework](https:\/\/www.ibm.com\/docs\/en\/maximo-ora-con\/8.1.0?topic=architecture-maximo-integration-framework-overview).\n\n\n\n\n\n\n\n Java Extensions \n\nJava extensions are not supported. Maximo Manage [Automation Scripting](https:\/\/ibm-maximo-dev.github.io\/maximo-autoscript-documentation\/introduction\/whatisautoscript) capability should instead be used. Existing Maximo customers who have Java extensions will need to migrate \/ convert these functions into automation scripts within the application.\n\n\n\n\n\n 3rd Party Applications \n\nMaximo Application Suite SaaS will not host or support 3rd party applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-saas?topic=mas-saas-limitations-exclusions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3868528072,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.3868528072}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07028-8585-10420","score":25.0222492333,"text":"\nTo add an advanced rule model, complete the following steps:\n\n\n\n1. Create the model and export the ZIP file that contains the model resources.\n\nFor more information about how to export the model, see the instructions for your model source:\n\n\n\n* [Knowledge Studio for IBM Cloud Pak\u00ae for Data](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-create-advanced-rules-model)\n* [Knowledge Studio for IBM Cloud](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-create-advanced-rules-model)\n* [Open source NLP Editor](https:\/\/github.com\/CODAIT\/nlp-editor)\n\n\n\n2. From the Teach domain concepts section of the Improvement tools panel, choose Advanced rules model.\n3. Click Upload.\n4. Specify a name for the model, and then choose the language that was used to define the model.\n5. Specify a name for the result field, which is the field in the index where the output of this enrichment will be stored.\n6. Click Upload to browse for the ZIP file that you exported earlier.\n7. Click Create.\n8. Choose the collection and field where you want to apply the enrichments from the model, and then click Apply.\n\n\n\n\n\n\n\n Output format for advanced rules \n\nKnowledge Studio uses the Annotation Query Language (AQL) to define the rules in an advanced rules model. Each model is defined by one or more views. Each view is a relational data structure that contains multiple data records. Each record is composed of values in columns that are defined by the view\u2019s schema. To facilitate representing these models, which are custom and therefore have various schemas, a uniform JSON output schema is used.\n\n\n\n* Each JSON object represents an Annotation Query Language (AQL) view.\n* The name-and-value pairs in the JSON objects represent the names and values of the attributes in the view.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-domain-ml"},{"document_id":"ibmcld_07046-11817-13746","score":23.6120675331,"text":"\nHowever, a different document ID was assigned to it and stored in the parent_document_id field. The assigned document ID is what was returned when you called the List documents method and is what had to be used as the document_id in the endpoint URL for a Delete document method request. When you used the Update document method to assign a new document_id, the original ID continued to be returned in query results. However, the assigned ID had to be used to delete the document. If you have an application that relies on the previous behavior, you can specify a version number earlier than 2023-03-31, such as 2020-08-30, in your API calls.\n\n\n\nNotes about enhancing data:\n\n\n\n* You cannot apply prebuilt or user-trained Smart Document Understanding models to JSON files.\n* When you apply an enrichment to a field from the JSON file, the field data type is converted to an array. The field is converted to an array even if it contains a single value. For example, \"field1\": \"Discovery\" becomes \"field1\": [\"Discovery\"].\n* Only the first 50,000 characters of a custom field from a JSON file are enriched.\n* In project types where the Part of Speech (POS) enrichment is applied automatically, the enrichment is applied to the field that contains the bulk of the file content in the first JSON file that is added to the collection. This field is determined by the following rules:\n\n\n\n* If a field is named text, the POS enrichment is applied to it.\n* The field with the longest string value and highest number of distinct values is chosen.\n* If more than one field meets the previous condition, one of the fields is chosen at random.\n\n\n\n* If you want to apply an enrichment to a nested field, you must create a Content Mining project, and then apply the enrichment to the field. If you want to use a project type other than Content Mining, you can reuse the collection that you created with the Content Mining project type elsewhere.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-index-overview"},{"document_id":"ibmcld_07019-8403-10537","score":23.0439673934,"text":"\nOn the Improvement tools panel, expand Teach domain concepts, and then choose the resource that you want to add.\n\nAfter you create the resource, it becomes a new type of enrichment that you can apply to your data.\n3. Specify the collection and field in which to apply the enrichment.\n\nYou can apply enrichments to the text and html fields, and to custom fields that were added from uploaded JSON or CSV files or from the Smart Document Understanding (SDU) tool. Only the first 50,000 characters of a custom field from a JSON file are enriched.\n\nFor example, if you add a dictionary and choose to apply it to the text field of a collection, the documents in the collection are reprocessed. If the term vehicle is specified as a synonym of the car dictionary entry and occurs in the document text, vehicle is tagged as a mention of the car dictionary entry type. If a customer later searches for car, the passage that contains the vehicle mention is included in the search results.\n\nIf the field that you choose comes from a JSON file, after you apply the enrichment, the field data type is converted to an array. The field is converted to an array even if it contains a single value. For example, \"field1\": \"Discovery\" becomes \"field1\": [\"Discovery\"].\n\n\n\nYou can choose to apply resource-derived enrichments to your data later. Enrichments that you add to a project are available for use from any collection in the project. Go to the Manage collections page, choose the collection where you want to apply the enrichment, and then open the Enrichments tab. Make sure the status of the enrichment shows that it is Ready, and then apply the enrichment to a field in the collection. Enrichments that you enable are applied to the documents in random order. For more information, see [Managing enrichments](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-manage-enrichments).\n\nFrom the deployed Content Mining application, you can create a classifier or a custom annotator from a dictionary, regular expression, machine learning, or PEAR file and use it as an enrichment in collections that are stored in other project types.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-domain"},{"document_id":"ibmcld_13493-1220-3010","score":22.9527026552,"text":"\n* If the format of the input objects is CSV and a delimiter other than the default , (comma) is used, you must specify the delimiter by using the FIELDS TERMINATED BY option of the [STORED AS](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause. All single Unicode characters are allowed as delimiters.\n* By default, it is assumed that CSV input objects have a header line that specifies the names of the input columns. If the objects don't have a header line, you must specify NOHEADER in the [STORED AS](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause.\n* By default, it is assumed that JSON input objects consist of a single JSON record per line. If individual records span multiple lines, you must specify MULTILINE in the [STORED AS](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause.\n* If required, you can use JOIN constructs to join data from several input URIs, even if those URIs point to different instances of Cloud Object Storage.\n* Use the INTO clause of a [query](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencechapterSQLQueryStatement) to specify the output [URI](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-runningunique), that is, the location to which the result is to be written and the wanted result format.\n\n\n\n2. The Target location field displays where the result is stored. An initial bucket in one of your Object Storage instances is automatically created for you when you open the UI. It is then chosen as your default location, if your query does not specify an INTO clause. To ensure the automatic setup of an initial bucket, do the following steps in advance:\n\n\n\n* You must create an Object Storage instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-running"},{"document_id":"ibmcld_03893-39361-41102","score":22.9060288329,"text":"\n\"format\": \"%{color}%{time:2006-01-02 15:04:05.000 MST} [%{module}] %{shortfunc} -> %{level:.4s} %{id:03x}%{color:reset} %{message}\"\n}\n},\n\"metrics\": {\n\"provider\": \"disabled\",\n\"statsd\": {\n\"network\": \"udp\",\n\"address\": \"127.0.0.1:8125\",\n\"writeInterval\": \"10s\",\n\"prefix\": null\n}\n}\n}\nShow more\n\n\n\n\n\n Providing your own customizations when you create a peer \n\nAfter you click Create a peer on the nodes tab and step through the peer configuration panels, you can click Edit configuration on the Summary panel to view and edit the JSON. Note that if you do not select any advanced options in the console, then the generated JSON is empty, but you can still insert your own customizations.\n\nAlternatively, if you do check any of the advanced options when you configure the peer, those settings are included in the JSON on the Summary panel and can be additionally customized with other fields as needed. Any edits that you make will override what was specified in the console. For example, if you selected to use a LevelDB as the state database, but then overrode the setting to use CouchDB as the state database in the JSON, then the CouchDB database settings would be used when the peer is deployed. The override settings that are visible in the JSON on the Summary page are what is used when the peer is deployed.\n\nYou don't need to include the entire set of available parameters in the JSON, only the advanced deployment options that you selected in the console along with the parameters that you want to override. For example, if you want to deploy a peer and override the chaincode startup timeout and specify a different port for the statsd address, you would paste in the following JSON:\n\n{\n\"peer\": {\n\"chaincode\": {\n\"startuptimeout\": \"600s\"\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deployment"},{"document_id":"ibmcld_03893-54294-56100","score":22.0627853825,"text":"\n\"BroadcastTraceDir\": null,\n\"DeliverTraceDir\": null\n},\n\"Metrics\": {\n\"Provider\": \"disabled\",\n\"Statsd\": {\n\"Network\": \"udp\",\n\"Address\": \"127.0.0.1:8125\",\n\"WriteInterval\": \"30s\",\n\"Prefix\": null\n}\n}\n}\nShow more\n\n\n\n\n\n Providing your own customizations when you create an ordering service \n\nAfter you click Add ordering service on the nodes tab and step through the ordering service configuration panels, you can click Edit configuration JSON on the Summary panel to view and edit the JSON. Note that if you do not select any advanced options in the console, then the generated JSON is empty, but you can insert your own customizations.\n\nAlternatively, if you do check any of the advanced options when you configure the ordering service, those settings are included in the JSON on the Summary panel. Any edits that you make to theJSON override what was specified in the console. You can insert additional fields or modify the generated JSON. The overrides that are visible in the JSON on the Summary page are what is used to override the default settings when the ordering node is deployed. If you are deploying multiple ordering nodes, then the overrides are applied to each ordering node.\n\nYou don't need to include the entire set of available parameters in the JSON, only any advanced deployment options that you selected in the console along with the parameters that you want to override. For example, if did not select any advanced options in the console and you want to deploy the ordering nodes with your own value for the ServerTimeout and the statsd address port, you would paste the following JSON into the Configuration JSON box:\n\n{\n\"General\": {\n\"Keepalive\": {\n\"ServerTimeout\": \"60s\"\n}\n},\n\"metrics\": {\n\"statsd\": {\n\"address\": \"127.0.0.1:9446\"\n}\n}\n}\n\n\n\n\n\n Modifying ordering node settings after deployment","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deployment"},{"document_id":"ibmcld_03893-23673-25002","score":21.6352259963,"text":"\n},\n\"metrics\": {\n\"provider\": \"prometheus\",\n\"statsd\": {\n\"network\": \"udp\",\n\"address\": \"127.0.0.1:8125\",\n\"writeInterval\": \"10s\",\n\"prefix\": \"server\"\n}\n}\n}\n}\nShow more\n\nPaste the modified JSON that contains only the parameters that you want to update into the Configuration JSON box. For example, if you only needed to update the value for the passwordattempts field you would paste in this JSON:\n\n{\n\"ca\": {\n\"cfg\": {\n\"identities\": {\n\"passwordattempts\": 3\n}\n}\n}\n}\n\nIf you need to enable deletion of registered users from a CA you would insert \"allowremove\": true into the JSON as follows:\n\n{\n\"ca\": {\n\"cfg\": {\n\"identities\": {\n\"passwordattempts\": 10,\n\"allowremove\": true\n}\n}\n}\n}\n\nThe ability to update a CA configuration is not available for CAs that have been imported into the console.\n\n\n\n\n\n\n\n\n\n Peer deployment \n\nWhen you deploy a peer, the following advanced deployment options are available:\n\n\n\n* [State database](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-level-couch) - Choose the database for your peers where ledger transactions are stored.\n* [Deployment zone selection](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-peer-k8s-zone) - In a multi-zone cluster, select the zone where the node is deployed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deployment"},{"document_id":"ibmcld_03893-40670-42257","score":21.3550809597,"text":"\nYou don't need to include the entire set of available parameters in the JSON, only the advanced deployment options that you selected in the console along with the parameters that you want to override. For example, if you want to deploy a peer and override the chaincode startup timeout and specify a different port for the statsd address, you would paste in the following JSON:\n\n{\n\"peer\": {\n\"chaincode\": {\n\"startuptimeout\": \"600s\"\n}\n},\n\"metrics\": {\n\"statsd\": {\n\"address\": \"127.0.0.1:9443\"\n}\n}\n}\n\n\n\n\n\n Modifying peer settings after deployment \n\nAfter a peer is deployed, a subset of the fields can be updated as well. Click the peer tile in the console and then the Settings icon to open a side panel. Click Edit configuration JSON (Advanced) to open the panel where you can override the peer settings. The JSON in the Current configuration box contains the current settings for the peer. Not all of these values can be overridden after the peer is deployed. A subset of these parameters can be overridden by pasting a JSON with the overrides into the Configuration JSON box. Again, you don't need to include the entire set of parameters from the Current configurationJSON, only paste the parameters you want to override into the Configuration JSON box.\n\nThe following subset of parameters can be overridden after a peer is deployed:\n\n{\n\"peer\": {\n\"id\": \"jdoe\",\n\"networkId\": \"dev\",\n\"keepalive\": {\n\"minInterval\": \"60s\",\n\"client\": {\n\"interval\": \"60s\",\n\"timeout\": \"20s\"\n},\n\"deliveryClient\": {\n\"interval\": \"60s\",\n\"timeout\": \"20s\"\n}\n},\n\"gossip\": {\n\"useLeaderElection\": true,\n\"orgLeader\": false,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deployment"},{"document_id":"ibmcld_12447-22464-24202","score":20.8257380732,"text":"\nA successful response returns the ID value for the secret, along with other metadata. For more information about the required and optional request parameters, check out the [API docs](https:\/\/cloud.ibm.com\/apidocs\/secrets-manager\/secrets-manager-v2update-secret).\n\n\n\n\n\n Rotating user credentials \n\nYou can rotate secrets by calling the Secrets Manager API.\n\nThe following example request creates a new version of your secret. When you call the API, replace the ID variables and IAM token with the values that are specific to your Secrets Manager instance.\n\nYou can store metadata that are relevant to the needs of your organization with the custom_metadata and version_custom_metadata request parameters. Values of the version_custom_metadata are returned only for the versions of a secret. The custom metadata of your secret is stored as all other metadata, for up to 50 versions, and you must not include confidential data.\n\ncurl -X POST -H \"Authorization: Bearer {iam_token}\" -H \"Accept: application\/json\" -H \"Content-Type: application\/json\" -d '{\n\"custom_metadata\": {\n\"metadata_custom_key\": \"metadata_custom_value\"\n},\n\"password\": \"new-password\",\n\"version_custom_metadata\": {\n\"custom_version_key\": \"custom_version_value\"\n}\n}' \n\"https:\/\/{instance_ID}.{region}.secrets-manager.appdomain.cloud\/api\/v2\/secrets\/{id}\/versions\"\n\nTo have the service generate and assign a random password to your credential, you can pass an empty string on the password field. For example, { \"password\": \"\"}. Secrets Manager replaces the existing value with a randomly generated 32-character password that contains uppercase letters, lowercase letters, digits, and symbols.\n\nA successful response returns the ID value for the secret, along with other metadata.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation&interface=ui"},{"document_id":"ibmcld_07067-29074-30687","score":20.3847779774,"text":"\n* In Discovery v2, the Entities v2 enrichment is used. Entity type names in v2 are specified in headline case, instead of all uppercase letters. If you use a query or aggregation that specifies an entity name, you must change the capitalization. For example, change PERSON to Person.\n* Fields from JSON files that are added to a collection are converted differently during ingestion between v1 and v2. If your application manipulates these results, you might need to make adjustments.\n\nYou can specify the normalizations and conversions objects in the [Update a collection](https:\/\/cloud.ibm.com\/apidocs\/discovery-dataupdatecollection) method of the API to move or merge JSON fields.\n\n\n\nHow JSON source fields are handled\n\n Original JSON field content v1 representation v2 representation Notes \n\n \"field\": null \"field\": null N\/A v1 retains the null value. v2 skips the null field altogether. \n \"field\": \"\" \"field\": \"\" N\/A v1 retains the empty text value. v2 skips the empty text field altogether. \n \"field\": \"value2\" \"field\": \"value2\" \"field\": \"value2\" No difference. \n \"field\": [] \"field\": [] N\/A v1 retains the empty array. v2 skips the field with the empty array altogether. \n \"field\": [ \"value4\" ] \"field\": [ \"value4\" ] \"field\": \"value4\" v1 retains the singleton array. v2 converts the singleton array into the value only; it is not stored as part of an array. \n \"field\": [ 1, 2, 3 ] \"field\": [ 1, 2, 3 ] \"field\": [ 1, 2, 3 ] No difference. \n \"field\": [ \"v6\", \"v7\", \"v8\" ] \"field\": [ \"v6\", \"v7\", \"v8\"] \"field\": [ \"v6\", \"v7\", \"v8\"] No difference. \n\n\n\n\n\n\n\n\n\n\n\n Verifying that your data was migrated successfully","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06968-15099-17180","score":27.061348737,"text":"\n[checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/icons\/checkmark-icon.svg) \n\n\n\n\n\n* PDF files that are secured with a password or certificate are not supported. Vector objects, including SVG images and vectorized text, are not supported. Only images of the supported image file types that occur in the PDF are rendered.\n* Only single-page image files are supported.\n* Files within compressed archive files (ZIP, GZIP, TAR) are extracted. Discovery ingests the supported file types within the archive; it ignores all other file types. The file names must be encoded in UTF-8. Files with names that include Japanese characters, for example, must be renamed before they are added to the ZIP file.\n* Discovery supports MacOS ZIP files only if they are generated by using a command such as: zip -r my-folder.zip my-folder -x \".DS_Store\". ZIP files that are created by right-clicking a folder and clicking Compress are not supported.\n* PDF files that you upload as part of an archive file are not displayed in the advanced view for a query result that you open from the Improve and customize page. If you want the file to be viewable from the advanced view, reimport the PDF file separately from the archive file.\n\n\n\nWhen you add files to a Document Retrieval for Contracts project type, any file types that support SDU and OCR are processed with a pretrained Smart Document Understanding model and Optical Character Recognition automatically.\n\n\n\n\n\n Document limits \n\nThe number of documents that are allowed per service instance depends on your Discovery plan type.\n\nThe document limit applies to the number of documents in the index. Upload fewer documents at the start if the enrichments that you plan to apply might increase the number of documents later. For example, the following configurations generate more documents:\n\n\n\n* Splitting documents segments one document into multiple documents\n* CSV files that you upload generate one document per line\n* Database data sources that you crawl produce one document per database row","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collections"},{"document_id":"ibmcld_16423-3286-5408","score":25.3002376454,"text":"\nUpload one CSV file at a time. The first column in the CSV file specifies the file name of the document. The second column in the file contains the document text. For an example of the required format, see the [documents-new.csv](https:\/\/watson-developer-cloud.github.io\/doc-tutorial-downloads\/knowledge-studio\/documents-new.csv) file in the tutorial sample files.\n\n\n\n\n\n PDF files \n\nText cannot be extracted from a PDF in some cases, depending on how the PDF was created. Typically, text can't be extracted from embedded fonts that don't map to unicode characters. If you are unsure whether text from a PDF can be extracted, you can try copying the text from the PDF and then pasting it into a text editor. If you do not see the same characters that are visible in the PDF itself, then the text extraction would likely fail.\n\n\n\n\n\n Formatted documents \n\nWhen formatted documents are converted to plain text, it's possible that losing the formatting could result in poor tokenization of words. For example, if a table row in a DOCX file contains cell values that do not end with a period, the values might be converted as one sentence. As another example, if a PDF document contains a very long word that is hyphenated at the end of a line, that word might be converted as two words. In cases like these, the documents might not be suitable for machine learning unless you pre-process the files to fix formatting limitations.\n\n\n\n\n\n Documents from another Watson Knowledge Studio workspace \n\nIf you previously downloaded documents from a Knowledge Studio workspace, you can upload the ZIP file that you downloaded. An option lets you specify whether you want the ground truth annotations to be included in the imported files.\n\nAfter documents are annotated, the annotated documents are stored in JSON format. The markup language in these files, which shows how the original document text was parsed and tokenized, includes elements for all of the annotations that a human annotator added. To improve model accuracy over time, you can upload these files into another workspace, thus preserving all of the existing annotations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotation"},{"document_id":"ibmcld_07117-1664-3943","score":25.2409163031,"text":"\nIf you encounter this issue, open the file in a more recent version of Microsoft Office and convert the file to the DOCX, PPTX, or XLSX format respectively, and then upload the DOCX, PPTX, or XLSX file.\n\nLine breaks are inserted randomly\n: When some files in Microsoft Office format are added to a collection, line breaks are inserted seemingly at random to the text that is stored in the html field in the collection's index. The unexpected line breaks can impact the efficiency of enrichments, such as custom rule recognition.\n\nCause: As part of their ingestion into Discovery, such files are converted from Office format to PDF format. When the conversion happens, textual content is sometimes lost due to the nature of a PDF file. While the new lines appear to be added at random, they typically get inserted in areas where text wraps in the original document, such as in narrow text boxes or to accommodate other inline elements, such as images or diagrams.\n\nSolution: To avoid new line insertions, increase the width of text boxes in the original document. If the original document has a section where text wraps to accommodate an inline element, such as an image, move the image so that it is situated in its own section and the nearby text doesn't need to wrap around it. To test whether your fixes address the issue, you can convert the original file to a PDF file to check for unexpected carriage returns in the text.\n\nAfter applying a pretrained Smart Document Understanding model to a PPT file, table boundaries are not recognized properly\n: During the conversion process, text that is extracted from the table is confused with text that is outside the table in some PPT pages. This issue is more likely to occur in tables with a lot of text and that have footnotes displayed just outside the table border. If you encounter this issue, export the PPT file as a PDF file, and then upload the PDF file instead. Apply a user-trained Smart Document Understanding (SDU) model to the document, and then use the SDU tool to identify the tables in the document. The resulting model handles table boundaries properly and can extract text from the tables cleanly.\n\n\n\n\n\n PDF file troubleshooting tips \n\nFailed to parse document due to invalid encoding\n: Enable OCR for the file.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-troubleshoot-ingestion"},{"document_id":"ibmcld_07232-1707-3805","score":24.4068215895,"text":"\nIf you crawl Box or Salesforce, a list of available resources is presented when you configure a source, using the Discovery tooling.\n* If you are using the Discovery tooling, you can configure a collection with a single data source.\n* Crawling a data source uses resources, namely API calls, of the data source. The number of API calls depends on the number of documents that need to be crawled. You must obtain an appropriate level of service license, for example Enterprise, for the data source. For information about the appropriate service level license that you need, contact the source system administrator.\n* Discovery source crawls do not delete documents that are stored in a collection, but you can manually delete them using the API. When a source is re-crawled, new documents are added, updated documents are modified to the current version, and deleted documents remain as the version last stored.\n* Discovery can only ingest the following file types, and it ignores all other document types:\n\n\n\n\n\n Lite plans Advanced plans \n\n PDF, Word, PowerPoint, Excel, JSON*, HTML* PDF, Word, PowerPoint, Excel, PNG**, TIFF**, JPG**, JSON*, HTML* \n\n\n\n* IBM Watson\u2122 Discovery supports crawling JSON and HTML documents, but you cannot edit these documents using the SDU editor. To change the configuration of HTML and JSON documents, you must use the API. For more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery\/).\n\n** Individual image files, such as PNG, TIFF, and JPG, are scanned, and any text is extracted. PNG, TIFF, and JPEG images embedded in PDF, Word, PowerPoint, and Excel files are also scanned, and any text is extracted.\n\nView the following table to see the objects that a data source can crawl and which data sources support crawling new and modified documents during a refresh:\n\n\n\nTable 1. Data sources that support crawling new and modified documents during refresh and objects that can be crawled\n\n Data source Crawls new and modified documents during refresh? Compatible objects that can be crawled \n\n Box (Application level access) No Files, folders","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sources"},{"document_id":"ibmcld_16358-7447-9162","score":23.2095648914,"text":"\nBefore we add anything to our new assistant, let's check on the status of our data.\n\n\n\n\n\n Step 5: Prepare your data for retrieval \n\nTo improve the retrievability of the information in your PDF files, you will split the PDF files into many smaller documents. To do so, you will first teach Discovery about the structure of your PDF files, so it understands how subsections are formatted and can split the document by subsection.\n\n\n\n1. Return to the web browser tab where your Discovery project is displayed.\n\nThe Improve and customize page for the last PDF file that you uploaded is displayed.\n2. From the Improvement tools panel, expand Define structure, and then click New fields.\n\nZoom\n\n![Shows the chat bot preview in a fake web page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/tut-neural-new-fields.png)\n\nFigure 5. Opening the tool for defining fields\n3. Choose the Discovery docs part 1 collection.\n\nThe Identify fields tab is displayed, where you can choose the type of Smart Document Understanding model that you want to use.\n4. Click User-trained models, and then click Submit.\n\nZoom\n\n![Shows the chat bot preview in a fake web page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/tut-neural-user-trained.png)\n\nFigure 6. Creating a user-trained model\n5. Click Apply changes and reprocess.\n\nAfter some processing occurs, a representation of the document is displayed in the Smart Document Understanding tool. The tool shows you a view of the original document along with a representation of the document, where the text is replaced by blocks. The blocks represent field types.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-tutorial-neuralseek"},{"document_id":"ibmcld_03054-7324-9318","score":22.4885483949,"text":"\nSelect the language of the files that you are adding to this collection.\n\nFor information about the languages supported by Discovery, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n\nIf you are uploading a PDF document and want to extract party, nature, and category information from it, then expand the Advanced section and click Use the Default Contract Configuration with this collection.\n\n\n\n2. Click Next.\n3. Click Select documents to upload documents.\n\nSupported file types include PDF, HTML, JSON, Word, Excel, PowerPoint, PNG, TIFF, JPG, GIF, TXT, CSV, ZIP, GZIP, and TAR\n\nNo ongoing synchronization of uploaded documents is available. If you want to pick up changes that are made to a document, upload a later version of the document.\n\n\n\n\n\n2. Wait for the collection to be fully ingested.\n\nYour collection is added to a project that is created for you automatically. The project is a conversational search project with a name like Untitled Project 3; its sole purpose is to store your data collection.\n3. Find the project name in the page breadcrumb after your collection is created. Make a note of the project name in case you want to return to the collection from the Discovery application later.\n4. 1.5.0 only: If you want to add another collection to the project, click Manage collections, and then click New collection to add another collection.\n5. When the project contains all of the data collections that you want to use, click Back to Watson Assistant to finish creating the search skill.\n6. Select the project you just created from the list of projects, and then click Configure.\n\n\n\n\n\n Data collection creation example \n\nFor example, you might have a JSON file like this one:\n\n{\n\"Title\": \"About\",\n\"Shortdesc\": \"IBM Watson Assistant is a cognitive bot that you can customize for your business needs, and deploy across multiple channels to bring help to your customers where and when they need it.\",\n\"Topics\": \"overview\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_07224-7-1998","score":22.1097889465,"text":"\nSmart Document Understanding \n\nSmart Document Understanding (SDU) trains IBM Watson\u2122 Discovery to extract custom fields in your documents. Customizing how your documents are indexed into Discovery improves the answers that your application returns.\n\nWith SDU, you annotate fields within your documents to train custom conversion models. As you annotate, Watson is learning and starts to predict annotations. SDU models can be exported and used on other collections.\n\nThis documentation applies to Discovery service instances that you create with a Lite or an Advanced plan, or that you created with a Premium plan before 16 July 2020. For more information about features in Premium plan instances created on or after 16 July 2020, and in Plus (including Plus Trial) plan instances, see [these docs](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-configuring-fields).\n\n\n\n Supported document types and browsers \n\nSupported document types for Smart Document Understanding:\n\n\n\n* Lite plans: PDF, Word, PowerPoint, Excel, JSON*, HTML*\n* Advanced plans: PDF, Word, PowerPoint, Excel, PNG**, TIFF**, JPG**, JSON*, HTML*\n\n\n\n* JSON and HTML documents are supported by IBM Watson\u2122 Discovery, but can not be edited using the SDU editor. To change the configuration of HTML and JSON docs, you need to use the API. For more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery\/).\n\n** Individual image files (PNG, TIFF, JPG) are scanned and the text (if any) is extracted. PNG, TIFF, and JPEG images embedded in PDF, Word, PowerPoint, and Excel files are also scanned and the text, if any, is extracted.\n\n\n\n\n\n Using the Smart Document Understanding editor \n\nThe SDU editor is only available for collections that contain supported document types and do not have the Element Classification enrichment applied. If you do not want to use the SDU editor, you can set up your configuration using the API, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sdu"},{"document_id":"ibmcld_06968-1711-4007","score":21.9414971824,"text":"\nThere a few things to consider as you decide how to break up your source content into collections.\n\n\n\n* Getting content from different data sources\n\nIf you store similar content in more than one type of data source (a website and Salesforce, for example), you can create one project with two separate collections. Each collection adds documents from a single data source. When they are built together into a single project, a user can search across both sources at the same time.\n* Applying enrichments\n\nCreating a collection is a good way to group documents that you want to enrich in a similar way. For example, maybe a subset of your documents contains industry jargon and you want to add a dictionary that recognizes the terms. You can create a separate collection and apply the Parts of Speech enrichment so you can use the term suggestions feature to speed up the process of creating the dictionary.\n* Creating separate Smart Document Understanding (SDU) models\n\nYou can use the Smart Document Understanding tool to identify content based on the structure of a document. If you have 20 PDF files that were created by your Sales department and use one template and 20 PDF files that were created by your Research department and use a different template, group each set into its own collection. You can then use the SDU tool to build a model for each structure separately, a model that understands the unique structure. You can also use the tool to define custom fields that are unique to the source documents.\n\n\n\n\n\n\n\n Creating a collection \n\nBefore you can create a collection, you must create a project. For more information, see [Creating projects](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-projects).\n\nThings to keep in mind:\n\n\n\n* A collection can support only one external data source.\n* Documents in the collection must be in one language only, the language that you specify for the collection.\n\n\n\nTo create a collection, complete the following steps:\n\n\n\n1. Open a project, go to the Manage collections page, and then click New collection.\n\n\n\n* The Conversational Search, Document Retrieval, and Custom project types can contain up to 5 collections.\n* A Content Mining project can contain only 1 collection.\n\n\n\n2. Choose how you want to add data to your collection.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collections"},{"document_id":"ibmcld_07140-2710-4310","score":21.8948641236,"text":"\n* HTML files are converted to JSON using the html options, and the resulting JSON is converted using the json options.\n* JSON files are converted using the json options.\n\n\n\nIf you configure your collection using [Smart Document Understanding](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sdu), the PDF and Word conversion settings listed are not used, so changing these conversion settings are ignored.\n\nThese options are described in the following sections. After conversion completes, [enrichment](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configrefenrichment) and [normalization](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configrefnormalization) are performed before the content is stored.\n\n\n\n PDF \n\nIf you configure your collection using [Smart Document Understanding](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sdu), the PDF and Word conversion settings listed are not used, so changing these conversion settings are ignored.\n\nThe pdf conversion object defines the conversion from PDF to HTML and has the following structure:\n\n\"pdf\": {\n\"heading\": {\n\"fonts\": [\n{\n\"level\": 1,\n\"min_size\": 24,\n\"max_size\": 80,\n\"bold\": false,\n\"italic\": true,\n\"name\": \"arial\"\n},\n{\n\"level\": 2,\n\"min_size\": 18,\n\"max_size\": 24,\n\"bold\": true,\n\"italic\": false,\n\"name\": \"ariel\"\n}\n]\n}\n},\nShow more\n\nWhen converting PDF files, headings in those files can be identified and converted into an appropriate HTML \"h\" tag by identifying the size, font, and style of each heading level. Heading levels can be specified multiple times, if necessary, to correctly identify all relevant sections.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configref"},{"document_id":"ibmcld_05166-15912-16684","score":21.7354579622,"text":"\nThis allows for lower latency when accessing storage from compute resources co-located within the same data center, or for data requiring a specific geographic location. More information can be found in the [Select Regions and Endpoints](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-endpoints) documentation.\n\n\n\n\n\n 8 August 2017 \n\nIntroducing IBM Cloud Object Storage\n: Object Storage is a highly available, durable, and secure platform for storing unstructured data. Unstructured data (sometimes called binary or \"blob\" data) refers to data that is not highly structured in the manner of a database. Object storage is the most efficient way to store PDFs, media files, database backups, disk images, or even large structured datasets.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-updates"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00510-5537-7566","score":27.1413799344,"text":"\nInstead, keep orders separate as their own document type, referencing the customer ID. Now the model is immutable. To add an order, I create a new order document in the database, which cannot generate conflicts.\n\nTo be able to retrieve all orders for a specific customer, we can employ a view, which we cover later.\n\nAvoid constructs that rely on updates to parts of existing documents, where possible. Bad data models are often hard to change after you\u2019re in production.\n\nThe previous pattern can be solved efficiently by using partitioned databases, which are covered in greater detailed later.\n\nFor more information, see the following documentation:\n\n\n\n* IBM Cloudant guide to [data modeling](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-five-tips-for-modeling-your-data-to-scale-faq)\n* [Database partitions](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning)\n\n\n\n\n\n\n\n Keep documents small \n\nIBM Cloudant imposes a max doc size of 1 MB. This limit does not mean that a close-to-1-MB document size is a good idea. On the contrary, if you find you are creating documents that exceed single-digit KB, you probably need to revisit your model. Several things in IBM Cloudant become less performant as documents grow. JSON decoding is costly, for example.\n\nLet's look at the following sections: Documents must group data that mostly changes together and Keep documents small. It\u2019s worth stressing that models that rely on updates have a maximum volume limit of 1 MB, the cut-off for document size. This size isn\u2019t what you want.\n\n\n\n\n\n Avoid using attachments \n\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"},{"document_id":"ibmcld_00558-23465-25360","score":26.3292425126,"text":"\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-23555-25450","score":26.3292425126,"text":"\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00581-0-1268","score":25.6420776074,"text":"\n\n\n\n\n\n\n  Limits \n\nLimits that pertain to the usage of IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases are shown in the following tables.\n\n\n\n  Databases \n\n\n\nTable 1. Limits for databases\n\n Description     Limit                                                                             \n\n Database size   Consult the IBM Cloudant team if your database is likely to exceed 5 TB in size.  \n Partition size  10 GB                                                                             \n\n\n\n\n\n\n\n  Indexes \n\n\n\nTable 2. Limits for indexes\n\n Description                  Limit     \n\n Number of global indexes     Unlimited \n Number of partition indexes  10        \n\n\n\n\n\n\n\n  Request payload \n\n\n\nTable 3. Limits for request payload\n\n Description         Limit \n\n Total request size  10 MB \n Document size       1 MB  \n Attachment size     10 MB \n\n\n\n\n\n\n\n  Request timeouts \n\n\n\nTable 4. Limits for request timeouts\n\n Description     Limit      \n\n Default         60 seconds \n _partition\/*    5 seconds  \n\n\n\n\n\n\n\n  Query \n\n\n\nTable 5. Limits for query results\n\n Description                    Limit     \n\n Default                        Unlimited \n _partition\/* default           2000      \n _search                        200       \n _find by using text index      200       \n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-limits"},{"document_id":"ibmcld_00510-7123-9213","score":22.5515213855,"text":"\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1. IBM Cloudant is expensive as a block store.\n2. IBM Cloudant\u2019s internal implementation is not efficient in handling large amounts of binary data.\n\n\n\nSo, slow and expensive.\n\nIBM Cloudant is acceptable for small assets and occasional use. As a rule, if you need to store binary data alongside IBM Cloudant documents, it\u2019s better to use a separate solution more suited for this purpose. You need store only the attachment metadata in the IBM Cloudant document. Yes, that means you need to write some extra code to upload the attachment to a suitable block store of your choice. Verify that it succeeded before you store the token or URL to the attachment in the IBM Cloudant document.\n\nYour databases are smaller, cheaper, faster, and easier to replicate. For more information, see the following websites:\n\n\n\n* IBM Cloudant docs on [attachments](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments)\n* Detaching IBM Cloudant attachments to [Object Storage](https:\/\/medium.com\/codait\/detaching-cloudant-attachments-to-object-storage-with-serverless-functions-99b8c3c77925)\n\n\n\n\n\n\n\n Fewer databases are better than many \n\nIf you can, limit the number of databases per IBM Cloudant account to 500 or fewer. While this particular number is not magic (IBM Cloudant can safely handle more), several use cases exist that are adversely affected by large numbers of databases in an account.\n\nThe replicator scheduler has a limited number of simultaneous replication jobs that it is prepared to run. As the number of databases grows, the replication latency is likely to increase if you try to replicate everything contained in an account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"},{"document_id":"ibmcld_00556-7-1696","score":22.4364003598,"text":"\nHow to use attachments \n\nAnother way to store data is to use attachments. Attachments are Binary Large OBject ([BLOB](https:\/\/en.wikipedia.org\/wiki\/Binary_large_object)) files that are included within documents.\n\nIt's a good idea to keep attachments small in size and number because attachments can impact performance.\n\nThe BLOB is stored in the _attachments component of the document. The BLOB holds data that includes the following information:\n\n\n\n* The attachment name\n* The type of the attachment\n* The actual content\n\n\n\nExamples of BLOBs would be images and multimedia.\n\nIf you include the attachment as an [inline](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the overall JSON, the attachment content is represented by using BASE64 form.\n\nThe content type corresponds to a [MIME type](https:\/\/en.wikipedia.org\/wiki\/Internet_media_typeList_of_common_media_types). For example, if you want to attach a .jpg image file to a document, you specify the attachment MIME type as image\/jpeg.\n\nAttachments aren't permitted on documents in [_replicator](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostreplicate) or [_users](https:\/\/cloud.ibm.com\/apidocs\/cloudantputsecurity) databases.\n\n\n\n Create or update \n\nTo create a new attachment at the same time as creating a new document, include the attachment as an [inline](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the JSON content.\n\nTo create a new attachment on an existing document, or to update an attachment on a document, make a PUT request with the document's most recent _rev to https:\/\/$ACCOUNT.cloudant.com\/$DATABASE\/$DOCUMENT_ID\/$ATTACHMENT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments"},{"document_id":"ibmcld_00564-1452-3164","score":21.5607342352,"text":"\ncouchbackup --url \"$SERVICE_URL\" --db animaldb > backup.txt\n\nThe [NPM readme file](https:\/\/github.com\/cloudant\/couchbackup\/blob\/master\/README.md) details other options, including the ones in this list:\n\n\n\n* Environment variables to set the names of the database and URL.\n* Using a log file to record the progress of a backup.\n* The ability to resume an interrupted backup.\n\nThis option is only available with the log file for the interrupted backup.\n* Sending the backup text file to a named output file, rather than redirecting the stdout output.\n\nThe CouchBackup tools have [limitations](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoverylimitations).\n\n\n\n\n\n\n\n Restoring your IBM Cloudant data \n\nTo restore your data, use the couchrestore tool. Use couchrestore to import the backup file into a new IBM Cloudant database. Then, ensure that you build all indexes before any application tries to use the restored data.\n\nFor example, to restore the data that was backed up in the earlier example:\n\ncouchrestore --url \"https:\/\/myaccount.cloudant.com\" --db newanimaldb < backup.txt\n\nThe [NPM readme file](https:\/\/github.com\/cloudant\/couchbackup\/blob\/master\/README.md) provides details of other restore options.\n\n\n\n\n\n Limitations \n\nThe CouchBackup tools have the following limitations:\n\n\n\n* _security settings aren't backed up by the tools.\n* Attachments aren't backed up by the tools.\n* Backups aren't precise \"point-in-time\" snapshots. The reason is that the documents in the database are retrieved in batches, but other applications might be updating documents at the same time. Therefore, data in the database can change between the times when the first and last batches are read.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recovery"},{"document_id":"ibmcld_00629-29811-31959","score":21.4175431141,"text":"\ncurl \"$SERVICE_URL\/$DATABASE\/_changes?feed=continuous&include_docs=true&since=now&filter=mydesigndoc\/myfilter\"\n\nThe ordering of documents within the _changes feed is not always the same. In other words, changes might not appear in strict time order. The reason is that data is returned from multiple IBM Cloudant nodes, and eventual consistency rules apply.\n\n\n\n\n\n Replication pitfalls \n\nTo replicate successfully, the sum of the document size and all attachment sizes must be less than the maximum request size of the target cluster. For example, if the maximum HTTP request size is 11 MB, then the following scenarios apply:\n\n\n\nTable 1. Various scenarios based on maximum HTTP request size 11 MB\n\n Document size Attachment size Total size Replicates? \n\n 1 MB Five 2-MB attachments 11 MB Yes \n 1 MB One 10-MB attachment 11 MB Yes \n 1 MB One hundred 1-MB attachments 101 MB No \n\n\n\nSeveral considerations apply when you use replication.\n\n\n\n Incorrect user permissions \n\nFor replication to proceed optimally when you replicate from database \"a\" to database \"b\", the credentials that are supplied must have:\n\n\n\n* _reader and _replicator permissions on database \"a\".\n* _writer permissions on database \"b\".\n\n\n\nAPI keys are generated in the IBM Cloudant Dashboard or through the [API](https:\/\/cloud.ibm.com\/apidocs\/cloudant). Each key can be given individual permissions that relate to a specific IBM Cloudant database. IBM Cloudant must be able to write its checkpoint documents at the \"read\" end of replication, otherwise no state is saved and replication cannot resume from where it stopped. If the state is not saved, it can lead to performance problems when replication of large data sets resumes. The reason is that without checkpoints, the replication process restarts from the beginning each time that it is resumed.\n\n\n\n\n\n Replication document is conflicted \n\nAnother consequence of setting user permissions incorrectly is that the _replicator document becomes conflicted. The _replicator document records the current state of the replication process. In an extreme case, the document can become huge because it contains many unresolved conflicts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-replication-guide"},{"document_id":"ibmcld_00620-9537-11012","score":21.0330019323,"text":"\nHowever, in a real application, the page size might be different and depends on document size, latency demands, memory consumption, and other tradeoffs.You can use the options that are described in the following sections.<-- <section \"id=\"section-option-1-fetch-one-doc-too-many\" \"> --> Option 1 - Fetch one document too many Instead of fetching five documents (limit=5), fetch 5+1 (limit=6), but hide the sixth document from your users. The _id of the sixth document becomes the startkey of your request for the next page of results.See the following example of a first request:<-- <ul> --> * Curl * Java * Node * Python * Go<-- <\/ul> --> curl -H \"Authorization: Bearer $API_BEARER_TOKEN\" \"$SERVICE_URL\/orders\/_all_docs?limit=6\"\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsResult;\nimport com.ibm.cloud.cloudant.v1.model.DocsResultRow;\nimport com.ibm.cloud.cloudant.v1.model.PostAllDocsOptions;\n\nCloudant service = Cloudant.newInstance();\n\nint pageSize = 5;\nPostAllDocsOptions.Builder docsOptionsBuilder =\nnew PostAllDocsOptions.Builder()\n.db(\"orders\")\n.limit(pageSize + 1); \/\/ Fetch pageSize + 1 documents\n\nAllDocsResult response =\nservice.postAllDocs(docsOptionsBuilder.build())\n.execute()\n.getResult();\n\nwhile (response.getRows().size() > 1) {\nList<DocsResultRow> responseDocuments = response.getRows();\n\/\/ on the last page, show all documents:\nif (responseDocuments.size() <= pageSize) {\nSystem.out.println(responseDocuments);","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pagination-and-bookmarks"},{"document_id":"ibmcld_00485-1687-3253","score":20.199919051,"text":"\nFull-text search No No Yes, requires separate installer or container. Yes \n Partition queries No No Yes Yes \n Shard splitting No No Yes Available as tool for IBM Ops. \n Selector on changes feed No Yes Yes Yes \n Rate limits No No No User-defined [provisioned throughput capacity](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicprovisioned-throughput-capacity) settings \n Request size 4 GB (default) 4 GB (default) 4 GB (default) 11 MB \n Attachment size 4 GB (default) 4 GB (default) 4 GB (default) 10 MB \n Security auth [CouchDB Auth](https:\/\/docs.couchdb.org\/en\/stable\/intro\/security.html) [CouchDB Auth](https:\/\/docs.couchdb.org\/en\/stable\/intro\/security.html) [CouchDB Auth](https:\/\/docs.couchdb.org\/en\/stable\/intro\/security.html) [IBM Cloudant legacy auth with API Keys](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-work-with-your-accountauthorization), [IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant), or [CouchDB Auth](https:\/\/docs.couchdb.org\/en\/stable\/intro\/security.html) \n LDAP No No No No \n\n\n\nThe CouchDB _show, _list, _update, and _rewrite functions were deprecated in Apache CouchDB 3.0. For more information, see [deprecated feature warnings](https:\/\/docs.couchdb.org\/en\/stable\/whatsnew\/3.0.htmldeprecated-feature-warnings).\n\nAs a result, these functions are no longer supported for IBM Cloudant. They do not appear in IBM Cloudant documentation, and while the APIs currently remain in service, their use is not recommended. The IBM Cloudant Support team no longer supports them.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-couchdb-and-cloudant"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00558-23465-25360","score":16.7342302573,"text":"\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-23555-25450","score":16.7342302573,"text":"\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00581-0-1268","score":16.1268891039,"text":"\n\n\n\n\n\n\n  Limits \n\nLimits that pertain to the usage of IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases are shown in the following tables.\n\n\n\n  Databases \n\n\n\nTable 1. Limits for databases\n\n Description     Limit                                                                             \n\n Database size   Consult the IBM Cloudant team if your database is likely to exceed 5 TB in size.  \n Partition size  10 GB                                                                             \n\n\n\n\n\n\n\n  Indexes \n\n\n\nTable 2. Limits for indexes\n\n Description                  Limit     \n\n Number of global indexes     Unlimited \n Number of partition indexes  10        \n\n\n\n\n\n\n\n  Request payload \n\n\n\nTable 3. Limits for request payload\n\n Description         Limit \n\n Total request size  10 MB \n Document size       1 MB  \n Attachment size     10 MB \n\n\n\n\n\n\n\n  Request timeouts \n\n\n\nTable 4. Limits for request timeouts\n\n Description     Limit      \n\n Default         60 seconds \n _partition\/*    5 seconds  \n\n\n\n\n\n\n\n  Query \n\n\n\nTable 5. Limits for query results\n\n Description                    Limit     \n\n Default                        Unlimited \n _partition\/* default           2000      \n _search                        200       \n _find by using text index      200       \n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-limits"},{"document_id":"ibmcld_00510-5537-7566","score":15.6473935965,"text":"\nInstead, keep orders separate as their own document type, referencing the customer ID. Now the model is immutable. To add an order, I create a new order document in the database, which cannot generate conflicts.\n\nTo be able to retrieve all orders for a specific customer, we can employ a view, which we cover later.\n\nAvoid constructs that rely on updates to parts of existing documents, where possible. Bad data models are often hard to change after you\u2019re in production.\n\nThe previous pattern can be solved efficiently by using partitioned databases, which are covered in greater detailed later.\n\nFor more information, see the following documentation:\n\n\n\n* IBM Cloudant guide to [data modeling](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-five-tips-for-modeling-your-data-to-scale-faq)\n* [Database partitions](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning)\n\n\n\n\n\n\n\n Keep documents small \n\nIBM Cloudant imposes a max doc size of 1 MB. This limit does not mean that a close-to-1-MB document size is a good idea. On the contrary, if you find you are creating documents that exceed single-digit KB, you probably need to revisit your model. Several things in IBM Cloudant become less performant as documents grow. JSON decoding is costly, for example.\n\nLet's look at the following sections: Documents must group data that mostly changes together and Keep documents small. It\u2019s worth stressing that models that rely on updates have a maximum volume limit of 1 MB, the cut-off for document size. This size isn\u2019t what you want.\n\n\n\n\n\n Avoid using attachments \n\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"},{"document_id":"ibmcld_00558-21994-23839","score":14.9468256019,"text":"\nAs the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3. The instance drops back to 9.5 GB for the next 10 minutes of hour 02:00, then increases to 108 GB for the next 25 minutes of hour 02:00. Finally, your instance finishes the hour and indeed the rest of the month by dropping down to 28 GB.\n\nThis pattern means the maximum number of GB more than the plan allocation was 88 GB during hour 2 of day 3. From hour 03:00 of day 3, and for the rest of the month, your instance was 8 GB more than the plan allocation.\n\nTherefore, from hour 02:00 of day 3, your bill includes an overage based on 88 GB x 1 hour = 88 GB hours.\n\nFrom hour 03:00 of day 3 to the end of day 3, your bill includes an overage based on 8 GB x 21 hours = 168 GB hours.\n\nFrom hour 00:00 of day 4 until the end of the month (of 30 days), your bill includes an overage. The overage is based on 8 GB x 24 hours x 27 days = 5184 GB hours.\n\nThe total overage bill for the month is based on a total of 88 + 168 + 5184 = 5440 GB hours.\n\n\n\n\n\n\n\n Request and document size limits \n\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-22084-23929","score":14.9468256019,"text":"\nAs the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3. The instance drops back to 9.5 GB for the next 10 minutes of hour 02:00, then increases to 108 GB for the next 25 minutes of hour 02:00. Finally, your instance finishes the hour and indeed the rest of the month by dropping down to 28 GB.\n\nThis pattern means the maximum number of GB more than the plan allocation was 88 GB during hour 2 of day 3. From hour 03:00 of day 3, and for the rest of the month, your instance was 8 GB more than the plan allocation.\n\nTherefore, from hour 02:00 of day 3, your bill includes an overage based on 88 GB x 1 hour = 88 GB hours.\n\nFrom hour 03:00 of day 3 to the end of day 3, your bill includes an overage based on 8 GB x 21 hours = 168 GB hours.\n\nFrom hour 00:00 of day 4 until the end of the month (of 30 days), your bill includes an overage. The overage is based on 8 GB x 24 hours x 27 days = 5184 GB hours.\n\nThe total overage bill for the month is based on a total of 88 + 168 + 5184 = 5440 GB hours.\n\n\n\n\n\n\n\n Request and document size limits \n\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_11793-4987-7154","score":14.8870604052,"text":"\n9 hosts Up to 5 clusters 40 workers across 5 clusters, or 140 workers across 3 clusters 60 workers per cluster \n 12 hosts Up to 8 clusters 60 workers across 8 clusters, or 200 workers across 4 clusters 60 workers per cluster \n\n\n\n\n\n\n\n Location size for testing \n\nThe following table shows sizing guidance for the number of hosts that the Satellite location control plane requires to run a Satellite location demonstration. This configuration is not intended for production use.\n\nFor a non-RHCOS enabled location, your hosts must have at least 4 vCPU and 16 GB RAM. For an RHCOS enabled location, your hosts must have at least 8 vCPU and 32 GB RAM.\n\nNon RHCOS enabled location\n\nRHCOS enabled location\n\n\n\nSizing guidance for demonstrations\n\n Number of control plane hosts Max clusters in location Max cluster size \n\n 3 hosts 4x16 1 cluster 20 workers per cluster \n\n\n\n\n\n\n\n FAQs about location sizing \n\nReview the following frequently asked questions for more information about sizing your location.\n\n\n\n How do I know what size and number of hosts to attach to my cluster? \n\nTo decide on the size and number of hosts to attach to your clusters, consider the workloads that you want to run in the location. Review the [Red Hat OpenShift on IBM Cloud documentation](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategysizing) for guidance about the following considerations.\n\n\n\n* How many resources does my app require?\n* What else besides my app might use resources in the cluster?\n* What type of availability do I want my workload to have?\n* How many worker nodes (hosts) do I need to handle my workload?\n* How do I monitor resource usage and capacity in my cluster?\n\n\n\n\n\n\n\n How do I know when to attach capacity to the Satellite location control plane? \n\nWhen you list locations, such as with the ibmcloud sat location ls command or in the [Satellite console](https:\/\/cloud.ibm.com\/satellite\/locations), the location enters an Action required health state. You see warning messages similar to the following example.\n\nHosts in the location control plane are running out of disk space.\n\nHosts in the location control plane have critical CPU or memory usage issues.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-location-sizing"},{"document_id":"ibmcld_00629-29811-31959","score":14.4307781056,"text":"\ncurl \"$SERVICE_URL\/$DATABASE\/_changes?feed=continuous&include_docs=true&since=now&filter=mydesigndoc\/myfilter\"\n\nThe ordering of documents within the _changes feed is not always the same. In other words, changes might not appear in strict time order. The reason is that data is returned from multiple IBM Cloudant nodes, and eventual consistency rules apply.\n\n\n\n\n\n Replication pitfalls \n\nTo replicate successfully, the sum of the document size and all attachment sizes must be less than the maximum request size of the target cluster. For example, if the maximum HTTP request size is 11 MB, then the following scenarios apply:\n\n\n\nTable 1. Various scenarios based on maximum HTTP request size 11 MB\n\n Document size Attachment size Total size Replicates? \n\n 1 MB Five 2-MB attachments 11 MB Yes \n 1 MB One 10-MB attachment 11 MB Yes \n 1 MB One hundred 1-MB attachments 101 MB No \n\n\n\nSeveral considerations apply when you use replication.\n\n\n\n Incorrect user permissions \n\nFor replication to proceed optimally when you replicate from database \"a\" to database \"b\", the credentials that are supplied must have:\n\n\n\n* _reader and _replicator permissions on database \"a\".\n* _writer permissions on database \"b\".\n\n\n\nAPI keys are generated in the IBM Cloudant Dashboard or through the [API](https:\/\/cloud.ibm.com\/apidocs\/cloudant). Each key can be given individual permissions that relate to a specific IBM Cloudant database. IBM Cloudant must be able to write its checkpoint documents at the \"read\" end of replication, otherwise no state is saved and replication cannot resume from where it stopped. If the state is not saved, it can lead to performance problems when replication of large data sets resumes. The reason is that without checkpoints, the replication process restarts from the beginning each time that it is resumed.\n\n\n\n\n\n Replication document is conflicted \n\nAnother consequence of setting user permissions incorrectly is that the _replicator document becomes conflicted. The _replicator document records the current state of the replication process. In an extreme case, the document can become huge because it contains many unresolved conflicts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-replication-guide"},{"document_id":"ibmcld_07578-1268470-1270517","score":14.1474408251,"text":"\nYou can also access the correct mount point through an API call: SoftLayer_Network_Storage::getNetworkMountAddress().\n* How many volumes can I provision?\n\nBy default, you can provision a combined total of 700 Block and File Storage for Classic volumes. To increase your limit, contact your sales representative. For more information, see [Managing storage limits](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managinglimits).\n* How many instances can share the use of a provisioned File Storage for Classic volume?\n\nThe default limit for number of authorizations per file volume is 64. To increase this limit, contact your sales representative.\n* How many File Storage for Classic volumes can be attached to a single host?\n\nThat depends on what the host operating system can handle, it\u2019s not something that IBM Cloud\u00ae limits. Refer to your OS Documentation for limits on the number of file shares that can be mounted.\n* How many files and directories are allowed for specific file volume sizes? What is the maximum number of inodes allowed per volume size?\n\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger. The maximum number of inodes that can be configured on a volume is calculated by taking the total allocated volume size in KB and dividing it by 4. Any volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1271119-1273166","score":14.1474408251,"text":"\nYou can also access the correct mount point through an API call: SoftLayer_Network_Storage::getNetworkMountAddress().\n* How many volumes can I provision?\n\nBy default, you can provision a combined total of 700 Block and File Storage for Classic volumes. To increase your limit, contact your sales representative. For more information, see [Managing storage limits](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managinglimits).\n* How many instances can share the use of a provisioned File Storage for Classic volume?\n\nThe default limit for number of authorizations per file volume is 64. To increase this limit, contact your sales representative.\n* How many File Storage for Classic volumes can be attached to a single host?\n\nThat depends on what the host operating system can handle, it\u2019s not something that IBM Cloud\u00ae limits. Refer to your OS Documentation for limits on the number of file shares that can be mounted.\n* How many files and directories are allowed for specific file volume sizes? What is the maximum number of inodes allowed per volume size?\n\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger. The maximum number of inodes that can be configured on a volume is calculated by taking the total allocated volume size in KB and dividing it by 4. Any volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01197-3424-5754","score":12.8677172515,"text":"\nStep 3: Attach extra hosts to the Satellite location \n\nEvent Streams provides high availability by using multi-zone region deployment to protect against single points of failure. These extra hosts are used to create a service cluster into which Event Streams gets deployed. You must provision and balance the host compute infrastructure for the zones in your Satellite location.\n\nAttach the following hosts to your Satellite location:\n\n\n\n* Event Streams requires hosts running Red Hat Enterprise Linux 8 (RHEL 8)\n* 6 hosts of 4 vCPU and 16 GiB memory\n* 3 hosts of 8 vCPU and 32 GiB memory\n\n\n\nWhen Event Streams provisions, the provision process discovers the 4 vCPU and 8 vCPU hosts in the Satellite location and automatically assigns them to the Event Streams service instance. If 4 vCPU and 8 vCPU hosts are not available in the Satellite location, the Event Streams provision runs until the hosts are attached to the Satellite location. The Event Streams provision does not use other types of hosts in replacement of what is indicated precedingly.\n\nThe hosts requirement is for a single Event Streams Satellite instance. If multiple Event Streams Satellite instances are required, the hosts requirement applies to each Event Streams instance.\n\n\n\n\n\n Step 4: Provision Event Streams service instance \n\nAfter you prepare your Satellite location, granting service authorization, and attaching extra hosts, you can provision a Event Streams service instance:\n\n\n\n1. Go to the catalog, by clicking Catalog in the navigation bar.\n2. Look for the Event Streams tile in the Integration section and select it.\n3. In the Platform section of the Event Streams page, select the Satellite tile.\n4. In the Select a location field, select the Satellite location that you provisioned. When the Satellite tile was selected, the pricing plan information was updated. Review the Satellite plan details.\n5. Specify a Service name if you want something other than the default name.\n6. Click Create.\n\n\n\nWhen you provision an Event Streams service instance, a service cluster is automatically deployed into your Satellite location. You can verify the start of the deployment of the service cluster with the following steps:\n\n\n\n1. From the left Navigation menu, select Satellite, then Locations.\n2. Select your Satellite location.\n3. Select Services.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-satellite-provisioning"},{"document_id":"ibmcld_10393-7104-8488","score":12.1664700959,"text":"\nprintf \"iamapikey:IAM-API-KEY\" | base64\n4. Add the following section to your auth.json file.\n\n{\"auths\": {\"us.icr.io\": {\"auth\": \"BASE64-VALUE\",\"email\": \"IBM-EMAIL\"}}}\n5. Create the secret in the openshift-marketplace namespace.\n\noc create secret generic odf-secret -n openshift-marketplace --from-file=.dockerconfigjson=auth.json\u00a0 --type=kubernetes.io\/dockerconfig\n\n\n\n\n\n\n\n Step 10: Update the catalog source in your cluster \n\n\n\n1. After mirroring is complete, a results directory is created on your bastion host called oc-mirror-workspace.\n2. Change directories into the oc-mirror-workspace directory.\n\ncd oc-mirror-workspace\n3. Look for a results-XXX directory and cd into it.\n\nls\n\ncd results-XXX\n4. Look for the catalogSource-redhat-operator-index.yaml.\n\nls\n5. Edit the catalog source. Change the name to redhat-operators, add the odf-secret, and your registry details.\n\napiVersion: operators.coreos.com\/v1alpha1\nkind: CatalogSource\nmetadata:\nname: redhat-operators Make sure the name is redhat-operators\nnamespace: openshift-marketplace\nspec:\nimage: us.icr.io\/NAMESPACE\/redhat\/redhat-operator-index:v4.10 Add your registry\nsourceType: grpc\ndisplayName: Red Hat Operators\npublisher: Red Hat\nupdateStrategy:\nregistryPoll:\ninterval: 10m0s\nsecrets: Add the odf-secret\n- \"odf-secret\"\n6. Create the catalog source in your cluster.\n\noc create -f catalogSource-redhat-operator-index.yaml\n7.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-odf-private"},{"document_id":"ibmcld_02172-6043-7731","score":11.8654527525,"text":"\nYou can update which products are included or excluded at any time by updating your private catalog's settings.\n\n\n\n\n\n Branding your private catalog with a custom banner \n\nYou can enhance the look and feel of your private catalog to match your brand by adding a custom image to your private catalog's banner. All users who are given access to your private catalog can see the custom banner when they go to the private catalog to search for products, instead of the default IBM Cloud banner. To add a custom banner image, complete the following steps:\n\n\n\n1. Go to Manage > Catalogs, then click Private catalogs.\n2. Click the Overflow menu icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/action-menu-icon.svg) on the row of the private catalog that you want to add a banner for, then click Edit.\n3. Add a URL to your custom banner in the Catalog banner field, or you can click Upload to add an image directly. The maximum recommended image size is 944 x 260 pixels.\n4. Click Update.\n5. Then, go to the [catalog](https:\/\/cloud.ibm.com\/catalog), and select your private catalog from the list to view the updated look and feel of your private catalog.\n\n\n\nYou can also customize the provider name for private catalog products that you add to your catalogs. By default, they display with Community as the provider, which is a filter in the catalog, but you can customize this to be your company or organization's name. For more information, see [Providing catalog entry details](https:\/\/cloud.ibm.com\/docs\/account?topic=account-cm-catalog-detailscm-catalog-entry).\n\n\n\n\n\n Authorizing access to private catalogs by using the console","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-restrict-by-user"},{"document_id":"ibmcld_02114-28721-30820","score":11.4944347077,"text":"\n--version-locator VERSION_NUMBER\n: To get the version locator for the product, run the ibmcloud catalog offering listcommand and locate the specified product or version you want to use.\n\n--output FORMAT (optional)\n: Specifies output format. The default is terminal compatible and the only supported alternative is JSON, for example, --output json.\n\n\n\n\n\n\n\n ibmcloud catalog offering category-options \n\nRun the following command to retrieve the list of category choices.\n\nibmcloud catalog offering category-options [--output FORMAT]\n\n\n\n Command options \n\n--output FORMAT (optional)\n: Specifies output format. The default is terminal compatible and the only supported alternative is JSON, for example, --output json.\n\n\n\n\n\n Example \n\nibmcloud catalog offering category-options\n\n\n\n\n\n Output \n\nThe command returns the following output:\n\nName Tags Description\nVPC Infrastructure vpc Fully customizable, software-defined virtual network with superior isolation.\nCompute compute,content,containers,openwhisk,vmware,runtime Build your virtual environments\nContainers containers,clusters,registry Get started by creating a Kubernetes cluster, or manage your Docker images in the registry.\nNetworking network Order network.\nStorage storage Order storage.\n\n\n\n\n\n\n\n ibmcloud catalog offering add-category \n\nRun the following command to add a category tag to a product. You can provide the category name, which you can find by running the ibmcloud catalog offering category-options command. The products must be placed in a category to be visible in the catalog. Default is Developer tools.\n\nibmcloud catalog offering category-options [--output FORMAT]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n--category CATEGORY\n: Provide the category that best fits how users might use your product. Categories are used to organize products in the catalog based on common solutions, function, or use. You can select only one category. Run the ibmcloud catalog offering category-options command to view all options. Default is Developer tools.\n\n\n\n\n\n Example","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-manage-catalogs-plugin"},{"document_id":"ibmcld_04491-28713-30812","score":11.4944347077,"text":"\n--version-locator VERSION_NUMBER\n: To get the version locator for the product, run the ibmcloud catalog offering listcommand and locate the specified product or version you want to use.\n\n--output FORMAT (optional)\n: Specifies output format. The default is terminal compatible and the only supported alternative is JSON, for example, --output json.\n\n\n\n\n\n\n\n ibmcloud catalog offering category-options \n\nRun the following command to retrieve the list of category choices.\n\nibmcloud catalog offering category-options [--output FORMAT]\n\n\n\n Command options \n\n--output FORMAT (optional)\n: Specifies output format. The default is terminal compatible and the only supported alternative is JSON, for example, --output json.\n\n\n\n\n\n Example \n\nibmcloud catalog offering category-options\n\n\n\n\n\n Output \n\nThe command returns the following output:\n\nName Tags Description\nVPC Infrastructure vpc Fully customizable, software-defined virtual network with superior isolation.\nCompute compute,content,containers,openwhisk,vmware,runtime Build your virtual environments\nContainers containers,clusters,registry Get started by creating a Kubernetes cluster, or manage your Docker images in the registry.\nNetworking network Order network.\nStorage storage Order storage.\n\n\n\n\n\n\n\n ibmcloud catalog offering add-category \n\nRun the following command to add a category tag to a product. You can provide the category name, which you can find by running the ibmcloud catalog offering category-options command. The products must be placed in a category to be visible in the catalog. Default is Developer tools.\n\nibmcloud catalog offering category-options [--output FORMAT]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n--category CATEGORY\n: Provide the category that best fits how users might use your product. Categories are used to organize products in the catalog based on common solutions, function, or use. You can select only one category. Run the ibmcloud catalog offering category-options command to view all options. Default is Developer tools.\n\n\n\n\n\n Example","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-catalogs-plugin"},{"document_id":"ibmcld_12577-28741-30840","score":11.4944347077,"text":"\n--version-locator VERSION_NUMBER\n: To get the version locator for the product, run the ibmcloud catalog offering listcommand and locate the specified product or version you want to use.\n\n--output FORMAT (optional)\n: Specifies output format. The default is terminal compatible and the only supported alternative is JSON, for example, --output json.\n\n\n\n\n\n\n\n ibmcloud catalog offering category-options \n\nRun the following command to retrieve the list of category choices.\n\nibmcloud catalog offering category-options [--output FORMAT]\n\n\n\n Command options \n\n--output FORMAT (optional)\n: Specifies output format. The default is terminal compatible and the only supported alternative is JSON, for example, --output json.\n\n\n\n\n\n Example \n\nibmcloud catalog offering category-options\n\n\n\n\n\n Output \n\nThe command returns the following output:\n\nName Tags Description\nVPC Infrastructure vpc Fully customizable, software-defined virtual network with superior isolation.\nCompute compute,content,containers,openwhisk,vmware,runtime Build your virtual environments\nContainers containers,clusters,registry Get started by creating a Kubernetes cluster, or manage your Docker images in the registry.\nNetworking network Order network.\nStorage storage Order storage.\n\n\n\n\n\n\n\n ibmcloud catalog offering add-category \n\nRun the following command to add a category tag to a product. You can provide the category name, which you can find by running the ibmcloud catalog offering category-options command. The products must be placed in a category to be visible in the catalog. Default is Developer tools.\n\nibmcloud catalog offering category-options [--output FORMAT]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n--category CATEGORY\n: Provide the category that best fits how users might use your product. Categories are used to organize products in the catalog based on common solutions, function, or use. You can select only one category. Run the ibmcloud catalog offering category-options command to view all options. Default is Developer tools.\n\n\n\n\n\n Example","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-manage-catalogs-plugin"},{"document_id":"ibmcld_11296-5100-5811","score":11.3766879659,"text":"\nibmcloud pi instance-capture INSTANCE_ID --destination DEST --name NAME [--volumes \"VOLUME1 VOLUME2\"] [--access-key KEY] [--secret-key KEY] [--region REGION] [--image-path TYPE]\n2. Find your newly exported image by completing either one of the following tasks:\n\n\n\n* To see your newly exported image in the image catalog, use the ibmcloud pi image-list-catalog command:\n\nibmcloud pi image-list-catalog [--long] [--json]\n* To see your newly exported image in COS, use the ibmcloud cos list-objects command:\n\nibmcloud cos list-objects --bucket BUCKET_NAME [--delimiter DELIMITER] [--encoding-type METHOD] [--prefix PREFIX] [--starting-token TOKEN] [--page-size SIZE] [--max-items NUMBER] [--region REGION] [--json]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-capturing-exporting-vm"},{"document_id":"ibmcld_11149-6741-9103","score":11.1920482012,"text":"\nDiscover all that IBM Cloud has to offer. From services, software, and\n\ndeployable architecturesranging from containers, compute, security, data, AI, and more, find what you need to transform your business.\n\nThe available services include options for compute, storage, networking, end-to-end developer solutions for app development, testing and deployment, security management services, traditional and open source databases, and cloud-native services. The lifecycle and operations of services are the responsibility of IBM.\n\nYou can also find a number of software products, including [Cloud Paks](https:\/\/www.youtube.com\/watch?v=DzFhhSR8SSs), Terraform-based templates, Helm charts, and Operators. The preconfigured software solutions help you build faster. And, with a simplified installation process, you can get started quickly. You manage the deployment and configuration of the software on your own compute resources.\n\nIf you're looking for more robust solutions for your enterprise business goals, IBM Cloud offers deployable architectures that use cloud automation for deploying common architectural patterns that combine one or more cloud resources that are designed for easy deployment, scalability, and modularity.\n\nAnd, if you're looking for help in your journey to cloud, check out our professional services. Browse your options for scheduling a consultation with technical experts depending on your needs, such as cloud migration, creating business solutions with IBM Garage, or developing a container security solution that works for you.\n\nThe catalog supports command-line interfaces (CLIs) and a RESTful API for you to use to retrieve information about existing products.\n\n\n\n Searching the catalog for services \n\nAll products that are available in IBM Cloud are displayed by default in the catalog. You can filter the catalog by type to view a specific type of product, for example, only services, software, or deployable architectures. Enter keywords or set additional filters to further scope your view of the catalog. For example, if you want to deploy an analytics instance to Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae, you can select the Analytics category, and filter the results by selecting Red Hat OpenShift as the deployment target.\n\nSee the following table for the list of filters that you can use to search the catalog.\n\nCategory\n\nCompliance","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-whatis-platform"},{"document_id":"ibmcld_16671-4467-6313","score":11.1210948007,"text":"\nWhen you register your own bucket, ensure to provide the correct details for bucket configuration. Quick start wizard does not validate the bucket configuration details and you cannot modify them later.\n\nEnsure that the data bucket contains data.\n2. Click Next. This displays the Catalogs configuration page.\n3. In the Catalogs configuration page, select Apache Iceberg.\n4. Click Next. This displays the Engine configuration page.\n5. In the Engine configuration page, select the engine type and size.\n\nDepending on the workload that you have, you can select the type and size of the Presto engine.\n6. Click Next. This displays the Summary page.\n7. In the Summary page, review the configurations before you finish setting up your data infrastructure.\n\nWhen the setup is complete, the watsonx.data home page is displayed. You are all set to use the watsonx.data or you can configure it further.\n8. Click Finish and go. This displays the Infrastructure manager page.\n\n\n\nYou can add more engines, catalogs, buckets, and databases in the Infrastructure manager page if you want to. For more information about creating engines, catalogs, buckets, databases, see Configuring watsonx.data components in the How To section.\n\n--------------------\n\n\n\n\n\n Step 4: Querying data \n\nIn this section of the tutorial, you learn how to navigate to the Query workspace, and create SQL queries to query your data from the bucket.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1. From the navigation menu, select SQL. The Query workspace page opens.\n2. Select the Presto engine from the Engine drop-down.\n3. Select the catalog. In this scenario, consider the Apache Iceberg catalog, default schema, order_detail table, to run the query.\n4. Click the overflow menu and select the required query.\n\n\n\n* For a catalog and schema, you can run the Generate Path query.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-tutorial_prov_custbckt"},{"document_id":"ibmcld_11142-7-1829","score":11.1032921111,"text":"\nTry out IBM Cloud, for free \n\nLooking to try out IBM Cloud\u00ae? Create an account and start building proof of concepts (POCs) with the many components available in IBM Cloud. You can try Lite and Free service plans to explore IBM Cloud at no cost while learning how to work in the cloud, use Watson, and more. This quick start guide is intended to help you get up and running on IBM Cloud without having to think about costs until you're ready.\n\n\n\n Before you begin \n\nGo to the [IBM Cloud console](https:\/\/cloud.ibm.com) and create an account. You're asked to enter your credit card information to secure your account and verify your identity. There are no costs that are associated with signing up, and you can try out IBM Cloud for free. You pay only for billable services that you choose to use, with no long-term contracts or commitments.\n\nYou're set up with a [Pay-As-You-Go account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountspaygo), and you can access the full IBM Cloud catalog, including all Lite and Free plans. You receive a $200 credit to help get you started. You can use the $200 credit on IBM Cloud products that are used in the first 30 days.\n\n\n\n\n\n Step 1: Explore the catalog \n\nExplore the catalog for services that are free to use by filtering for Lite and Free pricing plans. You can work on your projects worry free, without the risk of generating a bill.\n\n\n\n1. Go to the [catalog](https:\/\/cloud.ibm.com\/catalog).\n2. Select the Lite and Free pricing plan options.\n\n\n\n\n\n\n\n Step 2: Create an instance \n\nCreate an instance of product that includes a free Lite plan or a Free tier pricing plan.\n\n\n\n1. Select the tile from the catalog after reviewing the filtered list of products.\n2. Enter any required information to create the instance.\n3. Click Create.\n\n\n\n\n\n\n\n Step 3: Check out the tutorials","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-tutorial-try-for-free"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01150-4410-6468","score":30.0089661928,"text":"\nWhat is Event Streams's maximum message size? \n\nEvent Streams's maximum message size is 1 MB, which is the Kafka default.\n\n\n\n\n\n What are Event Streams's replication settings? \n\nEvent Streams is configured to provide strong availability and durability. The following configuration settings apply to all topics and cannot be changed:\n\n\n\n* replication.factor = 3\n* min.insync.replicas = 2\n\n\n\n\n\n\n\n What are the restrictions and defaults for topics and partitions? \n\n\n\n* Topic names are restricted to a maximum of 100 characters.\n* The default number of partitions for a topic is one.\n* Each IBM Cloud space has a limit of 100 partitions. To create more partitions, you must use a new IBM Cloud space.\n\n\n\n\n\n\n\n How do I check which Event Streams plan I've provisioned? \n\nTo confirm which type of Event Streams plan you've provisioned (Lite, Standard, or Enterprise), complete the following steps:\n\n\n\n1. In the IBM Cloud console, navigate to the instance of Event Streams that you want to check.\n2. Click the Plan tab in the navigation pane on the left. The Current plan section displays your plan type.\n\n\n\n\n\n\n\n Can I change my Event Streams plan using the IBM Cloud console? \n\nYes, but only if you are moving from the Lite plan to the Standard plan.\n\n\n\n1. In the IBM Cloud console, navigate to the instance of Event Streams Lite plan that you want to change.\n2. Click the Plan tab in the navigation pane on the left.\n3. In the Change pricing plan section, check the Standard box. Click Upgrade.\n\nAllow a few minutes for the cached limit of 1 partition for the Lite plan to clear so that you can take advantage of the 100 partition limit for the Standard plan.\n\nHowever, this option does not currently work in the IBM Cloud console for any other combination of plans. For example, if you try a different plan combination, you'll see an error message like the the following:\n\nCould not find VCAP::CloudController::ServicePlan with guid: ibm.eventstreams.standard\n\n\n\n\n\n\n\n What are the differences between the Event Streams Standard and Event Streams Enterprise plans?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-faqs"},{"document_id":"ibmcld_16242-3349-4513","score":29.6160625841,"text":"\n[Action response mode](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/response-mode-modal.png)\n\nAction response mode\n2. Click the other mode if you want to change it, and then click Save response mode.\n\n\n\n\n\n\n\n Override system defaults modes \n\nEnterprise\n\nFor Lite and Plus plans, the default settings can\u2019t be changed. For Enterprise plans, you can override system defaults to customize each mode in global settings for actions.\n\nTo override system defaults:\n\n\n\n1. Set the Override System Defaults toggle to On. This toggle is available only for Enterprise plans.\n2. Use the menu to modify any of the settings for either mode.\n\n\n\nIf you customize, the choices for each setting are;\n\n\n\nMode customization choices\n\n Setting Choices \n\n Clarify when one action matches More often, Sometimes, Less often \n Clarify when more than one action matches More often, Sometimes, Less often \n Offer support option when asking a clarifying question More often, Sometimes, Less often \n Step validation attempts before offering support 1 time, 2 times, 3 times \n\n\n\nIf you customize modes, be sure to test any changes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-action-response-modes"},{"document_id":"ibmcld_07578-699255-701206","score":29.2509810915,"text":"\nClick the Plan tab in the navigation pane on the left. The Current plan section displays your plan type.\n\n\n\n* Can I change my Event Streams plan using the IBM Cloud console?\n\nYes, but only if you are moving from the Lite plan to the Standard plan.\n\n\n\n1. In the IBM Cloud console, navigate to the instance of Event Streams Lite plan that you want to change.\n2. Click the Plan tab in the navigation pane on the left.\n3. In the Change pricing plan section, check the Standard box. Click Upgrade.\n\nAllow a few minutes for the cached limit of 1 partition for the Lite plan to clear so that you can take advantage of the 100 partition limit for the Standard plan.\n\nHowever, this option does not currently work in the IBM Cloud console for any other combination of plans. For example, if you try a different plan combination, you'll see an error message like the the following:\n\nCould not find VCAP::CloudController::ServicePlan with guid: ibm.eventstreams.standard\n\n\n\n* What are the differences between the Event Streams Standard and Event Streams Enterprise plans?\n\nTo find out more information about the different Event Streams plans, see [Choosing your plan](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-plan_choose).\n* How do I handle disaster recovery?\n\nCurrently, it is the responsibility of the user to manage their own Event Streams disaster recovery. Event Streams data can be replicated between an Event Streams instance in one location (region) and another instance in a different location. However, the user is responsible for provisioning a remote Event Streams instance and managing the replication.\n\nWe suggest a tool like Kafka MirrorMaker to replicate data between clusters. For information about how to run MirrorMaker, see [Event Streams kafka-mirrormaker repository](https:\/\/github.com\/ibm-messaging\/event-streams-samples\/tree\/master\/kafka-mirrormaker).\n\nThe user is also responsible for the backup of message payload data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-699213-701164","score":29.2509810915,"text":"\nClick the Plan tab in the navigation pane on the left. The Current plan section displays your plan type.\n\n\n\n* Can I change my Event Streams plan using the IBM Cloud console?\n\nYes, but only if you are moving from the Lite plan to the Standard plan.\n\n\n\n1. In the IBM Cloud console, navigate to the instance of Event Streams Lite plan that you want to change.\n2. Click the Plan tab in the navigation pane on the left.\n3. In the Change pricing plan section, check the Standard box. Click Upgrade.\n\nAllow a few minutes for the cached limit of 1 partition for the Lite plan to clear so that you can take advantage of the 100 partition limit for the Standard plan.\n\nHowever, this option does not currently work in the IBM Cloud console for any other combination of plans. For example, if you try a different plan combination, you'll see an error message like the the following:\n\nCould not find VCAP::CloudController::ServicePlan with guid: ibm.eventstreams.standard\n\n\n\n* What are the differences between the Event Streams Standard and Event Streams Enterprise plans?\n\nTo find out more information about the different Event Streams plans, see [Choosing your plan](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-plan_choose).\n* How do I handle disaster recovery?\n\nCurrently, it is the responsibility of the user to manage their own Event Streams disaster recovery. Event Streams data can be replicated between an Event Streams instance in one location (region) and another instance in a different location. However, the user is responsible for provisioning a remote Event Streams instance and managing the replication.\n\nWe suggest a tool like Kafka MirrorMaker to replicate data between clusters. For information about how to run MirrorMaker, see [Event Streams kafka-mirrormaker repository](https:\/\/github.com\/ibm-messaging\/event-streams-samples\/tree\/master\/kafka-mirrormaker).\n\nThe user is also responsible for the backup of message payload data.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16729-112397-114109","score":27.102685679,"text":"\n[Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan)Migrating an Enterprise plan to a Lite or Standard plan\n\nMigration from the Enterprise plans to IBM Cloudant Lite or Standard plans includes these tasks, which are described in the following steps.\n\nCloudant\n\n\n\n* 30 minutes\n* 2023-04-06\n\n\n\n[Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan)Migrating from a Lite plan to a Standard plan\n\nMigrating from the free Lite plan to the Standard plan by completing the following tasks.\n\nCloudant\n\n\n\n* 15 minutes\n* 2023-04-06\n\n\n\n[Finding your IBM Cloudant plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-find-your-ibm-cloudant-plan)Finding your IBM Cloudant plan\n\nYou can subscribe to different IBM Cloudant plans, including the Lite, Standard, or Enterprise plans.\n\nCloudant\n\n\n\n* 20 minutes\n* 2023-03-30\n\n\n\n[Combining IBM Cloudant with other IBM services](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-combine-ibm-services)Combining IBM Cloudant with other IBM services\n\nEach database technology has its own strengths and weaknesses. Some are built for high availability and data durability (at the expense of more hardware and extra cost). Others favor speed and can churn out blazingly fast queries (but might lose data in a sudden power failure).\n\nCloudant\n\n\n\n* 2023-03-30\n\n\n\n[Enhance cloud security by applying context-based restrictions](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-cbr-enhanced-security)Enhance cloud security by applying context-based restrictions","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_07578-447531-449109","score":27.0243046476,"text":"\n[Upload](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.\n\n\n\n* Migration FAQ\n\n Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-447513-449091","score":27.0243046476,"text":"\n[Upload](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.\n\n\n\n* Migration FAQ\n\n Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00535-0-1738","score":27.0071204209,"text":"\n\n\n\n\n\n\n  Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\n  Which plans can I migrate? \n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n*  IBM Cloudant Enterprise\n*  Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\n  Can I back up my data before I migrate? \n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\n  Can I keep my username.cloudant.com domain and redirect it to the new service on IBM Cloudant? \n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\n  Who do I contact if I have questions? \n\nGo to the [IBM Cloud Support portal](https:\/\/www.ibm.com\/cloud\/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-migration"},{"document_id":"ibmcld_07578-448564-450242","score":26.5831847493,"text":"\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\nGo to the [IBM Cloud Support portal](https:\/\/www.ibm.com\/cloud\/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n* Which plans can I migrate?\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n* Can I back up my data before I migrate?\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-448546-450224","score":26.5831847493,"text":"\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\nGo to the [IBM Cloud Support portal](https:\/\/www.ibm.com\/cloud\/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n* Which plans can I migrate?\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n* Can I back up my data before I migrate?\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07103-31052-33321","score":33.0156791079,"text":"\nYou cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, and Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 24 September 2021 \n\nNew scoring for NLU enrichments\n: Relevance and confidence scores are displayed for NLU enrichments that are returned by search. For example, when you open the JSON view of the document preview from a query result, you can see confidence scores for Entities mentions and relevance scores for Keyword mentions.\n\n\n\n\n\n 9 September 2021 \n\nNew location for Plus plan\n: The Plus plan is now available from the Sydney location. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product. For more information, see [Getting the most from Discovery](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-version-choose).\n\nChange to Lite and Advanced plans in most locations\n: Lite and Advanced plans are discontinued. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\n\n\n\n\n 26 August 2021 \n\nNew locations for the Plus plan\n: The Plus plan is now available from the London and Washington DC locations, in addition to Dallas, Frankfurt, and Tokyo.\n\nChange to Lite and Advanced plans in some locations\n: You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\nNew answer finding feature\n: Answer finding is now generally available for managed deployments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_11143-7-2028","score":30.4079604489,"text":"\nNavigating the IBM Cloud console \n\nThe [IBM Cloud\u00ae console](https:\/\/cloud.ibm.com) is the user interface that you use to manage all your IBM Cloud resources. You can create a free account, log in, access documentation, access the catalog, view pricing information, get support, or check the status of IBM Cloud components. After you log in, the menu bar contains a Navigation Menu icon ![Navigation Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/adcecdbe4e86955f88aac7f3c1e7ec3ff44992ef\/icons\/icon_hamburger.svg) and more links.\n\n\n\n Watch a tour \n\n\n\n* Video transcript\n\nWelcome to IBM Cloud, your open, secure, and enterprise-ready cloud platform with over 350 unique products for you to start building the solutions that you need today! Just log in, and you're ready to start building in the cloud.\n\nFrom the global navigation, you can explore how to get started with key technologies in IBM Cloud. Choose from technologies including serverless computing with Functions [Click Menu icon > Functions], container-based deployments on Kubernetes [Click Kubernetes to expand the options] or Red Hat OpenShift [Click OpenShift to expand the options], and VPC infrastructure [Click VPC Infrastructure to expand the options]. Developers can start with API management tools, app development starter kits, DevOps toolchains, and more to expedite and automate your app development.\n\nYou can get started creating resources through any of these guided journeys [Click Kubernetes > Clusters].\n\nOr, if you want to explore everything that IBM Cloud has to offer, go to the catalog to browse over 350 unique products [Click Catalog menu item]. Choose from our broad portfolio of managed services [Click Services], explore software products to take advantage of simplified installation [Click Software], or consult with IBM Cloud experts [Click Consulting]. If you're just here to try it out, filter the catalog by products that offer Lite plans, which are free to use [Click Services, and select the Lite pricing plan option].","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-ui"},{"document_id":"ibmcld_07103-34419-36390","score":27.8497385286,"text":"\nImproved SharePoint Online connector\n: The Microsoft SharePoint Online data source connector now accepts any valid Azure Active Directory user ID syntax; the format of the user ID doesn't need to match the <admin_user>@.onmicrosoft.com syntax. For more information, see [Microsoft SharePoint Online](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-connector-sharepoint-online-cloud).\n\n\n\n\n\n 16 July 2021 \n\nNew beta dynamic website web crawl\n: The Web crawler can now crawl dynamic websites that use JavaScript to render content. If you enable this beta feature, the time it takes to crawl the site increases. For more information, see [Web crawl](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-connector-web-cloud).\n\n\n\n\n\n 23 June 2021 \n\nNew Plus plan\n: Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product. Currently, the Plus plan is available from the Dallas location. For more information, see [Getting the most from Discovery](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-version-choose).\n\nChange to Lite and Advanced plans\n: Lite and Advanced plans are no longer offered. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas location. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\n\n\n\n\n Endpoint deprecation reminder \n\nChange to Discovery API endpoint\n: As part of work done to fully support Identity and Access Management (IAM) authentication, the endpoint that you use to access your Discovery service programmatically is changing. The old endpoint URLs are deprecated and will be retired on 26 May 2021. Update your API calls to use the new URLs.\n\nThe pattern for the endpoint URL changed from gateway-{location}.watsonplatform.net\/discovery\/api\/ to api.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_11142-7-1829","score":27.2801501112,"text":"\nTry out IBM Cloud, for free \n\nLooking to try out IBM Cloud\u00ae? Create an account and start building proof of concepts (POCs) with the many components available in IBM Cloud. You can try Lite and Free service plans to explore IBM Cloud at no cost while learning how to work in the cloud, use Watson, and more. This quick start guide is intended to help you get up and running on IBM Cloud without having to think about costs until you're ready.\n\n\n\n Before you begin \n\nGo to the [IBM Cloud console](https:\/\/cloud.ibm.com) and create an account. You're asked to enter your credit card information to secure your account and verify your identity. There are no costs that are associated with signing up, and you can try out IBM Cloud for free. You pay only for billable services that you choose to use, with no long-term contracts or commitments.\n\nYou're set up with a [Pay-As-You-Go account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountspaygo), and you can access the full IBM Cloud catalog, including all Lite and Free plans. You receive a $200 credit to help get you started. You can use the $200 credit on IBM Cloud products that are used in the first 30 days.\n\n\n\n\n\n Step 1: Explore the catalog \n\nExplore the catalog for services that are free to use by filtering for Lite and Free pricing plans. You can work on your projects worry free, without the risk of generating a bill.\n\n\n\n1. Go to the [catalog](https:\/\/cloud.ibm.com\/catalog).\n2. Select the Lite and Free pricing plan options.\n\n\n\n\n\n\n\n Step 2: Create an instance \n\nCreate an instance of product that includes a free Lite plan or a Free tier pricing plan.\n\n\n\n1. Select the tile from the catalog after reviewing the filtered list of products.\n2. Enter any required information to create the instance.\n3. Click Create.\n\n\n\n\n\n\n\n Step 3: Check out the tutorials","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-tutorial-try-for-free"},{"document_id":"ibmcld_07103-29564-31587","score":26.7998933705,"text":"\nPreviously, the list included fields that were not valid choices.\n\n\n\n\n\n 14 October 2021 \n\nNew Discovery home page\n: A new home page is displayed when you start Discovery and gives you quick access to a product overview video, and tours. You can collapse the home page welcome banner to see more projects.\n\nNew plan usage section\n: Stay informed about plan usage and check your usage against the limits for your plan type from the Plan limits and usage page. From the product page header, click the user icon ![User icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/user--avatar.svg). The Usage section shows a short summary. Click View all to see usage information for all of the plan limit categories.\n\nChange to spelling settings in Search\n: The spelling correction setting changed from being enabled automatically in new projects to being disabled by default. If you want to alert users when they misspell a term in their query, turn on Spelling suggestions. For more information, see [Customizing the search bar](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-search-bar).\n\nImproved Guided tours availability\n: The Guided tours button is now available from the product page header, which make them accessible from anywhere. Previously, it was available from the My Projects page only.\n\n\n\n\n\n 1 October 2021 \n\nChange to Lite and Advanced plans in all locations\n: Lite and Advanced plans are discontinued. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, and Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 24 September 2021 \n\nNew scoring for NLU enrichments","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_11143-1499-3764","score":25.5039504753,"text":"\nOr, if you want to explore everything that IBM Cloud has to offer, go to the catalog to browse over 350 unique products [Click Catalog menu item]. Choose from our broad portfolio of managed services [Click Services], explore software products to take advantage of simplified installation [Click Software], or consult with IBM Cloud experts [Click Consulting]. If you're just here to try it out, filter the catalog by products that offer Lite plans, which are free to use [Click Services, and select the Lite pricing plan option].\n\nWhen you're working in IBM Cloud [Click IBM Cloud menu option], check out your dashboard to get a high-level overview of your account's resources, users, support cases, compliance monitoring, and usage, with quick links out to each area. You can tailor the information that's displayed to only what you need by creating custom dashboards and adding widgets for specific resources, team notes, management tasks, and more [Click the Actions menu icon > Create dashboard > Management > Create].\n\nFor any account management tasks that you need to take care of, go to Manage > Account [Click Manage menu option > Account]. Here you can create and manage your resource groups, Cloud Foundry orgs, create tags to organize resources, manage your account settings, and more.\n\nFrom the same Manage menu, you can go to Billing and usage [Click Manage menu option > Billing and usage] to view your usage, view invoices, and set spending notifications to help keep track of your costs.\n\nThen, through the Manage > Access (IAM) option [Click Manage menu item > Access (IAM)], you can invite users to your account and manage their access to account resources including IAM-enabled, Cloud Foundry, and classic infrastructure resources.\n\nIn a connected world, security is more important than ever, and we've built it right into the platform [Click Menu icon > Security and Compliance]. With the IBM Cloud Security and Compliance Center [Click Dashboard], you can set up a unified dashboard to monitor security and compliance, govern configuration, and gain insights into threats.\n\nIf you prefer to work from the command line [Click IBM Cloud Shell menu item], you can manage your IBM Cloud account and resources from your browser with IBM Cloud Shell.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-ui"},{"document_id":"ibmcld_07103-32746-34817","score":25.1697933914,"text":"\n: The Plus plan is now available from the London and Washington DC locations, in addition to Dallas, Frankfurt, and Tokyo.\n\nChange to Lite and Advanced plans in some locations\n: You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\nNew answer finding feature\n: Answer finding is now generally available for managed deployments. Use answer finding when you want to return a concise answer to a question. For more information, see [Answer finding](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parametersanswer-finding).\n\n\n\n\n\n 16 August 2021 \n\nNew locations for the Plus plan\n: The Plus plan is now available from the Frankfurt and Tokyo locations, in addition to Dallas.\n\nChange to Lite and Advanced plans in some locations\n: Lite and Advanced plans are no longer offered. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, or Tokyo locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\n\n\n\n\n 27 July 2021 \n\nImproved document size limit\n: Document size limit is increased. For Premium plan collections, you can now upload files that are up to 50 MB in size instead of 32 MB. For more information, see [Document limits](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collectionscollections-doc-limits).\n\n\n\n\n\n 23 July 2021 \n\nImproved SharePoint Online connector\n: The Microsoft SharePoint Online data source connector now accepts any valid Azure Active Directory user ID syntax; the format of the user ID doesn't need to match the <admin_user>@.onmicrosoft.com syntax. For more information, see [Microsoft SharePoint Online](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-connector-sharepoint-online-cloud).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_07578-447531-449109","score":25.165018768,"text":"\n[Upload](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.\n\n\n\n* Migration FAQ\n\n Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-447513-449091","score":25.165018768,"text":"\n[Upload](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.\n\n\n\n* Migration FAQ\n\n Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00535-0-1738","score":25.1172776049,"text":"\n\n\n\n\n\n\n  Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\n  Which plans can I migrate? \n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n*  IBM Cloudant Enterprise\n*  Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\n  Can I back up my data before I migrate? \n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\n  Can I keep my username.cloudant.com domain and redirect it to the new service on IBM Cloudant? \n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\n  Who do I contact if I have questions? \n\nGo to the [IBM Cloud Support portal](https:\/\/www.ibm.com\/cloud\/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-migration"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12343-7-1769","score":28.185715731,"text":"\nPython \n\nGiven its ease of use and adoption for data science applications, [Python](https:\/\/www.python.org\/) support is imperative to increase adoption of your IBM Cloud service. Supporting Python applications using [Flask](https:\/\/github.com\/pallets\/flask), [Django](https:\/\/www.djangoproject.com\/), [Jupyter](https:\/\/jupyter.org\/), and functional programming paradigms introduces special considerations that need to be observed by your SDK.\n\n\n\n Environment support \n\n\n\n* Your Python SDK should be written to support all [Python >=3.5](https:\/\/www.python.org\/downloads\/) releases.\n* Ensure your SDK is compatible with data science usecases, such as [Jupyter Notebooks](https:\/\/jupyter.org\/).\n\n\n\n\n\n\n\n Publishing \n\nAll Python SDKs should be publicly available on an [IBM GitHub organization](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-distributionopen-source). The releases of these SDKs should be published on [PyPI](https:\/\/pypi.org\/).\n\nYour SDK should follow the [semantic versioning best practices](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-distributionsemantic-versioning).\n\n\n\n\n\n Community support \n\nAllow your users to find answers to their questions. Users should be able to report problems on GitHub by raising issues on your SDK repository. Having a public Slack channel is a great way to engage with users who have questions specific to their use cases.\n\n\n\n\n\n Style guidelines \n\nYou should follow the [PEP8 style guide for Python](https:\/\/www.python.org\/dev\/peps\/pep-0008\/), with a few modifications, like four spaces instead of tabs for indentation.\n\nYou should use the standard [development tools](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-developer-tools) for Python to check style and code coverage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-python"},{"document_id":"ibmcld_12341-1239-2954","score":26.7519405715,"text":"\nThe releases of these SDKs should be published on [NPM](https:\/\/www.npmjs.com\/). Your NPM package should be [scoped](https:\/\/docs.npmjs.com\/creating-and-publishing-scoped-public-packagescreating-a-scoped-public-package) with [@ibm-cloud](https:\/\/www.npmjs.com\/search?q=%40ibm-cloud), so that NPM users can find similar packages across NPM.\n\nYour SDK should follow the [semantic versioning best practices](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-distributiondistribution-semver).\n\n\n\n\n\n Community support \n\nAllow your users to find answers to their questions. Users should be able to report problems on GitHub by raising issues on your SDK repository. Having a public Slack channel is a great way to engage with users who have questions specific to their use cases.\n\n\n\n\n\n Style guidelines \n\nYou should follow the [Airbnb conventions](https:\/\/github.com\/airbnb\/javascript), with two spaces for indentation.\n\nYou should use the standard [development tools](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools) for JavaScript to check style and code coverage.\n\n\n\n\n\n Streaming support \n\nIf your API takes fileType parameters, you should accept Node.js streams as an input type.\n\n\n\n\n\n Dependencies \n\nUse a well-defined, well-documented request library that includes browser support, like [axios](https:\/\/github.com\/axios\/axios), [superagent](https:\/\/github.com\/visionmedia\/superagent), or [node-fetch](https:\/\/github.com\/node-fetch\/node-fetch).\n\n\n\n\n\n Objects for arguments \n\nThe methods in your SDK should take a JSON object as an argument. This object will contain the options for the requests, instead of using positional parameters in the function definition.\n\n\n\n\n\n Async architecture","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-node"},{"document_id":"ibmcld_02698-7-1759","score":25.9502685366,"text":"\nIntegrating SDKs \n\nThe App Configuration client SDK is available for Android, JavaScript, and React, the server SDKs for Node, Python, Go, and Java, and the admin SDK for Go, to integrate with your web and mobile applications, microservices, and distributed environments.\n\n\n\n Client-side and Server-side SDKs \n\nUnderstand the differences between the various SDKs so that you can decide between SDK types for your use case.\n\n\n\n Types of SDKs \n\nSDKs supported by App Configuration include:\n\n\n\n* Server-side SDK\n* Client-side SDK\n* Admin SDK\n\n\n\nSDKs that help evaluate feature flag and property values are broadly classified as Server-side or Client-side - based on the deployment environment. These SDKs can be integrated into your application to assess the feature or property values by considering segment targeting rules, if any.\n\nEvaluation SDKs fetch the latest configuration data from the App Configuration service and ensure that any change in the service configuration is made available to your application in real time.\n\nAdmin SDKs can be used to create and manage configurations for Environments, Collections, Feature flags, Properties, and Segments. As an option to IBM Cloud Dashboard or IBM Cloud CLI, Admin SDKs can be used to programmatically manage your service configuration from within your application.\n\nThe currently available Go language Admin SDK integrates with your Go application.\n\nDifferences between client-side and server-side SDKs:\n\n\n\nTable 1. List of App Configuration server, client, and admin SDKs\n\n SDK type Details Links to SDKs and integration docs \n\n Server side These SDKs are designed for multi-user systems and are intended to be used in a trusted environment, such as inside a corporate network or on a web server.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-sdks"},{"document_id":"ibmcld_00620-14227-15704","score":25.2526756637,"text":"\nThe previous Go example requires the following import block: import (\n\"encoding\/json\"\n\"fmt\"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n\"github.com\/IBM\/go-sdk-core\/core\"\nAll Go examples require the service object to be initialized. For more information, see the API documentation's Authentication section]] ! ! ! ! for examples.This option works, but you end up fetching n+1 documents when only n are required.<-- <\/section \"id=\"section-option-1-fetch-one-doc-too-many\" \"> --><-- <section \"id=\"section-option-2-the-u0000-trick\" \"> --> Option 2 - The \\u0000 trick If you're determined to fetch only n documents each time, then you need to calculate a value of startkey, which means the next ID after the last _id in the result set. For example, if the last document in the first page of results is \"example\", what must the startkey of the next call to _all_docs be? It can't be \"example\", otherwise you get the same document ID again. It turns out that you can append u0000 to the end of a key string to indicate the \"next key\" (u0000 is a Unicode null character, which can be placed in a URL as-is or with the percent code %00). ).See the following example of a first request:<-- <ul> --> * Curl * Java * Node * Python * Go<-- <\/ul> --> curl -H \"Authorization: Bearer $API_BEARER_TOKEN\" \"$SERVICE_URL\/orders\/_all_docs?limit=5\"\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsResult;\nimport com.ibm.cloud.cloudant.v1.model.DocsResultRow;","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pagination-and-bookmarks"},{"document_id":"ibmcld_00620-8515-9974","score":23.7008320045,"text":"\npanic(err)\n}\nb, _ := json.MarshalIndent(allDocsResult3, \"\", \" \")\nfmt.Println(string(b))\nThe previous Go example requires the following import block: import (\n\"encoding\/json\"\n\"fmt\"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n\"github.com\/IBM\/go-sdk-core\/core\"\n)\nAll Go examples require the service object to be initialized. For more information, see the API documentation's Authentication section]] ! ! ! ! ! for examples.This practice means you define the size of the data set and the range of the _id field to return, but that isn't quite the same as pagination.The startkey\/endkey values are in double quotation marks because they're expected to be JSON-encoded and JSON.stringify('order00077') === \"order00077\".<-- <\/section \"id=\"section-the-limit-startkey-endkey-parameters\" \"> --><-- <section \"id=\"section-pagination-options\" \"> --> Pagination options For performance reasons, if you are displaying large amounts of data, you must consider using pagination. In these examples, documents are fetched in blocks of five. However, in a real application, the page size might be different and depends on document size, latency demands, memory consumption, and other tradeoffs.You can use the options that are described in the following sections.<-- <section \"id=\"section-option-1-fetch-one-doc-too-many\" \"> --> Option 1 - Fetch one document too many Instead of fetching five documents (limit=5), fetch 5+1 (limit=6), but hide the sixth document from your users.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pagination-and-bookmarks"},{"document_id":"ibmcld_02683-12957-13877","score":23.597171366,"text":"\nproperty.getPropertyDataFormat(); \/\/ YAML\nproperty.getCurrentValue(entityId, entityAttributes); \/\/ Yaml String is returned\n}\nShow more\n\n\n\n\n\n Set listener for feature or property changes \n\nThe SDK provides mechanism to notify you in real time when feature flag's or property's configuration changes. You can subscribe to configuration changes by using the same appConfigClient.\n\nappConfigClient.registerConfigurationUpdateListener(new ConfigurationUpdateListener() {\n@Override\npublic void onConfigurationUpdate() {\nSystem.out.println(\"Received updated configurations\");\n\/\/ add your code\n\/\/ To find the effect of any configuration changes, you can call the feature or property related methods\n\n\/\/ Feature feature = appConfigClient.getFeature(\"numeric-feature\");\n\/\/ Integer newValue = (Integer) feature.getCurrentValue(entityId, entityAttributes);\n}\n});\n\n\n\n\n\n Fetch most recent data \n\nappConfigClient.fetchConfigurations();","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-java"},{"document_id":"ibmcld_12463-25842-27664","score":23.2812247634,"text":"\n: Secrets Manager is now available in the London (eu-gb), Tokyo (jp-tok), and Washington DC (us-east) regions.\n\nFor more information, see [Regions and endpoints](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-endpoints).\n\n\n\n\n\n 15 February 2021 \n\nNow available: Secrets Manager Java SDK\n: You can now use the IBM Cloud Secrets Manager Java SDK to connect to your Secrets Manager service instance.\n\nFor more information, check out the [IBM Cloud Secrets Manager Java SDK repository in GitHub](https:\/\/github.com\/IBM\/secrets-manager-java-sdk).\n\n\n\n\n\n 27 January 2021 \n\nNow available: Secrets Manager Go and Python SDKs\n: You can now use the IBM Cloud Secrets Manager Go and Python SDKs to connect to your Secrets Manager service instance.\n\nFor more information, check out the SDK repositories in GitHub:\n\n\n\n* [IBM Cloud Secrets Manager Go SDK](https:\/\/github.com\/IBM\/secrets-manager-go-sdk)\n* [IBM Cloud Secrets Manager Python SDK](https:\/\/github.com\/IBM\/secrets-manager-python-sdk)\n\n\n\n\n\n\n\n 18 December 2020 \n\nAnnouncing Secrets Manager general availability\n: Secrets Manager is now generally available in the IBM Cloud catalog!\n\nTo find out more about this release, check out the [announcement blog](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/ibm-cloud-secrets-manager-is-now-generally-available).\n\n\n\n\n\n 15 December 2020 \n\nSydney availability\n: You can now create a Secrets Manager service instance in the Sydney (au-syd) region.\n\nFor more information, see [Regions and endpoints](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-endpoints).\n\n\n\n\n\n 14 December 2020 \n\nNow available: Secrets Manager CLI plug-in\n: The Secrets Manager CLI plug-in is now available for download!\n\nYou can use the Secrets Manager CLI to interact with the secrets that you store in your Secrets Manager instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-release-notes"},{"document_id":"ibmcld_00462-1307-2903","score":23.2648582541,"text":"\nThe IBM Cloudant SDK for Python library is the official IBM Cloudant library for Python.\n\nInstall the [IBM Cloudant SDK for Python](https:\/\/pypi.org\/project\/ibmcloudant\/) library by running pip or easy_install as shown in the following examples:\n\npip install --upgrade \"ibmcloudant>=0.0.27\"\n\nor\n\neasy_install --upgrade \"ibmcloudant>=0.0.27\"\n\nFor more information, see the [python.org](https:\/\/www.python.org\/about\/) website.\n\n\n\n Library for Python \n\n\n\n* [IBM Cloudant SDK for Python](https:\/\/github.com\/IBM\/cloudant-python-sdk)\n\n\n\n\n\n\n\n\n\n Go \n\nThe IBM Cloudant SDK for Go library is the official IBM Cloudant library for Go.\n\nInstall the [IBM Cloudant SDK for Go](https:\/\/pkg.go.dev\/mod\/github.com\/IBM\/cloudant-go-sdk) library by running the following command:\n\ngo get -u github.com\/IBM\/cloudant-go-sdk\/cloudantv1\n\n\n\n Library for Go \n\n\n\n* [IBM Cloudant SDK for Go](https:\/\/github.com\/ibm\/cloudant-go-sdk)\n\n\n\n\n\n\n\n\n\n Useful tools \n\nYou can use the following tools with IBM Cloudant.\n\n\n\n Supported tools \n\nSupported tools are maintained and supported by IBM Cloudant.\n\n\n\n couchbackup \n\nA tool that you use from the command line to back up an IBM Cloudant or CouchDB database to a text file.\n\nTo install couchbackup, run the following command by using npm:\n\nnpm install -g @cloudant\/couchbackup\n\nFor more information, see [couchbackup](https:\/\/github.com\/cloudant\/couchbackup).\n\n\n\n\n\n\n\n Unsupported tools \n\nUnsupported tools are not maintained or supported by IBM Cloudant.\n\n\n\n cURL \n\nA tool that you use from the command line to transfer data.\n\nFor more information, see [curl](https:\/\/curl.haxx.se\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-client-libraries"},{"document_id":"ibmcld_02693-12182-13567","score":23.0263032568,"text":"\n\/\/ input json :- {\"role\": \"tester\", \"description\": \"do testing\"}\n\/\/ expected output :- \"tester\"\n\ntar_val = property.get_current_value(entityId, entityAttributes)\nexpected_output = tar_val['role']\n\nproperty = appconfig_client.get_property('yaml-property')\nproperty.get_property_data_type() \/\/ STRING\nproperty.get_property_data_format() \/\/ YAML\nproperty.get_current_value(entityId, entityAttributes) \/\/ returns dictionary object\n\n\/\/ Example Below\n\/\/ input yaml string :- \"---nrole: testerndescription: do_testing\"\n\/\/ expected output :- \"do_testing\"\n\ntar_val = property.get_current_value(entityId, entityAttributes)\nexpected_output = tar_val['description']\nShow more\n\n\n\n\n\n Set listener for the feature and property data changes \n\nThe SDK provides mechanism to notify you in real time when feature flags' or properties' configuration changes. You can subscribe to configuration changes by using the same appconfig_client.\n\ndef configuration_update(self):\nprint('Received updates on configurations')\n add your code\n To find the effect of any configuration changes, you can call the feature or property related methods\n\n feature = appconfig_client.getFeature('online-check-in')\n new_value = feature.get_current_value(entity_id, entity_attributes)\n\nappconfig_client.register_configuration_update_listener(configuration_update)\n\n\n\n\n\n Fetch latest data \n\nappconfig_client.fetch_configurations()","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-python"},{"document_id":"ibmcld_13481-6212-7871","score":22.7501295808,"text":"\nDownload the [Hive-compatible client](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/hive-metastore-standalone-client-3.1.2-sqlquery-1.0.13.jar) and place it in a directory of your Apache Spark cluster that is not on the classpath. This step is necessary, as the client is loaded into an isolated classloader to avoid version conflicts. Note that in the examples the files are placed in \/tmp\/dataengine, when you use a different folder, adjust the example accordingly.\n\nThe client differs from the Hive version 3.1.2 release by more enhancements that add support for TLS and authentication through IBM Cloud\u00ae Identity and Access Management. For user, specify the CRN and for password a valid API key with access to your Data Engine. Find the endpoint to use in the following table.\n\n\n\nTable 1. Region endpoints\n\n Region Endpoint \n\n us-south thrift:\/\/catalog.us.dataengine.cloud.ibm.com:9083 \n eu-de thrift:\/\/catalog.eu-de.dataengine.cloud.ibm.com:9083 \n\n\n\n\n\n\n\n Convenience libraries to configure Spark \n\nWhile the Data Engine catalog is compatible with the Hive metastore and can be used as any other external Hive metastore server, an SDK is provided to minimize the steps that are needed to configure Apache Spark. The SDK simplifies connecting to the Hive metastore and IBM Cloud Object Storage buckets referenced by tables or views.\n\nIn case of using Python download both, the Scala and the Python SDK, and place them in a folder that is in the classpath of your Apache Spark cluster. When using Scala, the Scala SDK is enough.\n\n\n\n* [spark-dataengine-scala](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/dataengine-spark-integration-1.4.51.jar)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1934264036}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03369-66296-68553","score":40.5709102762,"text":"\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page. This settings page is not displayed in English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills because use of the legacy version of the API is no longer supported for those languages. For more information about the new system entities, see [System entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 28 October 2020 \n\nIntroducing the actions skill!\n: The actions skill is the latest step in the continuing evolution of Watson Assistant as a software as a service application. The actions skill is designed to make it simple enough for anyone to build a virtual assistant. We've removed the need to navigate between intents, entities, and dialog to create conversational flows. Building can all now be done in one simple and intuitive interface.\n\nWeb chat integration is created automatically\n: When you create a new assistant, a web chat integration is created for you automatically (in addition to the preview link integration, which was created previously). These integrations are added also to the assistant that is auto-generated (named My first assistant) when you create a new service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03329-1102-2607","score":40.5148225974,"text":"\n[Finish creating the new assistant](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-create-assistant-done.png)\n3. Click Create assistant.\n\n\n\n\n\n\n\n Step 2: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click Add an actions or dialog skill.\n\n![Add actions or dialog skill button](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-addskill.png)\n2. Give your skill the name My first skill.\n3. Optional. If the dialog you plan to build will use a language other than English, then choose the appropriate language from the list.\n4. For skill type, choose Dialog.\n\n![Finish creating the skill](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-add-skill-done.png)\n5. Click Create skill.\n\nThe skill is created and appears in your assistant.\n\n\n\n\n\n\n\n Step 3: Add intents from a content catalog \n\nThe Intents page is where you start to train your assistant. In this tutorial, you will add training data that was built by IBM to your skill. Prebuilt intents are available from the content catalog. You will give your assistant access to the General content catalog so your dialog can greet users, and end conversations with them.\n\n\n\n1. Make sure your My first skill is open.\n2. Click Content Catalog from the Skills menu.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-gs-dialog"},{"document_id":"ibmcld_16364-103662-105841","score":40.3640819171,"text":"\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page. This settings page is not displayed in English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills because use of the legacy version of the API is no longer supported for those languages. For more information about the new system entities, see [System entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 28 October 2020 \n\nIntroducing the actions skill!\n: The actions skill is the latest step in the continuing evolution of Watson Assistant as a software as a service application. The actions skill is designed to make it simple enough for anyone to build a virtual assistant. We've removed the need to navigate between intents, entities, and dialog to create conversational flows. Building can all now be done in one simple and intuitive interface.\n\nThe actions skill is available as a beta feature. For more information, see [Adding an actions skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-actions-add).\n\nWeb chat integration is created automatically\n: When you create a new assistant, a web chat integration is created for you automatically (in addition to the preview link integration, which was created previously). These integrations are added also to the assistant that is auto-generated (named My first assistant) when you create a new service instance. For more information, see [Integrating the web chat with your website](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat).\n\nText messaging integration was renamed\n: The Twilio messaging integration was renamed to SMS with Twilio.\n\n\n\n\n\n 9 October 2020 \n\nSearch skill update","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_02998-1325-2715","score":40.0552478253,"text":"\nName the assistant My first assistant.\n3. Click Create assistant.\n\n![Finish creating the new assistant](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-create-assistant-done.png)\n\n\n\n\n\n\n\n Step 3: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click the My first assistant tile to open the assistant.\n2. Click Add dialog skill.\n\n![Shows the Add skill button from the home page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-add-dialog-skill.png)\n3. Click the Create skill tab.\n4. Give your skill the name My first skill.\n5. Optional: If the dialog you plan to build will use a language other than English, then choose the appropriate language from the list.\n\n![Finish creating the skill](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-add-skill-done.png)\n6. Click Create skill.\n\n![Shows the My first assistant with the My first skill added to it](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-my-first-skill.png)\n7. Click the skill you just created to open it.\n\n\n\n\n\n\n\n Step 4: Add intents from a content catalog","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started"},{"document_id":"ibmcld_03049-1355-3132","score":39.1708875165,"text":"\nClick Import skill, and then click Choose JSON File, and select the JSON file you want to import.\n\nImportant:\n\n\n\n* The imported JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding.\n* The maximum size for a skill JSON file is 10MB. If you need to import a larger skill, consider importing the intents and entities separately after you have imported the skill. (You can also import larger skills using the REST API. For more information, see the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-data-v1?curl=createworkspace).)\n* The JSON cannot contain tabs, newlines, or carriage returns.\n\n\n\nSpecify the data you want to include:\n\n\n\n* Select Everything (Intents, Entities, and Dialog) if you want to import a complete copy of the exported skill, including the dialog.\n* Select Intents and Entities if you want to use the intents and entities from the exported skill, but you plan to build a new dialog.\n\n\n\nClick Import.\n\nIf you have trouble importing a skill, see [Troubleshooting skill import issues](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-addskill-dialog-add-import-errors).\n\n\n\n5. Specify the details for the skill:\n\n\n\n* Name: A name no more than 100 characters in length. A name is required.\n* Description: An optional description no more than 200 characters in length.\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-catalog).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_07578-18457-20516","score":38.9805813846,"text":"\n5. Under Time Frame, select the month you need.\n6. Select your Plus plans or Plus Trial plans to see monthly active users and the API calls.\n\n\n\n* Error: New Off Topic not supported\n\nYou see the error New Off Topic not supported after editing the JSON file for a dialog skill and changing the skill language from English to another language.\n\nTo resolve this issue, modify the JSON file by setting off_topic to false. For more information about this feature, see [Defining what's irrelevant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-irrelevance-detection).\n* Is it possible to increase the number of intents per skill\n\nNo, it is not possible to increase the number of intents per skill.\n\n\n\nDiscovery v1\n\n\n\n* Where can I get technical support for Discovery?\n\nIf you cannot find a solution to the issue you are having, search this documentation. You can also try the resources available from the Developer community section of the table of contents.\n\nIf your service plan covers it, you can get help by creating a case from [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n* How do you interpret the confidence score that appears in query results?\n\nDiscovery returns a confidence score for both natural language queries and those written in the Discovery Query Language. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n* How do you integrate Watson Discovery with Watson Assistant?\n\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-18457-20516","score":38.9805813846,"text":"\n5. Under Time Frame, select the month you need.\n6. Select your Plus plans or Plus Trial plans to see monthly active users and the API calls.\n\n\n\n* Error: New Off Topic not supported\n\nYou see the error New Off Topic not supported after editing the JSON file for a dialog skill and changing the skill language from English to another language.\n\nTo resolve this issue, modify the JSON file by setting off_topic to false. For more information about this feature, see [Defining what's irrelevant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-irrelevance-detection).\n* Is it possible to increase the number of intents per skill\n\nNo, it is not possible to increase the number of intents per skill.\n\n\n\nDiscovery v1\n\n\n\n* Where can I get technical support for Discovery?\n\nIf you cannot find a solution to the issue you are having, search this documentation. You can also try the resources available from the Developer community section of the table of contents.\n\nIf your service plan covers it, you can get help by creating a case from [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n* How do you interpret the confidence score that appears in query results?\n\nDiscovery returns a confidence score for both natural language queries and those written in the Discovery Query Language. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n* How do you integrate Watson Discovery with Watson Assistant?\n\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16364-146046-148039","score":37.4102198137,"text":"\n: For some first-time users, a new introductory product tour is shown that the user can choose to follow to perform the initial steps of creating an assistant.\n\n\n\n\n\n 1 August 2019 \n\nWebhook callouts are available\n: Add webhooks to dialog nodes to make programmatic calls to an external application as part of the conversational flow. The new Webhook support simplifies the callout implementation process. (No more action JSON objects required.) For more information, see [Making a programmatic call from a dialog node](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-webhooks).\n\nImproved dialog page responsiveness\n: In all service instances, the user interface of the Dialog page was updated to use a new JavaScript library that increases the page responsiveness. As a result, the look of some graphical user interface elements, such as buttons, changed slightly, but the function did not.\n\n\n\n\n\n 31 July 2019 \n\nSearch skill and autocorrection are generally available\n: The search skill and spelling autocorrection features, which were previously available as beta features, are now generally available.\n\n\n\n* Search skills can be created by users of Plus or Premium plans only.\n* You can enable autocorrection for English-language dialog skills only. It is enabled automatically for new English-language dialog skills.\n\n\n\n\n\n\n\n 26 July 2019 \n\nMissing skills issue is resolved\n: In some cases, workspaces that were created through the API only were not being displayed when you opened the Watson Assistant user interface. This issue has been addressed. All workspaces that you create by using the API are displayed as dialog skills when you open the user interface.\n\n\n\n\n\n 23 July 2019 \n\nDialog search is fixed\n: In some skills, the search function was not working in the Dialog page. The issue is now fixed.\n\n\n\n\n\n 17 July 2019 \n\nDisambiguation choice limit\n: You can now set the maximum number of options to show to users when the assistant asks them to clarify what they want to do.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_16364-101992-104197","score":36.9416391268,"text":"\n: The new model, which is being offered as a beta feature in English-language dialog and actions skills, is faster and more accurate. It combines traditional machine learning, transfer learning, and deep learning techniques in a cohesive model that is highly responsive at run time. For more information, see [Improved intent recognition](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intent-detection).\n\n\n\n\n\n 3 November 2020 \n\nSuggestions are now generally available\n: The Suggestions feature that is available for the web chat integration is generally available and is enabled by default when you create a new web chat integration. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nNew languages supported by the dialog analysis notebook\n: The Dialog skill analysis notebook was updated with language support for French, German, Spanish, Czech, Italian, and Portuguese. For more information, see [Analysis notebooks](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resourceslogs-resources-jupyter-logs).\n\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03313-17920-19395","score":36.9402941638,"text":"\nTo do so, add a new intent or entity, and then delete it. This action starts a new training process.\n\n\n\n\n\n Is there a range of IP addresses that are being used by a webhook? \n\nUnfortunately, the IP address ranges from which Watson Assistant may call a webhook URL are subject to change, which in turn prevent using them in any static firewall configuration. Please use the https transport and specify an authorization header to control access to the webhook.\n\n\n\n\n\n How do I see my monthly active users in Watson Assistant? \n\nTo see your monthly active users (MAU) do the following:\n\n\n\n1. Sign in to [https:\/\/cloud.ibm.com](https:\/\/cloud.ibm.com)\n2. Click on the Manage menu, then choose Billing and usage.\n3. Click on Usage.\n4. For Watson Assistant, select View Plans.\n5. Under Time Frame, select the month you need.\n6. Select your Plus plans or Plus Trial plans to see monthly active users and the API calls.\n\n\n\n\n\n\n\n Error: New Off Topic not supported \n\nYou see the error New Off Topic not supported after editing the JSON file for a dialog skill and changing the skill language from English to another language.\n\nTo resolve this issue, modify the JSON file by setting off_topic to false. For more information about this feature, see [Defining what's irrelevant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-irrelevance-detection).\n\n\n\n\n\n Is it possible to increase the number of intents per skill \n\nNo, it is not possible to increase the number of intents per skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1412669729}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03120-3469-5331","score":27.1483299872,"text":"\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_03353-5263-7331","score":26.5517179126,"text":"\nItalian (it) GA Deprecated \n Japanese (ja) GA Deprecated \n Korean (ko) GA Deprecated \n Portuguese (Brazilian) (pt-br) GA Deprecated \n Spanish (es) GA Deprecated \n Universal (xx) GA NA \n\n\n\nThe Watson Assistant service supports multiple languages as noted, but the tool interface itself (descriptions, labels, etc.) is in English. All supported languages can be input and trained through the English interface.\n\nGB18030 compliance: GB18030 is a Chinese standard that specifies an extended code page for use in the Chinese market. This code page standard is important for the software industry because the China National Information Technology Standardization Technical Committee has mandated that any software application that is released for the Chinese market after September 1, 2001, be enabled for GB18030. The Watson Assistant service supports this encoding, and is certified GB18030-compliant\n\n\n\n\n\n\n\n Changing a skill language \n\nOnce a skill has been created, its language cannot be modified. If it is necessary to change the supported language of a skill, you can do so by editing the skill's underlying JSON.\n\nTo change the skill language, take the following steps:\n\n\n\n1. Download the skill that you want to edit.\n2. Open the downloaded skill JSON file in a text editor.\n3. Search for the property named language.\n\nThe language property is set to the original language of the skill. For example, the language property is en for an English skill.\n4. Change the value of this property to the language you want to use instead. For example, change it to fr for French or de for German.\n5. Save the changes to the JSON file, and then upload the edited file, overwriting the existing skill.\n\n\n\n\n\n\n\n Configuring bidirectional languages \n\nFor bidirectional languages, such as Arabic, you can change your skill preferences.\n\n\n\n1. From your skill tile, click the Actions drop-down menu, and then select Language Preferences.\n\nThis option is only available for skills that are configured to use a bidirectional language.\n2. Select from the following options for your skill:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support"},{"document_id":"ibmcld_02839-3583-5403","score":25.8699431036,"text":"\nIf your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. Add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-basicsweb-chat-basics-global).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_03027-4976-6968","score":25.8232262626,"text":"\nEnglish (en) GA Deprecated \n Arabic (ar) GA Deprecated \n Chinese (Simplified) (zh-cn) GA Deprecated \n Chinese (Traditional) (zh-tw) GA Deprecated \n Czech (cs) GA Deprecated \n Dutch (nl) GA Deprecated \n French (fr) GA Deprecated \n German (de) GA Deprecated \n Italian (it) GA Deprecated \n Japanese (ja) GA Deprecated \n Korean (ko) GA Deprecated \n Portuguese (Brazilian) (pt-br) GA Deprecated \n Spanish (es) GA Deprecated \n Universal (xx) GA NA \n\n\n\nThe Watson Assistant service supports multiple languages as noted, but the tool interface itself (descriptions, labels, etc.) is in English. All supported languages can be input and trained through the English interface.\n\nGB18030 compliance: GB18030 is a Chinese standard that specifies an extended code page for use in the Chinese market. This code page standard is important for the software industry because the China National Information Technology Standardization Technical Committee has mandated that any software application that is released for the Chinese market after September 1, 2001, be enabled for GB18030. The Watson Assistant service supports this encoding, and is certified GB18030-compliant\n\n\n\n\n\n\n\n Changing a skill language \n\nOnce a skill has been created, its language cannot be modified. If it is necessary to change the supported language of a skill, you can do so by editing the skill's underlying JSON.\n\nTo change the skill language, take the following steps:\n\n\n\n1. Download the skill that you want to edit.\n2. Open the downloaded skill JSON file in a text editor.\n3. Search for the property named language.\n\nThe language property is set to the original language of the skill. For example, the language property is en for an English skill.\n4. Change the value of this property to the language you want to use instead. For example, change it to fr for French or de for German.\n5. Save the changes to the JSON file, and then upload the edited file, overwriting the existing skill.\n\n\n\n\n\n\n\n Configuring bidirectional languages","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support"},{"document_id":"ibmcld_03418-1763-3833","score":25.7370553885,"text":"\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Global audience support \n\nThe underlying skills understand customer messages that are written in any of the languages that are supported by the service. For more information, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support). The responses from your assistant are defined by you in the underlying skill and can be written in any language you want.\n\nEven if your skill includes responses in a language other than English, some of the phrases that are displayed in the web chat widget are added by the web chat itself and do not come from the underlying skill. These hardcoded phrases are specified in English unless you choose to apply a different language.\n\nThere are language files that contain translations of each English-language phrase that is used by the web chat. You can instruct the web chat to use one of these other languages files by using the instance.updateLanguagePack() method.\n\nLikewise, the web chat applies an American English locale to content that is added by the web chat unless you specify something else. The locale setting affects how values such as dates and times are formatted.\n\nTo configure the web chat for customers outside the US, follow these steps:\n\n\n\n1. To apply the appropriate syntax to dates and times and to use a translation of the English-language phrases, set the locale. Use the instance.updateLocale() method.\n\nFor example, if you apply the Spanish locale (es), the web chat uses Spanish-language phrases that are listed in the es.json file, and uses the DD-MM-YYYY format for dates instead of MM-DD-YYYY.\n\nThe locale you specify for the web chat does not impact the syntax of dates and times that are returned by the underlying skill.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basics"},{"document_id":"ibmcld_02839-1790-3940","score":25.5866110746,"text":"\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n3. Create the skill.\n4. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_02855-19323-21142","score":25.5101008698,"text":"\nintegrationID: 'YOUR_INTEGRATION_ID',\nregion: 'YOUR_REGION',\nserviceInstanceID: 'YOUR_SERVICE_INSTANCE',\nonLoad: function(instance) {\ninstance.updateUserID(L12345);\ninstance.render();\n}\n};\nsetTimeout(function(){\nconst t=document.createElement('script');\nt.src=\"https:\/\/web-chat.global.assistant.watson.appdomain.cloud\/loadWatsonAssistantChat.js\";\ndocument.head.appendChild(t);\n});\n<\/script>\nShow more\n\n\n\n\n\n\n\n Global audience support \n\nThe underlying skills understand customer messages that are written in any of the languages that are supported by the service. For more information, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support). The responses from your assistant are defined by you in the underlying skill and can be written in any language you want.\n\nEven if your skill includes responses in a language other than English, some of the phrases that are displayed in the web chat widget are added by the web chat itself and do not come from the underlying skill. These hardcoded phrases are specified in English unless you choose to apply a different language.\n\nThere are language files that contain translations of each English-language phrase that is used by the web chat. You can instruct the web chat to use one of these other languages files by using the instance.updateLanguagePack() method.\n\nLikewise, the web chat applies an American English locale to content that is added by the web chat unless you specify something else. The locale setting affects how values such as dates and times are formatted.\n\nTo configure the web chat for customers outside the US, follow these steps:\n\n\n\n1. To apply the appropriate syntax to dates and times and to use a translation of the English-language phrases, set the locale. Use the instance.updateLocale() method.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_02839-7-2335","score":25.0985413893,"text":"\nAdding support for global audiences \n\nYour customers come from all around the globe. You need an assistant that can talk to them in their own language and in a familiar style. Choose the approach that best fits your business needs.\n\n\n\n* Quickest solution: The simplest way to add language support is to author the conversational skill in a single language. You can translate each message that is sent to your assistant from the customer's local language to the skill language. Later you can translate each response from the skill language back to the customer's local language.\n\nThis approach simplifies the process of authoring and maintaining the conversational skill. You can build one skill and use it for all languages. However, the intention and meaning of the customer message can be lost in the translation.\n\nFor more information about webhooks you can use for translation, see [Webhook overview](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-webhook-overview).\n* Most precise solution: If you have the time and resources, the best user experience can be achieved when you build multiple conversational skills, one for each language that you want to support. Watson Assistant has built-in support for all languages. Use one of 13 language-specific models or the universal model, which adapts to any other language you want to support.\n\nWhen you build a skill that is dedicated to a language, a language-specific classifier model is used by the skill. The precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_03120-1659-3917","score":25.050903616,"text":"\nThe precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\nFor example, use the web chat integration with your French-speaking assistant to deploy to a French-language page on your website. Deploy your German-speaking assistant to the German page of your website. Maybe you have a support phone number for French customers. You can configure your French-speaking assistant to answer those calls, and configure another phone number that German customers can use.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_03353-4-2000","score":24.5702123059,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Supported languages \n\nWatson Assistant supports individual features to varying degrees per language.\n\nWatson Assistant has classifier models that are designed specifically to support conversational skills in the following languages:\n\n\n\nTable 1. Supported languages\n\n Language Language code \n\n Arabic ar \n Chinese (Simplified) zh-cn \n Chinese (Traditional) zh-tw \n Czech cs \n Dutch nl \n English en-us \n French fr \n German de \n Italian it \n Japanese ja \n Korean ko \n Portuguese (Brazilian) pt-br \n Spanish es \n Universal* xx \n\n\n\n* If you want to support conversations in a language for which Watson Assistant doesn't have a dedicated model, such as Russian, use the Universal language model. For more information, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language).\n\n\n\n Feature support details \n\nThe following tables illustrate the level of language support available for product features.\n\nIn the following tables, the level of language and feature support is indicated by these codes:\n\n\n\n* GA: The feature is generally available and supported for this language. Note that features might continue to be updated even after they are generally available.\n* Beta: The feature is supported only as a Beta release, and is still undergoing testing before it is made generally available in this language.\n* NA: Indicates that a feature is not available in this language.\n\n\n\n\n\n Skill support details \n\n\n\nTable 2. Skill support details\n\n Language [Actions skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-actions-add) [Dialog skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add) [Search skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add) \n\n English (en) GA GA GA \n Arabic (ar) GA GA GA","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03373-7076-8670","score":17.3458633508,"text":"\nYou can then create a collection from a data source and configure your search skill to search this collection for answers to customer queries.\n\nThe following diagram illustrates how user input is processed when both a dialog skill and a search skill are added to an assistant. Any questions that the dialog is not designed to answer are sent to the search skill, which finds a relevant response from a Discovery data collection.\n\n![Diagram of how a question gets routed to the search skill.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/search-skill-diagram.png)\n\n\n\n\n\n Creating a skill \n\nYou can add one conversation skill (actions or dialog) and one search skill to an assistant.\n\n\n\n Conversation \n\n\n\n* [Actions skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-actions-add)\n* [Dialog Skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add)\n\n\n\n\n\n\n\n Search \n\n\n\n* [Search Skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add)\n\n\n\n\n\n\n\n\n\n Skill limits \n\nThe number of skills you can create depends on your Watson Assistant plan type. Any sample dialog skills that are available for you to use do not count toward your limit unless you use them. A skill version does not count as a skill.\n\n\n\nPlan details\n\n Plan Maximum number of skills of each type per service instance \n\n Enterprise 100 \n Premium (legacy) 100 \n Plus 50 \n Standard (legacy) 20 \n Lite, Trial 5 \n\n\n\n* After 30 days of inactivity, an unused skill in a Lite plan service instance might be deleted to free up space.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add"},{"document_id":"ibmcld_16364-158662-160553","score":16.8683585837,"text":"\nDialog node limit changes\n: The dialog node limit was temporarily changed from 100,000 to 500 for new Standard plan instances. This limit change was later reversed. If you created a Standard plan instance during the time frame in which the limit was in effect, your dialogs might be impacted. The limit was in effect for skills created between 10 December and 12 December 2018. The lower limits will be removed from all impacted instances in January. If you need to have the lower limit lifted before then, open a support ticket.\n\n\n\n\n\n 1 December 2018 \n\nDetermine the number of dialog nodes\n: To determine the number of dialog nodes in a dialog skill, do one of the following things:\n\n\n\n* From the tool, if it is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant. The trained data section lists the number of dialog nodes.\n* Send a GET request to the \/dialog_nodes API endpoint, and include the include_count=true parameter. For example:\n\ncurl -u \"apikey:{apikey}\" \"https:\/\/{service-hostname}\/assistant\/api\/v1\/workspaces\/{workspace_id}\/dialog_nodes?version=2018-09-20&include_count=true\"\n\nwhere {service-hostname} is the appropriate URL for your instance. For more details, see [Service endpoint](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1service-endpoint).\n\nIn the response, the total attribute in the pagination object contains the number of dialog nodes.\n\nSee [Troubleshooting skill import issues](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-addskill-dialog-add-import-errors) for information about how to edit skills that you want to continue using.\n\n\n\n\n\n\n\n 27 November 2018 \n\nA new service plan, the Plus plan, is available\n: The new plan offers premium-level features at a lower price point. Unlike previous plans, the Plus plan is a user-based billing plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03112-5424-6783","score":16.390143901,"text":"\n},\n'skills': {\n'main skill': {\n'user_defined': {\n'account_number': '123456'\n}\n}\n}\n}\n).get_result()\n\nprint(json.dumps(response, indent=2))\n\nservice\n.message({\nassistant_id: '{assistant_id}',\nsession_id: '{session_id}',\ninput: {\nmessage_type: 'text',\ntext: 'Hello',\noptions: {\n'return_context': true\n}\n},\ncontext: {\n'global': {\n'system': {\n'user_id': 'my_user_id'\n}\n},\n'skills': {\n'main skill': {\n'user_defined': {\n'account_number': '123456'\n}\n}\n}\n}\n})\n.then(res => {\nconsole.log(JSON.stringify(res, null, 2));\n})\n.catch(err => {\nconsole.log(err);\n});\n\nIn this example request, the application specifies a value for user_id as part of the global context. In addition, it sets one user-defined context variable (account_number) as part of the skill-specific context. This context variable can be accessed by dialog nodes as $account_number. (For more information about using the context in your dialog, see [How the dialog is processed](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime).)\n\nYou can specify any variable name you want to use for a user-defined context variable. If the specified variable already exists, it is overwritten with the new value; if not, a new variable is added to the context.\n\nThe output from this request includes not only the usual output, but also the context, showing that the specified values have been added.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-client-get-context"},{"document_id":"ibmcld_03120-1659-3917","score":16.2746447713,"text":"\nThe precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\nFor example, use the web chat integration with your French-speaking assistant to deploy to a French-language page on your website. Deploy your German-speaking assistant to the German page of your website. Maybe you have a support phone number for French customers. You can configure your French-speaking assistant to answer those calls, and configure another phone number that German customers can use.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_03119-7-1688","score":16.2589914059,"text":"\nCreating an assistant \n\nCreate an assistant with the skills it needs to address the business goals of your customers.\n\nTo learn more about what an assistant is first, see [Assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants).\n\nFollow these steps to create an assistant:\n\n\n\n1. Click the Assistants icon ![Assistants menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/nav-ass-icon.png).\n2. Click Create assistant.\n3. Add details about the new assistant:\n\n\n\n* Name: A name no more than 100 characters in length. A name is required.\n* Description: An optional description no more than 200 characters in length.\n\n\n\n4. Click Create assistant.\n5. Add a skill to the assistant.\n\nNote: You can choose to add an existing skill or create a new one.\n\nSee [Adding a skill to an assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add).\n\n\n\n\n\n Assistant limits \n\nThe number of assistants you can create depends on your Watson Assistant [plan type](https:\/\/www.ibm.com\/products\/watson-assistant\/pricing\/). There is also a limit of 100 assistants per service instance.\n\nAfter 30 days of inactivity, an unused assistant in a Lite plan service instance might be deleted to free up space. See [Changing the inactivity timeout setting](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-settings) for more information on the subject.\n\nYou can connect one skill of each type to your assistant. The number of skills you can build differs depending on the plan you have. See [Skill limits](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-addskill-add-limits) for more details.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add"},{"document_id":"ibmcld_03273-14436-16185","score":16.2255059286,"text":"\nhttps:\/\/{location}.assistant.watson.cloud.ibm.com\/{location}\/{instance-id}\/skills\/{skill-id}\/build\/dialognode={node-id}\n4. Edit the URL by replacing the current {node-id} value with the ID of the node you want to find, and then submit the new URL.\n5. If necessary, highlight the edited URL again, and resubmit it.\n\n\n\nThe page refreshes, and shifts focus to the dialog node with the node ID that you specified. If the node ID is for a slot, a Found or Not found slot condition, a slot handler, or a conditional response, then the node in which the slot or conditional response is defined gets focus and the corresponding modal is displayed.\n\nIf you still cannot find the node, you can export the dialog skill and use a JSON editor to search the skill JSON file.\n\n\n\n How many nodes are in my dialog? \n\nTo see the number of dialog nodes in a dialog skill, do one of the following things:\n\n\n\n* If it is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant. The trained data section lists the number of dialog nodes.\n* Send a GET request to the \/dialog_nodes API endpoint, and include the include_count=true parameter. For example:\n\ncurl -u \"apikey:{apikey}\" \"{url}\/v1\/workspaces\/{workspace_id}\/dialog_nodes?version=2018-09-20&include_count=true\"\n\nwhere {url} is the appropriate URL for your instance. For more details, see [Service endpoint](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1service-endpoint).\n\nIn the response, the total attribute in the pagination object contains the number of dialog nodes.\n\n\n\nIf the total seems larger than you expected, it might be because the dialog that you build from the application is translated into a JSON object.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks"},{"document_id":"ibmcld_03369-121126-122848","score":15.8471981033,"text":"\n: You can now create Watson Assistant service instances that are hosted in the London data center without syndication. See [Data centers](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-services-informationservices-information-regions) for more details.\n\nDialog node limit changes\n: The dialog node limit was temporarily changed from 100,000 to 500 for new Standard plan instances. This limit change was later reversed. If you created a Standard plan instance during the time frame in which the limit was in effect, your dialogs might be impacted. The limit was in effect for skills created between 10 December and 12 December 2018. The lower limits will be removed from all impacted instances in January. If you need to have the lower limit lifted before then, open a support ticket.\n\n\n\n\n\n 1 December 2018 \n\nDetermine the number of dialog nodes\n: To determine the number of dialog nodes in a dialog skill, do one of the following things:\n\n\n\n* From the tool, if it is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant. The trained data section lists the number of dialog nodes.\n* Send a GET request to the \/dialog_nodes API endpoint, and include the include_count=true parameter. For example:\n\ncurl -u \"apikey:{apikey}\" \"https:\/\/{service-hostname}\/assistant\/api\/v1\/workspaces\/{workspace_id}\/dialog_nodes?version=2018-09-20&include_count=true\"\n\nwhere {service-hostname} is the appropriate URL for your instance. For more details, see [Service endpoint](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1service-endpoint).\n\nIn the response, the total attribute in the pagination object contains the number of dialog nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_16364-147609-149563","score":15.7646931688,"text":"\nAll workspaces that you create by using the API are displayed as dialog skills when you open the user interface.\n\n\n\n\n\n 23 July 2019 \n\nDialog search is fixed\n: In some skills, the search function was not working in the Dialog page. The issue is now fixed.\n\n\n\n\n\n 17 July 2019 \n\nDisambiguation choice limit\n: You can now set the maximum number of options to show to users when the assistant asks them to clarify what they want to do. For more information about disambiguation, see [Disambiguation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-disambiguation).\n\nDialog search issue\n: In some skills, the search function is not working in the Dialog page. A new user interface library, which increases the page responsiveness, is being rolled out to existing service instances in phases. This search issue affects only dialog skills for which the new library is not yet enabled.\n\nMissing skills issue\n: In some cases, workspaces that were created through the API only are not being displayed when you open the Watson Assistant user interface. Normally, these workspaces are displayed as dialog skills. If you do not see your skills from the UI, don't worry; they are not gone. Contact support to report the issue, so the team can enable the workspaces to be displayed properly.\n\n\n\n\n\n 15 July 2019 \n\nNumeric system entities upgrade available in Dallas\n: The new system entities are now also available as a beta feature for instances that are hosted in Dallas. See [New system entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 12 June 2019 \n\nNumeric system entities upgrade\n: New system entities are available as a beta feature that you can enable in dialog skills that are written in English or German. The revised system entities offer better date and time understanding. They can recognize date and number spans, national holiday references, and classify mentions with more precision.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03112-4463-5613","score":15.7621644253,"text":"\nMap<String, Object> userDefinedContext = new HashMap<>();\nuserDefinedContext.put(\"account_number\",\"123456\");\nMessageContextSkill mainSkillContext = new MessageContextSkill.Builder()\n.userDefined(userDefinedContext)\n.build();\nMap<String, MessageContextSkill> skillsContext = new HashMap<>();\nskillsContext.put(\"main skill\", mainSkillContext);\n\nMessageContext context = new MessageContext.Builder()\n.global(globalContext)\n.skills(skillsContext)\n.build();\n\nMessageOptions options = new MessageOptions.Builder()\n.assistantId(\"{assistant_id}\")\n.sessionId(\"{session_id}\")\n.input(input)\n.context(context)\n.build();\n\nMessageResponse response = service.message(options).execute().getResult();\n\nSystem.out.println(response);\n\nShow more\n\nresponse=service.message(\nassistant_id='{assistant_id}',\nsession_id='{session_id}',\ninput={\n'message_type': 'text',\n'text': 'Hello',\n'options': {\n'return_context': True\n}\n},\ncontext={\n'global': {\n'system': {\n'user_id': 'my_user_id'\n}\n},\n'skills': {\n'main skill': {\n'user_defined': {\n'account_number': '123456'\n}\n}\n}\n}\n).get_result()\n\nprint(json.dumps(response, indent=2))\n\nservice\n.message({\nassistant_id: '{assistant_id}',","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-client-get-context"},{"document_id":"ibmcld_14600-4888-7036","score":15.7315703141,"text":"\nGateway firewall \n\nDoes your source environment include gateway firewalls such as FortiGate\u00ae, vRAs, or Juniper\u00ae vSRX?\n\nDue to the architectural differences between NSX-V and NSX-T, these aspects might require advanced configuration skills to build the wanted network topology. In some cases, gateway firewalls might be rebuilt with new IP addresses. For example, when the new deployment is in a new IBM Cloud data center or POD. This action requires skills and work effort to reconfigure the related firewalls.\n\nThis is not a key parameter. However, it gives guidance on where more project tasks and skills are required.\n\n\n\n\n\n Distributed firewall \n\nIf you use the NSX-V distributed firewalling feature, the configurations must be migrated to the NSX-T environment. The number and complexity of these rules impact the migration. Depending on the complexity of the rules, some of them can be migrated easily. However, if the rules use vCenter tagging, then they cannot be migrated as-is, as this feature doesn't exist in NSX-T. Consider the usage of a third-party tool for a large number or complex use of distributed firewall.\n\nThis is a key parameter and also gives guidance on where more project tasks, tools, and skills are required.\n\n\n\n\n\n Load balancing \n\nThe use of load-balancers number and the complexity of the rules impact the migration of the VMs. Due to the architectural differences between NSX-V and NSX-T, these aspects might require advanced configuration skills to build the wanted load-balancing solution.\n\nThis is not a key parameter. However, it gives guidance on where more project tasks and skills are required.\n\n\n\n\n\n Additional services \n\nThe optional vCenter server instance services, such as Veeam or Zerto are linked to your vCenter server instance. By deleting the source vCenter Server instance, these services are deleted, and so are your historical backups. Additional work effort is required to reconfigure the services or migrate configurations post the automated deployment. This action is done to match your needs and requirements in the new target NSX-T based vCenter Server instance.\n\nThis is not a key parameter.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-v2t-complexity"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09229-16048-18016","score":16.6734018136,"text":"\nen-th English (en) Thai (th) general \n en-tr English (en) Turkish (tr) general \n en-uk English (en) Ukrainian (uk) general \n en-ur English (en) Urdu (ur) general \n en-vi English (en) Vietnamese (vi) general \n en-zh English (en) Simplified Chinese (zh) general \n en-zh-TW English (en) Traditional Chinese (zh-TW) general \n\n\n\n\n\n\n\n Estonian \n\nThe following Estonian translation model can be customized.\n\n\n\nTable 15. Estonian translation model\n\n Model ID Source Target Domain \n\n et-en Estonian (et) English (en) general \n\n\n\n\n\n\n\n Finnish \n\nThe following Finnish translation model can be customized.\n\n\n\nTable 16. Finnish translation model\n\n Model ID Source Target Domain \n\n fi-en Finnish (fi) English (en) general \n\n\n\n\n\n\n\n French \n\nThe following French translation model can be customized.\n\n\n\nTable 17. French translation model\n\n Model ID Source Target Domain \n\n fr-en French (fr) English (en) general \n\n\n\n\n\n\n\n French (Canadian) \n\nThe following French (Canadian) translation model can be customized.\n\n\n\nTable 18. Canadian French translation model\n\n Model ID Source Target Domain \n\n fr-CA-en Canadian French (fr-CA) English (en) general \n\n\n\n\n\n\n\n German \n\nThe following German translation models can be customized.\n\n\n\nTable 19. German translation models\n\n Model ID Source Target Domain \n\n de-en German (de) English (en) general \n de-fr German (de) French (fr) general \n de-it German (de) Italian (it) general \n\n\n\n\n\n\n\n Greek \n\nThe following Greek translation model can be customized.\n\n\n\nTable 20. Greek translation model\n\n Model ID Source Target Domain \n\n el-en Greek (el) English (en) general \n\n\n\n\n\n\n\n Gujarati \n\nThe following Gujarati translation model can be customized.\n\n\n\nTable 21. Gujarati translation model\n\n Model ID Source Target Domain \n\n gu-en Gujarati (gu) English (en) general \n\n\n\n\n\n\n\n Hebrew \n\nThe following Hebrew translation model can be customized.\n\n\n\nTable 22. Hebrew translation model\n\n Model ID Source Target Domain \n\n he-en Hebrew (he) English (en) general","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-translation-models"},{"document_id":"ibmcld_09229-17595-19748","score":16.5780009137,"text":"\nel-en Greek (el) English (en) general \n\n\n\n\n\n\n\n Gujarati \n\nThe following Gujarati translation model can be customized.\n\n\n\nTable 21. Gujarati translation model\n\n Model ID Source Target Domain \n\n gu-en Gujarati (gu) English (en) general \n\n\n\n\n\n\n\n Hebrew \n\nThe following Hebrew translation model can be customized.\n\n\n\nTable 22. Hebrew translation model\n\n Model ID Source Target Domain \n\n he-en Hebrew (he) English (en) general \n\n\n\n\n\n\n\n Hindi \n\nThe following Hindi translation model can be customized.\n\n\n\nTable 23. Hindi translation model\n\n Model ID Source Target Domain \n\n hi-en Hindi (hi) English (en) general \n\n\n\n\n\n\n\n Hungarian \n\nThe following Hungarian translation model can be customized.\n\n\n\nTable 24. Hungarian translation model\n\n Model ID Source Target Domain \n\n hu-en Hungarian (hu) English (en) general \n\n\n\n\n\n\n\n Indonesian \n\nThe following Indonesian translation model can be customized.\n\n\n\nTable 25. Indonesian translation model\n\n Model ID Source Target Domain \n\n id-en Indonesian (id) English (en) general \n\n\n\n\n\n\n\n Irish \n\nThe following Irish translation model can be customized.\n\n\n\nTable 26. Irish translation model\n\n Model ID Source Target Domain \n\n ga-en Irish (ga) English (en) general \n\n\n\n\n\n\n\n Italian \n\nThe following Italian translation models can be customized.\n\n\n\nTable 27. Italian translation models\n\n Model ID Source Target Domain \n\n it-de Italian (it) German (de) general \n it-en Italian (it) English (en) general \n\n\n\n\n\n\n\n Japanese \n\nThe following Japanese translation model can be customized.\n\n\n\nTable 28. Japanese translation model\n\n Model ID Source Target Domain \n\n ja-en Japanese (ja) English (en) general \n\n\n\n\n\n\n\n Kannada \n\nThe following Kannada translation model can be customized.\n\n\n\nTable 29. Kannada translation model\n\n Model ID Source Target Domain \n\n kn-en Kannada (kn) English (en) general \n\n\n\n\n\n\n\n Korean \n\nThe following Korean translation model can be customized.\n\n\n\nTable 30. Korean translation model\n\n Model ID Source Target Domain \n\n ko-en Korean (ko) English (en) general \n\n\n\n\n\n\n\n Latvian \n\nThe following Latvian translation model can be customized.\n\n\n\nTable 31. Latvian translation model\n\n Model ID Source Target Domain","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-translation-models"},{"document_id":"ibmcld_09226-18248-20249","score":15.9509349725,"text":"\n* English to and from Slovenian (en-sl and sl-en)\n\n\n\nNew identifiable languages\n: The following languages can now be identified by the service:\n\n\n\n* Catalan (ca)\n* Croatian (hr)\n* Irish (ga)\n* Malay (ms)\n* Maltese (mt)\n* Serbian (sr)\n* Slovenian (sl)\n* Thai (th)\n\n\n\n\n\n\n\n 14 June 2019 \n\nNew translation models\n: New translation models are now available for English and Greek:\n\n\n\n* English to Greek (en-el)\n* Greek to English (el-en)\n\n\n\n\n\n\n\n 13 June 2019 \n\nNew translation models\n: New translation models are now available for English and Hebrew:\n\n\n\n* English to Hebrew (en-he)\n* Hebrew to English (he-en)\n\n\n\n\n\n\n\n 21 March 2019 \n\nChanges to service credential information\n: From March 21 2019, you will see only service credential information associated with the role that has been assigned to your IBM Cloud account. For example, if you have assigned a reader role, any writer or higher levels of service credentials will not be visible.\n\nThis change does not affect API access for users or applications with existing service key credentials. Only the viewing of credentials within IBM Cloud is affected.\n\nFor more information about service keys and user roles, see [Authenticating to Watson services](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-iam).\n\n\n\n\n\n 14 December 2018 \n\nNew London location\n: You can now create Language Translator service instances in the IBM Cloud London location.\n\n\n\n\n\n 16 November 2018 \n\nNew beta support for document translation\n: [Translating documents](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-document-translator-tutorial) is now available through new API endpoints. Submit a Microsoft Office document, PDF, or other document with a supported file format, and Language Translator will provide a translated copy that preserves the original formatting. [Supported file formats](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-document-translator-tutorialsupported-file-formats) include .doc, .ppt, .pdf, and more.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-release-notes"},{"document_id":"ibmcld_16460-9978-11758","score":14.2458124326,"text":"\nThe following types are supported:<br><br><br><br> * adjective<br> * adposition<br> * adverb<br> * conjunction<br> * determiner<br> * interjection<br> * noun<br> * numeral<br> * pronoun<br> * residual<br> * verb<br><br><br> \n Lemma Must have the same lemma as this token. \n Character Type Must have the same character type as this token. The following types are supported:<br><br><br><br> * Arabic: Contains a sequence of Arabic characters<br> * ChineseNumeral: Contains only Chinese numerals<br> * ClauseEndingPunctuation: Punctuation characters that separate one clause or sentence from the next<br> * Han: Contains Han characters<br> * Hangul: Contains Korean Hangul syllabic characters<br> * Hebrew: Contains a sequence of Hebrew characters<br> * Hiragana: Contains Japanese Hiragana syllabic characters<br> * Ideographic: Contains an ideogram, or symbol representing an idea or thing<br> * Katakana: Contains Japanese Katakana syllabic characters<br> * Lowercase: Contains only lower case alphabetic characters<br> * Numeric: Contains only numeric characters<br> * Punctuation: One or more characters that provide punctuation in the text<br> * Syllabic: Contains syllabic characters<br> * Thai: Contains Thai characters<br> * Titlecase: Starts with a single upper case alphabetic character, followed by one or more lower case alphabetic characters<br> * Uppercase: A token containing only upper case alphabetic characters<br><br><br> \n\n\n\n* Rule Match:\n\nTable 4. Rule matching\n\n\n\n Setting option Description \n\n Rule Match Must match the named class. Remember, a class can be derived from a regex, a dictionary, or a rule. If the class specified here was derived from a regular expression, for example, then this token must match the search pattern of the expression. \n\n\n\n\n\n11.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_rule_creation"},{"document_id":"ibmcld_16542-9963-11743","score":14.2458124326,"text":"\nThe following types are supported:<br><br><br><br> * adjective<br> * adposition<br> * adverb<br> * conjunction<br> * determiner<br> * interjection<br> * noun<br> * numeral<br> * pronoun<br> * residual<br> * verb<br><br><br> \n Lemma Must have the same lemma as this token. \n Character Type Must have the same character type as this token. The following types are supported:<br><br><br><br> * Arabic: Contains a sequence of Arabic characters<br> * ChineseNumeral: Contains only Chinese numerals<br> * ClauseEndingPunctuation: Punctuation characters that separate one clause or sentence from the next<br> * Han: Contains Han characters<br> * Hangul: Contains Korean Hangul syllabic characters<br> * Hebrew: Contains a sequence of Hebrew characters<br> * Hiragana: Contains Japanese Hiragana syllabic characters<br> * Ideographic: Contains an ideogram, or symbol representing an idea or thing<br> * Katakana: Contains Japanese Katakana syllabic characters<br> * Lowercase: Contains only lower case alphabetic characters<br> * Numeric: Contains only numeric characters<br> * Punctuation: One or more characters that provide punctuation in the text<br> * Syllabic: Contains syllabic characters<br> * Thai: Contains Thai characters<br> * Titlecase: Starts with a single upper case alphabetic character, followed by one or more lower case alphabetic characters<br> * Uppercase: A token containing only upper case alphabetic characters<br><br><br> \n\n\n\n* Rule Match:\n\nTable 4. Rule matching\n\n\n\n Setting option Description \n\n Rule Match Must match the named class. Remember, a class can be derived from a regex, a dictionary, or a rule. If the class specified here was derived from a regular expression, for example, then this token must match the search pattern of the expression. \n\n\n\n\n\n11.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_rule_creation"},{"document_id":"ibmcld_16460-10316-12439","score":13.9486207292,"text":"\nThe following types are supported:<br><br><br><br> * Arabic: Contains a sequence of Arabic characters<br> * ChineseNumeral: Contains only Chinese numerals<br> * ClauseEndingPunctuation: Punctuation characters that separate one clause or sentence from the next<br> * Han: Contains Han characters<br> * Hangul: Contains Korean Hangul syllabic characters<br> * Hebrew: Contains a sequence of Hebrew characters<br> * Hiragana: Contains Japanese Hiragana syllabic characters<br> * Ideographic: Contains an ideogram, or symbol representing an idea or thing<br> * Katakana: Contains Japanese Katakana syllabic characters<br> * Lowercase: Contains only lower case alphabetic characters<br> * Numeric: Contains only numeric characters<br> * Punctuation: One or more characters that provide punctuation in the text<br> * Syllabic: Contains syllabic characters<br> * Thai: Contains Thai characters<br> * Titlecase: Starts with a single upper case alphabetic character, followed by one or more lower case alphabetic characters<br> * Uppercase: A token containing only upper case alphabetic characters<br><br><br> \n\n\n\n* Rule Match:\n\nTable 4. Rule matching\n\n\n\n Setting option Description \n\n Rule Match Must match the named class. Remember, a class can be derived from a regex, a dictionary, or a rule. If the class specified here was derived from a regular expression, for example, then this token must match the search pattern of the expression. \n\n\n\n\n\n11. For tokens that have annotations that were added indirectly from a dictionary annotation or regular expression match, you can choose whether the pattern should require any word with the same annotation type or the actual underlying words that were annotated instead.\n\nIn the lower layer of cells, you can see which cells are included in the pattern because a horizontal line connects them to one another. Where an annotation has been applied, there is a split. Cells with the original words are displayed below a cell with the annotation label. You can click one set of cells or the other to change the path of the line, and thus change the cells that are included in the pattern.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_rule_creation"},{"document_id":"ibmcld_16542-10301-12424","score":13.9486207292,"text":"\nThe following types are supported:<br><br><br><br> * Arabic: Contains a sequence of Arabic characters<br> * ChineseNumeral: Contains only Chinese numerals<br> * ClauseEndingPunctuation: Punctuation characters that separate one clause or sentence from the next<br> * Han: Contains Han characters<br> * Hangul: Contains Korean Hangul syllabic characters<br> * Hebrew: Contains a sequence of Hebrew characters<br> * Hiragana: Contains Japanese Hiragana syllabic characters<br> * Ideographic: Contains an ideogram, or symbol representing an idea or thing<br> * Katakana: Contains Japanese Katakana syllabic characters<br> * Lowercase: Contains only lower case alphabetic characters<br> * Numeric: Contains only numeric characters<br> * Punctuation: One or more characters that provide punctuation in the text<br> * Syllabic: Contains syllabic characters<br> * Thai: Contains Thai characters<br> * Titlecase: Starts with a single upper case alphabetic character, followed by one or more lower case alphabetic characters<br> * Uppercase: A token containing only upper case alphabetic characters<br><br><br> \n\n\n\n* Rule Match:\n\nTable 4. Rule matching\n\n\n\n Setting option Description \n\n Rule Match Must match the named class. Remember, a class can be derived from a regex, a dictionary, or a rule. If the class specified here was derived from a regular expression, for example, then this token must match the search pattern of the expression. \n\n\n\n\n\n11. For tokens that have annotations that were added indirectly from a dictionary annotation or regular expression match, you can choose whether the pattern should require any word with the same annotation type or the actual underlying words that were annotated instead.\n\nIn the lower layer of cells, you can see which cells are included in the pattern because a horizontal line connects them to one another. Where an annotation has been applied, there is a split. Cells with the original words are displayed below a cell with the annotation label. You can click one set of cells or the other to change the path of the line, and thus change the cells that are included in the pattern.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_rule_creation"},{"document_id":"ibmcld_07103-9826-12106","score":13.7936734032,"text":"\nThe problems were related to a new version of the optical character recognition (OCR v2) feature that was enabled automatically for English, German, French, Spanish, Dutch, Brazilian Portuguese, and Hebrew collections during that timeframe. The new version changes sentence boundaries in ways that can negatively impact other functions, including element identification in contracts and the document labeling view in the entity extractor tool.\n\nIf you experience any of these issues with documents that were added or processed during this period, revert the version of OCR that is applied to the documents. Starting on 12 November 2022, OCR v1 is applied to all collections where OCR is enabled. To go back to using OCR v1, make a change that will reprocess the affected documents. For example, you can re-add documents that were added during the timeframe to reprocess them. Or you can reprocess an entire collection.\n\nTo reprocess a collection, from the Manage collections page, open the collection, and then go to the Processing settings tab. Expand the More processing settings section, set the OCR switch to Off, and then set it back to On. Click Apply changes and reprocess to reprocess your collection.\n\n\n\n\n\n 2 November 2022 \n\nA new and improved optical character recognition technology is available\n: A new version of optical character recognition technology is now available. This latest version (OCR v2) is used automatically when you enable OCR for English, German, French, Spanish, Dutch, Brazilian Portuguese, and Hebrew collections in all IBM Cloud service plans. The new optical character recognition model was developed by IBM Research to be better at extracting text from scanned documents and other images that have the following limitations:\n\n\n\n* Low quality images due to incorrect scanner settings, insufficient resolution, bad lighting (such as with mobile capture), loss of focus, unaligned pages, and badly printed documents\n* Documents with irregular fonts or a variety of colors, font sizes, and backgrounds\n\n\n\n\n\n\n\n 1 November 2022 \n\nEntity extractor loads the first 40,000 characters from training data documents\n: Even extra long documents from the collection that you use to define custom entity examples are loaded into the document view of the tool.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_07104-32103-34057","score":13.4521147243,"text":"\nFor more information, see [Monitoring usage](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-analyzeapiapi-usage).\n\n\n\n\n\n 30 August 2020 \n\nUpdate to API version\n: The current API version (v2) is now 2020-08-30. The following change was made with this version:\n\nChange to 'options' object\n: The List enrichments method no longer returns the options object per enrichment. Use the Get enrichment method to return the options object for a single enrichment.\n\n\n\n\n\n 2.1.3 release, 19 June 2020 \n\nNew release now available\n: IBM Watson\u00ae Discovery for IBM Cloud Pak\u00ae for Data version 2.1.3 is available.\n: Discovery for Cloud Pak for Data now works with IBM Cloud Pak\u00ae for Data 3.0.1.\n\nNew Finnish and Hebrew language support\n: Added basic support for Finnish and Hebrew. For more information, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n\nChange to Analyze endpoint\n: The Analyze endpoint, which supports stateless document ingestion workflows. For details, see the [Analyze API](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-analyzeapi). The Analyze API supports JSON documents only. Use of the Analyze API affects license usage.\n\nNew options for Content Miner\n: The content mining application includes two new options: Cyclic time scale on the Time series dashboard, and the Contextual view tab.\n\nNew shortcut for Content Mining projects\n: For Content Mining projects only, the Improve and customize page includes a shortcut: the Launch application button. Previously, you were required to open the Integrate and deploy page, select the Launch application tab, and click the Launch button.\n\nImproved segment limit\n: The segment limit when splitting documents has been increased to 1,000. For details, see [Split documents to make query results more succinct](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-split-documents).\n\nImproved Filenet connector","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes-data"},{"document_id":"ibmcld_09903-9624-10554","score":11.9425999146,"text":"\nHebrew [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-entity-type-systems"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03285-34490-35530","score":43.9222240531,"text":"\nIf the assistant is unable to send an SMS message to the caller, a new turn is initiated with the text input vgwSMSFailed. This input indicates that an SMS message could not be sent the caller. You can design your dialog or actions to handle such a failure by creating intents or actions that are triggered by the input text vgwSMSFailed.\n\n{\n\"input\": {\n\"message_type\": \"text\",\n\"text\": \"vgwSMSMessage\"\n},\n\"context\": {\n\"skills\": {\n\"main skill\": {\n\"user_defined\": {\n\"vgwSMSMessage\": \"1545 Lexington Ave.\"\n}\n}\n}\n}\n\n\n\n\n\n Defining a sequence of phone commands \n\nIf you want to run more than one command in succession, include multiple responses in the output.generic array. These commands are processed in the order in which they are specified in the array.\n\nThis example shows two responses: first a text response, followed by an end_session response to end the call.\n\n{\n\"output\": {\n\"generic\": [\n{\n\"values\":\n{\n\"text\": \"Goodbye.\"\n}\n],\n\"response_type\": \"text\",\n\"selection_policy\": \"sequential\"\n},\n{\n\"response_type\": \"end_session\"\n}\n]\n}\n}\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_03218-2635-4110","score":37.5888931697,"text":"\n* [Choosing nodes to disable](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-disambig-choose-nodes)\n* [Disabling disambiguation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-disambig-disable)\n* [Handling none of the above](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-handle-none)\n* [Testing disambiguation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-disambig-test)\n\n\n\nFor information about how disambiguation works with actions skills, see [Disambiguation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-actionsactions-disambiguation).\n\n\n\n Disambiguation example \n\nFor example, you have a dialog that has two nodes with intent conditions that address cancellation requests. The conditions are:\n\n\n\n* eCommerce_Cancel_Product_Order\n* Customer_Care_Cancel_Account\n\n\n\nIf the user input is i must cancel it today, then the following intents might be detected in the input:\n\n[ Shows the top 3 intents recognized in the user input from the Try it out pane.Shows the top 3 intents recognized in the user input from the Try it out pane_.]\n{\"intent\":\"Customer_Care_Cancel_Account\",\"confidence\":0.5602024316787719},\n{\"intent\":\"eCommerce_Cancel_Product_Order\",\"confidence\":0.46903514862060547},\n{\"intent\":\"Customer_Care_Appointments\",\"confidence\":0.29033891558647157},\n{\"intent\":\"General_Greetings\",\"confidence\":0.2894785046577454},","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime"},{"document_id":"ibmcld_02900-23378-25261","score":35.1579735139,"text":"\nIn this example, the eCommerce_Cancel_Product_Order intent has a close confidence score of 46%.As a result, when the user input is i must cancel it today, both dialog nodes are likely to be considered viable candidates to respond. To determine which dialog node to process, the assistant asks the user to pick one. And to help the user choose between them, the assistant provides a short summary of what each node does. The summary text is extracted directly from the external node name information that is specified for each node.!]Notice that your assistant recognizes the term today in the user input as a date, a mention of the @sys-date entity. If your dialog tree contains a node that conditions on the @sys-date entity, then it is also included in the list of disambiguation choices. This image shows it included in the list as the Capture date information option.!]The following video explains the benefits of using disambiguation. A few things have changed since the video was created:<-- <ul> --> * You enable dismabiguation from the Options page instead of a Settings link from the Dialog page. * You can also set a maximum number of options to display in the disambiguation list.<-- <\/ul> --><-- <\/section \"id=\"section-dialog-runtime-disambig-example\" \"> --><-- <section \"id=\"section-dialog-runtime-disambig-enable\" \"> --> Enabling disambiguation To enable disambiguation, complete the following steps:<-- <ol> -->1. From the Skills menu of the dialog skill where you want to enable disabmiguation, click Options.2. On the Disambiguation page, switch the toggle to On.3. In the Disambiguation message field, add text to show before the list of dialog node options. For example, What do you want to do?4. In the Anything else field, add text to display as an additional option that users can pick if none of the other dialog node options reflect what the user wants to do.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime"},{"document_id":"ibmcld_02961-2870-4843","score":34.8669818416,"text":"\nYou can change how someone reacts to your system based simply on how you phrase a response. Changing one line of text can prevent you from having to write multiple lines of code to implement a complex programmatic solution.\n* Back up your skill frequently. See [Downloading a skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-addskill-dialog-add-download).\n\n\n\n\n\n\n\n Tips for capturing information from user input \n\nIt can be difficult to know the syntax to use in your dialog node to accurately capture the information you want to find in the user input. Here are some approaches you can use to address common goals.\n\n\n\n* Returning the user's input: You can capture the exact text uttered by the user and return it in your response. Use the following SpEL expression in a response to repeat the text that the user specified back in the response:\n\nYou said: <? input.text ?>.\n\nIf autocorrection is on, and you want to return the user's original input before it was corrected, you can use <? input.original_text ?>. But, be sure to use a response condition that checks whether the original_text field exists first.\n* Determining the number of words in user input: You can perform any of the supported String methods on the input.text object. For example, you can find out how many words there are in a user utterance by using the following SpEL expression:\n\ninput.text.split(' ').size()\n\nSee [Expression language methods for String](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-methodsdialog-methods-strings) to learn about more methods you can use.\n* Dealing with multiple intents: A user enters input that expresses a wish to complete two separate tasks. I want to open a savings account and apply for a credit card. How does the dialog recognize and address both of them? See the [Compound questions](https:\/\/sodoherty.ai\/2017\/02\/06\/compound-questions\/) entry from Simon O'Doherty's blog for strategies you can try.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tips"},{"document_id":"ibmcld_03026-7-2040","score":34.7522041577,"text":"\nDefining what's irrelevant \n\nTeach your dialog skill to recognize when a user asks about topics that it is not designed to answer.\n\nTo teach your assistant about subjects it should ignore, you can review your user conversation logs to mark utterances that discuss off-topic subjects as irrelevant.\n\nIntents that are marked as irrelevant are saved as counterexamples in the JSON workspace, and are included as part of the training data. They teach your assistant to explicitly not answer utterances of this type.\n\nWhile testing your dialog, you can mark an intent as irrelevant directly from the Try it out pane.\n\n![Mark as irrelevant screen capture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/irrelevant.png)\n\nBe certain before you designate an input as irrelevant.\n\n\n\n* There is no way to access or change the inputs from the user interface later.\n* The only way to reverse the identification of an input as being irrelevant is to use the same input in a test integration channel, and then explicitly assign it to an intent.\n\n\n\nOften there are subjects that you expect customers to ask and that you want your assistant to address eventually, but that you aren't ready to fully implement yet. Instead of adding those topics as counterexamples which can be hard to find later, capture the customer input examples as new intents. But, don't link dialog nodes to the intents until you're ready. If customers ask about one of these topics in the meantime, the anything_else node is triggered to explain that the assistant can't help with the current request, but can help them with other things.\n\n\n\n Irrelevance detection \n\nA new irrelevance detection algorithm was introduced with version 1.5.0. The irrelevance detection model helps your dialog skill recognize subjects that you do not want it to address, even if you haven't explicitly taught it about what to ignore. This enhanced model helps your skill recognize irrelevant inputs earlier in the development process.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-irrelevance-detection"},{"document_id":"ibmcld_03006-3162-5290","score":34.724079119,"text":"\nThe dialog gathers any information it needs to respond or perform a transaction on the user's behalf.\n\nThe dialog can interact with the following resources:\n\n\n\n* Other IBM services: Connect with additional Watson services to analyze user input, such as Speech to Text.\n* Back-end systems: Based on the user's intent and additional information, extract information or perform transactions by interacting with your back-end systems. For example, answer question, open tickets, update account information, or place orders.\n\n\n\n* Any questions that cannot be answered by the dialog skill are sent to the search skill, which finds relevant answers by searching the company knowledge bases that you configure for the purpose. The search skill routes complex customer inquiries to IBM Watson\u00ae Discovery for IBM Cloud Pak\u00ae for Data. Discovery treats the user input as a search query. It finds information that is relevant to the query from the configured data sources and returns it so the assistant can share the information with the user as its response.\n\n\n\n\n\n\n\n Implementation \n\nThis diagram shows the implementation in more detail:\n\n![Flow diagram of the service](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/cp4d-diagram.png)\n\nHere's how you implement your assistant:\n\n\n\n1. Create an assistant.\n2. Create a dialog skill. Use the intuitive graphical tool to define the training data and dialog for the conversation between your assistant and your customers.\n\nThe training data consists of the following artifacts:\n\n\n\n* Intents: Goals that you anticipate your users have when they interact with your assistant. Define one intent for each goal that can be identified in a user's input. For example, you might define an intent that is named store_hours that answers questions about store hours. For each intent, you add sample utterances that reflect the input customers might use to ask for the information they need, such as, What time do you open?\n\nOr use prebuilt content catalogs that are provided by IBM to get started with data that addresses common customer goals.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-index"},{"document_id":"ibmcld_03350-4-2142","score":34.4251384636,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Defining what's irrelevant \n\nTeach your dialog skill to recognize when a user asks about topics that it is not designed to answer.\n\nTo teach your assistant about subjects it should ignore, you can review your user conversation logs to mark utterances that discuss off-topic subjects as irrelevant.\n\nIntents that are marked as irrelevant are saved as counterexamples in the JSON workspace, and are included as part of the training data. They teach your assistant to explicitly not answer utterances of this type.\n\nWhile testing your dialog, you can mark an intent as irrelevant directly from the Try it out pane.\n\n![Mark as irrelevant screen capture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/irrelevant.png)\n\nBe certain before you designate an input as irrelevant.\n\n\n\n* There is no way to access or change the inputs from the user interface later.\n* The only way to reverse the identification of an input as being irrelevant is to use the same input in a test integration channel, and then explicitly assign it to an intent.\n\n\n\nOften there are subjects that you expect customers to ask and that you want your assistant to address eventually, but that you aren't ready to fully implement yet. Instead of adding those topics as counterexamples which can be hard to find later, capture the customer input examples as new intents. But don't link dialog nodes to the intents until you're ready. If customers ask about one of these topics in the meantime, the anything_else node is triggered to explain that the assistant can't help with the current request, but can help them with other things.\n\n\n\n Irrelevance detection \n\nThe irrelevance detection feature helps your dialog skill recognize subjects that you do not want it to address, even if you haven't explicitly taught it about what to ignore. This feature helps your skill recognize irrelevant inputs earlier in the development process.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-irrelevance-detection"},{"document_id":"ibmcld_03069-7-2188","score":34.1879025872,"text":"\nTutorial: Building a complex dialog \n\nIn this tutorial, you will use the Watson Assistant service to create a dialog for an assistant that helps users with inquiries about a fictitious restaurant called Truck Stop Gourmand.\n\n\n\n Learning objectives \n\nBy the time you finish the tutorial, you will understand how to:\n\n\n\n* Plan a dialog\n* Define custom intents\n* Add dialog nodes that can handle your intents\n* Add entities to make your responses more specific\n* Add a pattern entity, and use it in the dialog to find patterns in user input\n* Set and reference context variables\n\n\n\n\n\n Duration \n\nThis tutorial will take approximately 2 to 3 hours to complete.\n\n\n\n\n\n Prerequisite \n\nBefore you begin, complete the [Getting Started tutorial](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started).\n\nYou will use the dialog skill that you created, and add nodes to the simple dialog that you built as part of the getting started exercise.\n\n\n\n\n\n\n\n Step 1: Plan the dialog \n\nYou are building an assistant for a restaurant named Truck Stop Gourmand that has one location and a thriving cake-baking business. You want the simple assistant to answer user questions about the restaurant, its menu, and to cancel customer cake orders. Therefore, you need to create intents that handle inquiries related to the following subjects:\n\n\n\n* Restaurant information\n* Menu details\n* Order cancellations\n\n\n\nYou'll start by creating intents that represent these subjects, and then build a dialog that responds to user questions about them.\n\n\n\n\n\n Step 2: Answer questions about the restaurant \n\nAdd an intent that recognizes when customers ask for details about the restaurant itself. An intent is the purpose or goal expressed in user input. The General_About_You intent that is provided with the General content catalog serves a similar function, but its user examples are designed to focus on queries about the assistant as opposed to the business that is using the assistant to help its customers. So, you will add your own intent.\n\n\n\n Add the about_restaurant intent \n\n\n\n1. From the Intents tab, click Create intent.\n\n![Shows the the Create intent button on the Intents page.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial"},{"document_id":"ibmcld_03403-4-2208","score":34.1879025872,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Building a complex dialog \n\nIn this tutorial, you will use the Watson Assistant service to create a dialog for an assistant that helps users with inquiries about a fictitious restaurant called Truck Stop Gourmand.\n\n\n\n Learning objectives \n\nBy the time you finish the tutorial, you will understand how to:\n\n\n\n* Plan a dialog\n* Define custom intents\n* Add dialog nodes that can handle your intents\n* Add entities to make your responses more specific\n* Add a pattern entity, and use it in the dialog to find patterns in user input\n* Set and reference context variables\n\n\n\n\n\n Duration \n\nThis tutorial will take approximately 2 to 3 hours to complete.\n\n\n\n\n\n Prerequisite \n\nBefore you begin, complete the [Getting Started tutorial](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-getting-started).\n\nYou will use the dialog skill that you created, and add nodes to the simple dialog that you built as part of the getting started exercise.\n\n\n\n\n\n\n\n Step 1: Plan the dialog \n\nYou are building an assistant for a restaurant named Truck Stop Gourmand that has one location and a thriving cake-baking business. You want the simple assistant to answer user questions about the restaurant, its menu, and to cancel customer cake orders. Therefore, you need to create intents that handle inquiries related to the following subjects:\n\n\n\n* Restaurant information\n* Menu details\n* Order cancellations\n\n\n\nYou'll start by creating intents that represent these subjects, and then build a dialog that responds to user questions about them.\n\n\n\n\n\n Step 2: Answer questions about the restaurant \n\nAdd an intent that recognizes when customers ask for details about the restaurant itself. An intent is the purpose or goal expressed in user input. The General_About_You intent that is provided with the General content catalog serves a similar function, but its user examples are designed to focus on queries about the assistant as opposed to the business that is using the assistant to help its customers. So, you will add your own intent.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial"},{"document_id":"ibmcld_16321-35490-37376","score":34.1529397272,"text":"\nIf no tenantPhoneNumber value is provided, the tenant ID from the phone integration configuration for the active call is used. Optional. \n userPhoneNumber string The phone number to send the SMS message to. The format of the number must match the format that is required by the SMS provider. If no userPhoneNumber value is provided, the voice caller's phone number from From header of the incoming SIP INVITE request is used. Optional. \n\n\n\nIf your SMS integration supports more than one SMS phone number, or you are using a SIP trunk different from your SMS provider, be sure to specify the phone number that you want to use to send the text message. Otherwise, the text is sent using the same phone number that was called.\n\nAfter the assistant receives an SMS message, a new conversation turn is initiated with the text input vgwSMSMessage. This input indicates that a message was received from the caller. The text of the customer's message is included as the value of the vgwSMSMessagecontext variable.\n\nIf the assistant is unable to send an SMS message to the caller, a new turn is initiated with the text input vgwSMSFailed. This input indicates that an SMS message could not be sent the caller. You can design your assistant to handle such a failure by creating actions that are triggered by the input text vgwSMSFailed.\n\n{\n\"input\": {\n\"message_type\": \"text\",\n\"text\": \"vgwSMSMessage\"\n},\n\"context\": {\n\"skills\": {\n\"main skill\": {\n\"user_defined\": {\n\"vgwSMSMessage\": \"1545 Lexington Ave.\"\n}\n}\n}\n}\n\n\n\n\n\n Defining a sequence of phone commands \n\nIf you want to run more than one command in succession, include multiple responses in the generic array. These commands are processed in the order in which they are specified in the array.\n\nThis example shows two responses: first a text response, followed by an end_session response to end the call.\n\n{\n\"generic\": [\n{\n\"response_type\": \"text\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09690-6214-6589","score":13.3920009201,"text":"\nsysdig-agent\tibm-observe\t1 \t2023-03-24 15:02:58.408108 +0100 CET\tdeployed\tsysdig-deploy-1.6.3\n2. Uninstall the chart.\n\nhelm delete sysdig-agent -n ibm-observe\n\nIn terms of Helm, sysdig-agent is the name of teh release.\n\nIf you forget to include the namespace in the command, you get the folloqing error: Error: uninstall: Release not loaded: sysdig-agent: release: not found.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-agent-deploy-kube-helm"},{"document_id":"ibmcld_09691-6211-6586","score":13.3920009201,"text":"\nsysdig-agent\tibm-observe\t1 \t2023-03-24 15:02:58.408108 +0100 CET\tdeployed\tsysdig-deploy-1.6.3\n2. Uninstall the chart.\n\nhelm delete sysdig-agent -n ibm-observe\n\nIn terms of Helm, sysdig-agent is the name of teh release.\n\nIf you forget to include the namespace in the command, you get the folloqing error: Error: uninstall: Release not loaded: sysdig-agent: release: not found.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-agent-deploy-openshift-helm"},{"document_id":"ibmcld_02600-2982-3625","score":12.7668573325,"text":"\n* Do not store an API key in files inside your application's source code control system. If you store API keys in files, keep the files outside of your application's source code. This practice is important if you use a public source-code management system such as GitHub.\n* Regenerate your API keys periodically. You can create new credentials at any time.\n\n\n\n1. From the resource list, select a service instance.\n2. In the navigation list, click Service credentials.\n\n\n\nWhen you migrate your application to the new credentials, don't forget to delete the old credentials by using the trashcan icon for the credentials that you want to delete.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-call_apim_apis"},{"document_id":"ibmcld_00166-17617-18332","score":12.5575041301,"text":"\nThe password is case-sensitive. To recover the data, you must provide the encryption password that was entered when the files were backed up. You can also enter a password hint. When you want to restore data, you can view the password hint to remind you of the encryption password for this job.\n\nIf you forget the encryption password, you lose access to the data. You cannot retrieve the password from the system.\n\n\n\n\n\n\n\n Downloading the user guide \n\nConnect to the IBM Cloud\u00ae network with [IBM Cloud\u00ae VPN](https:\/\/www.ibm.com\/cloud\/vpn-access) so that you can download the user guides from the [Downloadable IBM Cloud Backup for Classic Documentation](http:\/\/downloads.service.softlayer.com\/evault\/Documentation\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Backup?topic=Backup-configureMSSQLBackup"},{"document_id":"ibmcld_02718-4890-5645","score":12.4756728074,"text":"\nSo we've got maybe [Writing] app one here, [Writing] app two, and say a [Writing] web page.\n\nWith a feature flagging service we can actually group these in collections so that we're a little bit more organized with which feature flags are tied to, which apps are web pages.\n\nSo now today we've learned about returning feature flags on and off without deployment testing directly in production, and then segmenting those features based on the user attributes.\n\nThank you for watching. If you have questions, please drop us a line below. If you want to see more videos like this in the future, please like and subscribe. And don't forget, you can grow your skills and earn badges with IBM CloudLabs, which are free browser-based interactive kubernetes labs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-videos"},{"document_id":"ibmcld_07113-3203-3875","score":12.4756728074,"text":"\nFrom the Integrate and Deploy > Preview Link page, follow the instructions to give your team members access to your project. (In Content Mining projects, the page is named Share Link.)\n\nIBM Cloud\n\nFor more information about access in IBM Cloud, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources&interface=ui).\n2. Click the copy icon for the Copy Link field to copy the URL of the preview application.\n3. Paste the URL into a web browser to test it yourself or send the URL to team members.\n\nDon't forget to send any login credentials that are needed to access the project when you send the link to your colleagues.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-test"},{"document_id":"ibmcld_03160-8103-9403","score":11.3647884387,"text":"\nconsole.log(\"ReferTransferTarget: \" + event.ReferTransferTarget);\n\nconst referToSipUriHeaders = event.ReferTransferTarget.split(\"?\")[1];\nconsole.log(referToSipUriHeaders);\nif (referToSipUriHeaders) {\nconst sanitizedReferToSipUriHeaders = referToSipUriHeaders.replace(\">\", \"\");\nconsole.log(\"Custom Headers: \" + sanitizedReferToSipUriHeaders);\n\nconst sipHeadersList = sanitizedReferToSipUriHeaders.split(\"&\");\n\nconst sipHeaders = {};\nfor (const sipHeaderSet of sipHeadersList) {\nconst [name, value] = sipHeaderSet.split('=');\nsipHeaders[name] = value;\n}\n\nconst USER_TO_USER_HEADER = 'User-to-User';\n\n\/\/ Extracts the User-to-User header value\nconst uuiData = sipHeaders[USER_TO_USER_HEADER];\n\nif (uuiData) {\nconst decodedUUIData = decodeURIComponent(uuiData);\nconst sessionHistoryKey = decodedUUIData.split(';')[0];\n\/\/ Passes the session history key back to Twilio Studio through a query parameter.\nstudioWebhookReturnUrl = ${studioWebhookReturnUrl}&SessionHistoryKey=${sessionHistoryKey};\n}\n}\n\nresponse.redirect(\n{ method: 'POST' },\nstudioWebhookReturnUrl\n);\n\n\/\/ This callback is what is returned in response to this function being invoked.\n\/\/ It's really important! E.g. you might respond with TWiML here for a voice or SMS response.\n\/\/ Or you might return JSON data to a studio flow. Don't forget it!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone-flex"},{"document_id":"ibmcld_16289-8198-9498","score":11.3647884387,"text":"\nconsole.log(\"ReferTransferTarget: \" + event.ReferTransferTarget);\n\nconst referToSipUriHeaders = event.ReferTransferTarget.split(\"?\")[1];\nconsole.log(referToSipUriHeaders);\nif (referToSipUriHeaders) {\nconst sanitizedReferToSipUriHeaders = referToSipUriHeaders.replace(\">\", \"\");\nconsole.log(\"Custom Headers: \" + sanitizedReferToSipUriHeaders);\n\nconst sipHeadersList = sanitizedReferToSipUriHeaders.split(\"&\");\n\nconst sipHeaders = {};\nfor (const sipHeaderSet of sipHeadersList) {\nconst [name, value] = sipHeaderSet.split('=');\nsipHeaders[name] = value;\n}\n\nconst USER_TO_USER_HEADER = 'User-to-User';\n\n\/\/ Extracts the User-to-User header value\nconst uuiData = sipHeaders[USER_TO_USER_HEADER];\n\nif (uuiData) {\nconst decodedUUIData = decodeURIComponent(uuiData);\nconst sessionHistoryKey = decodedUUIData.split(';')[0];\n\/\/ Passes the session history key back to Twilio Studio through a query parameter.\nstudioWebhookReturnUrl = ${studioWebhookReturnUrl}&SessionHistoryKey=${sessionHistoryKey};\n}\n}\n\nresponse.redirect(\n{ method: 'POST' },\nstudioWebhookReturnUrl\n);\n\n\/\/ This callback is what is returned in response to this function being invoked.\n\/\/ It's really important! E.g. you might respond with TWiML here for a voice or SMS response.\n\/\/ Or you might return JSON data to a studio flow. Don't forget it!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-flex"},{"document_id":"ibmcld_02332-0-1016","score":11.2977221138,"text":"\n\n\n\n\n\n\n  Updating the classic infrastructure VPN password \n\nYou can update your own VPN password, or in the case where a user forgets their password and can't reset it themselves, another user with correct access can update that user's VPN password.\n\nIf you have the following access, you can update the VPN password for another user:\n\n\n\n*  An IAM policy with the Editor or higher role on the User management service.\n*  You are an ancestor in the classic infrastructure hierarchy for the user and you have the Manage users classic infrastructure permission assigned\n\n\n\nTo update the VPN password, complete the following steps:\n\n\n\n1.  In the IBM Cloud\u00ae console, click Manage > Access (IAM), and select Users.\n2.  Select a user from the list.\n3.  From the User details page, go to the VPN password section.\n4.  Click the Edit icon ![Edit icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_write.svg) to enter a new VPN password.\n5.  Click Update password.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-vpnpassword"},{"document_id":"ibmcld_04695-1381-2386","score":10.727948488,"text":"\n<\/featureManager>\n<\/server>\n2. Set the IBM_LIBERTY_BETA environment variable to true. This variable directs the Liberty buildpack to install and enable the beta features for your app. For example:\n\n\n\n* Using the [IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-install-ibmcloud-cli):\n\nibmcloud cf set-env <yourappname> IBM_LIBERTY_BETA true\n* Or, using the manifest.yml file:\n\nenv:\nIBM_LIBERTY_BETA: \"true\"\n\n\n\n3. Set the JBP_CONFIG_LIBERTY environment variable to \"version: +\". This variable enables the [Liberty monthly runtime](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-buildpack_defautsliberty_versions), which supports beta features. For example:\n\n\n\n* Using the IBM Cloud CLI tool:\n\nibmcloud cf set-env <yourappname> JBP_CONFIG_LIBERTY \"version: +\"\n* Or, using the manifest.yml file:\n\nenv:\nJBP_CONFIG_LIBERTY: \"version: +\"\n\n\n\n\n\nIf you are enabling the beta features on an existing app, don't forget to re-stage your app after you set the environment variables.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-using_beta_features"}],"retriever_scores":{}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00166-17617-18332","score":25.3181890003,"text":"\nThe password is case-sensitive. To recover the data, you must provide the encryption password that was entered when the files were backed up. You can also enter a password hint. When you want to restore data, you can view the password hint to remind you of the encryption password for this job.\n\nIf you forget the encryption password, you lose access to the data. You cannot retrieve the password from the system.\n\n\n\n\n\n\n\n Downloading the user guide \n\nConnect to the IBM Cloud\u00ae network with [IBM Cloud\u00ae VPN](https:\/\/www.ibm.com\/cloud\/vpn-access) so that you can download the user guides from the [Downloadable IBM Cloud Backup for Classic Documentation](http:\/\/downloads.service.softlayer.com\/evault\/Documentation\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Backup?topic=Backup-configureMSSQLBackup"},{"document_id":"ibmcld_00189-1695-3780","score":24.5895191842,"text":"\nClick the Jobs tab.\n4. Find the job with the database that you want to restore. In the job\u2019s Select Action menu, click Restore.\n5. In the Choose how to restore dialog box, select Restore database to an SQL Server instance.\n6. In the Instance list, click the SQL Server instance where you want to restore the database.\n7. Connect to the instance by using one of the following methods.\n\n\n\n* To connect to the instance by using a Windows\u00ae administrator account, select Windows\u00ae authentication. Enter the username, password, and domain in the appropriate fields.\n* To connect to the instance by using an SQL Server administrator account, select SQL Server authentication. Enter the username and password in the appropriate fields.\n\n\n\n8. Click Continue. The SQL Server Restore dialog box shows the most recent safe set for the job.\n9. To restore data from an older safe set, or from SSI (safe set image) files, take one of the following steps.\n\n\n\n* To restore data from an older safe set, click the calendar. In the calendar that appears, click the date of the safe set from which you want to restore. To the right of the calendar, click the specific safe set that you want to use.\n* To restore data from SSI (safe set image) files on disk, select Directory on disk from the Source Device list. Click the folder. In the Select Folder dialog box, select the directory where the files are located, and click Okay.\n\n\n\nSSI files are full backups that were exported from the vault or backed up from a computer to disk instead of to a vault. It can be quicker to save backup files on physical media and transport them to a location for a restore than to restore data from a vault in a remote data center. Note: You cannot restore from backups to disk (SSI files) until the safe set is imported into the vault and the IBM Cloud\u00ae Backup for Classic Agent is synchronized with the vault.\n10. In the Database Selection box, select the checkbox for each database that you want to restore.\n11. In the Encryption Password field, enter the data encryption password. To view the password hint, click Hint.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Backup?topic=Backup-restoreMSSQLDB"},{"document_id":"ibmcld_00119-1275-3294","score":24.3620419049,"text":"\nIt is expected - proceed by sending the form.\n\n\n\n\n\n\n\n Adding a vSphere backup job \n\n\n\n1. On the navigation, click Computers. The computers page shows the registered computers and environments.\n2. Click Jobs.\n3. In the Select job Task menu, click Create New VMware\u00ae vCenter Job.\n4. Specify the following information.\n\n\n\n* In the Name field, type a name for the backup job.\n* In the Description field, optionally type a description for the backup job.\n* In the Destination list, select the vault where you want to save the backup data.\n* In the Password and Confirm Password fields, type an encryption password. You can also type a password hint in the Password Hint field.\n\n\n\nA vault appears in the list only if it is assigned to the user, or if the user added it to the computer\u2019s Vault Settings. For new backup jobs, the encryption method is AES 256 bit. Existing jobs can have other encryption methods.\n5. In the Include in Backup field, take one or more of the following steps until the Backup Set field shows the VMs that you want to include in the backup job.\n\n\n\n* To add specific VMs to the backup job, select each VM, and then click Include.\n* To exclude specific VMs from the backup job, select each VM, and then click Exclude.\n* To add VMs to the backup job by name, check the virtual machines box, and then click Include.\n* To remove an inclusion or exclusion record from the Backup Set box, click Delete next to the record.\n\n\n\n6. Click Apply Now to consolidate and simplify records in the Backup Set box, if changes need to be applied.\n7. Click Create Job.\n\n\n\n\n\n\n\n Setting up a schedule \n\nAfter the backup job is created, you can add one or more schedules for running the job automatically.\n\n\n\n1. When you click Create Job, the Schedule window appears and gives you an option to create a custom schedule for the backup job.\n\nBy default Daily retention is selected for the job. Retention and Job schedule can be changed in this window, and multiple Retention schemes can also be assigned to the backup job.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Backup?topic=Backup-ConfigureVRA"},{"document_id":"ibmcld_00166-15839-18065","score":23.7599218802,"text":"\nThen, you can register a virtual server for the SQL Server role in the Portal and create and run backup jobs on the virtual server. Backup jobs on a virtual server are automatically directed to the active cluster node and do not reseed after a failover.\n\nTo fully protect an SQL Server cluster, you must back up:\n\n\n\n* The quorum disk,\n* Each physical node in the cluster,\n* Cluster volumes,\n* The SQL Server databases to provide point-in-time database recovery.\n\n\n\nWhen a cluster is fully protected, you can recover the cluster if components are lost, are corrupted, or fail.\n\n\n\n\n\n Advanced settings \n\n\n\n Log file options \n\nWhen you create or edit a backup job, you can specify the level of detail for job logging. Select one of the following logging levels from the list.\n\n\n\n* Files - this setting provides the most detailed information, and is typically used for troubleshooting. Provides information about files that are backed up.\n* Directory - This setting provides less detail than the Files logging level. Provides information about folders that are backed up.\n* Summary - This setting provides high-level information, including the vault and IBM Cloud Backup for Classic Agent version, and backup sizes.\n* Minimal - This setting provides high-level information, including the vault and IBM Cloud Backup for Classic Agent version.\n\n\n\nChanging the logging level affects only the log files that are created at that point and after. It does not affect previously created log files.\n\n\n\n\n\n Encryption settings and password \n\nEncryption settings specify the encryption type for backup data at rest on the vault. AES 256-bit encryption is the default encryption type available for new backup jobs. When you create a backup job, you must enter a password for the encrypted data. The password is case-sensitive. To recover the data, you must provide the encryption password that was entered when the files were backed up. You can also enter a password hint. When you want to restore data, you can view the password hint to remind you of the encryption password for this job.\n\nIf you forget the encryption password, you lose access to the data. You cannot retrieve the password from the system.\n\n\n\n\n\n\n\n Downloading the user guide","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Backup?topic=Backup-configureMSSQLBackup"},{"document_id":"ibmcld_00167-5622-7843","score":23.6790487526,"text":"\n* To specify a maximum amount of time that the backup job can run, click Minutes or Hours in the Deferring list. In the adjacent box, type the maximum number of minutes or hours that the job can run.\n\n\n\nWhen you use the deferring option, the backup job doesn't back up any new data after the specified amount of time, even if some data is not backed up. Changes to data that was previously backed up are still backed up, regardless of the amount of time specified.\n8. To run the job on the specified schedule, select the Enable checkbox near the end of the row.\n9. Click Save.\n\n\n\n\n\n\n\n Advanced Settings \n\n\n\n Log file options \n\nWhen you create or edit a backup job, you can specify the level of detail for job logging. Select one of the following levels from the list.\n\n\n\n* Files - this setting provides the most detailed information, and is typically used for troubleshooting. Provides information about files that are backed up.\n* Directory - This setting provides less detail than the Files logging level. Provides information about folders that are backed up.\n* Summary - This setting provides high-level information, including the vault and IBM Cloud Backup for Classic Agent version, and backup sizes.\n* Minimal - This setting provides high-level information, including the vault and IBM Cloud Backup for Classic Agent version.\n\n\n\nChanging the logging level affects only the log files that are created at that point and after. It does not affect previously created log files.\n\n\n\n\n\n Encryption settings and password \n\nEncryption settings specify the encryption type for backup data at rest on the vault. AES 256-bit encryption is the default encryption type that is available for new backup jobs. When you create a backup job, you must enter a password for the encrypted data. The password is case-sensitive. To recover the data, you must provide the encryption password that was entered when the files were backed up.\n\nYou can also enter a password hint. When you want to restore data, you can view the password hint to remind you of the encryption password for this job.\n\nIf you forget the encryption password, you lose access to the data. You cannot retrieve the password from the system.\n\n\n\n\n\n Performance Options","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Backup?topic=Backup-configureOracleBackup"},{"document_id":"ibmcld_00167-7323-9424","score":23.6484902998,"text":"\nWhen you create a backup job, you must enter a password for the encrypted data. The password is case-sensitive. To recover the data, you must provide the encryption password that was entered when the files were backed up.\n\nYou can also enter a password hint. When you want to restore data, you can view the password hint to remind you of the encryption password for this job.\n\nIf you forget the encryption password, you lose access to the data. You cannot retrieve the password from the system.\n\n\n\n\n\n Performance Options \n\nBandwidth throttling settings specify the amount of bandwidth that is used by an IBM Cloud Backup for Classic Agent for backups. For example, you might want to restrict the amount of bandwidth that is used for daytime backups so that online users are not affected. At the same time, you might allow unlimited bandwidth usage at night so that scheduled backups run as fast as possible.\n\nBandwidth settings include the following parameters.\n\n\n\n* Maximum bandwidth, in megabits per second, to be used by the IBM Cloud Backup for Classic Agent for all backups and restores.\n* Length of time during the day that throttling is in effect. Only one time window can be specified. Outside the window, no throttling takes place.\n* Days of the week that throttling is in effect.\n\n\n\nIf the bandwidth-throttling time period begins when a backup is underway, the maximum bandwidth is applied dynamically to the running backup. Similarly, if the bandwidth-throttling time period ends when a backup is running, bandwidth throttling is ended for the backup.\n\nIf you edit an IBM Cloud Backup for Classic Agent\u2019s bandwidth settings while a backup is running, the new settings do not affect the backup that is running. Bandwidth settings are applied when a backup starts, not during its operation.\n\n\n\n\n\n\n\n Downloading the user guide \n\nConnect to the IBM Cloud\u00ae network with [IBM Cloud\u00ae VPN](https:\/\/www.ibm.com\/cloud\/vpn-access) so that you can download the user guides from the [Downloadable IBM Cloud Backup for Classic Documentation](http:\/\/downloads.service.softlayer.com\/evault\/Documentation\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Backup?topic=Backup-configureOracleBackup"},{"document_id":"ibmcld_00162-1301-3205","score":23.5455606453,"text":"\nYou can choose between manual or automatic backup agent configuration methods.\n\n\n\n* The automatic agent configuration creates a backup job of the complete C Drive (Windows\u00ae OS) or .\/<root> directory (Linux\u00ae OS) with Monthly and Daily Retention schemes.\n\nThis job can be modified after it was configured.\n\n\n\n1. Create a password.\n2. Confirm the password.\n3. Add a password hint.\n4. Click Configure automatically.\n\n\n\n* If you choose to configure the IBM Cloud Backup for Classic agent manually, the automatic settings are ignored. Then, you can specify the folders and files to be retained with a retention scheme of your choice.\n\n\n\n1. In the navigation, click Computers, then the expansion arrow to display the information of the selected server.\n2. Click Configure Manually. The vault settings page loads.\n3. Click Add Vault.\n4. Expand the Vault Profile menu, and select the vault. All values auto-populate.\n5. Click Save.\n6. Click the Jobs tab.\n7. From the Select Job Task menu, select Create New Local System Job.\n8. In the Create New Job window, enter a Job Name and a Job Description.\n9. Select the files and folders that you want to include and exclude in the backup. To exclude files, you must add an exclusions record. Select the directory that contains the file that you want to exclude and click Exclude. This action adds the file to the Backup Set with a red minus sign. From here, you can filter out a directory or specific file name from that directory that you want skipped during backup.\n10. Enter the encryption password into the Password and Confirm Password fields. You can also add a Password Hint.\n\nYou need this password to restore files from the backup. Without the password, you can't restore an encrypted backup. Lost password cannot be recovered in any way.\n11. Click Apply now to confirm the backup sets.\n12. You can leave the Advanced Backup Options with their default settings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Backup?topic=Backup-configureFileBackup"},{"document_id":"ibmcld_00189-6588-8692","score":23.5054252236,"text":"\nThe SQL Server Restore dialog shows the most recent safe set for the job.\n7. To restore data from an older safe set, or from SSI (safe set image) files, take one of the following steps.\n\n\n\n* To restore data from an older safe set, click the calendar. In the calendar that appears, click the date of the safe set from which you want to restore. To the right of the calendar, click the specific safe set that you want to use.\n* To restore data from SSI (safe set image) files on disk, select Directory on disk from the Source Device list. Click the folder. In the Select Folder dialog, select the directory where the files are located, and click Okay.\n\n\n\nSSI files are full backups that were exported from the vault or backed up from a computer to disk instead of to a vault. It can be quicker to save backup files on physical media and transport them to a location for a restore than to restore data from a vault in a remote data center. Note: You cannot restore from backups to disk (SSI files) until the safe set is imported into the vault and the IBM Cloud Backup for Classic Agent is synchronized with the vault.\n8. In the Database Selection, select the checkbox for each database that you want to restore.\n9. In the Encryption Password field, enter the data encryption password. To view the password hint, click Hint.\n10. Under Restore Destination, enter a path for the destination, or click the folder. In the Select Folder dialog box, select the location where you want to restore, and click Okay.\n11. To change the log detail level, bandwidth throttling setting, or hard recovery option, click Advanced Restore Options. In the dialog box, you can select the options:\n\n\n\n* In the Log Level Detail list, select the level of detail for job logging.\n* Select or clear the Use all available bandwidth option.\n\n\n\n12. Click Run Restore. The Process Details dialog shows the restore progress and indicates when the restore is completed. Other recent job processes might also be listed in the dialog. To close the Process Details screen, click Close. Closing the window does not affect the restore process.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Backup?topic=Backup-restoreMSSQLDB"},{"document_id":"ibmcld_00166-4315-6272","score":23.1328539754,"text":"\nA vault appears in the list if it is assigned to the user, or if the user added it in the computer\u2019s Vault Settings.\n* In the Log File Options list, select the level of detail for job logging. For more information, see [Log file options](https:\/\/cloud.ibm.com\/docs\/Backup?topic=Backup-configureMSSQLBackupSQLDBLogfile).\n* For new backup jobs, the encryption method is AES 256 bit. Existing jobs can have other encryption methods. For more information, see [Encryption settings](https:\/\/cloud.ibm.com\/docs\/Backup?topic=Backup-configureMSSQLBackupSQLDBEncrypt).\n* In the Password and Confirm Password boxes, enter an encryption password. You can also enter a password hint in the Password Hint box.\n\n\n\n8. In the Select Databases for Backup box, select the database that you want to back up.\n\n\n\n* To add specific databases to the backup job, select the checkbox for each database, and then click Include. The included databases appear in the Backup Set box.\n* To back up all databases in the selected SQL Server instance, select the checkbox for the instance, and then click Include. The included instances appear in the Backup Set box.\n\n\n\nWhen the job runs, newly added databases in the selected instance are automatically backed up.\n\n\n\n* To back up databases with names that match a filter when the job runs, select the checkbox for the SQL Server instance, and then click Include. An inclusion record with an asterisk () appears in the Backup Set box. In the Database Filter box, enter the names of databases to include. Separate multiple names with commas, and use asterisks () and question marks (?) as wildcard characters. Filters are applied when the backup job runs. New databases that match the specified filters are automatically backed up when the job runs.\n\n\n\nFor example, to back up databases with names that end with \u201cManagement\u201d or include the word \u201cdatabase\u201d followed by a single character, enter the following filter: management, database?.\n9.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Backup?topic=Backup-configureMSSQLBackup"},{"document_id":"ibmcld_00167-2738-4540","score":23.0785782352,"text":"\nIn the Connect to Oracle Server dialog box, provide the following information.\n\n\n\n* In the Database Service Name box, type the database instance.\n* In the username box, type the name of a user who has sysdba privileges.\n* In the Password box, type the password for the specified user.\n\n\n\n6. Click Connect.\n7. In the Create New Job dialog box, specify the following information.\n\n\n\n* In the Name box, type a name for the backup job.\n* In the Description box, type a description for the backup job. The description is optional.\n* In the Destination list, select the vault where you want to save the backup data.\n\nA vault appears in the list if it is assigned to the user, or if the user added it in the computer\u2019s Vault Settings.\n* In the Log File Options list, select the level of detail for job logging. For more information, see [log file options](https:\/\/cloud.ibm.com\/docs\/Backup?topic=Backup-configureOracleBackupODBLogfile).\n* For new backup jobs, the encryption method is AES 256 bit. Existing jobs can have other encryption methods. For more information, see [encryption settings](https:\/\/cloud.ibm.com\/docs\/Backup?topic=Backup-configureOracleBackupODBEncrypt).\n* In the Password and Confirm Password boxes, enter an encryption password. You can also enter a password hint in the Password Hint box.\n\n\n\n8. In the Include in Backup box, select the database that you want to back up.\n9. Click Save. The job is now created, and the View\/Add Schedule dialog box appears. Next, you can create a schedule for running the backup. Click Cancel if you don't want to create a schedule now.\n\n\n\n\n\n\n\n Scheduling the backup job \n\n\n\n1. In the View\/Add Schedule dialog box, click Add Schedule.\n2. In the new schedule row, in the Retention list, click a retention type.\n3. In the Schedule box, click the arrow.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Backup?topic=Backup-configureOracleBackup"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09120-94597-96242","score":9.3397685255,"text":"\nA unique, human readable name for the key-ring. Required if the user doesn't have permissions on the default key ring.\n\n\n\n\n\n\n\n\n\n kp key schedule-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-referencekp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID_OR_ALIAS\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID_OR_ALIAS --output json\n\n[\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference"},{"document_id":"ibmcld_08988-95785-97389","score":9.3383511797,"text":"\nA unique, human readable name for the key-ring. Required if the user doesn't have permissions on the default key ring.\n\n\n\n\n\n\n\n\n\n kp key schedule-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-referencekp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID_OR_ALIAS\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-reference"},{"document_id":"ibmcld_04488-93746-95375","score":9.3324969525,"text":"\nA unique, human readable name for the key-ring. Required if the user doesn't have permissions on the default key ring.\n\n\n\n\n\n\n\n\n\n kp key schedule-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-referencekp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID_OR_ALIAS\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID_OR_ALIAS --output json\n\n[\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-reference"},{"document_id":"ibmcld_09055-22025-23534","score":9.2860169281,"text":"\ncorrelation_id='cbc0d18b-a816-45ab-af6a-b8e18dc3e628',\nmsg='Conflict: 1 prior authorization(s) are required for deletion: Key could not be deleted. Please see \"reasons\" for more details.',\nreasons='[AUTHORIZATIONS_NOT_MET: Number of authorizations required to delete is not met -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/apidocs\/key-protect]'\n\n\n\n\n\n\n\n Required parameters \n\n-d, --disable\nor\n-e, --enable\n: Disable or enable the dual authorization policy. One option is required.\n\n\n\n\n\n\n\n kp key cancel-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nThis command (kp key cancel-delete) cancels, or removes, a prior authorization.\n\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-twokp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_09120-29325-30645","score":9.2683225251,"text":"\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-referencekp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference"},{"document_id":"ibmcld_08988-30080-31503","score":9.2651047137,"text":"\nThis command (kp key cancel-delete) cancels, or removes, a prior authorization.\n\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-referencekp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-reference"},{"document_id":"ibmcld_09055-69659-70937","score":9.2625574789,"text":"\nUser 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-twokp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_08987-28071-29358","score":9.261164682,"text":"\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect-cli-pluginkp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin"},{"document_id":"ibmcld_04488-28730-30034","score":9.2532859548,"text":"\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-referencekp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-reference"},{"document_id":"ibmcld_09087-21484-22833","score":9.2385104573,"text":"\n\"collectionType\": \"application\/vnd.ibm.kms.error+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"errorMsg\": \"Key could not be deleted. Please 'reasons' for more details.\",\n\"reasons\":\n{\n\"code\": \"PREV_KEY_DEL_ERR\",\n\"message\": \"The key cannot be deleted because it's protecting a cloud resource that has a retention policy.\",\n\"status\": 409,\n\"moreInfo\":\"https:\/\/cloud.ibm.com\/apidocs\/key-protect\"\n}\n]\n}\n]\n}\nShow more\n\n\n\n\n\n\n\n\n\n 7 - Key has already been deleted... \n\n\n\n Message \n\nKey has already been deleted: Please delete references to this key\n\nReason code: KEY_DELETED_ERR\n\n\n\n\n\n HTTP status code \n\n410 - Gone\n\nThe HTTP 410 Gone client error response code indicates that access to the target resource is no longer available at the origin server and that this condition is likely to be permanent.\n\nIf you don't know whether this condition is temporary or permanent, a 404 status code should be used instead.\n\nA 410 response is cacheable by default.\n\n\n\n\n\n Context \n\nThe delete key request fails because the key was previously deleted. You cannot delete a key more than once.\n\n\n\n Example \n\n delete an existing key\n$ ibmcloud kp key delete $KEY_ID -i $KP_INSTANCE_ID\n\nDeleting key: '0c17...<redacted>...5c34', from instance: 'a192...<redacted>...7411'...\nOK\nDeleted Key\n0c17...<redeacted>...5c34\n\n this request fails because the key was previously deleted","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-error-messages"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08435-4-1684","score":23.9672852515,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys by using dual authorization \n\nYou can use IBM Cloud\u00ae Hyper Protect Crypto Services to safely delete root keys or standard keys by using a dual authorization process.\n\nBefore you delete keys, make sure you understand [the concept of deleting and purging keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-purge-keys) and review the [considerations](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for deleting a key using dual authorization \n\nDeleting a key that has a [dual authorization policy](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) requires an authorization from two users. With the Hyper Protect Crypto Services key management service API, you can provide the first authorization by [setting the key for deletion](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api). Then, a different user provides a second authorization by using the IBM Cloud console or key management service API to delete the key.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Hyper Protect Crypto Services resources. To use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08695-7-1852","score":23.9192206074,"text":"\nWhy can't I delete keys? \n\nWhen you use the Hyper Protect Crypto Services user interface, you're unable to delete a key.\n\n What\u2019s happening \n\nFrom the IBM Cloud dashboard, you select your instance of the Hyper Protect Crypto Services service.\n\nYou're assigned a Manager access policy for the service instance. You try to delete a key, but the action fails with either of the following error messages:\n\n\n\n* Error message 1:\n\n> The service was not able to delete key \"<key_name>\". The key cannot be deleted because it is protecting one or more cloud resources that have a retention policy.\n* Error message 2:\n\n> The service was not able to delete key \"<key_name>\". Because the key is enabled with the dual authorization policy and you set the key for deletion, a second approver needs to continue with the key deletion operation.\n\n\n\n Why it\u2019s happening \n\nThe following reasons might cause the errors:\n\n\n\n* If error message 1 is displayed, this key is actively protecting one or more cloud resources, such as a Cloud Object Storage bucket.\n* If error message 2 is displayed, this key is enabled with the dual authorization policy that requires a deletion authorization from two users. You set the key for deletion and you need to contact the second approver to complete the deletion.\n\n\n\n How to fix it \n\nThe following instructions can help you solve the problems:\n\n\n\n* To resolve the error that is reported in error message 1, [review the resources](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-protected-resources) that are associated with the key before you delete a key.\n\nYou can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-key-force) that's protecting a cloud resource. However, the action won't succeed if the key's associated resource is nonerasable due to a retention policy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys"},{"document_id":"ibmcld_07578-1212442-1214450","score":23.8499974532,"text":"\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted. If you want to enable those keys for dual authorization, you can use the Key Protect APIs t [set dual authorization policies for those individual keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-dual-auth-key-policy).\n* Can I disable a dual authorization settings for my Key Protect instance?\n\nYes. If you need to add a key that doesn't require dual authorization to your Key Protect instance, you can always [disable dual authorization for the Key Protect instance](\/docs\/key-protect?topic=key-protect-manage-dual-auth#disable dual-auth-instance-policy-ui) so that any new or future keys won't require it.\n* What happens when I need to delete or deprovision my Key Protect instance?\n\nIf you decide to move on from Key Protect, you must delete any remaining keys from your Key Protect instance before you can delete or deprovision the service. After you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1215075-1217083","score":23.8499974532,"text":"\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted. If you want to enable those keys for dual authorization, you can use the Key Protect APIs t [set dual authorization policies for those individual keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-dual-auth-key-policy).\n* Can I disable a dual authorization settings for my Key Protect instance?\n\nYes. If you need to add a key that doesn't require dual authorization to your Key Protect instance, you can always [disable dual authorization for the Key Protect instance](\/docs\/key-protect?topic=key-protect-manage-dual-auth#disable dual-auth-instance-policy-ui) so that any new or future keys won't require it.\n* What happens when I need to delete or deprovision my Key Protect instance?\n\nIf you decide to move on from Key Protect, you must delete any remaining keys from your Key Protect instance before you can delete or deprovision the service. After you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_15994-2940-5003","score":23.7664890625,"text":"\nYou can't delete a block storage volume by name or ID.\n\n Why it\u2019s happening \n\nThe volume name and ID are not accepted.\n\n How to fix it \n\nVerify that the volume name or identifier is correct and that the volume is not attached to a virtual server instance. Also, verify that the volume is not in a pending state.\n\n\n\n\n\n Expandable volume remains in an updating state when an attempt is made to delete an instance \n\n What\u2019s happening \n\nWhen you attempt to delete a virtual server instance with an attached volume that is being resized, the volume remains in an updating state and can't be deleted.\n\n Why it\u2019s happening \n\nA volume is being resized and you tried to delete the instance that the volume is attached to, either manually or by auto-delete. The status of the volume remains updating and the volume isn't deleted with the instance.\n\n How to fix it \n\nA volume must be in an available state for operations such as attach, detach, delete. When you are expanding a volume, wait for the volume resize to complete before you perform any operations. If you try to delete a volume that's resizing, the volume remains in an updating state and is not deleted with the instance. To delete the volume, reattach the volume to a different instance, and make sure that the resizing is complete (volume status becomes available), and then delete the volume.\n\n\n\n\n\n Removing IAM authorization from the storage service to the KMS causes root key deregistration failure \n\n What\u2019s happening \n\nThe root keys in the Key management service (KMS) instance remain registered to the deleted block storage volume or image resources.\n\n Why it\u2019s happening \n\nIf you remove IAM authorization from Cloud Block Storage to the KMS before you delete all BYOK volumes or images, the root key fails to unregister from the resource.\n\n How to fix it \n\nAs best practice, delete all storage or image resources before you remove IAM authorization. If you already removed authorization, you must restore the IAM authorization between Cloud Block Storage (source service) and your KMS (target service).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-troubleshooting-block-storage"},{"document_id":"ibmcld_08435-1255-3053","score":23.0616739536,"text":"\nTo use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key. During this period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. To complete the deletion, the second user with a Manager access policy can use the IBM Cloud console or API to delete the key.\n* The key and its associated data become inaccessible 90 days after the key is deleted. When you delete a key, the key can be restored within 30 days after the deletion. You are able to retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically purged and its associated data will be permanently removed from your instance.\n\n\n\n\n\n\n\n Authorize deletion for a key with the IBM Cloud console \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you [enable dual authorization for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by using the IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_09061-4-1966","score":22.8773073781,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys that have a dual-authorization deletion policy \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to safely delete encryption keys by using a dual authorization process.\n\nBefore deleting keys, make sure to review the [Considerations before deleting and purging a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for a key that has a dual-authorization deletion policy \n\n[Dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) are set to ensure that keys are not deleted in error by requiring the authorization of two specified users. Whatever the reason for a dual authorization policy, the method for deletion is the same. One of the users authorized to delete the key schedules it for deletion, which must be confirmed by another user.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Key Protect resources. To use dual authorization, be sure to identify a user who can set the key for deletion and another who can delete the key. Users with a Writer or Manager role can set keys for deletion, but only users with a Manager role can delete keys.\n* Plan to delete the key within a seven day authorization period. When the first user authorizes a key for deletion, it remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_09088-10880-12721","score":22.3250439393,"text":"\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n\n\n\n\n\n What is a dual authorization policy? \n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n\n\n\n\n\n What happens after I enable a dual authorization policy? \n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted. If you want to enable those keys for dual authorization, you can use the Key Protect APIs t [set dual authorization policies for those individual keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-dual-auth-key-policy).\n\n\n\n\n\n Can I disable a dual authorization settings for my Key Protect instance? \n\nYes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-faqs"},{"document_id":"ibmcld_07578-1211120-1213024","score":22.2615771739,"text":"\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1213753-1215657","score":22.2615771739,"text":"\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.2,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1208113027}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08435-3634-5079","score":74.6020241695,"text":"\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-6973-8664","score":73.3080013249,"text":"\nYour IBM Cloud access token. Include the full contents of the IAM token, including the Bearer value, in the cURL request. For more information, see [Retrieving an access token](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Hyper Protect Crypto Services instance. For more information, see [Retrieving an instance ID](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) by using the IBM Cloud console or key management service API.\n\nIf you need to prevent the deletion of a key that is already authorized for deletion, you can remove the existing authorization by calling POST \/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion.\n\n\n\n\n\n\n\n Step 2. Delete the key \n\nAfter you set a key for deletion, a second user with a Manager access policy can safely delete the key.\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-8253-9823","score":70.7816056963,"text":"\nDuring this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\nTo delete a key and the contents, make a DELETE call to the service endpoint by following instructions in [Deleting keys with the API](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-api).\n\n\n\n\n\n Removing an existing authorization \n\nIf you need to cancel an authorization for a key before the 7-day waiting period expires, you can remove the existing authorization by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo remove an authorization to delete a key, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to unset or deauthorize for deletion.\n3. Remove an existing authorization to delete the key.\n\ncurl -X POST","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-4752-6201","score":62.0655774134,"text":"\nIf no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you enable dual authorization [for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo set a key for deletion, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to set or authorize for deletion.\n3. Provide the first authorization to delete the key.\n\ncurl -X POST \n'https:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-4-1684","score":57.6613448824,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys by using dual authorization \n\nYou can use IBM Cloud\u00ae Hyper Protect Crypto Services to safely delete root keys or standard keys by using a dual authorization process.\n\nBefore you delete keys, make sure you understand [the concept of deleting and purging keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-purge-keys) and review the [considerations](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for deleting a key using dual authorization \n\nDeleting a key that has a [dual authorization policy](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) requires an authorization from two users. With the Hyper Protect Crypto Services key management service API, you can provide the first authorization by [setting the key for deletion](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api). Then, a different user provides a second authorization by using the IBM Cloud console or key management service API to delete the key.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Hyper Protect Crypto Services resources. To use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-1255-3053","score":56.824209884,"text":"\nTo use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key. During this period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. To complete the deletion, the second user with a Manager access policy can use the IBM Cloud console or API to delete the key.\n* The key and its associated data become inaccessible 90 days after the key is deleted. When you delete a key, the key can be restored within 30 days after the deletion. You are able to retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically purged and its associated data will be permanently removed from your instance.\n\n\n\n\n\n\n\n Authorize deletion for a key with the IBM Cloud console \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you [enable dual authorization for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by using the IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_16059-9270-11112","score":51.7157496735,"text":"\nWhen you delete a root key, the key is no longer available to decrypt passphrases that are used to protect your resources. Deleting a root key places it in a destroyed or deleted state in the KMS. Volume, snapshot, and image resources that are protected by the deleted root key have an unusable status and can't be used for normal operations. File Storage for VPC shares show a suspended status. The storage system is offline, and data cannot be accessed.\n\nYour data still exists. You have a 30-day grace period to [restore the deleted key](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managing&interface=uibyok-restore-root-key). Otherwise, your encrypted resources become inaccessible. After 30 days, your root key can't be restored, and your resources are unrecoverable.\n\nBy default, the KMS prevents you from deleting a root key that's actively protecting a resource. You can force delete a root key in Key Protect and Hyper Protect Crypto Services. When you force delete a root key, the following actions happen automatically:\n\n\n\n* If the deleted root key is protecting boot volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting data volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting file shares, the file share is suspended.\n* Deleting a root key purges usage of the key for all resources in the VPC.\n* Events are logged in the Activity Tracker.\n\n\n\nTo force the deletion of a root key in Hyper Protect Crypto Services, use the API. Hyper Protect Crypto Services requires that you delete all resources before you delete a root key that is protecting those resources. If you can't delete the key, see [troubleshooting key management service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managing&interface=ui"},{"document_id":"ibmcld_08695-7-1852","score":51.5689471511,"text":"\nWhy can't I delete keys? \n\nWhen you use the Hyper Protect Crypto Services user interface, you're unable to delete a key.\n\n What\u2019s happening \n\nFrom the IBM Cloud dashboard, you select your instance of the Hyper Protect Crypto Services service.\n\nYou're assigned a Manager access policy for the service instance. You try to delete a key, but the action fails with either of the following error messages:\n\n\n\n* Error message 1:\n\n> The service was not able to delete key \"<key_name>\". The key cannot be deleted because it is protecting one or more cloud resources that have a retention policy.\n* Error message 2:\n\n> The service was not able to delete key \"<key_name>\". Because the key is enabled with the dual authorization policy and you set the key for deletion, a second approver needs to continue with the key deletion operation.\n\n\n\n Why it\u2019s happening \n\nThe following reasons might cause the errors:\n\n\n\n* If error message 1 is displayed, this key is actively protecting one or more cloud resources, such as a Cloud Object Storage bucket.\n* If error message 2 is displayed, this key is enabled with the dual authorization policy that requires a deletion authorization from two users. You set the key for deletion and you need to contact the second approver to complete the deletion.\n\n\n\n How to fix it \n\nThe following instructions can help you solve the problems:\n\n\n\n* To resolve the error that is reported in error message 1, [review the resources](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-protected-resources) that are associated with the key before you delete a key.\n\nYou can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-key-force) that's protecting a cloud resource. However, the action won't succeed if the key's associated resource is nonerasable due to a retention policy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys"},{"document_id":"ibmcld_16045-9337-11274","score":50.7791039758,"text":"\nVolume, snapshot, and image resources that are protected by the deleted root key have an unusable status and can't be used for normal operations. File Storage for VPC shares show a suspended status. The storage system is offline, and data cannot be accessed.\n\nYour data still exists. You have a 30-day grace period to [restore the deleted key](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managingbyok-restore-root-key). Otherwise, your encrypted resources become inaccessible. After 30 days, your root key can't be restored, and your resources are unrecoverable.\n\nBy default, the KMS prevents you from deleting a root key that's actively protecting a resource. You can force delete a root key in Key Protect and Hyper Protect Crypto Services. When you force delete a root key, the following actions happen automatically:\n\n\n\n* If the deleted root key is protecting boot volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting data volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting file shares, the file share is suspended.\n* Deleting a root key purges usage of the key for all resources in the VPC.\n* Events are logged in the Activity Tracker.\n\n\n\nTo force the deletion of a root key in Hyper Protect Crypto Services, use the API. Hyper Protect Crypto Services requires that you delete all resources before you delete a root key that is protecting those resources. If you can't delete the key, see [troubleshooting key management service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys).\n\nBlock Storage for VPC volumes, snapshots, and custom images with a deleted root key appear in the list of resources with an unusable status. File Storage for VPC shares show a suspended status. The API reason code is encryption_key_deleted.\n\nDeletion of the root key results in the following conditions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managing"},{"document_id":"ibmcld_08781-13678-15646","score":49.8803766467,"text":"\nAdded: Hyper Protect Crypto Services expands into the S\u00e3o-Paulo region\n: You can now create Hyper Protect Crypto Services instances in the S\u00e3o-Paulo (br-sao) region where the infrastructure is based on IBM Cloud Virtual Private Cloud (VPC). For more information, see [Regions and locations](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-regions).\n\n\n\n\n\n 21 January 2022 \n\nUpdated: Hyper Protect Crypto Services key management functions\n: The Hyper Protect Crypto Services key management service API is updated to version 2.82. The following functions are added:\n\n\n\n1. Purge a deleted key: By default, a deleted key becomes purged automatically after 90 days of the deletion. Now you can manually purge a key to permanently remove the key from your instance before 90 days. After a key is deleted, there is a wait period of up to 4 hours before you can perform the action. Make sure that you are assigned the KMS Key Purge role before you purge a key. For more information, see [Purging keys manually](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-purge-keys).\n2. Update the key ring of a key: After you create a key, you can move the key to a different key ring. For more information, see [Transferring a key to a different key ring](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-managing-key-ringstransfer-key-key-ring).\n\n\n\n\n\n\n\n 30 July 2021 \n\nAdded: Exclusive control on the execution of cryptographic operations\n: To ensure the exclusive control on the execution of cryptographic operations, you can use the Hyper Protect Crypto Services certificate manager CLI to enable the second layer of authentication for EP11 (GREP11 or PKCS #11 API) connections. By enabling this function, you enable an extra layer of access control on top of the Identity and Access Management (IAM) token to the EP11 applications. A mutual TLS connection is established to ensure that only EP11 applications with a valid client certificate can perform EP11 operations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-what-new"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.5,"recall_5":0.75,"recall_10":0.75,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.7536976113,"ndcg_cut_10":0.7536976113}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08435-1255-3053","score":24.3232970335,"text":"\nTo use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key. During this period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. To complete the deletion, the second user with a Manager access policy can use the IBM Cloud console or API to delete the key.\n* The key and its associated data become inaccessible 90 days after the key is deleted. When you delete a key, the key can be restored within 30 days after the deletion. You are able to retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically purged and its associated data will be permanently removed from your instance.\n\n\n\n\n\n\n\n Authorize deletion for a key with the IBM Cloud console \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you [enable dual authorization for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by using the IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-8253-9823","score":22.9518216354,"text":"\nDuring this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\nTo delete a key and the contents, make a DELETE call to the service endpoint by following instructions in [Deleting keys with the API](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-api).\n\n\n\n\n\n Removing an existing authorization \n\nIf you need to cancel an authorization for a key before the 7-day waiting period expires, you can remove the existing authorization by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo remove an authorization to delete a key, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to unset or deauthorize for deletion.\n3. Remove an existing authorization to delete the key.\n\ncurl -X POST","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-6973-8664","score":21.3097450631,"text":"\nYour IBM Cloud access token. Include the full contents of the IAM token, including the Bearer value, in the cURL request. For more information, see [Retrieving an access token](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Hyper Protect Crypto Services instance. For more information, see [Retrieving an instance ID](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) by using the IBM Cloud console or key management service API.\n\nIf you need to prevent the deletion of a key that is already authorized for deletion, you can remove the existing authorization by calling POST \/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion.\n\n\n\n\n\n\n\n Step 2. Delete the key \n\nAfter you set a key for deletion, a second user with a Manager access policy can safely delete the key.\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08211-1158-3123","score":20.6474024359,"text":"\nibmcloud hpvs instance-delete CRN --force\n\n\n\nWhere CRN is Cloud resource name of the server you want to delete. Use --force to force the deletion of the Hyper Protect Virtual Servers instance without showing a confirmation prompt.\n\nYou can find more information and example output [here](https:\/\/cloud.ibm.com\/docs\/hpvs-cli-pluginhpvs-instance-delete).\n\n\n\n\n\n What happens during the reclamation period \n\nWhen you delete a virtual server from the resource list, the server isn't deleted immediately, it's stopped and marked for deletion, and a reclamation period of seven days starts. The server is deleted after the reclamation period ends. During this seven-day reclamation period, you can restore the virtual server, or manually trigger a deletion from [resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations). Resource reclamations lists the Hyper Protect Virtual Servers that are marked for deletion together with the time (Target time) when the actual deletion is triggered.\n\n\n\n\n\n Deleting servers that belong to the free plan \n\nThe free plan servers expire 30 days after they are created. When a server expires, it's immediately deleted at the backend. The server is also deleted at the backend if it expires during the seven-day reclamation period. Even though the server is deleted at the backend, it's still displayed in the resource list or in the resource reclamations as if it still exists.\n\nIf the server has expired, you can remove the entry from the resource list and either:\n\n\n\n* Wait for the target time to trigger deletion for you, or\n* Manually trigger the deletion from the resource reclamations.\n\n\n\nIf an expired server is restored, only the entry within the resource list is restored, not the server itself.\n\n\n\n\n\n Restoring servers that belong to paid plans \n\nServers that belong to a paid plans do not expire, and that's why they can be restored during the reclamation period.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"},{"document_id":"ibmcld_08435-3634-5079","score":20.5017395482,"text":"\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_12448-7795-9977","score":19.8632519984,"text":"\nAfter it is restored, you must upgrade your plan within 1 hour or it will be deleted again.\n\nThe Secrets Manager data retention policy describes how long your data is stored after you delete the service. The data retention policy is included in the Secrets Manager service description, which you can find in the [IBM Cloud Terms and Notices](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-terms).\n\n\n\n Deleting a Secrets Manager instance \n\nIf you no longer need an instance of Secrets Manager, you can delete the service instance and any data that is stored. Your instance enters a disabled state, and after 7 days its data is permanently deleted. You can also choose to delete your service instance by using the console.\n\nDuring the 7-day reclamation period, do not delete authorizations between Secrets Manager and other integrated services, such as Key Protect. Secrets Manager uses the authorization to unregister your instance from any associated resources in those services. After the instance is permanently deleted, the authorization is also deleted by IAM.\n\n\n\n1. Delete the service and place it in a reclamation period of 7 days.\n\nibmcloud resource service-instance-delete \"<instance_name>\"\n\nReplace <instance_name> with the name of the Secrets Manager instance that you want to delete.\n2. Optional: To permanently delete your instance, get the reclamation ID.\n\nibmcloud resource reclamations --resource-instance-id <instance_ID>\n\nReplace <instance_ID> with your Secrets Manager instance ID.\n\nIf you choose to permanently delete the instance by deleting its reclamation, you cannot restore your data.\n3. Optional: Permanently delete the reclamation instance.\n\nibmcloud resource reclamation-delete <reclamation_ID>\n\nReplace <reclamation_ID> with the value that you retrieved in the previous step.\n\n\n\n\n\n\n\n Restoring a deleted service instance \n\nIf you haven't permanently deleted your instance, you can restore it during the 7-day reclamation period.\n\n\n\n1. View which service instances are available for restoration.\n\nibmcloud resource reclamations\n\nFrom the list of available instances, copy the reclamation ID of the Secrets Manager instance that you want to restore.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-mng-data"},{"document_id":"ibmcld_09061-12083-13778","score":19.6461429262,"text":"\nFor more information about deleting and purging keys, check out [About deleting and purging keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keys).\n\nThe following table lists which APIs you can use to retrieve data related to a deleted key.\n\n\n\nTable 4. Lists the API that users can use to view details about a key and its registrations.\n\n API Description \n\n [Get key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-key) Retrieve key details \n [Get key metadata](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-key-metadata) Retrieve key metadata \n [Get registrations](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) Retrieve a list of registrations associated with the key \n\n\n\n\n\n\n\n Removing an existing authorization \n\nIf you need to cancel an authorization for a key before the seven-day authorization period expires, you can remove the existing authorization by making a POST call to the following endpoint.\n\nhttps:\/\/<region>.kms.cloud.ibm.com\/api\/v2\/keys\/<keyID_or_alias>\/actions\/unsetKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-up-api).\n\nTo remove an authorization to delete a key, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Key Protect service actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-accessmanage-access-roles).\n2. Copy the ID of the key that you want to unset or deauthorize for deletion.\n3. Remove an existing authorization to delete the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_09061-6176-7874","score":19.479709376,"text":"\n<br> <br>For more information, see [Retrieving an access token](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Key Protect service instance. <br>For more information, see [Retrieving an instance ID](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) by using the Key Protect GUI or API.\n\nIf you need to prevent the deletion of a key that's already authorized for deletion, you can remove the existing authorization by calling POST \/api\/v2\/keys\/<keyID_or_alias>\/actions\/unsetKeyForDeletion.\n\n\n\n Delete the key \n\nAfter you set a key for deletion, another user with a Manager access policy can safely delete the key by using the Key Protect GUI or API.\n\nKey Protect sets a seven-day authorization period that starts after you provide the first authorization to delete the key. During this seven-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) and all key operations are allowed on the key. If no action is taken by another user and the seven-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-set-key-deletion-api) to delete the key.\n\nDelete a key and its contents by making a DELETE call to the following endpoint.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-4-1684","score":19.4625469269,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys by using dual authorization \n\nYou can use IBM Cloud\u00ae Hyper Protect Crypto Services to safely delete root keys or standard keys by using a dual authorization process.\n\nBefore you delete keys, make sure you understand [the concept of deleting and purging keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-purge-keys) and review the [considerations](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for deleting a key using dual authorization \n\nDeleting a key that has a [dual authorization policy](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) requires an authorization from two users. With the Hyper Protect Crypto Services key management service API, you can provide the first authorization by [setting the key for deletion](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api). Then, a different user provides a second authorization by using the IBM Cloud console or key management service API to delete the key.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Hyper Protect Crypto Services resources. To use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_09061-1334-3188","score":18.2675472899,"text":"\nWhen the first user authorizes a key for deletion, it remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted. When you delete a key, it is \"soft deleted\", meaning that the key and its associated data will be restorable up to 30 days after deletion. You are able to still retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically [purged](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-key-purge), or hard deleted, and its associated data will be permanently removed from the Key Protect service.\n\n\n\n\n\n\n\n Authorize deletion for a key in the console \n\n[After you enable dual authorization for an instance or key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth), you can provide the first authorization to delete a key by using the Key Protect IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/login\/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the application details page, use the Keys table to browse the keys in your service.\n5. Click the \u22ef icon to open a list of options for the key that you want to delete.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09120-94597-96242","score":9.3397685255,"text":"\nA unique, human readable name for the key-ring. Required if the user doesn't have permissions on the default key ring.\n\n\n\n\n\n\n\n\n\n kp key schedule-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-referencekp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID_OR_ALIAS\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID_OR_ALIAS --output json\n\n[\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference"},{"document_id":"ibmcld_08988-95785-97389","score":9.3383511797,"text":"\nA unique, human readable name for the key-ring. Required if the user doesn't have permissions on the default key ring.\n\n\n\n\n\n\n\n\n\n kp key schedule-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-referencekp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID_OR_ALIAS\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-reference"},{"document_id":"ibmcld_04488-93746-95375","score":9.3324969525,"text":"\nA unique, human readable name for the key-ring. Required if the user doesn't have permissions on the default key ring.\n\n\n\n\n\n\n\n\n\n kp key schedule-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-referencekp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID_OR_ALIAS\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID_OR_ALIAS --output json\n\n[\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-reference"},{"document_id":"ibmcld_09055-22025-23534","score":9.2860169281,"text":"\ncorrelation_id='cbc0d18b-a816-45ab-af6a-b8e18dc3e628',\nmsg='Conflict: 1 prior authorization(s) are required for deletion: Key could not be deleted. Please see \"reasons\" for more details.',\nreasons='[AUTHORIZATIONS_NOT_MET: Number of authorizations required to delete is not met -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/apidocs\/key-protect]'\n\n\n\n\n\n\n\n Required parameters \n\n-d, --disable\nor\n-e, --enable\n: Disable or enable the dual authorization policy. One option is required.\n\n\n\n\n\n\n\n kp key cancel-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nThis command (kp key cancel-delete) cancels, or removes, a prior authorization.\n\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-twokp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_09120-29325-30645","score":9.2683225251,"text":"\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-referencekp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference"},{"document_id":"ibmcld_08988-30080-31503","score":9.2651047137,"text":"\nThis command (kp key cancel-delete) cancels, or removes, a prior authorization.\n\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-referencekp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-reference"},{"document_id":"ibmcld_09055-69659-70937","score":9.2625574789,"text":"\nUser 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-twokp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_08987-28071-29358","score":9.261164682,"text":"\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect-cli-pluginkp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin"},{"document_id":"ibmcld_04488-28730-30034","score":9.2532859548,"text":"\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-referencekp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-reference"},{"document_id":"ibmcld_09087-21484-22833","score":9.2385104573,"text":"\n\"collectionType\": \"application\/vnd.ibm.kms.error+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"errorMsg\": \"Key could not be deleted. Please 'reasons' for more details.\",\n\"reasons\":\n{\n\"code\": \"PREV_KEY_DEL_ERR\",\n\"message\": \"The key cannot be deleted because it's protecting a cloud resource that has a retention policy.\",\n\"status\": 409,\n\"moreInfo\":\"https:\/\/cloud.ibm.com\/apidocs\/key-protect\"\n}\n]\n}\n]\n}\nShow more\n\n\n\n\n\n\n\n\n\n 7 - Key has already been deleted... \n\n\n\n Message \n\nKey has already been deleted: Please delete references to this key\n\nReason code: KEY_DELETED_ERR\n\n\n\n\n\n HTTP status code \n\n410 - Gone\n\nThe HTTP 410 Gone client error response code indicates that access to the target resource is no longer available at the origin server and that this condition is likely to be permanent.\n\nIf you don't know whether this condition is temporary or permanent, a 404 status code should be used instead.\n\nA 410 response is cacheable by default.\n\n\n\n\n\n Context \n\nThe delete key request fails because the key was previously deleted. You cannot delete a key more than once.\n\n\n\n Example \n\n delete an existing key\n$ ibmcloud kp key delete $KEY_ID -i $KP_INSTANCE_ID\n\nDeleting key: '0c17...<redacted>...5c34', from instance: 'a192...<redacted>...7411'...\nOK\nDeleted Key\n0c17...<redeacted>...5c34\n\n this request fails because the key was previously deleted","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-error-messages"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-1211120-1213024","score":23.7294882799,"text":"\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1213753-1215657","score":23.7294882799,"text":"\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_08695-7-1852","score":23.2351246357,"text":"\nWhy can't I delete keys? \n\nWhen you use the Hyper Protect Crypto Services user interface, you're unable to delete a key.\n\n What\u2019s happening \n\nFrom the IBM Cloud dashboard, you select your instance of the Hyper Protect Crypto Services service.\n\nYou're assigned a Manager access policy for the service instance. You try to delete a key, but the action fails with either of the following error messages:\n\n\n\n* Error message 1:\n\n> The service was not able to delete key \"<key_name>\". The key cannot be deleted because it is protecting one or more cloud resources that have a retention policy.\n* Error message 2:\n\n> The service was not able to delete key \"<key_name>\". Because the key is enabled with the dual authorization policy and you set the key for deletion, a second approver needs to continue with the key deletion operation.\n\n\n\n Why it\u2019s happening \n\nThe following reasons might cause the errors:\n\n\n\n* If error message 1 is displayed, this key is actively protecting one or more cloud resources, such as a Cloud Object Storage bucket.\n* If error message 2 is displayed, this key is enabled with the dual authorization policy that requires a deletion authorization from two users. You set the key for deletion and you need to contact the second approver to complete the deletion.\n\n\n\n How to fix it \n\nThe following instructions can help you solve the problems:\n\n\n\n* To resolve the error that is reported in error message 1, [review the resources](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-protected-resources) that are associated with the key before you delete a key.\n\nYou can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-key-force) that's protecting a cloud resource. However, the action won't succeed if the key's associated resource is nonerasable due to a retention policy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys"},{"document_id":"ibmcld_09088-9397-11338","score":23.047616529,"text":"\nIf it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n\n\n\n\n\n What happens if I try to delete a key that's actively encrypting data? \n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-faqs"},{"document_id":"ibmcld_09192-5368-7014","score":22.3043717986,"text":"\n\"message\": \"Key is protecting one or more cloud resources\",\n\"status\": 409,\n\"moreInfo\": \"https:\/\/cloud.ibm.com\/apidocs\/key-protect\",\n\"target\": {\n\"type\": \"query_param\",\n\"name\": \"force\"\n}\n}\n]\n}\n]\n}\n\n Why it\u2019s happening \n\nThis key is actively protecting one or more cloud resources, such as a IBM Cloud\u00ae Object Storage bucket or a Cloud Databases deployment.\n\n How to fix it \n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. Before you delete a key, [review which resources are encrypted by this key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nYou can get the current list of resources associated with your key by first [synchronizing the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-sync-associated-resources), which might take up to 4 hours. Then, proceed to [viewing associations between root keys and encrypted IBM Cloud resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources).\n\nAfter using Sync, associations between the key and other resources will be current and up to date. If there are no associations after using Sync, the key can be deleted normally.\n\nIf the associations are still there after Sync:\n\n\n\n* You can use the Key Protect API to [force deletion on the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete).\n* You can delete the resources associated with the key, and then delete the key normally.\n\n\n\n\n\n\n\n Getting help and support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-troubleshooting"},{"document_id":"ibmcld_16059-9270-11112","score":22.1150702881,"text":"\nWhen you delete a root key, the key is no longer available to decrypt passphrases that are used to protect your resources. Deleting a root key places it in a destroyed or deleted state in the KMS. Volume, snapshot, and image resources that are protected by the deleted root key have an unusable status and can't be used for normal operations. File Storage for VPC shares show a suspended status. The storage system is offline, and data cannot be accessed.\n\nYour data still exists. You have a 30-day grace period to [restore the deleted key](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managing&interface=uibyok-restore-root-key). Otherwise, your encrypted resources become inaccessible. After 30 days, your root key can't be restored, and your resources are unrecoverable.\n\nBy default, the KMS prevents you from deleting a root key that's actively protecting a resource. You can force delete a root key in Key Protect and Hyper Protect Crypto Services. When you force delete a root key, the following actions happen automatically:\n\n\n\n* If the deleted root key is protecting boot volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting data volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting file shares, the file share is suspended.\n* Deleting a root key purges usage of the key for all resources in the VPC.\n* Events are logged in the Activity Tracker.\n\n\n\nTo force the deletion of a root key in Hyper Protect Crypto Services, use the API. Hyper Protect Crypto Services requires that you delete all resources before you delete a root key that is protecting those resources. If you can't delete the key, see [troubleshooting key management service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managing&interface=ui"},{"document_id":"ibmcld_16045-9337-11274","score":21.7838644759,"text":"\nVolume, snapshot, and image resources that are protected by the deleted root key have an unusable status and can't be used for normal operations. File Storage for VPC shares show a suspended status. The storage system is offline, and data cannot be accessed.\n\nYour data still exists. You have a 30-day grace period to [restore the deleted key](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managingbyok-restore-root-key). Otherwise, your encrypted resources become inaccessible. After 30 days, your root key can't be restored, and your resources are unrecoverable.\n\nBy default, the KMS prevents you from deleting a root key that's actively protecting a resource. You can force delete a root key in Key Protect and Hyper Protect Crypto Services. When you force delete a root key, the following actions happen automatically:\n\n\n\n* If the deleted root key is protecting boot volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting data volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting file shares, the file share is suspended.\n* Deleting a root key purges usage of the key for all resources in the VPC.\n* Events are logged in the Activity Tracker.\n\n\n\nTo force the deletion of a root key in Hyper Protect Crypto Services, use the API. Hyper Protect Crypto Services requires that you delete all resources before you delete a root key that is protecting those resources. If you can't delete the key, see [troubleshooting key management service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys).\n\nBlock Storage for VPC volumes, snapshots, and custom images with a deleted root key appear in the list of resources with an unusable status. File Storage for VPC shares show a suspended status. The API reason code is encryption_key_deleted.\n\nDeletion of the root key results in the following conditions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managing"},{"document_id":"ibmcld_09192-4150-5583","score":21.7620363406,"text":"\nIf the Key Protect instance contains more than 200 keys, you need to use the [offset and limit parameters](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-keysretrieve-subset-keys-api) to list another subset of keys.\n\nFor example, if you want to list keys 201 - 210 that are available in a service instance, you use ..\/keys?offset=200&limit=10 to skip the first 200 keys.\n\n\n\n\n\n Unable to delete keys \n\nWhen you use the Key Protect user interface or REST API, you're unable to delete a key.\n\n What\u2019s happening \n\nFrom the IBM Cloud dashboard, you select your instance of the Key Protect service.\n\nYou're assigned a Manager access policy for the Key Protect instance. You try to delete a key, but the action fails with the following error message.\n\nConflict: Key could not be deleted. Status: 409, Correlation ID: 160cc463-71d1-4b30-a5f2-d3f7e9f2b75e\n\nYou also try to delete the key by using the Key Protect API, but you receive the following error message.\n\n{\n\"metadata\": {\n\"collectionType\": \"application\/vnd.ibm.kms.error+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"errorMsg\": \"Conflict: Key could not be deleted. Please see reasons for more details.\",\n\"reasons\":\n{\n\"code\": \"PROTECTED_RESOURCE_ERR\",\n\"message\": \"Key is protecting one or more cloud resources\",\n\"status\": 409,\n\"moreInfo\": \"https:\/\/cloud.ibm.com\/apidocs\/key-protect\",\n\"target\": {\n\"type\": \"query_param\",\n\"name\": \"force\"\n}\n}\n]\n}\n]\n}\n\n Why it\u2019s happening","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-troubleshooting"},{"document_id":"ibmcld_07578-1209748-1211682","score":20.960274121,"text":"\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n* What happens if I try to delete a key that's actively encrypting data?\n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1212381-1214315","score":20.960274121,"text":"\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n* What happens if I try to delete a key that's actively encrypting data?\n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09551-1435-3087","score":25.1203497058,"text":"\nList of service instances on the Resource List\n\n\n\n\n\n Deleting your Deployment by using the CLI \n\nBy using the CLI, you can delete your existing IBM Cloud\u00ae Databases instance with the [ibmcloud resource service-instance-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_service_instance_delete) command:\n\nibmcloud resource service-instance-delete my-service-instance\n\nUsing the command ibmcloud resource reclamation-delete deletes a reclaimed resource so that the resource can no longer be restored.\n\n\n\n\n\n Deleting your database by using DROP DATABASE Statement \n\n[DROP DATABASE](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/drop-database.html) drops all tables in the database and deletes the database.\n\nDROP {DATABASE | SCHEMA} [IF EXISTS] db_name\n\n\n\n\n\n Deleting your database by using mysqladmin \n\nYou can also drop databases with [mysqladmin, a MySQL Server Administration Program](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/mysqladmin.html). Launch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-deprovisioning"},{"document_id":"ibmcld_06564-1431-3083","score":25.1203497058,"text":"\nList of service instances on the Resource List\n\n\n\n\n\n Deleting your Deployment by using the CLI \n\nBy using the CLI, you can delete your existing IBM Cloud\u00ae Databases instance with the [ibmcloud resource service-instance-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_service_instance_delete) command:\n\nibmcloud resource service-instance-delete my-service-instance\n\nUsing the command ibmcloud resource reclamation-delete deletes a reclaimed resource so that the resource can no longer be restored.\n\n\n\n\n\n Deleting your database by using DROP DATABASE Statement \n\n[DROP DATABASE](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/drop-database.html) drops all tables in the database and deletes the database.\n\nDROP {DATABASE | SCHEMA} [IF EXISTS] db_name\n\n\n\n\n\n Deleting your database by using mysqladmin \n\nYou can also drop databases with [mysqladmin, a MySQL Server Administration Program](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/mysqladmin.html). Launch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-deprovisioning"},{"document_id":"ibmcld_08211-1158-3123","score":23.1531769836,"text":"\nibmcloud hpvs instance-delete CRN --force\n\n\n\nWhere CRN is Cloud resource name of the server you want to delete. Use --force to force the deletion of the Hyper Protect Virtual Servers instance without showing a confirmation prompt.\n\nYou can find more information and example output [here](https:\/\/cloud.ibm.com\/docs\/hpvs-cli-pluginhpvs-instance-delete).\n\n\n\n\n\n What happens during the reclamation period \n\nWhen you delete a virtual server from the resource list, the server isn't deleted immediately, it's stopped and marked for deletion, and a reclamation period of seven days starts. The server is deleted after the reclamation period ends. During this seven-day reclamation period, you can restore the virtual server, or manually trigger a deletion from [resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations). Resource reclamations lists the Hyper Protect Virtual Servers that are marked for deletion together with the time (Target time) when the actual deletion is triggered.\n\n\n\n\n\n Deleting servers that belong to the free plan \n\nThe free plan servers expire 30 days after they are created. When a server expires, it's immediately deleted at the backend. The server is also deleted at the backend if it expires during the seven-day reclamation period. Even though the server is deleted at the backend, it's still displayed in the resource list or in the resource reclamations as if it still exists.\n\nIf the server has expired, you can remove the entry from the resource list and either:\n\n\n\n* Wait for the target time to trigger deletion for you, or\n* Manually trigger the deletion from the resource reclamations.\n\n\n\nIf an expired server is restored, only the entry within the resource list is restored, not the server itself.\n\n\n\n\n\n Restoring servers that belong to paid plans \n\nServers that belong to a paid plans do not expire, and that's why they can be restored during the reclamation period.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"},{"document_id":"ibmcld_06381-1376-2975","score":22.7454376184,"text":"\nDeleting your Deployment by using the CLI \n\nBy using the CLI, you can delete your existing IBM Cloud\u00ae Databases instance with the [ibmcloud resource service-instance-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_service_instance_delete) command:\n\nibmcloud resource service-instance-delete my-service-instance\n\nUsing the command ibmcloud resource reclamation-delete deletes a reclaimed resource so that the resource can no longer be restored.\n\n\n\n\n\n Deleting your database by using DROP DATABASE Statement \n\n[DROP DATABASE](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/drop-database.html) drops all tables in the database and deletes the database.\n\nDROP {DATABASE | SCHEMA} [IF EXISTS] db_name\n\n\n\n\n\n Deleting your database by using mysqladmin \n\nYou can also drop databases with [mysqladmin, a MySQL Server Administration Program](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/mysqladmin.html). Launch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=cloud-databases-deprovisioning"},{"document_id":"ibmcld_06341-2428-3641","score":21.7725020598,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-deprovisioning"},{"document_id":"ibmcld_06499-2416-3629","score":21.7725020598,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mongodb?topic=databases-for-mongodb-deprovisioning"},{"document_id":"ibmcld_06443-2410-3623","score":21.7725020598,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-deprovisioning"},{"document_id":"ibmcld_06627-2422-3635","score":21.7725020598,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-deprovisioning"},{"document_id":"ibmcld_06696-2412-3625","score":21.7725020598,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-deprovisioning"},{"document_id":"ibmcld_15964-0-900","score":20.7585600397,"text":"\n\n\n\n\n\n\n  Why can't I can access a service by using the service's URL? \n\nYou are supposed to be able to access a service by using the reserved IP or service's URL. If you can't access a service by using the URL, you might need to force the DHCP client to renew its lease.\n\n  What\u2019s happening \n\nCannot use the service's URL to access the service.\n\n  Why it\u2019s happening \n\nThe DNS service was not able to change the default DNS server for the virtual server instance that's trying to access the service.\n\n  How to fix it \n\nTo correct this issue, follow steps similar to the following Ubuntu commands:\n\n\n\n1.  In the virtual server instance, check the last lease in \/var\/lib\/dhcp\/dhclient.leases. The entry for DNS servers is to read option domain-name-servers 161.26.0.7,161.26.0.8, not 161.26.0.10,161.26.0.11.\n2.  If this entry is not updated, run \/sbin\/dhclient to force the DHCP client update.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-troubleshoot-cannot-access-url"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.2997490289}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15163-33329-34758","score":16.9615654199,"text":"\nFor more information about the arguments and attributes, see [ibm_is_backup_policy_plan](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/resources\/is_backup_policy_plan).\n\n\n\n\n\n Creating a backup plan with cross-regional copy option with Terraform \n\nNew\n\nTo create a backup plan with cross-regional copy option, use the ibm_is_backup_policy_plan resource. If the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the --encryption-key option. See the following example.\n\nresource \"ibm_is_backup_policy_plan\" \"example\" {\nbackup_policy_id = \"ibm_is_backup_policy.example.id\"\ncron_spec = \"30 \/2 * * 1-5\"\nname = \"my-policy-plan\"\ndeletion_trigger {\ndelete_after = 20\ndelete_over_count = 20\n}\nremote_copy_policies {\ndelete_over_count = 1\nencryption_key = \"crn:v1:bluemix:public:kms:us-south:a\/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd6179\"\nregion = \"us-south\"\n}\n}\n\nFor more information about the arguments and attributes, see [ibm_is_backup_policy_plan](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/resources\/is_backup_policy_plan).\n\n\n\n\n\n\n\n Next steps \n\nAfter you create a backup policy, you can do the following actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=terraform"},{"document_id":"ibmcld_15164-33294-34723","score":16.9615654199,"text":"\nFor more information about the arguments and attributes, see [ibm_is_backup_policy_plan](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/resources\/is_backup_policy_plan).\n\n\n\n\n\n Creating a backup plan with cross-regional copy option with Terraform \n\nNew\n\nTo create a backup plan with cross-regional copy option, use the ibm_is_backup_policy_plan resource. If the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the --encryption-key option. See the following example.\n\nresource \"ibm_is_backup_policy_plan\" \"example\" {\nbackup_policy_id = \"ibm_is_backup_policy.example.id\"\ncron_spec = \"30 \/2 * * 1-5\"\nname = \"my-policy-plan\"\ndeletion_trigger {\ndelete_after = 20\ndelete_over_count = 20\n}\nremote_copy_policies {\ndelete_over_count = 1\nencryption_key = \"crn:v1:bluemix:public:kms:us-south:a\/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd6179\"\nregion = \"us-south\"\n}\n}\n\nFor more information about the arguments and attributes, see [ibm_is_backup_policy_plan](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/resources\/is_backup_policy_plan).\n\n\n\n\n\n\n\n Next steps \n\nAfter you create a backup policy, you can do the following actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=ui"},{"document_id":"ibmcld_15160-33229-34658","score":16.9615654199,"text":"\nFor more information about the arguments and attributes, see [ibm_is_backup_policy_plan](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/resources\/is_backup_policy_plan).\n\n\n\n\n\n Creating a backup plan with cross-regional copy option with Terraform \n\nNew\n\nTo create a backup plan with cross-regional copy option, use the ibm_is_backup_policy_plan resource. If the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the --encryption-key option. See the following example.\n\nresource \"ibm_is_backup_policy_plan\" \"example\" {\nbackup_policy_id = \"ibm_is_backup_policy.example.id\"\ncron_spec = \"30 \/2 * * 1-5\"\nname = \"my-policy-plan\"\ndeletion_trigger {\ndelete_after = 20\ndelete_over_count = 20\n}\nremote_copy_policies {\ndelete_over_count = 1\nencryption_key = \"crn:v1:bluemix:public:kms:us-south:a\/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd6179\"\nregion = \"us-south\"\n}\n}\n\nFor more information about the arguments and attributes, see [ibm_is_backup_policy_plan](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/resources\/is_backup_policy_plan).\n\n\n\n\n\n\n\n Next steps \n\nAfter you create a backup policy, you can do the following actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan"},{"document_id":"ibmcld_15161-33369-34798","score":16.9615654199,"text":"\nFor more information about the arguments and attributes, see [ibm_is_backup_policy_plan](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/resources\/is_backup_policy_plan).\n\n\n\n\n\n Creating a backup plan with cross-regional copy option with Terraform \n\nNew\n\nTo create a backup plan with cross-regional copy option, use the ibm_is_backup_policy_plan resource. If the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the --encryption-key option. See the following example.\n\nresource \"ibm_is_backup_policy_plan\" \"example\" {\nbackup_policy_id = \"ibm_is_backup_policy.example.id\"\ncron_spec = \"30 \/2 * * 1-5\"\nname = \"my-policy-plan\"\ndeletion_trigger {\ndelete_after = 20\ndelete_over_count = 20\n}\nremote_copy_policies {\ndelete_over_count = 1\nencryption_key = \"crn:v1:bluemix:public:kms:us-south:a\/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd6179\"\nregion = \"us-south\"\n}\n}\n\nFor more information about the arguments and attributes, see [ibm_is_backup_policy_plan](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/resources\/is_backup_policy_plan).\n\n\n\n\n\n\n\n Next steps \n\nAfter you create a backup policy, you can do the following actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=api"},{"document_id":"ibmcld_15162-33319-34748","score":16.9615654199,"text":"\nFor more information about the arguments and attributes, see [ibm_is_backup_policy_plan](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/resources\/is_backup_policy_plan).\n\n\n\n\n\n Creating a backup plan with cross-regional copy option with Terraform \n\nNew\n\nTo create a backup plan with cross-regional copy option, use the ibm_is_backup_policy_plan resource. If the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the --encryption-key option. See the following example.\n\nresource \"ibm_is_backup_policy_plan\" \"example\" {\nbackup_policy_id = \"ibm_is_backup_policy.example.id\"\ncron_spec = \"30 \/2 * * 1-5\"\nname = \"my-policy-plan\"\ndeletion_trigger {\ndelete_after = 20\ndelete_over_count = 20\n}\nremote_copy_policies {\ndelete_over_count = 1\nencryption_key = \"crn:v1:bluemix:public:kms:us-south:a\/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd6179\"\nregion = \"us-south\"\n}\n}\n\nFor more information about the arguments and attributes, see [ibm_is_backup_policy_plan](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/resources\/is_backup_policy_plan).\n\n\n\n\n\n\n\n Next steps \n\nAfter you create a backup policy, you can do the following actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=cli"},{"document_id":"ibmcld_09562-7597-9856","score":16.8872775655,"text":"\nOne is the entry for the deployment that lists its status as delegator. It is \"User Created\".\n\n\n\nTable 1. Example delegator Key Protect Authorization\n\n Role Source Target Type \n\n AuthorizationDelegator, Reader <cloud-databases> Service Key Protect Service User defined \n\n\n\nAnd one for the Cloud Object Storage bucket for its backups, where the deployment is the initiator.\n\n\n\nTable 2. Example Key Protect Authorization for Cloud Object Storage from Cloud Databases\n\n Role Source Target Type \n\n Reader Cloud Object Storage service Key Protect Service Created by <cloud-databases-crn> \n\n\n\n\n\n\n\n Removing Keys \n\nIAM\/Key Protect does not stop you from removing the policy between the key and Cloud Object Storage (the second example), but doing so can make your backups unrestorable. To prevent this, if you delete the Cloud Object Storage policy that governs the ability of Cloud Databases to use the key for Cloud Object Storage, the policy is re-created to continue backing up your deployment.\n\nBe careful when removing keys and authorizations. If you have multiple deployments that use the same keys, it is possible to inadvertently destroy backups to all of those deployments by revoking the delegation authorization. If possible, do not use the same key for multiple deployment's backups.\n\nIf you want to shred the backups, you can delete the key. Cloud Object Storage ensures that the storage is unreadable and unwriteable. However, any other deployments that use that same key for backups encounter subsequent backup failures.\n\nIf you do require that the same key to be used for multiple deployment's backups, removing keys and authorizations can have the following side effects.\n\n\n\n* If you delete just the Cloud Object Storage authorization (as seen in Table 2), then not only is the deployment that is shown as the creator affected, but any deployments that also use the same key are also affected. Those deployments can encounter temporary backup failures until the policy is automatically re-created. There should be no lasting effects, except for missing backups.\n* If you delete just Cloud Databases delegator authorization, which is created by you (as seen in Table 1), nothing immediately breaks because the second authorization is still in place.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-key-protect"},{"document_id":"ibmcld_06638-7607-9866","score":16.8872775655,"text":"\nOne is the entry for the deployment that lists its status as delegator. It is \"User Created\".\n\n\n\nTable 1. Example delegator Key Protect Authorization\n\n Role Source Target Type \n\n AuthorizationDelegator, Reader <cloud-databases> Service Key Protect Service User defined \n\n\n\nAnd one for the Cloud Object Storage bucket for its backups, where the deployment is the initiator.\n\n\n\nTable 2. Example Key Protect Authorization for Cloud Object Storage from Cloud Databases\n\n Role Source Target Type \n\n Reader Cloud Object Storage service Key Protect Service Created by <cloud-databases-crn> \n\n\n\n\n\n\n\n Removing Keys \n\nIAM\/Key Protect does not stop you from removing the policy between the key and Cloud Object Storage (the second example), but doing so can make your backups unrestorable. To prevent this, if you delete the Cloud Object Storage policy that governs the ability of Cloud Databases to use the key for Cloud Object Storage, the policy is re-created to continue backing up your deployment.\n\nBe careful when removing keys and authorizations. If you have multiple deployments that use the same keys, it is possible to inadvertently destroy backups to all of those deployments by revoking the delegation authorization. If possible, do not use the same key for multiple deployment's backups.\n\nIf you want to shred the backups, you can delete the key. Cloud Object Storage ensures that the storage is unreadable and unwriteable. However, any other deployments that use that same key for backups encounter subsequent backup failures.\n\nIf you do require that the same key to be used for multiple deployment's backups, removing keys and authorizations can have the following side effects.\n\n\n\n* If you delete just the Cloud Object Storage authorization (as seen in Table 2), then not only is the deployment that is shown as the creator affected, but any deployments that also use the same key are also affected. Those deployments can encounter temporary backup failures until the policy is automatically re-created. There should be no lasting effects, except for missing backups.\n* If you delete just Cloud Databases delegator authorization, which is created by you (as seen in Table 1), nothing immediately breaks because the second authorization is still in place.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-key-protect"},{"document_id":"ibmcld_09549-4-1855","score":16.7619272165,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Managing Cloud Databases backups \n\nBackups for Cloud Databases deployments are accessible from the Backups tab of your deployment's dashboard. Here is some additional general information about backups:\n\n\n\n* One backup is taken every day.\n* Backups are available for 30 days.\n* Backups cannot be deleted.\n* If you delete your deployment, its backups are deleted automatically.\n* Daily backup scheduling is not configurable.\n* Backups are restorable to other regions, except for eu-de and par-01, which can restore backups only between each other. For example, par-01 backups can be restored to eu-de, and vice versa.\n* Backup storage is encrypted. To manage the encryption keys, see [Key Protect integration](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-key-protectbyok-for-backups). Otherwise, backups are encrypted with a key that is automatically generated for your deployment.\n* Backups are restorable across accounts, but only through the API and only if the user that is running the restore has access to both the source and destination accounts.\n* Cloud Databases backups are not downloadable. If you need a local backup, use the appropriate software. For example, [pg_dump](https:\/\/www.postgresql.org\/docs\/9.6\/static\/backup-dump.html) is an effective tool for managing PostgreSQL backups.\n* IBM Cloud\u00ae Databases for DataStax does not support reenablement. After a deployment is disabled, that deployment must be restored from a backup.\n\n\n\nFor information on taking an on-demand backup, see [Taking an on-demand backup](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-dashboard-backups&interface=cliondemand-backup).\n\n\n\n Backups in the UI \n\nThe backup types have their respective tabs, either On-demand or Automatic. Each backup is listed with its type and when the backup was taken.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-dashboard-backups"},{"document_id":"ibmcld_06339-4-1855","score":16.7619272165,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Managing Cloud Databases backups \n\nBackups for Cloud Databases deployments are accessible from the Backups tab of your deployment's dashboard. Here is some additional general information about backups:\n\n\n\n* One backup is taken every day.\n* Backups are available for 30 days.\n* Backups cannot be deleted.\n* If you delete your deployment, its backups are deleted automatically.\n* Daily backup scheduling is not configurable.\n* Backups are restorable to other regions, except for eu-de and par-01, which can restore backups only between each other. For example, par-01 backups can be restored to eu-de, and vice versa.\n* Backup storage is encrypted. To manage the encryption keys, see [Key Protect integration](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-key-protectbyok-for-backups). Otherwise, backups are encrypted with a key that is automatically generated for your deployment.\n* Backups are restorable across accounts, but only through the API and only if the user that is running the restore has access to both the source and destination accounts.\n* Cloud Databases backups are not downloadable. If you need a local backup, use the appropriate software. For example, [pg_dump](https:\/\/www.postgresql.org\/docs\/9.6\/static\/backup-dump.html) is an effective tool for managing PostgreSQL backups.\n* IBM Cloud\u00ae Databases for DataStax does not support reenablement. After a deployment is disabled, that deployment must be restored from a backup.\n\n\n\nFor information on taking an on-demand backup, see [Taking an on-demand backup](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-dashboard-backups&interface=cliondemand-backup).\n\n\n\n Backups in the UI \n\nThe backup types have their respective tabs, either On-demand or Automatic. Each backup is listed with its type and when the backup was taken.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-dashboard-backups"},{"document_id":"ibmcld_06380-4-1855","score":16.7619272165,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Managing Cloud Databases backups \n\nBackups for Cloud Databases deployments are accessible from the Backups tab of your deployment's dashboard. Here is some additional general information about backups:\n\n\n\n* One backup is taken every day.\n* Backups are available for 30 days.\n* Backups cannot be deleted.\n* If you delete your deployment, its backups are deleted automatically.\n* Daily backup scheduling is not configurable.\n* Backups are restorable to other regions, except for eu-de and par-01, which can restore backups only between each other. For example, par-01 backups can be restored to eu-de, and vice versa.\n* Backup storage is encrypted. To manage the encryption keys, see [Key Protect integration](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-key-protectbyok-for-backups). Otherwise, backups are encrypted with a key that is automatically generated for your deployment.\n* Backups are restorable across accounts, but only through the API and only if the user that is running the restore has access to both the source and destination accounts.\n* Cloud Databases backups are not downloadable. If you need a local backup, use the appropriate software. For example, [pg_dump](https:\/\/www.postgresql.org\/docs\/9.6\/static\/backup-dump.html) is an effective tool for managing PostgreSQL backups.\n* IBM Cloud\u00ae Databases for DataStax does not support reenablement. After a deployment is disabled, that deployment must be restored from a backup.\n\n\n\nFor information on taking an on-demand backup, see [Taking an on-demand backup](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-dashboard-backups&interface=cliondemand-backup).\n\n\n\n Backups in the UI \n\nThe backup types have their respective tabs, either On-demand or Automatic. Each backup is listed with its type and when the backup was taken.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=cloud-databases-dashboard-backups"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11164-6586-7646","score":24.006746142,"text":"\n* A design document explains how load balancing is used to keep a service highly available.\n* Where multi-site failover occurs, the disaster recovery plan must explain who does what to cause the failover and ensure restart.\n* The disaster recovery plan must define how the solution works and include restore point objectives that clearly explain how much data might be lost in the outage, if any. The disaster recovery plan also includes a detailed recovery workflow for restoring services and data if a multi-availability zone failure.\n* It must confirm how the Maximum Tolerable Downtime is met and be stored on the Disaster Recovery Plan database.\n* The disaster recovery plan specifies the security controls for running in Disaster mode, if they are different from what's running in production.\n\n\n\n\n\n\n\n Management of the disaster recovery plan \n\nThe requirements that IBM Cloud follows are:\n\n\n\n* The disaster recovery plan must be updated after any major infrastructure change, major application release, and after any test.\n* It must be approved annually.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtime"},{"document_id":"ibmcld_12584-10119-11773","score":23.8986074167,"text":"\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilities for disaster recovery\nThe first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n Meet disaster recovery objectives IBM follows best practices for disaster recovery. All IBM applications automatically recover and restart after any disaster event. For more information about disaster recovery, see the [IBM Disaster Recovery Plan](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtimedisaster-recovery). Customers can help meet disaster recovery objectives by deploying their project in a development or test environment before they deploy to production. <br>\\nThe customer does not have to take other actions to prepare for an event of a catastrophic failure in a region. \n Meet high availability objectives IBM Cloud is available globally and load balanced from a single URL. It is highly available and continues to run even if your resources are unavailable. For more information about high availability, see the [IBM service level objectives](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-slo) and the [sample application architecture](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-bcdr-app-recovery). N\/A","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-responsibilities-deployable-architectures"},{"document_id":"ibmcld_00471-3725-5071","score":23.6782306903,"text":"\nIf you intend to store sensitive information in an IBM Cloudant database, you must use client-side encryption to render data unreadable to IBM Cloudant operators. For example, for PCI DSS compliance, you must encrypt the Primary Account Number (PAN) before sending a document that contains it to the database. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes the following tasks:\n\n\n\n* Provide dependencies on disaster recovery sites.\n* Provision disaster recovery environments.\n* Back up data and configuration.\n* Replicate data and configuration to the disaster recovery environment.\n* Fail over disaster events.\n\n\n\n\n\nTable 4. Responsibilities for disaster recovery\nThe first column describes the task that the customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n HA\/DR (cross-region) Customer is responsible for creating more IBM Cloudant instances in separate regions and configuring replications to achieve the cross-region HA\/DR architecture they want. See [Configuring IBM Cloudant for cross-region disaster recovery](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-configuring-ibm-cloudant-for-cross-region-disaster-recovery) for more details.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-responsibilities"},{"document_id":"ibmcld_14407-0-837","score":23.4101722387,"text":"\n\n\n\n\n\n\n  High availability and disaster recovery for VMware Solutions \n\nLearn about high availability and disaster recovery for IBM Cloud\u00ae for VMware\u00ae Solutions.\n\nReview the following sections for more information:\n\n\n\n*  [Disaster recovery](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-understand-responsibunderstand-responsib-disaster-recovery)\n*  [Client responsibilities for vCenter Server instances](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_compl_infovc_compl_info-client-responsibilities)\n*  [High availability and disaster recovery for KMIP](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-kmip-hadr)\n*  [High availability and disaster recovery for VMware Shared](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_datashared_data-ha-dr)\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ha-dr"},{"document_id":"ibmcld_12183-6059-6904","score":23.4002261173,"text":"\nIncludes tasks such as monitoring, event management, high availability, problem determination, recovery, and full state backup and recovery.\n\n\n\n\n\n Change management \n\nIncludes tasks such as deployment, configuration, upgrades, patching, configuration changes, and deletion.\n\n\n\n\n\n Identity and access management \n\nIncludes tasks such as authentication, authorization, access control policies, and approving, granting, and revoking access.\n\n\n\n\n\n Security and regulation compliance \n\nIncludes tasks such as security controls implementation and compliance certification.\n\n\n\n\n\n Disaster recovery \n\nIncludes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sc-responsibilities"},{"document_id":"ibmcld_00488-8957-9756","score":23.3894588086,"text":"\n================================================================================\ncouchbackup:restore restored 5 +0ms\ncouchbackup:restore finished { total: 5 } +1ms\n\n\n\nYou completed the backup and restore of a database and created a log file. For more information, see [Disaster recovery and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backupdisaster-recovery-and-backup), [Configuring IBM Cloudant for cross-region disaster recovery](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-configuring-ibm-cloudant-for-cross-region-disaster-recoveryconfiguring-ibm-cloudant-for-cross-region-disaster-recovery), and [IBM Cloudant backup and recovery](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-a-backup"},{"document_id":"ibmcld_11164-4529-7122","score":23.3696055501,"text":"\nFor more information about particular high availability and disaster recovery practices specific to each service or infrastructure option, refer the documentation for that service.\n\n\n\n\n\n High availability for the network \n\nExcept for the oldest pod that still has some single points of failure, the IBM Cloud network is designed in such a way that a single point of failure never happens. Diverse, redundant connectivity exists at every point of the network, by using diverse telecommunication providers for the same service connectivity whenever possible within each region. Diverse dark fiber providers are used to connect every edge site to all of the regional compute facilities. Each edge site additionally has redundant backbone connectivity into other regions, and peers with multiple providers, both directly and indirectly, through a local exchange. No single event should ever result in a service disruption that is noticed by our customers.\n\nYou can always choose to \"break\" having no single point of failure with how you order or configure your SoftLayer classic servers. For Direct Link, you must order redundant connections if you want full redundancy because it's not built-in or automatic.\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery is about surviving a catastrophic failure or loss of availability in a single location. For the console and platform services, there are no actions that you need to take to prepare for an event of a catastrophic failure in a region.\n\n\n\n Disaster recovery plan \n\nIBM Cloud follows best practices for disaster recovery. All IBM Cloud applications automatically recover and restart after any disaster event. Recovery is from electronic backups at a recovery center or alternative computing facilities that restore computing. Before any potential disaster, the disaster recovery plan includes the systems and hosting requirements for hardware, software, networking connectivity, and offsite backup capabilities.\n\nThe following list includes the requirements that IBM adheres to for a disaster recovery plan:\n\n\n\n* A design document explains how load balancing is used to keep a service highly available.\n* Where multi-site failover occurs, the disaster recovery plan must explain who does what to cause the failover and ensure restart.\n* The disaster recovery plan must define how the solution works and include restore point objectives that clearly explain how much data might be lost in the outage, if any. The disaster recovery plan also includes a detailed recovery workflow for restoring services and data if a multi-availability zone failure.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtime"},{"document_id":"ibmcld_06123-7-1983","score":23.3312148519,"text":"\nSetting up disaster recovery with Portworx \n\nYou can configure disaster recovery for your data that you store in your Kubernetes clusters by using Portworx. When one of your clusters becomes unavailable, Portworx automatically fails over to another cluster so that you can still access your data.\n\nDisaster recovery with Portworx requires at least two Kubernetes clusters where Portworx is installed and configured for disaster recovery. One of the two clusters is considered the active cluster where your data is primarily stored. All data is then replicated to the standby cluster. If your active cluster becomes unavailable, Portworx automatically fails over to the standby cluster and makes the standby cluster the new active cluster so that data can continue to be accessed.\n\nIf you installed Portworx in one of your clusters without the Portworx disaster recovery plan, you must re-install Portworx with the disaster recovery plan so that you can include this cluster in your disaster recovery configuration.\n\nDepending on your cluster setup, Portworx offers the following two disaster recovery configurations:\n\n\n\n* [Metro DR](https:\/\/docs.portworx.com\/portworx-install-with-kubernetes\/disaster-recovery\/1-metro-dr-nodes-are-in-the-metro-area-network-man): Your Kubernetes clusters are in the same metro location, such as both clusters are deployed in one or multiple zones of the us-south region. All clusters are configured to use the same Portworx cluster and share the same Portworx key-value store. Data is automatically replicated between the clusters because the Portworx storage layer is shared. RPO (Recovery Point Objective) and RTO (Recovery Time Objective) for this configuration is less than 60 seconds.\n* [Asynchronous DR](https:\/\/docs.portworx.com\/portworx-install-with-kubernetes\/disaster-recovery\/2-asynchronous-dr-nodes-are-across-different-regions-datacenters): Your Kubernetes clusters are deployed in different regions, such as us-south and us-east.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage_portworx_recovery"},{"document_id":"ibmcld_14598-9419-11893","score":23.2901831107,"text":"\nResponsibilities for security and regulation compliance for VMware Solutions offerings (other than VMware Shared)\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM responsibilities Your responsibilities \n\n Encryption Provide integration with Key Protect and Hyper Protect Crypto Services through KMIP service as an option for implementing data at-rest encryption. Configure and manage encryption for both data at rest and in transit, as needed. \n\n\n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as:\n\n\n\n* Providing dependencies on disaster recovery sites\n* Provision disaster recovery environments\n* Data and configuration backup\n* Replicating data and configuration to the disaster recovery environment\n* Fail over on disaster events\n\n\n\n\n\n Disaster recovery for VMware Shared \n\nThe following table describes the responsibilities that are related to disaster recovery for VMware Shared.\n\n\n\nTable 8. Responsibilities for disaster recovery for VMware Shared\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM responsibilities Your responsibilities \n\n Backup of configuration data Backups are conducted of the shared management components to include customer environment configurations. Offsite backup copies are enabled and they run daily. \n Backup of workload Backup services are enabled for customer workload. Configure individual backup jobs to include critical systems. Offsite copies can be enabled per request. \n Recovery of configuration Recovery will be conducted in the original data center after the infrastructure is available. If long-term outage occurs, offsite recovery is conducted. \n Recovery of workloads Restore capabilities are available in normal operations. For configuration restores, customer restore services will be provided after the infrastructure is available. If an offsite recovery is required, IBM works with the customer to help recover. Restore systems from the configured backup jobs. \n\n\n\n\n\n\n\n Disaster recovery for VMware Solutions offerings (other than VMware Shared)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-understand-responsib"},{"document_id":"ibmcld_12585-5718-7900","score":23.2783510427,"text":"\n(https:\/\/cloud.ibm.com\/docs\/overview\/terms-of-use?topic=overview-security). Secure your workloads and data. Integrate tools into your toolchains that satisfy your security and compliance requirements. To learn more about securing your cloud apps, see [Security to safeguard and monitor your cloud apps](https:\/\/www.ibm.com\/cloud\/architecture\/architecture\/practices\/securing-cloud-native-apps-risks-mitigation\/). To learn more about securing your data while you are using the Projects service, see [Securing your data](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd_data_security&interface=ui). To learn more about regulatory compliance with the Projects service, see [Understanding tool integrations with IBM for Financial Services](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-integrations&interface=ui). \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilites for disaster recovery\nThe first column describes the task that the customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n Meet disaster recovery objectives IBM follows best practices for disaster recovery. All IBM applications automatically recover and restart after any disaster event. For more information about disaster recovery see the [IBM Disaster Recovery Plan](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtimedisaster-recovery). Customer can help meet DR objectives by deploying their project in a development or test environment before deploying to production.<br><br>There are no other actions the customer needs to take to prepare for an event of a catastrophic failure in a region. \n Meet high availability objectives IBM is available globally and load balanced from a single URL.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-responsibilities-projects"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04149-3050-4970","score":20.4325745191,"text":"\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https:\/\/whois.icann.org\/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04334-199697-200931","score":19.1873432957,"text":"\n<-- <\/section \"id=\"section-create-cis-service-instance-examples\" \"> --><-- <\/section \"id=\"section-create-cis-service-instance\" \"> --><-- <section \"id=\"section-delete-cis-service-instance\" \"> --> ibmcloud cis instance-delete Delete a CIS service instance. ibmcloud cis instance-delete INSTANCE -f, --force] ! ! ! ! ! !\n<-- <section \"id=\"section-delete-cis-service-instance-options\" \"> --> Command options INSTANCE: The name or ID of a CIS service instance. Required.-f, --force: Delete instance without prompting for confirmation.<-- <\/section \"id=\"section-delete-cis-service-instance-options\" \"> --><-- <section \"id=\"section-delete-cis-service-instance-examples\" \"> --> Examples Delete cis instance cis-demo ibmcloud cis instance-delete cis-demo -f\n<-- <\/section \"id=\"section-delete-cis-service-instance-examples\" \"> --><-- <\/section \"id=\"section-delete-cis-service-instance\" \"> --><-- <section \"id=\"section-update-cis-service-instance\" \"> --> ibmcloud cis instance-update Update a CIS service instance. ibmcloud cis instance-update INSTANCE --name NAME] --plan PLAN] --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-update-cis-service-instance-options\" \"> --> Command options INSTANCE: The name or ID of a CIS service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04183-0-2205","score":18.7777096018,"text":"\n\n\n\n\n\n\n  Securing your data in CIS \n\nTo ensure that you can securely manage your data when you use IBM Cloud\u00ae Internet Services, it is important to know exactly what data is stored and encrypted and how to delete any stored personal data.\n\n\n\n  How your data is stored and encrypted in CIS \n\nCIS interacts with Cloudflare services using a channel that is fully encrypted end-to-end using Transport Layer Security (TLS) 1.2. CIS does not store any customer data. Configuration data about your specific CIS configuration is encrypted in transit and at rest. CIS configuration data is deleted on your request through the UI, CLI, or API.\n\n\n\n\n\n  Protecting your sensitive data in CIS \n\nAll data related to CIS configuration is not considered sensitive data. The configuration data is encrypted at rest. No customer-managed keys are managed by the CIS offering. Therefore, neither Key Protect nor Hyper Protect Crypto Services are used.\n\n\n\n  Working with customer-managed keys for CIS \n\nNo customer-managed keys are managed by the CIS offering.\n\n\n\n\n\n\n\n  Deleting your data in CIS \n\nThe CIS configuration data is deleted on request through the UI, CLI or API.\n\n\n\n  Deleting CIS instances \n\nThe CIS data retention policy describes how long your data is stored after you delete the service. The data retention policy is included in the CIS service description, which you can find in [IBM Cloud Terms](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-terms). When a CIS instance is deleted by the UI, CLI, or API, the instance data is retained for seven days from deletion.\n\nBefore deleting an instance, all the domains in the instance must be removed.\n\nDeleting the CIS instance removes all data.\n\n\n\n\n\n  Restoring deleted data for CIS \n\nCIS can currently restore the deleted instance. After you delete an instance of CIS, you can restore the deleted service instance within the data retention period of seven days. After the seven-day period expires, the service instance is permanently deleted.\n\nTo view which service instances are available for restoration, use the ibmcloud resource reclamations command. To restore a deleted service instance, use the ibmcloud resource reclamation-restore command.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mng-data"},{"document_id":"ibmcld_04186-18298-19703","score":18.7551668652,"text":"\n[Page Rules](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cb1eb27836421578019401fa7556779109430b29\/cis\/includes\/solution-tutorials\/includes\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-pagerules.png)\n\nPage Rules\n\n\n\n\n\n\n\n Step 5: Remove resources \n\n\n\n Remove Kubernetes Cluster resources \n\n\n\n1. Remove the Ingress, you can do so by running the following command:\n\nkubectl delete -f glb-ingress.yaml\n2. Remove the service, you can do so by running the following command:\n\nkubectl delete service hello-world-service\n3. Remove the deployment, you can do so by running the following command:\n\nkubectl delete deployment hello-world-deployment\n4. Delete the clusters if you created them specifically for this tutorial.\n\n\n\n\n\n\n\n Remove CIS resources \n\n\n\n1. Remove the GLB.\n2. Remove the origin pools.\n3. Remove the health checks.\n4. Update the DNS for your custom domain.\n5. Delete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)\n* [Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers)\n* [Building containers from images](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-images)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-region-k8s-cis"},{"document_id":"ibmcld_01391-18343-19753","score":18.6683921965,"text":"\n[Page Rules](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cbb80bf851fb762a838129cba09d5674f8bfffda\/Registry\/includes\/solution-tutorials\/includes\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-pagerules.png)\n\nPage Rules\n\n\n\n\n\n\n\n Step 5: Remove resources \n\n\n\n Remove Kubernetes Cluster resources \n\n\n\n1. Remove the Ingress, you can do so by running the following command:\n\nkubectl delete -f glb-ingress.yaml\n2. Remove the service, you can do so by running the following command:\n\nkubectl delete service hello-world-service\n3. Remove the deployment, you can do so by running the following command:\n\nkubectl delete deployment hello-world-deployment\n4. Delete the clusters if you created them specifically for this tutorial.\n\n\n\n\n\n\n\n Remove CIS resources \n\n\n\n1. Remove the GLB.\n2. Remove the origin pools.\n3. Remove the health checks.\n4. Update the DNS for your custom domain.\n5. Delete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)\n* [Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers)\n* [Building containers from images](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-images)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-multi-region-k8s-cis"},{"document_id":"ibmcld_04334-198873-200152","score":18.5627223934,"text":"\n<-- <\/section \"id=\"section-set-context-cis-service-examples\" \"> --><-- <\/section \"id=\"section-set-context-cis-service-instance\" \"> --><-- <section \"id=\"section-create-cis-service-instance\" \"> --> ibmcloud cis instance-create Create a CIS service instance. ibmcloud cis instance-create INSTANCE_NAME PLAN --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-create-cis-service-instance-options\" \"> --> Command options INSTANCE_NAME: The name of CIS service instance. Required.PLAN: The name or ID of a service plan. Required.--output: Specify output format, only JSON is supported.<-- <\/section \"id=\"section-create-cis-service-instance-options\" \"> --><-- <section \"id=\"section-create-cis-service-instance-examples\" \"> --> Examples Create a standard plan cis instance cis-demo ibmcloud cis instance-create cis-demo standard\n<-- <\/section \"id=\"section-create-cis-service-instance-examples\" \"> --><-- <\/section \"id=\"section-create-cis-service-instance\" \"> --><-- <section \"id=\"section-delete-cis-service-instance\" \"> --> ibmcloud cis instance-delete Delete a CIS service instance. ibmcloud cis instance-delete INSTANCE -f, --force] ! ! ! ! ! !\n<-- <section \"id=\"section-delete-cis-service-instance-options\" \"> --> Command options INSTANCE: The name or ID of a CIS service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04132-3821-5296","score":18.5427577147,"text":"\nDeleting a webhook using the CLI \n\nTo delete a webhook using the CLI, run the following command.\n\nibmcloud cis alert-webhook-delete WEBHOOK_ID [-i, --instance INSTANCE] [-f, --force]\n\nWhere:\n\n\n\n* WEBHOOK_ID is the ID of webhook.\n* i, --instance value is the instance name or ID. If not set, the context instance specified by 'cis instance-set INSTANCE' is used.\n* -f, --force attempts to delete webhook without prompting for confirmation.\n\n\n\n\n\n\n\n\n\n Configuring webhooks using the API \n\nTo call these methods, you must be assigned one or more IAM access roles.\n\n\n\n* internet-svcs.zones.read\n* internet-svcs.zones.update\n\n\n\nYou can check your access by going to Users > name > Access policies.\n\n\n\n Creating a webhook using the API \n\nCreating a webhook alert is a two step process. First, create the webhook, then use the ID in the response that you receive to create the alert.\n\nTo create a webhook by using the API, follow these steps:\n\n\n\n1. Set up your API environment with the correct variables.\n2. Store your the following variable to be used in the API command:\n\n\n\n* crn: the full url-encoded CRN of the service instance.\n* name: the name of the webhook.\n* url: the URL of the webhook.\n* secret: the optional secret or API key needed to use the webhook.\n\n\n\n3. When all variables are initiated, create the webhook:\n\n\n\ncurl -X POST https:\/\/api.cis.cloud.ibm.com\/v1\/:crn\/alerting\/destinations\/webhooks\n-H 'content-type: application\/json'\n-H 'x-auth-user-token: Bearer xxxxxx'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-webhooks"},{"document_id":"ibmcld_13139-17831-19468","score":18.4037886992,"text":"\nIn addition, you can now control what content gets cached by CIS and how long it stays cached. Go to Performance > Caching to define the global caching level and the browser expiration. You can customize the global security and caching rules with Page Rules. Page Rules enable fine-grained configuration using specific domain paths. As example with Page Rules, you could decide to cache all contents under \/assets for 3 days:\n\nZoom\n\n![Page Rules](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-pagerules.png)\n\nPage Rules\n\n\n\n\n\n\n\n Step 5: Remove resources \n\n\n\n Remove Kubernetes Cluster resources \n\n\n\n1. Remove the Ingress, you can do so by running the following command:\n\nkubectl delete -f glb-ingress.yaml\n2. Remove the service, you can do so by running the following command:\n\nkubectl delete service hello-world-service\n3. Remove the deployment, you can do so by running the following command:\n\nkubectl delete deployment hello-world-deployment\n4. Delete the clusters if you created them specifically for this tutorial.\n\n\n\n\n\n\n\n Remove CIS resources \n\n\n\n1. Remove the GLB.\n2. Remove the origin pools.\n3. Remove the health checks.\n4. Update the DNS for your custom domain.\n5. Delete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-multi-region-k8s-cis"},{"document_id":"ibmcld_04334-74160-75348","score":18.2597757607,"text":"\n* lockdowns: Lock access to URLs in this domain to only permitted addresses or address ranges.\n\n\n\n-d, --domain\n: DNS Domain ID. For ua-rules and lockdowns type rule, it is a required parameter.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n\n\n\n\n Examples \n\nDelete a firewall rule.\n\nibmcloud cis firewall-delete dc014906ccce4e7ea2e28be7df70d0d2 -t access-rules -i \"cis-demo\"\nibmcloud cis firewall-delete bc014906ccce4e7ea2e28be7df70d0d2 -t access-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall-delete 4af47b1518be478aa2c8f024af1c0bad -t ua-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall-delete e6106d7ec58e47ebb2fa053dedcd7dcb -t lockdown -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n\n\n Firewall rules \n\nManipulate how firewall rules perform using the following firewall-rules commands:\n\n\n\n ibmcloud cis firewall-rules \n\nRetrieve a list of currently existing firewall-rules for a given DNS domain.\n\nibmcloud cis firewall-rules DNS_DOMAIN_ID [--page PAGE] [--per-page PER_PAGE] [-i, --instance INSTANCE] [ ! ! ! ! ! ! --output FORMAT","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-196613-197723","score":18.2570890389,"text":"\n! ! ! ! ! ! !\n<-- <section \"id=\"section-delete-ratelimit-rule-options\" \"> --> Command options DNS_DOMAIN_ID: The ID of DNS domain. Required.RATELIMIT_RULE_ID: The ID of rate limit rule. Required.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.<-- <\/section \"id=\"section-delete-ratelimit-rule-options\" \"> --><-- <section \"id=\"section-delete-ratelimit-rule-examples\" \"> --> Examples Delete rate limiting rule 372e67954025e0ba6aaa6d586b9e0b60. ibmcloud cis ratelimit-rule-delete 31984fea73a15b45779fa0df4ef62f9b 372e67954025e0ba6aaa6d586b9e0b60 -i \"cis-demo\"\n<-- <\/section \"id=\"section-delete-ratelimit-rule-examples\" \"> --><-- <\/section \"id=\"section-delete-ratelimit-rule\" \"> --><-- <\/section \"id=\"section-ratelimit\" \"> --><-- <section \"id=\"section-resource-instance\" \"> --> Resource instance Manipulate CIS Service instances by using the following instance commands.<-- <section \"id=\"section-list-cis-service-instances\" \"> --> ibmcloud cis instances List all CIS service instances. ibmcloud cis instances --output FORMAT] ! ! ! ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04149-3050-4970","score":50.996515193,"text":"\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https:\/\/whois.icann.org\/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04334-31256-32402","score":46.9455334039,"text":"\n: The ID of DNS record. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nGet a dns record details in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-record-delete \n\nDelete a DNS record for a given domain of a service instance.\n\nibmcloud cis dns-record-delete DNS_DOMAIN_ID DNS_RECORD_ID [-i, --instance INSTANCE]\n\n\n\n Command options \n\n`DNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\nDNS_RECORD_ID\n: The ID of DNS record. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE will be used.\n\n\n\n\n\n Examples \n\nDelete a dns record in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record-delete 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records \n\nList all DNS records for a given domain of a service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-32129-33511","score":41.49415888,"text":"\nDelete a dns record in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record-delete 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records \n\nList all DNS records for a given domain of a service instance.\n\nibmcloud cis dns-records DNS_DOMAIN_ID [--type TYPE] [--name NAME] [--content CONTENT] [--page PAGE] [--per-page PER_PAGE] [--order ORDER] [--direction DIRECTION] [--match MATCH] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--type\n: Type of DNS records to display.\n\n--name\n: Value of name field to filter by.\n\n--content\n: Value of content field to filter by.\n\n--page\n: Page number of paginated results.\n\n--per_page\n: Maximum number of DNS records per page.\n\n--order\n: Field by which to order list of DNS records. Valid values are type, name, content, ttl, proxied\n\n--direction\n: Direction in which to order results [ascending or descending order]. Valid values are asc, desc\n\n--match\n: Whether to match all or at least one search parameter. Valid values are any, all.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList all dns records in domain 31984fea73a15b45779fa0df4ef62f9b.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-33215-34565","score":40.131960565,"text":"\nValid values are any, all.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList all dns records in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records-import \n\nImport your BIND config.\n\nibmcloud cis dns-records-import DNS_DOMAIN_ID --file FILE [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: BIND config to import. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nImport BIND config in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records-import 31984fea73a15b45779fa0df4ef62f9b --file bind_config_file.txt -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records-export \n\nExport BIND config.\n\nibmcloud cis dns-records-export DNS_DOMAIN_ID [--file FILE] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: The BIND config file that saves exported DNS records.\n\n-i, --instance\n: Instance name or ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04140-0-1975","score":39.4849321666,"text":"\n\n\n\n\n\n\n  Why is my domain still in Moved status? \n\n  What\u2019s happening \n\nYou have a domain that should be Active, but is still in the Moved status.\n\n  Why it\u2019s happening \n\nCIS becomes the authoritative DNS provider for your domain when your domain points to CIS nameservers. During the setup process CIS detects the nameservers and activates the domain.\n\n\n\n*  If the nameservers no longer point to CIS, the system automatically mark your domain as Moved after 7 days. An email to inform you of this status change is sent to the email address on file. A domain in Moved status remains in the system for an additional 7 days before it is permanently deleted.\n*  Conflicting NS records can cause a domain to change to Moved status.\n\n\n\n  How to fix it \n\nTo resolve the condition where your domain remains in Moved status longer than expected, take the following troubleshooting steps.\n\n\n\n*  Check your DNS registrar and ensure that the NS records match with the NS records given by CIS.\n\n\n\n*  Find the NS records in the CIS name servers section of the DNS tab in the Reliability page. For more information, see [Step 4. Configure your name servers with the registrar or existing DNS provider](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-startedconfigure-your-name-servers-with-the-registrar-or-existing-dns-provider).\n\n\n\n*  Run the activation check API again. You can use the [API endpoint](https:\/\/cloud.ibm.com\/apidocs\/ciszone-activation-check) first to initiate the recheck.\n\n\n\n*  As long as the NS values for the domain are pointed in the correct direction by a dig, and the reactivation check is done by using the API, the domain should go from Moved status to Active.\n\n\n\n*  Remove and replace any previous NS records with the CIS-provided records in your DNS registrar.\n\n\n\nIf the domain is still stuck in a Moved status after taking these steps, [open a Support](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-gettinghelp) case with details about which steps you took.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-domain-moved-status"},{"document_id":"ibmcld_04195-6086-8151","score":39.345712388,"text":"\nBecause CIS doesn't support email traffic by default, you must set the PTR record to the location of your email server. Contact your email provider for assistance.\n\n\n\n\n\n\n\n Updating DNS records \n\nIn each record row, you can click the Edit record option from the menu, which opens a dialog box that you can use to update the record.\n\nAfter you are finished making your changes, select Update record to save them, or Cancel to abort the changes.\n\n\n\n\n\n Deleting DNS records \n\nIn each record row, you can select the Delete record option from the menu, which opens a dialog box to confirm the delete process.\n\nYou can select the Delete button to confirm your delete action. Select Cancel if you don't want to delete.\n\n\n\n\n\n Importing and exporting DNS records \n\nDNS records can be imported into and exported from CIS. All files are imported and exported as .txt files in BIND format. Learn more about [BIND format](https:\/\/en.wikipedia.org\/wiki\/Zone_file). Click the overflow menu and select to import or export records.\n\nImport records - By default, a total of 3500 DNS records are allowed (imported and created on CIS). You can import multiple files, one at a time, as long as the total number of records is under the max limit. After importing, you are shown a summary with the number of records successfully added and the number that failed, along with the reason why each record failed.\n\nExport records - Use Export records to create a backup of your zone file, or export it to use with another DNS provider. When this menu option is clicked, the records are downloaded to the location specified by your browser settings (typically the Downloads folder). To select another folder location, change your browser's settings to prompt you for a location with each download.\n\n\n\n\n\n Configuring and managing your secure DNS \n\nDNSSec is a technology to digitally sign DNS data so you can be assured it is valid. To eliminate vulnerability from the internet, DNSSec must be deployed at each step in the lookup, from root zone to final domain name (for example, www.icann.org).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-set-up-your-dns-for-cis"},{"document_id":"ibmcld_04334-30336-31563","score":39.2533636219,"text":"\nA file contains input JSON data.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nUpdate a dns record in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record-update 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 --json '{\"name\": \"testCNAME\", \"type\": \"CNAME\", \"content\": \"example.com\"}' -i \"cis-demo\"\nibmcloud cis dns-record-update 31984fea73a15b45779fa0df4ef62f9b 417e8605a72d3e085020b82c93cd7f82 --type A --name testA --content \"127.0.0.1\" -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-record \n\nGet a DNS record details for a given domain under a service instance.\n\nibmcloud cis dns-record DNS_DOMAIN_ID DNS_RECORD_ID [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\nDNS_RECORD_ID\n: The ID of DNS record. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nGet a dns record details in domain 31984fea73a15b45779fa0df4ef62f9b.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-25771-26954","score":39.1349140528,"text":"\nCreate a dns record in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record-create 31984fea73a15b45779fa0df4ef62f9b --json '{\"name\": \"testCNAME\", \"type\": \"CNAME\", \"content\": \"example.com\"}' -i \"cis-demo\"\nibmcloud cis dns-record-create 31984fea73a15b45779fa0df4ef62f9b --type A --name testA --content \"127.0.0.1\" -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-record-update \n\nUpdate a DNS record for a given domain of a service instance.\n\nibmcloud cis dns-record-update DNS_DOMAIN_ID DNS_RECORD_ID (--json @JSON_FILE | JSON_STRING) [-i, --instance INSTANCE] [--output FORMAT]\nibmcloud cis dns-record-update DNS_DOMAIN_ID DNS_RECORD_ID [--type TYPE] [--name NAME] [--content CONTENT] [--proxied PROXIED] [--ttl TTL] [--output FORMAT]\n[Deprecated] ibmcloud cis dns-record-update DNS_DOMAIN_ID DNS_RECORD_ID --json-str JSON_STR [-i, --instance INSTANCE] [--output FORMAT]\n[Deprecated] ibmcloud cis dns-record-update DNS_DOMAIN_ID DNS_RECORD_ID --json-file JSON_FILE [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\nDNS_RECORD_ID\n: The ID of DNS record. Required.\n\n--name\n: DNS record name.\n\n--type\n: DNS record type.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-20830-22207","score":38.6748317206,"text":"\nibmcloud cis custom-pages [-d, --domain DNS_DOMAIN_ID] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\n`-d, --domain\n: DNS Domain ID.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList existing custom pages for domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis custom-pages -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n\n\n DNS record \n\nManipulate how the DNS Record performs using the following dns-record commands:\n\n\n\n ibmcloud cis dns-record-create \n\nCreate a DNS record for a given domain of a service instance.\n\nibmcloud cis dns-record-create DNS_DOMAIN_ID (--json @JSON_FILE | JSON_STRING) [-i, --instance INSTANCE] [--output FORMAT]\nibmcloud cis dns-record-create DNS_DOMAIN_ID --type TYPE --name NAME --content CONTENT [--ttl TTL] [-i, --instance INSTANCE] [--output FORMAT]\n[Deprecated] ibmcloud cis dns-record-create DNS_DOMAIN_ID --json-str JSON_STR [-i, --instance INSTANCE] [--output FORMAT]\n[Deprecated] ibmcloud cis dns-record-create DNS_DOMAIN_ID --json-file JSON_FILE [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--name\n: DNS record name.\n\n--type\n: DNS record type.\n\n--content\n: DNS record content.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04145-3314-5349","score":37.020084435,"text":"\nWhen you add a domain to CIS, we give you a couple of name servers to configure at your registrar (or at your DNS provider, if you are adding a subdomain). The domain or subdomain remains in pending state until you configure the name servers correctly. Make sure you add both the name servers to your registrar or DNS provider. We periodically scan the public DNS system to check whether the name servers have been configured as instructed. As soon as we are able to verify the name server change (which can take up to 24 hours), we activate your domain. You can submit a request to recheck name servers by clicking on Recheck name servers in the overview page.\n\n\n\n\n\n Who is the registrar for my domain? \n\nConsult [https:\/\/whois.icann.org\/](https:\/\/whois.icann.org\/) for this information.\n\nYou must have the administrator privilege to edit your domain's configuration at the registrar in order to update or add the name servers provided for your domain when you add it to CIS. If you don't know who the registrar is for the domain you're trying to add to CIS, it is unlikely you have the permission to update your domain's configuration at the registrar. Work with the owner of the domain in your organization to make the necessary changes.\n\n\n\n\n\n I want to keep my current DNS provider for my domain (example.com). Can I delegate a subdomain (subdomain.example.com) from my current DNS provider to CIS? \n\nYes. The process is similar to adding a domain, but instead of the registrar, you work with the DNS provider for the higher level domain. When you add a subdomain to CIS, you are given two name servers to configure, as usual. You configure a Name Server (NS) record for each of the two name servers as DNS records within your domain being managed by the other DNS provider. When we are able to verify that the required NS records have been added, we activate your subdomain. If you do not manage the higher level domain within your organization, you must work with the owner of the higher level domain to get the NS records added.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-faq"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.8315546296}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07019-6617-8864","score":19.0879320163,"text":"\nHowever, if you use an entity extractor enrichment, you can identify when a location is mentioned based on how the location is referenced in a sentence. With phrases such as, \u201cI live in x\u201d or \u201cI'm from x\u201d or \u201cI'm traveling to x\u201d in its training data, the entity extractor can learn that x is a reference to a location.\n\nWhen you need to choose between using a dictionary or an entity extractor enrichment, follow these guidelines:\n\n\n\n* If the list of possible examples is short, use a dictionary.\n\nIt is more efficient to define a dictionary term planet with synonyms such as Earth and Saturn than to create a planet entity because only 8 planets exist in our solar system. However, defining a list of every possible location on Earth is not feasible. An entity extractor can recognize more location mentions.\n* If the list of possible examples is static, use a dictionary.\n\nControversy over Pluto aside, the planet category is a good example here too because the list of planets in our solar system is static. Or maybe you want to monitor general customer sentiment about your products. You need to be able to recognize product name mentions, but might not need specifics. If you have a large variety of product names, you can create a product name entity. As new products are added to your portfolio, or product names change over time, you do not need to maintain an overall product list. The entity extractor can continue to recognize general feedback about your products based on the context of the sentences in which products are mentioned.\n\n\n\n\n\n\n\n Add a resource \n\nWhen you add a custom enrichment to a project it is available to any collection in the project.\n\nTo add a resource, complete the following steps:\n\n\n\n1. Open your project and go to the Improve and customize page.\n2. On the Improvement tools panel, expand Teach domain concepts, and then choose the resource that you want to add.\n\nAfter you create the resource, it becomes a new type of enrichment that you can apply to your data.\n3. Specify the collection and field in which to apply the enrichment.\n\nYou can apply enrichments to the text and html fields, and to custom fields that were added from uploaded JSON or CSV files or from the Smart Document Understanding (SDU) tool.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-domain"},{"document_id":"ibmcld_14308-8236-10382","score":18.4979913294,"text":"\nAt the required time, the domain controllers can be migrated to the vCenter Server instance with no change.\n\nDepending on the complexity of the Active Directory Domain Services, when the layer 2 network extension is removed, more Active Directory Domain Services tasks might need to be completed if the complete forest domain is not moved to IBM Cloud. The use of AD sites can help with the control of replication traffic across the layer 3 network between on-premises and IBM Cloud. See to the extended domain with AD sites model described in the previous section. The following diagram shows the Active Directory Domain Services topology for this extended domain model.\n\nZoom\n\n![Extended domain diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/adds-extendeddomain.svg)\n\nFigure 5. Extended domain diagram\n\n\n\n\n\n Restructuring AD domains \n\nHowever, it is possible to restructure AD domains the details are out of scope of this document. Review the following two types of restructure.\n\n\n\n* Inter-forest restructure - When you migrate objects between forests, both the source domain and the target domain environments exist, and you can roll back to the source environment during the migration, if necessary.\n* Intra-forest restructure - When you restructure domains within a forest, the migrated accounts no longer exist in the source domain.\n\n\n\nFor more information, see [ADMT guide - Migrating and restructuring Active Directory domains](https:\/\/www.microsoft.com\/en-us\/download\/confirmation.aspx?id=19188) (Document download).\n\n\n\n\n\n Best practice guidance for AD in a vCenter Server instance \n\nReview the following guidance for AD in a vCenter Server instance.\n\n\n\n* For more information about supported AD trusts, see [Microsoft Active Directory trusts supported by VMware vCenter Single Sign-on](https:\/\/kb.vmware.com\/s\/article\/2064250).\n* Enable vCenter with an identity source for authentication of all vCenter services and system administrators. This configuration is made by the VMware Solutions automation ready for the customer to add their system administrator users.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-adds-wkld-domain"},{"document_id":"ibmcld_13309-10859-13196","score":18.3838914546,"text":"\nHow Is Coronary Microvascular Disease Treated?\nIf you're diagnosed with coronary MVD and also have anemia, you may benefit from treatment for that condition.\nAnemia is thought to slow the growth of cells needed to repair damaged blood vessels.\nWhat causes autoimmune hepatitis?\nA combination of autoimmunity, environmental triggers, and a genetic predisposition can lead to autoimmune hepatitis.\nWhat research is being done for Spinal Cord Injury?\nThe National Institute of Neurological Disorders and Stroke NINDS conducts spinal cord research in its laboratories at the National Institutes of Health NIH.\nNINDS also supports additional research through grants to major research institutions across the country.\nSome of the more promising rehabilitation techniques are helping spinal cord injury patients become more mobile.\nWhat is Osteogenesis imperfecta OI?\n. . .\nShow more\n\nCharacter sequences in words from a custom model are in competition with character sequences from the base model, as well as sequences from other words of the model. (Factors such as audio noise and speaker accents also affect the quality of transcription.)\n\nThe accuracy of transcription can depend largely on the data that you add to a model and how speakers say words in audio. To improve the service's accuracy, use corpora to provide as many examples as possible of how words are used in a domain. Repeating the words in corpora can improve the quality of a custom language model. How you duplicate the words in corpora depends on how you expect users to say them in the audio that is to be recognized. The more sentences that you add that represent the context in which speakers use words from the domain, the better the service's recognition accuracy.\n\nFor example, accountants adhere to a common set of standards and procedures that are known as Generally Accepted Accounting Principles (GAAP). When you create a custom model for a financial domain, provide sentences that use the term GAAP in context. The sentences help the service distinguish between general phrases such as \"the gap between them is small\" and domain-centric phrases such as \"GAAP provides guidelines for measuring and disclosing financial information.\"\n\nIn general, it is better for corpora to use words in different contexts, which can improve how the service learns the phrases.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-corporaWords-ng"},{"document_id":"ibmcld_13301-7730-10125","score":18.2181448251,"text":"\nThe National Institute of Neurological Disorders and Stroke NINDS conducts spinal cord research in its laboratories at the National Institutes of Health NIH.\nNINDS also supports additional research through grants to major research institutions across the country.\nSome of the more promising rehabilitation techniques are helping spinal cord injury patients become more mobile.\nWhat is Osteogenesis imperfecta OI?\n. . .\nShow more\n\nSpeech recognition relies on statistical algorithms to analyze audio. Words from a custom model are in competition with words from the service's base vocabulary as well as other words of the model. (Factors such as audio noise and speaker accents also affect the quality of transcription.)\n\nThe accuracy of transcription can depend largely on how words are defined in a model and how speakers say them. To improve the service's accuracy, use corpora to provide as many examples as possible of how OOV words are used in the domain. Repeating the OOV words in corpora can improve the quality of the custom language model. How you duplicate the words in corpora depends on how you expect users to say them in the audio that is to be recognized. The more sentences that you add that represent the context in which speakers use words from the domain, the better the service's recognition accuracy.\n\nThe service does not apply a simple word-matching algorithm. Its transcription depends on the context in which words are used. When it parses a corpus, the service includes information about n-grams (bi-grams, tri-grams, and so on) from the sentences of the corpus in the custom model. This information helps the service transcribe audio with greater accuracy, and it explains why training a custom model on corpora is more valuable than training it on custom words alone.\n\nFor example, accountants adhere to a common set of standards and procedures that are known as Generally Accepted Accounting Principles (GAAP). When you create a custom model for a financial domain, provide sentences that use the term GAAP in context. The sentences help the service distinguish between general phrases such as \"the gap between them is small\" and domain-centric phrases such as \"GAAP provides guidelines for measuring and disclosing financial information.\"\n\nIn general, it is better for corpora to use words in different contexts, which can improve how the service learns the words.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-corporaWords"},{"document_id":"ibmcld_13447-3789-6014","score":18.076089988,"text":"\nIn general, shorter utterances that occupy separate lines of the corpus are most effective.\n* It is neither necessary nor possible to associate a specific corpora with a specific audio file. A custom language model can contain multiple corpora, just as a custom acoustic model can include multiple audio files. All contents of a custom language model help improve the internal transcript of the audio that the service generates during the training process.\n* A transcript does not need to be a verbatim reflection of all sentences and words from the audio. It can include only sentences and words of the audio that are relevant to the domain. For both language model and acoustic model customization, the training data needs to reflect the actual use-case of the speech that you want to recognize. If only 20 percent of the data (transcript or audio) is specific to the domain of the use-case, use just that 20 percent of the data for training.\n\nHowever, if you are using acoustic model customization to achieve better results for accented speech (for example, for speech by non-native speakers), keep as much audio as possible, even if it's not relevant to the domain. The same is true if you are using acoustic model customization to improve speech recognition accuracy under difficult acoustic conditions, such as a noisy background.\n* A verbatim transcript does not need to contain the disfluencies, verbal tics, and filler statements that are common to human speech. You can remove these elements from the transcript, the audio, or both. (You can also remove audio in which people are talking over each other, since that does not contribute to the training.)\n\nFor example, suppose a verbatim transcript includes the following sentence:\n\nSo that's, uhm, you know, that, as I say, is the is the predominant form today.\n\nYou can edit these peculiarities from the transcript, the audio, or both to create the following sentence:\n\nSo that as I say is the predominant form today.\n\n\n\n\n\n\n\n Performing lightly supervised training \n\nTo train a custom acoustic model with a custom language model, you use the optional custom_language_model_id query parameter of the POST \/v1\/acoustic_customizations\/{customization_id}\/train method.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-useBoth"},{"document_id":"ibmcld_04625-7-1865","score":17.5774655084,"text":"\nAdding and using a custom domain \n\nIBM\u00ae Cloud Foundry is deprecated and no longer supported as of 1 June 2023. For more information, see the [deprecation details](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-deprecationdep_details).\n\nDomains provide the URL route that is allocated to your organization in IBM Cloud\u00ae. Custom domains direct requests for your apps to a URL that you own. A custom domain can be a shared domain, a shared subdomain, or a shared domain and host. Unless a custom domain is specified, IBM Cloud uses a default shared domain in the route to your app. You can create and use a custom domain by using either the IBM Cloud console or the command-line interface.\n\nThe default shared domain is mybluemix.net, but appdomain.cloud is another domain option that you can use. For more information about migrating to appdomain.cloud, see [Updating your domain](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-update-domain).\n\nTo use a custom domain, you must register the custom domain on a public DNS server, and then configure the custom domain in IBM Cloud. Next, you must map the custom domain to the IBM Cloud system domain on the public DNS server. After your custom domain is mapped to the system domain, requests for your custom domain are routed to your app in IBM Cloud.\n\n\n\n Adding a custom domain from the IBM Cloud console \n\nComplete these steps to add a custom domain for your org by using the console:\n\n\n\n1. Go to Manage > Account, and select Cloud Foundry orgs.\n2. Click the name of the org for which you're creating a custom domain.\n3. Click the Domains tab to view a list of available domains.\n4. Click Add a domain, enter your domain name, and select the region.\n5. Confirm your updates, and click Add.\n\n\n\n\n\n\n\n Adding the route with the custom domain to an app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-custom-domains"},{"document_id":"ibmcld_07578-757483-759510","score":17.2612274928,"text":"\nActivating the domain before migrating from CIS can cause your domain to changed to a [Moved state](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-domain-moved-status).\n* I added a user to my account and gave that user permission to manage Internet Services instance(s). Why is that user facing authentication issues?\n\nIt's possible that you did not assign \"service access roles\" to the user. Note that there are two separate sets of roles:\n\n\n\n* Platform access\n* Service access\n\n\n\nYou need platform access roles to create and manage service instances, while service access roles perform service-specific operations on service instances. In the console, these settings can be updated by selecting Manage > Security > Identity and Access.\n* Why is my domain in Pending state? How do I activate it?\n\nWhen you add a domain to CIS, we give you a couple of name servers to configure at your registrar (or at your DNS provider, if you are adding a subdomain). The domain or subdomain remains in pending state until you configure the name servers correctly. Make sure you add both the name servers to your registrar or DNS provider. We periodically scan the public DNS system to check whether the name servers have been configured as instructed. As soon as we are able to verify the name server change (which can take up to 24 hours), we activate your domain. You can submit a request to recheck name servers by clicking on Recheck name servers in the overview page.\n* Who is the registrar for my domain?\n\nConsult [https:\/\/whois.icann.org\/](https:\/\/whois.icann.org\/) for this information.\n\nYou must have the administrator privilege to edit your domain's configuration at the registrar in order to update or add the name servers provided for your domain when you add it to CIS. If you don't know who the registrar is for the domain you're trying to add to CIS, it is unlikely you have the permission to update your domain's configuration at the registrar. Work with the owner of the domain in your organization to make the necessary changes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_08069-7119-8044","score":17.1799110062,"text":"\nThese resources are at strategic IBM locations around the world. IBM Cloud support resources, which are known as the Advanced Customer Support team, is made up of technical engineers that have specific domain knowledge to triage and troubleshoot problems quickly and effectively.\n\nThe teams are organized by technology domains, which include compute, network, security, storage, VPC, Kubernetes service, Red Hat OpenShift on IBM Cloud, Satellite, databases, app development, and cognitive solutions. Our teams keep their skills and technical knowledge up-to-date through specialized training on cloud services throughout the year. Support engineers are equipped to go deep on issues and solve most without any additional support from our backend teams. Collaboration across cloud service teams ensures continuous knowledge transfer and skills development within the team to deliver the best possible service to our customers.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans"},{"document_id":"ibmcld_07449-7-1566","score":16.9993405039,"text":"\nManaging custom name servers for a domain \n\nDomains running on the IBM Cloud\u00ae network can point to a maximum of five (5) custom name servers. Custom name servers can be added, deleted, or changed at any time. Follow these steps to add, edit, or delete custom name servers for a domain.\n\n\n\n1. From your browser, open the [IBM Cloud\u00ae console](https:\/\/cloud.ibm.com\/) and log in to your account.\n2. Select the Menu icon ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/icon_hamburger.svg), then click Classic Infrastructure.\n3. From the Classic Infrastructure menu, select Services > Domain Registration to open the Domains page.\n4. Select the Domain Name to expand the domain into its snapshot view.\n5. Select Unlocked from the Lock Domain.\n6. Click the > character to expand the domain and configure name servers.\n\nZoom\n\n![Sample domains collapsed image](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/86dadb3996e7fa2b119c2c09bda56dbc01297416\/dns\/images\/custom-name-server-collapsed.png)\n\nFigure 1. Domains page with the domain collapsed\n\nZoom\n\n![Sample domains expanded image](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/86dadb3996e7fa2b119c2c09bda56dbc01297416\/dns\/images\/custom-name-server-expanded.png)\n\nFigure 2. Domains page with the domain expanded\n7. Select the Add\/Edit NS option in the Custom Name Servers section of the page. A dialog appears.\n8. To complete the appropriate action based on the task, refer to one of the following bullets:\n\n\n\n* To add a custom name server, enter the hostname for the name server in the empty field.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns?topic=dns-add-edit-or-delete-custom-name-servers-for-a-domain"},{"document_id":"ibmcld_04113-1734-4014","score":16.9406801201,"text":"\nIBM CIS usually accelerates API traffic by removing connection overhead. However, the default security stance can interfere with many API calls. It is recommended that you take a few actions to prevent interference with your API traffic after proxying is active.\n\n\n\n* Turn security features off selectively, using the Page Rules features.\n\n\n\n* Create a Page Rule with the URL pattern of your API, such as api.example.com\n* Add the following rule behaviors:\n\n\n\n* Select Security Level to Essentially off\n* Select TLS to Off\n* Select Browser Integrity Check to Off\n\n\n\n* Select Provision Resource\n\n\n\n* Alternatively, you can turn off Web Application Firewall globally from the Security page.\n\n\n\n\n\n What does the Browser Integrity Check do? \n\nThe browser integrity check looks for HTTP headers that are commonly abused by spammers. It denies traffic with those headers access to your page. It also blocks visitors that do not have a user agent, or who add a non-standard user agent (this tactic is commonly used by abuse bots, crawlers, or APIs).\n\n\n\n\n\n\n\n Best practice 4: Configure your security settings as strictly as possible \n\nCIS provides some options for encrypting your traffic. As a reverse proxy the TLS connection is terminated at Cloudflare and a new TLS connection is opened to your origin servers. For your termination with CIS, you can upload a custom certificate from your account, you can use a wildcard certificate provisioned for you by CIS, or both.\n\n\n\n Upload a custom certificate \n\nYou can upload your public and private key when you create an Enterprise domain. If you upload your own certificate, you gain immediate compatibility with encrypted traffic, and you maintain control over your certificate (for example, an Extended Validation (EV) certificate). Remember that you'll be responsible for managing your certificate if you upload a custom certificate. For example, IBM CIS won't track the certificate expiration dates.\n\n\n\n\n\n Alternatively, use a certificate provisioned by CIS \n\nIBM CIS has partnered with several Certificate Authorities (CAs) to provide domain wildcard certificates for our customers, by default. Manual verification could be required for setting up these certificates, and your support team can help you perform these additional steps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-best-practices-for-cis-setup"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14311-3835-5367","score":24.4025889682,"text":"\n[Layer 2 bridge setup with a new bridge edge cluster](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-bridge-edge.svg)\n\nFigure 3. Layer 2 bridge setup with a new bridge edge cluster\n\nMake sure you have the bridged VLANs transport zone (for example tz-bridge) configured on all wanted transport nodes.\n\n\n\n\n\n Considerations \n\nWhen you design or deploy this architecture pattern, consider the following steps:\n\n\n\n* Using the existing workload edge cluster is good for testing the layer 2 capability and for small deployments.\n* If you have a larger deployment, deploying a dedicated edge cluster or several edge clusters offers better performance and generally scales better.\n* If you use new edge nodes for bridging, they do not have to be in the same network or POD as the workload edge. Edge nodes are transport nodes and they communicate with the other NSX-T transport nodes (edges or hosts) through Geneve tunnels over layer 3 routed connections by using the IBM Cloud classic network as a transport network.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [VMware vSphere overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_vsphereclusteroverview)\n* [Getting started with IBM Cloud Gateway Appliance](https:\/\/cloud.ibm.com\/docs\/gateway-appliance?topic=gateway-appliance-getting-started)\n* [Installing NSX-T edge transport nodes](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.2\/installation\/GUID-5EF2998C-4867-4DA6-B1C6-8A6F8EBCC411.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"},{"document_id":"ibmcld_14311-2669-4435","score":22.8368245133,"text":"\nIf you use the existing workload edge cluster, you must create the edge bridge profile by using that cluster and change the existing-distributed port group to allow Promiscuous mode and Forged transmits. This setup shares the capacity of the private uplinks from the edge nodes for both private routed and bridged traffic. Transport zones are defined in the edge host switch (N-VDS), for example add the new tz-bridge to nvds-edge-private.\n\nZoom\n\n![Layer 2 bridge setup with workload edge cluster](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-workload-edge.svg)\n\nFigure 2. Layer 2 bridge setup with workload edge cluster\n\nAlternatively, you can deploy a new edge cluster for bridging. In this case, you must create new edge nodes and create a new edge cluster by using these nodes. When you configure the edge bridge profile, you can then use this edge cluster for bridging only. This alternative scales better, and provides a better dedicated bridging performance. Transport zones are defined in the edge host switch (N-VDS), for example add the new tz-bridge to nvds-bridge.\n\nZoom\n\n![Layer 2 bridge setup with a new bridge edge cluster](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-bridge-edge.svg)\n\nFigure 3. Layer 2 bridge setup with a new bridge edge cluster\n\nMake sure you have the bridged VLANs transport zone (for example tz-bridge) configured on all wanted transport nodes.\n\n\n\n\n\n Considerations \n\nWhen you design or deploy this architecture pattern, consider the following steps:\n\n\n\n* Using the existing workload edge cluster is good for testing the layer 2 capability and for small deployments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"},{"document_id":"ibmcld_14311-7-1811","score":20.9656286198,"text":"\nArchitecture pattern for using layer 2 (L2) bridging with NSX-T \n\nWith layer 2 bridging, you can have a L2 connection to a VLAN-backed port group or a device that is outside of your NSX-T data center deployment. An L2 bridge is also useful in a migration scenario, in which you need to split a subnet across physical and virtual workloads. Or when you run a database cluster on IBM Cloud bare metal servers.\n\nYou can use layer 2 bridging in IBM Cloud by following the principles that are presented in this pattern. You can adapt the pattern based on your needs by following VMware\u00ae best practices and IBM Cloud Classic network capabilities.\n\n\n\n Layer 2 bridging with NSX-T \n\nThe following diagram presents an overview for an architecture pattern for using layer 2 bridging with NSX-T edges in IBM Cloud classic infrastructure.\n\nZoom\n\n![Layer 2 bridging with NSX-T](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-bridge.svg)\n\nFigure 1. Layer 2 bridging with NSX-T\n\nThe following list is a summary of the architecture pattern deployment:\n\n\n\n1. An L2 bridge requires an Edge cluster and an Edge Bridge profile to be deployed. An Edge Bridge profile specifies which Edge cluster to use for bridging and which Edge transport node acts as the primary and backup bridge.\n2. You need to have a new VLAN for the bridged devices. After the VLAN is provisioned, you can request to trunk the hosts. VLAN must be trunked to all hosts in your cluster through IBM Cloud Classic portal (Classic Infrastructure > Network > Gateway appliances). Then, add the ESX hosts to a wanted NSX-T VLAN transport zone, for example tz-bridge.\n3. On the edge cluster uplink distributed port group, enable Promiscuous mode and Forged transmits for bridging.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"},{"document_id":"ibmcld_15141-6204-8279","score":20.6451050272,"text":"\nThe VPN server receives the username and passcode from the VPN client and makes an IAM call to verify the passcode and permission with IAM policy.\n\n\n\n* The passcode is an one-time password. The user MUST re-generate the passcode for re-connection, even if the re-connection is initiated by the VPN server.\n* The SoftLayer MFA is not supported because SoftLayer MFA enforcement is not done via the browser.\n\n\n\nIf you use user ID\/passcode authentication, maintenance activities force users to re-authenticate by fetching and re-entering the code. The connection is restored only after the new code is entered. This is applicable using stand-alone or HA mode.\n\n\n\n\n\n Client certificate revocation lists \n\nOptionally, you can import a certificate revocation list (CRL), which is a time-stamped list of certificates that have been revoked by a certificate authority (CA). A certificate in a certificate revocation list (CRL) might not be expired, but is no longer trusted by the certificate authority that issued the certificate. The VPN client uses this list to validate digital certificates.\n\nAfter you import a CRL, the VPN client uses this list to validate digital certificates. The CRL is saved as a string (not a file) in the system. If you need to download the CRL in the future, it is renamed as <vpn_server_name>.pem.\n\nFor more information, see [Setting up client-to-server authentication](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-client-to-site-authentication).\n\n\n\n\n\n Transport protocol \n\nThe transport layer oversees the delivery of data from a process on one device to a process on another device. Transport layer protocols act as liaisons between the application layer protocols and the services that are provided by the network. Client VPN for VPC supports the following protocols:\n\nUDP is recommended for optimal performance; TCP for reliability.\n\n\n\n* User Datagram Protocol (UDP)\n\nThe User Datagram Protocol (UDP) is a simple, lightweight protocol with minimum overhead. If a process wants to send a small message and doesn't care about reliability, it can use UDP.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-client-to-site-vpn-planning"},{"document_id":"ibmcld_16000-0-2579","score":19.594730439,"text":"\n\n\n\n\n\n\n  Understanding Internet Communication Protocols \n\nGenerally speaking, a communication protocol is a system of rules that allow two or more entities of a communications system to transmit information. The internet has a large suite of protocols to cover many situations. In creating web-based applications and programming interfaces, software developers commonly use three of these communication protocols to describe the state of the network and the ways that data packets are moved across the network:\n\n\n\n*  ICMP, Internet Control Message Protocol, part of the internet protocol suite defined in RFC 792.\n*  TCP, Transmission Control Protocol\n*  UDP, User Datagram Protocol\n\n\n\nThe protocols that are used for a particular implementation of, say, an API call, can influence the overall behavior of your network. So it is worthwhile to understand the basic differences between them. If you need more information, many good articles are available on the internet with detailed descriptions of the protocols.\n\n\n\n  ICMP \n\nICMP is a control protocol, meaning that it is designed to carry information about the status of the network itself. It is essentially a network layer (OSI layer 3) error-reporting and error-control protocol for the network. The best-known examples of ICMP in practice are the ping and traceroute utilities. The ping utility uses ICMP to probe remote hosts for responsiveness and overall round-trip time of the probe messages. The traceroute utility uses ICMP to discover and trace network routes that the ICMP packets take when they travel to their destination.\n\nWhat developers need to know is that ICMP packets have no TCP or UDP port numbers that are associated with them because port numbers are a layer 4 (transport layer) construct.\n\n\n\n\n\n  TCP and UDP \n\nBoth Transmission Control Protocol (TCP) and User Datagram Protocol (UDP) are OSI layer 4 transport protocols. These protocols are used to pass the actual data. The main difference between TCP and UDP, from a developer's perspective, is how they handle packet order.\n\nTCP is a connection-oriented protocol, it guarantees that all sent packets reach the destination in the correct order.\n\nAlternatively, UDP is a connection-less protocol. Communication is datagram-oriented, so the integrity is guaranteed only on the single datagram. Datagrams reach a destination and can arrive out of order, or possibly they don't arrive at all.\n\nTypically, UDP is used for real-time communication, where a little percentage of the packet loss rate is preferable to the overhead of a TCP connection.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-understanding-icp"},{"document_id":"ibmcld_15141-7808-9997","score":18.9638730281,"text":"\nTransport layer protocols act as liaisons between the application layer protocols and the services that are provided by the network. Client VPN for VPC supports the following protocols:\n\nUDP is recommended for optimal performance; TCP for reliability.\n\n\n\n* User Datagram Protocol (UDP)\n\nThe User Datagram Protocol (UDP) is a simple, lightweight protocol with minimum overhead. If a process wants to send a small message and doesn't care about reliability, it can use UDP. Sending a message by using UDP takes much less time than using TCP. It performs little error checking and does not add any advantages to IP services except to provide process-to-process communication instead of host-to-host communication.\n* Transmission Control Protocol (TCP)\n\nTransmission Control Protocol (TCP) is a reliable but complex transport-layer protocol. TCP adds connection-oriented features and reliability to IP services.\n\nTCP is a stream delivery service that guarantees delivery of data streams sent from one host to another without duplication or lost data. Since packet transfer is not reliable, a technique known as positive acknowledgment with retransmission is used to guarantee reliability of packet transfers. This fundamental technique requires the receiver to respond with an acknowledgment message as it receives the data.\n\nThe sender keeps a record of each packet it sends, and waits for acknowledgment before sending the next packet. The sender also keeps a timer from when the packet was sent, and retransmits a packet if the timer expires. This timer is needed in case a packet becomes lost or corrupted.\n\n\n\n\n\n\n\n Full versus split-tunnel mode \n\nWhen a VPN connection is set up, an encrypted tunnel is created over the internet to the VPN server. The VPN connection appears as a virtual network interface to the computer in addition to the existing LAN interface. You can now use both interfaces simultaneously by sending the private traffic destined to the VPC inside the VPN tunnel and the public traffic (internet traffic) over the other interface (outside the VPN tunnel). When the traffic is split between the VPN interface and other interfaces, split tunneling is said to be in use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-client-to-site-vpn-planning"},{"document_id":"ibmcld_04107-6095-8145","score":18.4908115424,"text":"\nThis tactic is commonly used by abuse bots, crawlers, or APIs.\n* Challenge passage - Controls how long a visitor that passed a challenge (or JavaScript challenge) gains access to your site before they are challenged again. This challenge is based on the visitor's IP, and therefore does not apply to challenges presented by WAF rules because they are based on an action that the user performs on your site.\n* Security level - Sets the security level of your website to determine which visitors receive a challenge page.\n* Always use HTTPS - Redirects all visitors to the HTTPS version.\n* Email obfuscation - Prevents spam from harvesters and bots that try to access email addresses on your pages.\n* Automatic HTTPS rewrites - Helps fix mixed content by changing http to https for all resources (or links) on your website that can be served with HTTPS.\n* Opportunistic encryption - Allows browsers to benefit from the improved performance of HTTP\/2 by informing them that your site is available over an encrypted connection.\n* Universal SSL - Activates universal SSL certificates from your zone to the edge.\n* True client IP header - Sends the user's IP address in the True-Client-IP header.\n\n\n\n\n\n\n\n Security standards and platform \n\n\n\n* TLS (SHA2 and SHA1)\n* IPv4 and IPv6\n* HTTP\/2\n\n\n\n\n\n\n\n Network attacks and mitigation \n\nGenerally, attacks fall into two categories:\n\n\n\nTable 1. Types of network attacks\n\n Layer-3 or Layer-4 attacks Layer-7 attacks \n\n These attacks consist of a flood of traffic at ISO Layer 3 (the network layer), such as ICMP floods, or at Layer 4 (the transport layer), such as TCP SYN floods or reflected UDP floods. These attacks send malicious ISO Layer-7 requests (the application layer), such as GET floods. \n Automatically blocked at CIS edge CIS handles these attacks with Defense mode, WAF, and security-level settings. \n\n\n\n\n\n\n\n On-demand anti-DDoS \n\nIBM Cloud Internet Services ingests traffic by returning a CIS IP address on the DNS lookup for a domain, instead of the actual record for the origin server\u2019s IP address.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_14311-5070-5527","score":18.4639758002,"text":"\n* [Getting started with IBM Cloud Gateway Appliance](https:\/\/cloud.ibm.com\/docs\/gateway-appliance?topic=gateway-appliance-getting-started)\n* [Installing NSX-T edge transport nodes](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.2\/installation\/GUID-5EF2998C-4867-4DA6-B1C6-8A6F8EBCC411.html)\n* [Administering NSX-T Layer 2 bridging](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.2\/administration\/GUID-B4ABDE64-52BC-40F0-A560-670D3B7EAF7A.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"},{"document_id":"ibmcld_04107-7548-9466","score":18.2726199283,"text":"\nThese attacks consist of a flood of traffic at ISO Layer 3 (the network layer), such as ICMP floods, or at Layer 4 (the transport layer), such as TCP SYN floods or reflected UDP floods. These attacks send malicious ISO Layer-7 requests (the application layer), such as GET floods. \n Automatically blocked at CIS edge CIS handles these attacks with Defense mode, WAF, and security-level settings. \n\n\n\n\n\n\n\n On-demand anti-DDoS \n\nIBM Cloud Internet Services ingests traffic by returning a CIS IP address on the DNS lookup for a domain, instead of the actual record for the origin server\u2019s IP address. This allows CIS to ingest, single-pass inspect, and re-encrypt data before sending it to the origin server destination. CIS can also act in DNS-only mode, returning the actual DNS record without obfuscating the IP, which disables DDoS and the other functions of CIS. To enable CIS protections, switch the \"proxy\" slider next to each DNS record to on; to disable protections, switch to off.\n\n\n\n\n\n Unlimited DDoS mitigation \n\nDDoS mitigation is typically an expensive service that can grow in cost when under attack. Unlimited DDoS mitigation is included with CIS at no additional cost.\n\n\n\n\n\n Mitigate Layer 7 attacks (configuration) \n\nThough DDoS is enabled by default in CIS, you can further configure Layer 7 security by:\n\n\n\n* Configuring WAF ruleset sensitivity and response behavior\n* Adding rate limiting\n* Adding firewall rules\n\n\n\nUse these features to customize Layer 7 mitigation of both volumetric and non-volumetric attacks.\n\n\n\n\n\n Mitigate non volumetric attacks \n\nCIS WAF contains rulesets to mitigate non-volumetric attacks, including cross-site forgery, cross-site-scripting (XSS), file inclusion, and SQL injection. For additional information about WAF, see [Web Application Firewall concepts](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-waf-q-and-awhat-types-of-attacks-can-waf-prevent).\n\n\n\n\n\n Cost protection","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_11891-7-2391","score":18.1880377875,"text":"\nSetting up Satellite as a Secure Gateway for on-prem solutions \n\nDeploy IBM Cloud Satellite as a secure solution for connecting resources in a protected on-premises environment to cloud resources.\n\n\n\n Satellite as a Layer 4 connection solution \n\nWhile you can set up many possible solutions to enable secure connections between your on-premises network and IBM Cloud, you can use Satellite to control client communications among your hybrid cloud deployments.\n\nFor example, you might use a minimal Satellite location deployment as an alternative to the [Secure Gateway solution](https:\/\/cloud.ibm.com\/docs\/SecureGateway?topic=SecureGateway-getting-started-with-sg). Satellite provides the same application-level transport through common ports as Secure Gateway, with greater client visibility and audit control. The Satellite Link functionality improves upon the Secure Gateway client experience with a highly available and secure-by-default communication between the cloud and on-premises networks, third-party clouds, or network edge.\n\nOn-premises setup with a Satellite location\n: A minimum deployment of Satellite includes using three RHEL 7 or 8 hosts to set up a Satellite location control plane. These hosts might be in your on-premises network or in other clouds. Then, you can attach more hosts to your location and deploy IBM Cloud managed services to run on these hosts. For example, you can deploy a Red Hat OpenShift cluster to your on-premises hosts that are attached to your Satellite location. Then, you can deploy any apps that need secure access to IBM Cloud to your Red Hat OpenShift cluster.\n\nSecure transport to IBM Cloud\n: Next, your on-premises client that runs on the location hosts can use [Satellite Link](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-link-cloud-createlink-location) as Layer 4 application transport between the location and other services that run in IBM Cloud or your own applications that run within IBM Cloud. You can use Satellite Link to create location endpoints, which allow resources in IBM Cloud to securely access a resource in your on-premises Satellite location, and cloud endpoints, which allow resources in your on-premises Satellite location to access a resource that runs anywhere outside of the Satellite location. To allow access to a resource, authorization must granted in the Link endpoint's access control list.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sg-usecase"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08766-9493-11228","score":33.1363916908,"text":"\n[Using IBM Db2 default encryption with Hyper Protect Crypto Services PKCS #11](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-db2-pkcs11).\n\n\n\n\n\n\n\n Protecting data in transit with TLS\/SSL offloading \n\nTransport Layer Security (TLS) and Secure Sockets Layer (SSL) are cryptographic protocols that are designed to provide communication security over a computer network. The TLS\/SSL protocol aims primarily to provide privacy and data integrity between two or more communicating computer applications.\n\nIn the context of web servers, the TLS\/SSL protocol allows a website to establish the identity. Users of the website can be sure that no one else is masquerading as the website. It is done through a public-private key pair.\n\nHyper Protect Crypto Services provides a way to offload the cryptographic operations that are done during the TLS handshake to establish a secure connection to the web server, while it keeps the TLS\/SSL private key securely stored in the dedicated HSM. In this way, you have control over your TLS\/SSL keys and processing. As a result, security is improved and reputational risk is decreased.\n\nTLS\/SSL offloading to the Hyper Protect Crypto Services HSM enables data in transit protection for web, API, and mobile transactions by using the standard PKCS #11 API. With Hyper Protect Crypto Services, you can integrate TLS\/SSL offloading with other cloud proxies.\n\nFor a tutorial on how to offload the SSL workload to a load balancer such as NGINX while managing keys by using Hyper Protect Crypto Services, see [Using IBM Cloud Hyper Protect Crypto Services to offload NGINX TLS](https:\/\/developer.ibm.com\/components\/ibmz\/tutorials\/use-hyper-protect-crypto-services-to-offload-nginx-tls\/).\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-use-cases"},{"document_id":"ibmcld_08739-11193-12939","score":33.0757188257,"text":"\n* For a tutorial on how to use TDE with Hyper Protect Crypto Services, see\n\n[Tutorial: Using Oracle Transparent Database Encryption with Hyper Protect Crypto Services PKCS #11](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-tde-pkcs11).\n* For a tutorial on how to use Db2 default encryption with Hyper Protect Crypto Services, see\n\n[Using IBM Db2 default encryption with Hyper Protect Crypto Services PKCS #11](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-db2-pkcs11).\n\n\n\n\n\n\n\n Protecting data in transit with TLS\/SSL offloading \n\nTransport Layer Security (TLS) and Secure Sockets Layer (SSL) are cryptographic protocols that are designed to provide communication security over a computer network. The TLS\/SSL protocol aims primarily to provide privacy and data integrity between two or more communicating computer applications.\n\nIn the context of web servers, the TLS\/SSL protocol allows a website to establish the identity. Users of the website can be sure that no one else is masquerading as the website. It is done through a public-private key pair.\n\nHyper Protect Crypto Services provides a way to offload the cryptographic operations that are done during the TLS handshake to establish a secure connection to the web server, while it keeps the TLS\/SSL private key securely stored in the dedicated HSM. In this way, you have control over your TLS\/SSL keys and processing. As a result, security is improved and reputational risk is decreased.\n\nTLS\/SSL offloading to the Hyper Protect Crypto Services HSM enables data in transit protection for web, API, and mobile transactions by using the standard PKCS #11 API. With Hyper Protect Crypto Services, you can integrate TLS\/SSL offloading with other cloud proxies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-uko-use-cases"},{"document_id":"ibmcld_08766-8126-10005","score":27.7168220619,"text":"\n[IBM Db2 default encryption by using the standard PKCS #11 API](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/hs-crypto\/\/images\/pkcs-db2.svg)\n\nFigure 5. IBM Db2 default encryption by using the standard PKCS #11 API\n\n\n\nWith the PKCS #11 library integration, Hyper Protect Crypto Services supports the industry-standard PKCS #11 API. The Hyper Protect Crypto Services PKCS #11 library connects your database to Hyper Protect Crypto Services to perform cryptographic operations. The database system can invoke operations to manage the TDE master encryption keys or the master keys in the Hyper Protect Crypto Services PKCS #11 library. The Hyper Protect Crypto Services PKCS #11 library then interacts with your Hyper Protect Crypto Services instance to provide the highest level of security for storing and managing your TDE master encryption keys or your master keys in the cloud. It, in turn, provides the highest level of security to your data encryption keys and your data.\n\n\n\n* For a tutorial on how to use TDE with Hyper Protect Crypto Services, see\n\n[Tutorial: Using Oracle Transparent Database Encryption with Hyper Protect Crypto Services PKCS #11](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-tde-pkcs11).\n* For a tutorial on how to use Db2 default encryption with Hyper Protect Crypto Services, see\n\n[Using IBM Db2 default encryption with Hyper Protect Crypto Services PKCS #11](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-db2-pkcs11).\n\n\n\n\n\n\n\n Protecting data in transit with TLS\/SSL offloading \n\nTransport Layer Security (TLS) and Secure Sockets Layer (SSL) are cryptographic protocols that are designed to provide communication security over a computer network. The TLS\/SSL protocol aims primarily to provide privacy and data integrity between two or more communicating computer applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-use-cases"},{"document_id":"ibmcld_05011-1380-3213","score":24.7990068611,"text":"\nHow do I allow Aspera High-Speed Transfer through a bucket with context-based restrictions or a firewall? \n\nThe full list (in JSON) of Aspera High-Speed Transfer IP addresses that are used with IBM Cloud Object Storage can be found [using this API endpoint](https:\/\/ats.aspera.io\/pub\/v1\/servers\/softlayer).\n\n\n\n\n\n Does Object Storage provide encryption at rest and in motion? \n\nYes. Data at rest is encrypted with automatic provider-side Advanced Encryption Standard (AES) 256-bit encryption and the Secure Hash Algorithm (SHA)-256 hash. Data in motion is secured by using the built-in carrier grade Transport Layer Security\/Secure Sockets Layer (TLS\/SSL) or SNMPv3 with AES encryption.\n\nIf you want more control over encryption, you can make use of IBM Key Protect to manage generated or \"bring your own\" keying. For details, see [Key-protect COS Integration](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-integrate-cos).\n\n\n\n\n\n Is there additional encryption processing if a customer wants to encrypt their data? \n\nServer-side encryption is always on for customer data. Compared to the hashing required in S3 authentication and the erasure coding, encryption is not a significant part of the processing cost of Object Storage.\n\n\n\n\n\n Does Object Storage encrypt all data? \n\nYes, Object Storage encrypts all data.\n\n\n\n\n\n Does Object Storage have FIPS 140-2 compliance for the encryption algorithms? \n\nYes, the IBM COS Federal offering is approved for FedRAMP Moderate Security controls, which require a validated FIPS configuration. IBM COS Federal is certified at FIPS 140-2 level 1. For more information on COS Federal offering, [contact us](https:\/\/www.ibm.com\/cloud\/government) via our Federal site.\n\n\n\n\n\n Is client-key encryption supported? \n\nYes, client-key encryption is supported by using SSE-C, Key Protect, or HPCS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-faq-encryption"},{"document_id":"ibmcld_07578-1312986-1314802","score":24.4981732855,"text":"\nAlso, see [API Key vs HMAC](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/iam?topic=cloud-object-storage-service-credentialsservice-credentials-iam-hmac).\n* How do cross-origin resource sharing (CORS) and a bucket firewall differ in limiting access to data?\n\nCORS allows interactions between resources from different origins that are normally prohibited. A bucket firewall allows access only to requests from a list of allowed IP addresses. For more information on CORS, see [What is CORS?](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-cors-and-cors-requests-through-your-cdnwhat-is-cors).\n* How do I allow Aspera High-Speed Transfer through a bucket with context-based restrictions or a firewall?\n\nThe full list (in JSON) of Aspera High-Speed Transfer IP addresses that are used with IBM Cloud Object Storage can be found [using this API endpoint](https:\/\/ats.aspera.io\/pub\/v1\/servers\/softlayer).\n* Does Object Storage provide encryption at rest and in motion?\n\nYes. Data at rest is encrypted with automatic provider-side Advanced Encryption Standard (AES) 256-bit encryption and the Secure Hash Algorithm (SHA)-256 hash. Data in motion is secured by using the built-in carrier grade Transport Layer Security\/Secure Sockets Layer (TLS\/SSL) or SNMPv3 with AES encryption.\n\nIf you want more control over encryption, you can make use of IBM Key Protect to manage generated or \"bring your own\" keying. For details, see [Key-protect COS Integration](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-integrate-cos).\n* Is there additional encryption processing if a customer wants to encrypt their data?\n\nServer-side encryption is always on for customer data. Compared to the hashing required in S3 authentication and the erasure coding, encryption is not a significant part of the processing cost of Object Storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1315651-1317467","score":24.4981732855,"text":"\nAlso, see [API Key vs HMAC](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/iam?topic=cloud-object-storage-service-credentialsservice-credentials-iam-hmac).\n* How do cross-origin resource sharing (CORS) and a bucket firewall differ in limiting access to data?\n\nCORS allows interactions between resources from different origins that are normally prohibited. A bucket firewall allows access only to requests from a list of allowed IP addresses. For more information on CORS, see [What is CORS?](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-cors-and-cors-requests-through-your-cdnwhat-is-cors).\n* How do I allow Aspera High-Speed Transfer through a bucket with context-based restrictions or a firewall?\n\nThe full list (in JSON) of Aspera High-Speed Transfer IP addresses that are used with IBM Cloud Object Storage can be found [using this API endpoint](https:\/\/ats.aspera.io\/pub\/v1\/servers\/softlayer).\n* Does Object Storage provide encryption at rest and in motion?\n\nYes. Data at rest is encrypted with automatic provider-side Advanced Encryption Standard (AES) 256-bit encryption and the Secure Hash Algorithm (SHA)-256 hash. Data in motion is secured by using the built-in carrier grade Transport Layer Security\/Secure Sockets Layer (TLS\/SSL) or SNMPv3 with AES encryption.\n\nIf you want more control over encryption, you can make use of IBM Key Protect to manage generated or \"bring your own\" keying. For details, see [Key-protect COS Integration](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-integrate-cos).\n* Is there additional encryption processing if a customer wants to encrypt their data?\n\nServer-side encryption is always on for customer data. Compared to the hashing required in S3 authentication and the erasure coding, encryption is not a significant part of the processing cost of Object Storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_14311-3835-5367","score":24.4025889682,"text":"\n[Layer 2 bridge setup with a new bridge edge cluster](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-bridge-edge.svg)\n\nFigure 3. Layer 2 bridge setup with a new bridge edge cluster\n\nMake sure you have the bridged VLANs transport zone (for example tz-bridge) configured on all wanted transport nodes.\n\n\n\n\n\n Considerations \n\nWhen you design or deploy this architecture pattern, consider the following steps:\n\n\n\n* Using the existing workload edge cluster is good for testing the layer 2 capability and for small deployments.\n* If you have a larger deployment, deploying a dedicated edge cluster or several edge clusters offers better performance and generally scales better.\n* If you use new edge nodes for bridging, they do not have to be in the same network or POD as the workload edge. Edge nodes are transport nodes and they communicate with the other NSX-T transport nodes (edges or hosts) through Geneve tunnels over layer 3 routed connections by using the IBM Cloud classic network as a transport network.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [VMware vSphere overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_vsphereclusteroverview)\n* [Getting started with IBM Cloud Gateway Appliance](https:\/\/cloud.ibm.com\/docs\/gateway-appliance?topic=gateway-appliance-getting-started)\n* [Installing NSX-T edge transport nodes](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.2\/installation\/GUID-5EF2998C-4867-4DA6-B1C6-8A6F8EBCC411.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"},{"document_id":"ibmcld_04107-7548-9466","score":23.6564226096,"text":"\nThese attacks consist of a flood of traffic at ISO Layer 3 (the network layer), such as ICMP floods, or at Layer 4 (the transport layer), such as TCP SYN floods or reflected UDP floods. These attacks send malicious ISO Layer-7 requests (the application layer), such as GET floods. \n Automatically blocked at CIS edge CIS handles these attacks with Defense mode, WAF, and security-level settings. \n\n\n\n\n\n\n\n On-demand anti-DDoS \n\nIBM Cloud Internet Services ingests traffic by returning a CIS IP address on the DNS lookup for a domain, instead of the actual record for the origin server\u2019s IP address. This allows CIS to ingest, single-pass inspect, and re-encrypt data before sending it to the origin server destination. CIS can also act in DNS-only mode, returning the actual DNS record without obfuscating the IP, which disables DDoS and the other functions of CIS. To enable CIS protections, switch the \"proxy\" slider next to each DNS record to on; to disable protections, switch to off.\n\n\n\n\n\n Unlimited DDoS mitigation \n\nDDoS mitigation is typically an expensive service that can grow in cost when under attack. Unlimited DDoS mitigation is included with CIS at no additional cost.\n\n\n\n\n\n Mitigate Layer 7 attacks (configuration) \n\nThough DDoS is enabled by default in CIS, you can further configure Layer 7 security by:\n\n\n\n* Configuring WAF ruleset sensitivity and response behavior\n* Adding rate limiting\n* Adding firewall rules\n\n\n\nUse these features to customize Layer 7 mitigation of both volumetric and non-volumetric attacks.\n\n\n\n\n\n Mitigate non volumetric attacks \n\nCIS WAF contains rulesets to mitigate non-volumetric attacks, including cross-site forgery, cross-site-scripting (XSS), file inclusion, and SQL injection. For additional information about WAF, see [Web Application Firewall concepts](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-waf-q-and-awhat-types-of-attacks-can-waf-prevent).\n\n\n\n\n\n Cost protection","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_09121-34367-36050","score":23.6449064264,"text":"\nAs an account owner or admin, review the existing access policies for all Key Protect users in your account to ensure that they are assigned the appropriate levels of access. To learn more about Key Protect roles and permissions, see [Managing user access](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-access).\n\n\n\n\n\n\n\n September 2019 \n\n\n\n 27 September 2019 \n\nKey Protect supports fine-grain access\n: As an account admin, you can now assign fine-grained access to individual keys within a Key Protect instance. To learn more about granting access, see [Granting access to keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-grant-access-keys).\n\n\n\n\n\n 16 September 2019 \n\nTransport keys deprecated, replaced with import tokens\n: On 20 March 2019, [Key Protect announced transport keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-key-protect-relnotesadded-transport-keys-beta) as a beta feature for importing encryption keys to the cloud with an extra layer of security. We're happy to announce that the feature has now reached its end of beta period. The following API methods have changed:\n\n\n\n* POST api\/v2\/lockers is now POST api\/v2\/import_token\n* GET api\/v2\/lockers is now GET api\/v2\/import_token\n* GET api\/v2\/lockers\/{id} is no longer supported\n\n\n\nYou can now create [import tokens](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-importing-keysusing-import-tokens) to enable added security for keys that you upload to Key Protect.\n\nTo find out more about your options for importing keys, check out [Bringing your encryption keys to the cloud](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-importing-keys).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-key-protect-relnotes"},{"document_id":"ibmcld_05440-3062-4677","score":23.5124925728,"text":"\nUse secrets to store sensitive information You can store information, such as passwords and SSH keys in a secret. For more information, see [Working with secrets](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secret). \n\n\n\n\n\n Supported TLS versions and cipher suites \n\nThe Code Engine API and application endpoints support transport layer security (TLS) 1.2 (or higher) and the following cipher suites.\n\n\n\n TLS cipher suites \n\n\n\n* ECDHE-ECDSA-AES128-GCM-SHA256\n* ECDHE-ECDSA-AES256-GCM-SHA384\n* ECDHE-RSA-AES128-GCM-SHA256\n* ECDHE-RSA-AES256-GCM-SHA384\n* ECDHE-ECDSA-CHACHA20-POLY1305\n* ECDHE-RSA-CHACHA20-POLY1305\n\n\n\n\n\n\n\n\n\n DDoS protection \n\nCode Engine provides out-of-the-box DDoS protection for your application. Code Engine's DDoS protection is provided by Cloud Internet Services (CIS) at no additional cost to you.\n\nDDoS protection covers System Interconnection (OSI) Layer 3 and Layer 4 (TCP\/IP) protocol attacks, but not Layer 7 (HTTP) attacks.\n\nTo address Layer 7 attacks, you can take the following steps so that your traffic runs through a secure route using your custom domain and is no longer available to the public internet through the Code Engine provided domain.\n\n\n\n1. Obtain your custom domain.\n2. In Code Engine, [create a custom domain mapping](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappings) for your app.\n3. Set up an instance of [Cloud Internet Services (CIS)](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) to manage your custom domain.\n4. [Add the custom domain to the CIS instance](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-domain-support).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secure"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08766-9493-11228","score":26.4687055863,"text":"\n[Using IBM Db2 default encryption with Hyper Protect Crypto Services PKCS #11](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-db2-pkcs11).\n\n\n\n\n\n\n\n Protecting data in transit with TLS\/SSL offloading \n\nTransport Layer Security (TLS) and Secure Sockets Layer (SSL) are cryptographic protocols that are designed to provide communication security over a computer network. The TLS\/SSL protocol aims primarily to provide privacy and data integrity between two or more communicating computer applications.\n\nIn the context of web servers, the TLS\/SSL protocol allows a website to establish the identity. Users of the website can be sure that no one else is masquerading as the website. It is done through a public-private key pair.\n\nHyper Protect Crypto Services provides a way to offload the cryptographic operations that are done during the TLS handshake to establish a secure connection to the web server, while it keeps the TLS\/SSL private key securely stored in the dedicated HSM. In this way, you have control over your TLS\/SSL keys and processing. As a result, security is improved and reputational risk is decreased.\n\nTLS\/SSL offloading to the Hyper Protect Crypto Services HSM enables data in transit protection for web, API, and mobile transactions by using the standard PKCS #11 API. With Hyper Protect Crypto Services, you can integrate TLS\/SSL offloading with other cloud proxies.\n\nFor a tutorial on how to offload the SSL workload to a load balancer such as NGINX while managing keys by using Hyper Protect Crypto Services, see [Using IBM Cloud Hyper Protect Crypto Services to offload NGINX TLS](https:\/\/developer.ibm.com\/components\/ibmz\/tutorials\/use-hyper-protect-crypto-services-to-offload-nginx-tls\/).\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-use-cases"},{"document_id":"ibmcld_08739-11193-12939","score":26.0245869651,"text":"\n* For a tutorial on how to use TDE with Hyper Protect Crypto Services, see\n\n[Tutorial: Using Oracle Transparent Database Encryption with Hyper Protect Crypto Services PKCS #11](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-tde-pkcs11).\n* For a tutorial on how to use Db2 default encryption with Hyper Protect Crypto Services, see\n\n[Using IBM Db2 default encryption with Hyper Protect Crypto Services PKCS #11](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-db2-pkcs11).\n\n\n\n\n\n\n\n Protecting data in transit with TLS\/SSL offloading \n\nTransport Layer Security (TLS) and Secure Sockets Layer (SSL) are cryptographic protocols that are designed to provide communication security over a computer network. The TLS\/SSL protocol aims primarily to provide privacy and data integrity between two or more communicating computer applications.\n\nIn the context of web servers, the TLS\/SSL protocol allows a website to establish the identity. Users of the website can be sure that no one else is masquerading as the website. It is done through a public-private key pair.\n\nHyper Protect Crypto Services provides a way to offload the cryptographic operations that are done during the TLS handshake to establish a secure connection to the web server, while it keeps the TLS\/SSL private key securely stored in the dedicated HSM. In this way, you have control over your TLS\/SSL keys and processing. As a result, security is improved and reputational risk is decreased.\n\nTLS\/SSL offloading to the Hyper Protect Crypto Services HSM enables data in transit protection for web, API, and mobile transactions by using the standard PKCS #11 API. With Hyper Protect Crypto Services, you can integrate TLS\/SSL offloading with other cloud proxies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-uko-use-cases"},{"document_id":"ibmcld_04111-24547-25723","score":25.915090387,"text":"\nGET \/v1\/{crn}\/zones\/{domain_id}\/setting\/ssl internet-svcs.security.read internet-svcs.ssl-setting.read \n Update SSL settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/ssl internet-svcs.security.update internet-svcs.ssl-setting.update \n Get security level settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/security_level internet-svcs.security.read internet-svcs.security-level-setting.read \n Update security level settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/security_level internet-svcs.security.update internet-svcs.security-level-setting.update \n Get TLS 1.2 settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/tls_1_2_only internet-svcs.security.read internet-svcs.tls-1-2-only-setting.read \n Update TLS 1.2 settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/tls_1_2_only internet-svcs.security.update internet-svcs.tls-1-2-only-setting.update \n Get TLS 1.3 only settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/tls_1_3 internet-svcs.security.read internet-svcs.tls-1-3-setting.read \n Update TLS 1.3 only settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/tls_1_3 internet-svcs.security.update internet-svcs.tls-1-3-setting.update \n Get automatic HTTPS rewrites settings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_07578-760449-762535","score":23.5827842231,"text":"\nA TLS certificate is necessary to create a TLS connection with a website and comprises the domain name, the name of the company, and additional data, such as company address, city, state, and country. The certificate also shows the expiration date and details of the issuing Certificate Authority (CA).\n* How Does TLS Work?\n\nWhen a browser initiates a connection with a TLS secured website, it first retrieves the site's TLS Certificate to check whether the certificate is still valid. It verifies that the CA is one that the browser trusts, and that the certificate is being used by the website for which it has been issued. If any of these checks fail, you'll get a warning indicating that the website is not secured by a valid certificate.\n\nWhen a TLS certificate is installed on a web server, it enables a secure connection between the web server and the browser that connects to it. The website's URL is prefixed with \"HTTPS\" instead of \"HTTP\" and a padlock is shown on the address bar. If the website uses an extended validation (EV) certificate, the browser might also show a green address bar.\n* Why do I see a privacy warning?\n\nThe TLS certificates issued by IBM Cloud CIS cover the root domain (example.com) and one level of subdomain (.example.com). If you\u2019re trying to reach a second-level subdomain (..example.com) a privacy warning appears in your browser, because these host names are not added to the SAN.\n\nAllow up to 15 minutes for one of our partner Certificates Authorities (CAs) to issue a new certificate. A privacy warning appears in your browser if your new certificate has not yet been issued.\n* Why do I see invalid SSL certificate error?\n\nIf you see \"Error 526, Invalid SSL Certificate\" when visiting your site, it might mean your origin certificate is invalid. When the CIS proxy is enabled, a valid CA-signed certificate is required at the origin in the default SSL mode, which is \"End-to-end CA Signed\". Note that the default setting for the SSL mode was previously \"End-to-end Flexible\", which ignores the validity of certificates presented by the origin.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_08739-12532-14280","score":23.2877366331,"text":"\nIn this way, you have control over your TLS\/SSL keys and processing. As a result, security is improved and reputational risk is decreased.\n\nTLS\/SSL offloading to the Hyper Protect Crypto Services HSM enables data in transit protection for web, API, and mobile transactions by using the standard PKCS #11 API. With Hyper Protect Crypto Services, you can integrate TLS\/SSL offloading with other cloud proxies.\n\nFor a tutorial on how to offload the SSL workload to a load balancer such as NGINX while managing keys by using Hyper Protect Crypto Services, see [Using IBM Cloud Hyper Protect Crypto Services to offload NGINX TLS](https:\/\/developer.ibm.com\/components\/ibmz\/tutorials\/use-hyper-protect-crypto-services-to-offload-nginx-tls\/).\n\nZoom\n\n![Protecting data in transit with TLS\/SSL offloading](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/hs-crypto\/\/images\/ssl-offloading.svg)\n\nFigure 7. Protecting data in transit with TLS\/SSL offloading\n\n\n\n\n\n\n\n Using Hyper Protect Crypto Services as Enterprise PKCS 11 HSMs \n\nHyper Protect Crypto Services provides the\n\n[Enterprise PKCS #11 (EP11) API](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-grep11-api-ref). Cloud application can use this function through [gRPC](https:\/\/grpc.io).\n\nEnterprise PKCS #11 supports stateless cryptography use cases and allows for scaling and redundancy in an enterprise environment. For some use cases around asset protection, the keys can be managed outside the cryptographic service, while all sensitive operations are executed within the HSM boundary. You can use Enterprise PKCS #11 when state handling is an issue, especially for enterprise applications that benefit from the stateless character of Enterprise PKCS #11.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-uko-use-cases"},{"document_id":"ibmcld_04284-7-1578","score":23.2380647999,"text":"\nCreate and apply a new cipher suite \n\nA cipher suite is a combination of authentication, encryption, Message Authentication Code (MAC) and key exchange algorithms used to negotiate the security settings for SSL and TLS protocols. [: shortdesc]\n\nTo guarantee proper authentication you must ensure your Citrix Netscaler VPX uses the best combination of ciphers.\n\nTo learn more about SSL cipher suites and other best practices visit the following links:\n\n\n\n* [Scoring an A+ at SSLlabs.com with Citrix NetScaler](https:\/\/www.citrix.com\/blogs\/2018\/05\/16\/scoring-an-a-at-ssllabs-com-with-citrix-netscaler-q2-2018-update\/) \u2013 Q2 2018 update (refer to steps three and five in the command guide)\n* [SSL and TLS Deployment Best Practices](https:\/\/github.com\/ssllabs\/research\/wiki\/SSL-and-TLS-Deployment-Best-Practices23-use-secure-cipher-suites)\n* [How Do I Setup ECC on NetScaler?](https:\/\/support.citrix.com\/article\/CTX205289)\n\n\n\nThis topic focuses on specific and required configurations for SSL ciphers. The information in the previous links may provide additional settings that can be applied to optimize SSL operation.\n\nTo create a new Cipher Suite that prioritizes AEAD, ECDHE, and ECDSA ciphers, perform the following procedure:\n\n\n\n1. Enter the following commands simultaneously in your Citrix VPX CLI, and ensure they are all applied:\n\nadd ssl cipher SSLLABS\nbind ssl cipher SSLLABS -cipherName TLS1.2-ECDHE-ECDSA-AES128-GCM-SHA256\nbind ssl cipher SSLLABS -cipherName TLS1.2-ECDHE-ECDSA-AES256-GCM-SHA384\nbind ssl cipher SSLLABS -cipherName TLS1.2-ECDHE-ECDSA-AES128-SHA256","title":"","source":"https:\/\/cloud.ibm.com\/docs\/citrix-netscaler-vpx?topic=citrix-netscaler-vpx-create-and-apply-a-new-cipher-suite"},{"document_id":"ibmcld_06698-2686-4489","score":23.160469703,"text":"\nport=parsed.port,\npassword=parsed.password,\nssl=True,\nssl_ca_certs='\/etc\/ssl\/certs\/ca-certificates.crt',\ndecode_responses=True)\n\nRedis has a vast array of clients for applications to use. A fairly [comprehensive list is maintained on the Redis site](https:\/\/redis.io\/clients). Some useful things to keep in mind when choosing a client are features that allow you to easily design your application for the cloud, like configuring [high-availability](https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-high-availability), security, and self-signed certificate support.\n\n\n\n\n\n TLS and self-signed certificate support \n\nAll connections to Databases for Redis are TLS 1.2 enabled, so the driver you use to connect need to be able to support TLS encryption.\n\nIf your driver does not support the rediss: protocol or TLS\/SSL connections, it is still possible to tunnel connections to the Redis database endpoint by using a TLS\/SSL tunnel application such as Stunnel. An example of using Stunnel can be found on the [Connecting with a Command-line Client](https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-connecting-cli-client) page, where it is used to connect the redis-cli application.\n\nDeployments also come with a self-signed certificate so you can verify the server upon starting a connection. While not required, it is an additional security step that is recommended if your client supports it.\n\n\n\n Using the self-signed certificate \n\n\n\n1. Copy the certificate information from the Endpoints panel or the Base64 field of the connection information.\n2. If needed, decode the Base64 string into text.\n3. Save the certificate to a file. (You can use the Name that is provided or your own file name).\n4. Provide the path to the certificate to the driver or client.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-external-app"},{"document_id":"ibmcld_09888-9922-11302","score":22.6268388854,"text":"\n* [Administering a queue manager using IBM MQ Web Console](https:\/\/cloud.ibm.com\/docs\/services\/mqcloud?topic=mqcloud-mqoc_admin_mqweb)\n* [Administering a queue manager using IBM MQ Explorer](https:\/\/cloud.ibm.com\/docs\/services\/mqcloud?topic=mqcloud-mqoc_admin_mqcliexp)\n* [Administering a queue manager using runmqsc from an IBM MQ client](https:\/\/cloud.ibm.com\/docs\/services\/mqcloud?topic=mqcloud-mqoc_admin_mqcliexp)\n\n\n\n\n\n\n\n\n\n Securing remote administration \n\nAfter configuring TLS security on the required channels, you will need to properly establish a connection. This can be done in two ways:\n\n\n\n* [MQ explorer](https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-mqoc_remote_ssl_exp_admin)\n* [runmqsc](https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-mqoc_remote_ssl_runmqsc_admin)\n\n\n\n\n\n\n\n Application connections in C MQI&JMS programs \n\nTo securely connect to an MQ on Cloud queue manager using \"C MQI\" and \"JMS\" applications, please refer to the following document:\n\n\n\n* [Connections in C MQI&JMS programs](https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-mqoc_connect_app_ssl)\n\n\n\n\n\n\n\n Enabling TLS between a client and a queue manager \n\nIf TLS security has not been enabled on a queue manager, the following document explains how to correctly configure a queue manager. This walkthrough covers an \"anonymous\" one-way TLS connection as well as a \"mutual\" two-way connection.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-security"},{"document_id":"ibmcld_01022-0-1082","score":22.4865094554,"text":"\n\n\n\n\n\n\n  Data security and encryption \n\nThe IBM\u00ae Db2\u00ae on Cloud service has security built into all levels of its architecture.\n\nThe following methods are used to secure your data:\n\n\n\n*  The default keys are managed by [Key Protect](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-importing-keys). Bring-your-own-key [(BYOK)](https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-key-protect-v2) for encryption is also available through Key Protect integration.\n*  Backups are encrypted.\n*  Data in motion is encrypted through SSL\/TLS. The current supported version of this encryption is TLS 1.2.\n*  All Db2 on Cloud storage is provided on storage encrypted by using AES-256 encryption.\n*  Backplane network connectivity is supported through IBM Cloud\u00ae Service Endpoints\n*  Database-level security is supported through Role-Based Access Control (RBAC) and Row and Column Access Control (RCAC)\n\n\n\nAdministrators can make encrypted connections mandatory. For more information, see [SSL connectivity](https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-ssl_support).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-encryption"},{"document_id":"ibmcld_07982-7-2122","score":22.4288296014,"text":"\nHandling and securing secrets \n\nA secret is any piece of data that is sensitive within the context of an application or service. Secrets must be securely protected through their entire lifecycle.\n\nSecrets include all of the following but are not limited to:\n\n\n\n* Passwords of any type (database logins, OS accounts, functional IDs, and so on)\n* API keys\n* Long-lived authentication tokens (OAuth2, GitHub, IAM, and so on)\n* SSH keys\n* Encryption keys\n* Other private keys (PKI\/TLS certificates, HMAC keys, signing keys, and so on)\n\n\n\nApplication providers should ensure:\n\n\n\n* Secrets are generated and stored in the environment (for example, dev, test, and production) where your service is deployed.\n* Secrets never leave their environments (for example, dev, test, and production) and should be secured by using access control measures. Service design should minimize the number of machines and people with access to secrets by using both authorization and network restrictions based on the principle of least privilege.\n* Secrets are rotated in according with the requirements of the IBM Cloud Framework for Financial Services with minimal or no downtime.\n* Secrets are never stored in source code, configuration files, or documentation.\n\n\n\nThe following table lists the different solutions that you can use to protect your application secrets.\n\n\n\nTable 1. Secrets management and data protection scenarios\n\n Scenario What to use \n\n You need to create, lease, and manage API keys, credentials, database configurations, and other secrets for your services and applications. Use [IBM Cloud Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-getting-started). \n You need to generate, renew, and manage TLS\/SSL certificates for your deployments. Use [IBM Cloud Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-getting-started). \n You need to create and manage encryption keys. Use [Hyper Protect Crypto Services](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-overview) to manage encryption keys in a single-tenant service with dedicated hardware.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-secrets"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-842782-844922","score":17.6301274368,"text":"\nFor HA, a Hardware Firewall (High Availability) or FortiGate Security Appliance (High Availability) is required. The Network Gateway product also has an HA option with firewall capabilities.\n* I am running a hypervisor on an IBM Cloud server. Will the Hardware Firewall protect the Virtual Machines running on my hypervisor?\n\nNo. Portable IPs are used for the VMs in a hypervisor environment and portable IPs are not protected by the hardware firewall. A FortiGate Security Appliance is recommended.\n* What are the grayed out ports in my Windows Firewall?\n\nIBM Cloud offers many different services that you can utilize with your server including Evault, SNMP and Nagios monitoring. These services require that our internal systems communicate with your server to some degree. The grayed out ports you see in the Exceptions list are ports open on the internal network port only. They are still blocked on the public (internet) network connection. Since the internal network is a secured network having these ports open is considered secure.\n\nThese ports generally cannot be modified; however, if you reset the firewall rules, it will clear them from the Exceptions list. Please beware that resetting the firewall rules may have an adverse affect not only on these additional services but also could cause other issues as well with your server depending on its current configuration.\n* What Hardware Firewall options are available for 10Gbps servers?\n\nFSA 10G is the only option to support 10Gbps servers for both public and private traffic. If 10Gbps is only required on the private network (for database, backup, storage, etc), then customers can request a downgrade of only their public uplinks and order any of the Hardware Firewall products.\n* What IP ranges do I allow through the firewall?\n\nFor the list of IP addresses and IP ranges to allow through the firewall, go [here](https:\/\/cloud.ibm.com\/docs\/hardware-firewall-shared?topic=cloud-infrastructure-ibm-cloud-ip-ranges).\n* What VPN options are included with each firewall product?\n\nNot all firewalls offer VPN and not all VPN options are the same. The general options for VPN are:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-842655-844795","score":17.6301274368,"text":"\nFor HA, a Hardware Firewall (High Availability) or FortiGate Security Appliance (High Availability) is required. The Network Gateway product also has an HA option with firewall capabilities.\n* I am running a hypervisor on an IBM Cloud server. Will the Hardware Firewall protect the Virtual Machines running on my hypervisor?\n\nNo. Portable IPs are used for the VMs in a hypervisor environment and portable IPs are not protected by the hardware firewall. A FortiGate Security Appliance is recommended.\n* What are the grayed out ports in my Windows Firewall?\n\nIBM Cloud offers many different services that you can utilize with your server including Evault, SNMP and Nagios monitoring. These services require that our internal systems communicate with your server to some degree. The grayed out ports you see in the Exceptions list are ports open on the internal network port only. They are still blocked on the public (internet) network connection. Since the internal network is a secured network having these ports open is considered secure.\n\nThese ports generally cannot be modified; however, if you reset the firewall rules, it will clear them from the Exceptions list. Please beware that resetting the firewall rules may have an adverse affect not only on these additional services but also could cause other issues as well with your server depending on its current configuration.\n* What Hardware Firewall options are available for 10Gbps servers?\n\nFSA 10G is the only option to support 10Gbps servers for both public and private traffic. If 10Gbps is only required on the private network (for database, backup, storage, etc), then customers can request a downgrade of only their public uplinks and order any of the Hardware Firewall products.\n* What IP ranges do I allow through the firewall?\n\nFor the list of IP addresses and IP ranges to allow through the firewall, go [here](https:\/\/cloud.ibm.com\/docs\/hardware-firewall-shared?topic=cloud-infrastructure-ibm-cloud-ip-ranges).\n* What VPN options are included with each firewall product?\n\nNot all firewalls offer VPN and not all VPN options are the same. The general options for VPN are:","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_08152-3492-5681","score":17.4231754392,"text":"\nWill the Hardware Firewall protect the Virtual Machines running on my hypervisor? \n\nNo. Portable IPs are used for the VMs in a hypervisor environment and portable IPs are not protected by the hardware firewall. A FortiGate Security Appliance is recommended.\n\n\n\n\n\n What are the grayed out ports in my Windows Firewall? \n\nIBM Cloud offers many different services that you can utilize with your server including Evault, SNMP and Nagios monitoring. These services require that our internal systems communicate with your server to some degree. The grayed out ports you see in the Exceptions list are ports open on the internal network port only. They are still blocked on the public (internet) network connection. Since the internal network is a secured network having these ports open is considered secure.\n\nThese ports generally cannot be modified; however, if you reset the firewall rules, it will clear them from the Exceptions list. Please beware that resetting the firewall rules may have an adverse affect not only on these additional services but also could cause other issues as well with your server depending on its current configuration.\n\n\n\n\n\n What Hardware Firewall options are available for 10Gbps servers? \n\nFSA 10G is the only option to support 10Gbps servers for both public and private traffic. If 10Gbps is only required on the private network (for database, backup, storage, etc), then customers can request a downgrade of only their public uplinks and order any of the Hardware Firewall products.\n\n\n\n\n\n What IP ranges do I allow through the firewall? \n\nFor the list of IP addresses and IP ranges to allow through the firewall, go [here](https:\/\/cloud.ibm.com\/docs\/hardware-firewall-shared?topic=cloud-infrastructure-ibm-cloud-ip-ranges).\n\n\n\n\n\n What VPN options are included with each firewall product? \n\nNot all firewalls offer VPN and not all VPN options are the same. The general options for VPN are:\n\n\n\n* Each customer receives unlimited SSL VPN connections to our private network. These connections can be established by clicking the VPN link at the top of the page while logged into the IBM Cloud console.\n* IBM Cloud also offers a basic multi-tenant IPsecVPN service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hardware-firewall-shared?topic=hardware-firewall-shared-faqs-for-hardware-firewall-shared-"},{"document_id":"ibmcld_13915-6476-8449","score":17.3585947009,"text":"\nUnlike the firewall rules applied for packets traversing through the VRA, the default action of firewall rules for traffic entering or leaving the control plane is Allow. Users must add explicit drop rules if the default behavior is not desired.\n\nThe VRA provides a basic CPP rule set as template. You can merge it into your configuration by running:\n\nvyatta@vrouter merge \/opt\/vyatta\/etc\/cpp.conf\n\nAfter this rule set is merged, a new firewall rule set named CPP is added and applied to the loopback interface. It is recommend that you modify this rule set to suit your environment.\n\nPlease note that CPP rules cannot be stateful, and will only apply on ingress traffic.\n\n\n\n\n\n Zone firewalling \n\nAnother firewall concept within the IBM Cloud\u00ae Virtual Router Appliance is zone based firewalls. In zone-based firewall operation an interface is assigned to a zone (only one zone per interface) and firewall rule sets are assigned to the boundaries between zones with the idea that all interfaces within a zone have the same security level and are allowed to route freely. Traffic is only scrutinized when it is passing from one zone to another. Zones drop any traffic coming into them which is not explicitly allowed.\n\nAn interface can either belong to a zone or have a per-interface firewall configuration; an interface cannot do both.\n\nImagine the following office scenario with three departments, each department with its own VLAN:\n\n\n\n* Department A - VLANs 10 and 20 (interface dp0bond1.10 and dp0bond1.20)\n* Department B - VLANs 30 and 40 (interface dp0bond1.30 and dp0bond1.40)\n* Department C - VLAN 50 (interface dp0bond1.50)\n\n\n\nA zone can be created for each department and the interfaces for that department can be added to the zone. The following example illustrates this:\n\nset security zone-policy zone DEPARTMENTA interface dp0bond1.10\nset security zone-policy zone DEPARTMENTA interface dp0bond1.20\nset security zone-policy zone DEPARTMENTB interface dp0bond1.30","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-manage-your-ibm-firewalls"},{"document_id":"ibmcld_07616-1644-3817","score":17.0850813718,"text":"\nIBM Cloud offers many different services that you can use with your server including, Evault, SNMP and Nagios monitoring. These services require that IBM's internal systems communicate with your server to some degree. The disabled ports you see in the Exceptions list are ports open on the internal network port only. They are still blocked on the public (internet) network connection. Since the internal network is a secured network, having these ports open is considered secure.\n\nThese ports generally cannot be modified; however, if you reset the firewall rules, the ports are cleared from the Exceptions list. Be aware that resetting the firewall rules can have an adverse effect on these additional services and can cause other issues as well depending on your server configuration.\n\n\n\n\n\n What IP ranges do I allow through the firewall? \n\nFor the list of IP addresses and IP ranges to allow through the firewall, go [here](https:\/\/cloud.ibm.com\/docs\/hardware-firewall-shared?topic=hardware-firewall-shared-ibm-cloud-ip-ranges).\n\n\n\n\n\n What is the maximum number of servers that the FortiGate Security Appliance 1 Gbps will protect? \n\nThe FortiGate Security Appliance 1 Gbps can protect every server on a Public VLAN. However it is important to note that since these firewall devices are connected with 2 Gbps Uplink, IBM recommends scaling the number of firewall instances to meet the performance needs of your application. You can do so by deploying extra public VLAN Firewalls within a pod to allow for additional firewall and associated compute resources to be added.\n\n\n\n\n\n What VPN options are included with each Firewall product? \n\nNot all firewalls offer VPN and not all VPN options are the same. The general options for VPN are:\n\n\n\n* Each customer receives unlimited SSL VPN connections to IBM's private network. These connections can be established by clicking the VPN link at the top of the page while logged in to the Cloud Catalog console.\n* IBM Cloud also offers a basic multi-tenant IPsec VPN service.\n* The FortiGate Security Appliance 1 Gbps provides SSL and IPsec VPN options with Public network access only (no access to the IBM Cloud private network).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/fortigate-1g?topic=fortigate-1g-faqs-for-fortigate-security-appliance-1gbps"},{"document_id":"ibmcld_07578-834797-836955","score":17.0850813718,"text":"\nIBM Cloud offers many different services that you can use with your server including, Evault, SNMP and Nagios monitoring. These services require that IBM's internal systems communicate with your server to some degree. The disabled ports you see in the Exceptions list are ports open on the internal network port only. They are still blocked on the public (internet) network connection. Since the internal network is a secured network, having these ports open is considered secure.\n\nThese ports generally cannot be modified; however, if you reset the firewall rules, the ports are cleared from the Exceptions list. Be aware that resetting the firewall rules can have an adverse effect on these additional services and can cause other issues as well depending on your server configuration.\n* What IP ranges do I allow through the firewall?\n\nFor the list of IP addresses and IP ranges to allow through the firewall, go [here](https:\/\/cloud.ibm.com\/docs\/hardware-firewall-shared?topic=hardware-firewall-shared-ibm-cloud-ip-ranges).\n* What is the maximum number of servers that the FortiGate Security Appliance 1 Gbps will protect?\n\nThe FortiGate Security Appliance 1 Gbps can protect every server on a Public VLAN. However it is important to note that since these firewall devices are connected with 2 Gbps Uplink, IBM recommends scaling the number of firewall instances to meet the performance needs of your application. You can do so by deploying extra public VLAN Firewalls within a pod to allow for additional firewall and associated compute resources to be added.\n* What VPN options are included with each Firewall product?\n\nNot all firewalls offer VPN and not all VPN options are the same. The general options for VPN are:\n\n\n\n* Each customer receives unlimited SSL VPN connections to IBM's private network. These connections can be established by clicking the VPN link at the top of the page while logged in to the Cloud Catalog console.\n* IBM Cloud also offers a basic multi-tenant IPsec VPN service.\n* The FortiGate Security Appliance 1 Gbps provides SSL and IPsec VPN options with Public network access only (no access to the IBM Cloud private network).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-834670-836828","score":17.0850813718,"text":"\nIBM Cloud offers many different services that you can use with your server including, Evault, SNMP and Nagios monitoring. These services require that IBM's internal systems communicate with your server to some degree. The disabled ports you see in the Exceptions list are ports open on the internal network port only. They are still blocked on the public (internet) network connection. Since the internal network is a secured network, having these ports open is considered secure.\n\nThese ports generally cannot be modified; however, if you reset the firewall rules, the ports are cleared from the Exceptions list. Be aware that resetting the firewall rules can have an adverse effect on these additional services and can cause other issues as well depending on your server configuration.\n* What IP ranges do I allow through the firewall?\n\nFor the list of IP addresses and IP ranges to allow through the firewall, go [here](https:\/\/cloud.ibm.com\/docs\/hardware-firewall-shared?topic=hardware-firewall-shared-ibm-cloud-ip-ranges).\n* What is the maximum number of servers that the FortiGate Security Appliance 1 Gbps will protect?\n\nThe FortiGate Security Appliance 1 Gbps can protect every server on a Public VLAN. However it is important to note that since these firewall devices are connected with 2 Gbps Uplink, IBM recommends scaling the number of firewall instances to meet the performance needs of your application. You can do so by deploying extra public VLAN Firewalls within a pod to allow for additional firewall and associated compute resources to be added.\n* What VPN options are included with each Firewall product?\n\nNot all firewalls offer VPN and not all VPN options are the same. The general options for VPN are:\n\n\n\n* Each customer receives unlimited SSL VPN connections to IBM's private network. These connections can be established by clicking the VPN link at the top of the page while logged in to the Cloud Catalog console.\n* IBM Cloud also offers a basic multi-tenant IPsec VPN service.\n* The FortiGate Security Appliance 1 Gbps provides SSL and IPsec VPN options with Public network access only (no access to the IBM Cloud private network).","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_04109-7-2036","score":16.8955105182,"text":"\nAssigning firewall rule actions \n\nFirewall rule actions tell CIS how to respond to requests that match the criteria you define.\n\nFor lightweight firewall rules, navigate to Security > IP firewall, which contains IP rules, User Agent rules, and Domain Lockdown rules. Firewall rules are based on IP address, IP address range, Autonomous System Number (ASN), or country\/region.\n\nDomain lockdown rules specify a list of IP addresses, CIDR ranges, or networks that can access a domain, subdomain, or URL. Anything not on the list is blocked.\n\nFor more robust firewall rules, navigate to Security > Firewall rules, where you can create rules that examine incoming HTTP traffic against a set of filters to block, challenge, log, or allow matching requests.\n\nThe following table describes the actions that you can assign to your rules. The priority column shows what precedence the action receives. If a request matches two different rules that have the same priority, precedence determines the action to take.\n\n\n\nTable 1. Firewall rule actions and priority\n\n Action Available in Description Priority \n\n Log <br><br> * Firewall rules<br><br><br> Logs matching requests on the CIS edge for access with Enterprise Logpush and Logpull. Recommended for testing rule effectiveness you commit to a more severe action. Available to Enterprise customers only. 1 \n Bypass <br><br> * Firewall rules<br><br><br> Allows dynamic disabling of security features for a request. Exempts matching requests from evaluation, based on a user-defined list that contains one or more of the following features: Browser Integrity Check, Domain Lockdown, Hotlink Protection, Rate Limiting, Security Level, User Agent Block, WAF Managed Rules. Matching requests are still subject to evaluation within Firewall Rules, based on order of execution. 2 \n Allow <br><br> * Firewall rules<br> * IP firewall<br><br><br> Allows matching requests to access the site, on condition that no other CIS firewall features block the request, such as IP firewall or access rules. 3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-actions"},{"document_id":"ibmcld_14076-10944-12839","score":16.8552314709,"text":"\nThis problem can occur if a firewall prevents the provisioning framework from updating the password value.\n\n\n\n\n\n How to fix it \n\n\n\n* Option 1: Update the firewall to allow the IBM Cloud service IP ranges as described in the firewall [documentation](https:\/\/cloud.ibm.com\/docs\/vsrx?topic=hardware-firewall-shared-ibm-cloud-ip-ranges). These ranges allow for provisioning, monitoring, and management. Restart the server so the provisioning network to populate the password in the portal.\n* Option 2: Bypass the VLAN of the server from the firewall. Then, restart the server to allow provisioning network to populate the password in the portal and then route the VLAN back in the firewall.\n\n\n\n\n\n\n\n\n\n Why is my virtual server read-only? \n\n\n\n Why it's happening \n\nA virtual server might receive a read-only issue because of unplanned networking incidents or outages.\n\n\n\n\n\n How to fix it \n\nTo bring back your server from a read-only status, you need to restart the server to rescue kernel, and you need to run a file system check on all your file systems.\n\n\n\n1. From your device list, click the name of the server > Actions menu > Rescue kernel.\n2. When your server restarts in rescue mode, log in to the server by using SSH with the root user credentials.\n3. Run a file system check by using the following command: fsck -y -C \/dev\/xvda1\n4. Run the same command if you have more files systems such as \/dev\/xvda2, \/dev\/xvda3, and so on.\n\n\n\nFor more help, contact [support](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-gettinghelp) or open a support case.\n\nRunning a file system check might cause data loss, so make sure that your data is backed up.\n\n\n\n\n\n\n\n Why does my server have connectivity issues? \n\n\n\n Why it's happening \n\nIf your server has connectivity issues, the server might experience packet drops or packet loss and intermittent network connectivity.\n\n\n\n\n\n How to fix it","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-troubleshooting-virtual-server"},{"document_id":"ibmcld_07578-1006129-1007999","score":16.6907697532,"text":"\n* How can I filter internet-bound traffic and only allow specific protocols and destinations?\n\nThis is a common question when Source NAT and a firewall must be combined.\n\nKeep in mind the order of operations in the VRA you design your rulesets.\n\nIn short, firewall rules are applied after SNAT.\n\nTo block all outgoing traffic in a firewall, but allow specific SNAT flows, you must move the filtering logic onto your SNAT. For example, to only allow HTTPS internet-bound traffic for a host, the SNAT rule would be:\n\nset service nat source rule 10 description 'SNAT https traffic from server 10.1.2.3 to Internet'\nset service nat source rule 10 destination port 443\nset service nat source rule 10 outbound-interface 'dp0bond1'\nset service nat source rule 10 protocol 'tcp'\nset service nat source rule 10 source address '10.1.2.3'\nset service nat source rule 10 translation address '150.1.2.3'\n\n150.1.2.3 would be a public address for the VRA.\n\nIt is recommended to use the VRRP public address of the VRA so that you can differentiate between host and VRA public traffic.\n\nAssume that 150.1.2.3 is the VRRP VRA address, and 150.1.2.5 is the real dp0bond1 address. The stateful firewall applied on dp0bond1 out would be:\n\nset security firewall name TO_INTERNET default-action drop\nset security firewall name TO_INTERNET rule 10 action accept\nset security firewall name TO_INTERNET rule 10 description 'Accept host traffic to Internet - SNAT to VRRP'\nset security firewall name TO_INTERNET rule 10 source address '150.1.2.3'\nset security firewall name TO_INTERNET rule 10 state 'enable'\nset security firewall name TO_INTERNET rule 20 action accept\nset security firewall name TO_INTERNET rule 20 description 'Accept VRA traffic to Internet'\nset security firewall name TO_INTERNET rule 20 source address '150.1.2.5'\nset security firewall name TO_INTERNET rule 20 state 'enable'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16417-3559-5683","score":34.359973863,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-3559-5682","score":34.359973863,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16464-12399-14287","score":26.1718517228,"text":"\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.\n\nFor more information about inter-annotator agreement, see [Building the ground truth](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator and select Machine Learning Model > Annotations. Click the Annotation Tasks tab, then click the Test task.\n\nIn the Status column, you can see that the document sets are submitted.\n2. Click Calculate Inter-Annotator Agreement.\n3. View IAA scores for mention, relations, and coreference chains by clicking the first menu. You can also view agreement by pairs of human annotators. You can also view agreement by specific documents. In general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16417-1764-4158","score":25.8141585498,"text":"\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-1764-4158","score":25.8141585498,"text":"\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16563-12333-14196","score":25.7123359696,"text":"\nThe IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.\n\nFor more information about inter-annotator agreement, see [Building the ground truth](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator and select Machine Learning Model > Annotations. Click the Annotation Tasks tab, then click the Test task.\n\nIn the Status column, you can see that the document sets are submitted.\n2. Click Calculate Inter-Annotator Agreement.\n3. View IAA scores for mention, relations, and coreference chains by clicking the first menu. You can also view agreement by pairs of human annotators. You can also view agreement by specific documents. In general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/50eddb8fd81f33092880335ff107a78ff5cd0f65\/watson-knowledge-studio\/images\/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16417-5155-7505","score":25.2202028437,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-5154-7504","score":25.2202028437,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16563-10714-12816","score":23.9032257967,"text":"\nFrom the status menu, select Completed, and then click the Save button.\n9. Click Open document list to return to the list of documents for this task and click Submit All Documents to submit the documents for approval.\n\nIn a realistic situation, you would create many more annotations and complete all the documents in the set before submitting.\n10. Close this annotation set, and then open the other annotation set in the Test task.\n\nDepending on how you set up the annotation tasks and which users you assigned them to, you might need to log in to Knowledge Studio as the user who is assigned to the other annotation set in the annotation task.\n11. Repeat the same annotations in the Technology - gmanews.tv document, except this time, use the employedBy relation instead of the founderOf relation.\n\nLogging in as another user will help illustrate inter-annotator agreement in the next lesson. But if you have only one user, you can still complete the tutorial to get an understanding of how inter-annotator agreement works.\n12. After you complete the annotations for the second annotation set, click Submit All Documents.\n\n\n\n\n\n\n\n\n\n Lesson 5: Analyzing inter-annotator agreement \n\nIn this lesson, you will learn how to compare the work of multiple human annotators in Knowledge Studio.\n\n\n\n About this task \n\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16464-13891-15856","score":23.8947680992,"text":"\nIn general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/148d3bd95f946aa1bb53ea1540475f522e6b61c9\/watson-knowledge-studio-data\/images\/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:\n\n\n\n* If the scores are acceptable for an annotation set, select the check box and click Accept. Documents that do not overlap with other document sets are promoted to ground truth. Documents that do overlap must first be reviewed through adjudication so that conflicts can be resolved. For this tutorial, accept both document sets.\n* If the scores are not acceptable for an annotation set, select the check box and click Reject. The document set needs to be revisited by the human annotator to improve the annotations.\n\n\n\n\n\n\n\n\n\n Results \n\nWhen you evaluated the inter-annotator agreement scores, you saw how different pairs of human annotators annotated the same document. If the inter-annotator agreement score was acceptable, you accepted the document set.\n\n\n\n\n\n\n\n Lesson 6: Adjudicating conflicts in annotated documents \n\nIn this lesson, you will learn how to adjudicate conflicts in documents that overlap between document sets in Knowledge Studio.\n\n\n\n About this task \n\nWhen you approve a document set, only the documents that do not overlap with other document sets are promoted to ground truth. If a document is part of the overlap between multiple document sets, you must adjudicate any annotation conflicts before the document can be promoted to ground truth.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16417-3559-5683","score":43.1573379372,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-3559-5682","score":43.1573379372,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16425-14122-16407","score":40.1157856201,"text":"\nAnother indicator of annotation inconsistency is if you have enough annotations, but the corpus density is low. Density can be impacted when a mention that is significant in the domain literature occurs often, but is annotated as different types across the document set.\n\nLow precision is often an indication that you need to improve annotation consistency. To do so, review the annotation guidelines, better train the human annotators, and ensure that human annotators are working in concert and not in isolation from one another.\n\nCheck the inter-annotator agreement score. This score, which measures the degree of agreement between different annotators' output on the same document, is a valuable number. Not only does this score tell you the quality of the ground truth documents that will be used to train the machine learning model, but it also indicates the upper bound of machine learning model performance. A model that is trained on these documents is unlikely to outperform the best agreement that humans can reach. For example, if performance persists at 75 and does not go higher, take a look at the inter-annotator agreement results. If the inter-annotator agreement score is 80, take actions to better train the human annotators and ensure that conflicts are correctly resolved (according to the annotation guidelines) during adjudication. If humans can't agree on how something should be labeled, then it's unlikely that a machine learning model will apply the correct labels.\n* Enhance human annotator guidelines\n\nClear and comprehensive annotator guidelines are a crucial part of a harmonious and successful annotation development effort. Human annotators have a tough job to do. There can be nuances in assigning entity and relation types that are hard to anticipate until you start to work with the domain documents. The guidelines can provide a sanity check to human annotators as they evaluate documents. The guidelines should be a living and changing document, especially at the beginning of the annotation process. They provide a key feedback loop because a human annotator can capture things she learned while annotating a few documents, then as she or someone else annotates a few more documents, new tips and gotchas can be added to the guideline, and so on.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-ml"},{"document_id":"ibmcld_16490-14092-16377","score":40.1157856201,"text":"\nAnother indicator of annotation inconsistency is if you have enough annotations, but the corpus density is low. Density can be impacted when a mention that is significant in the domain literature occurs often, but is annotated as different types across the document set.\n\nLow precision is often an indication that you need to improve annotation consistency. To do so, review the annotation guidelines, better train the human annotators, and ensure that human annotators are working in concert and not in isolation from one another.\n\nCheck the inter-annotator agreement score. This score, which measures the degree of agreement between different annotators' output on the same document, is a valuable number. Not only does this score tell you the quality of the ground truth documents that will be used to train the machine learning model, but it also indicates the upper bound of machine learning model performance. A model that is trained on these documents is unlikely to outperform the best agreement that humans can reach. For example, if performance persists at 75 and does not go higher, take a look at the inter-annotator agreement results. If the inter-annotator agreement score is 80, take actions to better train the human annotators and ensure that conflicts are correctly resolved (according to the annotation guidelines) during adjudication. If humans can't agree on how something should be labeled, then it's unlikely that a machine learning model will apply the correct labels.\n* Enhance human annotator guidelines\n\nClear and comprehensive annotator guidelines are a crucial part of a harmonious and successful annotation development effort. Human annotators have a tough job to do. There can be nuances in assigning entity and relation types that are hard to anticipate until you start to work with the domain documents. The guidelines can provide a sanity check to human annotators as they evaluate documents. The guidelines should be a living and changing document, especially at the beginning of the annotation process. They provide a key feedback loop because a human annotator can capture things she learned while annotating a few documents, then as she or someone else annotates a few more documents, new tips and gotchas can be added to the guideline, and so on.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-evaluate-ml"},{"document_id":"ibmcld_16417-5155-7505","score":39.1330534826,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-5154-7504","score":39.1330534826,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16417-1764-4158","score":38.7299764091,"text":"\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-1764-4158","score":38.7299764091,"text":"\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16563-10714-12816","score":37.8549165877,"text":"\nFrom the status menu, select Completed, and then click the Save button.\n9. Click Open document list to return to the list of documents for this task and click Submit All Documents to submit the documents for approval.\n\nIn a realistic situation, you would create many more annotations and complete all the documents in the set before submitting.\n10. Close this annotation set, and then open the other annotation set in the Test task.\n\nDepending on how you set up the annotation tasks and which users you assigned them to, you might need to log in to Knowledge Studio as the user who is assigned to the other annotation set in the annotation task.\n11. Repeat the same annotations in the Technology - gmanews.tv document, except this time, use the employedBy relation instead of the founderOf relation.\n\nLogging in as another user will help illustrate inter-annotator agreement in the next lesson. But if you have only one user, you can still complete the tutorial to get an understanding of how inter-annotator agreement works.\n12. After you complete the annotations for the second annotation set, click Submit All Documents.\n\n\n\n\n\n\n\n\n\n Lesson 5: Analyzing inter-annotator agreement \n\nIn this lesson, you will learn how to compare the work of multiple human annotators in Knowledge Studio.\n\n\n\n About this task \n\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16464-12399-14287","score":37.8319774252,"text":"\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.\n\nFor more information about inter-annotator agreement, see [Building the ground truth](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator and select Machine Learning Model > Annotations. Click the Annotation Tasks tab, then click the Test task.\n\nIn the Status column, you can see that the document sets are submitted.\n2. Click Calculate Inter-Annotator Agreement.\n3. View IAA scores for mention, relations, and coreference chains by clicking the first menu. You can also view agreement by pairs of human annotators. You can also view agreement by specific documents. In general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1934264036}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10550-19180-21065","score":20.470382157,"text":"\nFor more information, see [Delete Pods](https:\/\/kubernetes.io\/docs\/tasks\/run-application\/force-delete-stateful-set-pod\/delete-pods).\n\nVolumeClaimTemplates.name\n: In the spec volume claim templates metadata section, enter a name for your volume. Use the same name that you defined in the spec.containers.volumeMount.name section. The name that you enter here is used to create the name for your PVC in the format: <volume_name>-<statefulset_name>-<replica_number>.\n\nibm.io\/auto-create-bucket\n: In the spec volume claim templates metadata section, set an annotation to configure how buckets are created. Choose between the following options:\n\n\n\n* true: Choose this option to automatically create a bucket for each stateful set replica. Note that the service credentials must have Writer permissions to automatically create the bucket.\n* false: Choose this option if you want to share an existing bucket across your stateful set replicas. Make sure to define the name of the bucket in the spec.volumeClaimTemplates.metadata.annotions.ibm.io\/bucket section of your stateful set YAML.\n\n\n\nibm.io\/auto-delete-bucket\n: In the spec volume claim templates metadata section, set an annotation to configure how buckets are deleted. Choose between the following options:\n\n\n\n* true: Your data, the bucket, and the PV is automatically removed when you delete the PVC. Your IBM Cloud Object Storage service instance remains and is not deleted. If you choose to set this option to true, then you must set ibm.io\/auto-create-bucket: true and ibm.io\/bucket: \"\"so that your bucket is automatically created with a name with the format tmp-s3fs-xxxx.\n* false: When you delete the PVC, the PV is deleted automatically, but your data and the bucket in your IBM Cloud Object Storage service instance remain. To access your data, you must create a new PVC with the name of your existing bucket.\n\n\n\nibm.io\/bucket","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage_cos_apps"},{"document_id":"ibmcld_16464-4463-6317","score":19.6923913814,"text":"\nOn the Machine Learning Model > Pre-annotation > Dictionaries tab, click Apply This Pre-annotator.\n4. Select the document set that you created in [Lesson 1](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introtut_lessml1).\n5. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task \n\nIn this lesson, you will learn how to create annotation sets and use annotation tasks to track the work of human annotators in Knowledge Studio.\n\n\n\n About this task \n\nAn annotation set is a subset of documents from an uploaded document set that you assign to a human annotator. The human annotator annotates the documents in the annotation set. To later use inter-annotator scores to compare the annotations that are added by each human annotator, you must assign at least two human annotators to different annotation sets. You must also specify that some percentage of documents overlap between the sets.\n\n> Note: In a realistic scenario, you would create as many annotation sets as needed, based on the number of human annotators who are working in the workspace. In this tutorial, you will create two annotation sets. If you do not have access to multiple user IDs, you can assign both annotation sets to the same user.\n\nFor more information about annotation sets and annotation tasks, see [Creating an annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Machine Learning Model > Annotations.\n2. Click the Annotation Tasks tab, then click Add Task.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_06109-18618-20495","score":19.3804631137,"text":"\nInstead, you must define these labels in the spec.selector.matchLabels and spec.template.metadata.labels section of your stateful set YAML. To make sure that all your stateful set replicas are into the load balancing of your service, include the same label that you used in the spec.selector section of your service YAML.\n\nlabels\n: In the spec metadata labels section, enter the same labels that you added to the spec.selector.matchLabels section of your stateful set YAML.\n\nterminationGracePeriodSeconds\n: Enter the number of seconds to give the kubelet to safely terminate the pod that runs your stateful set replica. For more information, see [Delete Pods](https:\/\/kubernetes.io\/docs\/tasks\/run-application\/force-delete-stateful-set-pod\/delete-pods).\n\nVolumeClaimTemplates.name\n: In the spec volume claim templates metadata section, enter a name for your volume. Use the same name that you defined in the spec.containers.volumeMount.name section. The name that you enter here is used to create the name for your PVC in the format: <volume_name>-<statefulset_name>-<replica_number>.\n\nibm.io\/auto-create-bucket\n: In the spec volume claim templates metadata section, set an annotation to configure how buckets are created. Choose between the following options:\n\n\n\n* true: Choose this option to automatically create a bucket for each stateful set replica. Note that the service credentials must have Writer permissions to automatically create the bucket.\n* false: Choose this option if you want to share an existing bucket across your stateful set replicas. Make sure to define the name of the bucket in the spec.volumeClaimTemplates.metadata.annotions.ibm.io\/bucket section of your stateful set YAML.\n\n\n\nibm.io\/auto-delete-bucket\n: In the spec volume claim templates metadata section, set an annotation to configure how buckets are deleted. Choose between the following options:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage_cos_apps"},{"document_id":"ibmcld_16425-1845-4030","score":19.2713471599,"text":"\nSee [Analyzing low precision scores](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-mlevaluate-mllowp).\n* Recall\n\nA measurement that specifies how many mentions that should have been annotated by a given label were actually annotated with that label - the right mentions being those that human annotators identified in the same documents. Recall is determined by the number of correctly labeled annotations divided by the number of annotations that should have been created. A recall score of 1.0 means that every mention that should have been labeled as entity type A was labeled correctly. A low recall score helps you identify places where the machine learning model failed to create an annotation that it should have. The score says nothing about how many other mentions were also labeled as entity type A, but should not have been; the precision score reflects that information. See [Analyzing low recall scores](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-mlevaluate-mllowr).\n* Percentage of total annotations\n\nA measurement of ground truth that shows how many words were annotated with a given entity type or relation type out of the total number of words that were annotated as any entity type or relation type in the test document set. This statistic is not available for coreferenced mentions. This value can help you to see how prevalent mentions of one type are compared to the other types in your ground truth.\n* Percentage of corpus density (by the number of words)\n\nA measurement of ground truth that shows the number of words that were annotated with a given entity type or relation type out of the total number of words, whether annotated or unannotated. This statistic is not available for coreferenced mentions. This value can help you to see how prevalent mentions of this type are compared to all of the other words in your domain documents.\n* Percentage of documents that contain the type\n\nA measurement of ground truth that shows how many documents contain a given entity type or relation type. This statistic is not available for coreferenced mentions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-ml"},{"document_id":"ibmcld_16516-12409-14637","score":19.2084257284,"text":"\nAnnotation tasks Assets & Tools > Documents > Tasks Machine Learning Model > Annotation Tasks \n Coreferences tab Document Annotation Machine Learning Model > Annotation Tasks > task > annotation set > document \n Dictionaries page (management) Assets & Tools > Pre-annotators > Manage Dictionaries Assets \n Dictionaries tab (mapping to classes for rule-based model) Document Annotation Rule-based Model > Rules \n Documents page Assets & Tools Assets \n Entity Types page Assets & Tools Assets \n Mentions tab Document Annotation Machine Learning Model > Annotation Tasks > task > annotation set > document \n Performance page Model Management Machine Learning Model \n Pre-annotators page Assets & Tools Machine Learning Model > Pre-annotation \n Regex tab Document Annotation Rule-based Model > Rules \n Relation Types page Assets & Tools Assets \n Relations tab Document Annotation Machine Learning Model > Annotation Tasks > task > annotation set > document \n Rules tab Document Annotation Rule-based Model \n Tasks tab Assets & Tools > Documents Machine Learning Model > Annotation Tasks \n Versions page (machine learning model) Model Management Machine Learning Model \n Versions page (rule-based model) Model Management Rule-based Model \n\n\n\n\n\n\n\n\n\n May 2018 \n\n\n\n New features and changes \n\nConfiguration issue fixed\n: A configuration issue was fixed that caused service instances in Sydney region to not appear in US South region.\n\nDeploy Model window support changes\n: In the Deploy Model window, if the region you're deploying to supports both IBM Cloud\u00ae Identity and Access Management resource groups and Cloud Foundry spaces, to see the list, you will need to choose the method of access management that your service instance uses.\n\nData collection setting added\n: Added the data collection setting on the Service Details page. For more information about data collection, see [Troubleshooting, support, and FAQs](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-troubleshootingcontent)\n\nSupport for Chinese (Traditional)\n: Added Chinese (traditional) language support.\n\nAdministrators can see number of workspaces\n: Users who have the Admin role can now see the number of workspaces that are used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-release-notes"},{"document_id":"ibmcld_16437-1699-3728","score":18.8601599775,"text":"\nTo take a snapshot of the current version, click Machine Learning Model > Versions, and then click Take Snapshot. The resources in version 1.0 are frozen, and a new version, labeled 1.1, becomes the current version. For each new version that you create, the minor version number is incremented, for example, 1.0 becomes 1.1 and then becomes 1.2.\n4. Revise the workspace resources as needed, re-train, and re-evaluate the model.\n5. If you are pleased with the performance results and want to store the new version before making future changes, create another version. Continue revising resources and re-training the model as needed, creating a new version for each iteration that you want to retain.\n6. If performance results are worse, and you want to revert to a previous version before testing any further:\n\n\n\n1. Open the Assets > Dictionaries page and download any dictionaries that you want to re-use in the restored model.\n2. Click Machine Learning Model > Versions and click Promote for the version that you want to restore. The version that you promote becomes the current version, and the version number changes to 2.0. When you promote a version, the major version number is incremented and the minor version number becomes 0, for example, 1.1 becomes 2.0.\n3. Open the Dictionaries page and upload the dictionaries that you downloaded.\n4. If testing of the new version requires changes to ground truth, open the Machine Learning Model > Annotations page. Click the Annotation Tasks tab and create a new annotation task.\n\n\n\n\n\n\n\n\n\n\n\n Modifying a type system without losing human annotations \n\nYou might need to make modifications while you train a model, based on the performance statistics. But, generally, you want the type system to be as close to final as possible before you begin large-scale annotation tasks. If you change the type system after human annotators began their work, they must revisit the documents that they annotated. They must assess the applicability of the type system changes.\n\n\n\n About this task","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-improve-ml"},{"document_id":"ibmcld_16495-1699-3728","score":18.8601599775,"text":"\nTo take a snapshot of the current version, click Machine Learning Model > Versions, and then click Take Snapshot. The resources in version 1.0 are frozen, and a new version, labeled 1.1, becomes the current version. For each new version that you create, the minor version number is incremented, for example, 1.0 becomes 1.1 and then becomes 1.2.\n4. Revise the workspace resources as needed, re-train, and re-evaluate the model.\n5. If you are pleased with the performance results and want to store the new version before making future changes, create another version. Continue revising resources and re-training the model as needed, creating a new version for each iteration that you want to retain.\n6. If performance results are worse, and you want to revert to a previous version before testing any further:\n\n\n\n1. Open the Assets > Dictionaries page and download any dictionaries that you want to re-use in the restored model.\n2. Click Machine Learning Model > Versions and click Promote for the version that you want to restore. The version that you promote becomes the current version, and the version number changes to 2.0. When you promote a version, the major version number is incremented and the minor version number becomes 0, for example, 1.1 becomes 2.0.\n3. Open the Dictionaries page and upload the dictionaries that you downloaded.\n4. If testing of the new version requires changes to ground truth, open the Machine Learning Model > Annotations page. Click the Annotation Tasks tab and create a new annotation task.\n\n\n\n\n\n\n\n\n\n\n\n Modifying a type system without losing human annotations \n\nYou might need to make modifications while you train a model, based on the performance statistics. But, generally, you want the type system to be as close to final as possible before you begin large-scale annotation tasks. If you change the type system after human annotators began their work, they must revisit the documents that they annotated. They must assess the applicability of the type system changes.\n\n\n\n About this task","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-improve-ml"},{"document_id":"ibmcld_03038-6010-7982","score":18.6347030559,"text":"\n* stop: Stops the service by scaling down the replicas in an order that limits possible dependency issues. This option also stores an annotation within the deployment or statefulset. If you subsequently try to use the script to start the service and the annotation doesn't exist in one of the deployments or statefulsets, the script fails.\n* start: You can only use this command to start the service if the wactl script was used to stop the service.\n* restart: Use this method to scale down the replicas, but to keep at least one replica for each pod running at all times to prevent a disruption in service.\n* clean: Removes the annotation that was created by the stop option from all objects including datastores.\n\n\n\n* release: The release name is hardcoded as watson-assistant.\n* cli: Specify the command line interface you are using.\n\nSpecify oc for OpenShift and kubectl for Kubernetes.\n* include-ds: Optional. Indicates that you want to perform the action on the data sources. When you specify this parameter with the restart action, all of the data sources are restarted except Redis.\n\n\n\n\n\n\n\n To manually scale the cluster all the way down and back \n\nTo scale down the cluster all the way, you must scale down the deployed services in the following order:\n\n\n\n* ui deployment\n* store deployment\n* gateway deployment\n* All other deployments\n* All statefulsets\n\n\n\n\n\n1. If you have local storage, complete the following steps:\n\n\n\n* Connect over SSH to each worker node, and then run the following command from a given worker to synchronize data to the same directory on each other worker.\n\nThe destination folders should be empty. If they're not, empty them.\n\nrsync -av \/mnt\/local-storage\/storage\/watson\/assistant\/{yourPV} {other worker}:\/mnt\/local-storage\/storage\/watson\/assistant\n* Double-check the postgres-keeper persistent volume permissions on each worker node.\n\nYou might need to scale postgres-keeper deployments first to see which persistent volumes they claim.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-manage"},{"document_id":"ibmcld_16436-14174-15978","score":18.4832103456,"text":"\nIn a dictionary, individual lexical items are assigned part of speech (POS) tags. For example, the word 'fly' can be identified as a verb or a noun.\n* performance\n\nThe measurement of a Watson system in terms of accuracy, precision, and recall, for example, when answering questions, discovering relationships, or annotating text.\n* pre-annotation\n\nThe process of annotating a set of documents prior to human annotation. Documents can be pre-annotated by using a rule-based model, a machine-learning model, IBM Watson\u2122 Natural Language Understanding, or a dictionary. Pre-annotation can help human annotators more quickly prepare a set of ground truth documents.\n* precision\n\nA measurement that specifies the proportion of results that are relevant. Precision, which is a positive predictive value, is determined by the number of correct positive results divided by the number of all positive results. Accuracy is best measured by using both precision and recall. See also [accuracy](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-glossarygloss_A) and [recall](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-glossarygloss_R).\n* processing engine archive (PEAR)\n\nA .pear archive file that includes an Unstructured Information Management Architecture (UIMA) analysis engine and all of the resources that are required to use it for custom analysis.\n\n\n\n\n\n\n\n R \n\n\n\n* recall\n\nA measurement that specifies the percentage of relevant results returned, out of all available relevant results. Recall, which is a measure of sensitivity, is determined by the number of correct positive results divided by the number of positive results that should have been returned. Accuracy is best measured by using both precision and recall.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-glossary"},{"document_id":"ibmcld_02970-29508-31593","score":18.4405315316,"text":"\nThe annotation is added to the entity you associated it with, and the system begins to train itself on the new data.\n\nThe term you annotated is added to the entity as a new dictionary value. If you associated the annotated term with an existing entity value, then the term is added as a synonym of that entity value instead of as an independent entity value.\n9. To see all of the mentions you annotated for a particular entity, from the entity's configuration page, click the Annotation tab.\n\n![Annotation view selector highlighted](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/oe-annotate2.png)\n\nContextual entities understand values that you have not explicitly defined. The system makes predictions about additional entity values based on how your user examples are annotated, and uses those values to train other entities. Any similar user examples are added to the Annotation view, so you can see how this option impacts training.\n\nIf you do not want your contextual entities to use this expanded understanding of entity values, select all the user examples in the Annotation view for that entity, and then click Delete.\n\n\n\nTo walk through a tutorial that shows you how to define contextual entities before you add your own, go to [Tutorial: Defining contextual entities](https:\/\/www.ibm.com\/cloud\/garage\/demo\/try-watson-assistant-contextual-entities).\n\n\n\n\n\n Enabling system entities \n\nWatson Assistant provides a number of system entities, which are common entities that you can use for any application. Enabling a system entity makes it possible to quickly populate your skill with training data that is common to many use cases.\n\nSystem entities can be used to recognize a broad range of values for the object types they represent. For example, the @sys-number system entity matches any numerical value, including whole numbers, decimal fractions, or even numbers written out as words.\n\nSystem entities are centrally maintained, so any updates are available automatically. You cannot modify system entities.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-entities"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16437-3299-5354","score":20.1978806512,"text":"\nYou might need to make modifications while you train a model, based on the performance statistics. But, generally, you want the type system to be as close to final as possible before you begin large-scale annotation tasks. If you change the type system after human annotators began their work, they must revisit the documents that they annotated. They must assess the applicability of the type system changes.\n\n\n\n About this task \n\nThis process propagates the current type system, ground truth editor keyboard shortcuts, and color settings to all document sets in a task.\n\n\n\n\n\n Procedure \n\nTo modify the type system without losing the work that was done by human annotators:\n\n\n\n1. Change the type system. For example, you can add or remove entity types or relation types.\n2. Decide whether you want to propagate the changes to existing human annotation tasks.\n3. Open the Machine Learning Model > Annotations page and click the Annotation Tasks tab. Open each task that you want to update and click Apply Type System Updates.\n\nIf you removed entity types or relation types from the type system, all occurrences of those types are highlighted in gray in the documents. These invalid types are ignored by the machine learning model. They do not prevent you from submitting and approving document sets.\n4. Provide details to the human annotators about what changed in the type system.\n5. Ask human annotators to update their documents to reflect the changes in the type system. For example, if you added new entity types or relation types, they must review their documents and annotate them appropriately.\n\n> Note: If the task contains completed documents, human annotators cannot alter those documents to assess type system changes until they are back in an editable state. To become editable, ask human annotators to submit the document sets so that you can reject them.\n\n\n\nRelated concepts:\n\n[Type systems](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-typesystemwks_typesystem)\n\n\n\n\n\n\n\n Document set management","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-improve-ml"},{"document_id":"ibmcld_16495-3299-5420","score":20.0797472944,"text":"\nYou might need to make modifications while you train a model, based on the performance statistics. But, generally, you want the type system to be as close to final as possible before you begin large-scale annotation tasks. If you change the type system after human annotators began their work, they must revisit the documents that they annotated. They must assess the applicability of the type system changes.\n\n\n\n About this task \n\nThis process propagates the current type system, ground truth editor keyboard shortcuts, and color settings to all document sets in a task.\n\n\n\n\n\n Procedure \n\nTo modify the type system without losing the work that was done by human annotators:\n\n\n\n1. Change the type system. For example, you can add or remove entity types or relation types.\n2. Decide whether you want to propagate the changes to existing human annotation tasks.\n3. Open the Machine Learning Model > Annotations page and click the Annotation Tasks tab. Open each task that you want to update and click Apply Type System Updates.\n\nIf you removed entity types or relation types from the type system, all occurrences of those types are highlighted in gray in the documents. These invalid types are ignored by the machine learning model. They do not prevent you from submitting and approving document sets.\n4. Provide details to the human annotators about what changed in the type system.\n5. Ask human annotators to update their documents to reflect the changes in the type system. For example, if you added new entity types or relation types, they must review their documents and annotate them appropriately.\n\n> Note: If the task contains completed documents, human annotators cannot alter those documents to assess type system changes until they are back in an editable state. To become editable, ask human annotators to submit the document sets so that you can reject them.\n\n\n\nRelated concepts:\n\n[Type systems](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-typesystemwks_typesystem)\n\n\n\n\n\n\n\n Document set management \n\nUse the right sets of data to test and train the model at the right time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-improve-ml"},{"document_id":"ibmcld_16456-7-2174","score":19.940128926,"text":"\nAnnotating documents \n\nThe information in this section helps subject matter experts who have been asked to annotate industry documents use the ground truth editor to complete the task.\n\n\n\n Workspace access \n\nYou cannot see any workspaces until someone else creates a workspace and gives you access to it.\n\nWhen an administrator adds you to an instance of Knowledge Studio, you are added in the human annotator role. With that role, you cannot create a workspace. To get access to a workspace, the administrator must create a workspace. Then the administrator or a project manager that the administrator associates with the workspace must perform the following steps:\n\n\n\n1. Create an annotation set and associate you with it.\n2. Create a task that assigns you to annotate the documents in the set.\n\n\n\nIt is not until an annotation task is assigned to you that you can see the workspace.\n\nIf you were invited to participate in a Knowledge Studio workspace, but do not see any workspaces from the Workspaces page, contact the person who invited you, and ask her to perform the required steps.\n\n\n\n\n\n Annotation best practices \n\nThese annotation best practices provide some guidance and examples as you start to annotate documents.\n\n\n\n* Annotate all documents completely.\n\nMachine learning learns from negative examples -- what is not annotated -- not just from what is annotated. So, be judicious in what you annotate, but do a complete job. If you carefully annotate only the first 5 of 10 documents in a set, the annotations that you do not capture in the last 5 documents will teach the model to ignore any entity or relation mentions that were missed in those documents. You could end up reversing any gains you made by doing a thorough job with the first 5 documents.\n* Consistent annotation is at least as important as correct annotation.\n\nSome decisions regarding annotation guidelines are arbitrary, like whether car trim lines should be considered part of model names, such as Camry or Camry LX. Which of the policies is chosen is far less important than that the project team agrees on one or the other and annotates in accordance with that policy consistently.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-user-guide"},{"document_id":"ibmcld_16530-7-2174","score":19.940128926,"text":"\nAnnotating documents \n\nThe information in this section helps subject matter experts who have been asked to annotate industry documents use the ground truth editor to complete the task.\n\n\n\n Workspace access \n\nYou cannot see any workspaces until someone else creates a workspace and gives you access to it.\n\nWhen an administrator adds you to an instance of Knowledge Studio, you are added in the human annotator role. With that role, you cannot create a workspace. To get access to a workspace, the administrator must create a workspace. Then the administrator or a project manager that the administrator associates with the workspace must perform the following steps:\n\n\n\n1. Create an annotation set and associate you with it.\n2. Create a task that assigns you to annotate the documents in the set.\n\n\n\nIt is not until an annotation task is assigned to you that you can see the workspace.\n\nIf you were invited to participate in a Knowledge Studio workspace, but do not see any workspaces from the Workspaces page, contact the person who invited you, and ask her to perform the required steps.\n\n\n\n\n\n Annotation best practices \n\nThese annotation best practices provide some guidance and examples as you start to annotate documents.\n\n\n\n* Annotate all documents completely.\n\nMachine learning learns from negative examples -- what is not annotated -- not just from what is annotated. So, be judicious in what you annotate, but do a complete job. If you carefully annotate only the first 5 of 10 documents in a set, the annotations that you do not capture in the last 5 documents will teach the model to ignore any entity or relation mentions that were missed in those documents. You could end up reversing any gains you made by doing a thorough job with the first 5 documents.\n* Consistent annotation is at least as important as correct annotation.\n\nSome decisions regarding annotation guidelines are arbitrary, like whether car trim lines should be considered part of model names, such as Camry or Camry LX. Which of the policies is chosen is far less important than that the project team agrees on one or the other and annotates in accordance with that policy consistently.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-user-guide"},{"document_id":"ibmcld_05519-10178-11444","score":18.4124706554,"text":"\n<\/xsd:enumeration>\n<xsd:enumeration value=\"median\">\n<xsd:annotation>\n<xsd:documentation>Compute the median value of the values of the group.<\/xsd:documentation>\n<\/xsd:annotation>\n<\/xsd:enumeration>\n<xsd:enumeration value=\"minimum\">\n<xsd:annotation>\n<xsd:documentation>Compute the minimum value of the values of the group.<\/xsd:documentation>\n<\/xsd:annotation>\n<\/xsd:enumeration>\n<xsd:enumeration value=\"standardDeviation\">\n<xsd:annotation>\n<xsd:documentation>Compute the standard deviation value of the values of the group.<\/xsd:documentation>\n<\/xsd:annotation>\n<\/xsd:enumeration>\n<xsd:enumeration value=\"total\">\n<xsd:annotation>\n<xsd:documentation>Compute the sum of the values of the group.<\/xsd:documentation>\n<\/xsd:annotation>\n<\/xsd:enumeration>\n<xsd:enumeration value=\"variance\">\n<xsd:annotation>\n<xsd:documentation>Compute the variance value of the values of the group.<\/xsd:documentation>\n<\/xsd:annotation>\n<\/xsd:enumeration>\n<xsd:enumeration value=\"doNotUse\">\n<xsd:annotation>\n<xsd:documentation>The related item must not be used as a grouping item and must not be aggregated. This value is used for the item that represents the property of a level of a dimension.<\/xsd:documentation>\n<\/xsd:annotation>\n<\/xsd:enumeration>\n<\/xsd:restriction>\n<\/xsd:simpleType>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cognos-dashboard-embedded?topic=cognos-dashboard-embedded-workingwithdatasources"},{"document_id":"ibmcld_06279-76124-77630","score":17.091726724,"text":"\n: Optional. The health check URL path for HTTP and HTTPs health checks. This annotation applies only if ibm-load-balancer-cloud-provider-vpc-health-check-protocol is set to http or https.\n\n\n\n* The URL path must be in the format of an [origin-form request target](https:\/\/www.rfc-editor.org\/rfc\/rfc7230section-5.3.1).\n* If this annotation is not specified and the ibm-load-balancer-cloud-provider-vpc-health-check-protocol annotation is set to http or https, the default value \/ is applied.\n\n\n\nservice.kubernetes.io\/ibm-load-balancer-cloud-provider-vpc-health-check-delay\n: Optional. The number of seconds to wait between health check attempts. By default, this value is set to 5, and has a minimum of 2 and a maximum of 60. This value must be greater than the ibm-load-balancer-cloud-provider-vpc-health-check-timeout value, which is set to 2 by default.\n\nservice.kubernetes.io\/ibm-load-balancer-cloud-provider-vpc-health-check-timeout\n: Optional. The number of seconds to wait for a response to a health check. By default, this value is set to 2, and has a minimum of 1 and a maximum of 59. This value must be less than the ibm-load-balancer-cloud-provider-vpc-health-check-delay value, which is set to 5 by default.\n\nservice.kubernetes.io\/ibm-load-balancer-cloud-provider-vpc-health-check-retries\n: The maximum number of health check retries for the VPC load balancer. By default, this value is set to 2, and has a minimum of 1 and a maximum of 10.\n\n\n\n\n\n Enabling TCP health checks for UDP load balancers","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-lbaas"},{"document_id":"ibmcld_10686-75783-77289","score":17.091726724,"text":"\n: Optional. The health check URL path for HTTP and HTTPs health checks. This annotation applies only if ibm-load-balancer-cloud-provider-vpc-health-check-protocol is set to http or https.\n\n\n\n* The URL path must be in the format of an [origin-form request target](https:\/\/www.rfc-editor.org\/rfc\/rfc7230section-5.3.1).\n* If this annotation is not specified and the ibm-load-balancer-cloud-provider-vpc-health-check-protocol annotation is set to http or https, the default value \/ is applied.\n\n\n\nservice.kubernetes.io\/ibm-load-balancer-cloud-provider-vpc-health-check-delay\n: Optional. The number of seconds to wait between health check attempts. By default, this value is set to 5, and has a minimum of 2 and a maximum of 60. This value must be greater than the ibm-load-balancer-cloud-provider-vpc-health-check-timeout value, which is set to 2 by default.\n\nservice.kubernetes.io\/ibm-load-balancer-cloud-provider-vpc-health-check-timeout\n: Optional. The number of seconds to wait for a response to a health check. By default, this value is set to 2, and has a minimum of 1 and a maximum of 59. This value must be less than the ibm-load-balancer-cloud-provider-vpc-health-check-delay value, which is set to 5 by default.\n\nservice.kubernetes.io\/ibm-load-balancer-cloud-provider-vpc-health-check-retries\n: The maximum number of health check retries for the VPC load balancer. By default, this value is set to 2, and has a minimum of 1 and a maximum of 10.\n\n\n\n\n\n Enabling TCP health checks for UDP load balancers","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-lbaas"},{"document_id":"ibmcld_10686-38113-39712","score":16.9078977723,"text":"\n: Optional. The health check URL path for HTTP and HTTPs health checks. This annotation applies only if ibm-load-balancer-cloud-provider-vpc-health-check-protocol is set to http or https. - The URL path must be in the format of an [origin-form request target](https:\/\/www.rfc-editor.org\/rfc\/rfc7230section-5.3.1). - If this annotation is not specified and the ibm-load-balancer-cloud-provider-vpc-health-check-protocol annotation is set to http or https, the default value \/ is applied.\n\nservice.kubernetes.io\/ibm-load-balancer-cloud-provider-vpc-health-check-delay\n: Optional. The number of seconds to wait between health check attempts. By default, this value is set to 5, and has a minimum of 2 and a maximum of 60. This value must be greater than the ibm-load-balancer-cloud-provider-vpc-health-check-timeout value, which is set to 2 by default.\n\nservice.kubernetes.io\/ibm-load-balancer-cloud-provider-vpc-health-check-timeout\n: Optional. The number of seconds to wait for a response to a health check. By default, this value is set to 2, and has a minimum of 1 and a maximum of 59. This value must be less than the ibm-load-balancer-cloud-provider-vpc-health-check-delay, which is set to 5 by default.\n\nservice.kubernetes.io\/ibm-load-balancer-cloud-provider-vpc-health-check-retries\n: The maximum number of health check retries for the VPC load balancer. By default, this value is set to 2, and has a minimum of 1 and a maximum of 10.\n\nselector\n: The label key (<selector_key>) and value (<selector_value>) that you used in the spec.template.metadata.labels section of your app deployment YAML.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-lbaas"},{"document_id":"ibmcld_10686-57619-59229","score":16.8175182906,"text":"\n: Optional. The health check URL path for HTTP and HTTPs health checks. This annotation applies only if ibm-load-balancer-cloud-provider-vpc-health-check-protocol is set to http or https. - The URL path must be in the format of an [origin-form request target](https:\/\/www.rfc-editor.org\/rfc\/rfc7230section-5.3.1). - If this annotation is not specified and the ibm-load-balancer-cloud-provider-vpc-health-check-protocol annotation is set to http or https, the default value \/ is applied.\n\nservice.kubernetes.io\/ibm-load-balancer-cloud-provider-vpc-health-check-delay\n: Optional. The number of seconds to wait between health check attempts. By default, this value is set to 5, and has a minimum of 2 and a maximum of 60. This value must be greater than the ibm-load-balancer-cloud-provider-vpc-health-check-timeout value, which is set to 2 by default.\n\nservice.kubernetes.io\/ibm-load-balancer-cloud-provider-vpc-health-check-timeout\n: Optional. The number of seconds to wait for a response to a health check. By default, this value is set to 2, and has a minimum of 1 and a maximum of 59. This value must be less than the ibm-load-balancer-cloud-provider-vpc-health-check-delay, which is set to 5 by default.\n\nservice.kubernetes.io\/ibm-load-balancer-cloud-provider-vpc-health-check-retries\n: The maximum number of health check retries for the VPC load balancer. By default, this value is set to 2, and has a minimum of 1 and a maximum of 10.\n\nservice.kubernetes.io\/ibm-load-balancer-cloud-provider-vpc-idle-connection-timeout\n: Optional. The idle connection timeout of the listener in seconds. The default is 50.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-lbaas"},{"document_id":"ibmcld_16364-29811-31777","score":16.7836911354,"text":"\nYou need to set up a list variable as the source of the options. For more information, see [Dynamic options](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-dynamic-options).\n\nExtension inspector\n: You can use the new extension inspector in the action editor Preview pane to debug problems with custom extensions. The extension inspector shows detailed information about what data is being sent to and returned from an external API. For more information, see [Debugging failures](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-call-extensionextension-debug).\n\n\n\n\n\n 3 November 2022 \n\nNever ask a step\n: There may be some situations where you need a step to never ask a question because you anticipate there might be redundant questions in the conversation. A new setting, Never ask, is now available for any step that expects a customer response. For more information, see [Skipping steps, always asking steps, or never asking steps](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-collect-infocollect-info-skip-step).\n\nAction notes\n: You can now add free-form notes to each action. Within each action, you can use Action notes to add a description, documentation, comments, or any other annotations to help you keep track of your work as you build an action. For more information, see [Using the action editor](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-build-actions-overviewbuild-actions-overview-use).\n\nVariable values in Preview\n: Viewing action variables in Preview has been improved. Now you can see the history of all action variables, rather than one action at a time. For more information, see [Variable values](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-reviewreview-variable-values).\n\n\n\n\n\n 21 October 2022 \n\nAlgorithm version updates\n: The algorithm version setting for both actions and dialog now includes three choices: beta, latest, and previous.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}],"retriever_scores":{}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16444-7-2064","score":49.5060903448,"text":"\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16464-4463-6317","score":48.5491031234,"text":"\nOn the Machine Learning Model > Pre-annotation > Dictionaries tab, click Apply This Pre-annotator.\n4. Select the document set that you created in [Lesson 1](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introtut_lessml1).\n5. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task \n\nIn this lesson, you will learn how to create annotation sets and use annotation tasks to track the work of human annotators in Knowledge Studio.\n\n\n\n About this task \n\nAn annotation set is a subset of documents from an uploaded document set that you assign to a human annotator. The human annotator annotates the documents in the annotation set. To later use inter-annotator scores to compare the annotations that are added by each human annotator, you must assign at least two human annotators to different annotation sets. You must also specify that some percentage of documents overlap between the sets.\n\n> Note: In a realistic scenario, you would create as many annotation sets as needed, based on the number of human annotators who are working in the workspace. In this tutorial, you will create two annotation sets. If you do not have access to multiple user IDs, you can assign both annotation sets to the same user.\n\nFor more information about annotation sets and annotation tasks, see [Creating an annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Machine Learning Model > Annotations.\n2. Click the Annotation Tasks tab, then click Add Task.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16563-4292-6145","score":46.9818788405,"text":"\nSelect the document set that you created in [Lesson 1](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_introtut_lessml1).\n6. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task \n\nIn this lesson, you will learn how to create annotation sets and use annotation tasks to track the work of human annotators in Knowledge Studio.\n\n\n\n About this task \n\nAn annotation set is a subset of documents from an uploaded document set that you assign to a human annotator. The human annotator annotates the documents in the annotation set. To later use inter-annotator scores to compare the annotations that are added by each human annotator, you must assign at least two human annotators to different annotation sets. You must also specify that some percentage of documents overlap between the sets.\n\nIn a realistic scenario, you create as many annotation sets as needed, based on the number of human annotators who are working in the workspace. In this tutorial, you will create two annotation sets. If you do not have access to multiple user IDs, you can assign both annotation sets to the same user.\n\nFor more information about annotation sets and annotation tasks, see [Creating an annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documentswks_hatask).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Machine Learning Model > Annotations.\n2. Click the Annotation Tasks tab, then click Add Task.\n3. Specify the details for the task:\n\n\n\n* In the Task name field, enter Test.\n* In the Deadline field, select a date in the future.\n\n\n\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16563-1598-3452","score":46.7893731804,"text":"\nHowever, if you have access to only a single user ID, you can still simulate most parts of the process.\n\nFor more information about user roles, see [User roles in Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-roles).\n\n\n\n\n\n\n\n Results \n\nAfter completing this tutorial, you will have a custom machine learning model that you can use with other Watson services.\n\n\n\n\n\n Lesson 1: Adding documents for annotation \n\nIn this lesson, you will learn how to add documents to a workspace in Knowledge Studio that can be annotated by human annotators.\n\n\n\n About this task \n\nFor more information about adding documents, see [Adding documents to a workspace](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-documents-for-annotationwks_projadd).\n\n\n\n\n\n Procedure \n\n\n\n1. Download the [documents-new.csv](https:\/\/watson-developer-cloud.github.io\/doc-tutorial-downloads\/knowledge-studio\/documents-new.csv) file to your computer. This file contains example documents suitable for uploading.\n2. Within your workspace, click Assets > Documents.\n3. On the Documents page, click Upload Document Sets.\n4. Upload the documents-new.csv file from your computer. The uploaded file is displayed in the table.\n\n\n\n\n\n\n\n\n\n Lesson 2: Pre-annotating with a dictionary-based annotator \n\nIn this lesson, you will learn how to use a dictionary-based annotator to pre-annotate documents in Knowledge Studio.\n\n\n\n About this task \n\nPre-annotating documents is an optional step. However, it is a worthwhile step because it makes the job of human annotators easier later.\n\nFor more information about pre-annotation with dictionaries, see [Pre-annotating documents with a dictionary](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannot).\n\n\n\n\n\n Procedure \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16507-1455-3632","score":46.2741779299,"text":"\nThis choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\n\n\n\n\n Running multiple pre-annotators","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16563-3072-4738","score":46.2428851843,"text":"\nPre-annotating documents is an optional step. However, it is a worthwhile step because it makes the job of human annotators easier later.\n\nFor more information about pre-annotation with dictionaries, see [Pre-annotating documents with a dictionary](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannot).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Assets > Dictionaries.\n\nThe Test dictionary dictionary opens. The [Adding a dictionary](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutintrowks_tutless4) lesson of the Getting started with Knowledge Studio tutorial shows you how to create this dictionary.\n2. From the Entity type list, select the ORGANIZATION entity type to map it to the Test dictionary dictionary.\n\nThe [Creating a type system](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutintrowks_tutless3) lesson of the Getting started with Knowledge Studio tutorial shows how to create the type system that contains the ORGANIZATION entity type.\n3. On the Machine Learning Model > Pre-annotation page, click Run Pre-annotators.\n4. Select Dictionary, then click Next.\n5. Select the document set that you created in [Lesson 1](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_introtut_lessml1).\n6. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16464-3021-4769","score":45.5198291719,"text":"\nYou can now divide the corpus into multiple document sets and assign the document sets to human annotators.\n\n\n\n\n\n\n\n Lesson 2: Pre-annotating with a dictionary-based annotator \n\nIn this lesson, you will learn how to use a dictionary-based annotator to pre-annotate documents in Knowledge Studio.\n\n\n\n About this task \n\nPre-annotating documents is an optional step. However, it is a worthwhile step because it makes the job of human annotators easier later.\n\nFor more information about pre-annotation with dictionaries, see [Pre-annotating documents with a dictionary](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannot).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Assets > Dictionaries.\n\nThe Test dictionary dictionary opens. The [Adding a dictionary](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutintrowks_tutless4) lesson of the Getting started with Knowledge Studio tutorial shows how to create this dictionary.\n2. From the Entity type list, select the ORGANIZATION entity type to map it to the Test dictionary dictionary.\n\nThe [Creating a type system](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutintrowks_tutless3) lesson of the Getting started with Knowledge Studio tutorial shows how to create the type system that contains the ORGANIZATION entity type.\n3. On the Machine Learning Model > Pre-annotation > Dictionaries tab, click Apply This Pre-annotator.\n4. Select the document set that you created in [Lesson 1](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introtut_lessml1).\n5. Click Run.\n\n\n\n\n\n\n\n Results","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16507-7-2044","score":45.3436402221,"text":"\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Natural Language Understanding\n\nA pre-annotator that you can use to find mentions of entities in your documents automatically. If your source documents have general knowledge subject matter, then this pre-annotator is a good choice for you. If you are working with highly specialized documents that focus on a specific field, such as patent law research, for example, the dictionary pre-annotator or rule-based model might be a better choice.\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16464-1626-3475","score":44.9061083191,"text":"\nHowever, if you have access to only a single user ID, you can still simulate most parts of the process.\n\nFor information about user roles, see [User roles in Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-roles).\n\n\n\n\n\n\n\n Results \n\nAfter completing this tutorial, you will have a custom machine learning model that you can use with other Watson services.\n\n\n\n\n\n Lesson 1: Adding documents for annotation \n\nIn this lesson, you will learn how to add documents to a workspace in Knowledge Studio that can be annotated by human annotators.\n\n\n\n About this task \n\nFor more information about adding documents, see [Adding documents to a workspace](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotationwks_projadd).\n\n\n\n\n\n Procedure \n\n\n\n1. Download the [documents-new.csv![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/watson-developer-cloud.github.io\/doc-tutorial-downloads\/knowledge-studio\/documents-new.csv) file to your computer. This file contains example documents suitable for uploading.\n2. Within your workspace, click Assets > Documents.\n3. On the Documents page, click Upload Document Sets.\n4. Upload the documents-new.csv file from your computer. The uploaded file is displayed in the table.\n\n\n\n\n\n\n\n What to do next \n\nYou can now divide the corpus into multiple document sets and assign the document sets to human annotators.\n\n\n\n\n\n\n\n Lesson 2: Pre-annotating with a dictionary-based annotator \n\nIn this lesson, you will learn how to use a dictionary-based annotator to pre-annotate documents in Knowledge Studio.\n\n\n\n About this task \n\nPre-annotating documents is an optional step. However, it is a worthwhile step because it makes the job of human annotators easier later.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16444-4487-6387","score":43.4141131827,"text":"\nIf a dictionary that is first in the order labels IBM as an Organization entity type, a machine learning model that is second in the order can't annotate IBM Watson as a Software Brand entity type because that would override the earlier annotation made to IBM.\n\nYou can view the current order of pre-annotators in the Order column on the Machine Learning Model > Pre-annotation page. To change the order, complete the following steps.\n\n\n\n1. Click Order Settings.\n2. Click the Move up and Move down arrow** buttons to move pre-annotation methods earlier or later in the order.\n3. Click Save.\n4. Double check the Order column on the Pre-annotation page to make sure that it matches the order that you want.\n\n\n\n\n\n\n\n Run pre-annotators \n\n\n\n1. After your pre-annotation methods are prepared and you have configured the order of your pre-annotators, click Run Pre-annotators.\n2. Select the pre-annotators that you want to use, and then click Next.\n3. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n4. Select the document sets that you want to pre-annotate.\n5. Click Run.\n\n\n\n\n\n\n\n\n\n Pre-annotating documents with a dictionary \n\nTo help human annotators get started with their annotation tasks, you can create a dictionary and use it to pre-annotate documents that you add to the corpus.\n\n\n\n About this task \n\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries. The human annotator can change or remove the pre-annotated entity types and assign entity types to unannotated mentions. Pre-annotation by a dictionary does not annotate relations, coreferences. Relations and coreferences must be annotated by human annotators.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.7844801365}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03126-5596-6966","score":36.4193958585,"text":"\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n\n\n\n\n\n Do you have existing content to leverage? \n\nThe answer to many a common question is already documented somewhere in your organization's technical information collateral. If only you could find it!\n\nGive your assistant access to this information by adding a search skill to your assistant. The search skill uses Discovery to return smart answers to natural language questions.\n\n\n\n\n\n Expand your assistant's responsibilities \n\nIf you start small, and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. The built-in metrics of active user conversations help you understand what your customers are asking about and how well your assistant is able to meet their needs.\n\nNothing beats real customer data. It will tell you what areas to tackle next.\n\n\n\n\n\n Ready to start building? \n\nSee [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add) to get started.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants"},{"document_id":"ibmcld_03421-6867-8448","score":35.5523722494,"text":"\nA context variable is a variable that you can use to pass information to your assistant before a conversation starts. It can also collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on.\n\nThe following script preserves the context of the conversation. In addition, it adds an $ismember context variable and sets it to true.\n\nThe name that is specified for the skill (main skill) is a hardcoded name that is used to refer to any skill that you create from the product user interface. You do not need to edit your skill name.\n\n<script>\nfunction preSendhandler(event) {\nevent.data.context.skills['main skill'].user_defined.ismember = true;\n}\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE_ID\",\n\nonLoad: function(instance) {\n\/\/ Subscribe to the \"pre:send\" event.\ninstance.on({ type: \"pre:send\", handler: preSendhandler });\ninstance.render();\n}\n};\n\nsetTimeout(function(){\nconst t=document.createElement('script');\nt.src='https:\/\/web-chat.global.assistant.dev.watson.appdomain.cloud\/versions\/' +\n(window.watsonAssistantChatOptions.clientVersion || 'latest') +\n'\/WatsonAssistantChatEntry.js';\ndocument.head.appendChild(t);});\n\n<\/script>\nShow more\n\nYou can reference the $ismember context variable from your dialog. For example, the following screen capture shows a dialog node that conditions on #General_Greetings. It has multiple conditioned responses.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_03080-6989-8610","score":31.054677995,"text":"\nFor example, you might want to ask for the customer's name and then address the person by name later on.\n\nThe following script preserves the context of the conversation. In addition, it adds an $ismember context variable and sets it to true.\n\nThe name that is specified for the skill (main skill) is a hardcoded name that is used to refer to any skill that you create from the product user interface. You do not need to edit your skill name.\n\n<script>\nfunction preSendhandler(event) {\nevent.data.context.skills['main skill'].user_defined.ismember = true;\n}\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE_ID\",\ncloudPrivateHostURL: \"YOUR_HOST_URL\",\n\nonLoad: function(instance) {\n\/\/ Subscribe to the \"pre:send\" event.\ninstance.on({ type: \"pre:send\", handler: preSendhandler });\ninstance.render();\n}\n};\n\nsetTimeout(function(){\nconst t=document.createElement('script');\nt.src='https:\/\/web-chat.global.assistant.dev.watson.appdomain.cloud\/versions\/' +\n(window.watsonAssistantChatOptions.clientVersion || 'latest') +\n'\/WatsonAssistantChatEntry.js';\ndocument.head.appendChild(t);});\n\n<\/script>\nShow more\n\nYou can reference the $ismember context variable from your dialog. For example, the following screen capture shows a dialog node that conditions on #General_Greetings. It has multiple conditioned responses. The first response checks whether the current user is a member of your rewards program by checking for the presence of the $ismember context variable. If the variable is present, the response addresses the user as a member.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_07042-19884-20539","score":30.4054869929,"text":"\nWhere is the part of the contract that I need for my task? Quickly extract critical information from contracts. Document Retrieval for Contracts \n I want the chatbot I'm building to use knowledge that I own. Give a virtual assistant quick access to technical information that is stored in various external data sources and document formats to answer customer questions. Conversational Search \n I want to uncover insights I didn't know to ask about. Gain insights from pattern analysis or perform root cause analysis. Content Mining \n\n\n\nFor more information, see [Creating projects](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-projects).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-getting-started"},{"document_id":"ibmcld_16259-1485-3642","score":30.3768127267,"text":"\nUnique user is anyone who interacts with your assistant. User ID identifies each user, using a unique label to track the level of service usage. A unique user can have multiple conversations, but a conversation never has more than one unique user.\n\nConversation is a set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back. Conversations can have multiple requests within a single conversation, but a single request doesn't span more than 1 conversation.\n\nRequest is a root-level utterance, such as an initial question or request, that signals the start of a specific flow. A user can initiate multiple requests. Requests are meant to represent the core concepts or topics your users are asking about. A request can have multiple steps within it, for example I want to order a pizza is a request. Delivery\/takeout, Small\/Medium\/Large, Cheese\/Pepperoni\/Mushrooms\/Peppers are all steps within the request of ordering a pizza.\n\n\n\n\n\n Completion and recognition \n\nThe completion and recognition charts provide information about the actions in your assistant.\n\n![Completion and recognition](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-completion-recognition-2.png)\n\n\n\n Completion \n\nCompletion is the measurement of how often users are able to successfully get through all steps of an action.\n\nYour assistant measures when someone reaches the final step of an action. The completion chart provides an overview of all the actions you have built and how many of these are being completed or not.\n\nCompletion is only applicable when a user question or request matched to an action, and the action starts.\n\nOne action can be triggered multiple times, so to better understand individual action performance, click Action completion to understand each action in more detail.\n\n\n\n\n\n Recognition \n\nRecognition is the measurement of how many requests are being recognized by the assistant and routed into starting an action.\n\nThe recognition chart provides you with a view into how many requests are matched to actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-overview"},{"document_id":"ibmcld_16456-13093-15345","score":29.3787461577,"text":"\nIf so, select a mention and click Attribute View.\n8. Click Save at any time to save your work.\n\n\n\n\n\n\n\n What to do next \n\nAfter you finish annotating all entity mentions, relation mentions, and coreferences in the document, as applicable, change the document status from In Progress to Completed, click Save, and then close the document.\n\nAfter you finish annotating all documents and mark them Completed, the status of the annotation set changes to Submitted. That is how project managers know that they can start to evaluate the documents for inter-annotator agreement, reject or accept documents, and promote them to ground truth.\n\n\n\n\n\n\n\n Annotating repeating mentions \n\nYou can optionally use the concordance tool to label multiple occurrences of a mention at once. The tool enables you to annotate the same text with the same entity type throughout a document and across annotation sets. Using the tool helps to ensure consistency in annotation across multiple documents. For example, you can label each occurrence of the mention encryption individually in mention mode, or you can label all occurrences of the mention encryption by using the concordance tool. Either way, the model learns from the entity type that you apply to the mention.\n\n\n\n About this task \n\nAlthough the concordance tool is optional, a good practice is to use the concordance tool to annotate mentions within a document or across documents before you start annotating mentions in individual documents. When you apply an entity type to a mention with the concordance tool, the system applies the entity type to all matching mentions, overriding any existing entity types that are assigned to a matching mention. To avoid conflicts, attributes (such as roles or subtypes) are removed from existing entity types when a new entity type is applied by the concordance tool.\n\n\n\n\n\n Procedure \n\nTo annotate repeating mentions:\n\n\n\n1. Log in as a human annotator (or as an administrator or project manager who was assigned documents to annotate). Workspaces that contain tasks that are assigned to you are displayed.\n2. Open a workspace, and then click Machine Learning Model > Annotations. Click the Annotation Tasks tab. The annotation tasks that are assigned to you are displayed.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-user-guide"},{"document_id":"ibmcld_16530-13093-15345","score":29.3787461577,"text":"\nIf so, select a mention and click Attribute View.\n8. Click Save at any time to save your work.\n\n\n\n\n\n\n\n What to do next \n\nAfter you finish annotating all entity mentions, relation mentions, and coreferences in the document, as applicable, change the document status from In Progress to Completed, click Save, and then close the document.\n\nAfter you finish annotating all documents and mark them Completed, the status of the annotation set changes to Submitted. That is how project managers know that they can start to evaluate the documents for inter-annotator agreement, reject or accept documents, and promote them to ground truth.\n\n\n\n\n\n\n\n Annotating repeating mentions \n\nYou can optionally use the concordance tool to label multiple occurrences of a mention at once. The tool enables you to annotate the same text with the same entity type throughout a document and across annotation sets. Using the tool helps to ensure consistency in annotation across multiple documents. For example, you can label each occurrence of the mention encryption individually in mention mode, or you can label all occurrences of the mention encryption by using the concordance tool. Either way, the model learns from the entity type that you apply to the mention.\n\n\n\n About this task \n\nAlthough the concordance tool is optional, a good practice is to use the concordance tool to annotate mentions within a document or across documents before you start annotating mentions in individual documents. When you apply an entity type to a mention with the concordance tool, the system applies the entity type to all matching mentions, overriding any existing entity types that are assigned to a matching mention. To avoid conflicts, attributes (such as roles or subtypes) are removed from existing entity types when a new entity type is applied by the concordance tool.\n\n\n\n\n\n Procedure \n\nTo annotate repeating mentions:\n\n\n\n1. Log in as a human annotator (or as an administrator or project manager who was assigned documents to annotate). Workspaces that contain tasks that are assigned to you are displayed.\n2. Open a workspace, and then click Machine Learning Model > Annotations. Click the Annotation Tasks tab. The annotation tasks that are assigned to you are displayed.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-user-guide"},{"document_id":"ibmcld_07082-4568-6992","score":28.9472678564,"text":"\nIf you are working with English-language legal contracts, enable the Content Intelligence feature to apply a contracts enrichment that can recognize and tag contract-related concepts in your data. Use this project type to automate complex business processes, such as contract review and negotiation. This project type can help to increase productivity, minimize costs, and reduce your legal exposure.\n\nOnly users of installed deployments (IBM Cloud Pak for Data) or Premium or Enterprise plan managed deployments can create this type of project.\n\nIn addition to the enrichments that are applied to a typical document retrieval project, the following enrichments are made automatically:\n\n\n\n* Content from tables in the source document is tagged so that it can be found later.\n* Contract details, such as payment terms or parties that are involved in the contract, are identified and tagged.\n\n\n\nFor any collection that you add to the project, optical character recognition (OCR) is enabled automatically so that text from scanned documents or other images is processed.\n\nWhen you apply the contracts enrichment, you cannot use Smart Document Understanding to annotate documents. A pretrained SDU model that can recognize contract-related information is applied automatically. The Table understanding enrichment is automatically applied.\n\nFor more information, see [Understanding contracts](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-contracts-schema).\n\n\n\n\n\n Conversational Search \n\nThe Conversational Search project returns information from a connected data collection as answers to questions that customers ask a chatbot, which is also known as an assistant.\n\nUse IBM Watson\u00ae Assistant and Discovery together to give your assistant access to technical content and other knowledge base resources without having to relocate or copy your corporate data. The built-in synchronization capabilities mean that your assistant can share the most up-to-date information available. Use the integrations that are provided with Watson Assistant to deploy an assistant that connects to this project to various platforms, including your company website, in minutes.\n\nThe documents that you add to this type of project are not enriched automatically.\n\nIf you need to perform more complex searches from your virtual assistant, you might want to create a Document Retrieval project instead of Conversational Search project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-projects"},{"document_id":"ibmcld_03196-16626-18708","score":27.5586558948,"text":"\n* [Adding variety](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-variety)\n\n\n\n\n\n\n\n Adding multiple lines \n\nIf you want a single text response to include multiple lines separated by carriage returns, then follow these steps:\n\n\n\n1. Add each line that you want to show to the user as a separate sentence into its own response variation field. For example:\n\n\n\nMultiple line response\n\n Response variations \n\n Hi. \n How are you today? \n\n\n\n2. For the response variation setting, choose multiline.\n\nIf you are using a dialog skill that was created before support for rich response types was added to the product, then you might not see the multiline option. Add a second text response type to the current node response. This action changes how the response is represented in the underlying JSON. As a result, the multiline option becomes available. Choose the multiline variation type. Now, you can delete the second text response type that you added to the response.\n\n\n\nWhen the response is shown to the user, both response variations are displayed, one on each line, like this:\n\nHi.\nHow are you today?\n\n\n\n\n\n Adding variety \n\nIf your users return to your conversation service frequently, they might be bored to hear the same greetings and responses every time. You can add variations to your responses so that your conversation can respond to the same condition in different ways.\n\nIn this example, the answer that your assistant provides in response to questions about store locations differs from one interaction to the next:\n\n![Shows a node that shows a user ask, Where are you located, and the dialog has three different responses defined.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/variety.png)\n\nYou can choose to rotate through the response variations sequentially or in random order. By default, responses are rotated sequentially, as if they were chosen from an ordered list.\n\nTo change the sequence in which individual text responses are returned, complete the following steps:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview"},{"document_id":"ibmcld_16343-7-1927","score":27.4332222421,"text":"\nNeuralSeek extension setup \n\n[NeuralSeek](https:\/\/neuralseek.com) by [Cerebral Blue](https:\/\/cerebralblue.com\/) is a combined search and natural-language generation system that is designed to [make conversational AI feel more conversational](https:\/\/garrettrowe.medium.com\/making-conversational-ai-feel-more-conversational-8748009b3fda). It requires that you load all your content into [IBM Watson\u00ae Discovery](https:\/\/cloud.ibm.com\/catalog\/services\/watson-discovery). Then, when a user asks a question, it has Discovery search for multiple relevant documents and then it generates a natural-language answer that uses the contents of those documents. In some cases, the answer might be taken directly from a single document, and in others, the answer can include information from multiple sources that are combined into a single coherent statement. For each query, NeuralSeek returns a single answer and a confidence score. In most cases, it also returns a URL of a document that influenced the answer, which might be one of several documents.\n\nTo set up the extension for NeuralSeek search:\n\n\n\n Set up IBM Watson\u00ae Discovery \n\n\n\n1. You need an instance of [IBM Watson\u00ae Discovery](https:\/\/cloud.ibm.com\/catalog\/services\/watson-discovery). Because NeuralSeek can modify your data as needed to make it more effective, make sure it is not an instance with important data that you are using for other purposes.\n2. In Discovery, create a project and load the documents that you want to use.\n\n\n\n\n\n\n\n Get the NeuralSeek OpenAPI specification and API Key \n\n\n\n1. You also need an instance of [NeuralSeek on IBM Cloud](https:\/\/cloud.ibm.com\/catalog\/services\/neuralseek).\n2. In NeuralSeek, open the Configure page and enter your information in the Discovery instance details section.\n3. On the Integrate page, and click the OpenAPI file link to download the NeuralSeek.json OpenAPI specification file configured for your instance.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-extension-neuralseek"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14508-9410-11470","score":18.4821882092,"text":"\nThe pack includes the following items.\n\n\n\n* Configuration assurance\n* Health\n* Performance\n* Capacity\n* Troubleshooting for NSX-T objects\n\n\n\n\n\n\n\n Management Pack for NSX for vSphere \n\nThe NSX for vSphere management pack offers operations management coverage for deployments of VMware's NSX virtual networking technologies. This management pack extends VMware Aria Operations core analytics, correlation, predictive capacity, and visualization capabilities to virtual networks. Coverage includes configuration assurance, health, performance, capacity, and troubleshooting for NSX logical switches, logical routers, edge services, distributed firewall, and load balancers.\n\nThe NSX for vSphere management pack is tightly integrated with VMware Aria Operations and vSphere host data is correlated with the NSX services that run with these hosts. With log integration by VMware Aria Operations for Logs, error and outage conditions, triggered by log messages, are alerted within the management pack object and problem windows.\n\n\n\n\n\n VMware Aria Operations Federation Management Pack \n\nVMware Aria Operations Federation Management Pack enables a multisite VMware Aria Operations deployment into a single pane of glass. It allows a deployment of VMware Aria Operations with the capability of receiving key metrics for specified objects from VMware Aria Operations deployments.\n\n\n\n\n\n Management Pack for Hybrid Cloud Extension (HCX) \n\nVMware Aria Operations Management Pack for HCX extends the Operations Management capabilities of VMware Aria Operations to hybrid capabilities presented by HCX. With the management pack, you can collect metrics, change events, and resource topology information from HCX. It enables the monitoring, isolation, and resolution of performance bottlenecks in the HCX Interconnects, Migrations, or Protected workloads.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [VMware Aria Operations 8.12.x Sizing Guidelines](https:\/\/kb.vmware.com\/s\/article\/91692)\n* [VMware Aria Operations Documentation](https:\/\/docs.vmware.com\/en\/VMware-Aria-Operations\/index.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-opsmgmt-vrops"},{"document_id":"ibmcld_13464-5732-7496","score":18.4749983627,"text":"\n: Uses a [fast Fourier transform (FFT)](https:\/\/en.wikipedia.org\/wiki\/Fast_Fourier_transform) algorithm to return the discrete Fourier transform of a time series. The string that is specified for the second parameter determines the type of transform:\n\n\n\n* forward or f for a forward transform\n* inverse or i for an inverse transform\n\n\n\nTS_SEG_FFT(DoubleSegmentTimeSeries, String)\n: Output: DoubleArrayTimeSeries\n: Uses a [fast Fourier transform (FFT)](https:\/\/en.wikipedia.org\/wiki\/Fast_Fourier_transform) algorithm to return the discrete Fourier transform for each segment of the input time series. The string that is specified for the second parameter determines the type of transform:\n\n\n\n* forward or f for a forward transform\n* inverse or i for an inverse transform\n\n\n\n: Each timetick in the output time series is the timetick of the corresponding segment.\n\nTS_AUTO_CORRELATION(DoubleTimeSeries)\n: Output: DoubleArray\n: Use an [auto correlation](https:\/\/en.wikipedia.org\/wiki\/Autocorrelation) algorithm to return the correlation of a time series with a delayed copy of itself.\n\nTS_SEG_AUTO_CORRELATION(DoubleSegmentTimeSeries)\n: Output: DoubleArrayTimeSeries\n: Use an [auto correlation](https:\/\/en.wikipedia.org\/wiki\/Autocorrelation) algorithm to return the correlation of each segment of the input time series with a delayed copy of itself. Each timetick in the output time series is the timetick of the corresponding segment.\n\nTS_CROSS_CORRELATION(DoubleTimeSeries, DoubleTimeSeries)\n: Output: DoubleArray\n: Use a [cross correlation](https:\/\/en.wikipedia.org\/wiki\/Cross-correlation) algorithm to return a measure of the similarity of two time series.\n\nTS_SEG_CROSS_CORRELATION(DoubleSegmentTimeSeries, DoubleSegmentTimeSeries)\n: Output: DoubleArrayTimeSeries","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-data_processing_functions"},{"document_id":"ibmcld_06231-33579-35126","score":18.1456253391,"text":"\nThe labels for the predefined cluster roles are as follows.<br><br><br><br> * IAM Manager service access role, scoped to a namespace: rbac.authorization.k8s.io\/aggregate-to-admin: \"true\"<br> * IAM Writer service access role: rbac.authorization.k8s.io\/aggregate-to-edit: \"true\"<br> * IAM Reader service access role: rbac.authorization.k8s.io\/aggregate-to-view: \"true\"<br><br><br> \n rules.apiGroups Specify the Kubernetes [API groups](https:\/\/kubernetes.io\/docs\/reference\/using-api\/api-groups) that you want users to be able to interact with, such as \"apps\", \"batch\", or \"extensions\". For access to the core API group at REST path api\/v1, leave the group blank: [\"\"]. \n rules.resources Specify the Kubernetes [resource types](https:\/\/kubernetes.io\/docs\/reference\/kubectl\/cheatsheet\/) to which you want to grant access, such as \"daemonsets\", \"deployments\", \"events\", or \"ingresses\". \n rules.verbs Specify the types of [actions](https:\/\/kubectl.docs.kubernetes.io\/) that you want users to be able to do, such as \"get\", \"list\", \"describe\", \"create\", or \"delete\". \n\n\n\n2. Create the cluster role in your cluster. Any users that have a role binding to the admin cluster role now have the additional permissions from the view-pod-metrics cluster role.\n\nkubectl apply -f <cluster_role_file.yaml>\n3. Follow up with users that have the admin cluster role. Ask them to [refresh their cluster configuration](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster) and test the action, such as kubectl top pods.\n\n\n\n\n\n\n\n\n\n Checking user permissions","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-users"},{"document_id":"ibmcld_10646-34141-35678","score":18.1456253391,"text":"\nThe labels for the predefined cluster roles are as follows.<br><br><br><br> * IAM Manager service access role, scoped to a namespace: rbac.authorization.k8s.io\/aggregate-to-admin: \"true\"<br> * IAM Writer service access role: rbac.authorization.k8s.io\/aggregate-to-edit: \"true\"<br> * IAM Reader service access role: rbac.authorization.k8s.io\/aggregate-to-view: \"true\"<br><br><br> \n rules.apiGroups Specify the Kubernetes [API groups](https:\/\/kubernetes.io\/docs\/reference\/using-api\/api-groups) that you want users to be able to interact with, such as \"apps\", \"batch\", or \"extensions\". For access to the core API group at REST path api\/v1, leave the group blank: [\"\"]. \n rules.resources Specify the Kubernetes [resource types](https:\/\/kubernetes.io\/docs\/reference\/kubectl\/cheatsheet\/) to which you want to grant access, such as \"daemonsets\", \"deployments\", \"events\", or \"ingresses\". \n rules.verbs Specify the types of [actions](https:\/\/kubectl.docs.kubernetes.io\/) that you want users to be able to do, such as \"get\", \"list\", \"describe\", \"create\", or \"delete\". \n\n\n\n2. Create the cluster role in your cluster. Any users that have a role binding to the admin cluster role now have the additional permissions from the view-pod-metrics cluster role.\n\noc apply -f <cluster_role_file.yaml>\n3. Follow up with users that have the admin cluster role. Ask them to [refresh their cluster configuration](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster) and test the action, such as oc top pods.\n\n\n\n\n\n\n\n\n\n Checking user permissions","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-users"},{"document_id":"ibmcld_02934-20364-22061","score":17.8281499788,"text":"\nYou can ask for a list of items and save them in one slot.\n\nFor example, you might want to ask users whether they want toppings on their pizza. To do so define an entity (@toppings), and the accepted values for it (pepperoni, cheese, mushroom, and so on). Add a slot that asks the user about toppings. Use the values property of the entity type to capture multiple values, if provided.\n\n\n\nMultiple value slot\n\n Check for Save as Prompt Follow-up if found Follow-up if not found \n\n @toppings.values $toppings Any toppings on that? Great addition. What toppings would you like? We offer ... \n\n\n\nTo reference the user-specified toppings later, use the <? $entity-name.join(',') ?> syntax to list each item in the toppings array and separate the values with a comma. For example, I am ordering you a $size pizza with <? $toppings.join(',') ?> for delivery by $time.\n\n\n\n\n\n Reformatting values \n\nBecause you are asking for information from the user and need to reference their input in responses, consider reformatting the values so you can display them in a friendlier format.\n\nFor example, time values are saved in the hh:mm:ss format. You can use the JSON editor for the slot to reformat the time value as you save it so it uses the hour:minutes AM\/PM format instead:\n\n{\n\"context\":{\n\"time\": \"<? @sys-time.reformatDateTime('h:mm a') ?>\"\n}\n}\n\nSee [Expression language methods](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-methods) for other reformatting ideas.\n\n\n\n\n\n Dealing with zeros \n\nUsing @sys-number in a slot condition is helpful for capturing any numbers that users specify in their input. However, it does not behave as expected when users specify the number zero (0).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots"},{"document_id":"ibmcld_03249-18988-20805","score":17.7644780089,"text":"\nFrom the Customize pane where you enabled the Slots feature, select the Prompt for everything checkbox to enable the intial prompt. This setting adds the If no slots are pre-filled, ask this first field to the node, where you can specify the text that prompts the user for everything.\n\n\n\n\n\n Capturing multiple values \n\nYou can ask for a list of items and save them in one slot.\n\nFor example, you might want to ask users whether they want toppings on their pizza. To do so define an entity (@toppings), and the accepted values for it (pepperoni, cheese, mushroom, and so on). Add a slot that asks the user about toppings. Use the values property of the entity type to capture multiple values, if provided.\n\n\n\nMultiple value slot\n\n Check for Save it as Prompt Follow-up if found Follow-up if not found \n\n @toppings.values $toppings Any toppings on that? Great addition. What toppings would you like? We offer ... \n\n\n\nTo reference the user-specified toppings later, use the <? $entity-name.join(',') ?> syntax to list each item in the toppings array and separate the values with a comma. For example, I am ordering you a $size pizza with <? $toppings.join(',') ?> for delivery by $time.\n\n\n\n\n\n Reformatting values \n\nBecause you are asking for information from the user and need to reference their input in responses, consider reformatting the values so you can display them in a friendlier format.\n\nFor example, time values are saved in the hh:mm:ss format. You can use the JSON editor for the slot to reformat the time value as you save it so it uses the hour:minutes AM\/PM format instead:\n\n{\n\"context\":{\n\"time\": \"<? @sys-time.reformatDateTime('h:mm a') ?>\"\n}\n}\n\nSee [Expression language methods](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-methods) for other reformatting ideas.\n\n\n\n\n\n Dealing with zeros","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-slots"},{"document_id":"ibmcld_14508-7830-9886","score":17.5519232606,"text":"\nIf the client installed the following, you can monitor them.\n\n\n\n* VMware Aria Automation\n* VMware Aria Orchestrator\n* VMware Aria Business for Cloud\n* VMware Site Recovery Manager\n\n\n\nThe VMware SDDC Health Management Pack provides the following dashboards:\n\n\n\n* SDDC Management Health Overview Dashboard - You can use SDDC Management Health overview dashboard to view and analyze the application-specific problems in the SDDC components.\n* SDDC Health Historic Trend Dashboard - The VMware SDDC Health Management Pack consists of SDDC health historic trend dashboard, which displays the health trend for each component in the SDDC stack.\n* SDDC VMware Aria Operations Manager Sizing Dashboard - The SDDC VMware Aria Operations Manager Sizing Dashboard provides VMware Aria Operations Manager cluster capacity to process object and metrics.\n\n\n\nThe plug-ins in the VMware SDDC Health Management Pack collect metrics for object types that are contained in the plug-ins. The Management Pack collects health metrics for the following components:\n\n\n\n* vCenter Server\n* Management Pack for NSX for vSphere\n* VMware Aria Automation\n* VMware Aria Operations Manager\n* VMware Aria Business\n* VMware Aria Operations for Logs\n* VMware Site Recovery Manager\n* vCenter HA\n* vMware vSAN Health\n* Services in vCenter Server Appliance\n* VMware Aria Operations Manager Sizing\n* VMware Aria Orchestrator\n\n\n\n\n\n\n\n Management Pack for NSX-T \n\nThe NSX-T management pack extends VMware Aria Operations core analytics, correlation, predictive capacity, and visualization capabilities to virtual networks. The pack includes the following items.\n\n\n\n* Configuration assurance\n* Health\n* Performance\n* Capacity\n* Troubleshooting for NSX-T objects\n\n\n\n\n\n\n\n Management Pack for NSX for vSphere \n\nThe NSX for vSphere management pack offers operations management coverage for deployments of VMware's NSX virtual networking technologies. This management pack extends VMware Aria Operations core analytics, correlation, predictive capacity, and visualization capabilities to virtual networks.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-opsmgmt-vrops"},{"document_id":"ibmcld_09745-0-1466","score":17.3516884234,"text":"\n\n\n\n\n\n\n  Frequently Asked Questions \n\nFrequently asked questions about IBM Cloud Monitoring.\n\n\n\n  Where can I find the list of Cloud services that generate metrics? \n\nYou can find information about the services that generate metrics in the following documentation topic: [Cloud services](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-cloud_services).\n\n\n\n\n\n  Are you seeing errors when there are no problems? \n\nAre you observing monitoring agent connection errors or receiving uptime alerts reporting an host is down when there are no problems?\n\nIBM Cloud Monitoring has identified an issue with a subset of agent versions:\n\n\n\n*  monitoring agent 10.3.0\n*  monitoring agent 10.3.1\n*  monitoring agent 10.4.0\n*  monitoring agent 10.4.1\n\n\n\nWhere connectivity between your infrastructure and Monitoring's hosted service may fail.\n\nYou must upgrade all monitoring agents to 10.5. [Learn more](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-troubleshoottroubleshoot-entry-3).\n\n\n\n\n\n  How can I find out the metrics that are collected per agent? \n\nIn IBM Cloud Monitoring, you can monitor your monitoring agent by using the dashboard template monitoring agent Health & Status that is available in Host Infrastructure. In this dashboard, you can see the number of monitoring agents that are deployed and connected to the monitoring instance, check the version of the monitoring agents, and find out how many metrics per host the agent is collecting.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-faq"},{"document_id":"ibmcld_03334-8550-10459","score":16.2067687794,"text":"\nCurrently, you can only directly reference synonym entities that you define (pattern values are ignored). You cannot use [system entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities).\n\nIf you choose to reference an entity as an intent example (for example, @PhoneModelName)anywhere in your training data it cancels the value of using a direct reference (for example, Galaxy S8) in an intent example anywhere else. All intents will then use the entity-as-an-intent-example approach. You cannot apply this approach for a specific intent only.\n\nIn practice, this means that if you have previously trained most of your intents based on direct references (Galaxy S8), and you now use entity references (@PhoneModelName) for just one intent, the change impacts your previous training. If you do choose to use @Entity references, you must replace all previous direct references with @Entity references.\n\nDefining one example intent with an @Entity that has 10 values that are defined for it does not equate to specifying that example intent 10 times. The Watson Assistant service does not give that much weight to that one example intent syntax.\n\n\n\n\n\n\n\n Testing your intents \n\nAfter you have finished creating new intents, you can test the system to see if it recognizes your intents as you expect.\n\n\n\n1. Click Try it.\n\n![Ask Watson](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/ask_watson.png)\n2. In the \"Try it out\" pane, enter a question or other text string and press Enter to see which intent is recognized. If the wrong intent is recognized, you can improve your model by adding this text as an example to the correct intent.\n\nIf you have recently made changes in your skill, you might see a message that indicates that the system is still retraining. If you see this message, wait until training completes before testing:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents"},{"document_id":"ibmcld_09606-0-823","score":16.1480019779,"text":"\n\n\n\n\n\n\n  Getting help and support \n\nIf you have problems or questions when using the IBM Cloud Metrics Routing, you can get help by searching for information or by asking questions through a forum. You can also open a support ticket.\n\n\n\n*  You can check whether the IBM Cloud is available by going to the [IBM Cloud status page](https:\/\/cloud.ibm.com\/status?selected=status).\n*  You can review the forums to see whether other users ran into the same problem. When using the forums to ask a question, tag your question so that it is seen by the IBM Cloud development teams.\n*  If you still can't resolve the problem, you can open an IBM support ticket. For information about opening an IBM support ticket, or about support levels and ticket severities, see [Getting support](https:\/\/cloud.ibm.com\/docs\/get-support).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-gettinghelp"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06160-11142-12906","score":38.9253388799,"text":"\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-11475-13230","score":38.9253388799,"text":"\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10596-5350-7330","score":31.8018081423,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.\n\n\n\n1. Check if there were any recent changes to your cluster, environment, or account that might impact your worker nodes. If so, revert the changes and then check the worker node status to determine if the changes caused the issue.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_06160-5357-7356","score":31.6482493578,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\nIf some, but not all, of your worker nodes frequently enter a Critical or NotReady state, consider enabling [worker autorecovery](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorautorecovery) to automate these recovery steps.\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_06160-12611-14167","score":30.5332494839,"text":"\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\nkubectl describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) . Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.\n\nkubectl get mutatingwebhookconfigurations\n\nkubectl get validatingwebhookconfigurations\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-12943-14509","score":30.0004622238,"text":"\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\noc describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) and the [Openshift Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug-tool). Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10596-9883-11854","score":29.5458332317,"text":"\nIf they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n7. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states \n\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_05713-581893-583377","score":29.0180886924,"text":"\n* [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-bm_machine_idbm_machine_id)\n\n[After deleting all worker nodes, why don't my pods start on new worker nodes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-zero_nodes_calico_failurezero_nodes_calico_failure)\n\n[After a worker node updates or reloads, why do duplicate nodes and pods appear?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_10534-545406-546780","score":28.988441976,"text":"\n* [If all worker nodes in a single zone, subnet, or VLAN are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-zone)\n* [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-bm_machine_idbm_machine_id)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_06160-10037-11653","score":28.9802673642,"text":"\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05762-7-1980","score":23.5288544034,"text":"\nDebugging worker nodes \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nReview the options to debug your worker nodes and find the root causes for failures.\n\n\n\n Check worker node notifications and maintenance updates \n\nCheck the IBM Cloud health and status dashboard for any notifications or maintenance updates that might be relevant to your worker nodes. These notifications or updates might help determine the cause of the worker node failures.\n\n\n\n1.\nClassic clusters\n\nCheck the [health dashboard](https:\/\/cloud.ibm.com\/gen1\/infrastructure\/health-dashboard) for any IBM Cloud emergency maintenance notifications that might affect classic worker nodes in your account. Depending on the nature of the maintenance notification, you might need to reboot or reload your worker nodes.\n2. Check the IBM Cloud [status dashboard](https:\/\/cloud.ibm.com\/status) for any known problems that might affect your worker nodes or cluster. If any of the following components show an error status, that component might be the cause of your worker node disruptions.\n\n\n\n* For all clusters, check the Kubernetes Service and Container Registry components.\n* For VPC clusters, check the Virtual Private Cloud, Virtual Private Endpoint and Virtual Server for VPC components.\n* For Classic clusters, check the Classic Infrastructure Provisioning and Virtual Servers components.\n\n\n\n\n\n\n\n\n\n Quick steps to resolve worker node issues \n\nIf your worker node is not functioning as expected, you can follow these steps to update your cluster and command line tools or run diagnostic tests. If the issue persists, see [Debugging your worker node](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodesworker-debug-steps) for additional steps.\n\n\n\n1. [Update your cluster and worker nodes to the latest version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate).\n2. [Update your command line tools](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cli-update).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes"},{"document_id":"ibmcld_10197-7-2062","score":23.3696201255,"text":"\nDebugging worker nodes \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nReview the options to debug your worker nodes and find the root causes for failures.\n\n\n\n Check worker node notifications and maintenance updates \n\nCheck the IBM Cloud health and status dashboard for any notifications or maintenance updates that might be relevant to your worker nodes. These notifications or updates might help determine the cause of the worker node failures.\n\n\n\n1.\nClassic clusters\n\nCheck the [health dashboard](https:\/\/cloud.ibm.com\/gen1\/infrastructure\/health-dashboard) for any IBM Cloud emergency maintenance notifications that might affect classic worker nodes in your account. Depending on the nature of the maintenance notification, you might need to reboot or reload your worker nodes.\n2. Check the IBM Cloud [status dashboard](https:\/\/cloud.ibm.com\/status) for any known problems that might affect your worker nodes or cluster. If any of the following components show an error status, that component might be the cause of your worker node disruptions.\n\n\n\n* For all clusters, check the Kubernetes Service and Container Registry components.\n* For Red Hat Openshift clusters, check the Red Hat OpenShift on IBM Cloud component.\n* For VPC clusters, check the Virtual Private Cloud, Virtual Private Endpoint and Virtual Server for VPC components.\n* For Classic clusters, check the Classic Infrastructure Provisioning and Virtual Servers components.\n\n\n\n\n\n\n\n\n\n Quick steps to resolve worker node issues \n\nIf your worker node is not functioning as expected, you can follow these steps to update your cluster and command line tools or run diagnostic tests. If the issue persists, see [Debugging your worker node](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_worker_nodesworker-debug-steps) for additional steps.\n\n\n\n1. [Update your cluster and worker nodes to the latest version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate).\n2. [Update your command line tools](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cli-update).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_worker_nodes"},{"document_id":"ibmcld_10394-7-1848","score":22.9599226132,"text":"\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_10534-140407-141645","score":22.6650278065,"text":"\n[Updating clusters, worker nodes, and cluster components](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateupdate)\n\n\n\n* [Updating the master](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatemaster)\n\n\n\n* [About updating the master](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatemaster-about)\n* [Steps to update the cluster master](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatemaster-steps)\n\n\n\n* [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker_node)\n\n\n\n* [Prerequisites](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker-up-prereqs)\n* [Updating classic worker nodes in the CLI with a configmap](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker-up-configmap)\n* [Updating classic worker nodes in the console](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker_up_console)\n\n\n\n* [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatevpc_worker_node)\n\n\n\n* [Prerequisites](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatevpc_worker_prereqs)\n* [Updating VPC worker nodes in the CLI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatevpc_worker_cli)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_05713-143677-145052","score":22.4552793048,"text":"\n* [About updating the master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster-about)\n* [Steps to update the cluster master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster-steps)\n\n\n\n* [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node)\n\n\n\n* [Prerequisites](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker-up-prereqs)\n* [Updating classic worker nodes in the CLI with a configmap](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker-up-configmap)\n* [Updating classic worker nodes in the console](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_up_console)\n\n\n\n* [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node)\n\n\n\n* [Prerequisites](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_prereqs)\n* [Updating VPC worker nodes in the CLI](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_cli)\n* [Updating VPC worker nodes in the console](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_ui)\n\n\n\n* [Updating flavors (machine types)](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemachine_type)\n* [Updating cluster components](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatecomponents)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_10642-18947-20676","score":21.8425210016,"text":"\nYou notice that an update is available for your worker nodes in a [VPC infrastructure cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers). What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only VPC clusters. Have a classic cluster? See [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker_node) instead.\n\nIf you have Portworx deployed in your cluster, follow the steps to [update VPC worker nodes with Portworx volumes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage_portworx_updateportworx_vpc_up).\n\nIf you have OpenShift Data Foundation deployed in your cluster, follow the steps to [update VPC worker nodes with OpenShift Data Foundation](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-vpc).\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the VPC worker node to the latest patch by using the ibmcloud oc worker replace command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_06209-19911-21816","score":20.9523795195,"text":"\nAs security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only VPC clusters. Have a classic cluster? See [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node) instead.\n\nIf you have Portworx deployed in your cluster, follow the steps to [update VPC worker nodes with Portworx volumes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage_portworx_updateportworx_vpc_up).\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the VPC worker node to the latest patch by using the ibmcloud ks worker replace command.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the VPC worker node to the same patch by using the ibmcloud ks worker replace command with the --update option.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_05762-2732-3732","score":20.885281829,"text":"\nIf the details include an error message, review the list of [common error messages for worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-common_worker_nodes_issues) to learn how to resolve the problem.\n\nibmcloud ks worker get --cluster <cluster_name_or_id> --worker <worker_node_id>\n\n\n\n\n\n Step 4: Review the infrastructure provider for the worker node \n\nReview the infrastructure environment to check for other reasons that might cause the worker node issues.\n\n\n\n1. Check with your networking team to make sure that no recent maintenance, such as firewall or subnet updates, might impact the worker node connections.\n2. Review [IBM Cloud](https:\/\/cloud.ibm.com\/status\/) for IBM Cloud Kubernetes Service and the underlying infrastructure provider, such as Virtual Servers for classic, VPC related components, or Satellite.\n3. If you have access to the underlying infrastructure, such as classic Virtual Servers, review the details of the corresponding machines for the worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes"},{"document_id":"ibmcld_10197-2810-3810","score":20.8549764451,"text":"\nIf the details include an error message, review the list of [common error messages for worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-common_worker_nodes_issues) to learn how to resolve the problem.\n\nibmcloud oc worker get --cluster <cluster_name_or_id> --worker <worker_node_id>\n\n\n\n\n\n Step 4: Review the infrastructure provider for the worker node \n\nReview the infrastructure environment to check for other reasons that might cause the worker node issues.\n\n\n\n1. Check with your networking team to make sure that no recent maintenance, such as firewall or subnet updates, might impact the worker node connections.\n2. Review [IBM Cloud](https:\/\/cloud.ibm.com\/status\/) for Red Hat OpenShift on IBM Cloud and the underlying infrastructure provider, such as Virtual Servers for classic, VPC related components, or Satellite.\n3. If you have access to the underlying infrastructure, such as classic Virtual Servers, review the details of the corresponding machines for the worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_worker_nodes"},{"document_id":"ibmcld_06209-18717-20364","score":20.7871796836,"text":"\nComplete the [prerequisite steps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker-up-prereqs) and [set up a config map](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node) to control how your worker nodes are updated.\n2. From the [IBM Cloud console](https:\/\/cloud.ibm.com\/) menu ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/icons\/icon_hamburger.svg), click Kubernetes.\n3. From the Clusters page, click your cluster.\n4. From the Worker Nodes tab, select the checkbox for each worker node that you want to update. An action bar is displayed over the table header row.\n5. From the action bar, click Update.\n\n\n\nIf you have Portworx installed in your cluster, you must restart the Portworx pods on updated worker nodes. For more information, see [Portworx limitations](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage_portworx_planportworx_limitations).\n\n\n\n\n\n\n\n Updating VPC worker nodes \n\nYou notice that an update is available for your worker nodes in a [VPC infrastructure cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers). What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only VPC clusters. Have a classic cluster? See [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node) instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.234639363,"ndcg_cut_10":0.234639363}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00778-7-2280","score":16.5175542281,"text":"\nFAQs for Pipeline Private Workers \n\nGet answers to frequently asked questions about using Pipeline Private Workers.\n\n\n\n How do I install a multi-cluster worker pool? \n\nYou can install agents on multiple clusters that work together within a single private worker pool. By using this configuration, the private worker pool can manage more pipeline runs in parallel, and you can remove clusters from the maintenance rotation without deactivating the worker pool.\n\nAlthough having multiple agents on the same cluster supports multiple worker pools, it does not improve performance or throughput.\n\nTo configure a multi-cluster worker pool, follow the instructions for [installing directly on a cluster](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-install-private-workersinstall_pw) and [registering a Delivery Pipeline Private Worker](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-install-private-workersregister_pw) for each cluster that participates in the worker pool. Make sure that you update the worker name to identify the cluster on which the worker resides.\n\nThe multiple worker agents are now listed in the private worker integration UI and jobs are scheduled on those agents based on the cluster load at pipeline run request time.\n\n\n\n\n\n How do I view the status of private workers on multiple clusters by using the CLI? \n\nYou can use the following command within a script that traverses all of the clusters that private workers are installed on.\n\nkubectl get workeragent -ojson | jq '.items[] | .status.versionStatus.state'\n\nConsider upgrading any private workers that return results that are not OK.\n\n\n\n\n\n Which attributes can I use for private worker agents? \n\nThe following attributes are available for private worker agents:\n\n\n\n* NAME: The name that was specified when the agent was registered. This name appears on the Private Worker integration page.\n* SERVICEID: The work queue ID from which this agent processes work requests.\n* AGENT: A value of OK indicates that the agent can process work requests.\n* REGISTERED: A value of Succeeded indicates that the agent successfully registered with the regional private worker service.\n* VERSION: A value of OK indicates whether the version of the agent is current.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-faq_pipeline_private_workers&interface=ui"},{"document_id":"ibmcld_10284-7-1974","score":15.0884500405,"text":"\nTuning performance \n\nIf you have specific performance optimization requirements, you can change the default settings for some cluster components in Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae.\n\nIf you choose to change the default settings, you are doing so at your own risk. You are responsible for running tests against any changed settings and for any potential disruptions caused by the changed settings in your environment.\n\nInstead of tuning worker node performance with MachineConfig files in Red Hat OpenShift, you can modify the host with a daemonset file. For more information, see [Changing the Calico MTU](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kernelcalico-mtu) or [Tuning performance for Red Hat CoreOS worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-rhcos-performance).\n\n\n\n Default worker node settings \n\nBy default, your worker nodes have the operating system and compute hardware of the [worker node flavor](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodes) that you choose when you create the worker pool.\n\n\n\n Customizing the operating system \n\nYou can find a list of supported operating systems by cluster version in the [Red Hat OpenShift on IBM Cloud version information](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions). Your cluster can't mix operating systems or use different operating systems.\n\nTo optimize your worker nodes, consider the following information.\n\n\n\n* Image and version updates: Worker node updates, such as security patches to the image or Red Hat OpenShift versions, are provided by IBM for you. However, you choose when to apply the updates to the worker nodes. For more information, see [Updating clusters, worker nodes, and cluster components](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update).\n* Temporary modifications: If you log in to a pod or use some other process to modify a worker node setting, the modifications are temporary.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kernel"},{"document_id":"ibmcld_10284-1470-3569","score":14.988902979,"text":"\n* Image and version updates: Worker node updates, such as security patches to the image or Red Hat OpenShift versions, are provided by IBM for you. However, you choose when to apply the updates to the worker nodes. For more information, see [Updating clusters, worker nodes, and cluster components](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update).\n* Temporary modifications: If you log in to a pod or use some other process to modify a worker node setting, the modifications are temporary. Worker node lifecycle operations, such as autorecovery, reloading, updating, or replacing a worker node, change any modifications back to the default settings.\n* Persistent modifications: For modifications to persist across worker node lifecycle operations, create a daemon set that uses an init container. For more information, see [Modifying default worker node settings to optimize performance](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kernelworker).\n\n\n\nModifications to the operating system are not supported. If you modify the default settings, you are responsible for debugging and resolving the issues that might occur.\n\n\n\n\n\n Hardware changes \n\nTo change the compute hardware, such as the CPU and memory per worker node, choose among the following options.\n\n\n\n* [Create a worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workers). The instructions vary depending on the type of infrastructure for the cluster, such as classic, VPC, Satellite, or gateway clusters.\n* [Update the flavor](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemachine_type) in your cluster by creating a worker pool and removing the previous worker pool.\n\n\n\n\n\n\n\n\n\n Modifying worker node settings to optimize performance \n\n\n\n Modifying worker node settings by using the Node Tuning Operator \n\nYou can use the node tuning operator to tune worker node performance by creating custom profiles. For more information, see the Red Hat [Node Tuning Operator](https:\/\/docs.openshift.com\/container-platform\/4.7\/scalability_and_performance\/using-node-tuning-operator.html) docs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kernel"},{"document_id":"ibmcld_06115-7-2109","score":14.5634696103,"text":"\nAbout Portworx \n\nReview frequently asked questions to learn more about Portworx and how Portworx provides highly available persistent storage management for your containerized apps.\n\n\n\n What is software-defined storage (SDS)? \n\nAn SDS solution abstracts storage devices of various types, sizes, or from different vendors that are attached to the worker nodes in your cluster. Worker nodes with available storage on hard disks are added as a node to a storage cluster. In this cluster, the physical storage is virtualized and presented as a virtual storage pool to the user. The storage cluster is managed by the SDS software. If data must be stored on the storage cluster, the SDS software decides where to store the data for highest availability. Your virtual storage comes with a common set of capabilities and services that you can leverage without caring about the actual underlying storage architecture.\n\n\n\n\n\n How does Portworx work? \n\nAs a software defined storage solution, Portworx aggregates available storage that is attached to your worker nodes and creates a unified persistent storage layer for containerized databases or other stateful apps that you want to run in the cluster. By using volume replication of each container-level volume across multiple worker nodes, Portworx ensures data persistence and data accessibility across zones.\n\nPortworx also comes with additional features that you can use for your stateful apps, such as volume snapshots, volume encryption, isolation, and an integrated Storage Orchestrator for Kubernetes (Stork) to ensure optimal placement of volumes in the cluster. For more information, see the [Portworx documentation](https:\/\/docs.portworx.com\/).\n\n\n\n\n\n What are the requirements to run Portworx? \n\nReview the requirements to [install Portworx](https:\/\/docs.portworx.com\/install-portworx\/prerequisites\/).\n\nFor production environments, choose one of the [SDS worker node flavors](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodessds-table) for best performance.\n\n\n\n\n\n How can I make sure that my data is stored highly available?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage_portworx_about"},{"document_id":"ibmcld_10556-7-2107","score":14.5634696103,"text":"\nAbout Portworx \n\nReview frequently asked questions to learn more about Portworx and how Portworx provides highly available persistent storage management for your containerized apps.\n\n\n\n What is software-defined storage (SDS)? \n\nAn SDS solution abstracts storage devices of various types, sizes, or from different vendors that are attached to the worker nodes in your cluster. Worker nodes with available storage on hard disks are added as a node to a storage cluster. In this cluster, the physical storage is virtualized and presented as a virtual storage pool to the user. The storage cluster is managed by the SDS software. If data must be stored on the storage cluster, the SDS software decides where to store the data for highest availability. Your virtual storage comes with a common set of capabilities and services that you can leverage without caring about the actual underlying storage architecture.\n\n\n\n\n\n How does Portworx work? \n\nAs a software defined storage solution, Portworx aggregates available storage that is attached to your worker nodes and creates a unified persistent storage layer for containerized databases or other stateful apps that you want to run in the cluster. By using volume replication of each container-level volume across multiple worker nodes, Portworx ensures data persistence and data accessibility across zones.\n\nPortworx also comes with additional features that you can use for your stateful apps, such as volume snapshots, volume encryption, isolation, and an integrated Storage Orchestrator for Kubernetes (Stork) to ensure optimal placement of volumes in the cluster. For more information, see the [Portworx documentation](https:\/\/docs.portworx.com\/).\n\n\n\n\n\n What are the requirements to run Portworx? \n\nReview the requirements to [install Portworx](https:\/\/docs.portworx.com\/install-portworx\/prerequisites\/).\n\nFor production environments, choose one of the [SDS worker node flavors](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodessds-table) for best performance.\n\n\n\n\n\n How can I make sure that my data is stored highly available?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage_portworx_about"},{"document_id":"ibmcld_05882-7-2215","score":14.4572359387,"text":"\nTuning performance \n\nIf you have specific performance optimization requirements, you can change the default settings for some cluster components in IBM Cloud\u00ae Kubernetes Service.\n\nIf you choose to change the default settings, you are doing so at your own risk. You are responsible for running tests against any changed settings and for any potential disruptions caused by the changed settings in your environment.\n\n\n\n Default worker node settings \n\nBy default, your worker nodes have the operating system and compute hardware of the [worker node flavor](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodes) that you choose when you create the worker pool.\n\n\n\n Customizing the operating system \n\nYou can find a list of supported operating systems by cluster version in the [Kubernetes version information](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions). Your cluster can't mix operating systems or use different operating systems.\n\nTo optimize your worker nodes, consider the following information.\n\n\n\n* Image and version updates: Worker node updates, such as security patches to the image or Kubernetes versions, are provided by IBM for you. However, you choose when to apply the updates to the worker nodes. For more information, see [Updating clusters, worker nodes, and cluster components](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update).\n* Temporary modifications: If you log in to a pod or use some other process to modify a worker node setting, the modifications are temporary. Worker node lifecycle operations, such as autorecovery, reloading, updating, or replacing a worker node, change any modifications back to the default settings.\n* Persistent modifications: For modifications to persist across worker node lifecycle operations, create a daemon set that uses an init container. For more information, see [Modifying default worker node settings to optimize performance](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kernelworker).\n\n\n\nModifications to the operating system are not supported. If you modify the default settings, you are responsible for debugging and resolving the issues that might occur.\n\n\n\n\n\n Hardware changes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kernel"},{"document_id":"ibmcld_16364-64329-66554","score":14.4386682274,"text":"\nThere are 5 levels of sensitivity:\n\n\n\n* high\n* medium_high\n* medium\n* medium_low\n* low\n\n\n\nThe default (auto) is medium_high if this option is not set.\n* More predictable: The new disambiguation feature is more stable and predictable. The choices shown may sometimes vary slightly to enable learning and analytics, but the order and depth of disambiguation is largely stable.\n\n\n\nThese new features may affect various metrics, such as disambiguation rate and click rates, as well as influence conversation-level key performance indicators such as containment.\n\nIf the new disambiguation algorithm works differently than expected for your assistant, you can adjust it using the sensitivity parameter in the update workspace API. For more information, see [Update workspace](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1updateworkspace).\n\n\n\n\n\n 9 September 2021 \n\nActions skill improvements\n: Actions skills now include these new features:\n\n\n\n* Change conversation topic: In general, an action is designed to lead a customer through a particular process without any interruptions. In real life, however, conversations almost never follow such a simple flow. In the middle of a conversation, customers might get distracted, ask questions about related issues, misunderstand something, or just change their minds about what they want to do. The Change conversation topic feature enables your assistant to handle these digressions, dynamically responding to the user by changing the conversation topic as needed. For more information, see [Changing the topic of the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-actionsactions-change-topic).\n* Fallback action: The built-in action, Fallback, provides a way to automatically connect customers to a human agent if they need more help. This action helps you to handle errors in the conversation, and is triggered by these conditions:\n\n\n\n* Step validation failed: The customer repeatedly gave answers that were not valid for the expected customer response type.\n* Agent requested: The customer directly asked to be connected to a human agent.\n* No action matches: The customer repeatedly made requests or asked questions that the assistant did not understand.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_11770-5930-7773","score":14.3861362168,"text":"\nYou can also perform a rolling update of your worker node hosts with a ConfigMap.\n\nBefore you begin\n\n\n\n* Verify that all your worker nodes are in a healthy state.\n* If you are using persistent block storage volumes, you must detach these volumes from the node before you start your updates. Move the persistent volumes to a different worker node that does not require updates. Then, cordon and drain the workload from the worker node to update with the kubectl drain NODENAME command. If you cannot move the block storage volumes, use the [Applying version updates to worker nodes by replacing hosts](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workershost-update-workers-minor).\n\n\n\nApplying updates to worker nodes can cause downtime for your apps and services. Do not perform any actions on the host while the update process is running. A maximum of 20% of all your worker nodes can be unavailable during the update process.\n\n\n\n Apply version updates to worker node hosts one at a time \n\n\n\n1. Optional: [Attach](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-attach-hosts) and [assign](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-assigning-hostshost-assign-manual) extra hosts to the service cluster to handle the compute capacity while your existing hosts are updating.\n2. [Identify your worker node hosts](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workershost-identify). The worker node hosts do not have infrastructure listed in the Cluster column of the output, but instead have the name of the cluster.\n3. Update your worker nodes individually by running the ibmcloud ks worker update command.\n\nibmcloud ks worker update -c CLUSTER_NAME_OR_ID --worker WORKER_ID\n4. Confirm that the update is complete by reviewing the Kubernetes version of your worker nodes.\n\nkubectl get nodes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers"},{"document_id":"ibmcld_04111-14988-16358","score":14.3020919998,"text":"\nDelete edge function script DELETE \/v1\/{crn}\/workers\/scripts\/{script_name} internet-svcs.performance.manage internet-svcs.edge-functions-scripts.delete \n Get edge function routes GET \/v1\/{crn}\/zones\/{domain_id}\/workers\/routes internet-svcs.performance.read internet-svcs.edge-functions-routes.read \n Create edge function route POST \/v1\/{crn}\/zones\/{domain_id}\/workers\/routes internet-svcs.performance.manage internet-svcs.edge-functions-routes.create \n Update edge function route PUT \/v1\/{crn}\/zones\/{domain_id}\/workers\/routes\/{route_id} internet-svcs.performance.update internet-svcs.edge-functions-routes.update \n Delete edge function route DELETE \/v1\/{crn}\/zones\/{domain_id}\/workers\/routes\/{route_id} internet-svcs.performance.manage internet-svcs.edge-functions-routes.delete \n\n\n\n\n\n\n\n Range \n\n\n\nTable 16. Range\n\n Action Method IAM ACTION AT ACTION \n\n Get range apps GET \/v1\/{crn}\/zones\/{domain_id}\/range\/apps internet-svcs.security.read internet-svcs.range-apps.read \n Create a range app POST \/v1\/{crn}\/zones\/{domain_id}\/range\/apps internet-svcs.security.manage internet-svcs.range-apps.create \n Update a range app PUT \/v1\/{crn}\/zones\/{domain_id}\/range\/apps\/{app_id} internet-svcs.security.update internet-svcs.range-apps.update \n Delete a range app DELETE \/v1\/{crn}\/zones\/{domain_id}\/range\/apps\/{app_id} internet-svcs.security.manage internet-svcs.range-apps.delete","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_04111-13789-15438","score":14.0230332753,"text":"\nDelete a certificate uploaded to CIS edge DELETE \/v1\/{crn}\/zones\/{domain_id}\/custom_certificates\/{cert_id} internet-svcs.security.manage internet-svcs.custom-certificates.delete \n Get origin certificate issued by CIS GET \/v1\/{crn}\/zones\/{domain_id}\/origin_certificates internet-svcs.security.read internet-svcs.origin-certificates.read \n Create an origin certificate issued by CIS POST \/v1\/{crn}\/zones\/{domain_id}\/origin_certificates internet-svcs.security.manage internet-svcs.origin-certificates.create \n Revoke an origin certificate issued by CIS DELETE \/v1\/{crn}\/zones\/{domain_id}\/origin_certificates\/{cert_id} internet-svcs.security.manage internet-svcs.origin-certificates.delete \n\n\n\n\n\n\n\n Edge Functions \n\n\n\nTable 15. Edge Functions\n\n Action Method IAM ACTION AT ACTION \n\n Get edge function scripts GET \/v1\/{crn}\/workers\/scripts internet-svcs.performance.read internet-svcs.edge-functions-scripts.read \n Create edge function script POST \/v1\/{crn}\/workers\/scripts internet-svcs.performance.manage internet-svcs.edge-functions-scripts.create \n Update edge function script PUT \/v1\/{crn}\/workers\/scripts\/{script_name} internet-svcs.performance.update internet-svcs.edge-functions-scripts.update \n Delete edge function script DELETE \/v1\/{crn}\/workers\/scripts\/{script_name} internet-svcs.performance.manage internet-svcs.edge-functions-scripts.delete \n Get edge function routes GET \/v1\/{crn}\/zones\/{domain_id}\/workers\/routes internet-svcs.performance.read internet-svcs.edge-functions-routes.read \n Create edge function route POST \/v1\/{crn}\/zones\/{domain_id}\/workers\/routes internet-svcs.performance.manage internet-svcs.edge-functions-routes.create","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10068-139713-141302","score":31.1869038684,"text":"\nRed Hat OpenShift on IBM Cloud toolkit 4.3.0+20201110 4.3.0+20210111 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.3.0+20210111). \n\n\n\n\n\n\n\n Change log for worker node fix pack 4.3.40_1551_openshift, released 18 January 2021 \n\nThe following table shows the changes that are in the worker node fix pack 4.3.40_1551_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.3.40_1549_openshift\n\n Component Previous Current Description \n\n RHEL 7 Packages N\/A N\/A Updated worker node image with package updates. \n\n\n\n\n\n\n\n Change log for master fix pack 4.3.40_1550_openshift, released 6 January 2021 \n\nThe following table shows the changes that are in the master fix pack patch update 4.3.40_1550_openshift. Master patch updates are applied automatically.\n\n\n\nChanges since version 4.3.40_1548_openshift\n\n Component Previous Current Description \n\n IBM Calico extension 538 556 Updated image to include the ip command. \n IBM Cloud Block Storage driver and plug-in 1.17.2 v2.0.0 Updated to use the universal base image (UBI), to use Go version 1.15.5, to run with a least privileged security context, and to improve logging. Updated image to implement additional IBM security controls. \n IBM Cloud Controller Manager v1.17.15-1 v1.17.16-1 Updated to support the Kubernetes 1.17.16 release. \n IBM Cloud File Storage for Classic plug-in N\/A N\/A Updated to run with a privileged security context.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-changelog_archive"},{"document_id":"ibmcld_05598-81555-83001","score":31.1456566403,"text":"\nChange log for master fix pack 1.19.6_1531, released 6 January 2021 \n\nThe following table shows the changes that are in the master fix pack patch update 1.19.6_1531. Master patch updates are applied automatically.\n\n\n\nChanges since version 1.19.5_1529\n\n Component Previous Current Description \n\n IBM Calico extension 538 556 Updated image to include the ip command. \n IBM Cloud Controller Manager v1.19.5-1 v1.19.6-1 Updated to support the Kubernetes 1.19.6 release and to use Go version 1.15.5. \n IBM Cloud File Storage for Classic plug-in N\/A N\/A Updated to run with a privileged security context. \n IBM Cloud RBAC Operator c148a8a f859228 Updated image for [CVE-2020-1971](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2020-1971) and [CVE-2020-24659](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2020-24659). \n Kubernetes v1.19.5 v1.19.6 See the [Kubernetes release notes](https:\/\/github.com\/kubernetes\/kubernetes\/releases\/tag\/v1.19.6). \n Kubernetes NodeLocal DNS cache N\/A N\/A Updated to run with a least privileged security context. \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.19.5_1530, released 21 December 2020 \n\nThe following table shows the changes that are in the worker node fix pack 1.19.5_1530. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.19.5_1529\n\n Component Previous Current Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog_119"},{"document_id":"ibmcld_10527-7268-9206","score":30.9951849452,"text":"\n* OwnerReferencesPermissionEnforcement\n* PodTolerationRestriction\n* openshift.io\/JenkinsBootstrapper\n* openshift.io\/BuildConfigSecretInjector\n* openshift.io\/ImageLimitRange\n* openshift.io\/RestrictedEndpointsAdmission\n* openshift.io\/ImagePolicy\n* openshift.io\/IngressAdmission\n* openshift.io\/ClusterResourceQuota\n* MutatingAdmissionWebhook\n* ValidatingAdmissionWebhook\n\n\n\n: You can [install your own admission controllers in the cluster](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/extensible-admission-controllers\/admission-webhooks) or choose from the optional admission controllers that Red Hat OpenShift on IBM Cloud provides. Container image security enforcement: Install [Portieris](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-imagesportieris-image-sec) to block container deployments from unsigned images.\n: If you manually installed admission controllers and you don't want to use them anymore, make sure to remove them entirely. If admission controllers aren't entirely removed, they might block all actions that you want to perform on the cluster.\n\n\n\n\n\n Red Hat OpenShift version 4 worker node components \n\nReview the following components in the customer-managed worker nodes of your Red Hat OpenShift on IBM Cloud cluster.\n\nThese components run on your worker nodes because you are able to use them with the workloads that you deploy to your cluster. For example, your apps might use an operator from the OperatorHub that runs a container from an image in the internal registry. You are responsible for your usage of these components, but IBM provides updates for them in the worker node patch updates that you choose to apply.\n\nIn OpenShift Container Platform 4, many components are configured by a corresponding operator for ease of management. The following table discusses these operators and components together, to focus on the main functionality the component provides to the cluster.\n\nSingle tenancy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-architecture"},{"document_id":"ibmcld_05532-12790-14283","score":30.7965177699,"text":"\nComponent Previous Current Description \n\n Kubernetes v1.9.7 v1.9.8 See th [Kubernetes release notes]([https:\/\/github.com\/kubernetes\/kubernetes\/releases\/tag\/v1.9.8](https:\/\/github.com\/kubernetes\/kubernetes\/releases\/tag\/v1.9.8)] \n Kubernetes Configuration N\/A N\/A Added PodSecurityPolicy to the --admission-control option for the cluster's Kubernetes API server and configured the cluster to support pod security policies. For more information, see (\/docs\/containers?topic=containers-psp) [Configuring pod security policies]. \n IBM Cloud Provider v1.9.7-102 v1.9.8-141 Updated to support Kubernetes 1.9.8 release. \n OpenVPN client N\/A N\/A Added livenessProbe to the OpenVPN client vpn deployment that runs in the kube-system namespace. \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.9.7_1513, released 11 June 2018 \n\nThe following table shows the changes that are in the worker node fix pack 1.9.7_1513.\n\n\n\nTable 1. Changes since version 1.9.7_1512\n\n Component Previous Current Description \n\n Kernel update 4.4.0-116 4.4.0-127 New worker node images with kernel update for [CVE-2018-3639](http:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2018-3639) \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.9.7_1512, released 18 May 2018 \n\nThe following table shows the changes that are in the worker node fix pack 1.9.7_1512.\n\n\n\nTable 1. Changes since version 1.9.7_1511\n\n Component Previous Current Description \n\n Kubelet N\/A N\/A Fix to address a bug that occurred if you used the block storage plug-in.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-19_changelog"},{"document_id":"ibmcld_05531-4056-5642","score":30.7366798066,"text":"\nChange log for worker node fix pack 1.8.13_1516, released 3 July 2018 \n\n\n\nTable 1. Changes since version 1.8.13_1515\n\n Component Previous Current Description \n\n Kernel N\/A N\/A Optimized sysctl for high performance networking workloads. \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.8.13_1515, released 21 June 2018 \n\n\n\nTable 1. Changes since version 1.8.13_1514\n\n Component Previous Current Description \n\n Docker N\/A N\/A For non-encrypted flavors, the secondary disk is cleaned by getting a fresh file system when you reload or update the worker node. \n\n\n\n\n\n\n\n Change log 1.8.13_1514, released 19 June 2018 \n\n\n\nTable 1. Changes since version 1.8.11_1512\n\n Component Previous Current Description \n\n Kubernetes v1.8.11 v1.8.13 See the [Kubernetes release notes]([https:\/\/github.com\/kubernetes\/kubernetes\/releases\/tag\/v1.8.13](https:\/\/github.com\/kubernetes\/kubernetes\/releases\/tag\/v1.8.13)] \n Kubernetes Configuration N\/A N\/A Added PodSecurityPolicy to the --admission-control option for the cluster's Kubernetes API server and configured the cluster to support pod security policies. For more information, see [Configuring pod security policies](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-psp). \n IBM Cloud Provider v1.8.11-126 v1.8.13-176 Updated to support Kubernetes 1.8.13 release. \n OpenVPN client N\/A N\/A Added livenessProbe to the OpenVPN client vpn deployment that runs in the kube-system namespace. \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.8.11_1512, released 11 June 2018 \n\n\n\nTable 1. Changes since version 1.8.11_1511\n\n Component Previous Current Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-18_changelog"},{"document_id":"ibmcld_10527-8650-10663","score":30.5203270012,"text":"\nFor example, your apps might use an operator from the OperatorHub that runs a container from an image in the internal registry. You are responsible for your usage of these components, but IBM provides updates for them in the worker node patch updates that you choose to apply.\n\nIn OpenShift Container Platform 4, many components are configured by a corresponding operator for ease of management. The following table discusses these operators and components together, to focus on the main functionality the component provides to the cluster.\n\nSingle tenancy\n: The worker nodes and all worker node components are dedicated only to you, and are not shared with other IBM customers. However, if you use worker node virtual machines, the underlying hardware might be shared with other IBM customers depending on the [level of hardware isolation](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesvm) that you choose.\n\nOperating System\n: Worker nodes run on the Red Hat Enterprise Linux 7 or Red Hat Enterprise Linux 8 operating system.\n\n\n\n* For cluster version 4.10 and later, only RHEL 8 is supported.\n* For cluster version 4.9, you can choose RHEL 7 or RHEL 8, however the default operating system is RHEL 7.\n* For cluster versions 4.8 and earlier, only RHEL 7 is supported.\n\n\n\nCRI-O container runtime\n: Your worker nodes are installed with [CRI-O](https:\/\/cri-o.io\/) as the container runtime interface. For more information, see [Container runtime](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitycontainer-runtime).\n\nProjects\n: Red Hat OpenShift organizes your resources into projects, which are Kubernetes namespaces with annotations, and includes many more components than community Kubernetes clusters to run Red Hat OpenShift features such as the catalog. Select components of projects are described in the following rows. For more information, see [Working with projects](http:\/\/docs.openshift.com\/container-platform\/4.11\/applications\/projects\/working-with-projects.html).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-architecture"},{"document_id":"ibmcld_05528-36924-38197","score":30.2875305497,"text":"\nThe following table shows the changes that are in the master fix pack patch update 1.17.16_1550. Master patch updates are applied automatically.\n\n\n\nChanges since version 1.17.15_1548\n\n Component Previous Current Description \n\n IBM Calico extension 544 556 Updated image to include the ip command. \n IBM Cloud Controller Manager v1.17.15-1 v1.17.16-1 Updated to support the Kubernetes 1.17.16 release. \n IBM Cloud File Storage for Classic plug-in N\/A N\/A Updated to run with a privileged security context. \n Kubernetes v1.17.15 v1.17.16 See the [Kubernetes release notes](https:\/\/github.com\/kubernetes\/kubernetes\/releases\/tag\/v1.17.16). \n Operator Lifecycle Manager 0.14.1-IKS-1 0.14.1-IKS-2 Updated image for [CVE-2020-1971](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2020-1971) and [CVE-2020-28928](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2020-28928). \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.17.15_1549, released 21 December 2020 \n\nThe following table shows the changes that are in the worker node fix pack 1.17.15_1549. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.17.15_1548\n\n Component Previous Current Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-117_changelog"},{"document_id":"ibmcld_10392-166218-167377","score":30.0242740083,"text":"\n: Added [IAM actions and Activity Tracker events](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iamks-ingress) for the Ingress secret, Ingress ALB, and NLB DNS APIs.\n\n\n\n\n\n 9 November 2020 \n\nNew! Reduced and hourly billing is available for OCP licenses\n: Now when you create worker nodes with the latest flavors, OCP license costs are billed at reduced rates as part of the worker node cost. You can check the new rates in the pricing estimate when you create a cluster or worker pool. This billing change means that virtual worker nodes are only billed hourly for OCP license instead of monthly. Existing worker nodes in clusters continue to be billed at the previous rates for monthly OCP licenses. For more information and to migrate existing worker nodes, see [On-demand OCP licenses from Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costslicenses-on-demand) or review the [IBM Cloud blog announcement](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/run-workloads-by-the-hour-with-red-hat-openshift-on-ibm-cloud).\n\nWorker node versions\n: Worker node fix pack update change log documentation is available.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-relnotes"},{"document_id":"ibmcld_05602-31736-32765","score":29.9115254954,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.23.15_1556\n\n Component Previous Current Description \n\n Ubuntu 18.04 packages N\/A N\/A N\/A \n Ubuntu 20.04 packages N\/A N\/A N\/A \n Kubernetes N\/A N\/A N\/A \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.23.15_1556, released 19 December 2022 \n\nThe following table shows the changes that are in the worker node fix pack 1.23.15_1556. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.23.14_1554\n\n Component Previous Current Description \n\n Containerd 1.6.10 1.6.12 See the [1.6.12 change log](https:\/\/github.com\/containerd\/containerd\/releases\/tag\/v1.6.12), the [1.6.11 change log](https:\/\/github.com\/containerd\/containerd\/releases\/tag\/v1.6.11), and the security bulletin for [CVE-2022-23471](https:\/\/www.ibm.com\/support\/pages\/node\/6850799).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog_123"},{"document_id":"ibmcld_05603-45298-46323","score":29.9115254954,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.24.9_1548\n\n Component Previous Current Description \n\n Ubuntu 18.04 packages N\/A N\/A N\/A \n Ubuntu 20.04 packages N\/A N\/A N\/A \n Kubernetes N\/A N\/A N\/A \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.24.9_1548, released 19 December 2022 \n\nThe following table shows the changes that are in the worker node fix pack 1.24.9_1548. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.24.8_1546\n\n Component Previous Current Description \n\n Containerd 1.6.10 1.6.12 See the [1.6.12 change log](https:\/\/github.com\/containerd\/containerd\/releases\/tag\/v1.6.12), the [1.6.11 change log](https:\/\/github.com\/containerd\/containerd\/releases\/tag\/v1.6.11), and the security bulletin for [CVE-2022-23471](https:\/\/www.ibm.com\/support\/pages\/node\/6850799).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog_124"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10394-7-1848","score":13.4800904243,"text":"\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_10395-7-1827","score":13.4015194616,"text":"\nUpdating VPC worker nodes that use OpenShift Data Foundation \n\nVirtual Private Cloud\n\nFor VPC clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-vpc"},{"document_id":"ibmcld_06209-9632-11487","score":12.9682102803,"text":"\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.\n\nIn addition, you can create a Kubernetes config map that specifies the maximum number of worker nodes that can be unavailable at a time, such as during an update. Worker nodes are identified by the worker node labels. You can use IBM-provided labels or custom labels that you added to the worker node.\n\nThe Kubernetes config map rules are used for updating worker nodes only. These rules do not impact worker node reloads which means reloading happens immediately when requested.\n\nWhat if I choose not to define a config map?\n: When the config map is not defined, the default is used. By default, a maximum of 20% of all your worker nodes in each cluster can be unavailable during the update process.\n\n\n\n Prerequisites \n\nBefore you update your classic infrastructure worker nodes, review the prerequisite steps.\n\nUpdates to worker nodes can cause downtime for your apps and services. Your worker node machine is reimaged, and data is deleted if not [stored outside the pod](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan).\n\n\n\n* [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n* [Update the master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster). The worker node version can't be higher than the API server version that runs in your Kubernetes master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_06209-26818-28444","score":12.8562188957,"text":"\n[Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/icons\/icon_hamburger.svg), click Kubernetes.\n3. From the Clusters page, click your cluster.\n4. From the Worker Nodes tab, select the checkbox for each worker node that you want to update. An action bar is displayed over the table header row.\n5. From the action bar, click Update.\n\n\n\n\n\n\n\n\n\n Updating flavors (machine types) \n\nBefore you begin:\n\n\n\n* [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n* Data on the worker node is deleted. Consider storing your data on persistent storage outside of the worker node.\n* Make sure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\n\n\nTo update flavors:\n\n\n\n1. List available worker nodes and note their private IP address.\n\n1. List available worker pools in your cluster.\n {: pre}\nibmcloud ks worker-pool ls --cluster CLUSTER\n\n2. List the worker nodes in the worker pool. Note the ID and Private IP.\n {: pre}\nibmcloud ks worker ls --cluster CLUSTER --worker-pool WORKER-POOL\n\n3. Get the details for a worker node. In the output, note the zone and either the private and public VLAN ID for classic clusters or the subnet ID for VPC clusters.\n {: pre}\nibmcloud ks worker get --cluster CLUSTER --worker WORKER-ID\n\n2. List available flavors in the zone.\n\nibmcloud ks flavors --zone <zone>\n3. Create a worker node with the new machine type.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_06209-22921-24746","score":12.6904234155,"text":"\n: If you replace multiple worker nodes at the same time, they are deleted and replaced concurrently, not one by one. Make sure that you have enough capacity in your cluster to reschedule your workloads before you replace worker nodes.\n\nWhat if a replacement worker node is not created?\n: A replacement worker node is not created if the worker pool does not have [automatic rebalancing enabled](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-auto-rebalance-off).\n\n\n\n Prerequisites \n\nBefore you update your VPC infrastructure worker nodes, review the prerequisite steps.\n\nUpdates to worker nodes can cause downtime for your apps and services. Your worker node machine is removed, and data is deleted if not [stored outside the pod](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan).\n\n\n\n* [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n* [Update the master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster). The worker node version can't be higher than the API server version that runs in your Kubernetes master.\n* Make any changes that are marked with Update after master in the [Kubernetes version preparation guide](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions).\n* If you want to apply a patch update, review the [Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog) version change log.\n* Make sure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\n\n\n\n\n\n\n Updating VPC worker nodes in the CLI \n\nComplete the following steps to update your worker nodes by using the CLI.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_02914-12647-14729","score":12.423477889,"text":"\nFor more information about the methods available for you to use, see [Expression language methods](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-methods).\n\n\n\n\n\n Deleting a context variable \n\nTo delete a context variable, set the variable to null.\n\n\n\nNulling a context variable\n\n Variable Value \n\n order_form null \n\n\n\nAlternatively you can delete the context variable in your application logic. For information about how to remove the variable entirely, see [Deleting a context variable in JSON](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-delete-json).\n\n\n\n\n\n Updating a context variable value \n\nTo update a context variable's value, define a context variable with the same name as the previous context variable, but this time, specify a different value for it.\n\nWhen more than one node sets the value of the same context variable, the value for the context variable can change over the course of a conversation with a user. Which value is applied at any given time depends on which node is being triggered by the user in the course of the conversation. The value specified for the context variable in the last node that is processed overwrites any values that were set for the variable by nodes that were processed previously.\n\nFor information about how to update the value of a context variable when the value is a JSON object or JSON array data type, see [Updating a context variable value in JSON](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-update-json)\n\n\n\n\n\n How context variables are processed \n\nWhere you define the context variable matters. The context variable is not created and set to the value that you specify for it until your assistant processes the part of the dialog node where you defined the context variable. In most cases, you define the context variable as part of the node response. When you do so, the context variable is created and given the specified value when your assistant returns the node response.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-context"},{"document_id":"ibmcld_05581-5428-7191","score":12.2257296586,"text":"\nBefore you begin: [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\n\n\n1. Make sure that your worker node applies the latest patch for your minor version to run your worker node with the latest security settings. The patch version also ensures that the root password on the worker node is renewed.\n\nIf you did not apply updates or reload your worker node within the last 90 days, your root password on the worker node expires and the installation of the storage plug-in might fail.\n\n\n\n1. List the current patch version of your worker nodes.\n\nibmcloud ks worker ls --cluster <cluster_name_or_ID>\n\nExample output\n\nOK\nID Public IP Private IP Machine Type State Status Zone Version\nkube-dal10-crb1a23b456789ac1b20b2nc1e12b345ab-w26 169.xx.xxx.xxx 10.xxx.xx.xxx b3c.4x16.encrypted normal Ready dal10 1.26_1523\n\nIf your worker node does not apply the latest patch version, you see an asterisk () in the Version column of your CLI output.\n2. Review the [version change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog) to find the changes that are in the latest patch version.\n3. Apply the latest patch version by reloading your worker node. Follow the instructions in the [ibmcloud ks worker reload command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_reload) to safely reschedule any running pods on your worker node before you reload your worker node. Note that during the reload, your worker node machine is updated with the latest image and data is deleted if not [stored outside the worker node](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-block_storage"},{"document_id":"ibmcld_06209-36554-38368","score":12.0133886931,"text":"\nYou can use worker pools to spread worker nodes evenly across zones and build a balanced cluster. Balanced clusters are more available and resilient to failures. If a worker node is removed from a zone, you can rebalance the worker pool and automatically provision new worker nodes to that zone. Worker pools are also used to install Kubernetes version updates to all your worker nodes.\n\nIf you created clusters before multizone clusters became available, your worker nodes are still stand-alone and not automatically grouped into worker pools. You must update these clusters to use worker pools. If not updated, you can't change your single zone cluster to a multizone cluster.\n\nReview the following image to see how your cluster setup changes when you move from stand-alone worker nodes to worker pools.\n\nZoom\n\n![Update your cluster from stand-alone worker nodes to worker pools](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/containers\/images\/cs_cluster_migrate.png)\n\nFigure 1. Update your cluster from stand-alone worker nodes to worker pools\n\nBefore you begin:\n\n\n\n* Ensure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms) for the cluster.\n* [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\n\n\nTo update stand-alone worker nodes to worker pools:\n\n\n\n1. List existing stand-alone worker nodes in your cluster and note the ID, the Machine Type, and Private IP.\n\nibmcloud ks worker ls --cluster <cluster_name_or_ID>\n2. Create a worker pool and decide on the flavor and the number of worker nodes that you want to add to the pool.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_05810-30330-32310","score":11.9315912444,"text":"\n* [Isolating clusters on the private network](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-network_policiesisolate_workers).\n\n\n\n\n\n\n\n Allowing traffic from your cluster in other services' allowlists or in on-premises allowlists \n\nIf you want to access services that run inside or outside IBM Cloud or on-premises and that are protected by an allowlist, you can add the IP addresses of your worker nodes in that allowlist to allow outbound network traffic to your cluster. For example, you might want to read data from an IBM Cloud database that is protected by an allowlist, or specify your worker node subnets in an on-premises allowlist to allow network traffic from your cluster.\n\n\n\n1. [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n2. Get the worker node subnets or the worker node IP addresses.\n\n\n\n* Worker node subnets: If you anticipate changing the number of worker nodes in your cluster frequently, such as if you enable the [cluster autoscaler](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-scaling-classic-vpc), you might not want to update your allowlist for each new worker node. Instead, you can add the VLAN subnets that the cluster uses. Keep in mind that the VLAN subnet might be shared by worker nodes in other clusters. Note that the primary public subnets that IBM Cloud Kubernetes Service provisions for your cluster come with 14 available IP addresses, and can be shared by other clusters on the same VLAN. When you have more than 14 worker nodes, another subnet is ordered, so the subnets that you need to allow can change. To reduce the frequency of change, create worker pools with worker node flavors of higher CPU and memory resources so that you don't need to add worker nodes as often.\n\n\n\n1. List the worker nodes in your cluster.\n\nibmcloud ks worker ls --cluster <cluster_name_or_ID>\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-firewall"},{"document_id":"ibmcld_02914-4552-6143","score":11.9300340165,"text":"\n* [Passing context from node to node](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-node-to-node)\n* [Defining a context variable](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-var-define)\n* [Common context variable tasks](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-common-tasks)\n* [Deleting a context variable](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-delete)\n* [Updating a context variable](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-update)\n* [How context variables are processed](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-processing)\n* [Order of operation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-order-of-ops)\n* [Adding context variables to a node with slots](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-var-slots)\n\n\n\n\n\n Passing context from the application \n\nPass information from the application to the dialog by setting a context variable and passing the context variable to the dialog.\n\nFor example, your application can set a $time_of_day context variable, and pass it to the dialog which can use the information to tailor the greeting it displays to the user.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-context"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06320-2897-4555","score":38.4256730662,"text":"\n[NodeSync](https:\/\/docs.datastax.com\/en\/dse\/6.7\/dse-admin\/datastax_enterprise\/config\/aboutNodesync.html) is a continuous repair service that runs automatically in the background to validate that your data is in sync on all replicas and reduces the need for manual repairs. For operational simplicity and performance, Databases for DataStax enables the NodeSync service on all key spaces and tables to handle node repairs. Traditional repairs are unnecessary, as the automation ensures that NodeSync handles the repairs for you.\n\nWhile the automation enables NodeSync, you can also manually create tables with NodeSync enabled so that the service can repair the tables' data when necessary:\n\nCREATE TABLE myTable (...) WITH nodesync = { 'enabled': 'true'};\n\nFor more information, see [enabling the NodeSync service](https:\/\/docs.datastax.com\/en\/dse\/6.7\/dse-admin\/datastax_enterprise\/config\/enablingNodesync.html).\n\nNodetool is unsupported. Manual repairs that are issued against any table that is enabled with the NodeSync service [are ignored](https:\/\/docs.datastax.com\/en\/opscenter\/6.5\/opsc\/online_help\/services\/opscNodeSyncService.htmlNodeSyncServiceversusRepairService). See error:\n\nWARNING: A manual nodetool repair or a repair operation from the OpsCenter node administration menu fails to run if a NodeSync-enabled table is targeted.\n\n\n\n\n\n Recommendations \n\n\n\n Benchmark before production \n\n\n\n* Do not use cqlsh and COPY for benchmarking, as COPY does not mimic typical client behavior. Instead, [nosqlbench](https:\/\/github.com\/nosqlbench\/nosqlbench) can be used for benchmarking.\n\n\n\n\n\n\n\n Data migrations \n\n\n\n* DSBULK is recommended for data migration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-getting-started"},{"document_id":"ibmcld_09919-29346-31291","score":33.1366840843,"text":"\n19 April 2018 \n\nBug fixes and performance improvements\n: Added support for Japanese relations.\n: Improved German keywords.\n: Fixed a bug that caused incorrect entity mention text to be returned.\n: Fixed a bug that could cause poor results for targeted sentiment.\n: Fixed a bug that caused the returned analyzed_text to include characters that were not analyzed.\n\n\n\n\n\n 5 April 2018 \n\nWebpage improvements\n: Improved webpage content fetching. If you use the url parameter to analyze webpages, you'll see better results, especially from webpages that use framesets and cookies.\n\nKorean concept improvement\n: Minor improvements to Korean concepts.\n\n\n\n\n\n\n\n 16 March 2018 \n\nLanguage support improvements\n: Added support for German categories, relations, and semantic roles.\n: A new relation type system is used for German relations. To view details, see the [Relation types (Version 2)](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-relation-types-version-2) page.\n: Improved German keywords and sentiment.\n: Added support for Japanese categories and concepts.\n: Language detection improvements.\n: Improved webpage cleaning.\n: Improved French and German entities models. The models use a new entity type system. Check out the new entity types and subtypes on the [Entity types and subtypes (Version 2)](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-entity-types-version-2) page. When your application is compatible with the new type system, change the version date parameter in your requests to 2018-03-16 to use the new model. The following are the differences between the Version 1 type system and the Version 2 type system.\n\n\n\n* New entity types:\n\n\n\n* Date\n* Duration\n* Measure\n* Money\n* Number*\n* Percent*\n* PhoneNumber*\n* Ordinal\n* Time\n* URL*\n\n\n\n* Removed entity types:\n\n\n\n* Anatomy\n* Award\n* Broadcaster\n* Company\n* Crime\n* Drug\n* HealthCondition","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-release-notes"},{"document_id":"ibmcld_09919-22213-24727","score":31.6219987729,"text":"\nSentiment improved for Spanish\n: Improved Spanish sentiment.\n\nBug fix for special characters\n: Fixed a bug that may have affected targeted sentiment results if the target contained special characters.\n\nService instance changes\n: The following changes are enabled for service instances in Washington DC, Tokyo, London, and Sydney:\n\n\n\n* Sentiment option for entities requests that use custom models is enabled for all sentiment-supported languages except Arabic and Russian.\n\n\n\n\n\n\n\n 24 May 2019 \n\nKeywords improved for German\n: Improved German keywords.\n\nSentiment updates for English to locations\n: English sentiment updates released to service instances in all IBM Cloud locations other than Dallas.\n\n\n\n\n\n 3 May 2019 \n\nSentiment detection for German improved\n: Improved German document-level sentiment detection.\n\n\n\n\n\n\n\n 25 April 2019 \n\nEntity mentions for rule-based custom models\n: Enabled entity mentions for rule-based [custom models](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing). To view mentions in your results, set the mentions entities option to true.\n\nExplanations for English categories results\n: Released explanations for English categories results. To see relevant text from the source that contributed to each result, set the explanation categories option to true.\n\n\n\n\n\n 19 March 2019 \n\nCustom categories models created with Knowledge Studio\n: Introduced experimental support for custom categories models created with Knowledge Studio.\n\nKeywords and concepts improved for Spanish\n: Improved Spanish keywords and concepts.\n\n\n\n\n\n 10 January 2019 \n\nRequests with no version date parameter return error\n: List models and Delete model requests that don't include a version date parameter now return 400 errors instead of successful responses.\n\nEntites performance improved\n: Improved entities performance for languages other than English.\n\n\n\n\n\n December 2018 \n\n\n\n 14 December 2018 \n\nSupport improvements\n: You can now create Natural Language Understanding service instances in the IBM Cloud London location.\n: Added support for Portuguese relations.\n: Added support for Italian relations.\n: Added a limit parameter for categories requests that controls the number of categories returned up to a maximum of 10.\n: Improved accuracy for Japanese and German sentiment.\n\n\n\n\n\n 6 December 2018 \n\nImproved accuracy for Italian\n: Improved accuracy for Italian categories, keywords, entities, and categories.\n\n\n\n\n\n\n\n November 2018 \n\n\n\n 27 November 2018","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-release-notes"},{"document_id":"ibmcld_16489-0-1921","score":31.1556133122,"text":"\n\n\n\n\n\n\n  Enabling cross-sentence relations (Experimental) \n\nEnglish entities and relations workspaces that you create can support annotating relations between pairs of entity mentions that exist within spans of six sentences. In workspaces where the cross-sentence relations feature is not enabled, the ground truth editor and runtime models do not support annotating relations that cross sentence boundaries.\n\nCross-sentence relations is an experimental feature that might be discontinued without notice. It is not recommended to use this feature in a production environment.\n\nEnabling cross-sentence relations might decrease the performance of the ground truth editor and the performance of any models that you deploy from the workspace at runtime. The cross-sentence relations setting cannot be changed for a workspace after it is created.\n\nFor example, if you plan to annotate a relation for an entity mention in the seventh sentence below, you are limited to selecting other entity mentions only in the seventh sentence unless you enable cross-sentence relations. With the feature enabled, you can annotate a related entity mention within a span of six sentences (across up to five sentence boundaries), so the second entity mention in the relation could be annotated anywhere from the second sentence to the twelfth sentence.\n\nSentence 1.\n Sentence 2.\nSentence 3.\nSentence 4.\nSentence 5.\nSentence 6.\n-----> Sentence 7.\nSentence 8.\nSentence 9.\nSentence 10.\nSentence 11.\n Sentence 12.\nSentence 13.\n\n\n\n  Procedure \n\n\n\n1.  Launch the Knowledge Studio application.\n2.  If you have existing workspaces, click Create Workspace.\n3.  Click Create entities and relations workspace.\n4.  Click Advanced options.\n5.  Click the Enable cross sentence relations box.\n6.  Click Create.\n\n\n\nIn the new workspace, you will be able to annotate relations between pairs of entity mentions that exist within spans of six sentences.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-enabling-cross-sentence-relations"},{"document_id":"ibmcld_16456-6603-8681","score":30.1158409383,"text":"\nIn this mode, the human annotator connects mentions by associating a relation type, as defined in the type system. For example, the mention John Smith might be connected to the mention IBM by the relation type employedBy. The annotation of relation types is optional and can occur before or after you annotate mentions as coreferences.\n* Coreference mode\n\nIn this mode, the human annotator identifies mentions that mean the same thing, thus helping to ensure consistency in the annotations when words are not identical. For example, the mention of IBM in the first sentence, the mention of International Business Machines, and the mention of IBM in a later sentence refer to the same thing and would all be labeled by the same entity type, such as ORGANIZATION. The annotation of mentions as coreferences is optional and can occur before or after you annotate relation types.\n\n\n\n\n\n Tips for using the editor \n\n\n\n* Save your work as you go.\n* If you make a mistake, you can press Ctrl+Z to undo the previous action. To redo the action after undoing it, press Ctrl+Y. You can undo the previous 10 actions that you performed while editing the current document. The actions are lost as soon as you close the document. The actions must be undone in reverse order, and you must switch to the mode that you were in when you performed the action to undo it. You cannot undo and redo concordance tool actions.\n\n\n\n\n\n\n\n\n\n Annotating entity mentions \n\nTo annotate entity mentions, a human annotator selects a string of text in a document, and then applies a label that most appropriately describes what the string of text represents. The labels that can be applied are entity types defined in the workspace's type system.\n\n\n\n About this task \n\nBefore starting to annotate entity mentions in a document, it's a good practice to read the entire document. Doing so can help keep the entire context in mind while annotating, and can help provide insights into how entity mentions might relate to each other and which mentions might need to be coreferenced in future passes through the document.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-user-guide"},{"document_id":"ibmcld_16530-6603-8681","score":30.1158409383,"text":"\nIn this mode, the human annotator connects mentions by associating a relation type, as defined in the type system. For example, the mention John Smith might be connected to the mention IBM by the relation type employedBy. The annotation of relation types is optional and can occur before or after you annotate mentions as coreferences.\n* Coreference mode\n\nIn this mode, the human annotator identifies mentions that mean the same thing, thus helping to ensure consistency in the annotations when words are not identical. For example, the mention of IBM in the first sentence, the mention of International Business Machines, and the mention of IBM in a later sentence refer to the same thing and would all be labeled by the same entity type, such as ORGANIZATION. The annotation of mentions as coreferences is optional and can occur before or after you annotate relation types.\n\n\n\n\n\n Tips for using the editor \n\n\n\n* Save your work as you go.\n* If you make a mistake, you can press Ctrl+Z to undo the previous action. To redo the action after undoing it, press Ctrl+Y. You can undo the previous 10 actions that you performed while editing the current document. The actions are lost as soon as you close the document. The actions must be undone in reverse order, and you must switch to the mode that you were in when you performed the action to undo it. You cannot undo and redo concordance tool actions.\n\n\n\n\n\n\n\n\n\n Annotating entity mentions \n\nTo annotate entity mentions, a human annotator selects a string of text in a document, and then applies a label that most appropriately describes what the string of text represents. The labels that can be applied are entity types defined in the workspace's type system.\n\n\n\n About this task \n\nBefore starting to annotate entity mentions in a document, it's a good practice to read the entire document. Doing so can help keep the entire context in mind while annotating, and can help provide insights into how entity mentions might relate to each other and which mentions might need to be coreferenced in future passes through the document.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-user-guide"},{"document_id":"ibmcld_06320-1330-3318","score":30.0980695014,"text":"\nAfter you click Create, the system displays a message to say that the instance is being provisioned, which returns you to the Resource list. From the Resource list, you see that the status for your instance is, Provision in progress.\n8. When the status changes to Active, select the instance.\n\n\n\n\n\n\n\n Step 3: Set your admin password \n\n\n\n* [Set the Admin Password](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-admin-password) for your deployment.\n\n\n\nReview the [Getting to production](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-best-practices) documentation for general guidance on setting up a basic IBM Cloud\u00ae Databases for DataStax deployment.\n\n\n\n\n\n Step 4: Connect with DataStax drivers \n\nDrivers are a key component to connecting external applications to your Databases for DataStax deployment. Review the information on [Connecting an external application](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-external-app) for details on compatible drivers. Further details on specific drivers, including upgrade guides, can be found at [Developing applications with Apache Cassandra and DataStax Enterprise](https:\/\/docs.datastax.com\/en\/devapp\/doc\/devapp\/aboutDrivers.html).\n\nOnly DataStax drivers that are explicitly listed in the [Connecting an external application](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-external-app) table function correctly for connecting to Databases for DataStax.\n\n\n\n\n\n Step 5: Node repairs with NodeSync \n\n[NodeSync](https:\/\/docs.datastax.com\/en\/dse\/6.7\/dse-admin\/datastax_enterprise\/config\/aboutNodesync.html) is a continuous repair service that runs automatically in the background to validate that your data is in sync on all replicas and reduces the need for manual repairs. For operational simplicity and performance, Databases for DataStax enables the NodeSync service on all key spaces and tables to handle node repairs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-getting-started"},{"document_id":"ibmcld_16425-3435-5660","score":29.2116982561,"text":"\nA measurement of ground truth that shows the number of words that were annotated with a given entity type or relation type out of the total number of words, whether annotated or unannotated. This statistic is not available for coreferenced mentions. This value can help you to see how prevalent mentions of this type are compared to all of the other words in your domain documents.\n* Percentage of documents that contain the type\n\nA measurement of ground truth that shows how many documents contain a given entity type or relation type. This statistic is not available for coreferenced mentions. This value can help you to assess whether the documents in the set represent the domain sufficiently. If the percentage is low for key entity types, then you might want to add more documents with mentions of under-represented types.\n\n\n\n\n\n\n\n Procedure \n\nTo view performance statistics for how well the model was trained:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Performance.\n3. For the mentions, relations, or coreferences, select the Detailed Statistics link.\n4. In the Summary view, specify whether you want to evaluate test data or training data, and then specify the type of annotations you want to see statistics for: entity types, relation types, or coreferenced mentions. As you scroll through the data, items that have low scores are flagged and highlighted to indicate that they require investigation and improvement. The triangle warning icon indicates that the F1 value is less than the fixed value, 0.5.\n\nFor example, the F1 score for some entity types might be high because the document was annotated through pre-annotation as well as by a human annotator. But the F1 score for other entity types might be low because differences in phrasing, and differences in how human annotators interpret the text or annotation guidelines, make it more difficult for the machine learning model to recognize the pattern and apply the correct annotation.\n5. In the Confusion Matrix view for test data, specify the type of annotations that you want to see statistics for: entity types or relation types. For each entity type or relation type:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-ml"},{"document_id":"ibmcld_16490-3348-5630","score":29.0841020265,"text":"\n* Percentage of corpus density (by the number of words)\n\nA measurement of ground truth that shows the number of words that were annotated with a given entity type or relation type out of the total number of words, whether annotated or unannotated. This statistic is not available for coreferenced mentions. This value can help you to see how prevalent mentions of this type are compared to all of the other words in your domain documents.\n* Percentage of documents that contain the type\n\nA measurement of ground truth that shows how many documents contain a given entity type or relation type. This statistic is not available for coreferenced mentions. This value can help you to assess whether the documents in the set represent the domain sufficiently. If the percentage is low for key entity types, then you might want to add more documents with mentions of under-represented types.\n\n\n\n\n\n\n\n Procedure \n\nTo view performance statistics for how well the model was trained:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Performance.\n3. For the mentions, relations, or coreferences, select the Detailed Statistics link.\n4. In the Summary view, specify whether you want to evaluate test data or training data, and then specify the type of annotations you want to see statistics for: entity types, relation types, or coreferenced mentions. As you scroll through the data, items that have low scores are flagged and highlighted to indicate that they require investigation and improvement. The triangle warning icon indicates that the F1 value is less than the fixed value, 0.5.\n\nFor example, the F1 score for some entity types might be high because the document was annotated through pre-annotation as well as by a human annotator. But the F1 score for other entity types might be low because differences in phrasing, and differences in how human annotators interpret the text or annotation guidelines, make it more difficult for the machine learning model to recognize the pattern and apply the correct annotation.\n5. In the Confusion Matrix view for test data, specify the type of annotations that you want to see statistics for: entity types or relation types. For each entity type or relation type:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-evaluate-ml"},{"document_id":"ibmcld_16456-3231-5337","score":28.7112529687,"text":"\n* The source document contains a split verb that you want to annotate. How do you annotate noncontiguous text as a single entity type? You can annotate each entity mention, and identify them as being related to each other by using a relation mention.\n\n[EVENT_ANSWER] [EVENT_ANSWER]\n\nAll of the phones were ringing, but he knew he should [pick] the red phone [up] first.\n\n^----splitType-----^\n\n\n\n* Avoid overlapping mentions, which are two different entity type labels that are applied to a single phrase in a document. For example, given the sentence, She donated her father's journals to the JFK Library., you would overlap mentions if you annotate JFK=PERSON and JFK Library=LOCATION for the single phrase JFK Library. The use of the term is more about the library than the person in this sentence, so only the latter annotation should be applied.\n\nDecoding such structures requires multiple parallel invocations of a machine learning model because mention detection only looks for a single label or no label on each word token.\n* Determine how the team will handle lists and plurals in running text. For example, the KLUE type system has PERSON and PEOPLE entity types that distinguish the singular from the plural. You can choose to annotate the list Barack, Michelle, Malia, and Sasha Obama, in one of the following ways:\n\n\n\n* Annotate each item in the list as a singular entity mention (Barack, Michelle, Malia, and Sasha Obama are each a PERSON mention)\n* Annotate the whole phrase as one plural entity mention (Barack, Michelle, Malia, and Sasha Obama is a single PEOPLE mention).\n\n\n\nNo one approach is necessarily better than the other. Just be sure that your team chooses one of them and applies it consistently to any lists that occur in the documents.\n* A coreference is used when mentions refer to the same real-world entity. Relations are used between distinct entities. So, no two mentions should be connected by both coreference and a relation.\n\n\n\n\n\n\n\n Annotation with the ground truth editor \n\nWhen a human annotator annotates a document, the document is opened in the ground truth editor.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-user-guide"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10154-9468-11364","score":24.0491654829,"text":"\nIn this sense, the installation is similar to IPI for you because you don't have to manage all the infrastructure and network settings. IBM also provides patch updates that you can choose to apply to your worker nodes, from the IBM Cloud interface (not the Red Hat OpenShift web console). SSH is disabled for added security. \n OCP versions and patch updates You are responsible for updating the underlying infrastructure for the master and worker nodes. You can use the Red Hat OpenShift web console to update OCP versions. IBM automatically applies updates to the master, and provides version updates and security patch updates for the worker nodes. You choose when to apply these updates to your worker nodes, from the IBM Cloud interface (not the Red Hat OpenShift web console). Supported versions might vary from standard OpenShift Container Platform. \n Autoscaling compute machines You can set up a ClusterAutoscaler resource. You can set up the [cluster autoscaler plug-in](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-scaling-classic-vpc). \n Worker node operating system CoreOS or RHEL For a list of supported operating systems by cluster version, see [Red Hat OpenShift on IBM Cloud version information](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions). \n Support Provided per the terms of your Red Hat subscription or cloud provider. You can use the oc adm must-gather tool to help gather information. Provided by [IBM Cloud Support](https:\/\/www.ibm.com\/cloud\/support). You can use the oc adm must-gather tool, or the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug-tool) to help gather information. \n Red Hat OpenShift web console You set up and can configure or disable the Red Hat OpenShift web console. The Red Hat OpenShift web console is set up for you. You can't configure or disable the web console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_10179-2409-3717","score":23.9974550786,"text":"\nUnsupported: Beta versions of numerous Kubernetes APIs For more information, review [Preparing to upgrade to Red Hat OpenShift Container Platform 4.9](https:\/\/access.redhat.com\/articles\/6329921), [Kubernetes API and Feature Removals In 1.22: Here\u2019s What You Need To Know](https:\/\/kubernetes.io\/blog\/2021\/07\/14\/upcoming-changes-in-kubernetes-1-22\/) and [Deprecated API Migration Guide](https:\/\/kubernetes.io\/docs\/reference\/using-api\/deprecation-guide\/v1-22). See [Deprecation Warnings](https:\/\/kubernetes.io\/blog\/2020\/09\/03\/warnings\/deprecation-warnings) for methods to identify use of deprecated APIs. Warnings for components provided by the Red Hat OpenShift on IBM Cloud cluster install can be ignored since they will be handled during the update. Note that Red Hat OpenShift on IBM Cloud cluster administrators do not need to provide a manual acknowledgment before the cluster can be upgraded, as mentioned in this Red Hat [article](https:\/\/access.redhat.com\/articles\/6329921). \n\n\n\n\n\n\n\n\n\n Migrating your worker nodes to RHEL 8 \n\nAfter updating your worker nodes to version 4.9, migrate them to use RHEL 8 by provisioning a new worker pool, then deleting the previous worker pool. See [Migrating to a new Red Hat Enterprise Linux version](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-rhel_migrate).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_versions_49"},{"document_id":"ibmcld_06160-11142-12906","score":22.75202219,"text":"\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-11475-13230","score":22.75202219,"text":"\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_07033-3226-5247","score":22.6372463087,"text":"\nIf you are familiar with the built-in Entities enrichment, you know that the enrichment can recognize terms that match generalized categories, such as Person and Location. With the entity extractor, you control what constitutes terms or phrases that are meaningful.\n\nThe following image shows the terms that an enrichment that recognizes family members entity type mentions might extract from text. The example illustrates how family member mentions and other entity mentions (that are recognized by the built-in Entities enrichment) both might be predicted.\n\nZoom\n\n![Shows an excerpt from Pride and Prejudice with family member (daughter, sisters, mother) mentions and entity (Mr. Bennett, Mr. Bingley, Netherfield, Longbourn) mentions labeled.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/pp3-both-annotations.png)\n\nFigure 1. Labeled entity examples\n\nThis excerpt comes from Chapter 3 of Pride and Prejudice by Jane Austen.\n\n\n\n\n\n Before you begin \n\nFind or create a collection with documents that have various examples of the entity types that you want Discovery to learn about. To teach the extractor, you must label examples of entity types. You can only label examples if your collection contains valid examples. Try to find documents that have many and varying terms that function as examples of every entity type that you want to define.\n\n\n\n\n\n Adding an entity extractor \n\nTo add an entity extractor, complete the following steps:\n\n\n\n1. Open the project where you want to create the entity extractor.\n\nThe project must have at least one collection with documents that are representative of your domain data.\n2. From the Improvement tools panel of the Improve and customize page, expand Teach domain concepts, and then click Extract entities.\n3. Click New.\n\nIf you want to create an entity extractor that is based on the entity type system from a IBM Watson\u00ae Knowledge Studio corpus, click the arrow, and then choose Import a Knowledge Studio corpus.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-entity-extractor"},{"document_id":"ibmcld_03040-43198-45083","score":22.6149332234,"text":"\nRich response types support\n: Rich response types are now supported in a dialog node with slots. You can display a list of options for a user to choose from as the prompt for a slot, for example. For more information, see [Gathering information with slots](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots).\n\nImproved Entities, Dialog, and Intents page responsiveness\n: The Entities, Dialog, and Intents pages were updated to use a new JavaScript library that increases the page responsiveness. As a result, the look of some graphical user interface elements, such as buttons, changed slightly, but the function did not.\n\nCreating contextual entities is easier\n: The process you use to annotate entity mentions from intent user examples was improved. You can now put the intent page into annotation mode to more easily select and label mentions. For more information, see [Adding contextual entities](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-entitiesentities-create-annotation-based).\n\nWebhook callouts are available\n: Add webhooks to dialog nodes to make programmatic calls to an external application as part of the conversational flow. This capability is being introduced as a beta feature. For more details, see [Making a programmatic call from dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-webhooks).\n\nTesting improvement\n: You can now see the top three intents that were recognized in a test user input from the Try it out pane. For more details, see [Testing your dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tasksdialog-tasks-test).\n\n\n\n\n\n 3 September 2019 \n\nIBM Watson\u00ae Assistant for IBM Cloud Pak\u00ae for Data version 1.3 is available\n: Watson Assistant for IBM Cloud Pak\u00ae for Data version 1.3 is compatible with IBM Cloud Pak\u00ae for Data versions 2.1.0.1 and 2.1.0.2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-release-notes"},{"document_id":"ibmcld_05713-581893-583377","score":22.5794570306,"text":"\n* [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-bm_machine_idbm_machine_id)\n\n[After deleting all worker nodes, why don't my pods start on new worker nodes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-zero_nodes_calico_failurezero_nodes_calico_failure)\n\n[After a worker node updates or reloads, why do duplicate nodes and pods appear?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_15243-47502-49297","score":22.1520551662,"text":"\nIf you select a catalog image that belongs to a different account, review [Using cross-account image references in a private catalog in Terraform](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-planning-custom-images&interface=uiprivate-catalog-image-reference-vpc-terraform) for more considerations and limitations. To create a private catalog, see the tutorial [Onboarding a virtual server image with Terraform](https:\/\/cloud.ibm.com\/docs\/account?topic=account-catalog-vsi-tutorial&interface=ui).\n\n\n\n\n\n Gathering information to create an instance by using Terraform \n\nReady to create an instance? Before you can run the ibm_is_instance command, you need to know the details about the instance, such as what profile or image that you want to use.\n\nGather the following information by using DataSource command.\n\n\n\n1. Gather instance profile details. Run the following command for the profile that you select. See [x86 instance profiles](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-profiles&interface=uiprofiles) for a list of available profiles. For more information, see the Terraform documentation on [ibm_is_instance_profiles](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/data-sources\/is_instance_profiles). Use an instance profile by referring to the instance profile data source. For more information, see the Terraform documentation on [ibm_is_instance_profile](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/data-sources\/is_instance_profile).\n\ndata \"ibm_is_instance_profile\" \"example_profile\" {\nname = \"bx2-2x8\"\n}\n2. List the available images for creating your instance. The command depends on what image that you want to use. You can use a stock image, a custom image from your account, or an image that was shared with your account from a private catalog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-virtual-servers"},{"document_id":"ibmcld_15244-47580-49375","score":22.1520551662,"text":"\nIf you select a catalog image that belongs to a different account, review [Using cross-account image references in a private catalog in Terraform](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-planning-custom-images&interface=uiprivate-catalog-image-reference-vpc-terraform) for more considerations and limitations. To create a private catalog, see the tutorial [Onboarding a virtual server image with Terraform](https:\/\/cloud.ibm.com\/docs\/account?topic=account-catalog-vsi-tutorial&interface=ui).\n\n\n\n\n\n Gathering information to create an instance by using Terraform \n\nReady to create an instance? Before you can run the ibm_is_instance command, you need to know the details about the instance, such as what profile or image that you want to use.\n\nGather the following information by using DataSource command.\n\n\n\n1. Gather instance profile details. Run the following command for the profile that you select. See [x86 instance profiles](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-profiles&interface=uiprofiles) for a list of available profiles. For more information, see the Terraform documentation on [ibm_is_instance_profiles](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/data-sources\/is_instance_profiles). Use an instance profile by referring to the instance profile data source. For more information, see the Terraform documentation on [ibm_is_instance_profile](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/data-sources\/is_instance_profile).\n\ndata \"ibm_is_instance_profile\" \"example_profile\" {\nname = \"bx2-2x8\"\n}\n2. List the available images for creating your instance. The command depends on what image that you want to use. You can use a stock image, a custom image from your account, or an image that was shared with your account from a private catalog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-virtual-servers&interface=api"},{"document_id":"ibmcld_15245-47530-49325","score":22.1520551662,"text":"\nIf you select a catalog image that belongs to a different account, review [Using cross-account image references in a private catalog in Terraform](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-planning-custom-images&interface=uiprivate-catalog-image-reference-vpc-terraform) for more considerations and limitations. To create a private catalog, see the tutorial [Onboarding a virtual server image with Terraform](https:\/\/cloud.ibm.com\/docs\/account?topic=account-catalog-vsi-tutorial&interface=ui).\n\n\n\n\n\n Gathering information to create an instance by using Terraform \n\nReady to create an instance? Before you can run the ibm_is_instance command, you need to know the details about the instance, such as what profile or image that you want to use.\n\nGather the following information by using DataSource command.\n\n\n\n1. Gather instance profile details. Run the following command for the profile that you select. See [x86 instance profiles](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-profiles&interface=uiprofiles) for a list of available profiles. For more information, see the Terraform documentation on [ibm_is_instance_profiles](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/data-sources\/is_instance_profiles). Use an instance profile by referring to the instance profile data source. For more information, see the Terraform documentation on [ibm_is_instance_profile](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/data-sources\/is_instance_profile).\n\ndata \"ibm_is_instance_profile\" \"example_profile\" {\nname = \"bx2-2x8\"\n}\n2. List the available images for creating your instance. The command depends on what image that you want to use. You can use a stock image, a custom image from your account, or an image that was shared with your account from a private catalog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-virtual-servers&interface=cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10214-4313-6479","score":35.2909028536,"text":"\nTo get started, try out the [Red Hat OpenShift on IBM Cloud tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\n\n\n\n\n Does the service come with a managed Red Hat OpenShift master and worker nodes? \n\nEvery cluster in Red Hat OpenShift on IBM Cloud is controlled by a dedicated Red Hat OpenShift master that is managed by IBM in an IBM-owned IBM Cloud infrastructure account. The Red Hat OpenShift master, including all the master components, compute, networking, and storage resources, is continuously monitored by IBM Site Reliability Engineers (SREs). The SREs apply the latest security standards, detect and remediate malicious activities, and work to ensure reliability and availability of Red Hat OpenShift on IBM Cloud.\n\nPeriodically, Red Hat OpenShift releases [major, minor, or patch updates](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types). These updates can affect the Red Hat OpenShift API server version or other components in your Red Hat OpenShift master. IBM automatically updates the patch version, but you must update the master major and minor versions. For more information, see [Updating the master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster).\n\nWorker nodes in standard clusters are provisioned in to your IBM Cloud infrastructure account. The worker nodes are dedicated to your account and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and Red Hat OpenShift on IBM Cloud components apply the latest security updates and patches. Security updates and patches are made available by IBM Site Reliability Engineers (SREs) who continuously monitor the Linux image that is installed on your worker nodes to detect vulnerabilities and security compliance issues. For more information, see [Updating worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node).\n\n\n\n\n\n Are the master and worker nodes highly available? \n\nThe Red Hat OpenShift on IBM Cloud architecture and infrastructure is designed to ensure reliability, low processing latency, and a maximum uptime of the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_10068-48639-50303","score":35.0200988718,"text":"\nRed Hat OpenShift on IBM Cloud toolkit 4.5.0+20201210 4.5.0+20210112 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.5.0+20210112). \n\n\n\n\n\n\n\n Change log for worker node fix pack 4.5.24_1526_openshift, released 18 January 2021 \n\nThe following table shows the changes that are in the worker node fix pack 4.5.24_1526_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.5.22_1524_openshift\n\n Component Previous Current Description \n\n Red Hat OpenShift 4.5.22 4.5.24 See the [Red Hat OpenShift release notes](https:\/\/docs.openshift.com\/container-platform\/4.5\/release_notes\/ocp-4-5-release-notes.htmlocp-4-5-24). \n RHEL 7 Packages N\/A N\/A Updated worker node image with package updates. \n\n\n\n\n\n\n\n Change log for master fix pack 4.5.24_1525_openshift, released 6 January 2021 \n\nThe following table shows the changes that are in the master fix pack patch update 4.5.24_1525_openshift. Master patch updates are applied automatically.\n\n\n\nChanges since version 4.5.18_1523_openshift\n\n Component Previous Current Description \n\n IBM Calico extension 538 556 Updated image to include the ip command. \n IBM Cloud Block Storage driver and plug-in 1.17.2 v2.0.0 Updated to use the universal base image (UBI), to use Go version 1.15.5, to run with a least privileged security context, and to improve logging. Updated image to implement additional IBM security controls. \n IBM Cloud Controller Manager v1.18.13-1 v1.18.14-1 Updated to support the Kubernetes 1.18.14 release.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-changelog_archive"},{"document_id":"ibmcld_14684-4336-5406","score":34.8425741013,"text":"\nAPI and API-INT load balancer 22623 ROUND-ROBIN default_tcp_monitor Bootstrap and primary nodes TCP IBM Cloud 10.x \n\n\n\n\n\n\n\n Red Hat OpenShift specifications \n\nThe following tables show the specifications of the management node, control plane node, and worker node.\n\nManagement node\n\nControl plane node\n\nWorker node\n\n\n\nTable 5. Management node specifications\n\n Host description vCPU Memory (GB) Disk (GB) OS \n\n Management0 2 8 50 Red Hat Enterprise Linux\u00ae 8.0 \n\n\n\n\n\n\n\n Related links \n\n\n\n* [VMware vCenter Server and Red Hat OpenShift architecture overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* [System context for vCenter Server and Red Hat OpenShift architecture](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-syscontext)\n* [Red Hat OpenShift architecture](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-redhat-arch)\n* [IBM Cloud for VMware Solutions SDDC architecture](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-arch)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-sddc-infra"},{"document_id":"ibmcld_07578-396975-399135","score":34.6455341617,"text":"\nWith Kubernetes, you can combine various resources such as secrets, deployments, and services to securely create and manage highly available, containerized apps.\n\nRed Hat OpenShift\n: Red Hat OpenShift on IBM Cloud is a Kubernetes-based platform that is designed especially to accelerate your containerized app delivery processes that run on a Red Hat Enterprise Linux 7 operating system. You can orchestrate and scale your existing Red Hat OpenShift workloads across on-prem and off-prem clouds for a portable, hybrid solution that works the same in multicloud scenarios. To get started, try out the [Red Hat OpenShift on IBM Cloud tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n* Does the service come with a managed Red Hat OpenShift master and worker nodes?\n\nEvery cluster in Red Hat OpenShift on IBM Cloud is controlled by a dedicated Red Hat OpenShift master that is managed by IBM in an IBM-owned IBM Cloud infrastructure account. The Red Hat OpenShift master, including all the master components, compute, networking, and storage resources, is continuously monitored by IBM Site Reliability Engineers (SREs). The SREs apply the latest security standards, detect and remediate malicious activities, and work to ensure reliability and availability of Red Hat OpenShift on IBM Cloud.\n\nPeriodically, Red Hat OpenShift releases [major, minor, or patch updates](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types). These updates can affect the Red Hat OpenShift API server version or other components in your Red Hat OpenShift master. IBM automatically updates the patch version, but you must update the master major and minor versions. For more information, see [Updating the master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster).\n\nWorker nodes in standard clusters are provisioned in to your IBM Cloud infrastructure account. The worker nodes are dedicated to your account and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and Red Hat OpenShift on IBM Cloud components apply the latest security updates and patches.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-396949-399109","score":34.6455341617,"text":"\nWith Kubernetes, you can combine various resources such as secrets, deployments, and services to securely create and manage highly available, containerized apps.\n\nRed Hat OpenShift\n: Red Hat OpenShift on IBM Cloud is a Kubernetes-based platform that is designed especially to accelerate your containerized app delivery processes that run on a Red Hat Enterprise Linux 7 operating system. You can orchestrate and scale your existing Red Hat OpenShift workloads across on-prem and off-prem clouds for a portable, hybrid solution that works the same in multicloud scenarios. To get started, try out the [Red Hat OpenShift on IBM Cloud tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n* Does the service come with a managed Red Hat OpenShift master and worker nodes?\n\nEvery cluster in Red Hat OpenShift on IBM Cloud is controlled by a dedicated Red Hat OpenShift master that is managed by IBM in an IBM-owned IBM Cloud infrastructure account. The Red Hat OpenShift master, including all the master components, compute, networking, and storage resources, is continuously monitored by IBM Site Reliability Engineers (SREs). The SREs apply the latest security standards, detect and remediate malicious activities, and work to ensure reliability and availability of Red Hat OpenShift on IBM Cloud.\n\nPeriodically, Red Hat OpenShift releases [major, minor, or patch updates](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types). These updates can affect the Red Hat OpenShift API server version or other components in your Red Hat OpenShift master. IBM automatically updates the patch version, but you must update the master major and minor versions. For more information, see [Updating the master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster).\n\nWorker nodes in standard clusters are provisioned in to your IBM Cloud infrastructure account. The worker nodes are dedicated to your account and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and Red Hat OpenShift on IBM Cloud components apply the latest security updates and patches.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_10397-7-2020","score":34.5782650892,"text":"\nVersion 3.11 change log \n\nView information of version changes for major, minor, and patch updates that are available for your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters that run version 3.11. Changes include updates to Red Hat OpenShift, Kubernetes, and IBM Cloud Provider components.\n\nRed Hat OpenShift version 3.11 is unsupported as of 6 June 2022.\n\n\n\n Overview \n\nUnless otherwise noted in the change logs, the IBM Cloud provider version enables Red Hat OpenShift APIs and features that are at beta. Red Hat OpenShift alpha features, which are subject to change, are disabled.\n\nCheck the [Security Bulletins on IBM Cloud Status](https:\/\/cloud.ibm.com\/status?selected=security) for security vulnerabilities that affect Red Hat OpenShift on IBM Cloud. You can filter the results to view only Kubernetes Service security bulletins that are relevant to Red Hat OpenShift on IBM Cloud. Change log entries that address other security vulnerabilities but don't also refer to an IBM security bulletin are for vulnerabilities that are not known to affect Red Hat OpenShift on IBM Cloud in normal usage. If you run privileged containers, run commands on the workers, or execute untrusted code, then you might be at risk.\n\nMaster patch updates are applied automatically. Worker node patch updates can be applied by reloading or updating the worker nodes. For more information about major, minor, and patch versions and preparation actions between minor versions, see [Red Hat OpenShift versions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n\n\n\n\n\n Version 3.11 change log \n\nReview the change logs for Red Hat OpenShift on IBM Cloud version 3.11 patch updates.\n\n\n\n Change log for worker node fix pack 3.11.705_1634_openshift, released 7 June 2022 \n\nThe following table shows the changes that are in the worker node fix pack 3.11.705_1634_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_311"},{"document_id":"ibmcld_10068-139713-141302","score":34.5578141941,"text":"\nRed Hat OpenShift on IBM Cloud toolkit 4.3.0+20201110 4.3.0+20210111 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.3.0+20210111). \n\n\n\n\n\n\n\n Change log for worker node fix pack 4.3.40_1551_openshift, released 18 January 2021 \n\nThe following table shows the changes that are in the worker node fix pack 4.3.40_1551_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.3.40_1549_openshift\n\n Component Previous Current Description \n\n RHEL 7 Packages N\/A N\/A Updated worker node image with package updates. \n\n\n\n\n\n\n\n Change log for master fix pack 4.3.40_1550_openshift, released 6 January 2021 \n\nThe following table shows the changes that are in the master fix pack patch update 4.3.40_1550_openshift. Master patch updates are applied automatically.\n\n\n\nChanges since version 4.3.40_1548_openshift\n\n Component Previous Current Description \n\n IBM Calico extension 538 556 Updated image to include the ip command. \n IBM Cloud Block Storage driver and plug-in 1.17.2 v2.0.0 Updated to use the universal base image (UBI), to use Go version 1.15.5, to run with a least privileged security context, and to improve logging. Updated image to implement additional IBM security controls. \n IBM Cloud Controller Manager v1.17.15-1 v1.17.16-1 Updated to support the Kubernetes 1.17.16 release. \n IBM Cloud File Storage for Classic plug-in N\/A N\/A Updated to run with a privileged security context.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-changelog_archive"},{"document_id":"ibmcld_10401-7-1942","score":34.5072445966,"text":"\nVersion 4.13 change log \n\nView information of version changes for major, minor, and patch updates that are available for your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters that run version 4.13. Changes include updates to Red Hat OpenShift, Kubernetes, and IBM Cloud Provider components.\n\n\n\n Overview \n\nUnless otherwise noted in the change logs, the IBM Cloud provider version enables Red Hat OpenShift APIs and features that are at beta. Red Hat OpenShift alpha features are disabled and subject to change.\n\nCheck the [Security Bulletins on IBM Cloud Status](https:\/\/cloud.ibm.com\/status?selected=security) for security vulnerabilities that affect Red Hat OpenShift on IBM Cloud. You can filter the results to view only Kubernetes Service security bulletins that are relevant to Red Hat OpenShift on IBM Cloud. Change log entries that address other security vulnerabilities but don't include an IBM security bulletin are for vulnerabilities that are not known to affect Red Hat OpenShift on IBM Cloud in normal usage. If you run privileged containers, run commands on the workers, or execute untrusted code, then you might be at risk.\n\nMaster patch updates are applied automatically. Worker node patch updates can be applied by reloading or updating the worker nodes. For more information about major, minor, and patch versions and preparation actions between minor versions, see [Red Hat OpenShift versions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n\n\n\n Change log for worker node fix pack 4.13.4_1525_openshift, released 03 July 2023 \n\nThe following table shows the changes that are in the worker node fix pack 4.13.4_1525_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.13.3_1523_openshift\n\n Component Previous Current Description \n\n Red Hat OpenShift on IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_413"},{"document_id":"ibmcld_10400-7-1945","score":34.5072445966,"text":"\nVersion 4.12 change log \n\nView information of version changes for major, minor, and patch updates that are available for your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters that run version 4.12. Changes include updates to Red Hat OpenShift, Kubernetes, and IBM Cloud Provider components.\n\n\n\n Overview \n\nUnless otherwise noted in the change logs, the IBM Cloud provider version enables Red Hat OpenShift APIs and features that are at beta. Red Hat OpenShift alpha features are disabled and subject to change.\n\nCheck the [Security Bulletins on IBM Cloud Status](https:\/\/cloud.ibm.com\/status?selected=security) for security vulnerabilities that affect Red Hat OpenShift on IBM Cloud. You can filter the results to view only Kubernetes Service security bulletins that are relevant to Red Hat OpenShift on IBM Cloud. Change log entries that address other security vulnerabilities but don't include an IBM security bulletin are for vulnerabilities that are not known to affect Red Hat OpenShift on IBM Cloud in normal usage. If you run privileged containers, run commands on the workers, or execute untrusted code, then you might be at risk.\n\nMaster patch updates are applied automatically. Worker node patch updates can be applied by reloading or updating the worker nodes. For more information about major, minor, and patch versions and preparation actions between minor versions, see [Red Hat OpenShift versions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n\n\n\n Change log for worker node fix pack 4.12.22_1550_openshift, released 03 July 2023 \n\nThe following table shows the changes that are in the worker node fix pack 4.12.22_1550_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.12.21_1547_openshift\n\n Component Previous Current Description \n\n Red Hat OpenShift on IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_412"},{"document_id":"ibmcld_10068-186013-187552","score":34.3805983754,"text":"\nRed Hat OpenShift 4.3.12-x86_64 4.3.18-x86_64 See the [Red Hat OpenShift release notes](https:\/\/docs.openshift.com\/container-platform\/4.3\/release_notes\/ocp-4-3-release-notes.html). \n Red Hat OpenShift Console configuration N\/A N\/A Fixed a problem that might leave the Red Hat OpenShift Console inaccessible after a cluster master operation. \n Red Hat OpenShift Control Plane Operator 3b3ff62 bc493d4 See the [Red Hat OpenShift HyperShift toolkit repository](https:\/\/github.com\/openshift\/hypershift-toolkit\/commit\/bc493d4b51ea7d3d8e60453dee2407baf03e1c6d). Removed incorrect notifications about available cluster updates that referred to OpenShift Container Platform versions instead of Red Hat OpenShift on IBM Cloud versions. \n Red Hat OpenShift HyperShift toolkit 3b3ff62 bc493d4 See the [Red Hat OpenShift HyperShift toolkit repository](https:\/\/github.com\/openshift\/hypershift-toolkit\/commit\/bc493d4b51ea7d3d8e60453dee2407baf03e1c6d). Removed incorrect notifications about available cluster updates that referred to OpenShift Container Platform versions instead of Red Hat OpenShift on IBM Cloud versions. \n\n\n\n\n\n\n\n Change log for worker node fix pack 4.3.14_1522_openshift, released 11 May 2020 \n\nThe following table shows the changes that are in the worker node fix pack update 4.3.13_1522_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.3.13_1521_openshift\n\n Component Previous Current Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-changelog_archive"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1815417925,"ndcg_cut_10":0.1815417925}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11436-2675-4262","score":19.3053852512,"text":"\nTo buy a SUSE subscription, see [How to Buy](https:\/\/www.suse.com\/support\/?id=SUSE_Linux_Enterprise_Server_for_SAP_Applicationshow-to-buy).\n2. To register your system, see [Registering an Installed System](https:\/\/documentation.suse.com\/sles\/12-SP4\/single-html\/SLES-deployment\/sec-y2-sw-register).\n\n\n\n\n\n\n\n Capturing and importing a SLES image \n\nTo use SLES within the Power Systems Virtual Server, you can use the [IBM Power Virtualization Center (PowerVC)](https:\/\/www.ibm.com\/support\/knowledgecenter\/en\/SSXK2N_1.4.4\/com.ibm.powervc.standard.help.doc\/powervc_images_hmc.html) to capture your Linux image, then [import it](https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-deploy-custom-image) as an Open Virtualization Appliance (OVA) file. You must also bring your own license (BYOL). If you cannot use PowerVC to capture an image, see the [Power Systems OVA image capture](https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-linux-deploymentvios-capture) instructions.\n\n\n\n\n\n Linux networking \n\nTo connect a Linux virtual machine (VM) to the public internet, you must add a public network when you provision a Power Systems Virtual Server. You must set up a Linux-based NAT gateway on a public-facing Linux VM if you have Linux VMs that do not need an internet-facing external IP address. For more information, see [19.6 Basic Router Setup](https:\/\/documentation.suse.com\/sles\/15-SP1\/html\/SLES-all\/cha-network.htmlsec-network-router) and [Linux NAT(Network Address Translation) Router Explained](https:\/\/www.slashroot.in\/linux-nat-network-address-translation-router-explained).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-using-linux"},{"document_id":"ibmcld_11335-4728-6681","score":19.1206340547,"text":"\nYou must set up a Linux-based Network Address Translation (NAT) gateway on a public-facing Linux VM if you have Linux VMs that do not need an internet-facing external IP address. For more information on NAT router, [Linux NAT Router Explained](https:\/\/www.slashroot.in\/linux-nat-network-address-translation-router-explained).\n\nWhen you are configuring a Source NAT (SNAT) gateway between your public and private networks, ensure that the TCP checksum offload option is disabled. You must also set the maximum transmission unit (MTU) value to 1450 on the network interface that is connected to the private network. To ensure that the interface checksum offloading and MTU settings of the network interface are persistent whenever the virtual machine is restarted, you need to modify the configuration files of your network interface.\n\nThe TCP checksum offload option must be disabled on the private network interface of the SNAT Gateway and virtual Ethernet device must be of the type ibmveth. You do not need to change the TCP checksum offload option for public network interface. IBM Power Systems Virtual Server VMs are deployed by using ibmveth devices only.\n\nYou can verify that the device interface type is ibmveth by using the following command:\n\nethtool -i <interface name> | grep driver\n\nThe following instructions are applicable to RHEL version 8.1, and later. If you need additional help to configure network interfaces, refer to the Red Hat documentation.\n\n\n\n1. Identify the name of the private network interface that you want to modify. Use the following command to identify the network interface names based on the IP address that is assigned to the network interface:\n\nip -4 a s (for IPv4 address)\nip -6 a s (for IPv6 address)\n2. Edit the ifcfg-<NIC> file (where NIC is the network interface name that is identified in step 1).\n\nRHEL: \/etc\/sysconfig\/network-scripts\/ifcfg-<NIC>\n\n\n\n* Add or modify the following lines:\n\n\n\nFor RHEL:\nMTU=1450","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-linux-with-powervs"},{"document_id":"ibmcld_11335-3546-5206","score":19.1029678095,"text":"\nTo buy an RHEL subscription, see [Red Hat Enterprise Linux Server](https:\/\/www.redhat.com\/en\/store\/red-hat-enterprise-linux-ibm-power-little-endian).\n2. To register your system, see [Quick Registration for RHEL](https:\/\/access.redhat.com\/documentation\/en-us\/red_hat_subscription_management\/1\/html\/quick_registration_for_rhel\/index).\n\n\n\n\n\n\n\n Capturing and importing an RHEL image \n\nTo use RHEL within Power Systems Virtual Server, you can use the [IBM Power Virtualization Center (PowerVC)](https:\/\/www.ibm.com\/support\/knowledgecenter\/en\/SSXK2N_1.4.4\/com.ibm.powervc.standard.help.doc\/powervc_images_hmc.html) to capture your Linux image, then [import it](https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-deploy-custom-image) as an Open Virtualization Appliance (OVA) file. You must also bring your own license (BYOL). If you cannot use PowerVC to capture an image, see the [Power Systems OVA image capture](https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-linux-deploymentvios-capture) instructions.\n\n\n\n\n\n Linux networking \n\nTo connect a Linux virtual machine (VM) to the public internet, you must add a public network when you provision a Power Systems Virtual Server. You must set up a Linux-based Network Address Translation (NAT) gateway on a public-facing Linux VM if you have Linux VMs that do not need an internet-facing external IP address. For more information on NAT router, [Linux NAT Router Explained](https:\/\/www.slashroot.in\/linux-nat-network-address-translation-router-explained).\n\nWhen you are configuring a Source NAT (SNAT) gateway between your public and private networks, ensure that the TCP checksum offload option is disabled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-linux-with-powervs"},{"document_id":"ibmcld_11436-3825-5765","score":19.1004693897,"text":"\nYou must set up a Linux-based NAT gateway on a public-facing Linux VM if you have Linux VMs that do not need an internet-facing external IP address. For more information, see [19.6 Basic Router Setup](https:\/\/documentation.suse.com\/sles\/15-SP1\/html\/SLES-all\/cha-network.htmlsec-network-router) and [Linux NAT(Network Address Translation) Router Explained](https:\/\/www.slashroot.in\/linux-nat-network-address-translation-router-explained).\n\nWhen you are configuring a Source NAT (SNAT) gateway between your public and private networks, ensure that the TCP checksum offload option is disabled. You must also set the maximum transmission unit (MTU) value to 1450 on the network interface that is connected to the private network. To ensure that the interface checksum offloading and MTU settings of the network interface are persistent whenever the virtual machine is restarted, you need to modify the configuration files of your network interface.\n\nThe TCP checksum offload option must be disabled on the private network interface of the SNAT Gateway and virtual Ethernet device must be of the type ibmveth. You do not need to change the TCP checksum offload option for public network interface. IBM Power Systems Virtual Server VMs are deployed by using ibmveth devices only.\n\nYou can verify that the device interface type is ibmveth by using the following command:\n\nethtool -i <interface name> | grep driver\n\nThe following instructions are applicable to SLES version SP15. If you need additional help to configure network interfaces, refer to the SLES documentation.\n\n\n\n1. Identify the name of the private network interface that you want to modify. Use the following command to identify the network interface names based on the IP address that is assigned to the network interface:\n\nip -4 a s (for IPv4 address)\nip -6 a s (for IPv6 address)\n2. Edit the ifcfg-<NIC> file (where NIC is the network interface name that is identified in step 1).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-using-linux"},{"document_id":"ibmcld_11353-7-2006","score":17.8135495219,"text":"\nGetting started with the Power Edge Router \n\nA Power Edge Router (PER) is a high-performance router that provides advanced routing capabilities for IBM\u00ae Power\u00ae Systems Virtual Server users.\n\nPER improves network communication across different parts of IBM network. The PER solution creates a direct connection to the IBM Cloud MPLS (Multi Protocol Label Switching) backbone, making it easy for different parts of the IBM network to communicate with each other. The PER solution is comprised of two routers that enable an aggregate connectivity of 400 Gbps to each Power Systems Virtual Server POD (acronym for Performance Optimized Datacenter that are modular datacenters).\n\nThe PER solution is currently available in DAL10. PER will be deployed in other datacenters over time.\n\nPER associates specific Power Systems Virtual Server networks with unique MPLS route distinguishers (RDs). This makes it easy for different networks to communicate with each other across the IBM Cloud MPLS backbone.\n\nTo facilitate communication between Power Systems Virtual Server instances and other parts of the network, such as [Classic infrastructure](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-getting-started-tutorial), [Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-started), and remote Power Systems Virtual Server instances, [Transit Gateway](https:\/\/cloud.ibm.com\/docs\/transit-gateway?topic=transit-gateway-getting-started&interface=ui) is used.\n\nOne of the benefits of the PER solution is that it makes it easier for a Power Systems Virtual Server user to access other IBM Cloud services, such as IBM Cloud DNS, NTP, and Cloud Object Storage. You can connect to these services without having to use proxies or virtual routers, as the PER solution includes a Network Address Translation (NAT) device that simplifies the access process.\n\nThe following network architecture diagram explains how the PER is integrated into the IBM Cloud environment:\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-per"},{"document_id":"ibmcld_14913-0-1238","score":17.7170164686,"text":"\n\n\n\n\n\n\n  About virtual network functions over VPC \n\nNetwork Function Virtualization (NFV) is the network infrastructure behind virtualizing network services (such as routers, firewalls, and load balancers) that were traditionally run on proprietary hardware. These services, called Virtual Network Functions (VNFs), are packaged as virtual machines (VMs) on commodity hardware, which allows service providers to run their networks on standard servers instead of proprietary ones. This third-party software interacts with the IBM Software-Defined Networking (SDN) controller to offer easy configuration, centralized management, and lower operational costs.\n\nWorking along with IBM Cloud\u00ae Schematics (Infrastructure as Code) and the IBM Content catalog, customers are able to instantiate best-in-network solutions to manage their workload.\n\nBenefits include:\n\n\n\n*  Instantiating virtual network services and modifying configurations without the need to deploy new network hardware.\n*  Rapid service delivery with the agility to scale well above physical hardware.\n*  Centralized policy control.\n*  Using the same routers, firewalls, load balancers, and VPNs in IBM Cloud that were used in physical hardware or other cloud providers.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vnf"},{"document_id":"ibmcld_16628-0-1541","score":17.5698743543,"text":"\n\n\n\n\n\n\n  About Visual Explain \n\nThe visual explain feature in IBM\u00ae watsonx.data shows the execution plan for a specified SQL query. This feature also validates the SQL query. The output results can be visualized in different formats, which can be rendered into a graph or a flow chart. Data exchange happens between single or multiple nodes within a fragment. Each fragment has a set of data that is distributed between the nodes.\n\nWith this visual explain feature, you can run the query and show the output in a distributed environment. You can output the results in different formats. When queries are run, they scan through the database. The queries retrieve table metadata to fetch the correct output.\n\nWith this visual explain feature, you can visualize the query in a graphical representation. When a query is run in the SQL editor and selects the Explain option, watsonx.data uses an EXPLAIN SQL statement on the query to create a corresponding graph. This graph can be used to analyze, fix, and improve the efficiency of your queries by saving time and cost.\n\nTo view the execution plans for a query that is run in watsonx.data SQL editor, follow the steps:\n\n\n\n1.  In the Query workspace page, enter the query and click Run on starter to get the results.\n2.  Click Explain on the screen to visualize the graphical representation of the query.\n\n\n\nOn the Explain window, click a stage to view the details on the right window. The details of each stage that is displayed are the estimate values for rows, CPU, memory, and network.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query"},{"document_id":"ibmcld_13200-11725-13301","score":17.4571089291,"text":"\nIn the next sections, you will use the script [test_provision.bash](https:\/\/github.com\/IBM-Cloud\/vpc-tutorials\/blob\/master\/vpc-app-deploy\/test_provision.bash) to confirm that the servers have been provisioned successfully, are able (or not) to access the Internet and that the uploaded.sh script was correctly executed.\n\n\n\n\n\n\n\n Step 2: Using the IBM Cloud CLI and shell scripts \n\nThe IBM Cloud CLI provides commands to interact with all the resources you can create in the IBM Cloud. This section explains how to use these commands, but you are not going to create any resources. It is recommended to use Terraform to deploy full solutions.\n\n\n\n Before you begin \n\nInstall the command line (CLI) tools by [following these steps](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-install-ibmcloud-cli)\n\n\n\n\n\n Provision virtual server instances and install software \n\nThe CLI has a [plugin for all VPC-related functionality](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-vpc-reference), including compute and network resources.\n\n\n\n1. Before working with VPC resources, set the current resource group and region:\n\nibmcloud target -g $TF_VAR_resource_group_name -r $TF_VAR_region\n2. To provision a virtual server instance, run the ibmcloud is create-instance CLI command. In [shared\/install.sh](https:\/\/github.com\/IBM-Cloud\/vpc-tutorials\/blob\/master\/vpc-app-deploy\/shared\/install.sh) is the cloud-init file used to initialize the frontend and the backend servers. You can pass the script with the --user-data parameter like this:\n\nibmcloud is instance-create ... --user-data @shared\/install.sh\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-app-deploy"},{"document_id":"ibmcld_16030-7-2126","score":17.354973426,"text":"\nVPC behind the curtain \n\nThe following information presents a detailed conceptual picture of what's happening \"behind the curtain\" in VPC networking. Learn about network isolation, address prefixes, Cloud Service Endpoint source addresses, data packet flows, external IP address lifecycle, and Classic infrastructure access. Readers are expected to have some networking background.\n\n\n\n Network isolation \n\nVPC network isolation takes place at three levels:\n\n\n\n* Hypervisor - The virtual server instances are isolated by the hypervisor. A virtual server instance can't directly reach other virtual server instances that are hosted by the same hypervisor if they are not in the same VPC.\n* Network - Isolation occurs at the network level by using virtual network identifiers (VNIs). These identifiers are assigned to each subnet and scoped to a single zone. A VNI is added to all data packets that enter any zone of the VPC: entering either from the hypervisor, when sent by a virtual server instance, or entering the zone from the cloud, when sent by the implicit routing function.\n\nA packet that leaves a zone has the VNI stripped off. When the packet reaches its destination zone, entering through the implicit routing function, the implicit router always adds the proper VNI for that zone.\n* Router - The implicit router function provides isolation to each VPC by providing a virtual routing function (VRF) and a VPN with MPLS (multi-protocol label switching) in the cloud backbone. Each VPC's VRF has a unique identifier, and this isolation allows each VPC to have access to its own copy of the IPv4 address space. The MPLS VPN allows for federating all edges of the cloud: Classic Infrastructure, Direct Link, and VPC.\n\n\n\n\n\n\n\n Address prefixes \n\nAddress prefixes are the summary information that is used by a VPC's implicit routing function to locate a destination virtual server instance, regardless of the availability zone in which the destination virtual server instance is located. The primary function of address prefixes is to optimize routing over the MPLS VPN, while pathological routing cases are avoided.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-behind-the-curtain"},{"document_id":"ibmcld_11353-1498-3370","score":17.301590707,"text":"\nOne of the benefits of the PER solution is that it makes it easier for a Power Systems Virtual Server user to access other IBM Cloud services, such as IBM Cloud DNS, NTP, and Cloud Object Storage. You can connect to these services without having to use proxies or virtual routers, as the PER solution includes a Network Address Translation (NAT) device that simplifies the access process.\n\nThe following network architecture diagram explains how the PER is integrated into the IBM Cloud environment:\n\nZoom\n\n![Power Edge Router network architecture diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/1d36273917990fbf48078805e201d2e85e2fcb27\/power-iaas\/images\/per-network-arch-diag.svg)\n\nFigure 1. Power Edge Router network architecture diagram\n\nThe network traffic in a PER environment can flow in the following two ways:\n\n\n\n* Accessing classic infrastructure through Transit Gateway.\n\n\n\n* 1 - Traffic from ACI tenants is forwarded to the PER.\n* 2 - PER forwards the traffic to classic infrastructure services that use Transit Gateway\n\n\n\n* Accessing cloud services that can access each other's resources.\n\n\n\n* 1 - Traffic from ACI tenants is forwarded to the PER.\n* 3 - Traffic from PER is forwarded to the NAT services with Service Gateway routers for conversion of destination addresses to ADN and CSE networks.\n* 4 - The converted traffic from NAT is forwarded to PER.\n* 2 - Traffic from PER is now forwarded to IBM Cloud PPRs for final delivery.\n\n\n\n\n\nThe automation of ACI, PER, and NAT Services provisioning in IBM data centres is designed to simplify network integration and accelerate connection time for IBM Power Systems Virtual Server users in the IBM Cloud.\n\n\n\n Considerations when using PER \n\n\n\n* You cannot create a cloud connection or a VPN connection in a PER workspace.\n* Currently, you can only choose DAL10 as the datacenter to create a PER workspace.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-per"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.167160455}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03080-7-1901","score":44.8988579577,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_16326-1697-3495","score":43.6748837046,"text":"\nFor more information, see [Changing background website](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-sharepreview-change-background).\n* Customize web chat: Customize your draft web chat channel to match your brand or website. For more information, see [Web chat setup overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n![Image of the Preview page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/preview-page.png)\n\n\n\n\n\n Copying a link to share \n\nYou can share an unauthenticated version of your assistant with your team by sending them a link. The link opens a sample web page with an interactive web chat widget where you can test out your assistant as if you were a customer. Your subject-matter experts can test your in-progress assistant without needing access to Watson Assistant itself. The experience is identical to using Preview this environment on the draft environment tab.\n\nTo share a link:\n\n\n\n1. On the Preview page, click Copy link to share.\n2. Send the link to your team.\n\n\n\nThe preview link is not accessible if web chat security is enabled. For more information about web chat security, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n\n\n Changing background website \n\nYou can visualize how your assistant would look as a web chat widget on your organization's website. You can enter a URL or upload an image.\n\n\n\n Entering a URL \n\nYou can enter a URL of your organization's website. Watson Assistant captures an image of your website to use as the Preview page background.\n\nYour website must be publicly available to all users. Private or intranet sites can\u2019t be accessed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-share"},{"document_id":"ibmcld_16368-7-2072","score":43.5548479832,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_03421-4-1877","score":43.4948467456,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16295-7-1721","score":42.7171119557,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_16365-12876-14604","score":41.9304643838,"text":"\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03421-1518-3290","score":41.3881362402,"text":"\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16295-1365-2938","score":40.6566205988,"text":"\nThe script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5. Edit the HTML source for the web page where you want the web chat widget to appear. Paste the code snippet into the page. Paste the code as close as possible to the closing <\/body> tag to ensure that your page renders faster.\n\nDo not modify the integrationID or region property values in the generated embed script.\n\nIf you aren't ready to add the web chat to a live website, you can quickly test it using a local HTML file. Use this HTML code as the source for a test page:\n\n<html>\n<head><\/head>\n<body>\n<title>My Test Page<\/title>\n<p>The body of my page.<\/p>\n\n<\/body>\n<\/html>\n\nJust copy this code into a file with the .html extension, and replace the script element with the embed script you copied in the previous step.\n\nThe identifiers in the embed script (such as integrationIDserviceInstanceID) are not considered secret, and are visible to anyone who has access to your website. For more information, see [Security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architectureweb-chat-architecture-security).\n6. If the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the URLs that host the web chat are accessible.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_03196-30333-32476","score":40.5635994828,"text":"\nIn the Message before link to web chat field, edit the introductory message to display to the user (in the originating channel) before the link that initiates the transfer. By default, this message is OK, click this link for additional help. Chat will continue on a new web page.\n3. In the URL to web chat field, type the URL for your website where the web chat widget is embedded.\n\n\n\nIn the integration that processes the Channel transfer response, the introductory message is displayed, followed by a link to the URL you specify. The user must then click the link to initiate the transfer.\n\nWhen a conversation is transferred from one channel to another, the session history and context are preserved, so the destination channel can continue the conversation from where it left off. Note that the message output that contains the Channel transfer response is processed first by the channel that initiates the transfer, and then by the target channel. If the output contains multiple responses (perhaps using different response types), these will be processed by both channels (before and after the transfer). If you want to target individual responses to specific channels, you can do so by editing the response using the JSON editor. For more information, see [Targeting specific integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-responses-jsondialog-responses-json-target-integrations).\n\n\n\n\n\n Adding an Image response type \n\nSometimes a picture is worth a thousand words. Include images in your response to do things like illustrate a concept, show off merchandise for sale, or maybe to show a map of your store location.\n\nTo add an Image response type, complete the following steps:\n\n\n\n1. Choose Image.\n2. Add the full URL to the hosted image file into the Image source field.\n\nThe image must be in .jpg, .gif, or .png format. The image file must be stored in a location that is publicly addressable by an https: URL.\n\nFor example: https:\/\/www.example.com\/assets\/common\/logo.png.\n\nIf you want to display an image title and description above the embedded image in the response, then add them in the fields provided.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview"},{"document_id":"ibmcld_03166-4-2012","score":40.2167909333,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding the web chat to your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks, and can transfer customers to human agents.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\nTo learn more about how web chat can help your business, read [this Medium blog post](https:\/\/medium.com\/ibm-watson\/building-an-engaging-virtual-assistant-cf39cd0c3730).\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, either click Integrate web chat, or click Add integration, and then choose the Web chat tile.\n\nThe web chat integration is added to your first assistant automatically. If you're using the My first assistant, click the Web chat tile to open the integration that was added for you.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n\nA preview pane is displayed that shows you what the web chat looks like when it is embedded in a web page. If a message is displayed that starts with, There is an error, it means you haven't added a conversational skill to your assistant yet. After you add a skill, you can test the conversation from the preview pane.\n4. Click Create to create a web chat instance.\n\nYou can skip this step if the web chat integration was created for you automatically.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16295-7-1721","score":37.3932789867,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_16368-7-2072","score":37.1034438667,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_16365-12876-14604","score":35.0777020293,"text":"\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03080-7-1901","score":35.0326980415,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_16389-0-2061","score":35.0165373602,"text":"\n\n\n\n\n\n\n  Configuring style and appearance \n\nOn the Style tab, you can configure the overall appearance of the web chat widget. You can make the following changes:\n\n\n\n*  Set the assistant name. Click Assistant's name as known by customers to specify the name that is displayed in the header of the chat window. The name can be up to 64 characters in length.\n*  Change the colors used in the web chat widget. You can set the following colors:\n\n\n\n*  Primary color: The color of the web chat header.\n*  Secondary color: The color of the customer input message bubble.\n*  Accent color: The color of interactive elements such as the following:\n\n\n\n*  Web chat buttons such as the suggestions button and the \"send message\" button\n*  The border around the input text field (when in focus)\n*  The markers that appear beside the assistant\u2019s messages\n*  The borders that appear around buttons and drop-down lists when customers select from options\n*  The home screen background\n\n\n\n\n\nEach color is specified as an HTML hexadecimal color code, such as FF33FC for pink and 329A1D for green. To change a color, type the HTML color code you want to use, or click the dot next to the field and choose the color from the interactive color picker.\n*  Enable or disable the Built with IBM Watson watermark that is displayed in the web chat widget. To disable the watermark, click to toggle the IBM Watermark switch to the off position. (The watermark cannot be disabled on the Lite plan.)\n*  Provide an avatar image to represent your assistant or organization in the web chat header. Click Add an avatar image to add an image, or Change avatar image to change an image you have previously added.\n\nSpecify the URL for a publicly accessible hosted image, such as a company or brand logo or an assistant avatar. The image file must be between 64 x 64 and 100 x 100 pixels in size.\n\n\n\nStyle changes you make are immediately reflected by the web chat preview that is shown on the page. However, no configuration changes are applied to the environment until you click Save and exit.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-style"},{"document_id":"ibmcld_03421-4-1877","score":34.9485331109,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_03421-1518-3290","score":34.8307466139,"text":"\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16334-24425-26157","score":34.6561981309,"text":"\n(For more information about this feature, see the launcherBeta configuration option at [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).)\n\n\n\n\n\n\n\n 4.5.0 \n\nRelease date: 29 July 2021\n\n\n\n* A new scrollToMessage method is available for scrolling the web chat view to a specified message in the chat history. For more information, see [instance.scrollToMessage()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsscrollToMessage).\n* A new pre:open event is available. This event is fired when the web chat window is opened, but before the welcome message or chat history are loaded. For more information, see [window:pre:open](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-eventswindowpreopen).\n* A new chat history widget is available for embedding in service desk agent UIs. This new widget is based on a read-only view of the standard web chat widget. For information about using the new chat history widget in integrations built using the starter kit, see [Embedded agent application](https:\/\/github.com\/watson-developer-cloud\/assistant-web-chat-service-desk-starter\/blob\/main\/docs\/AGENT_APP.md).\n\n\n\n\n\n\n\n 4.4.1 \n\nRelease date: 6 July 2021\n\n\n\n* Bug fixes.\n\n\n\n\n\n\n\n 4.4.0 \n\nRelease date: 25 June 2021\n\n\n\n* Bug fixes.\n\n\n\n\n\n\n\n 4.3.0 \n\nRelease date: 7 June 2021\n\n\n\n* Search suggestions: If a search skill is configured for your assistant, the suggestions include a new View related content section. This section contains search results that are relevant to the user input.\n* Focus trap: A new enableFocusTrap option enables maintaining focus inside the web chat widget while it is open.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-release-notes-chat"},{"document_id":"ibmcld_03080-1529-3357","score":33.8330310729,"text":"\nFor a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill. For examples of how to complete common tasks, see [Passing values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-context).\n* Change the language that is used by the web chat.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_16334-27263-29119","score":33.7604213407,"text":"\nFor more information about the suggestions feature, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate). For more information about the home screen, see [Configuring the home screen](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-home-screen).\n* onError callback: The new onError callback option in the web chat configuration enables you to specify a callback function that is called if errors occur in the web chat. This makes it possible for you to handle any errors or outages that occur with the web chat. For more information, see [Listening for errors](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationonerror-detail).\n* Session ID available in widget state: The state information returned by the getState() instance method now includes the session ID for the current conversation. For more information, see [instance.getState()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsgetState).\n* IBM watermark: The web chat can now display a Built with IBM Watson watermark to users. This watermark is always enabled for any new web chat integrations on Lite plans. For more information, see [Create a web chat instance to add to your website](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-task).\n* Fixes to rendering of list items: The rendering of HTML list items in the web chat widget has been updated.\n\n\n\n\n\n\n\n 4.1.0 \n\nRelease date: 8 April 2021\n\n\n\n* Home screen now generally available: Ease your customers into the conversation by adding a home screen to your web chat window. The home screen greets your customers and shows conversation starter messages that customers can click to easily start chatting with the assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-release-notes-chat"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16384-1889-3334","score":30.3303401309,"text":"\nYou can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.\n\n\n\n* [How the web chat works](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture): Overview of web chat capabilities and architecture\n* [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat): How to embed the web chat widget on your website\n* [Web chat setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to configure the web chat using the integration settings\n* [Web chat development](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to customize and extend the web chat by writing code\n* [Adding contact center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat-haa): How to integrate the web chat with a contact center platform so you can connect your customers to human agents","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16368-7-2072","score":29.6455974969,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_16299-1512-2608","score":28.2128428795,"text":"\n* [Web chat development overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop): You can use the web chat API to extensively customize the appearance and behavior of the web chat.\n* Customizing the phone integration: You can use commands and context variables to extensively configure how your assistant interacts with users using the phone integration. (More information coming soon.)\n* Customizing the SMS integration: You can use commands and context variables to customize how your assistant interacts with users using text messages. (More information coming soon.)\n* [Extending your assistant using webhooks](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-webhook-overview): You use webhooks to call external services that extend the capabilities of your assistant or log activity.\n* Developing a custom channel: If none of the built-in channel integrations meet your needs, you can use the Watson Assistant REST API and SDKs to develop a custom client application that interacts with your assistant. (More information coming soon.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-develop-overview"},{"document_id":"ibmcld_02855-13982-15842","score":27.6049102185,"text":"\nFor more information about rich response types, see [Rich responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia).\n\n\n\n\n\n Extending the web chat \n\nA developer can extend the capabilities of the web chat by using the Watson Assistant web chat toolkit on [GitHub](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html).\n\nIf you choose to use the provided methods, you implement them by editing the code snippet that was generated earlier. You then embed the updated code snippet into your web page.\n\nHere are some common tasks you might want to perform:\n\n\n\n* [Setting and passing context variable values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-set-context%7D)\n* [Adding user identity information (if you don't enable security)](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-userid)\n\n\n\n\n\n Setting and passing context variable values \n\nA context variable is a variable that you can use to pass information to your assistant before a conversation starts. It can also collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on.\n\nThe following script preserves the context of the conversation. In addition, it adds an $ismember context variable and sets it to true.\n\nThe name that is specified for the skill (main skill) is a hardcoded name that is used to refer to any skill that you create from the product user interface. You do not need to edit your skill name.\n\n<script>\nfunction preSendhandler(event) {\nevent.data.context.skills['main skill'].user_defined.ismember = true;\n}\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_16368-1661-3409","score":27.4258293657,"text":"\nFor more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages). By subscribing to events, you can implement custom behavior or even intercept and modify message content. For more information about the event system, see [Events](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-events) in the web chat API reference.\n\n\n\nIf you want to use the web chat API to customize your web chat implementation, you don't have to start from scratch. Tutorials are available that show examples of common web chat customizations. For more information, see [Web chat development tutorials](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-tutorials).\n\n\n\n Development tasks \n\nYou can use the web chat API to customize and extend the web chat in the following ways.\n\nWeb chat style and content\n: \n\n* [Customizing the look of the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-developlook)\n* [Customizing the home screen](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develophome-screen)\n* [Customizing strings](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-developstrings)\n* [Supporting global audiences](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-developglobal-audiences)\n\n\n\nOpening, closing, and rendering the web chat window\n:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_02855-12369-14489","score":26.7306520338,"text":"\nThe text in the Option label field has two functions:\n\n\n\n* The text is shown in the suggestions list as an option for customers to select.\n* When selected by a customer, the text is sent to your assistant as a new message. The label must be able to function as input that your dialog understands and knows how to handle.\n\n\n\nBy default, the option label Connect with agent is used. Change the option label to a message that helps your customers reach whatever form of support you do offer. If you offer a toll-free support line, you might add Get the support line phone number. Or if you offer an online support request form, you might add Open a support ticket.\n\nWhether you use the default option label or add your own, make sure your dialog is designed to recognize the message and respond to it appropriately. For more information, see [Connecting customers with support](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support).\n\n\n\n\n\n\n\n Dialog considerations \n\nThe rich responses that you add to a dialog are displayed in the web chat as expected, with the following exceptions:\n\n\n\n* Connect to human agent: This response type is ignored.\n* Option: If your option list contains up to four choices, they are displayed as buttons. If your list contains five or more options, then they are displayed in a drop-down list.\n* Pause: This response type pauses the assistant's activity in the chat. However, activity does not resume after the pause until another response is triggered. Whenever you include a pause response type, add another, different response type, such as text, after it.\n\n\n\nFor more information about rich response types, see [Rich responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia).\n\n\n\n\n\n Extending the web chat \n\nA developer can extend the capabilities of the web chat by using the Watson Assistant web chat toolkit on [GitHub](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html).\n\nIf you choose to use the provided methods, you implement them by editing the code snippet that was generated earlier.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_02855-5574-7284","score":26.664982674,"text":"\nFor more information, see the [Using a custom launcher tutorial](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Changing the size or position of the chat window that is displayed when users click the launcher button. For more information, see the [Render to a custom element tutorial](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n\n\n\n14. Click the icon to open the chat window and talk to your assistant.\n\n![Web chat window](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/web-chat-window.png)\n\nThe traffic to and from the web chat is sent between the instance that is hosted by your deployed cluster environment and the web page where you embed the web chat.\n15. Paste the code snippet into each web page where you want the assistant to be available to your customers.\n\nYou can paste the same script tag into as many pages on your website as you want. Add it anywhere that you want users to be able to reach your assistant for help. However, be sure to add it only one time per page.\n16. Submit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_16384-7-2422","score":26.6170947474,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16299-7-2120","score":26.350709839,"text":"\nOverview: Customizing and developing \n\nThe Watson Assistant user interface makes it easy to build an assistant and deploy it to your customers without writing any code. For advanced users and developers, there are powerful ways you can further customize and extend the capabilities of your assistant.\n\nA deployed assistant includes numerous components that work together to deliver the help your customers need over the channels they use.\n\n![Watson Assistant architecture diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/arch-detail.png)\n\n\n\n* Customers interact with the assistant using a channel such as the web chat or phone integration.\n* Based on natural language understanding, the assistant makes a decision about how to route the customer's request to the appropriate resolution mechanism, which might be an action or a search of existing content.\n* The assistant might also need to communicate with external services or hand off the conversation to a human agent.\n\n\n\nThere are multiple points at which a developer can customize and extend how the assistant behaves, or how it interacts with external services. These customization points include the following:\n\n\n\n* Customizing actions: By writing expressions and editing JSON data, you can extensively customize how an action evaluates step conditions, how it stores data, how it responds to customer input, and how it interacts with channels. (More information coming soon.)\n* [Web chat development overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop): You can use the web chat API to extensively customize the appearance and behavior of the web chat.\n* Customizing the phone integration: You can use commands and context variables to extensively configure how your assistant interacts with users using the phone integration. (More information coming soon.)\n* Customizing the SMS integration: You can use commands and context variables to customize how your assistant interacts with users using text messages. (More information coming soon.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-develop-overview"},{"document_id":"ibmcld_03166-8640-10452","score":26.0415287732,"text":"\nFor more information, see [Applying advanced customizations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config).\n4. Click the icon to open the chat window and talk to your assistant.\n\n![Web chat window](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/web-chat-window.png)\n5. Paste the code snippet into each web page where you want the assistant to be available to your customers.\n\nYou can paste the same script tag into as many pages on your website as you want. Add it anywhere where you want users to be able to reach your assistant for help. However, be sure to add it only one time per page.\n6. Submit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf the Connect to agent button is displayed and you don't have human agent support configured, you can hide it by changing the Suggestions configuration. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.\n\n\n\nA developer can use APIs to apply more advanced customizations to the style of the web chat. For more information, see [Applying advanced customizations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config).\n\n\n\n\n\n Launcher appearance and behavior","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.6713860725,"ndcg_cut_10":0.819427028}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16388-7-1918","score":45.6695370872,"text":"\nEncrypting sensitive data \n\nBy using the public key that is provided by IBM, you can add another level of encryption to hide sensitive data you send from the web chat.\n\nTo use this method for encrypting data, you must first enable the web chat security feature. For more information, see [Enabling web chat security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-enable).\n\nUse this method to send sensitive information in messages that come from your website, such as information about a customer's loyalty level, a user ID, or security tokens to use in webhooks that you call from actions. Information passed to your assistant in this way is stored in a private context variable. Private variables cannot be seen by customers and are never sent back to the web chat.\n\nFor example, you might start a business process for a VIP customer that is different from the process you start for a standard customer. You do not want non-VIPs to know that they are categorized as such, but you must pass this information to your action so it can change the flow of the conversation. To do this, you can pass the customer MVP status as an encrypted variable. This private context variable is available for use by the action, but not by anything else.\n\n![development icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/development-icon.png)Tutorial: For a tutorial that shows an example of using web chat security to authenticate users and protect sensitive data, see [Tutorial: Authenticating a user in the middle of a session](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-security).\n\nTo encrypt sensitive data:\n\n\n\n1. On the Security tab of the web chat integration settings, click the Generate key button.\n2. Copy the public key that displays in the IBM-provided public key field.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-encrypt"},{"document_id":"ibmcld_02875-7-2073","score":43.1773374477,"text":"\nAdding custom dialog flows for integrations \n\nUse the JSON editor in dialog to access information that is submitted from the web chat integration.\n\nThe context object that is passed as part of the v2 \/message API request contains an integrations object. This object makes it possible to pass information that is specific to a single integration type in the context. For more information about context variables, see [Context variables](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-variables).\n\nThe integrations object is available from the v2 API in version 2020-04-01 or later only.\n\n\n\n Web chat: Accessing sensitive data \n\nIf you enable security for the web chat, you can configure your web chat implementation to send encrypted data to the dialog. Payload data that is sent from web chat is stored in a private context variable named context.integrations.chat.private.user_payload. No private variables are sent from the dialog to any integrations. For more information about how to pass data, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-encrypt).\n\nTo access the payload data, you can reference the context.integrations.chat.private.user_payload object from the dialog node condition.\n\nYou must know the structure of the JSON object that is sent in the payload.\n\nFor example, if you passed the value \"mvp:true\" in the JSON payload, you can add a dialog flow that checks for this value to define a response that is meant for VIP customers only. Add a dialog node with a condition like this:\n\n\n\nPrivate variable as node condition\n\n Field Value \n\n If assistant recognizes $integrations.chat.private.user_payload.mvp \n Assistant responds I can help you reserve box seats at the upcoming conference! \n\n\n\n\n\n\n\n Web chat: Accessing web browser information \n\nWhen you use the web chat integration, information about the web browser that your customer is using to access the web chat is automatically collected and stored.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-integrations"},{"document_id":"ibmcld_02855-27616-29462","score":42.4540537242,"text":"\nreturn new Promise(function(resolve, reject) {\n\/\/ And then pass the new JWT into the callback and the service will resume processing messages.\nevent.identityToken = 'YOUR NEW JWT';\nresolve();\n});\n}});\ninstance.render();\n}\n};\nsetTimeout(function(){\nconst t=document.createElement('script');\nt.src=\"https:\/\/web-chat.global.assistant.watson.appdomain.cloud\/loadWatsonAssistantChat.js\";\ndocument.head.appendChild(t);\n});\n<\/script>\nShow more\n\n\n\n\n\n\n\n Passing sensitive data \n\nYou can optionally copy the public key that is provided by IBM, and use it to add an additional level of encryption to support passing sensitive data from the web chat.\n\nUse this method to send sensitive information in messages that come from your website, such as a information about a customer's loyalty level, a user ID, or security tokens to use in webhooks that you call from your dialog. Information that is passed to your assistant in this way is stored in a private variable in your assistant. Private variables cannot be seen by customers and are never sent back to the web chat.\n\nFor example, you might start a business process for a VIP customer that is different from the process you start for less important customers. You likely do not want non-VIPs to know that they are categorized as such. But you must pass this informataion to your dialog because it changes the route of the conversation. You can pass the customer MVP status as an encrypted variable. This private context variable will be available for use by the dialog, but not by anything else.\n\n\n\n1. From the web chat configuration page, copy the public key from the IBM provided public key field.\n2. From your website, write a function that signs a JSON Web Token.\n\nFor example, the following NodeJS code snippet shows a function that accepts a userID and payload content and sends it to the web chat.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_03422-6821-8665","score":42.4540537242,"text":"\nreturn new Promise(function(resolve, reject) {\n\/\/ And then pass the new JWT into the callback and the service will resume processing messages.\nevent.identityToken = 'YOUR NEW JWT';\nresolve();\n});\n}});\ninstance.render();\n}\n};\nsetTimeout(function(){\nconst t=document.createElement('script');\nt.src=\"https:\/\/web-chat.global.assistant.watson.appdomain.cloud\/loadWatsonAssistantChat.js\";\ndocument.head.appendChild(t);\n});\n<\/script>\nShow more\n\n\n\n\n\n Passing sensitive data \n\nYou can optionally copy the public key that is provided by IBM, and use it to add an additional level of encryption to support passing sensitive data from the web chat.\n\nUse this method to send sensitive information in messages that come from your website, such as a information about a customer's loyalty level, a user ID, or security tokens to use in webhooks that you call from your dialog. Information that is passed to your assistant in this way is stored in a private variable in your assistant. Private variables cannot be seen by customers and are never sent back to the web chat.\n\nFor example, you might start a business process for a VIP customer that is different from the process you start for less important customers. You likely do not want non-VIPs to know that they are categorized as such. But you must pass this informataion to your dialog because it changes the route of the conversation. You can pass the customer MVP status as an encrypted variable. This private context variable will be available for use by the dialog, but not by anything else.\n\n\n\n1. From the web chat configuration page, copy the public key from the IBM provided public key field.\n2. From your website, write a function that signs a JSON Web Token.\n\nFor example, the following NodeJS code snippet shows a function that accepts a userID and payload content and sends it to the web chat.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security"},{"document_id":"ibmcld_03180-5630-7213","score":42.3156131388,"text":"\nEnabling visitor authentication also enables support for cross-domain traffic and cross-browser identification. For more information, see the [Zendesk documentation](https:\/\/support.zendesk.com\/hc\/en-us\/articles\/360022185314-Enabling-authenticated-visitors-in-the-Chat-widget).\n\nBefore you can secure the Zendesk connection, complete the following required tasks:\n\n\n\n1. Secure the web chat. For more information see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security).\n2. Encrypt sensitive information that you pass to the web chat.\n\nWhen you enable security in Zendesk, you must provide the name and email address of the current user with each request. Configure the web chat to pass this information in the payload.\n\nSpecify the information by using the following syntax. Use the exact names (name and email) for the two name and value pairs.\n\n{\nuser_payload : {\nname: '{customerName}',\nemail: '{customerEmail}'\n}\n}\n\nFor more information, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-securityweb-chat-security-encrypt).\n\nZendesk also expects iat and external_id name and value pairs. However, there's no need for you to provide this information. IBM automatically provides a JWT that contains these values.\n\nFor example:\n\nconst userPayload = {\n\"name\" : \"Cade Jones\",\n\"email\" : \"cade@example.com\",\n}\n\n\/\/ Sample NodeJS code on your server.\nconst jwt = require('jsonwebtoken');\nconst RSA = require('node-rsa');\n\nconst rsaKey = new RSA(process.env.PUBLIC_IBM_RSA_KEY);\n\n\/\n* Returns a signed JWT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-zendesk"},{"document_id":"ibmcld_16298-6367-7794","score":41.7299754838,"text":"\nFor more information see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n2. Encrypt sensitive information that you pass to the web chat.\n\nWhen you enable security in Zendesk, you must provide the name and email address of the current user with each request. Configure the web chat to pass this information in the payload.\n\nSpecify the information by using the following syntax. Use the exact names (name and email) for the two name and value pairs.\n\n{\nuser_payload : {\nname: '{customerName}',\nemail: '{customerEmail}'\n}\n}\n\nFor more information, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-securityweb-chat-security-encrypt).\n\nZendesk also expects iat and external_id name and value pairs. However, there's no need for you to provide this information. IBM automatically provides a JWT that contains these values.\n\nFor example:\n\nconst userPayload = {\n\"name\" : \"Cade Jones\",\n\"email\" : \"cade@example.com\",\n}\n\n\/\/ Sample NodeJS code on your server.\nconst jwt = require('jsonwebtoken');\nconst RSA = require('node-rsa');\n\nconst rsaKey = new RSA(process.env.PUBLIC_IBM_RSA_KEY);\n\n\/\n* Returns a signed JWT. Optionally, adds an encrypted user_payload in stringified JSON.\n\/\nfunction mockLogin(userID, userPayload) {\nconst payload = {\nsub: userID, \/\/ Required\niss: 'www.ibm.com', \/\/ Required\nacr: 'loa1' \/\/ Required","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-zendesk"},{"document_id":"ibmcld_03188-3379-5204","score":41.3013217901,"text":"\nThe rich response types often behave differently when they are displayed in different built-in integrations or in the assistant preview. For more information about these unique behaviors, see the following topics:\n\n\n\n* [Web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-dialog)\n\n\n\n\n\n* [Phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-dialog)\n\n\n\n\n\n* [SMS with Twilio](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-smsdeploy-sms-dialog)\n\n\n\n\n\n* [Assistant preview](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-linkdeploy-web-link-dialog)\n\n\n\nIf you need to provide customized responses for different channels, and you do not need to modify your dialog flow based on which integration is in use, you can also use the channels array to target your responses to specific integrations. For more information, see [Targeting specific integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-responses-jsondialog-responses-json-target-integrations).\n\n\n\n\n\n Web chat: Accessing sensitive data \n\nIf you enable security for the web chat, you can configure your web chat implementation to send encrypted data to the dialog. Payload data that is sent from web chat is stored in a private context variable named context.integrations.chat.private.user_payload. No private variables are sent from the dialog to any integrations. For more information about how to pass data, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-securityweb-chat-security-encrypt).\n\nTo access the payload data, you can reference the context.integrations.chat.private.user_payload object from the dialog node condition.\n\nYou must know the structure of the JSON object that is sent in the payload.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrations"},{"document_id":"ibmcld_02855-16710-18404","score":41.2363754643,"text":"\nThe next response has a more generic greeting.\n\n![Shows multiple conditioned responses in a dialog node, one of which references the ismember context variable](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/web-chat-use-context-var.png)\n\nIf you enable security, you can encrypt the data that you pass to your dialog. For more information, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-encrypt).\n\nRemember that a session ends if there's no interaction with the user after 1 hour (or whatever inactivity timeout setting you specify, which can be up to 7 days). Any contextual information that you pass or collect is reset after the inactivity time period is passed. For more information, see [Changing the inactivity timeout setting](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-settings).\n\n\n\n\n\n Adding user identity information \n\nIf you do not enable security, and you want to perform tasks where you need to know the user who submitted the input, then you must pass the user ID to the web chat integration.\n\nIf you do enable security, you set the user ID in the JSON Web Token instead. For more information, see [Authenticating users](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-authenticate).\n\nChoose a non-human-identifiable ID. For example, do not use a person's email address as the user_id.\n\nUser information is used in the following ways:\n\n\n\n* The user_id is used to measure the number of monthly active users who interact with the web chat integration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_03421-8091-9846","score":40.1459564539,"text":"\n(window.watsonAssistantChatOptions.clientVersion || 'latest') +\n'\/WatsonAssistantChatEntry.js';\ndocument.head.appendChild(t);});\n\n<\/script>\nShow more\n\nYou can reference the $ismember context variable from your dialog. For example, the following screen capture shows a dialog node that conditions on #General_Greetings. It has multiple conditioned responses. The first response checks whether the current user is a member of your rewards program by checking for the presence of the $ismember context variable. If the variable is present, the response addresses the user as a member. The next response has a more generic greeting.\n\n![Shows multiple conditioned responses in a dialog node, one of which references the ismember context variable](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/web-chat-use-context-var.png)\n\nIf you enable security, you can encrypt the data that you pass to your dialog. For more information, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-securityweb-chat-security-encrypt).\n\nIf you're using a Lite plan, remember that a session ends if there's no interaction with the user after 5 minutes. When the session ends, any contextual information that you pass or collect is reset.\n\n\n\n\n\n Adding user identity information \n\nIf you do not enable security, and you want to perform tasks where you need to know the user who submitted the input, then you must pass the user ID to the web chat integration.\n\nIf you do enable security, you set the user ID in the JSON Web Token instead. For more information, see [Authenticating users](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-securityweb-chat-security-authenticate).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_03080-8169-9970","score":39.8478316212,"text":"\nShow more\n\nYou can reference the $ismember context variable from your dialog. For example, the following screen capture shows a dialog node that conditions on #General_Greetings. It has multiple conditioned responses. The first response checks whether the current user is a member of your rewards program by checking for the presence of the $ismember context variable. If the variable is present, the response addresses the user as a member. The next response has a more generic greeting.\n\n![Shows multiple conditioned responses in a dialog node, one of which references the ismember context variable](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/web-chat-use-context-var.png)\n\nIf you enable security, you can encrypt the data that you pass to your dialog. For more information, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-encrypt).\n\nIf you're using a Lite plan, remember that a session ends if there's no interaction with the user after 5 minutes. When the session ends, any contextual information that you pass or collect is reset.\n\n\n\n\n\n Adding user identity information \n\nIf you do not enable security, and you want to perform tasks where you need to know the user who submitted the input, then you must pass the user ID to the web chat integration.\n\nIf you do enable security, you set the user ID in the JSON Web Token instead. For more information, see [Authenticating users](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-authenticate).\n\nChoose a non-human-identifiable ID. For example, do not use a person's email address as the user_id.\n\nUser information is used in the following ways:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2640681226,"ndcg_cut_10":0.2640681226}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16295-7-1721","score":36.0587454152,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_16334-17373-19365","score":35.1499738608,"text":"\n* Home screen: The web chat home screen has been updated to have a more modern look. For more information about the home screen, see [Configuring the home screen](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-configweb-chat-configure-home-screen).\n* Agent events: New events are now fired by the web chat when interacting with a human agent using a service desk integration. If you are using a custom service desk integration based on the [starter kit](https:\/\/github.com\/watson-developer-cloud\/assistant-web-chat-service-desk-starter), you can use these events to create a pre-chat form before the agent escalation occurs, to create a post-chat form after the agent conversation ends, or to specify what happens if an agent isn\u2019t available (like create a ticket submission form). For more information, see [Agent events summary](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-eventssummary).\n* Markdown support: The web chat now fully supports common Markdown formatting in messages received from an assistant. You might need to review existing assistant output that contains strings that might be recognized as Markdown. (For example, a line of text that begins with a greater-than (>) character is interpreted as a block quote.)\n* Time zone: The time zone set in the context by the web chat no longer overrides any time zone set by the assistant.\n* Locale: Any locale configured for the web chat is now sent to the assistant as part of the context.\n* Window open events: The window:pre:open and window:open events now fire any time the chat window is opened, regardless of the reason. In previous releases, these events only fired if the window was opened by the customer clicking on the built-in launcher. Other methods of opening the chat window, such as session history or custom launchers, did not fire these events.\n\nThe event data passed to the listener has a new reason property that indicates the reason the window was opened.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-release-notes-chat"},{"document_id":"ibmcld_03166-4-2012","score":34.4307130619,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding the web chat to your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks, and can transfer customers to human agents.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\nTo learn more about how web chat can help your business, read [this Medium blog post](https:\/\/medium.com\/ibm-watson\/building-an-engaging-virtual-assistant-cf39cd0c3730).\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, either click Integrate web chat, or click Add integration, and then choose the Web chat tile.\n\nThe web chat integration is added to your first assistant automatically. If you're using the My first assistant, click the Web chat tile to open the integration that was added for you.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n\nA preview pane is displayed that shows you what the web chat looks like when it is embedded in a web page. If a message is displayed that starts with, There is an error, it means you haven't added a conversational skill to your assistant yet. After you add a skill, you can test the conversation from the preview pane.\n4. Click Create to create a web chat instance.\n\nYou can skip this step if the web chat integration was created for you automatically.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_03080-7-1901","score":34.2997709316,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_03109-5081-6683","score":34.0378097667,"text":"\nThe Intercom user_id property is the id of the author message object in the Conversation Model that is defined by Intercom.\n\n\n\n* To get the ID, open the channel from a web browser. Open the web developer tools to view the console. Look for author.\n\n\n\nThe full customer ID looks like this: customer_id=intercom_5c499e5535ddf5c7fa2d72b3.\n* For Slack, the customer_id is the user_id prepended with slack_. The Slack user_id property is a concatenation of the team ID, such as T09LVDR7Y, and the member ID of the user, such has W4F8K9JNF. For example: T09LVDR7YW4F8K9JNF.\n\n\n\n* To get the team ID, open the channel from a web browser. Open the web developer tools to view the console. Look for [BOOT] Initial team ID.\n* You can copy the member ID from the user's Slack profile.\n* To get the IDs programmatically, use the Slack API. For more information, see [Overview](https:\/\/api.slack.com\/apis). The full customer ID looks like this: customer_id=slack_T09LVDR7YW4F8K9JNF.\n\n\n\n* For the web chat integration, the service takes the user_id that is passed in and adds it as the customer_id parameter value to the X-Watson-Metadata header with each request.\n\n\n\n\n\n Before you begin \n\nTo be able to delete message data associated with a specific user, you must first associate all messages with a unique customer ID for each user. To specify the customer ID for any messages sent using the \/message API, include the X-Watson-Metadata: customer_id property in your header. For example:\n\ncurl -X POST -u \"apikey:3Df... ...Y7Pc9\"\n--header\n'Content-Type: application\/json'\n'X-Watson-Metadata: customer_id=abc'\n--data","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-securing"},{"document_id":"ibmcld_03421-4-1877","score":33.9980865864,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16255-4992-6513","score":31.8916938696,"text":"\nThe full customer ID looks like this: customer_id=intercom_5c499e5535ddf5c7fa2d72b3.\n* For Slack, the customer_id is the user_id prepended with slack_. The Slack user_id property is a concatenation of the team ID, such as T09LVDR7Y, and the member ID of the user, such has W4F8K9JNF. For example: T09LVDR7YW4F8K9JNF.\n\n\n\n* To get the team ID, open the channel from a web browser. Open the web developer tools to view the console. Look for [BOOT] Initial team ID.\n* You can copy the member ID from the user's Slack profile.\n* To get the IDs programmatically, use the Slack API. For more information, see [Overview](https:\/\/api.slack.com\/apis). The full customer ID looks like this: customer_id=slack_T09LVDR7YW4F8K9JNF.\n\n\n\n* For the web chat integration, the service takes the user_id that is passed in and adds it as the customer_id parameter value to the X-Watson-Metadata header with each request.\n\n\n\n\n\n Before you begin \n\nTo be able to delete message data associated with a specific user, you must first associate all messages with a unique customer ID for each user. To specify the customer ID for any messages sent using the \/message API, include the X-Watson-Metadata: customer_id property in your header. For example:\n\ncurl -X POST -u \"apikey:3Df... ...Y7Pc9\"\n--header\n'Content-Type: application\/json'\n'X-Watson-Metadata: customer_id=abc'\n--data\n'{\"input\":{\"text\":\"hello\"}}'\n'{url}\/v2\/assistants\/{assistant_id}\/sessions\/{session_id}\/message?version=2019-02-28'\n\nwhere {url} is the appropriate URL for your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-securing"},{"document_id":"ibmcld_16375-1468-2933","score":31.8538190371,"text":"\n\/\/ A UUID like '1d7e34d5-3952-4b86-90eb-7c7232b9b540' included in the embed code provided in Watson Assistant.\nintegrationID: \"YOUR_INTEGRATION_ID\",\n\/\/ Your assistants region e.g. 'us-south', 'us-east', 'jp-tok' 'au-syd', 'eu-gb', 'eu-de', etc.\nregion: \"YOUR_REGION\",\n\/\/ A UUID like '6435434b-b3e1-4f70-8eff-7149d43d938b' included in the embed code provided in Watson Assistant.\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE_ID\",\n\/\/ The callback function that is called after the widget instance has been created.\nonLoad: function(instance) {\ninstance.render();\n},\nshowLauncher: false, \/\/ Hide the web chat launcher, you will open the WebView from your mobile application\nopenChatByDefault: true, \/\/ When the web chat WebView is opened, the web chat will already be open and ready to go.\nhideCloseButton: true \/\/ And the web chat will not show a close button, instead relying on the controls to close the WebView\n};\nsetTimeout(function(){const t=document.createElement('script');t.src=\"https:\/\/web-chat.global.assistant.watson.appdomain.cloud\/versions\/\" + (window.watsonAssistantChatOptions.clientVersion || 'latest') + \"\/WatsonAssistantChatEntry.js\";document.head.appendChild(t);});\n<\/script>\n<\/body>\n<\/html>\nShow more\n\nIn your app, make sure you include logic to hide your web chat launching mechanism when the device is offline. If the device goes offline in the middle of a conversation, appropriate error messages and retries occur.\n\n\n\n\n\n Using a JavaScript bridge","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-mobile"},{"document_id":"ibmcld_03166-1557-3458","score":31.8443611603,"text":"\nA preview pane is displayed that shows you what the web chat looks like when it is embedded in a web page. If a message is displayed that starts with, There is an error, it means you haven't added a conversational skill to your assistant yet. After you add a skill, you can test the conversation from the preview pane.\n4. Click Create to create a web chat instance.\n\nYou can skip this step if the web chat integration was created for you automatically.\n\n![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/plus.png) For environments where private endpoints are in use, keep in mind that the web chat integration sends traffic over the internet. For more information, see [Private network endpoints](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-securitysecurity-private-endpoints).\n5. Optional: Customize the style of the chat window. You can make the following changes:\n\n\n\n* Assistant's name as known by customers: The name by which the assistant is known to users. This name is displayed in the header of the chat window. The name can be up to 64 characters in length.\n* Primary color: The color of the web chat header.\n\nClick the white dot to open a color switcher where you can choose a color. The color is saved as an HTML color code, such as FF33FC for pink and 329A1D for green. Alternatively, you can add an HTML color code directly to the field to set the color.\n* Secondary color: The color of the user input message bubble.\n* Accent color: The color of interactive elements, including:\n\n\n\n* Chat launcher button that is embedded in your web page\n* Send button associated with the input text field\n* Input text field border when in focus\n* Marker that shows the start of the assistant\u2019s response\n* Border of a button after it is clicked\n* Border of the drop-down list field as the user chooses an option","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_16368-1661-3409","score":31.0032343329,"text":"\nFor more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages). By subscribing to events, you can implement custom behavior or even intercept and modify message content. For more information about the event system, see [Events](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-events) in the web chat API reference.\n\n\n\nIf you want to use the web chat API to customize your web chat implementation, you don't have to start from scratch. Tutorials are available that show examples of common web chat customizations. For more information, see [Web chat development tutorials](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-tutorials).\n\n\n\n Development tasks \n\nYou can use the web chat API to customize and extend the web chat in the following ways.\n\nWeb chat style and content\n: \n\n* [Customizing the look of the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-developlook)\n* [Customizing the home screen](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develophome-screen)\n* [Customizing strings](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-developstrings)\n* [Supporting global audiences](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-developglobal-audiences)\n\n\n\nOpening, closing, and rendering the web chat window\n:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2021073465,"ndcg_cut_10":0.2021073465}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16365-14167-16117","score":25.8741801831,"text":"\n{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security \n\nThe web chat integration undergoes tests and scans on a regular basis to find and address potential security issues, such as cross-site scripting (XSS) vulnerabilities.\n\nBe sure to run your own security reviews to see how the web chat fits in with your current website structure and policies. The web chat is hosted on your site and can inherit any vulnerabilities that your site has. Only serve content over HTTPS, use a Content Security Policy (CSP), and implement other basic web security precautions.\n\n\n\n\n\n\n\n Billing \n\nWatson Assistant charges based on the number of unique monthly active users (MAU).\n\nBy default, the web chat creates a unique, anonymous ID the first time a new user starts a session. This identifier is stored in a first-party cookie, which remains active for 45 days. If the same user returns to your site and chats with your assistant again while this cookie is still active, the web chat integration recognizes the user and uses the same user ID. This means that you are charged only once per month for the same anonymous user.\n\nOn Apple devices, the Intelligent Tracking Prevention feature automatically deletes any client-side cookie after 7 days. This means that if an anonymous customer accesses your website and then visits again two weeks later, the two visits are treated as two different MAUs. For information about how to avoid this problem, see [Managing user identity information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16365-12876-14604","score":25.6087419922,"text":"\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16366-7-1826","score":25.4258130291,"text":"\nWeb chat setup overview \n\nYou can modify the web chat integration settings to configure the styling and appearance of the web chat.\n\nYou can quickly deploy and test the web chat integration using the default settings. However, before you go to production with your chatbot, you will need to configure the web chat to integrate with your website and better serve the needs of your customers.\n\nAt a minimum, you should update the following basic settings for your assistant:\n\n\n\n* The [assistant name](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-style) that you want to show to your customers\n* The contents of the [home screen](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-configure-home-screen)\n* The [suggestions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-suggestions) your assistant will offer if customers get stuck\n\n\n\nYou might also want to make additional configurations, such as changing the web chat colors to match your branding, changing the launcher greeting, or enabling encryption.\n\nIf you are a developer, you can customize the web chat by using the web chat API. With the API, you can customize the styling, change the behavior of the web chat widget and launcher, customize strings, modify message content, and more. For more information about using the web chat API, see [Web chat development overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop).\n\nTo change the web chat configuration, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click Open. The Open web chat window opens.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config"},{"document_id":"ibmcld_16365-7-1700","score":25.2994743134,"text":"\nHow the web chat works \n\nThe web chat provides an easy-to-use chatbot interface that you can add to your website without writing any code.\n\nAfter you add the web chat script to your website, your customers will see a launcher icon that they can click to open the chat window and start a conversation with the assistant. The appearance of the launcher icon adapts to desktop and mobile browsers.\n\n![web chat launcher in desktop browser](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-desktop-highlighted.png)\n\nWhen a customer clicks the launcher, the web chat window opens, initially displaying the home screen. The home screen displays a greeting and an optional set of suggested conversation starters for common questions and problems. The customer can either click a conversation starter or type a message in the input field to start the conversation with the assistant.\n\n![web chat example home screen](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-home-screen-lendyr.png)\n\nThe appearance and behavior of the launcher icon, the home screen, and most other aspects of the web chat can be configured and customized to match your website style and branding. For more information, see [Configuring the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03422-14609-15163","score":25.1691659576,"text":"\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Security measures \n\nThe web chat integration undergoes tests and scans on a regular basis to find and address potential security issues, such as cross-site scripting (XSS) vulnerabilities.\n\nBe sure to run your own security reviews to see how the web chat fits in with your current website structure and policies. The web chat is hosted on your site and can inherit any vulnerabilities that your site has. Only serve content over HTTPS, use Content Security Policy (CSP), and implement other basic web security precautions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security"},{"document_id":"ibmcld_16295-7-1721","score":25.1464552753,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_03166-6034-7833","score":25.0941270603,"text":"\nYou add this script to your website in the next section, [Deploy your assistant in production](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-snippet).\n13. If you made any customizations, click Save and exit. Otherwise, click Close.\n\nThe web chat instance is created as soon as you click the Create button, and does not need to be saved.\n\n\n\n\n\n\n\n Deploy your assistant in production \n\n\n\n1. If the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n2. Open the HTML source for a web page on your website where you want the chat window to be displayed. Paste the code snippet into the page.\n\nPaste the code as close to the closing <\/body> tag as possible to ensure that your page renders faster.\n\nThe following HTML snippet is the source for a test page that you can copy and save as a file with a .html extension for testing purposes. You would replace the script element block here with the script elements you copied from the web chat integration setup page.\n\n<html>\n<head><\/head>\n<body>\n<title>My Test Page<\/title>\n<p>The body of my page.<\/p>\n\n<\/body>\n<\/html>\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_03162-2864-4981","score":24.8940645127,"text":"\nFor more information, see [Integrating the web chat with your website](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat).\n2. From the web chat integration page in Watson Assistant, set the Allow transfers to live agents switch to On, and then choose Salesforce as the service desk type. Click Next.\n3. For Watson Assistant to connect to a Salesforce service desk, it needs information about your organization's Salesforce chat deployment and button implementations. Specifically, it needs the API endpoint, organization ID, deployment ID, and button ID. The service can derive the values that it needs from code snippets that you copy and paste to this configuration page.\n\nIn a separate browser tab or window, open your Salesforce account settings page. Log in with a user ID that has administrative privileges. You must switch back and forth between your Salesforce and Watson Assistant web chat integration setup pages. It's easier to do so if you have both pages open at once.\n\n\n\n* Get the deployment code for your Salesforce Agent Configuration chat deployment.\n\nGo to the Salesforce Feature Settings>Service>Chat>Deployments page. Find your organization's deployment. Scroll to the end of the chat deployment configuration page and copy the Deployment Code snippet.\n* Paste the deployment code snippet into the Deployment code field in the Watson Assistant Salesforce configuration page.\n* Get the Chat Button code.\n\nGo to the Salesforce Feature Settings>Service>Chat>Chat Buttons & Invitations page. Find your organization's button implementation. Scroll to the end of the page, and then copy the Chat Button Code snippet.\n* Paste the chat button code snippet into the Chat button code field in the Watson Assistant Salesforce configuration page, and then click Next.\n\n\n\n4. Add a chat app that enables the Salesforce agent to see a history of the chat. To do so, create a Visualforce page, and then add a chat app to the page.\n5. Add custom fields to the Salesforce chat transcript layout.\n\nThis is a one-time task. If the fields already exist for your organization, you can skip this step.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-salesforce"},{"document_id":"ibmcld_16334-7-1815","score":24.8260963295,"text":"\nWeb chat release notes \n\nFind out what's new in the web chat integration.\n\nThe web chat changelog lists changes ordered by version number. For more information about the web chat, see [Integrating the web chat with your website](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat).\n\nFor information about new features and improvements to the core Watson Assistant product, see [Release notes](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-release-notes).\n\n\n\n Controlling the web chat version \n\nIf you want to evaluate changes that are introduced in a web chat release before you apply them to your deployment, you can set a version of your web chat. For more information, see [Controlling the web chat version](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-versions).\n\n\n\n\n\n 7.4.0 \n\nRelease date: 12 June 2023\n\n\n\n* Added CSS variables for customizing the launcher. For more information, see [instance.updateCSSVariables](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsupdatecssvariables).\n\n\n\n\n\n\n\n 7.3.0 \n\nRelease date: 30 May 2023\n\n\n\n* Released a beta of a contact center integration for Genesys Web Messenger, which currently only includes user information strings in English. For more information, see [Genesys Web Messenger](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=service-desks-genesys).\n* Added beta support for file sharing with custom service desk integrations, which currently only includes user information strings in English. For more information, see [Custom service desks](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=service-desks-custom-sd).\n\n\n\n\n\n\n\n 7.2.2 \n\nRelease date: 1 May 2023\n\n\n\n* Bug fixes.\n\n\n\n\n\n\n\n 7.2.1","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-release-notes-chat"},{"document_id":"ibmcld_16366-1573-3444","score":24.7624256335,"text":"\nOn the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\n\n\n\n\n Setup tasks \n\nYou can configure the web chat in the following ways:\n\nStyle and appearance\n: You can configure the overall appearance of the web chat widget, including the assistant name, the colors of various elements, and the avatar image. For more information, see [Configuring style and appearance](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-style).\n\nLauncher\n: You can change the greeting text that is shown by the launcher that invites users to open the web chat. On the Launcher tab, you can specify separate greeting messages for the desktop launcher and the mobile launcher.\n\nThe message you specify is immediately reflected by the launcher preview that is shown on the page. However, no configuration changes are applied to the environment until you click Save and exit.\n\nHome screen\n: You can configure the contents of the home screen that greets customers and helps them start the conversation. For more information, see [Configuring the home screen](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-configure-home-screen).\n\nSuggestions\n: You can configure how and when the web chat offers offers suggestions to customers when the assistant isn't delivering what they expect. For more information, see [Configuring suggestions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-suggestions).\n\nSecurity","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03871-31988-33751","score":14.3562633236,"text":"\nSelect Provide a JSON identity file from the IBM Blockchain Platform and then browse to the admin identity that you exported from your console. If the identity is the administrator of multiple nodes in your network, you can associate the identity with multiple nodes.\n\n\n\nWhen you have associated an admin identity with your peers, CA, and an ordering node, you can connect to your network and use the extension to deploy smart contracts.\n\n\n\n\n\n\n\n Adding wallets and users \n\nUse the following steps to create a new wallet by using a certificate and private key:\n\n\n\n1. Hover your mouse over the Fabric Wallets pane and click +.\n2. Choose to Create a new wallet and add an identity from the options. Provide a name for your wallet and your identity.\n3. Enter the MSP ID of your organization.\n4. Choose to add a certificate and private key.\n5. If you use a certificate and private key, browse to the certificate and private key.\n\n\n\nYou can also add new users to the wallets that have already been created:\n\n\n\n1. In the Fabric Wallets pane, right-click a wallet and select Add Identity.\n2. Provide a name for the identity and an MSP ID.\n3. You can upload a JSON file, provide a certificate and private key, or provide an enrollment ID and secret.\n\n\n\n* If you are connecting to a network on the IBM Blockchain Platform, you can download an identity from your IBM Blockchain console, either by exporting an identity from your wallet or by enrolling and then exporting an identity using your Certificate Authority. You can then upload the JSON file directly to VS Code.\n* If you use a certificate and private key, browse to the certificate and private key.\n* If you use an enrollment ID and secret, choose the gateway to enroll with and enter the enrollment ID and secret.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-develop-vscode"},{"document_id":"ibmcld_16234-1331-2901","score":14.2225737278,"text":"\nAdding users from this menu enables them to read, write, and manage all assistants in the service instance.\n4. Click Submit.\n\n\n\nAfter you click Submit, any user that you invite receives an email to access the instance. After they accept the invite, they can open the service instance and manage all assistants.\n\n\n\n\n\n Managing access with Identity and Access Management \n\nAnother way to add users to your assistants is using Identity and Access Management (IAM). If you want to add users, and you don't want them to have full Manager access, use IAM to add them. From IAM, you can also manage access roles of those users that are already added to your assistants.\n\n\n\n Opening Identity and Access Management \n\n\n\n1. Open the Manage menu. ![Manage menu](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/user--avatar.svg)\n2. Click Manage users.\n3. In Access and permissions, click Identity and Access Management in step 2.\n\nZoom\n\n![Access and permissions](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/access-control-manage-users-modal.png)\n\nAccess and permissions\n\n\n\n\n\n\n\n Adding users in Identity and Access Management \n\n\n\n1. In IAM, click Invite users.\n2. Enter the email address of the person who needs access.\n3. In How do you want to assign access?, choose Access policy.\n\nZoom\n\n![Access policy](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/access-policy.png)\n\nAccess policy\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-access-control"},{"document_id":"ibmcld_03966-9450-11507","score":14.0811986412,"text":"\nBe sure that you have [set the identity](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identitiesibp-console-identities-ca-identity) to a CA admin that has the ability to register new users before you attempt this task. In general, this is your admin user. If the button is gray, you have either not set an identity, or that the identity cannot create new identities.\n\nClicking Register user opens a series of side panels:\n\n\n\n1. On the first side panel, enter the Enroll ID and Enroll Secret of the new identity. Save these values, as they are not stored by the console.\n2. Select the identity Type. The drop-down list contains the list of types that the CA supports. If you are registering an identity that will serve as an admin of a node, select type admin. If you are registering a peer identity select peer and likewise for an ordering node identity select orderer. When you need to register an identity for a client application select the type client.\n3. You can associate an affiliation with the user. Check the Use root affiliation checkbox for the user if you want them to have the root affiliation and be able to see all other users registered with this CA. When you deselect Use root affiliation, you can select a specific affiliation from the list to associate with this user. The platform includes the default affiliation ibp.\n4. Enter the Maximum Enrollments allowed for this identity. If not specified, the value defaults to unlimited enrollments.\n5. On the last side panel, add the Attributes of the identity you are creating.\n\n\n\nAfter you click Register, the new identity will be added to the list of Authenticated users that have been created by your CA. The identities are listed by their Enroll ID, along with their Type and Affiliation. Clicking on an identity in the table opens a side panel that displays the number of Maximum Enrollments and Attributes that were created during registration.\n\nDeleting a user\nIf you need to delete a registered user, click the action menu next to any user and select Delete user.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identities"},{"document_id":"ibmcld_16234-7-1792","score":14.0583859352,"text":"\nManaging access \n\nIf you need to collaborate with others on your assistants, you can quickly add users to your service instance from the Manage menu. Or to tailor specific access to your assistants, use the [Identity and Access Management (IAM) page](https:\/\/cloud.ibm.com\/iam\/users) in IBM Cloud.\n\n\n\n Adding users from the Manage menu \n\nIn the new Watson Assistant, each assistant contains all the draft and live resolution methods (actions and search integration) and channels you add (such as web chat, Facebook, or Slack). The simplest way to provide access is to add users to your Watson Assistant service instance with manager access to all assistants. Users get all the privileges that they need to build and deploy any assistant.\n\nTo quickly add users with manager access to all assistants, complete the following steps:\n\n\n\n1. Open the Manage menu. ![Manage menu](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/user--avatar.svg)\n2. Click Add users.\n3. Enter the email addresses of the users that you want to provide full access to. Separate email addresses with commas, spaces, or line breaks.\n\nZoom\n\n![Add users](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/add-users.png)\n\nAdd users\n\nAdding users from this menu enables them to read, write, and manage all assistants in the service instance.\n4. Click Submit.\n\n\n\nAfter you click Submit, any user that you invite receives an email to access the instance. After they accept the invite, they can open the service instance and manage all assistants.\n\n\n\n\n\n Managing access with Identity and Access Management \n\nAnother way to add users to your assistants is using Identity and Access Management (IAM).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-access-control"},{"document_id":"ibmcld_02774-5358-7120","score":13.9326442646,"text":"\nA user's predefined attributes are empty until their first authentication. Although they're empty, the user is still fully authenticated. You can use their profile ID just as you would someone who has already signed in. For instance, you can modify, search, or delete the profile.\n\n\n\n Before you begin \n\nBefore you get started, you must have the following information:\n\n\n\n* Which identity provider that the user will sign in with.\n* The email of the user that you want to add or their [unique identifier](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-preregisterpreregister-idp-provide).\n* The [custom attribute](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-profiles) information that you want to assign.\n\n\n\n\n\n\n\n With the GUI \n\nYou can add a future user and their custom attributes by using the GUI.\n\nThe ability to add future users is disabled for the user name and password configuration of Cloud Directory.\n\n\n\n1. Go to the User Profiles tab of the App ID dashboard.\n2. Click Future users. If you already have future users, you see a table with a list of the user's that you already added. To add another user, click Build a profile. If you don't have any users yet, click Get Started. A screen opens.\n3. Enter your user's email.\n4. Select the identity provider that they sign in with from the Identity Provider drop down.\n5. Add custom attributes by entering the information in a JSON object as shown in the following example.\n\n{\n\"food\": \"Pizza\",\n\"preference\": \"Vegetarian\",\n\"points\": \"37\"\n}\n6. Click Save. The table displays and the user is assigned an identifier.\n\n\n\n\n\n\n\n With the API \n\nYou can add a future user and their custom attributes by using the API.\n\n\n\n1. Log in to IBM Cloud.\n\nibmcloud login\n2. Find your IAM token by running the following command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-preregister"},{"document_id":"ibmcld_06966-6860-8310","score":13.9040544338,"text":"\nFor more information, see [Giving users access to a Watson Discovery instance](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/svc-discovery\/discovery-admin-add-users.html).\n3. Enable document-level security for the data source when you connect to it.\n\n\n\n\n\n Creating users for document-level security \n\nYou must create users that match the users available on the source system that Discovery is connecting to so that they can query with document-level security enabled.\n\n\n\n1. Log in to Discovery as an administrator.\n2. Create users who match the users available on your source or who are connected to the identity provider that your source system uses. If you create users for document-level security, keep the following points in mind:\n\n\n\n* Optional: For each user that you want to have access to query results, you must add users. The username must match the username that the source uses. This option is only for development and testing purposes. To create users individually, see [Managing users](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/cpd\/admin\/users.html).\n* To connect to an identity provider that the source is using, see [Connecting to your identity provider](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/cpd\/admin\/ldap.html).\n\n\n\n\n\nDiscovery does not synchronize changes that are made to the users in the identity provider with the user list for the service. Discovery administrators must ensure that the user list is current and remove any noncurrent users.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collection-types"},{"document_id":"ibmcld_03966-11017-13066","score":13.696807749,"text":"\nAfter you click Register, the new identity will be added to the list of Authenticated users that have been created by your CA. The identities are listed by their Enroll ID, along with their Type and Affiliation. Clicking on an identity in the table opens a side panel that displays the number of Maximum Enrollments and Attributes that were created during registration.\n\nDeleting a user\nIf you need to delete a registered user, click the action menu next to any user and select Delete user. If that option is not available, it can be enabled on your CA by overriding the CA configuration. See an example of how to enable this feature in [Modifying a CA configuration after deployment](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-ca-modify-json). Note this action does not revoke the associated certificates for the user. If you need to do that you would need to insert the associated signed certificate into the organization MSP under the \"revocation_list\": section. And then update that MSP definition everywhere that it occurs on the network.\n\n\n\n Creating new CA admins \n\nBy default, only the CA admin that is created during deployment has the ability to register new identities. You can create identities with the ability the register new users by using the Attributes panel of the registration process.\n\nOn the second side panel, click the Add Attribute button. Provide an attribute name of hf.Registrar.Roles. Enter an attribute value of . You can also use this panel to create an identity that can register only certain identity types, such as clients or peers, or within a certain affiliation. You can also create an identity that has the ability to revoke an identity and all the certificates that the identity has been issued. You can see a full list of the attributes in the [Registering a new identity](https:\/\/hyperledger-fabric-ca.readthedocs.io\/en\/release-1.4\/users-guide.htmlregistering-a-new-identity) section of the Fabric CA users guide.\n\n\n\n\n\n\n\n Enrolling an identity","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identities"},{"document_id":"ibmcld_02766-7-2005","score":13.5447882794,"text":"\nManaging authentication \n\nIdentity providers (IdP's) add a level of security for your mobile and web apps, through authentication. With IBM Cloud\u00ae App ID, you can configure one or several identity providers to create a custom sign-in experience for your users.\n\nApp ID interacts with identity providers by using various protocols such as OpenID Connect, SAML, and more. For example, OpenID Connect is the protocol that is used with many social providers such as Facebook, Google. Enterprise providers such as [Azure Active Directory](https:\/\/www.ibm.com\/cloud\/blog\/setting-ibm-cloud-app-id-azure-active-directory) or [Active Directory Federation Service](https:\/\/www.ibm.com\/cloud\/blog\/setting-ibm-cloud-app-id-active-directory-federation-service), generally use SAML as their identity protocol. For [Cloud Directory](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cloud-directory), the service uses SCIM to verify identity information.\n\nWhen you use social or enterprise identity providers, App ID reads user account information. Because the service never has write access to the information, users must go through their chosen identity provider to do actions, such as resetting their password. For example, if a user signs in to your app with Facebook, and then wanted to change their password, they must go to www.facebook.com to do so.\n\nWhen you use [Cloud Directory](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cloud-directory), App ID is the identity provider. The service uses your registry to verify your users identity. Because App ID is the identity provider, users can take advantage of advanced functionality, such as resetting their password, directly in your app.\n\nWorking with application identity? Check out [Application identity](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-app).\n\nSeveral identity providers can be configured to be used by App ID. Check out the following table to learn about your options.\n\n\n\nTable 1. Identity provider options\n\n Identity provider Type Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-managing-idp"},{"document_id":"ibmcld_03871-30641-32553","score":13.502619296,"text":"\nEnter the User ID for the console instance.\n6. Enter the Password for the console instance.\n7. Select Proceed without certificate verification, or Cancel if you're planning to add the CA certificates to the operating systems trusted CA certificate store.\n8. Enter a name for your environment.\n9. Select the CAs and peers that belong to your organization, along with the ordering nodes of your channels, click OK when done.\n\n\n\nIn steps 5 and 6, you can alternatively enter an API key and secret that you generate using the [IBM Blockchain Platform REST APIs](https:\/\/cloud.ibm.com\/docs\/blockchain-sw-254?topic=blockchain-sw-254-ibp-v2-apisconsole-icp-manage-create-api-key).\n\nYou also need to import your admin identities into the wallet pane and associate them with your nodes. You need to associate an admin identity with your peers, CA, and an ordering node before you can connect with your network.\n\n\n\n1. Click on the environment that you created in the Fabric Environments pane.\n2. You can see an Alert sign next to the peer and ordering node. Click on the alert to associate an admin identity with the node.\n3. Select Add a new wallet.\n4. Select Create a new wallet.\n5. Enter a name for your wallet to identify the orderer or peer admin of your network.\n6. Select Add a new identity.\n7. Enter name for your peer or orderer admin identity.\n8. Select Provide a JSON identity file from the IBM Blockchain Platform and then browse to the admin identity that you exported from your console. If the identity is the administrator of multiple nodes in your network, you can associate the identity with multiple nodes.\n\n\n\nWhen you have associated an admin identity with your peers, CA, and an ordering node, you can connect to your network and use the extension to deploy smart contracts.\n\n\n\n\n\n\n\n Adding wallets and users \n\nUse the following steps to create a new wallet by using a certificate and private key:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-develop-vscode"},{"document_id":"ibmcld_02734-7-2170","score":13.4902179759,"text":"\nAnonymous authentication \n\nWith IBM Cloud\u00ae App ID, you can allow users to anonymously browse your application under an anonymous user profile. If the user chooses to sign in, you can allow them to still access their anonymous attributes by attaching their anonymous profile to their user identity with App ID.\n\n\n\n Understanding progressive authentication \n\nWhen a user chooses not to sign in immediately, they are considered an anonymous user. For example, say you're an online retailer and you want to allow users to add objects to their shopping cart without signing in. However, you ask them to sign in to complete their purchase. If a user chooses to sign in, you can allow them to access the same objects that were in their shopping carts before they signed in.\n\nYou can use App ID to gather information about anonymous users into an anonymous user profile, which you can use to help personalize their experience of your application. If the user chooses to signs in, you can attach the user attributes that are part of the anonymous profile to their user identity that is stored in App ID. Anonymous profiles are temporarily valid. While you develop your app, you can [configure the lifetime](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-managing-idpidp-token-lifetime) of anonymous tokens.\n\nWhen a user signs in, they become an identified user. If an existing identified user profile does not exist, you can create a new identified user profile. After a user is identified, App ID issues new access and identity tokens and their anonymous token becomes invalid. However, an identified user can still access the attributes of their anonymous profile because they are accessible with the new access and identity tokens.\n\nYou can attach the attributes of only one anonymous profile to the user's identity that is stored in App ID. For example, say that a user browses your application anonymously in two separate browser tabs. The user adds a t-shirt to the shopping cart on the first tab and a pair of shorts to the cart on the second tab. App ID creates two separate anonymous profiles to track the interactions of the user with your application on each tab.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-anonymous"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16384-1889-3334","score":25.6767846313,"text":"\nYou can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.\n\n\n\n* [How the web chat works](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture): Overview of web chat capabilities and architecture\n* [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat): How to embed the web chat widget on your website\n* [Web chat setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to configure the web chat using the integration settings\n* [Web chat development](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to customize and extend the web chat by writing code\n* [Adding contact center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat-haa): How to integrate the web chat with a contact center platform so you can connect your customers to human agents","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16377-7-1723","score":24.9178931725,"text":"\nTutorial: Displaying a pre-chat or post-chat form \n\nThis tutorial shows how you can display pre-chat form before the web chat opens, or a post-chat form that opens after the web chat closes.\n\nFor a complete, working version of the example described in this tutorial, see [Pre and post-chat forms for Watson Assistant web chat](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/pre-post-chat-forms).\n\nIf you want to gather information from your customers before starting a chat session, you can display a pre-chat form before opening the web chat. Similarly, you might want to display a form after the web chat closes (for example, a customer satisfaction survey). You can use the same approach for either situation.\n\nWhen the web chat is opened or closed, it fires an [event](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-events) that you can subscribe to. In your event handler, you can use the [custom panels](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-rendercustompanel) feature to open a panel with custom content.\n\nBy returning a promise that is resolved when the custom panel closes, you can pause the process of opening or closing the web chat until after the customer completes the form.\n\nThis example shows how to create a pre-chat form. To create a post-chat form, follow the same steps, but subscribe to the window:pre:close event instead of the window:open event.\n\nTo display a pre-chat form, follow these steps:\n\n\n\n1. Create a handler for the [window:open](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-eventswindowpreopen) event, which is fired when the web chat opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-pre-chat"},{"document_id":"ibmcld_16365-7-1700","score":24.9108838372,"text":"\nHow the web chat works \n\nThe web chat provides an easy-to-use chatbot interface that you can add to your website without writing any code.\n\nAfter you add the web chat script to your website, your customers will see a launcher icon that they can click to open the chat window and start a conversation with the assistant. The appearance of the launcher icon adapts to desktop and mobile browsers.\n\n![web chat launcher in desktop browser](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-desktop-highlighted.png)\n\nWhen a customer clicks the launcher, the web chat window opens, initially displaying the home screen. The home screen displays a greeting and an optional set of suggested conversation starters for common questions and problems. The customer can either click a conversation starter or type a message in the input field to start the conversation with the assistant.\n\n![web chat example home screen](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-home-screen-lendyr.png)\n\nThe appearance and behavior of the launcher icon, the home screen, and most other aspects of the web chat can be configured and customized to match your website style and branding. For more information, see [Configuring the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16366-2985-3766","score":24.8002979423,"text":"\nFor more information, see [Configuring the home screen](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-configure-home-screen).\n\nSuggestions\n: You can configure how and when the web chat offers offers suggestions to customers when the assistant isn't delivering what they expect. For more information, see [Configuring suggestions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-suggestions).\n\nSecurity\n: You can protect your users' private information and prevent unauthorized messages to your assistant by enabling security on the Security tab. For more information about web chat security and how it works, see [Security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture-security).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config"},{"document_id":"ibmcld_16384-7-2422","score":24.6801180152,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16334-23017-24816","score":24.499820339,"text":"\n* Support for Carbon components: As part of the new styling support, you can now use [Carbon components](https:\/\/www.carbondesignsystem.com\/components\/overview\/) in user-defined responses and web chat writeable elements. These components will inherit any theming customizations you have made to the web chat.\n* New embedded script: The embedded script you use to add the web chat to your website has been updated to avoid unexpected code changes when you lock on to a web chat version. (For more information about web chat versioning, see [Versioning](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basicsweb-chat-basics-versions).) The previous version of the script will continue to work but is now deprecated. If you want to upgrade your existing web chat deployments to use the new script, copy the updated code snippet from the Embed tab of the web chat integration settings. (Remember to reapply any customizations you have made.)\n* Removal of deprecated methods and events:\n\n\n\n* The error event has been replaced by the onError method in the [configuration object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/testfest.html?to=api-configurationconfigurationobject).\n* The getID method has been removed.\n\n\n\n* Microsoft Internet Explorer 11 is no longer a supported browser.\n\n\n\n\n\n\n\n 4.5.1 \n\nRelease date: 30 August 2021\n\n\n\n* Bug fixes for the interactive launcher beta feature. (For more information about this feature, see the launcherBeta configuration option at [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).)\n\n\n\n\n\n\n\n 4.5.0 \n\nRelease date: 29 July 2021\n\n\n\n* A new scrollToMessage method is available for scrolling the web chat view to a specified message in the chat history.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-release-notes-chat"},{"document_id":"ibmcld_16380-7-2028","score":24.4217773363,"text":"\nTutorial: Customizing the size and position of the web chat \n\nThis tutorial shows how you can change the size and position of the web chat by rendering it in a custom element.\n\nFor a complete, working version of the example described in this tutorial, see [Custom elements for Watson Assistant web chat](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/custom-element).\n\nBy default, the web chat interface on your website is rendered in a host div element that is styled to appear in a fixed location on the page. If you want to change the size or position of the web chat, you can specify a custom element as the host location for the web chat. This host element is used as the location for both the main web chat interface and for the web chat launcher (unless you are using a custom launcher).\n\nWhen you use a custom element, you also take control of showing and hiding the web chat when it is opened or closed (such as when the customer clicks the launcher icon or the minimize button). This gives you the opportunity to apply additional effects, such as opening and closing animations. You can control showing and hiding the main window by using the [addClassName() and removeClassName()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodselements-get-main-window) functions.\n\nTo use a custom element, follow these steps:\n\n\n\n1. In your website code, define the custom element where you want the web chat to be rendered. There are many ways of doing this, depending on the framework you are using. A simple example is to define an empty HTML element with an ID:\n\n<div id=\"WebChatContainer\"><\/div>\n2. Get a reference to your custom element so you can reference it in the web chat configuration. To get a reference, use whatever mechanism makes sense for the library you are using. For example, you can save the reference returned from document.createElement(), or you can use a query function to look up the element in the DOM.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-size-position"},{"document_id":"ibmcld_16368-6482-8187","score":23.8123314083,"text":"\n[development icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/development-icon.png)Example: For a working example that shows how to add custom elements to the home screen, see [Home screen custom elements for Watson Assistant web chat](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/home-screen-custom-element).\n* To change the home screen style, use [CSS helper classes](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-renderhelper_classes).\n\n\n\nCustomizing strings\n: You can customize the strings that define the various labels and hardcoded phrases displayed by the web chat. To customize strings, use the [updateLanguagePack()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsupdatelanguagepack) instance method to replace strings in the current language pack. For more information, see [Languages](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslanguages).\n\nSupporting global audiences\n: By default, the strings displayed by the web chat are in English. To change to a different language, use the [updateLanguagePack()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsupdatelanguagepack) instance method to replace the current language pack with one of the available translated language packs. For more information, see [Supporting global audiences](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-global).\n\n\n\n\n\n Opening, closing, and rendering the web chat window \n\nReplacing the default launcher","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_16381-0-734","score":23.7616411723,"text":"\n\n\n\n\n\n\n  Web chat development tutorials \n\nThe tutorials in this section provide detailed examples, including code snippets, showing customizations that you can implement using the web chat API.\n\nEach tutorial includes links to a [GitHub repository](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/) where you can download complete working code for the example. You can run this code to see the customization in action, adapt it for your own web chat implementation, or use it as a guide for similar customizations of your own.\n\nThe GitHub repository also includes additional tutorials and examples that have not yet been added to this documentation, so feel free to browse.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-tutorials"},{"document_id":"ibmcld_16365-10062-12114","score":23.5172583485,"text":"\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Accessibility \n\nIBM strives to provide products with usable access for everyone, regardless of age or ability.\n\nThe web chat integration complies with the [Web Content Accessibility 2.1 Level AA](https:\/\/www.w3.org\/WAI\/standards-guidelines\/wcag\/new-in-21\/) standard. It is tested with both screen readers and automated tools on a continual basis.\n\n\n\n\n\n Language support \n\nBy default, the web chat displays hardcoded labels and messages in English, but support is built in for all of the languages supported by Watson Assistant. You can also choose from a wide selection of locales to customize the display of strings like dates and times for global audiences.\n\nIn whichever language you are using, you can also customize the text of any hardcoded strings.\n\nFor more information, see [Supporting global audiences](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-global).\n\n\n\n\n\n Security \n\nBy default, all messages that are sent between the web chat and the assistant are encrypted using Transport Layer Security (TLS). You can enable the web chat security feature if you need more robust protection.\n\nThe web chat embed script that you include on your website contains unique identifiers (such as the integration ID and service instance ID) that enable the web chat to connect with your assistant. These identifiers are not considered secret, and are visible to anyone who has access to your website. Anyone who has these IDs could use them to send messages to your assistant and receive its replies. However, these IDs cannot be used to log in to your account, make any changes to your assistant, or retrieve logs or analytics information about your assistant.\n\nIf you are concerned about unauthorized access to your assistant, you can enable the web chat security feature for additional security, such as verifying message origin and authenticating users. Enabling the security feature requires additional development work on your website.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.234639363,"ndcg_cut_10":0.234639363}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05873-73055-74805","score":13.7528305453,"text":"\n: All istio-monitoring support is deprecated in version 1.7 of the Istio add-on and is automatically removed in version 1.8 of the Istio add-on. To use monitoring with Istio, you must install the components separately from the Istio add-on.\n: For more information, see the [Istio documentation](https:\/\/istio.io\/latest\/docs\/ops\/integrations\/).\n: The istio-ingressgateway-public-(n)-enabled and istio-ingressgateway-zone-(n) options in the [managed-istio-custom ConfigMap resource](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istiocustomize) are generally available for production use.\n\n\n\n\n\n\n\n Version 1.6 (unsupported) \n\nVersion 1.6 of the managed Istio add-on is unsupported. (: deprecated)\n\n\n\n Differences between version 1.6 of managed and community Istio \n\nReview the following differences between the installation profiles of version 1.6 of the managed IBM Cloud Kubernetes Service Istio and version 1.6 of the community Istio.\n\nTo see options for changing settings in the managed version of Istio, see [Customizing the Istio installation](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istiocustomize).\n\n\n\nTable 1. Differences between the managed IBM Cloud Kubernetes Service Istio and the community Istio\n\n Setting Differences in the managed Istio add-on \n\n meshConfig.enablePrometheusMerge=true and values.telemetry.v2.enabled=true In the managed Istio add-on, support for telemetry with IBM Cloud Monitoring is enabled by default. This support can be disabled by [customizing the Istio installation](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istiocustomize). \n istio-ingressgateway and istio-egressgateway In the managed Istio add-on, placement of gateways on edge worker nodes is preferred, but not required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istio-changelog"},{"document_id":"ibmcld_05873-80552-82182","score":13.6672576328,"text":"\n* [CVE-2020-1752](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2020-1752).\n\n\n\n: For more information, see the [Istio security bulletin 2020-008](https:\/\/istio.io\/latest\/news\/security\/istio-security-2020-008\/)\n\n\n\n\n\n Change log for 1.6, released 08 July 2020 \n\nReview the changes that are in version 1.6 of the managed Istio add-on.\n\nPrevious version\n: 1.5.7\n\nCurrent version\n: 1.6\n\nUpdates in this version\n: See the Istio release notes for [Istio 1.6](https:\/\/istio.io\/latest\/news\/releases\/1.6.x\/announcing-1.6\/).\n: Support is added for the istio-knative-cluster-local-gateway-enabled and istio-monitoring-telemetry options in the [managed-istio-custom ConfigMap resource](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istiocustomize). You can use these options to manage inclusion of Knative apps in the service mesh and the Istio telemetry enablement. Support for IBM Cloud Monitoring is enabled for Istio by default.\n\n\n\n\n\n\n\n Version 1.5 (unsupported) \n\nVersion 1.5 of the managed Istio add-on is unsupported. (: deprecated)\n\n\n\n Differences between version 1.5 of managed and community Istio \n\nReview the following differences between the installation profiles of version 1.5 of the managed IBM Cloud Kubernetes Service Istio and version 1.5 of the community Istio.\n\nTo see options for changing settings in the managed version of Istio, see [Customizing the version 1.5 Istio installation](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istiocustomize).\n\n\n\nTable 1. Differences between the managed IBM Cloud Kubernetes Service Istio and the community Istio\n\n Setting Differences in the managed Istio add-on","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istio-changelog"},{"document_id":"ibmcld_05873-81662-83420","score":13.0193811065,"text":"\nReview the following differences between the installation profiles of version 1.5 of the managed IBM Cloud Kubernetes Service Istio and version 1.5 of the community Istio.\n\nTo see options for changing settings in the managed version of Istio, see [Customizing the version 1.5 Istio installation](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istiocustomize).\n\n\n\nTable 1. Differences between the managed IBM Cloud Kubernetes Service Istio and the community Istio\n\n Setting Differences in the managed Istio add-on \n\n egressGateways[name: istio-egressgateway].enabled: true In the managed Istio add-on, the egress gateway is enabled by default. \n istiod, istio-ingressgateway, and istio-egressgateway In the managed Istio add-on, istiod and all Istio ingress and egress gateways are set up for basic high availability support. High availability support on these components includes the following settings by default: node anti-affinity, HorizontalPodAutoscaler, PodDisruptionBudget, and automatic scaling of replicas. \n prometheus.enabled: false In the managed Istio add-on, the Prometheus, Grafana, Jaeger, and Kiali monitoring components are disabled by default due to current security concerns in the community release of Istio that can't be adequately addressed for a production environment. \n values.global.pilot.enableProtocolSniffingForInbound and values.global.pilot.enableProtocolSniffingForOutbound In the managed Istio add-on, protocol sniffing is disabled by default until the feature becomes more stable in the community Istio. \n\n\n\n\n\n\n\n Change log for 1.5.10, released 1 September 2020 \n\nReview the changes that are in version 1.5.10 of the managed Istio add-on.\n\nPrevious version\n: 1.5.9\n\nCurrent version\n: 1.5.10\n\nUpdates in this version","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istio-changelog"},{"document_id":"ibmcld_03369-1415-3586","score":12.7139809533,"text":"\nThese changes are the result of migrating the Watson Assistant platform to Java 17, where locale values are updated by using specifications in [CLDR 39](https:\/\/cldr.unicode.org\/index\/downloads\/cldr-39).\n\nTo avoid or minimize the impact of similar changes in the future, you can use [Actions display formats](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-global-settingsactions-global-settings-display-formats).\n\n\n\n\n\n 18 May 2023 \n\nDifferences in contextual entity detection for dialog skills with few annotations\n: If you have 10 to 20 examples of contextual entities in your dialog skill, you might see differences in the entities detected due to updates made to address critical vulnerabilities. The impact of these differences is limited to only newly-trained models. Existing models are unaffected. You can mitigate these differences by annotating more examples. For more information, see [Annotation-based method](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entitiesentities-annotations-overview).\n\n\n\n\n\n 15 May 2023 \n\nChange to dialog skill context variables named request\n: If your dialog skill used a context variable that is named request, it was removed from the response payload of any \/message calls in the V1 or V2 API, or through the Watson Assistant user interface. After 15 May 2023, this behavior changes. Watson Assistant doesn't remove context variables that are named request from the response payload anymore.\n\n\n\n\n\n 3 May 2023 \n\nAlgorithm version Beta provides improved intent detection and action matching\n: The algorithm version Beta now provides improved intent detection and action matching. It includes a new foundation model that is trained using a transformer architecture to improve intent detection and action matching for English.\n\nImprovements include:\n\n\n\n* Improved robustness to variations in user inputs such as typos and different inflection forms\n* Less training data required to reach the same level of performance compared to previous algorithms\n\n\n\nFor more information, see [Algorithm version and training](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-algorithm-version).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_16302-0-1237","score":12.438914011,"text":"\n\n\n\n\n\n\n  Publishing dialog and actions \n\nIf the dialog feature is enabled, the publishing and deployment processes remain the same. However, some slight differences in functionality exist.\n\nTo learn about the overall publishing and deployment model for Watson Assistant, see the [Publishing and deploying your assistant overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overview). For more information about the Publish page and how the publishing process works, see [Publishing your content](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish). The following slight differences exist when the dialog feature is enabled in an assistant:\n\n\n\n*  On the Publish page, the information in the Content type column lists whether your content changes contain a dialog.\n*  The version tiles on the Publish and Environments pages show whether the published content contains actions, or actions and a dialog. For example, if the dialog feature is enabled in your assistant, the version tile displays Contains actions & dialog.\n*  When you export a version of your content from the Publish page, two JSON files are downloaded. One file is for actions and one file is for the dialog.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-dialog-publish"},{"document_id":"ibmcld_06941-0-1401","score":12.1320880914,"text":"\n\n\n\n\n\n\n  Migration FAQ \n\nFind answers to questions that are commonly asked about migrating from Discovery v1 to v2.\n\nDo the two versions have all the same features?\n:   There are many feature differences between the two versions. For a full feature comparison, see [Getting the most from Discovery](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-version-choose).\n\nHow do I know which version I'm using now?\n:   When you open the product user interface in v2, the following page is displayed:\n\nZoom\n\n![Shows the main My Projects page with a single Sample Project tile.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/gs-home-page.png)\n\nFigure 1. Home page from the Sample Project\n\nHow long will the migration take?\n:   The time you need to set aside for the migration differs based on the amount of data you want to retain in your existing v1 service instance.\n\nDo I need to update my existing applications for them to work with v2?\n:   Yes. You will need to edit any existing applications to account for changes that are introduced with Discovery v2. For more information, see the [API version comparison](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2-api).\n\nTo get started, see [Migrating to Discovery v2](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data--migration-faq"},{"document_id":"ibmcld_07067-1816-3544","score":12.1080660403,"text":"\n* For more information about feature differences, see [the feature comparison table](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-version-chooseversion-choose-comparison).\n* For more information about detailed API differences, see [API version comparison](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2-api).\n\n\n\nDiscovery v2 is available for all users of Plus or Enterprise plan instances, or Premium plan instances that were created after 15 July 2020. v2 is also available for IBM Watson\u00ae Discovery Cartridge for IBM Cloud Pak\u00ae for Data users.\n\n\n\n Migration overview \n\nMigrating from Discovery v1 to v2 is a multistep process that you can do independently.\n\nThe two versions of the Discovery service have many differences, but you can adopt techniques and utilities that were applied to a v1 instance for use with your new v2 instance.\n\nTo migrate from v1 to v2, you must complete the following high-level steps:\n\n\n\n1. [Plan the migration](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2migrate-to-v2-plans).\n2. [Transfer your documents](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2migrate-to-v2-docs).\n3. [Update your application to use the v2 API](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2migrate-to-v2-difs).\n4. Regression test and deploy the updated application.\n5. [Delete your v1 plan service instance](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2migrate-to-v2-delete).\n\n\n\nSome steps require you to make programmatic changes by using the API and others involve changes that you can make from the product user interface.\n\n\n\n\n\n Plan the migration","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2"},{"document_id":"ibmcld_10534-328324-329702","score":11.8811801861,"text":"\n(https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkbenchmark-meaning)\n* [What parts of the benchmark am I responsible for?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkbencmark-resp)\n* [What if some part of the service fails to comply with a recommendation?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkbencmark-service-compliance)\n* [What else can I do to increase the security and compliance of my cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkbenchmark-what-else)\n\n\n\n* [Running the worker node CIS Kubernetes benchmark](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkcis-worker-test)\n\n\n\n[Comparing the CIS Kubernetes and the Compliance Operator benchmarks](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-benchmark-comparisonbenchmark-comparison)\n\n\n\n* [Major differences](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-benchmark-comparisonbenchmark-comparison-major)\n* [Minor differences](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-benchmark-comparisonbenchmark-comparison-minor)\n\n\n\n\n\n Version 4.13 \n\n[4.13 version information and update actions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_versions_413cs_versions_413)\n\n\n\n* [Release timeline](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_versions_413release_timeline_413)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_07068-7-1672","score":11.7598409896,"text":"\nAPI version comparison \n\nFor most API methods, the request parameters and response bodies differ between v1 and v2. Learn about the equivalent or alternative v2 methods that you can use to do actions that are supported by the v1 API.\n\nThe comparison information assumes you are using the latest version of the v1 API (version 2019-04-30) and compares it to the latest version of the v2 API (version 2020-08-30).\n\n\n\n Environments \n\nThere is no concept of an environment in v2. The deployment details such as size and index capacity are managed based on the service plan type. In v2, collections are organized in projects. You can create different types of projects to apply default configuration settings to the collections that you add to the projects.\n\nThere are no equivalent methods in v2 for the v1 environment methods. However, the following table shows v2 methods that serve similar functions to the corresponding v1 methods. The supported parameters and response bodies that are returned for each method differ also.\n\n\n\nEnvironment API action support details\n\n Action v1 API Related v2 API \n\n Create an environment [POST \/v1\/environments](https:\/\/cloud.ibm.com\/apidocs\/discoverycreateenvironment) [POST \/v2\/projects](https:\/\/cloud.ibm.com\/apidocs\/discovery-datacreateproject) \n List environments [GET \/v1\/environments](https:\/\/cloud.ibm.com\/apidocs\/discoverylistenvironments) [GET \/v2\/projects](https:\/\/cloud.ibm.com\/apidocs\/discovery-datalistprojects) \n Get environment info [GET \/v1\/environments\/{environment_id}](https:\/\/cloud.ibm.com\/apidocs\/discoverygetenvironment) [GET \/v2\/projects\/{project_id}](https:\/\/cloud.ibm.com\/apidocs\/discovery-datagetproject)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2-api"},{"document_id":"ibmcld_14105-0-1469","score":11.6180566177,"text":"\n\n\n\n\n\n\n  Differences between versions of XenServer \n\nLicensing is the only difference between versions of XenServer that are installed on the system. If you want to upgrade your license to a higher class license after installation, you experience no downtime to reinstall your server. Contact IBM Cloud\u00ae sales for pricing information.\n\nNote: Not all available features are supported.\n\nThe following lists of features are included for each of the different licenses that are offered (as of XenServer 6.0):\n\nXenServer free, advanced, enterprise license features\n\n\n\n*  XenServer Hypervisor\n*  Conversion Tools\n*  Management integration with Microsoft System Center VMM\n*  Resilient distributed management architecture\n*  VM disk snapshot and revert\n*  XenCenter Management Console\n*  XenMotion Live Migration\n\n\n\nXenServer advanced and enterprise license features\n\n\n\n*  Automated VM protection and recovery (Automated VM protection and recovery is only available for the Advanced and Enterprise editions in the 6.0 release and later.)\n*  Distributed virtual switching\n*  Heterogeneous Pools\n*  High Availability\n*  Memory Optimization\n*  Performance alerting and reporting\n\n\n\nXenServer Enterprise license features\n\n\n\n*  Dynamic workload balancing\n*  GPU pass-thru\n*  Host power management\n*  IntelliCache\n*  Live memory snapshot and revert\n*  Provisioning Services (virtual)\n*  Role-based administration\n*  StorageLink\n*  Web management console with delegated admin\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtualization?topic=virtualization-differences-between-versions-of-xenserver"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10140-2632-4302","score":12.5151372407,"text":"\nVersion 1.0.480 of the CLI was released on 14 December 2022.\n: Adjusted ibmcloud oc flavor get and ibmcloud oc flavor ls commands to show secondary storage details.\n: Introduced Secondary Storage Configuration for worker-pool get.\n: Added Ignored Errors to ingress status-report.\n\n\n\n\n\n Version 1.0.471 \n\nVersion 1.0.471 of the CLI was released on 1 December 2022.\n: Adds new endpoint type vpe(Virtual Private Endpoint) for cluster config command.\n: Updates the cluster get command to show VPE url.\n: Adds infrastructureTopology field to cluster response.\n: Adds JSON output to Satellite get host command.\n\n\n\n\n\n Version 1.0.459 \n\nVersion 1.0.459 of the CLI was released on 21 October 2022.\n: Adds the --infrastructure-topology option for the ibmcloud oc cluster create satellite command.\n: Adds new ibmcloud oc flavor get and ibmcloud oc flavor ls commands.\n\n\n\n\n\n Version 1.0.454 \n\nVersion 1.0.454 of the CLI was released on 3 October 2022.\n: Adds new [Ingress status](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clialb-commands) commands.\n: Adds the --operating-system option for the cluster create commands.\n\n\n\n\n\n Version 1.0.452 \n\nVersion 1.0.452 of the CLI was released on 21 September 2022.\n: Updates the help text in various languages.\n\n\n\n\n\n Version 1.0.446 \n\nVersion 1.0.446 of the CLI was released on 12 September 2022.\n: Adds --pod-network-interface-selection option to location create flow.\n\n\n\n\n\n Version 1.0.444 \n\nVersion 1.0.444 of the CLI was released on 8 September 2022.\n: Adds Secrets Manager registration to cluster create flow.\n: Adds worker-pool OS support.\n: Removes Ingress migration command support.\n\n\n\n\n\n Version 1.0.439","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelog"},{"document_id":"ibmcld_05684-2632-4362","score":12.4487422585,"text":"\nVersion 1.0.480 of the CLI was released on 14 December 2022.\n: Adjusted ibmcloud ks flavor get and ibmcloud ks flavor ls commands to show secondary storage details.\n: Introduced Secondary Storage Configuration for worker-pool get.\n: Added Ignored Errors to ingress status-report.\n\n\n\n\n\n Version 1.0.471 \n\nVersion 1.0.471 of the CLI was released on 1 December 2022.\n: Adds new endpoint type vpe(Virtual Private Endpoint) for cluster config command.\n: Updates the cluster get command to show VPE url.\n: Adds infrastructureTopology field to cluster response.\n: Adds JSON output to Satellite get host command.\n\n\n\n\n\n Version 1.0.459 \n\nVersion 1.0.459 of the CLI was released on 21 October 2022.\n: Adds the --infrastructure-topology option for the ibmcloud ks cluster create satellite command.\n: Adds new ibmcloud ks flavor get and ibmcloud ks flavor ls commands.\n\n\n\n\n\n Version 1.0.454 \n\nVersion 1.0.454 of the CLI was released on 3 October 2022.\n: Adds new [Ingress status](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clialb-commands) commands.\n: Adds the --operating-system option for the cluster create commands.\n\n\n\n\n\n Version 1.0.452 \n\nVersion 1.0.452 of the CLI was released on 21 September 2022.\n: Updates the help text in various languages.\n\n\n\n\n\n Version 1.0.446 \n\nVersion 1.0.446 of the CLI was released on 12 September 2022.\n: Adds --pod-network-interface-selection option to location create flow.\n\n\n\n\n\n Version 1.0.444 \n\nVersion 1.0.444 of the CLI was released on 8 September 2022.\n: Adds Secrets Manager registration to cluster create flow.\n: Adds worker-pool OS support.\n: Removes Ingress migration command support.\n\n\n\n\n\n Version 1.0.439 \n\nVersion 1.0.439 of the CLI was released on 26 Aug 2022.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_cli_changelog"},{"document_id":"ibmcld_16034-7-1778","score":12.4471132541,"text":"\nVPC CLI release notes \n\nThe following release notes are for the IBM Cloud\u00ae Virtual Private Cloud (VPC) command line interface (CLI).\n\n\n\n v6.15.0 \n\nVersion 6.15.0 was released on 2023-07-11.\n\n\n\n New commands \n\n\n\n* New commands image-obsolete and image-deprecate are introduced to support image lifecycle management.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for image lifecycle management in image-create, image-update, and images commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.14.1 \n\nVersion 6.14.1 was released on 2023-06-30.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed issue with using the SSH key generated from UI in CLI.\n\n\n\n\n\n\n\n\n\n v6.14.0 \n\nVersion 6.14.0 was released on 2023-06-23.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for more algorithms in the SSH key key-create command.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.13.0 \n\nVersion 6.13.0 was released on 2023-06-22.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for snapshot and backup cross region copy in snaphot-create, snapshots, backup-policy-plan-create and backup-policy-plan-update commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.12.0 \n\nVersion 6.12.0 was released on 2023-06-01.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for fileshare mount targets in share commands (Beta).\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed bare-metal-server-network-interfaces, bare-metal-server-profiles and bare-metal-servers commands to print correct response values.\n\n\n\n\n\n\n\n\n\n v6.11.1 \n\nVersion 6.11.1 was released on 2023-05-03.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_10140-1312-2995","score":11.9582324436,"text":"\nVersion 1.0.510 of the CLI was released on 11 April 2023.\n: Adds support for Pod Security admission.\n: Resolved an issue about config file race conditions.\n: Updates the ibmcloud oc ingress domain create command output to return the full qualified domain.\n\n\n\n\n\n Version v1.0.498 \n\nVersion 1.0.498 of the CLI was released on 1 March 2023.\n: Adds the ibmcloud oc cluster master pod-security get command.\n: Updates the golang version to resolve [CVE-2022-41723](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=2022-41723).\n: Adds an Architecture field to the ibmcloud oc flavor get command output.\n: Improves formatting of the ibmcloud oc ingress secret ls command output.\n: When the ibmcloud oc cluster config command returns, you can run kubectl or oc commands immediately without a waiting period.\n\n\n\n\n\n Version 1.0.489 \n\nVersion 1.0.489 of the CLI was released on 30 January 2023.\n: Adds a fix where table headings are no longer printed if the output of a command contains no results.\n: Adds the --secondary-storage option to the cluster create vpc-gen2, worker-pool create vpc-gen2, and flavor get commands.\n\n\n\n\n\n Version 1.0.487 \n\nVersion 1.0.487 of the CLI was released on 24 January 2023.\n: Adds the satellite-service-endpoint allowlist commands\n: Updates the help text in various languages.\n\n\n\n\n\n Version 1.0.480 \n\nVersion 1.0.480 of the CLI was released on 14 December 2022.\n: Adjusted ibmcloud oc flavor get and ibmcloud oc flavor ls commands to show secondary storage details.\n: Introduced Secondary Storage Configuration for worker-pool get.\n: Added Ignored Errors to ingress status-report.\n\n\n\n\n\n Version 1.0.471 \n\nVersion 1.0.471 of the CLI was released on 1 December 2022.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelog"},{"document_id":"ibmcld_05684-1312-2995","score":11.9582324436,"text":"\nVersion 1.0.510 of the CLI was released on 11 April 2023.\n: Adds support for Pod Security admission.\n: Resolved an issue about config file race conditions.\n: Updates the ibmcloud ks ingress domain create command output to return the full qualified domain.\n\n\n\n\n\n Version v1.0.498 \n\nVersion 1.0.498 of the CLI was released on 1 March 2023.\n: Adds the ibmcloud ks cluster master pod-security get command.\n: Updates the golang version to resolve [CVE-2022-41723](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=2022-41723).\n: Adds an Architecture field to the ibmcloud ks flavor get command output.\n: Improves formatting of the ibmcloud ks ingress secret ls command output.\n: When the ibmcloud ks cluster config command returns, you can run kubectl or oc commands immediately without a waiting period.\n\n\n\n\n\n Version 1.0.489 \n\nVersion 1.0.489 of the CLI was released on 30 January 2023.\n: Adds a fix where table headings are no longer printed if the output of a command contains no results.\n: Adds the --secondary-storage option to the cluster create vpc-gen2, worker-pool create vpc-gen2, and flavor get commands.\n\n\n\n\n\n Version 1.0.487 \n\nVersion 1.0.487 of the CLI was released on 24 January 2023.\n: Adds the satellite-service-endpoint allowlist commands\n: Updates the help text in various languages.\n\n\n\n\n\n Version 1.0.480 \n\nVersion 1.0.480 of the CLI was released on 14 December 2022.\n: Adjusted ibmcloud ks flavor get and ibmcloud ks flavor ls commands to show secondary storage details.\n: Introduced Secondary Storage Configuration for worker-pool get.\n: Added Ignored Errors to ingress status-report.\n\n\n\n\n\n Version 1.0.471 \n\nVersion 1.0.471 of the CLI was released on 1 December 2022.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_cli_changelog"},{"document_id":"ibmcld_15810-126236-127921","score":10.8697895478,"text":"\nIBM virtual servers for VPC on POWER (Beta)\n: Create POWER-based instances for all virtual server families, including the addition of the GPU family (for POWER only). For more information, see [Profiles](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-profiles).\n\nUI enhancement\n: On the VPC details page, a new section is available to view source IP addresses for any cloud service endpoints you enabled. For more information, see [Service endpoints](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-service-endpoints-for-vpc).\n\nCLI plug-in release 0.5.9\n: Target a specific resource group by using the '[-g YOUR_GROUP]' command option. If you specify the target resource group by using the ibmcloud target [-g YOUR_GROUP]command, the output displays only VPC resources inside of the specified resource group. This update also introduces enhancements to some of the commands for get and list, showing more detail for your VPC, instances, and instance profiles. For more information, see [VPC CLI reference](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference).\n\n\n\n\n\n 02 December 2019 \n\nAccess control lists\n: Use an access control list (ACL) to control all incoming and outgoing traffic in IBM Cloud\u00ae Virtual Private Cloud. For more information, see [Setting up network ACLs](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-using-acls).\n\n\n\n\n\n\n\n November 2019 \n\n\n\n 14 November 2019 \n\nVPC layout\n: View resources that are associated with a VPC in the IBM Cloud console. For more information, see [Viewing resources associated with a VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-a-vpc-using-the-ibm-cloud-consolevpc-layout).\n\n\n\n\n\n 07 November 2019 \n\nLoad balancer (Beta)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-release-notes"},{"document_id":"ibmcld_04543-131969-133359","score":10.1490083998,"text":"\n* --classic-access: This flag lists VPCs that have classic access enabled. If unspecified, it returns all VPCs with and without classic access enabled. One of: true, false.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n\n\n Virtual private endpoint gateways \n\nThe following section gives details about the CLI commands that are available for working with endpoint gateways.\n\n\n\n ibmcloud is endpoint-gateway-targets \n\nList all resources can be set as target for endpoint gateway in all regions.\n\nibmcloud is endpoint-gateway-targets [--output JSON] [-q, --quiet]\n\n\n\n Command options \n\n\n\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is endpoint-gateway \n\nView details of an endpoint gateway.\n\nibmcloud is endpoint-gateway ENDPOINT_GATEWAY [--vpc VPC] [--output JSON] [-q, --quiet]\n\n\n\n Command options \n\n\n\n* ENDPOINT_GATEWAY: ID or name of the endpoint gateway.\n* --vpc: ID or name of the VPC. It is only required to specify the unique resource by name inside this VPC.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is endpoint-gateways \n\nList all endpoint gateways in the region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-vpc-reference"},{"document_id":"ibmcld_15545-132073-133463","score":10.1490083998,"text":"\n* --classic-access: This flag lists VPCs that have classic access enabled. If unspecified, it returns all VPCs with and without classic access enabled. One of: true, false.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n\n\n Virtual private endpoint gateways \n\nThe following section gives details about the CLI commands that are available for working with endpoint gateways.\n\n\n\n ibmcloud is endpoint-gateway-targets \n\nList all resources can be set as target for endpoint gateway in all regions.\n\nibmcloud is endpoint-gateway-targets [--output JSON] [-q, --quiet]\n\n\n\n Command options \n\n\n\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is endpoint-gateway \n\nView details of an endpoint gateway.\n\nibmcloud is endpoint-gateway ENDPOINT_GATEWAY [--vpc VPC] [--output JSON] [-q, --quiet]\n\n\n\n Command options \n\n\n\n* ENDPOINT_GATEWAY: ID or name of the endpoint gateway.\n* --vpc: ID or name of the VPC. It is only required to specify the unique resource by name inside this VPC.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is endpoint-gateways \n\nList all endpoint gateways in the region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference"},{"document_id":"ibmcld_15558-132125-133515","score":10.1490083998,"text":"\n* --classic-access: This flag lists VPCs that have classic access enabled. If unspecified, it returns all VPCs with and without classic access enabled. One of: true, false.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n\n\n Virtual private endpoint gateways \n\nThe following section gives details about the CLI commands that are available for working with endpoint gateways.\n\n\n\n ibmcloud is endpoint-gateway-targets \n\nList all resources can be set as target for endpoint gateway in all regions.\n\nibmcloud is endpoint-gateway-targets [--output JSON] [-q, --quiet]\n\n\n\n Command options \n\n\n\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is endpoint-gateway \n\nView details of an endpoint gateway.\n\nibmcloud is endpoint-gateway ENDPOINT_GATEWAY [--vpc VPC] [--output JSON] [-q, --quiet]\n\n\n\n Command options \n\n\n\n* ENDPOINT_GATEWAY: ID or name of the endpoint gateway.\n* --vpc: ID or name of the VPC. It is only required to specify the unique resource by name inside this VPC.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is endpoint-gateways \n\nList all endpoint gateways in the region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference&interface=ui"},{"document_id":"ibmcld_16082-131969-133359","score":10.1490083998,"text":"\n* --classic-access: This flag lists VPCs that have classic access enabled. If unspecified, it returns all VPCs with and without classic access enabled. One of: true, false.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n\n\n Virtual private endpoint gateways \n\nThe following section gives details about the CLI commands that are available for working with endpoint gateways.\n\n\n\n ibmcloud is endpoint-gateway-targets \n\nList all resources can be set as target for endpoint gateway in all regions.\n\nibmcloud is endpoint-gateway-targets [--output JSON] [-q, --quiet]\n\n\n\n Command options \n\n\n\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is endpoint-gateway \n\nView details of an endpoint gateway.\n\nibmcloud is endpoint-gateway ENDPOINT_GATEWAY [--vpc VPC] [--output JSON] [-q, --quiet]\n\n\n\n Command options \n\n\n\n* ENDPOINT_GATEWAY: ID or name of the endpoint gateway.\n* --vpc: ID or name of the VPC. It is only required to specify the unique resource by name inside this VPC.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is endpoint-gateways \n\nList all endpoint gateways in the region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-reference"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3065735964,"ndcg_cut_5":0.3065735964,"ndcg_cut_10":0.3065735964}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15545-195860-197138","score":20.5506275338,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference"},{"document_id":"ibmcld_15558-195912-197190","score":20.5506275338,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference&interface=ui"},{"document_id":"ibmcld_16082-195756-197034","score":20.5506275338,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-reference"},{"document_id":"ibmcld_16092-195812-197090","score":20.5506275338,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-reference&interface=cli"},{"document_id":"ibmcld_15646-26617-28366","score":19.751357594,"text":"\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Remove a previously scheduled custom image lifecycle status change by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15647-26643-28392","score":19.751357594,"text":"\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Remove a previously scheduled custom image lifecycle status change by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15507-6657-8493","score":19.6965352643,"text":"\nIf you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Removing previously scheduled image from volume lifecycle statuses by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Changing an image from volume lifecycle status by using the API \n\nYou can change the lifecycle status of a IBM Cloud VPC image from volume by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15507-5434-7003","score":19.2883397864,"text":"\nTo remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15545-194867-196144","score":19.1903287346,"text":"\nIf this property is not provided, the root key from source volume is used.\n* --resource-group-id: ID of the resource group. This ID is mutually exclusive with --resource-group-name.\n* --resource-group-name: Name of the resource group. This name is mutually exclusive with --resource-group-id.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in the ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00\n* --obsolete-at: The obsolescence date and time to set for this image. The date and time must not be in the past, and must be later than \"deprecate_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is image-update \n\nUpdate an image.\n\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference"},{"document_id":"ibmcld_15558-194919-196196","score":19.1903287346,"text":"\nIf this property is not provided, the root key from source volume is used.\n* --resource-group-id: ID of the resource group. This ID is mutually exclusive with --resource-group-name.\n* --resource-group-name: Name of the resource group. This name is mutually exclusive with --resource-group-id.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in the ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00\n* --obsolete-at: The obsolescence date and time to set for this image. The date and time must not be in the past, and must be later than \"deprecate_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is image-update \n\nUpdate an image.\n\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1480409555}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15507-5434-7003","score":69.6238590835,"text":"\nTo remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15646-25256-26940","score":68.3898201456,"text":"\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-imagesschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15647-25269-26966","score":68.2471492384,"text":"\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=uischedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_16601-1150-2518","score":68.2390411305,"text":"\n* [Salesforce SDK](https:\/\/github.com\/watson-developer-cloud\/salesforce-sdk)\n* [Swift SDK](https:\/\/github.com\/watson-developer-cloud\/swift-sdk)\n* [Unity SDK](https:\/\/github.com\/watson-developer-cloud\/unity-sdk)\n\n\n\n\n\n\n\n SDK updates and deprecation \n\nThe supported Watson SDKs are updated according to the following guidelines.\n\n\n\n Semantic versioning \n\nSupported Watson SDKs adhere to semantic versioning with releases labeled as {major}.{minor}.{patch}.\n\n\n\n\n\n Release frequency \n\nSDKs are released independently and might not update on the same schedule.\n\n\n\n* The current releases of the Watson SDKs are updated on a 2- to 6-week schedule. These releases are either minor updates or patches that do not include breaking changes. You can update to any version of the SDK with the same major version number.\n* Major updates that might include breaking changes are released approximately every 6 months.\n\n\n\n\n\n\n\n Deprecated release \n\nWhen a major version is released, support continues on the previous major release for 12 months in a deprecation period. The deprecated release might be updated with bug fixes, but no new features will be added and documentation might not be available.\n\n\n\n\n\n Obsolete release \n\nAfter the 12-month deprecation period, a release is obsolete. The release might be functional but is unsupported and not updated. Update to the current release.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-using-sdks"},{"document_id":"ibmcld_15647-27849-29558","score":66.1293814746,"text":"\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=uischedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15646-27823-29559","score":65.7610103974,"text":"\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-imagesschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15507-8094-9618","score":63.6014950619,"text":"\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15175-10224-11754","score":62.6948255235,"text":"\necc68c2f-96a1-4862-bc86-14f47e5d9ed8 aa-1-bx-boot-1617035447000\nCreated 2021-05-20T09:43:16+08:00\nVisibility private\nFile size(GB) -\nEncryption none\nResource group f22cf48f-8836-4527-9131-1d7c73ba85e9\n\n\n\n\n\n\n\n Schedule custom image lifecycle status changes by using the CLI \n\nWhen you import a custom image by using the command-line interface (CLI), you can also schedule the lifecycle status changes of the IBM Cloud VPC custom image at the same time by using options of the ibmcloud is image-create command.\n\nSpecify the name of the custom image to be created by using the IMAGE_NAME variable and the source by using the --source-volume option to indicate that the source is an existing boot volume.\n\nTo schedule the deprecate-at or obsolete-at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates and times, the deprecate-at date must be after the obsolete-at date and time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-ifv"},{"document_id":"ibmcld_15507-6657-8493","score":61.5012408853,"text":"\nIf you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Removing previously scheduled image from volume lifecycle statuses by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Changing an image from volume lifecycle status by using the API \n\nYou can change the lifecycle status of a IBM Cloud VPC image from volume by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15646-26617-28366","score":60.413089737,"text":"\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Remove a previously scheduled custom image lifecycle status change by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.2857142857,"recall_5":0.2857142857,"recall_10":0.4285714286,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.3835663674,"ndcg_cut_10":0.3936118448}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13770-6649-7831","score":16.9609022861,"text":"\nThe request specifies the speaker ID for the speaker named speaker_one and the customization ID for the custom model that was created in the first step. The Content-Type header of the request must be multipart\/form-data.\n\nIBM Cloud\n\ncurl -X POST -u apikey:{apikey} --header \"Content-Type:multipart\/form-data\" --form metadata=\"{\"prompt_text\": \"Thank you and good-bye!\", \"speaker_id\": \"56367f89-546d-4b37-891e-4eb0c13cc833\"}\" --form file=@goodbye-prompt.wav \"{url}\/v1\/customizations\/82f4809a-bf63-89a6-52ca-22731fe467ba\/prompts\/goodbye\"\n\nIBM Cloud Pak for Data\n\ncurl -X POST --header \"Authorization: Bearer {token}\" --header \"Content-Type:multipart\/form-data\" --form metadata=\"{\"prompt_text\": \"Thank you and good-bye!\", \"speaker_id\": \"56367f89-546d-4b37-891e-4eb0c13cc833\"}\" --form file=@goodbye-prompt.wav \"{url}\/v1\/customizations\/82f4809a-bf63-89a6-52ca-22731fe467ba\/prompts\/goodbye\"\n\nThe service returns the following response with information about the prompt, including its initial status:\n\n{\n\"prompt\": \"Thank you and good-bye!\",\n\"prompt_id\": \"goodbye\",\n\"status\": \"processing\",\n\"speaker_id\": \"823068b2-ed4e-11ea-b6e0-7b6456aa95cc\"\n}\n\nAdding a prompt is an asynchronous operation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-tbe-create"},{"document_id":"ibmcld_03137-4194-5167","score":16.1603378866,"text":"\nIf it finds a term that it can match to an existing dictionary entity value or synonym, it adds the term to the list of words that belong to the skill, and does not correct it.\n\nFor example, if a user enters a sentence like I wnt to buy a boook, fuzzy matching recognizes that the term boook means the same thing as your entity value book, and adds it to the protected words list. Your assistant corrects the input to be, I want to buy a boook. Notice that it corrects wnt but does not correct the spelling of boook. If you see this type of result when you are testing your dialog, you might think your assistant is misbehaving. However, your assistant is not. Thanks to fuzzy matching, it correctly identifies boook as a @reading_material entity mention. And thanks to autocorrection revising the term to want, your assistant is able to map the input to your buy_something intent. Each feature does its part to help your assistant understand the meaning of the user input.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-autocorrection"},{"document_id":"ibmcld_13877-35297-36247","score":15.313220245,"text":"\nRelated content \n\n\n\n* [Security to safeguard and monitor your cloud apps](https:\/\/www.ibm.com\/cloud\/garage\/architectures\/securityArchitecture)\n* [IBM Cloud Platform security](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-securitysecurity)\n* [Security in the IBM Cloud](https:\/\/www.ibm.com\/cloud\/security)\n* Tutorial: [Best practices for organizing users, teams, applications](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-users-teams-applicationsusers-teams-applications)\n* Blog: [Secure Apps on IBM Cloud with Wildcard Certificates](https:\/\/www.ibm.com\/cloud\/blog\/secure-apps-on-ibm-cloud-with-wildcard-certificates)\n* Blog: [Cloud Offboarding: How to Remove a User and Maintain Security](https:\/\/www.ibm.com\/cloud\/blog\/cloud-offboarding-how-to-remove-a-user-and-maintain-security)\n* Blog: [Going Passwordless on IBM Cloud Thanks to FIDO2](https:\/\/www.ibm.com\/cloud\/blog\/going-passwordless-on-ibm-cloud-thanks-to-fido2)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tutorials?topic=solution-tutorials-cloud-e2e-security"},{"document_id":"ibmcld_05374-5986-7899","score":13.7206400239,"text":"\nI took the exact same code I did from Heroku. I created a new project and then I created an application and I just pushed it and it just worked so imagine what you can do with that for yourself. This shows the power that is Code Engine and on a free tier it is truly free - just like Heroku was or will be or was will won't be in the future. Code Engine is free forever, which is great and hopefully, it'll make your life a little easier.\n\nThanks so much for watching and if you have any questions, my Twitter handle is @jjasghar or you're more than welcome to email me at [awesome@ibm.com](mailto:awesome@ibm.com). My job is to be a personable nerd so never hesitate to reach out.\n\nThanks so much.\n\nBye y'all.\n\n\n\n\n\n\n\n Prerequisites \n\nBefore you can get started with Code Engine, you need to set up your account and install the CLI.\n\n\n\n* All Code Engine users are required to have a Pay-as-you-Go account.\n* While you can use Code Engine through the console, the examples in this documentation focus on the command line. Therefore, you must install the Code Engine CLI.\n\nibmcloud plugin install code-engine\n\nFor more information, see [setting up the Code Engine CLI](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-install-cli). For more information about the CLI, see [Code Engine CLI reference](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-cli).\n\n\n\n\n\n\n\n Comparing Heroku and Code Engine terminology \n\nBefore you get started with deploying apps in Code Engine, learn the basics about Code Engine. The following table describes some high-level terminology differences between Cloud Foundry and Code Engine.\n\n\n\nTable 1. Terminology\n\n Heroku Code Engine Description \n\n N\/A Resource group and projects A grouping of workloads. The specific choice of which workload goes into each grouping is defined by the user. \"Resource groups\" are an IBM Cloud concept, while \"projects\" are Code Engine specific.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-heroku-migrate"},{"document_id":"ibmcld_16267-2886-4844","score":13.7206400239,"text":"\n* Words containing special characters, such as hyphens (-), asterisks (*), ampersands (&), or at signs (@), including those used in email addresses or URLs.\n* Words that belong, meaning words that have implied significance because they occur in your action steps or dialog entity values, entity synonyms, or intent user examples.\n\n\n\n\n\n How is spelling autocorrection related to fuzzy matching? \n\nIn dialog, fuzzy matching helps your assistant recognize dictionary-based entity mentions in user input. It uses a dictionary lookup approach to match a word from the user input to an existing entity value or synonym in the skill's training data. For example, if the user enters boook, and your training data contains a @reading_material entity with a book value, then fuzzy matching recognizes that the two terms (boook and book) mean the same thing.\n\nIn dialog, when you enable both autocorrection and fuzzy matching, the fuzzy matching function runs before autocorrection is triggered. If it finds a term that it can match to an existing dictionary entity value or synonym, it adds the term to the list of words that belong to the skill, and does not correct it.\n\nFor example, if a user enters a sentence like I wnt to buy a boook, fuzzy matching recognizes that the term boook means the same thing as your entity value book, and adds it to the protected words list. Your assistant corrects the input to be, I want to buy a boook. Notice that it corrects wnt but does not correct the spelling of boook. If you see this type of result when you are testing your dialog, you might think your assistant is misbehaving. However, your assistant is not. Thanks to fuzzy matching, it correctly identifies boook as a @reading_material entity mention. And thanks to autocorrection revising the term to want, your assistant is able to map the input to your buy_something intent. Each feature does its part to help your assistant understand the meaning of the user input.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-autocorrection"},{"document_id":"ibmcld_02932-4408-6545","score":13.472057995,"text":"\nFor example, if the user enters boook, and your training data contains a @reading_material entity with a book value, then fuzzy matching recognizes that the two terms (boook and book) mean the same thing.\n\nWhen you enable both autocorrection and fuzzy matching, the fuzzy matching function runs before autocorrection is triggered. If it finds a term that it can match to an existing dictionary entity value or synonym, it adds the term to the list of words that belong to the skill, and does not correct it.\n\nFor example, if a user enters a sentence like I wnt to buy a boook, fuzzy matching recognizes that the term boook means the same thing as your entity value book, and adds it to the protected words list. Your assistant corrects the input to be, I want to buy a boook. Notice that it corrects wnt but does not correct the spelling of boook. If you see this type of result when you are testing your dialog, you might think your assistant is misbehaving. However, your assistant is not. Thanks to fuzzy matching, it correctly identifies boook as a @reading_material entity mention. And thanks to autocorrection revising the term to want, your assistant is able to map the input to your buy_something intent. Each feature does its part to help your assistant understand the meaning of the user input.\n\n\n\n\n\n How autocorrection works \n\nNormally, user input is saved as-is in the text field of the input object of the message. If, and only if the user input is corrected in some way, a new field is created in the input object, called original_text. This field stores the user's original input that includes any misspelled words in it. And the corrected text is added to the input.text field.\n\nIf you want to ask users to confirm the assistant's understanding of their meaning, you can do so in a way that takes into account that their input might have been corrected. Set the condition for the dialog node or conditional response that is asking for confirmation to original_text. This means that if the user's input was automatically corrected, show the corresponding response. And the response can contain the expression: You said: <?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-spell-check"},{"document_id":"ibmcld_13878-17352-18831","score":13.4058184621,"text":"\n* Tutorial: [Apply end to end security to a cloud application](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-cloud-e2e-security)\n* Tutorial: [Best practices for organizing users, teams, applications](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-users-teams-applications)\n* Blog: [Cloud App Security: What Makes a Secure App?](https:\/\/www.ibm.com\/cloud\/blog\/cloud-app-security)\n* Blog: [Onboarding Cloud Projects: Security and Resource Considerations](https:\/\/www.ibm.com\/cloud\/blog\/onboarding-cloud-projects-security-and-resource-considerations)\n* Blog: [Use Your FIDO2 Key for 2FA on IBM Cloud Apps](https:\/\/www.ibm.com\/cloud\/blog\/use-your-fido2-key-for-2fa-on-ibm-cloud-apps)\n* Blog: [Going Passwordless on IBM Cloud Thanks to FIDO2](https:\/\/www.ibm.com\/cloud\/blog\/going-passwordless-on-ibm-cloud-thanks-to-fido2)\n* Blog: [IBM Cloud Security Hands-On: Share Your Chatbot Project](https:\/\/www.ibm.com\/cloud\/blog\/share-your-chatbot-project)\n* Blog: [Increase Information Security for Db2 on IBM Cloud](https:\/\/www.ibm.com\/cloud\/blog\/increase-information-security-for-db2-on-ibm-cloud)\n* IBM Architecture Center: [Security to safeguard and monitor your cloud apps](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/securityArchitecture)\n* [IBM Cloud platform service CLIs and APIs](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-platform-svc-cli-api)\n* [IBM Cloud Compliance Programs](https:\/\/www.ibm.com\/cloud\/compliance)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tutorials?topic=solution-tutorials-extended-app-security"},{"document_id":"ibmcld_02718-4890-5645","score":13.3256229545,"text":"\nSo we've got maybe [Writing] app one here, [Writing] app two, and say a [Writing] web page.\n\nWith a feature flagging service we can actually group these in collections so that we're a little bit more organized with which feature flags are tied to, which apps are web pages.\n\nSo now today we've learned about returning feature flags on and off without deployment testing directly in production, and then segmenting those features based on the user attributes.\n\nThank you for watching. If you have questions, please drop us a line below. If you want to see more videos like this in the future, please like and subscribe. And don't forget, you can grow your skills and earn badges with IBM CloudLabs, which are free browser-based interactive kubernetes labs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-videos"},{"document_id":"ibmcld_08058-5456-6715","score":11.9966251828,"text":"\ncasemanagementv1.GetCaseOptionsFieldsStatusConst,\ncasemanagementv1.GetCaseOptionsFieldsSeverityConst,\ncasemanagementv1.GetCaseOptionsFieldsCreatedByConst,\n})\n\ncaseVar, response, err := caseManagementService.GetCase(getCaseOptions)\nif err != nil {\npanic(err)\n}\nb, _ := json.MarshalIndent(caseVar, \"\", \" \")\nfmt.Println(string(b))\n\nconst fieldsToReturn = [\nCaseManagementV1.GetCaseConstants.Fields.DESCRIPTION,\nCaseManagementV1.GetCaseConstants.Fields.STATUS,\nCaseManagementV1.GetCaseConstants.Fields.SEVERITY,\nCaseManagementV1.GetCaseConstants.Fields.CREATED_BY,\n];\n\nconst params = {\ncaseNumber: caseNumber,\nfields: fieldsToReturn,\n};\n\ncaseManagementService.getCase(params)\n.then(res => {\nconsole.log(JSON.stringify(res.result, null, 2));\n})\n.catch(err => {\nconsole.warn(err)\n});\n\n\n\n\n\n Updating support cases by using the API \n\nThe following sample request shows how to programmatically update a support case. For more information, see the [Case Management API](https:\/\/cloud.ibm.com\/apidocs\/case-managementcasemanagement-createcase).\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -X PUT '\/case-management\/v1\/cases\/{case_number}\/status' -H 'Authorization: TOKEN' -d '{\n\"action\": \"resolve\",\n\"comment\": \"The issue is resolved. Thank you!\",\n\"resolution_code\": 1\n}'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-managing-support-cases"},{"document_id":"ibmcld_13770-12514-13724","score":11.8574983562,"text":"\n* The service might fail to detect a mismatch between the prompt\u2019s text and audio. This problem is more likely to occur with longer prompts. Multiple shorter prompts are preferable to a single long prompt.\n* The text of a prompt might include a word that the service does not recognize. In this case, you can add a custom word\/translation pair to the prompt's custom model to tell the service how to pronounce the word. For more information, see [Adding a single word to a custom model](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-customWordscuWordAdd).\n* The quality of the input audio might be insufficient or the service\u2019s processing of the audio might fail to detect or reflect the intended prosody. Submitting new audio for the prompt can correct these issues.\n\n\n\nIf a prompt that is created without a speaker ID does not adequately reflect the intended prosody, enrolling the speaker and providing a speaker ID for the prompt is one recommended means of potentially improving the quality of the prompt. This is especially important for shorter prompts such as \"good-bye\" or \"thank you,\" where less audio data makes it more difficult for the service to match the prosody of the speaker.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-tbe-create"}],"retriever_scores":{}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09051-2356-3832","score":11.5722456371,"text":"\nCLI version 0.6.11 \n\nRelease date: 2022-06-27\n\n\n\n Changes \n\nChanges in this [version](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference) include support for filters when listing keys, support for listing the versions of a key, and support for using aliases in place of key IDs.\n\n\n\n\n\n\n\n CLI version 0.6.10 \n\nRelease date: 2022-02-08\n\n\n\n Changes \n\nChanges included in this [version](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference):\n\n\n\n* The environment variable KP_PRIVATE_ADDR is no longer required when authenticating to private.cloud.ibm.com. More information is available about using the CLI with [private endpoints](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cli-private-endpoints).\n* The environment variable IBMCLOUD_TRACE gives you more visibility into your diagnostics. Learn more at the [CLI documentation](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_env_varIBMCLOUD_TRACE).\n* Updated help text and messages.\n\n\n\n\n\n\n\n\n\n CLI version 0.6.9 \n\nRelease date: 2021-12-14\n\n\n\n Changes \n\nChanges included in this [version](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference):\n\n\n\n* Added support for [S\u00e3o-Paulo region](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-regions).\n\n\n\n\n\n\n\n\n\n CLI version 0.6.8 \n\nRelease date: 2021-11-05\n\n\n\n Changes \n\nChanges included in this [version](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference):","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-changelog"},{"document_id":"ibmcld_05873-43879-45189","score":11.2055680848,"text":"\n: For more information, see the [Istio security bulletin 2022-004](https:\/\/istio.io\/latest\/news\/security\/istio-security-2022-004\/).\n\n\n\n\n\n Change log for 1.12.4, released 8 March 2022 \n\nReview the changes that are included in version 1.12.4 of the managed Istio add-on.\n\nPrevious version\n: 1.12.3\n\nCurrent version\n: 1.12.4\n\nUpdates in this version\n: See the Istio release notes for [Istio 1.12.4](https:\/\/istio.io\/latest\/news\/releases\/1.12.x\/announcing-1.12.4\/.).\n: Resolves the following CVEs\n\n\n\n* [CVE-2021-3995](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2021-3995)\n* [CVE-2021-3996](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2021-3996)\n\n\n\n: For more information, see the [Istio security bulletin 2022-003](https:\/\/istio.io\/latest\/news\/security\/istio-security-2022-003\/).\n\n\n\n\n\n Change log for 1.12.3, released 22 February 2021 \n\nReview the changes that are included in version 1.12.3 of the managed Istio add-on.\n\nPrevious version\n: 1.12.2\n\nCurrent version\n: 1.12.3\n\nUpdates in this version\n: See the Istio release notes for [Istio 1.12.3](https:\/\/istio.io\/latest\/news\/releases\/1.12.x\/announcing-1.12.3\/.).\n\n\n\n\n\n Change log for 1.12.2, released 03 February 2022 \n\nReview the changes that are included in version 1.12.2 of the managed Istio add-on.\n\nPrevious version\n: 1.12.1\n\nCurrent version","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istio-changelog"},{"document_id":"ibmcld_06293-33323-34980","score":11.0741314294,"text":"\n* Fixes a bug related to unexpected IAM behavior.\n* Changes the version numbering system to X.X.Y_YYY where X.X is the major version number and .Y_YYY is the patch version number.\n\n\n\n\n\n\n\n\n\n Version 3.0.1 \n\nReview the changes in version 3.0.1 of the Block Storage for VPC add-on.\n\n\n\n Change log for version 3.0.1, released 15 July 2021 \n\nReview the change log for version 3.0.1 of the Block Storage for VPC add-on.\n\nVolume expansion in version 3.0.1 is available in beta for allowlisted accounts. Don't use this feature for production workloads.\n\n\n\n* Image tags: v3.0.7\n* Includes beta support for volume expansion on allowlisted accounts.\n* Fixes vulnerability [CVE-2021-27219](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-27219).\n* Includes the storage-secret-sidecar container in the Block Storage for VPC driver pods.\n\n\n\n\n\n\n\n\n\n Version 3.0.0 \n\nReview the changes in version 3.0.0 of the Block Storage for VPC add-on.\n\n\n\n Change log for patch update 3.0.0_521, released 01 April 2021 \n\nReview the changes in version 3.0.0_521 of the Block Storage for VPC add-on.\n\n\n\n* Image tags: v3.0.7\n* Updates the Golang version from 1.15.5 to 1.15.9.\n\n\n\n\n\n\n\n Change log for version 3.0.0, released 26 February 2021 \n\nReview the changes in version 3.0.0_521 of the Block Storage for VPC add-on.\n\n\n\n* Image tags: v.3.0.0\n* The vpc-block-csi-driver is now available for both managed clusters and unmanaged clusters.\n* No functional changes in this release.\n\n\n\n\n\n\n\n\n\n Archive \n\nFind an overview of Block Storage for VPC add-ons that are unsupported in IBM Cloud Kubernetes Service.\n\n\n\n Version 2.0.3 \n\nReview the changes in version 2.0.3 of the Block Storage for VPC add-on.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc_bs_changelog"},{"document_id":"ibmcld_10699-33314-34971","score":11.0741314294,"text":"\n* Fixes a bug related to unexpected IAM behavior.\n* Changes the version numbering system to X.X.Y_YYY where X.X is the major version number and .Y_YYY is the patch version number.\n\n\n\n\n\n\n\n\n\n Version 3.0.1 \n\nReview the changes in version 3.0.1 of the Block Storage for VPC add-on.\n\n\n\n Change log for version 3.0.1, released 15 July 2021 \n\nReview the change log for version 3.0.1 of the Block Storage for VPC add-on.\n\nVolume expansion in version 3.0.1 is available in beta for allowlisted accounts. Don't use this feature for production workloads.\n\n\n\n* Image tags: v3.0.7\n* Includes beta support for volume expansion on allowlisted accounts.\n* Fixes vulnerability [CVE-2021-27219](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-27219).\n* Includes the storage-secret-sidecar container in the Block Storage for VPC driver pods.\n\n\n\n\n\n\n\n\n\n Version 3.0.0 \n\nReview the changes in version 3.0.0 of the Block Storage for VPC add-on.\n\n\n\n Change log for patch update 3.0.0_521, released 01 April 2021 \n\nReview the changes in version 3.0.0_521 of the Block Storage for VPC add-on.\n\n\n\n* Image tags: v3.0.7\n* Updates the Golang version from 1.15.5 to 1.15.9.\n\n\n\n\n\n\n\n Change log for version 3.0.0, released 26 February 2021 \n\nReview the changes in version 3.0.0_521 of the Block Storage for VPC add-on.\n\n\n\n* Image tags: v.3.0.0\n* The vpc-block-csi-driver is now available for both managed clusters and unmanaged clusters.\n* No functional changes in this release.\n\n\n\n\n\n\n\n\n\n Archive \n\nFind an overview of Block Storage for VPC add-ons that are unsupported in IBM Cloud Kubernetes Service.\n\n\n\n Version 2.0.3 \n\nReview the changes in version 2.0.3 of the Block Storage for VPC add-on.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_bs_changelog"},{"document_id":"ibmcld_03040-9877-11861","score":11.0727256323,"text":"\nThis release of Watson Assistant for IBM Cloud Pak\u00ae for Data includes various fixes and features.\n\nAlgorithm version 01-Jun-2022 uses enhanced intent detection by default\n: The algorithm version Latest (01-Jun-2022) now uses enhanced intent detection by default. Before this change, some skills that did not include a specific algorithm version selection inadvertently used Previous (01-Jan-2022). You can notice small changes in intent detection behavior when changes are made to an assistant that previously didn't have enhanced intent detection enabled. For more information, see [Algorithm version and training](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-algorithm-version).\n\nTest the Beta algorithm version now to prepare for release 4.7.0\n: The Beta algorithm version in release 4.6.5 includes a new irrelevance detection implementation to improve off-topic detection accuracy.\n\nImprovements include:\n\n\n\n* Relevant user inputs are expected to get higher confidence, so they are less likely to be considered irrelevant or require clarification\n* Irrelevance detection is improved in the presence of direct entity references\n* Irrelevance detection is more stable across small changes to input\n* Intent detection is more stable regarding occurrence of numerics, such as postal codes\n* For German-language assistants, intent detection is more robust in the presence of umlauts\n\n\n\nIn the forthcoming 4.7.0 release, it is planned that this Beta version will become the Latest version, replacing the current Latest (01 Jun 2022) version. You can test the Beta version in 4.6.5 now to prepare.\n\nFor more information, see [Algorithm version and training](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-algorithm-version).\n\n\n\n\n\n 23 February 2023 \n\nIBM Watson\u00ae Assistant Cartridge for IBM Cloud Pak\u00ae for Data Version 4.6.3 is available\n: Watson Assistant for IBM Cloud Pak\u00ae for Data 4.6.3 is compatible with IBM Cloud Pak\u00ae for Data Version 4.6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-release-notes"},{"document_id":"ibmcld_09051-3538-5141","score":11.05004121,"text":"\n* Added support for [S\u00e3o-Paulo region](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-regions).\n\n\n\n\n\n\n\n\n\n CLI version 0.6.8 \n\nRelease date: 2021-11-05\n\n\n\n Changes \n\nChanges included in this [version](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference):\n\n\n\n* Added support for [targeting private endpoints](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-private-endpointstarget-private-endpoint).\n\n\n\n\n\n\n\n\n\n CLI version 0.6.7 \n\nThe release binary is not currently available. When released, please use v0.6.8.\n\n\n\n\n\n CLI version 0.6.6 \n\nRelease date: 2021-10-11\n\n\n\n Changes \n\nChanges included in this [version](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference):\n\n\n\n* Added feature for [key synchronizing](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-referencekp-key-sync) as a new subcommand under key.\n* Updated the \"Internal server error\" response message to return the actual error message.\n\n\n\n\n\n\n\n\n\n CLI version 0.6.5 \n\nRelease date: 2021-08-30\n\n\n\n Changes \n\nChanges included in this [version](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference):\n\n\n\n* The JSON response for the retrieval of multiple objects like listing keys, policies, and registrations is set as an empty array: [] when there are no objects returned by the service.\n* The JSON response for the retrieval of a single object, like a key policy, is set as an empty object: {} when there is no policy returned by the service.\n\n\n\n\n\n\n\n\n\n CLI version 0.6.4 \n\nRelease date: 2021-07-23\n\n\n\n Changes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-changelog"},{"document_id":"ibmcld_12369-7-2028","score":11.0280373586,"text":"\nSecrets Manager API change log \n\nIn this change log, you can learn about the latest changes, improvements, and updates for the [IBM Cloud\u00ae Secrets Manager API](https:\/\/cloud.ibm.com\/apidocs\/secrets-manager\/secrets-manager-v2). The change log lists changes that have been made, ordered by the date they were released. Changes to existing API versions are designed to be compatible with existing client applications.\n\nTo learn about general updates and improvements to the Secrets Manager service, see [Release notes](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-release-notes).\n\n\n\n 17 April 2023 \n\nVersion 2.0.0 was released on 17 April 2023. This release includes the following updates:\n\n\n\n* You no longer need to include secret_type in the API URL to identify a secret.\n* The secret group name must be unique per Secrets Manager instance.\n* Resources updates are defined as HTTP patch operations.\n* The configurations API follows the pattern of the Secrets Manager API. config_type acts as the API discriminator, similarly to secret_type.\n* Configurations are modeled as openAPI composites with metadata and data parts, similarly to the Secrets Manager model. Mappings between IAM roles and configurations API follow the same pattern for the Secrets Manager API. For example, an IAM viewer can list configurations to view their metadata.\n* List operations return metadata only for secret, secret version, and config resources.\n* The action to rotate a secret is now the create a new secret version API: POST\/v2\/secrets\/{id}\/versions.\n* The action to restore secret version is now the create a new secret version API with the restored_from_version body parameter.\n* The action to delete IAM credentials is now the delete a secret version data API: DELETE \/v2\/secrets\/{id}\/versions\/{version_id}\/secret_data.\n* Policies API is now embedded into the metadata API in version 2.0.\n* The actions to list Secrets and get secret metadata return the versions_total field. The version's content is not included.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-api-change-log"},{"document_id":"ibmcld_14879-6838-8227","score":10.9890405153,"text":"\n\"id\": \"549192f1-d238-42bd-8657-b6034a08f04e\"\n}\n}'\n\n\n\n\n\n Updating a file share mount target \n\nThe following examples compare how to make a request to update a file share mount target before and after the 2023-05-30 versioned change. The path of the API request is different before and after the change.\n\nThis request updates a mount target, specifying API version 2023-05-29 or earlier. The path of the API includes \/targets.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/shares\/$share_id\/targets\/$id?version=2023-05-29&generation=2&maturity=beta\" -H \"Authorization: Bearer $iam_token\" -H 'Content-Type: application\/json' -d '{\n\"name\": \"target-1-updated\"\n}'\n\nThis request updates a file share mount target, specifying API version 2023-05-30 or later. The path of the API includes \/mount_targets.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/shares\/$share_id\/mount_targets\/$id?version=2023-05-30&generation=2&maturity=beta\" -H \"Authorization: Bearer $iam_token\" -H 'Content-Type: application\/json' -d '{\n\"name\": \"target-2-updated\"\n}'\n\n\n\n\n\n Deleting a file share mount target \n\nThe following examples compare how to make a request to delete a file share mount target before and after the 2023-05-30 versioned change. The path of the API request is different before and after the change.\n\nThis request deletes a mount target, specifying API version 2023-05-29 or earlier. The path of the API includes \/targets.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-2023-05-30-migration-file-shares"},{"document_id":"ibmcld_10062-18937-20193","score":10.9419340231,"text":"\n* Includes fixes for [CVE-2021-44716](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-44716) and [CVE-2021-44717](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-44717).\n\n\n\n\n\n\n\n Change log for patch update 1.0.4_387, released 22 November 2021 \n\nReview the changes in version 1.0.4_387 of the cluster autoscaler add-on.\n\n\n\n* Image tags: 1.19.1-7, 1.20.0-7, 1.21.0-3, and 1.22.0-2.\n* Updates the Golang version to 1.16.10 which includes fixes for [CVE-2021-41772](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-41772) and [CVE-2021-41771](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-41771).\n\n\n\n\n\n\n\n Change log for patch update 1.0.4_374, released 7 October 2021 \n\nReview the changes in version 1.0.4_374 of the cluster autoscaler add-on.\n\n\n\n* Image tags: 1.19.1-6, 1.20.0-6, 1.21.0-2, and 1.22.0-1.\n* Adds support for Kubernetes version 1.22\n* Pulls the base Golang image from a proxy registry.\n* Adds an owner label to the cluster-autoscaler images.\n\n\n\n\n\n\n\n\n\n Version 1.0.3 \n\nReview the changes included in version 1.0.3 of the managed cluster autoscaler add-on.\n\n\n\n Change log for patch update 1.0.3_360, released 26 August 2021 \n\nReview the changes in version 1.0.3_360 of the cluster autoscaler add-on.\n\n\n\n* Image tags: 1.17.4-5, 1.18.3-5, 1.19.1-5, 1.20.0-5, and 1.21.0-1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ca_changelog"},{"document_id":"ibmcld_05588-18954-20210","score":10.9419340231,"text":"\n* Includes fixes for [CVE-2021-44716](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-44716) and [CVE-2021-44717](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-44717).\n\n\n\n\n\n\n\n Change log for patch update 1.0.4_387, released 22 November 2021 \n\nReview the changes in version 1.0.4_387 of the cluster autoscaler add-on.\n\n\n\n* Image tags: 1.19.1-7, 1.20.0-7, 1.21.0-3, and 1.22.0-2.\n* Updates the Golang version to 1.16.10 which includes fixes for [CVE-2021-41772](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-41772) and [CVE-2021-41771](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-41771).\n\n\n\n\n\n\n\n Change log for patch update 1.0.4_374, released 7 October 2021 \n\nReview the changes in version 1.0.4_374 of the cluster autoscaler add-on.\n\n\n\n* Image tags: 1.19.1-6, 1.20.0-6, 1.21.0-2, and 1.22.0-1.\n* Adds support for Kubernetes version 1.22\n* Pulls the base Golang image from a proxy registry.\n* Adds an owner label to the cluster-autoscaler images.\n\n\n\n\n\n\n\n\n\n Version 1.0.3 \n\nReview the changes included in version 1.0.3 of the managed cluster autoscaler add-on.\n\n\n\n Change log for patch update 1.0.3_360, released 26 August 2021 \n\nReview the changes in version 1.0.3_360 of the cluster autoscaler add-on.\n\n\n\n* Image tags: 1.17.4-5, 1.18.3-5, 1.19.1-5, 1.20.0-5, and 1.21.0-1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ca_changelog"}],"retriever_scores":{}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16324-3229-5312","score":37.114679244,"text":"\nChoose a narrow set of user goals first. If you start small and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. After your assistant is live, the built-in metrics of active user conversations help you understand what your customers are asking about, how well your assistant is able to meet their needs, and what to focus on next.\n\n\n\n\n\n 3. Choose the tone and language of your assistant \n\nBefore you build your assistant, it can also be helpful to choose the tone with which your assistant communicates. Is your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Write conversations that reflect your assistant's personality. Don't overdo it by sacrificing usability for the sake of keeping your assistant in character. Strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe that the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chatbots to identify themselves as chatbots.\n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-language-support).\n\n\n\n\n\n 4. Connect to content sources \n\nThe answer to common questions might already be documented somewhere in your organization's technical information. Plan whether you want to connect the assistant to existing content sources by taking an inventory of relevant help content (for example, product information, knowledge articles, FAQs) available to your customers.\n\nYou can give your assistant access to this information by adding a [search integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-add) to your assistant. The search integration uses IBM Watson\u00ae Discovery to return smart answers to natural language questions.\n\n\n\n\n\n 5. Plan your handoff strategy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-plan-assistant"},{"document_id":"ibmcld_03330-4-2191","score":36.2077015891,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n About Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant leverages industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search skill to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how the product delivers an exceptional, omnichannel customer experience:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index"},{"document_id":"ibmcld_16233-7-2298","score":35.7979430699,"text":"\nAbout Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant uses industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom-built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search integration with IBM Watson\u00ae Discovery to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how IBM Watson\u00ae Assistant delivers an exceptional, omnichannel customer experience:\n\nZoom\n\n![Flow diagram of the service](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/arch-detail.png)\n\nHow it works\n\nCustomers interact with the assistant through one or more of these channels:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-about"},{"document_id":"ibmcld_07148-7-2060","score":35.1815584086,"text":"\nUsing the COVID-19 kit \n\nThe COVID-19 kit is a special collection available in US instances of IBM Watson\u2122 Discovery. This pre-built collection includes more than 10 data sources you can use to fuel a dynamic chatbot built with IBM Watson\u2122 Assistant and Discovery to answer your customers' questions about COVID-19.\n\nFAQ extraction is a beta feature that was used to create question and answer pairs for the kit. The FAQ extraction beta feature is now deprecated and will stop being supported in v1 Discovery service instances on 1 March 2022. As a consequence, the COVID-19 kit data collection will stop being supported also.\n\nThe COVID-19 kit extracts answers from trusted sources and automatically updates your chatbot as the content from those sources are updated. It uses FAQ extraction machine learning models developed by IBM Research labs to extract question\/answer pairs. The kit is pre-configured with web crawl seeds from trusted sources such as the CDC, Harvard, and the United States Department of Labor. An expanded stopwords list and query expansions are also included in this collection to improve search results. It is designed to be augmented with your own data and customized to your needs.\n\nFor more information about this kit, and how you can create a chatbot and connect it to a data source with the IBM Watson\u2122 Assistant search skill using IBM Watson\u2122 Assistant and Discovery, see [COVID-19 \u2014 Are Your Virtual Assistant\u2019s Answers Up-To-Date?](https:\/\/medium.com\/ibm-watson\/covid-19-are-your-virtual-assistants-answers-up-to-date-c9e1ba70eb65654b).\n\nTo learn how to create a search skill in Watson Assistant, see [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add). (This feature is available only to Watson Assistant Plus or Premium plan users.)\n\nSee the following to learn more about working with Discovery:\n\n\n\n* To learn how to create a service instance, see [Getting started with the Discovery tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-getting-started).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-covidkit"},{"document_id":"ibmcld_07080-6045-7467","score":34.8708739802,"text":"\n[checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Deploy your solution. [Deploying your project](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-deploy) \n\n\n\n\n\n\n\n Enhance your chatbot \n\nDelight your customers by fortifying your chatbot with an answer to every question. Discovery is designed to work seemlessly with Watson Assistant to search and deliver answers from help content that you already own.\n\nZoom\n\n![Shows a chat bot with emphasize the answer enabled.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/convo-search.png)\n\nFigure 3. Answer finding enabled in the Watson Assistant web chat\n\nIf enhancing your chatbot is your goal, complete the steps that are listed in the following table.\n\n\n\nChecklist for enhancing your chatbot\n\n Step Task Related information \n\n ![checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Create a Conversational Search project. [Creating projects](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-projects) \n ![checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Add a collection that connects to an external data source or contains uploaded files.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-product-overview"},{"document_id":"ibmcld_03330-3253-5192","score":34.2135037535,"text":"\n* A conversational skill interprets the customer's message further, then directs the flow of the conversation. The skill gathers any information it needs to respond or perform a transaction on the customer's behalf.\n* A search skill leverages existing FAQ or other curated content that you own to find relevant answers to customer questions.\n* If a customer wants more personalized help or wants to discuss a sensitive subject, the assistant can connect the customer with someone from your support team through the web chat integration.\n\n\n\n\n\nFor more information about the architecture, read the [How to Make Chatbot Orchestration Easier](https:\/\/medium.com\/ibm-watson\/how-to-make-chatbot-orchestration-easier-c8ed61620b8d) blog on Medium.com.\n\nTo see how Watson Assistant is helping enterprises cut costs and improve customer satisfaction today, read the [Independent study finds IBM Watson Assistant customers can accrue $23.9 million in benefits](https:\/\/www.ibm.com\/blogs\/watson\/2020\/03\/independent-study-finds-ibm-watson-assistant-customers-accrued-23-9-million-in-benefits\/) blog on ibm.com.\n\nThis documentation describes managed instances of Watson Assistant that are offered in IBM Cloud or in Cloud Pak for Data as a Service. If you are interested in on-premises or installed deployments, see [this documentation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-index).\n\nRead more about these implementation steps by following these links:\n\n\n\n* [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add)\n* [Adding skills to your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add)\n* [Deploying your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add)\n\n\n\n\n\n\n\n Browser support \n\nThe Watson Assistant application (where you create assistants and skills) requires the same level of browser software as is required by IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index"},{"document_id":"ibmcld_13160-7-1812","score":33.895045064,"text":"\nBuild a database-driven Slackbot \n\nThis tutorial may incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nIn this tutorial, you are going to build a Slackbot which allows to search and create entries in a backend Db2 on Cloud database. The Slackbot is backed by the IBM Watson\u00ae Assistant service. You will integrate Slack and IBM Watson\u00ae Assistant using an Assistant integration. Db2 on Cloud is made available to Watson Assistant as custom extension.\n\nThe Slack integration sends messages between Slack and Watson Assistant. A custom extension, written in Python and deployed as serverless Code Engine app, exposes a REST API against the database backend.\n\nThis tutorial uses the new experience of Watson Assistant and an action skill. A former version was based on the dialog skill and the database was integrated using IBM Cloud\u00ae Functions with code written in Node.js. You can find that version of the tutorial in the [cloud-functions branch of the related code repository](https:\/\/github.com\/IBM-Cloud\/slack-chatbot-database-watson\/tree\/cloud-functions).\n\n\n\n Objectives \n\n\n\n* Build a chatbot using Watson Assistant which interacts with a database backend\n* Connect Watson Assistant to Slack using an integration\n* Create and deploy a Python database app to Code Engine\n* Access a Db2 on Cloud database via a Watson Assistant custom extension\n\n\n\nZoom\n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution19\/SlackbotArchitecture.svg)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. The user interacts with [IBM Watson\u00ae Assistant](https:\/\/cloud.ibm.com\/docs\/watson-assistant), either through Slack or using a web chat client\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"},{"document_id":"ibmcld_01090-0-821","score":33.8426619752,"text":"\n\n\n\n\n\n\n  Assessing your database compatibility \n\nIBM Database Conversion Workbench (DCW) is a no-charge plug-in that adds database migration capabilities to IBM Data Studio. You can download both Data Studio and Database Conversion Workbench from the web console.\n\nTo assess the compatibility of your database with Db2 and convert the SQL, you can also use the free, light-weight tool called [IBM Database Harmony Profiler](https:\/\/community.ibm.com\/community\/user\/hybriddatamanagement\/blogs\/jordan-hodges1\/2020\/01\/15\/introducing-database-harmony-profiler).\n\nFor more information about the Database Conversion Workbench and Database Harmony Profiler, see: [IBM Database Conversion Workbench (DCW)](https:\/\/www.ibm.com\/support\/knowledgecenter\/en\/SS6NHC\/com.ibm.swg.im.dashdb.apdv.porting.doc\/doc\/c_compat_dcw.html).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2whc?topic=Db2whc-dcw"},{"document_id":"ibmcld_01018-0-821","score":33.8426619752,"text":"\n\n\n\n\n\n\n  Assessing your database compatibility \n\nIBM Database Conversion Workbench (DCW) is a no-charge plug-in that adds database migration capabilities to IBM Data Studio. You can download both Data Studio and Database Conversion Workbench from the web console.\n\nTo assess the compatibility of your database with Db2 and convert the SQL, you can also use the free, light-weight tool called [IBM Database Harmony Profiler](https:\/\/community.ibm.com\/community\/user\/hybriddatamanagement\/blogs\/jordan-hodges1\/2020\/01\/15\/introducing-database-harmony-profiler).\n\nFor more information about the Database Conversion Workbench and Database Harmony Profiler, see: [IBM Database Conversion Workbench (DCW)](https:\/\/www.ibm.com\/support\/knowledgecenter\/en\/SSFMBX\/com.ibm.swg.im.dashdb.apdv.porting.doc\/doc\/c_compat_dcw.html).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-dcw"},{"document_id":"ibmcld_13160-14797-16607","score":33.2721734643,"text":"\nEnd the action under And then.\n13. Create a new step with the condition for 8 Ran successfully being false. Use something like It seems there was a problem creating the new event record for the Assistant to say and end the action under And then. Save and close the action with the icons in the upper right.\n14. Test the new action by clicking on Preview on the left and using the webchat. Type add new event and submit. When prompted by the bot, enter my conference as name, home office as location, pick dates for begin and end, and use [http:\/\/localhost](http:\/\/localhost) as URL. Thereafter, confirm that the data is correct.\n\n\n\nWhen creating a chatbot, you may want to [publish a chatbot](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish). It is the controlled release of a version which allows rolling back changes and to continue with development without impacting the chatbot interacting with real customers.\n\n\n\n\n\n Step 6: Integrate with Slack \n\nNow, you will integrate the chatbot with Slack.\n\n\n\n1. On the lower left, click on Integrations.\n2. In the integrations overview, in the section Channels, locate Slack and click Add.\n3. Follow the step by step instructions to integrate the Draft environment of your chatbot with Slack. More information about it is available in the topic [Integrating with Slack](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-slack).\n4. Once done, open up your Slack workspace. Begin a direct chat with the bot and say show me event details. Then, similar to above, answer with Think when prompted for an event name.\n\n\n\nZoom\n\n![Slack with the eventbot](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution19\/Slackbot_event.png)\n\nSlack with the eventbot","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.3868528072}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09118-10321-12086","score":37.9393027876,"text":"\n[View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-getting-startedgetting-started) You can use IBM Watson\u00ae Assistant to to build your own branded live chatbot into any device, application, or channel. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Natural Language Understanding](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-getting-startedgetting-started) You can use IBM Watson\u00ae Natural Language Understanding to analyze semantic features of text input, including categories, concepts, emotion, entities, keywords, metadata, relations, semantic roles, and sentiment. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Personality Insights](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-about) You can use IBM Watson\u00ae Personality Insights to analyze semantic features of text input, including categories, concepts, emotion, entities, keywords, metadata, relations, semantic roles, and sentiment. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n\n\n\n\n\n\n\n Container service integrations \n\nYou can integrate Key Protect with the following container services.\n\n\n\nTable 4. Supported container services.\n\n Service Description Integration docs \n\n [IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-getting-started) You can use the IBM Cloud Kubernetes Service service to deploy highly available apps in Docker containers that run in Kubernetes clusters. [View docs](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-encryptionkeyprotect)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-integrate-services"},{"document_id":"ibmcld_09118-9294-10691","score":36.4362698004,"text":"\n[Text to Speech](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-gettingStarted) You can use Text to Speech's speech-synthesis capabilities to convert written text into natural-sounding speech. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [Tone Analyzer](https:\/\/cloud.ibm.com\/docs\/tone-analyzer?topic=tone-analyzer-gettingStarted) You can use Tone Analyzer to detect emotional and language tones in your written texts. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/tone-analyzer?topic=tone-analyzer-gettingStarted) You can use Knowledge Studio to understand the linguistic nuances, meaning, and relationships specific to your industry. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [Watson OpenScale](https:\/\/dataplatform.cloud.ibm.com\/docs\/content\/wsj\/model\/getting-started.html) You can use Watson OpenScale to automate and maintain the AI lifecycle in your business applications. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-getting-startedgetting-started) You can use IBM Watson\u00ae Assistant to to build your own branded live chatbot into any device, application, or channel. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-integrate-services"},{"document_id":"ibmcld_09906-1621-3194","score":30.6950828948,"text":"\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --data '{\n\"url\": \"http:\/\/newsroom.ibm.com\/Guerbet-and-IBM-Watson-Health-Announce-Strategic-Partnership-for-Artificial-Intelligence-in-Medical-Imaging-Liver\",\n\"features\": {\n\"sentiment\": {},\n\"categories\": {},\n\"concepts\": {},\n\"entities\": {},\n\"keywords\": {}\n}\n}' \"{url}\/v1\/analyze?version=2019-07-12\"\n\nWindows users: This command might not run on Windows. Run the following command instead:\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --data \"{\"url\":\"http:\/\/newsroom.ibm.com\/Guerbet-and-IBM-Watson-Health-Announce-Strategic-Partnership-for-Artificial-Intelligence-in-Medical-Imaging-Liver\",\"features\":{\"sentiment\":{},\"categories\":{},\"concepts\":{},\"entities\":{},\"keywords\":{}}}\" \"{url}\/v1\/analyze?version=2019-07-12\"\n\nThe next step demonstrates how to specify options that customize the analysis for each feature.\n\n\n\n\n\n Step 2: Analyze target phrases and keywords \n\nNatural Language Understanding can analyze target phrases in context of the surrounding text for focused sentiment and emotion results. The targets option for sentiment in the following example tells the service to search for the targets \"apples\", \"oranges\", and \"broccoli\". Since \"apples\" and \"oranges\" are located in the text, sentiment scores are returned for those targets.\n\nYou can also get sentiment and emotion results for entities and keywords that are detected in your text. In the example, the emotion option for keywords tells the service to analyze each detected keyword for emotion results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-getting-started"},{"document_id":"ibmcld_07237-11651-12863","score":30.4613599805,"text":"\nFor general information about the security architecture, review [Securing AI apps: Watson on IBM Cloud security](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/securityArchitecture\/watson-security).\n\n\n\n\n\n What Watson solutions are available to respond to Covid-19 questions? \n\n[IBM Watson Assistant for Citizens](https:\/\/www.ibm.com\/watson\/covid-response) on the IBM public cloud brings together Watson Assistant, Natural Language Processing capabilities from IBM Research, and state-of-art enterprise AI search capabilities with Watson Discovery, to understand and respond to common questions about COVID-19. For information on what\u2019s available with Watson Discovery, review [Using the COVID-19 kit](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-covidkit).\n\n\n\n\n\n Can I migrate documents from one Discovery instance to another? \n\nYou cannot migrate original documents from one instance to another. Instead, ingest the documents to the newly created instance.\n\n\n\n\n\n How do I delete documents from my Discovery collection? \n\nUse the [Delete method](https:\/\/cloud.ibm.com\/apidocs\/discoverydelete-a-document) in the Discovery API to delete documents. There is no delete option within the user interface.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-troubleshoot"},{"document_id":"ibmcld_13074-16820-18514","score":30.2696230099,"text":"\nEmotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,\n\"joy\": 0.626655,\n\"anger\": 0.02303,\n\"fear\": 0.018884,\n\"sadness\": 0.096802\n}\n}\n}\n\nIn the preceding example, you could query the joy Emotion by accessing enriched_text.emotion.document.emotion.joy\n\nEmotion Analysis analyzes your text and calculates a score for each emotion (anger, disgust, fear, joy, sadness) on a scale of 0.0 to 1.0. If the score of any emotion is 0.5 or higher, then that emotion is detected. The higher the score above 0.5, the higher the relevance. In the snippet shown, joy has a score above 0.5, so Watson detected joy.\n\nEmotion Analysis is supported in English only.\n\n\n\n\n\n Element classification \n\nThe Element Classification enrichment is deprecated and will no longer be available, effective 10 July 2020.\n\nParses elements (sentences, lists, tables) in governing documents to classify important types and categories For more information, see [Element classification](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-element-classification).\n\n[Smart Document Understanding](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sdu) is unavailable if this enrichment is used.\n\n\n\n Enrichment pricing \n\nEnrichment pricing information is available on [IBM Cloud](https:\/\/cloud.ibm.com\/catalog\/services\/discovery).\n\n\n\n\n\n Enrichment language support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_09919-7713-9881","score":29.8545516469,"text":"\n: Version 2 entity type support is now available, for all public and premium service instances, for the following languages: Russian and Swedish. For details, see [Entity type systems](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-entity-type-systems).\n\n\n\n\n\n 3 August 2022 \n\nSupport for Single Label Classifications\n: Classifications now allows users to pass in a model_type training parameter when creating or updating a model, in order to train a single label classifier. See [Classifications training parameters](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-classificationsclassification-training-parameters) for more details.\n\n\n\n\n\n 11 July 2022 \n\nImproved [custom classifications](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-classifications) model - Japanese\n: Japanese custom classifications models now train and perform inference faster, with improved model results.\n\nImproved [custom categories](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-categories) model\n: Model contains improved word filtering, resulting in better category determination.\n\n\n\n\n\n 7 April 2022 \n\nCategories bug fix\n: Fixed a bug in the Version 2 Categories type system.\n\n\n\n\n\n 14 February 2022 \n\nEmotion support\n: Support for emotion is now available, for all public service instances, for French. For details, see [Language support](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-support).\n\nImproved error handling and validation for emotion\n: If a request contains both an error in the emotion feature and a valid feature request for another feature, the response returns a 200 with a warning for the emotion feature.\n: The error log has changed from emotion request must specify at least one of: document, targets to emotion request must specify at least one of: document or targets.\n: Requests that include the emotion feature with any nonstring elements in the targets list returns an error.\n\n\n\n\n\n 1 December 2021 \n\nTone analytics","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-release-notes"},{"document_id":"ibmcld_09892-7-1976","score":29.7383319762,"text":"\nAbout \n\nWith IBM Watson\u00ae Natural Language Understanding, developers can analyze semantic features of text input, including categories, concepts, emotion, entities, keywords, metadata, relations, semantic roles, and sentiment.\n\n\n\n Features \n\nSend requests to the API with text, HTML, or a public URL, and specify one or more of the following features to analyze:\n\n\n\n Categories \n\nCategorize your content using a five-level classification hierarchy. View the complete list of categories [here](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-categories-hierarchy). For example:\n\nInput\n\n> url: \"www.cnn.com\"\n\nResponse\n\n> \/news\n> \/art and entertainment\n> \/movies and tv\/television\n> \/news\n> \/international news\n\n\n\n\n\n Concepts \n\nIdentify high-level concepts that aren't necessarily directly referenced in the text. For example:\n\nInput\n\n> text: \"Natural Language Understanding uses natural language processing to analyze text.\"\n\nResponse\n\n> Linguistics\n> Natural language processing\n> Natural language understanding\n\n\n\n\n\n Emotion \n\nAnalyze emotion conveyed by specific target phrases or by the document as a whole. You can also enable emotion analysis for entities and keywords that are automatically detected by the service. For example:\n\nInput\n\n> text: \"I love apples, but I hate oranges.\"\n> targets: \"apples\", and \"oranges\"\n\nResponse\n\n> \"apples\": joy\n> \"oranges\": anger\n\n\n\n\n\n Entities \n\nFind people, places, events, and other types of entities mentioned in your content. View the complete list of entity types and subtypes [here](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-entity-type-systems). For example:\n\nInput\n\n> text: \"IBM is an American multinational technology company headquartered in Armonk, New York, United States, with operations in over 170 countries.\"\n\nResponse\n\n> IBM: Company\n> Armonk: Location\n> New York: Location\n> United States: Location\n\n\n\n\n\n Keywords","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-about"},{"document_id":"ibmcld_16261-17057-18537","score":29.4510980384,"text":"\nWhat day would you like to come in?\n>> Next Monday\nWhat time works for you?\n>> 10 AM\nOK, Robert. You have an appointment for 10:00 AM on Sep 12. See you then!\n\nSuccess! The application now uses the Watson Assistant service to understand natural-language input, and it displays the appropriate responses.\n\nThis simple example illustrates how you can build a custom client app to communicate with the assistant. Of course, a real-world application would use a more sophisticated user interface, and it might integrate with other applications such as a customer database or other business systems. It would also need to send additional data to the assistant, such as a user ID to identify each unique user. But the basic principles of how the application interacts with the Watson Assistant service would remain the same.\n\n\n\n\n\n Using the v1 runtime API \n\nUsing the v2 API is the recommended way to build a runtime client application that communicates with the Watson Assistant service. However, some older applications might still be using the v1 runtime API, which includes a similar method for sending messages to the workspace within a dialog skill. Note that if your app uses the v1 runtime API, it communicates directly with the workspace, bypassing the skill orchestration and state-management capabilities of the assistant.\n\nFor more information about the v1 \/message method and context, see the [v1 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1message).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client"},{"document_id":"ibmcld_07140-17709-19868","score":29.1388046143,"text":"\nThe emotion enrichment evaluates the overall emotional tone (for example anger) of entire document or specified target strings in the entire document. This enrichment can only be used with English content.\n\n\n\n* \"document\" : booleanoptional - When true the emotional tone of the entire document is evaluated.\n* \"targets\" : arrayoptional - A comma-separated array of target strings of which to evaluate the emotional state within the document.\n\n\n\n\n\n\n\n entities \n\nThe entities enrichment extracts instances of known entities such as people, places, and organizations. Optionally, a Knowledge Studio custom model can be specified to extract custom entities.\n\n\n\n* \"sentiment\" : boolean - optional - When true, sentiment analysis is performed on the extracted entity in the context of the surrounding content.\n* \"emotion\" : boolean - optional - When true, emotional tone analysis is performed on the extracted entity in the context of the surrounding content.\n* \"limit\" : INT - optional - The maximum number of entities to extract from the ingested document. The default is 50.\n* \"mentions\": boolean - optional - When true, the number of times that this entity is mentioned is recorded. The default is false.\n* \"mention_types\": boolean - optional - When true, the mention type for each mention of this entity is stored. The default is false.\n* \"sentence_location\": boolean - optional - When true, the sentence location of each entity mention is stored. The default is false.\n* \"model\" : string - optional - When specified, the custom model is used to extract entities instead of the public model. This option requires a Knowledge Studio custom model to be associated with your instance of Discovery. See [Integrating with Watson Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-integrating-with-wks) for more information.\n\n\n\n\n\n\n\n keywords \n\nThe keywords enrichment extracts instances of significant words within the text. To understand the difference between keywords, concepts, and entities, see [Understanding the difference between Entities, Concepts, and Keywords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configserviceudbeck).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configref"},{"document_id":"ibmcld_16299-7-2120","score":28.968467231,"text":"\nOverview: Customizing and developing \n\nThe Watson Assistant user interface makes it easy to build an assistant and deploy it to your customers without writing any code. For advanced users and developers, there are powerful ways you can further customize and extend the capabilities of your assistant.\n\nA deployed assistant includes numerous components that work together to deliver the help your customers need over the channels they use.\n\n![Watson Assistant architecture diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/arch-detail.png)\n\n\n\n* Customers interact with the assistant using a channel such as the web chat or phone integration.\n* Based on natural language understanding, the assistant makes a decision about how to route the customer's request to the appropriate resolution mechanism, which might be an action or a search of existing content.\n* The assistant might also need to communicate with external services or hand off the conversation to a human agent.\n\n\n\nThere are multiple points at which a developer can customize and extend how the assistant behaves, or how it interacts with external services. These customization points include the following:\n\n\n\n* Customizing actions: By writing expressions and editing JSON data, you can extensively customize how an action evaluates step conditions, how it stores data, how it responds to customer input, and how it interacts with channels. (More information coming soon.)\n* [Web chat development overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop): You can use the web chat API to extensively customize the appearance and behavior of the web chat.\n* Customizing the phone integration: You can use commands and context variables to extensively configure how your assistant interacts with users using the phone integration. (More information coming soon.)\n* Customizing the SMS integration: You can use commands and context variables to customize how your assistant interacts with users using text messages. (More information coming soon.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-develop-overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1815417925,"ndcg_cut_10":0.3228087654}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16306-2449-4025","score":11.1942962456,"text":"\nFor more information, see [Managing user identity information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid). \n Slack The Slack member ID (for example, U2147483697). \n Facebook The Facebook sender ID (for example, 4310101122439797). \n Whatsapp The customer's phone number. \n Phone The customer's phone number. \n SMS with Twilio The customer's phone number. \n\n\n\n\n\n\n\n\n\n chat \n\nIncluded only if the web chat integration is in use.\n\n\n\n Properties \n\n\n\nProperties of the chat object\n\n Name Type Description \n\n browser_info.browser_name String The browser name, such as chrome, edge, or firefox. \n browser_info.browser_version String The browser version, such as 109.0.0. \n browser_info.browser_OS String The operating system of the customer's computer, such as Mac OS. \n browser_info.language String The default locale code of the browser, such as en-US. \n browser_info.page_url String The URL of the web page where the web chat is embedded, not including any query parameters or hashes. \n browser_info.screen_resolution String The height and width of the browser window, such as width: 1440, height: 900. \n browser_info.user_agent String The content of the HTTP User-Agent request header. \n browser_info.client_ip_address String The IP address of the customer's computer. \n browser_info.ip_address_list Array Ann array IP addresses specified by HTTP X-Forwarded-For request headers. \n\n\n\n\n\n\n\n Example JSON \n\n\"chat\": {\n\"browser_info\": {\n\"browser_name\": \"chrome\",\n\"browser_version\": \"109.0.0\",\n\"browser_OS\": \"Mac OS\",\n\"language\": \"en-US\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-expression-integration-variables"},{"document_id":"ibmcld_02280-0-1181","score":11.1107897707,"text":"\n\n\n\n\n\n\n  Why do I encounter console pages that don't load? \n\nA page in the IBM Cloud\u00ae console might not load properly, and an error message is displayed.\n\n  What\u2019s happening \n\nOne of the following error messages might be displayed:\n\n> BXNUI0001E: The page wasn't loaded because IBM Cloud didn't detect whether a session exists.\n\nor\n\n> BXNUI0016E: The apps and services weren't retrieved because an IBM Cloud page didn't load.\n\nor\n\n> 500 internal server error\n\n  Why it\u2019s happening \n\nAn issue with the browser is causing a console page to not load. Or, there might be a temporary issue with connectivity.\n\n  How to fix it \n\nComplete one or more of the following actions, as necessary:\n\n\n\n*  Refresh or restart your browser.\n*  Log out of the console and log in again.\n*  Use the private browsing mode of your browser.\n*  Clear the cookies and the cache of the browser.\n*  Use a different browser. For the list of supported browsers, see [IBM Cloud prerequisites](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-prereqs-platform).\n*  If the problem persists, go to the [IBM Cloud Status page](https:\/\/cloud.ibm.com\/status) to check if a service or component has an issue.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-ts_err"},{"document_id":"ibmcld_04083-20934-23210","score":11.0660750502,"text":"\nThis issue can occur when another user or application installs the smart contract onto the peer and you do not have the peer admin identity in your browser wallet.\n\n How to fix it \n\nIn order to view the smart contracts installed on a peer, you need to be a peer admin. Ensure that the peer admin identity exists in your browser wallet. If it does not, you need to import it into your console wallet.\n\n\n\n\n\n My nodes, channels, smart contracts, and identities have disappeared from the console. How can I get them back? \n\n What\u2019s happening \n\nNodes, identities, channels, or smart contracts (or some combination of these) that I successfully deployed into the console are no longer available.\n\n Why it\u2019s happening \n\nOne of the features of IBM Blockchain Platform is that you are now responsible for securing and managing your certificates. Therefore, they are only persisted in the browser local storage to allow you to manage the component. If you are using a private browser window and then switch to another browser or non-private browser window, the identities that you created will be gone from your wallet in the new browser session. Therefore, it is required that you export the identities from the wallet in your private browser session to your file system. You can then import them into your non-private browser session if they are needed. Otherwise, there is no way to recover them.\n\n How to fix it \n\n\n\n* Whenever you create a new organization MSP definition, you generate keys for an identity that is allowed to administer the organization. Therefore, during that process you must click the Generate and then Export buttons to store the generated identity in your wallet and then save it to your file system as a JSON file.\n* To resolve this problem in your browser, you need to import those identities and associate them with the corresponding node:\n\n\n\n* In the browser where you are experiencing the problem, click the Wallet tab followed by Add identity to import the JSON file into your wallet.\n* Click Upload JSON and browse to the JSON file you exported using the Add files button.\n* Click Submit.\n* Now open the peer or ordering service node that this identity was originally associated to, and click on the Settings icon.\n* Click the Associate identity button.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshooting"},{"document_id":"ibmcld_13793-6227-7787","score":11.0571325618,"text":"\nGA en-US_EmilyV3Voice <br>Female Your browser does not support the audio tag. \n GA en-US_HenryV3Voice <br>Male Your browser does not support the audio tag. \n GA en-US_KevinV3Voice <br>Male Your browser does not support the audio tag. \n GA en-US_LisaV3Voice <br>Female Your browser does not support the audio tag. \n GA en-US_MichaelV3Voice <br>Male Your browser does not support the audio tag. \n GA en-US_OliviaV3Voice <br>Female Your browser does not support the audio tag. \n French <br>(Canadian) GA fr-CA_LouiseV3Voice <br>Female Your browser does not support the audio tag. \n French <br>(France) GA fr-FR_NicolasV3Voice <br>Male Your browser does not support the audio tag. \n GA fr-FR_ReneeV3Voice <br>Female Your browser does not support the audio tag. \n German GA de-DE_BirgitV3Voice <br>Female Your browser does not support the audio tag. \n GA de-DE_DieterV3Voice <br>Male Your browser does not support the audio tag. \n GA de-DE_ErikaV3Voice <br>Female Your browser does not support the audio tag. \n Italian GA it-IT_FrancescaV3Voice <br>Female Your browser does not support the audio tag. \n Japanese GA ja-JP_EmiV3Voice <br>Female Your browser does not support the audio tag. \n Korean GA ko-KR_JinV3Voice <br>Female Your browser does not support the audio tag. \n Portuguese <br>(Brazilian) GA pt-BR_IsabelaV3Voice <br>Female Your browser does not support the audio tag. \n Spanish <br>(Castilian) GA es-ES_EnriqueV3Voice <br>Male Your browser does not support the audio tag. \n GA es-ES_LauraV3Voice <br>Female Your browser does not support the audio tag.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices"},{"document_id":"ibmcld_13761-5201-6996","score":11.0243038397,"text":"\ncurl -X POST --header \"Authorization: Bearer {token}\" --header \"Content-Type: application\/json\" --header \"Accept: audio\/wav\" --output partial-cheerful-style.wav --data \"{\"text\":\"<express-as style='cheerful'>Oh, that's good news!<\/express-as> Do you need any further help?\"}\" \"{url}\/v1\/synthesize?voice=en-US_EmmaExpressive\"\n\n\n\n\n\n\n\n Emphasizing interjections \n\nWhen you use expressive neural voices, the service automatically detects a number of common interjections based on context. In the resulting audio, it gives them the natural emphasis that a human would use in normal conversation.\n\nTable 2 lists the interjections that the service recognizes and provides examples of how they are pronounced in synthesized speech. The samples use the en-US_AllisonExpressive voice. The table shows the primary spelling of each interjection. The service recognizes alternative spellings for some of the interjections. For example, oh and ohh produce the same sound, as do hmm and hmmm. However, the service produces slightly different pronunciations for other alternative spellings, such as ooh and uhm,\n\n\n\nTable 2. Interjections that are emphasized\n\n Interjection Example sentence Audio sample \n\n aha \"Aha. So that's the secret.\" Your browser does not support the audio tag. \n hmm \"Hmm. I'm not sure I understand.\" Your browser does not support the audio tag. \n huh \"Huh, I hadn't noticed that.\" Your browser does not support the audio tag. \n oh \"Oh, let me get that for you.\" Your browser does not support the audio tag. \n uh \"Uh, let me check.\" Your browser does not support the audio tag. \n uh-huh \"Uh-huh, that's right.\" Your browser does not support the audio tag. \n um \"That's, um, not quite right.\" Your browser does not support the audio tag. \n\n\n\n\n\n Enabling or disabling interjections with SSML","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-synthesis-expressive"},{"document_id":"ibmcld_13793-4723-6539","score":10.8630755436,"text":"\nEnglish <br>(Australian) GA en-AU_HeidiExpressive <br>Female Your browser does not support the audio tag. \n GA en-AU_JackExpressive <br>Male Your browser does not support the audio tag. \n English <br>(United States) GA en-US_AllisonExpressive <br>Female Your browser does not support the audio tag. \n GA en-US_EmmaExpressive <br>Female Your browser does not support the audio tag. \n GA en-US_LisaExpressive <br>Female Your browser does not support the audio tag. \n GA en-US_MichaelExpressive <br>Male Your browser does not support the audio tag. \n\n\n\n\n\n\n\n Enhanced neural voices \n\nTable 3 lists and provides audio samples for all available enhanced neural voices. The Availability column indicates whether each voice is generally available (GA) for production use or beta. The column also indicates whether each voice is available for\n\nIBM Cloud\n\n,\n\nIBM Cloud Pak for Data\n\n, or both (no product version is cited).\n\n\n\nTable 3. Enhanced neural languages and voices\n\n Language Availability Voice \/ Gender Audio sample \n\n Dutch <br>(Netherlands) Beta nl-NL_MerelV3Voice <br>Female Your browser does not support the audio tag. \n English <br>(United Kingdom) GA en-GB_CharlotteV3Voice <br>Female Your browser does not support the audio tag. \n GA en-GB_JamesV3Voice <br>Male Your browser does not support the audio tag. \n GA en-GB_KateV3Voice <br>Female Your browser does not support the audio tag. \n English <br>(United States) GA en-US_AllisonV3Voice <br>Female Your browser does not support the audio tag. \n GA en-US_EmilyV3Voice <br>Female Your browser does not support the audio tag. \n GA en-US_HenryV3Voice <br>Male Your browser does not support the audio tag. \n GA en-US_KevinV3Voice <br>Male Your browser does not support the audio tag. \n GA en-US_LisaV3Voice <br>Female Your browser does not support the audio tag.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices"},{"document_id":"ibmcld_08197-0-402","score":10.75744057,"text":"\n\n\n\n\n\n\n  Supported browsers \n\nFor a list of supported browsers, see [Required Browsers for IBM Cloud\u00ae](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-prereqs-platformbrowsers-platform).\n\nFor Safari, clear the options Prevent cross-site tracking and Block all cookies under Safari > Preferences > Privacy.\n\nIf you encounter problems when you use these browsers, disable your browser plug-ins.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-help-support-browsers"},{"document_id":"ibmcld_14076-2554-4278","score":10.7198770204,"text":"\nIf you use a security group to protect your virtual servers, you need to allow SSH traffic. For more information, see [Creating security groups and rules](https:\/\/cloud.ibm.com\/docs\/security-groups?topic=security-groups-creating-security-groups).\n\n\n\n\n\n\n\n Why can't I access KVM through a browser? \n\nIf you are unable to connect to the KVM console, review the following troubleshooting tips for help. For more information about accessing the KVM, see [Accessing the KVM console for virtual servers](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-access-kvm-console).\n\n\n\n* [Browser needs updating](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-troubleshooting-virtual-serverupdate-browser)\n* You haven\u2019t [established a VPN connection](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-troubleshooting-virtual-servervpn-connection)\n* Your [credentials are invalid](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-troubleshooting-virtual-servercheck-credentials)\n\n\n\n\n\n Browser needs updating \n\nMake sure that you're using a supported browser. For more information about IBM Cloud\u00ae-supported browsers, see [Browsers](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-prereqs-platformbrowsers-platform).\n\nThe KVM Console opens in a new browser tab or window. If the KVM Console doesn't open, check the browser for any blocked new windows.\n\nIf you can't access KVM through your browser, you might need to update your browser. Update your browser and try to access KVM.\n\n\n\n\n\n A VPN connection isn't established \n\nMake sure that a connection is established by using the VPN. If a connection isn't established, a warning displays that a VPN connection is required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-troubleshooting-virtual-server"},{"document_id":"ibmcld_06942-4977-6807","score":10.7158004565,"text":"\n[Help icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/help.svg) from the header of any page in the product user interface to open the Discovery documentation.\n\n\n\n\n\n Browser support \n\nIBM Cloud Pak for Data\n\n\n\n* The minimum required browser software for the product user interface includes the following browsers:\n\nGoogle Chrome\n: Latest version -1 for your operating system\n\nMozilla Firefox\n: Latest regular -1 and Extended Support Release (ESR) version for your operating system\n\nMicrosoft Edge\n: Latest version -1 for Windows\n\nApple Safari\n: Latest version -1 for Mac\n* The IBM Cloud Pak for Data web client where you create service instances supports the IBM Cloud Pak for Data requirements. For more information, see [Supported web browsers](https:\/\/www.ibm.com\/docs\/en\/cloud-paks\/cp-data\/4.6.x?topic=requirements-softwaresoftware-reqs__web)\n\n\n\nIBM Cloud\n\n\n\n* Deployments of Discovery that are managed by IBM Cloud follow the IBM Cloud requirements. For more information, see [Prerequisites](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-prereqs-platform)\n* For more information about browser support for deployments that are provisioned with Cloud Pak for Data as a Service, see [Which web browsers are supported for Cloud Pak for Data as a Service](https:\/\/dataplatform.cloud.ibm.com\/docs\/content\/wsj\/getting-started\/browser-support.html).\n\n\n\n\n\n\n\n Language support \n\nLanguage support by feature is detailed in the [Supported languages](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support) topic.\n\n\n\n\n\n Beta features \n\nIBM releases services, features, and language support for your evaluation that are classified as beta. These features might be unstable, might change frequently, and might be discontinued with short notice.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-about"},{"document_id":"ibmcld_04083-11129-13211","score":10.7058209599,"text":"\nWhy are my console actions failing in my Chrome browser Version 77.0.3865.90 (Official Build) (64-bit)? \n\n What\u2019s happening \n\nThe console has been working successfully, but requests have started to fail. For example, after I create an ordering service and open it I see the error: Unable to get system channel. If you associated an identity without administrative privilege on the ordering service node, you will not be able to view or manage ordering service details.\n\n Why it\u2019s happening \n\nThis problem can be caused by a [bug](https:\/\/bugs.chromium.org\/p\/chromium\/issues\/detail?id=1006243) introduced by the Chrome browser Version 77.0.3865.90 (Official Build) (64-bit) that causes actions from the browser to fail.\n\n How to fix it \n\nTo resolve this problem, open the console in a new browser tab in Chrome. Any identities that you saved in your console wallet will persist in the new browser tab. To avoid this problem you can upgrade your Chrome browser version. Ensure you have downloaded all of your wallet identities to your local machine before closing your browser.\n\n\n\n\n\n When I hover over my node, the status is Status unavailable or Status unknown, what does this mean? \n\n What\u2019s happening \n\nA CA, peer, or ordering node has a gray status box, meaning the status of the node is not available. Ideally, when you hover over any node, the node status should be Running.\n\n Why it\u2019s happening \n\nThis problem can occur if the node is newly created and the deployment process has not completed. If the node is a CA and the status has been gray for more than a few minutes, then it is likely that the deployment process has failed. Peers and ordering nodes take longer to deploy, but this condition can also occur when the health checker that runs against the peer or ordering nodes cannot contact the node. The request for status can fail with a timeout error because the node did not respond within a specific time period, the node could be down, or network connectivity is down.\n\n How to fix it \n\nIf this is a new node, wait a few more minutes for the deployment to complete.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-troubleshooting"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16364-25047-26964","score":39.6871997533,"text":"\nAutocorrection fixes misspellings that users make in their requests. The corrected words are used to match to an action.\n\nWhile the setting is new, the autocorrection feature was already used automatically by all English-language assistants. Autocorrection is also available in French-language assistants, but is disabled by default. The autocorrection setting isn't available for any other languages. The new setting lets you disable or enable autocorrection if necessary.\n\nFor more information, see [Autocorrecting user input](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-autocorrection).\n\nImproved experience when setting a variable value\n: The dropdown list for setting a variable value within an action step has a new organization. The new list is intended to provide an improved experience.\n\n\n\n\n\n 11 January 2023 \n\nAlgorithm version 01-Jun-2022 uses enhanced intent detection by default\n: As of this date, the algorithm version Latest (01-Jun-2022) now uses enhanced intent detection by default. Before this change, some skills that did not include a specific algorithm version selection inadvertently used Previous (01-Jan-2022). You can notice small changes in intent detection behavior when changes are made to an assistant that previously didn't have enhanced intent detection enabled. For more information, see [Algorithm version and training](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-algorithm-version).\n\n\n\n\n\n 6 December 2022 \n\nUpdated expression methods\n: The following new and updated methods are available in expressions:\n\n\n\n* The [Array.joinToArray()](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-expression-methods-actionsexpression-methods-actions-arrays-join-to-array) method now supports a new boolean parameter you can use to specify that the data type of values from the input array should be preserved in the returned array.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_16313-8575-10638","score":38.8555298962,"text":"\nFor more information on uploading or downloading example phrases, see [Adding more examples](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questionsunderstand-questions-adding-more-examples).\n\n\n\n\n\n\n\n Editing the fallback action \n\nThe built-in Fallback action is automatically provided with each assistant and cannot be deleted. However, you can edit the Fallback action to modify the conversation your users have with the assistant when errors occur. For example, you might want to add steps or modify step conditions to provide more control over how specific error conditions are handled.\n\nTo edit the Fallback action, click Set by assistant in the list of actions, and then click Fallback.\n\nZoom\n\n![Fallback built-in action](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/fallback-action.png)\n\nFallback built-in action\n\nWhenever the Fallback action is triggered, the assistant also sets a value for the Fallback reason session variable. This value indicates what kind of situation led to the Fallback action being triggered. By default, this variable can have one of five values:\n\n\n\n* Step validation failed: The customer repeatedly gave answers that were not valid for the expected customer response type.\n* Agent requested: The customer directly asked to be connected to a live agent.\n* No action matches: The customer repeatedly made requests or asked questions that the assistant did not understand.\n* Danger word detected: The customer uses words or phrases that match the Connect to agent step in the Trigger word detected action.\n* Profanity detected: The customer repeatedly used words or phrases that match the Show warning step in the Trigger word detected action.\n\n\n\nFor more information about the Trigger word detected action, see [Detecting trigger words](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-trigger-words).\n\nThe Fallback action defines five conditional steps, one for each possible value of the Fallback reason variable.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errors"},{"document_id":"ibmcld_16313-10077-11045","score":38.6324382562,"text":"\n* Danger word detected: The customer uses words or phrases that match the Connect to agent step in the Trigger word detected action.\n* Profanity detected: The customer repeatedly used words or phrases that match the Show warning step in the Trigger word detected action.\n\n\n\nFor more information about the Trigger word detected action, see [Detecting trigger words](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-trigger-words).\n\nThe Fallback action defines five conditional steps, one for each possible value of the Fallback reason variable. Each step sends a message to the customer, based on the error condition, and then uses the Connect to agent feature to transfer the conversation to a live agent. (For more information about this feature, see [Connecting to a live agent](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-human-agent).) You can modify these steps if you want to handle an error condition in a different way.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errors"},{"document_id":"ibmcld_16356-7-2036","score":37.3478315834,"text":"\nDetecting trigger words \n\nUse the Trigger word detected action to add words or phrases to two separate groups. The first group connects customers with an agent. The second group shows customers a customizable warning message.\n\nBy default, this action has two steps\u2014the Connect to agent step and the Show warning step. To see how this action works, click Set by assistant in the list of actions, and then click Trigger word detected.\n\nThis is a beta feature that is available for evaluation and testing purposes.\n\n\n\n Connect to agent \n\nThe first step of the Trigger word detected action is the Connect to agent step. The Connect to agent step goes to the Fallback action if any trigger words are detected in the customer's input. Use this step to capture any key phrases where it\u2019s important to connect a customer with a live agent rather than activate any further actions.\n\nFor example, you might add hurt and harm as trigger words for the Connect to agent step:\n\nZoom\n\n![Adding trigger words to the Connect to agent step](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/connect-to-agent-phrases.png)\n\nAdding trigger words to the Connect to agent step\n\nIn this example, a customer enters a word or phrase including hurt or harm, which triggers the Fallback action. Step 4 has:\n\n\n\n* Danger word detected as the fallback reason.\n* The default message: It seems this conversation would be best managed by a human agent. Let me connect you to one of our agents. You can customize this message.\n* And then set to Connect to agent (action ends).\n\n\n\nFor more information about the Fallback action, see [Editing the fallback action](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errorsfallback-action).\n\n\n\n\n\n Show warning \n\nThe second and final step of the Trigger word detected action is the Show warning step. The Show warning step shows a customizable warning message to your customer if any trigger words are detected in the customer's input.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-trigger-phrases"},{"document_id":"ibmcld_16356-1613-3336","score":36.6329929423,"text":"\nFor more information about the Fallback action, see [Editing the fallback action](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errorsfallback-action).\n\n\n\n\n\n Show warning \n\nThe second and final step of the Trigger word detected action is the Show warning step. The Show warning step shows a customizable warning message to your customer if any trigger words are detected in the customer's input. Use this step to discourage customers from interacting with your assistant in unacceptable ways, such as using profanity.\n\nFor example, you might add darn, dang, and heck as trigger words for the Show warning step:\n\nZoom\n\n![Adding trigger words to the Show warning step](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/show-warning-phrases.png)\n\nAdding trigger words to the Show warning step\n\nIn this example, a customer enters darn, dang, or heck, the assistant responds with Please use appropriate language when interacting with the assistant. You can customize this message.\n\nIf the customer triggers the Show warning step again, the Fallback action is triggered. The default setting is if attempts exceed 2 total tries. You can customize this setting.\n\nIn the Fallback action, step 5 has:\n\n\n\n* Profanity detected as the fallback reason.\n* The default message: It seems this conversation would be best managed by a human agent. Let me connect you to one of our agents. You can customize this message.\n* And then set to Connect to agent (action ends).\n\n\n\nFor more information about the Fallback action, see [Editing the fallback action](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errorsfallback-action).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-trigger-phrases"},{"document_id":"ibmcld_16251-6430-8753","score":35.0896867208,"text":"\nPortuguese (Brazilian) (pt-br) GA GA GA \n Spanish (es) GA GA GA \n Universal (xx) GA GA GA \n\n\n\nThe Watson Assistant service supports multiple languages as noted, but the user interface itself (such as descriptions and labels) is in English. All supported languages can be input and trained through the English interface.\n\nGB18030 compliance: GB18030 is a Chinese standard that specifies an extended code page for use in the Chinese market. This code page standard is important for the software industry because the China National Information Technology Standardization Technical Committee mandates that any software application that is released for the Chinese market after September 1, 2001, be enabled for GB18030. The Watson Assistant service supports this encoding, and is certified GB18030-compliant\n\n\n\n\n\n\n\n Changing an assistant language \n\nAfter an assistant is created, its language cannot be modified.\n\n\n\n\n\n Working with accented characters \n\nIn a conversational setting, users might or might not use accents with the Watson Assistant service. As such, both accented and nonaccented versions of words might be treated the same for intent detection and entity recognition.\n\nHowever, for some languages like Spanish, some accents can alter the meaning of the entity. Thus, for entity detection, although the original entity might implicitly have an accent, your assistant can also match the nonaccented version of the same entity, but with a slightly lower confidence score.\n\nFor example, for the word \"barri\u00f3\", which has an accent and corresponds to the past tense of the verb \"barrer\" (to sweep), your assistant can also match the word \"barrio\" (neighborhood), but with a slightly lower confidence.\n\nThe system provides the highest confidence scores in entities with exact matches. For example, barrio isn't detected if barri\u00f3 is in the training set; and barri\u00f3 isn't detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words that use the Spanish letter \u00f1 versus the letter n, such as \"u\u00f1a\" versus \"una\". In this case, the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-language-support"},{"document_id":"ibmcld_03040-8421-10433","score":34.9101866801,"text":"\nThe extension inspector shows detailed information about what data is being sent to and returned from an external API. For details, see [Debugging failures](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-call-extensionextension-debug).\n\nNew expression choice for setting a session variable\n: Previously, to use an expression to set or modify a variable value, you needed to pick an existing variable or create a new one and select the expression option. Now you can use a new Expression choice to write an expression directly without first picking a variable. For details, see [Storing a value in a session variable](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-manage-infostore-session-variable).\n\nUsing the Cloud Object Storage importer to migrate chat logs\n: You can use the Cloud Object Storage importer service to migrate your chat logs from one installation of Watson Assistant to another.For more information, see [Using the Cloud Object Storage importer to migrate chat logs](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-cos-importer).\n\n\n\n\n\n 2 May 2023 \n\nIBM Watson\u00ae Assistant Cartridge for IBM Cloud Pak\u00ae for Data Version 4.6.5 is available\n: Watson Assistant for IBM Cloud Pak\u00ae for Data 4.6.5 is compatible with IBM Cloud Pak\u00ae for Data Version 4.6. See the [support matrix](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-installinstall-support-matrix) for more details. This release of Watson Assistant for IBM Cloud Pak\u00ae for Data includes various fixes and features.\n\nAlgorithm version 01-Jun-2022 uses enhanced intent detection by default\n: The algorithm version Latest (01-Jun-2022) now uses enhanced intent detection by default. Before this change, some skills that did not include a specific algorithm version selection inadvertently used Previous (01-Jan-2022). You can notice small changes in intent detection behavior when changes are made to an assistant that previously didn't have enhanced intent detection enabled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-release-notes"},{"document_id":"ibmcld_13074-16820-18514","score":34.6620954375,"text":"\nEmotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,\n\"joy\": 0.626655,\n\"anger\": 0.02303,\n\"fear\": 0.018884,\n\"sadness\": 0.096802\n}\n}\n}\n\nIn the preceding example, you could query the joy Emotion by accessing enriched_text.emotion.document.emotion.joy\n\nEmotion Analysis analyzes your text and calculates a score for each emotion (anger, disgust, fear, joy, sadness) on a scale of 0.0 to 1.0. If the score of any emotion is 0.5 or higher, then that emotion is detected. The higher the score above 0.5, the higher the relevance. In the snippet shown, joy has a score above 0.5, so Watson detected joy.\n\nEmotion Analysis is supported in English only.\n\n\n\n\n\n Element classification \n\nThe Element Classification enrichment is deprecated and will no longer be available, effective 10 July 2020.\n\nParses elements (sentences, lists, tables) in governing documents to classify important types and categories For more information, see [Element classification](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-element-classification).\n\n[Smart Document Understanding](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sdu) is unavailable if this enrichment is used.\n\n\n\n Enrichment pricing \n\nEnrichment pricing information is available on [IBM Cloud](https:\/\/cloud.ibm.com\/catalog\/services\/discovery).\n\n\n\n\n\n Enrichment language support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_16364-192793-195089","score":33.8985205611,"text":"\nThe name you specify is saved as a title attribute of the node in the workspace JSON file and the system uses a unique ID that is stored in the name attribute to reference the node.\n\n\n\n\n\n 23 August 2017 \n\nUpdates to Korean, Japanese, and Italian\n: Language support has been enhanced for Korean, Japanese, and Italian. Note that the Watson Assistant service learning models may have been updated as part of this enhancement, and when you retrain your model any changes will be applied.\n\n\n\n\n\n 10 August 2017 \n\nAccent normalization\n: In a conversational setting, users may or may not use accents while interacting with the Watson Assistant service. As such, an update has been made to the algorithm so that accented and non-accented versions of words are treated the same for intent detection and entity recognition.\n\nHowever, for some languages like Spanish, some accents can alter the meaning of the entity. Thus, for entity detection, although the original entity may implicitly have an accent, your assistant can also match the non-accented version of the same entity, but with a slightly lower confidence score.\n\nFor example, for the word barri\u00f3, which has an accent and corresponds to the past tense of the verb barrer (to sweep), your assistant can also match the word barrio (neighborhood), but with a slightly lower confidence.\n\nThe system will provide the highest confidence scores in entities with exact matches. For example, barrio will not be detected if barri\u00f3 is in the training set; and barri\u00f3 will not be detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, then you should put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words using, for example, the Spanish letter \u00f1 vs. the letter n, such as u\u00f1a vs. una. In this case the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.\n\nYou can enable fuzzy matching if you think your customers will not use the appropriate accents, or misspell words (including, for example, putting a n instead of a \u00f1), or you can explicitly include them in the training examples.\n\nNote: Accent normalization is enabled for Portuguese, Spanish, French, and Czech.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03353-8238-10149","score":33.7854186327,"text":"\n[Bidi options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/bidi-options.png)\n3. Click the X to close the page. Your changes are saved automatically.\n\n\n\n\n\n\n\n Working with accented characters \n\nIn a conversational setting, users might or might not use accents while interacting with the Watson Assistant service. As such, both accented and non-accented versions of words might be treated the same for intent detection and entity recognition.\n\nHowever for some languages, like Spanish, some accents can alter the meaning of the entity. Thus, for entity detection, although the original entity might implicitly have an accent, your assistant can also match the non-accented version of the same entity, but with a slightly lower confidence score.\n\nFor example, for the word \"barri\u00f3\", which has an accent and corresponds to the past tense of the verb \"barrer\" (to sweep), your assistant can also match the word \"barrio\" (neighborhood), but with a slightly lower confidence.\n\nThe system will provide the highest confidence scores in entities with exact matches. For example, barrio will not be detected if barri\u00f3 is in the training set; and barri\u00f3 will not be detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, then you should put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words using, for example, the Spanish letter \u00f1 vs. the letter n, such as \"u\u00f1a\" vs. \"una\". In this case the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.\n\nYou can enable fuzzy matching if you think your customers will not use the appropriate accents, or misspell words (including, for example, putting a n instead of a \u00f1), or you can explicitly include them in the training examples.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1480409555}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09919-7713-9881","score":28.4942937402,"text":"\n: Version 2 entity type support is now available, for all public and premium service instances, for the following languages: Russian and Swedish. For details, see [Entity type systems](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-entity-type-systems).\n\n\n\n\n\n 3 August 2022 \n\nSupport for Single Label Classifications\n: Classifications now allows users to pass in a model_type training parameter when creating or updating a model, in order to train a single label classifier. See [Classifications training parameters](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-classificationsclassification-training-parameters) for more details.\n\n\n\n\n\n 11 July 2022 \n\nImproved [custom classifications](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-classifications) model - Japanese\n: Japanese custom classifications models now train and perform inference faster, with improved model results.\n\nImproved [custom categories](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-categories) model\n: Model contains improved word filtering, resulting in better category determination.\n\n\n\n\n\n 7 April 2022 \n\nCategories bug fix\n: Fixed a bug in the Version 2 Categories type system.\n\n\n\n\n\n 14 February 2022 \n\nEmotion support\n: Support for emotion is now available, for all public service instances, for French. For details, see [Language support](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-support).\n\nImproved error handling and validation for emotion\n: If a request contains both an error in the emotion feature and a valid feature request for another feature, the response returns a 200 with a warning for the emotion feature.\n: The error log has changed from emotion request must specify at least one of: document, targets to emotion request must specify at least one of: document or targets.\n: Requests that include the emotion feature with any nonstring elements in the targets list returns an error.\n\n\n\n\n\n 1 December 2021 \n\nTone analytics","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-release-notes"},{"document_id":"ibmcld_13761-7-2364","score":27.1186896529,"text":"\nModifying speech synthesis with expressive neural voices \n\nThe expressive neural voices that are available with the IBM Watson\u00ae Text to Speech service offer some additional features that are not available with other types of voices: using speaking styles, emphasizing interjections, and emphasizing words. These features are available for both the HTTP and WebSocket interfaces.\n\nThe features involve the use of elements of the Speech Synthesis Markup Language (SSML). The descriptions of the features provide information about how they interact with related SSML elements and attributes.\n\n\n\n Using speaking styles \n\nThe expressive neural voices determine the sentiment of the text from the context of its words and phrases. The speech that they produce, in addition to having a very conversational style, reflects the mood of the text. The expressive voices naturally express gratitude, thankfulness, happiness, empathy, confusion, and other sentiments by default, with no explicit additional tagging.\n\nHowever, you can embellish the voices' natural tendencies by using the <express-as> element with the required style attribute to indicate that all or some of the text is to emphasize specific characteristics. These characteristics are referred to as speaking styles:\n\n\n\n* cheerful - Expresses happiness and good news. The style is upbeat, welcoming, and conveys a positive message.\n* empathetic - Expresses empathy and compassion. The style has sympathetic undertones, but it is not excessively sorrowful.\n* neutral - Expresses objectivity and evenness. The style strives for less emotion, and instead conveys a more even and instructional tone.\n* uncertain - Expresses uncertainty and confusion. The style conveys the feeling of being unsure or in doubt.\n\n\n\nIn many cases, the effect of the styles is very subtle. In such cases, the differences might not be readily discernible from the default expressive tone. But there are instances where the style can audibly enhance the voices' inherent ability to detect and express emotion. The differences are often detectable only on certain words and phrases.\n\nTable 1 provides examples of each available style for the <express-as> element. To demonstrate the effect of the styles, the table provides two samples for each example. The first sample speaks the text with the default en-US_EmmaExpressive voice.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-synthesis-expressive"},{"document_id":"ibmcld_07140-17709-19868","score":25.2787924457,"text":"\nThe emotion enrichment evaluates the overall emotional tone (for example anger) of entire document or specified target strings in the entire document. This enrichment can only be used with English content.\n\n\n\n* \"document\" : booleanoptional - When true the emotional tone of the entire document is evaluated.\n* \"targets\" : arrayoptional - A comma-separated array of target strings of which to evaluate the emotional state within the document.\n\n\n\n\n\n\n\n entities \n\nThe entities enrichment extracts instances of known entities such as people, places, and organizations. Optionally, a Knowledge Studio custom model can be specified to extract custom entities.\n\n\n\n* \"sentiment\" : boolean - optional - When true, sentiment analysis is performed on the extracted entity in the context of the surrounding content.\n* \"emotion\" : boolean - optional - When true, emotional tone analysis is performed on the extracted entity in the context of the surrounding content.\n* \"limit\" : INT - optional - The maximum number of entities to extract from the ingested document. The default is 50.\n* \"mentions\": boolean - optional - When true, the number of times that this entity is mentioned is recorded. The default is false.\n* \"mention_types\": boolean - optional - When true, the mention type for each mention of this entity is stored. The default is false.\n* \"sentence_location\": boolean - optional - When true, the sentence location of each entity mention is stored. The default is false.\n* \"model\" : string - optional - When specified, the custom model is used to extract entities instead of the public model. This option requires a Knowledge Studio custom model to be associated with your instance of Discovery. See [Integrating with Watson Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-integrating-with-wks) for more information.\n\n\n\n\n\n\n\n keywords \n\nThe keywords enrichment extracts instances of significant words within the text. To understand the difference between keywords, concepts, and entities, see [Understanding the difference between Entities, Concepts, and Keywords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configserviceudbeck).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configref"},{"document_id":"ibmcld_09892-7-1976","score":24.2002285921,"text":"\nAbout \n\nWith IBM Watson\u00ae Natural Language Understanding, developers can analyze semantic features of text input, including categories, concepts, emotion, entities, keywords, metadata, relations, semantic roles, and sentiment.\n\n\n\n Features \n\nSend requests to the API with text, HTML, or a public URL, and specify one or more of the following features to analyze:\n\n\n\n Categories \n\nCategorize your content using a five-level classification hierarchy. View the complete list of categories [here](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-categories-hierarchy). For example:\n\nInput\n\n> url: \"www.cnn.com\"\n\nResponse\n\n> \/news\n> \/art and entertainment\n> \/movies and tv\/television\n> \/news\n> \/international news\n\n\n\n\n\n Concepts \n\nIdentify high-level concepts that aren't necessarily directly referenced in the text. For example:\n\nInput\n\n> text: \"Natural Language Understanding uses natural language processing to analyze text.\"\n\nResponse\n\n> Linguistics\n> Natural language processing\n> Natural language understanding\n\n\n\n\n\n Emotion \n\nAnalyze emotion conveyed by specific target phrases or by the document as a whole. You can also enable emotion analysis for entities and keywords that are automatically detected by the service. For example:\n\nInput\n\n> text: \"I love apples, but I hate oranges.\"\n> targets: \"apples\", and \"oranges\"\n\nResponse\n\n> \"apples\": joy\n> \"oranges\": anger\n\n\n\n\n\n Entities \n\nFind people, places, events, and other types of entities mentioned in your content. View the complete list of entity types and subtypes [here](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-entity-type-systems). For example:\n\nInput\n\n> text: \"IBM is an American multinational technology company headquartered in Armonk, New York, United States, with operations in over 170 countries.\"\n\nResponse\n\n> IBM: Company\n> Armonk: Location\n> New York: Location\n> United States: Location\n\n\n\n\n\n Keywords","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-about"},{"document_id":"ibmcld_13074-16820-18514","score":22.6868551426,"text":"\nEmotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,\n\"joy\": 0.626655,\n\"anger\": 0.02303,\n\"fear\": 0.018884,\n\"sadness\": 0.096802\n}\n}\n}\n\nIn the preceding example, you could query the joy Emotion by accessing enriched_text.emotion.document.emotion.joy\n\nEmotion Analysis analyzes your text and calculates a score for each emotion (anger, disgust, fear, joy, sadness) on a scale of 0.0 to 1.0. If the score of any emotion is 0.5 or higher, then that emotion is detected. The higher the score above 0.5, the higher the relevance. In the snippet shown, joy has a score above 0.5, so Watson detected joy.\n\nEmotion Analysis is supported in English only.\n\n\n\n\n\n Element classification \n\nThe Element Classification enrichment is deprecated and will no longer be available, effective 10 July 2020.\n\nParses elements (sentences, lists, tables) in governing documents to classify important types and categories For more information, see [Element classification](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-element-classification).\n\n[Smart Document Understanding](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sdu) is unavailable if this enrichment is used.\n\n\n\n Enrichment pricing \n\nEnrichment pricing information is available on [IBM Cloud](https:\/\/cloud.ibm.com\/catalog\/services\/discovery).\n\n\n\n\n\n Enrichment language support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_07140-15962-18273","score":22.0732098214,"text":"\n* \"destination_field\" : string - required - The name of the container object where enrichments are created.\n\nField names defined in your configuration must meet the restrictions defined in [Field Name Requirements](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configreffield_reqs).\n\n\n\n\n\n Element Classification enrichments \n\nThe Element Classification enrichment is deprecated and will no longer be available, effective 10 July 2020.\n\nWhen you use the Element Classification, each elements enrichment object must contain an \"options\": {} object with the following parameters specified:\n\n\n\n* \"model\" : string - required - The element extraction model to be used with on this document. Currently supported models are: contract\n\n\n\nWhen you use the elements enrichment, it is important to follow the guidelines specified in [Element Classification](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-element-classification). Specifically, only PDF files can be ingested when this enrichment is specified.\n\n\n\n\n\n Natural Language Understanding enrichments \n\nWhen you use the Natural Language Understanding, each object within the enrichments array must also contain an \"options\": { \"features\": { } } object that contains one or more of the following enrichments:\n\n\n\n\n\n categories \n\nThe categories enrichment identifies any general categories in the ingested document. This enrichment has no options and must be specified as an empty object \"categories\" : {}\n\n\n\n\n\n concepts \n\nThe concepts enrichment finds concepts with which the input text is associated, based on other concepts and entities that are present in that text.\n\n\n\n* \"limit\" : INT - required - The maximum number of concepts to extract from the ingested document.\n\n\n\n\n\n\n\n emotion \n\nThe emotion enrichment evaluates the overall emotional tone (for example anger) of entire document or specified target strings in the entire document. This enrichment can only be used with English content.\n\n\n\n* \"document\" : booleanoptional - When true the emotional tone of the entire document is evaluated.\n* \"targets\" : arrayoptional - A comma-separated array of target strings of which to evaluate the emotional state within the document.\n\n\n\n\n\n\n\n entities \n\nThe entities enrichment extracts instances of known entities such as people, places, and organizations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configref"},{"document_id":"ibmcld_07112-7-2045","score":21.1640759766,"text":"\nIdentifying words to ignore \n\nTo ignore meaningless terms during searches, add a list of custom stop words. Stop words are words that are not useful in distinguishing the semantic meaning of the content.\n\nIn English, the, is and and are examples of stop words.\n\nThe stop words that you define are filtered out of queries and improve the relevance of natural language query results.\n\nFor example, a company has three tiers of service. The documents in one of the collections pertain to only one tier, the Silver tier. You might want to add \"silver\" to the stop words list because the term doesn't help to distinguish the significance of one document over another, given that all of the documents relate to the Silver service tier. When a customer mentions the Silver tier in a query string, it is ignored. Other terms in the query that are more significant are used to search the data instead. Or maybe the document collection consists of car accident reports only. You might want to add \"car\" to the stop words list to prevent mentions of car in queries from adding noise to the search.\n\nDiscovery applies a list of default stop words for many of the supported languages automatically. These stop words are applied both at indexing time and at query time. The predefined stop words are ignored when content is indexed and they are filtered out of queries. However, stop words that you define are used at query time only. Your list doesn't replace the default list; it augments the default list. You can add stop words, but you cannot remove stop words.\n\nExample custom stop word list:\n\n{\n\"stopwords\": [\n\"a\", \"an\", \"the\", \"ibm\", \"what\", \"how\", \"when\", \"can\", \"should\", ...\n]\n}\n\n\n\n Default stop word lists \n\nYou can access the default stop words list for English from the [Watson Developer Cloud GitHub repository](https:\/\/github.com\/watson-developer-cloud\/doc-tutorial-downloads\/tree\/master\/discovery-data\/custom_stopwords_en.json).\n\nFor the following languages, Discovery uses the default stop words list that is defined by Apache Lucene.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-stopwords"},{"document_id":"ibmcld_13074-15255-17243","score":21.1039596906,"text":"\nSee [Entity extraction](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configserviceentity-extraction) and [Keyword extraction](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configservicekeyword-extraction) about those enrichments.\n\nThe subject, action, and object are extracted for every sentence that contains a relation.\n\n\n\n\n\n Sentiment analysis \n\nIdentifies attitude, opinions, or feelings in the content that is being analyzed. Discovery can calculate overall sentiment within a document, sentiment for user-specified targets, entity-level sentiment, quotation-level sentiment, directional-sentiment, and keyword-level sentiment. The combination of these capabilities supports a variety of use cases ranging from social media monitoring to trend analysis.\n\nExample portion of a document enriched with Sentiment Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"sentiment\": {\n\"document\": {\n\"score\": 0.459813,\n\"label\": \"positive\"\n}\n}\n\nIn the preceding example, you could query the sentiment label by accessing enriched_text.sentiment.document.label\n\nThe label is the overall sentiment of the document (positive, negative, or neutral). The sentiment label is based on the score; a score of 0.0 would indicate that the document is neutral, a positive number would indicate the document is positive, a negative number would indicate the document is negative.\n\n\n\n\n\n Emotion analysis \n\nDetects anger, disgust, fear, joy, and sadness implied in English text. Emotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_07214-69430-71715","score":20.7199016342,"text":"\nAny fields used in aggregations are also highlighted in the query results, but only the first aggregation operation is highlighted.\n\n\n\n\n\n 10 May 2017 \n\nNew support for 'highlight' parameter : The query and notices methods now support the highlight parameter. The parameter is a boolean. When you run a query and specified highlight as true, the service returns output that includes a new highlight field in which words that match the query are wrapped in HTML * (emphasis) tags. See the [Query parameters](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametershighlight) for details.\n\nKnown issue when deleting an environment : It is possible for the deletion of an environment to complete only partially, resulting in a situation in which a new environment cannot be created because only a single environment per service instance is permitted. If you attempt to delete and then create an environment but see either operation stuck in the pending state, it is likely that you encountered this problem. To work around it, re-run the deletion operation to complete it, then create the new environment.\n\n\n\n\n\n 8 May 2017 \n\nImproved precision for emotion analysis and training dataset : Updated the emotion tone score model to improve precision on emotion analysis (docEmotion) enrichments. The training dataset was expanded and feature engineering was altered and as a result, the model has higher precision on the benchmark dataset.\n\n\n\n\n\n 5 May 2017 \n\nNew beta support for entity normalization : Entity normalization is now available for use with the Discovery service that use a custom model generated by Watson Knowledge Studio. Entity normalization inserts normalized (canonical) names for different references to the same person or object in the source document. : Entity normalization is currently supported only as a beta capability. : [Resolved](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notesdiscovery-30june2017)\n\nImproved tooling error log : The Tooling error log is no longer limited to a maximum of eight (8) pages of results. The error log still displays the document ID if the document name is not available.\n\nUpdate to configuration names : Configuration names are limited to 50 characters and must consist of the characters [a-zA-Z0-9-_].","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_07067-26099-28206","score":20.6870524865,"text":"\nIf false, ranks the passages from all of the documents by passage quality regardless of the document quality and returns them in a separate passages field in the response.\n* When passages are returned for a query, you can also enable answer finding. When true, answer objects are returned as part of each passage in the query results. When find_answers and per_document are both set to true, the document search results and the passage search results within each document are reordered by using the answer confidences. The goal of this reordering is to place the best answer as the first answer of the first passage of the first document. Similarly, if the find_answers parameter is set to true and per_document parameter is set to false, then the passage search results are reordered in decreasing order of the highest confidence answer for each document and passage.\n* Both v1 and v2 support custom stop words. However, there are a few differences in how custom stop words are used:\n\n\n\n* There is no default custom stop words list for Japanese collections in v2.\n* When you define custom stop words in v1, your stop words list replaces the existing stop words list. In v2, your list augments the default list. You cannot replace the list, which means you cannot remove stop words that are part of the default list in v2.\n\n\n\n\n\n\n\n Update how your application handles query results \n\nThe way that your application shows query results might need to be updated due to the following differences between the query results document syntax between the v1 and v2 queries:\n\n\n\n* At the entity enrichment level, the following information is not supported in v2:\n\n\n\n* Disambiguation\n* Emotion\n* Sentiment\n\n\n\nThe Part of Speech enrichment is applied automatically to documents in most project types in v2, but the index fields that are generated by the enrichment are not displayed in the JSON representation of the document.\n\nZoom\n\n![Difference in entities data structure](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/compare-result-syntax.png)\n\nFigure 1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2371977128,"ndcg_cut_10":0.4306241164}}
