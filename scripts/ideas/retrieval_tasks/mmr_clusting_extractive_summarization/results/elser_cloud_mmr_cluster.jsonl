{"task_id": "1be66272113492407e814eaf21a761d4<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07085-32411-34041", "score": 14.251947, "text": "\n),\nshow_estimated_matching_results: <true_or_false>, show_total_matching_documents: <true_or_false> )\nThe resulting matrix can be represented in a table.<-- <table \"class=\"row-headers comparison-table\" \"> -->Table 5. Trend aggregation example This table has row and column headers. The row headers identify months of the year 2020. The column headers identify ice cream flavors. Each cell calculates a relevancy score by multiplying the month (row) relevancy value times the flavor (header) relevancy value.| Month in 2020 | Flavor: vanilla | Flavor: chocolate | Flavor: mint || ------------- | --------------- | ----------------- | ------------ || Jan | vanilla x Jan | chocolate x Jan | mint x Jan || Feb | vanilla x Feb | chocolate x Feb | mint x Feb || Mar | vanilla x Mar | chocolate x Mar | mint x Mar || Apr | vanilla x Apr | chocolate x Apr | mint x Apr || May | vanilla x May | chocolate x May | mint x May || Jun | vanilla x Jun | chocolate x Jun | mint x Jun |<-- </table \"class=\"row-headers comparison-table\" \"> -->In the following sample response, the key information is the trend_indicator value. The trend indicator measures the increase ratio of the frequency of a given facet value for a given time interval compared to the expected average frequency. The excepted average frequency is calculated based on the changes in the past time interval frequencies of the given facet value, using a weighted arithmetic mean.If the standarized residual value is less than -2, the observed frequency is less than the expected frequency. If it is greater than 2, the observed frequency is greater than the expected frequency.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-aggregations"}, {"document_id": "ibmcld_03036-7-2061", "score": 14.230292, "text": "\nMetrics overview \n\nThe Overview page provides a summary of the interactions between users and your assistant. You can view the amount of traffic for a given time period, as well as the intents and entities that were recognized most often in user conversations.\n\nThe Analytics page was introduced with version 1.5.0. The Analytics feature is supported only on clusters that are installed on Red Hat OpenShift 4.5 or later.\n\nUse the metrics to answer questions like:\n\n\n\n* What was the average number of conversations per week during the last month?\n* How often did customers need to go elsewhwere for support?\n* Which intents appeared most often last week?\n* Which entity values were recognized the most times during February?\n* Which days had the largest or smallest numbers of conversations in the last month?\n\n\n\nTo see metrics information, select Overview in the navigation bar.\n\n\n\n Controls \n\nYou can use the following controls to filter the information:\n\n\n\n* Time period control - Use this control to choose the period for which data is displayed. This control affects all data shown on the page: not just the number of conversations displayed in the graph, but also the statistics displayed along with the graph, and the lists of top intents and entities.\n\nThe statistics can cover a longer time period than the period for which logs of conversations are retained.\n\n![Time period control](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/oview-time.png)\n\nYou can choose whether to view data for a single day, a week, a month, or a quarter. In each case, the data points on the graph adjust to an appropriate measurement period. For example, when viewing a graph for a day, the data is presented in hourly values, but when viewing a graph for a week, the data is shown by day. A week always runs from Sunday through Saturday.\n\nYou can create custom time periods also, such as a week that runs from Thursday to the following Wednesday, or a month that begins on any date other than the first.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-overview"}, {"document_id": "ibmcld_00324-12617-14618", "score": 12.5964155, "text": "\nMetrics with graphical views \n\nMetrics for an individual CDN are provided on the Overview tab of the customer portal for that CDN mapping. Two types of metrics are calculated from the CDN's usage: those that show the metrics over a time period as a graph, and those that are shown as aggregate values.\n\nFor metrics that display the change over a period of time as a graph, you can see three line graphs and a pie chart. The three line graphs are: Bandwidth, Hits by Mapping, and Hits by Type. They display the activity daily over the course of your specified timeframe. The graphs for Bandwidth and Hits by Mapping are single-line graphs, whereas the breakdown of Hits by Type shows a line for each of the hit types provided. The pie chart displays a regional breakdown of the bandwidth for a CDN mapping on a percentage basis.\n\nMetrics that are shown for aggregate values include Bandwidth Usage in GB, Total Hits to the CDN Edge server, and the Hit Ratio. Hit Ratio indicates that the percentage of times content is delivered by the Edge server, not through its origin. Hit ratio currently is shown as a function of all your CDN mappings, not just the one being viewed.\n\nBy default, both the aggregate numbers and the graphs default to show metrics for the last 30 days, but you can change this through the [IBM Cloud console](https://cloud.ibm.com/). Both categories can display metrics for 7-, 15-, 30-, 60-, or 90-day periods.\n\n\n\n\n\n Object storage origin support \n\nIBM Cloud CDN can be configured to serve content from an object storage endpoint by providing the endpoint, the bucket name, protocol, and port. Optionally, you can specify a list of file extensions to allow caching for files only with those extensions. All objects in the bucket must be set with anonymous read or public read access.\n\nFor more information, see [Accelerate delivery of static files using a CDN](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-static-files-cdn).\n\n\n\n\n\n Path-based CDN mappings", "title": "", "source": "https://cloud.ibm.com/docs/CDN?topic=CDN-about-content-delivery-networks-cdn-"}, {"document_id": "ibmcld_09791-7-1663", "score": 12.219481, "text": "\nManaging panels \n\nUse a panel to display a metric or group of metrics in a dashboard. You can copy, change the scope, duplicate, delete, export, and explore panels.\n\nYou can use any of the following panel types:\n\n\n\nTable 1. Panel types\n\n Type Description \n\n Line Use this panel to view trends over time for one or more metrics. \n Top list Use this panel to compare a metric across groups of entities. The bar chart is sorted in descending order. \n Histogram Use this panel to view the frequency distribution of a metric in buckets. \n Number Use this panel to view a single number that represents the value of an aggregated metric over time for one or more entities. \n Table Use this panel to display numerical data for your infrastructure based on metrics and segments. \n Text Use this panel to add text. Use markdown to add your text. \n\n\n\n\n\n Copy a panel into a dashboard \n\nComplete the following steps to copy a panel:\n\n\n\n1. Navigate to the Dashboards section (![dashboard section](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/monitor/images/dashboards.png)) in the Web UI. Select a dashboard. Then, identify the panel that displays the metric that you want to copy.\n2. Click the Actions icon ![Three dots icon](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/monitor/images/actions.png) and select Copy to Dashboard![Copy to Dashboard icon](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/monitor/images/copy.png).\n3. Select one of the dashboards that are listed, or enter a name for a new dashboard.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-panels"}, {"document_id": "ibmcld_03036-1611-3443", "score": 12.193287, "text": "\nIn each case, the data points on the graph adjust to an appropriate measurement period. For example, when viewing a graph for a day, the data is presented in hourly values, but when viewing a graph for a week, the data is shown by day. A week always runs from Sunday through Saturday.\n\nYou can create custom time periods also, such as a week that runs from Thursday to the following Wednesday, or a month that begins on any date other than the first.\n\nThe time shown for each conversation is localized to reflect the time zone of your browser. However, API log calls are always shown in UTC time. As a result, if you choose a single day view, for example, the time shown in the visualization might differ from the timestamp specified in the log for the same conversation.\n\n![Time period control](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/oview-time2.png)\n* Intents and Entities filters - Use either of these drop-down filters to show data for a specific intent or entity in your skill.\n\nThe intent and entities filters are populated by the intents and entities in the skill, and not what is in the data source. If you have [selected a data source](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-overview"}, {"document_id": "ibmcld_09736-4143-5181", "score": 12.192687, "text": "\n[Pencil icon](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/images/pencil.png). Then, change the scope. If you need to restore the dashboard scope to the panel, delete the custom scope. Click Apply.\n6. In the Compare to field set the time range for the comparison.\n7. For Number and Threshold chart types you can set the panel color based on metric thresholds. Click Override Color Coding, then, Enable. Set values for the different thresholds.\n8. Click Save.\n\n\n\n\n\n\n\n\n\n Changing the scope \n\nInstead of changing the scope of a pre-defined dashboard, copy the dashboard and change the scope in the copied dashboard.\n\nComplete the following steps to change the scope of a dashboard:\n\n\n\n1. Navigate to the Dashboards section in the Web UI, and select a dashboard.\n2. Click the Pencil icon ![Pencil icon](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/images/pencil.png) to Edit Dashboard Scope to change default scope.\n3. Select the scope.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-dashboards"}, {"document_id": "ibmcld_03036-4322-6185", "score": 12.009353, "text": "\nper conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-overview"}, {"document_id": "ibmcld_09736-3051-4555", "score": 11.974287, "text": "\n[Pencil icon](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/images/pencil.png). The select the desired scope. By default, Entire infrastructure is selected.\n\n\n\n1. Select the scope.\n2. Optionally, click Override the custom panel scopes to override the scope for all panels which currently have a custom scope defined.\n\nThis action cannot be undone.\n\nTo reset the dashboard scope to the entire infrastructure, or to update an existing dashboard's scope to the entire infrastructure, select Entire infrastructure.\n3. Click Save.\n\n\n\n4. Configure panels. Repeat this step for any of the panels in the dashboard that you want to modify.\n\n\n\n1. Identify the panel that you want to modify.\n2. Select Edit Panel. This is the Pencil icon ![Pencil icon](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/images/pencil.png).\n3. Change the a chart type.\n4. Change the metric, and rate. Rate defines the type of aggregation that is done to the data.\n5. Change the scope of the panel. Click the Pencil icon ![Pencil icon](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/images/pencil.png). Then, change the scope. If you need to restore the dashboard scope to the panel, delete the custom scope. Click Apply.\n6. In the Compare to field set the time range for the comparison.\n7. For Number and Threshold chart types you can set the panel color based on metric thresholds.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-dashboards"}, {"document_id": "ibmcld_04334-179782-181318", "score": 11.965987, "text": "\nThe OR operator is defined using a comma (,) or OR keyword surrounded by whitespace. The AND operator is defined using a semicolon (;) or AND keyword surrounded by whitespace. Comparison options are: ==, =, >, <, >=, <=. An example value for filters is: event==connect AND coloName=SFO.--sort: The sort order for the result set. Sort fields must be included in metrics or dimensions. An example value for sort is: +count,-bytesIngress.--since: Start of time interval to query, defaults to until - 6 hours. This should be an absolute timestamp that conforms to RFC 3339.--until: End of time interval to query, defaults to current time. This should be an absolute timestamp that conforms to RFC 3339.--bytime: Analytics data for range applications grouped by time interval.--time-delta: Used to select time series resolution. Valid values: year, quarter, month, week, day, hour, dekaminute, minute. Only valid when --bytime is given.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.--output: Specify output format, only JSON is supported.<-- </section \"id=\"section-get-analytics-range-app-options\" \"> --><-- <section \"id=\"section-get-analytics-range-app-examples\" \"> --> Examples Get analytics data for range applications in domain 31984fea73a15b45779fa0df4ef62f9b. ibmcloud cis range-analytics 31984fea73a15b45779fa0df4ef62f9b --metrics \"count,bytesIngress\" --dimensions \"event,appID\" --since \"2020-05-22T02:20:00Z\"\n--until \"2020-05-23T02:20:00Z\" -i \"cis-demo\"", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_00404-5279-6843", "score": 11.752377, "text": "\nAre metrics updated in real time? \n\nThe most recent metrics can be updated every 5 minutes, while other metrics are updated every 24 hours.\n\n\n\n\n\n What is the time interval when you select Most recent from the Time frame list? \n\nThe time range and time interval relationships are shown.\n\n\n\nTable 2: Time range and time interval relationships\n\n Time range Time interval (minutes) \n\n (0, 60] 1 \n (60, 300] 5 \n (300, 600] 10 \n (600, 900] 15 \n (900, 1200] 20 \n (1200, 1500] 25 \n (1500, 1800] 30 \n (1800, 2100] 35 \n (2100, 2400] 40 \n (2400, 2700] 45 \n (2700, 2880] 50 \n\n\n\nMath notation ( means \"does not include\" and ] means \"include\".\n\nExample: Start Date timestamp: 1611244800 End Date timestamp: 1611248400 Time range = (End Date timestamp - Start Date timestamp) / 60 = 300 Referring to the preceding table, the time interval is 5 minutes.\n\n\n\n\n\n Why does the last point sometimes drop suddenly in the Most Recent Metrics Report? \n\nZoom\n\n![Most recent interval](https://cloud.ibm.com/docs-content/v1/content/006fd22ab2811b7d19804c763a00568b3da4c03a/CDN/images/metrics-most-recent-interval.png)\n\nFigure 7: Most recent interval\n\nIn the report, each point is a sum of metric data over a time interval, and the interval is calculated by the preceding table. However, for the last point, the interval might be smaller than others. For example, in the bandwidth \"most recent\" report, the time interval is 5 minutes, and all the points are the sum of bandwidth over 5 minutes, except that the last one is only 1-minute bandwidth (January 21 04:00 PM to January 21 05:00 PM).", "title": "", "source": "https://cloud.ibm.com/docs/CDN?topic=CDN-metrics"}]}
{"task_id": "1be66272113492407e814eaf21a761d4<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02877-29401-30879", "score": 16.364044, "text": "\n\"text\": \"6 hours ago was <? now().minusHours(6).reformatDateTime('h:mm a') ?>.\"\n}\n],\n\"response_type\": \"text\",\n\"selection_policy\": \"sequential\"\n}\n]\n}\n}\n\nResult if it is 2:19 PM: 6 hours ago was 8:19 AM.\n\n\n\n Working with time spans \n\nTo show a response based on whether today's date falls within a certain time frame, you can use a combination of time-related methods. For example, if you run a special offer during the holiday season every year, you can check whether today's date falls between November 25 and December 24 of this year. First, define the dates of interest as context variables.\n\nIn the following start and end date context variable expressions, the date is being constructed by concatenating the dynamically-derived current year value with hard-coded month and day values.\n\n\"context\": {\n\"end_date\": \"<? now().reformatDateTime('Y') + '-12-24' ?>\",\n\"start_date\": \"<? now().reformatDateTime('Y') + '-11-25' ?>\"\n}\n\nIn the response condition, you can indicate that you want to show the response only if the current date falls between the start and end dates that you defined as context variables.\n\nnow().after($start_date) && now().before($end_date)\n\n\n\n\n\n java.util.Date support \n\nIn addition to the built-in methods, you can use standard methods of the java.util.Date class.\n\nTo get the date of the day that falls a week from today, you can use the following syntax.\n\n{\n\"context\": {\n\"week_from_today\": \"<? new Date(new Date().getTime() +\n(7 * (2460601000L))) ?>\"\n}\n}", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-methods"}, {"document_id": "ibmcld_03191-30565-32214", "score": 15.002899, "text": "\nResult if it is 2:19 PM: 6 hours ago was 8:19 AM.\n\n\n\n Working with time spans \n\nTo show a response based on whether today's date falls within a certain time frame, you can use a combination of time-related methods. For example, if you run a special offer during the holiday season every year, you can check whether today's date falls between November 25 and December 24 of this year. First, define the dates of interest as context variables.\n\nIn the following start and end date context variable expressions, the date is being constructed by concatenating the dynamically-derived current year value with hard-coded month and day values.\n\n\"context\": {\n\"end_date\": \"<? now().reformatDateTime('Y') + '-12-24' ?>\",\n\"start_date\": \"<? now().reformatDateTime('Y') + '-11-25' ?>\"\n}\n\nIn the response condition, you can indicate that you want to show the response only if the current date falls between the start and end dates that you defined as context variables.\n\nnow().after($start_date) && now().before($end_date)\n\n\n\n\n\n java.util.Date support \n\nIn addition to the built-in methods, you can use standard methods of the java.util.Date class.\n\nTo get the date of the day that falls a week from today, you can use the following syntax.\n\n{\n\"context\": {\n\"week_from_today\": \"<? new Date(new Date().getTime() +\n(7 * (2460601000L))) ?>\"\n}\n}\n\nThis expression first gets the current date in milliseconds (since January 1, 1970, 00:00:00 GMT). It also calculates the number of milliseconds in 7 days. (The (2460601000L) represents one day in milliseconds.) It then adds 7 days to the current date. The result is the full date of the day that falls a week from today.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-methods"}, {"document_id": "ibmcld_09701-8202-9428", "score": 14.716579, "text": "\n\"enabled\": false,\n\"filter\": null,\n\"type\": \"\",\n\"condition\": \"\",\n\"timespan\": 600000000,\n\"notificationChannelIds\": ],\n\"reNotify\": false,\n\"reNotifyMinutes\": 30,\n\"segmentBy\": ],\n\"segmentCondition\": {\n\"type\": \"\"\n},\n\"severityLabel\": \"\"\n}\n}\n]\n}\n\n\n\n\n\n Alerts schema: Response body \n\n{\n\"alerts\": [\n{\n\"alert\": {\n\"autoCreated\": false,\n\"condition\": \"\",\n\"createdOn\": 1551358413000,\n\"enabled\": false,\n\"id\": 23211,\n\"modifiedOn\": 1551634372000,\n\"name\": \"\",\n\"filter\": \"\",\n\"notificationChannelIds\": ],\n\"segmentBy\": ],\n\"segmentCondition\": {\n\"type\": \"ANY\"\n},\n\"notificationCount\": 60,\n\"rateOfChange\": false,\n\"reNotify\": false,\n\"severity\": 0,\n\"severityLabel\": \"\",\n\"teamId\": 493,\n\"timespan\": 60000000,\n\"type\": \"\",\n\"version\": 9\n}\n}\n]\n}\n\n\n\n\n\n Error response codes \n\nThe following table show common error response codes:\n\n\n\nTable 1. RC\n\n RC Description \n\n 400 The alert configuration is not valid. \n 401 Unauthorized access. \n 404 The alert ID is not recognized. \n 409 There is a version mismatch. \n 422 The alert name is not valid. The name is already used. \n\n\n\n\n\n\n\n Body parameters \n\n\n\n id (integer) \n\nID of an alert.\n\n\n\n\n\n condition (string) \n\nDefines the threshold that is configured for the alert. This parameter is required for MANUAL alerts only.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-alert_api"}, {"document_id": "ibmcld_03191-29785-31006", "score": 14.5543585, "text": "\nnow().plusHours(1) ?>.\"\n}\n],\n\"response_type\": \"text\",\n\"selection_policy\": \"sequential\"\n}\n]\n}\n}\n\nResult if it is 8 AM: One hour from now is 09:00:00.\n\nTo get the time 30 minutes ago, specify the following expression:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"values\":\n{\n\"text\": \"A half hour before @sys-time is <? @sys-time.minusMinutes(30) ?>.\"\n}\n],\n\"response_type\": \"text\",\n\"selection_policy\": \"sequential\"\n}\n]\n}\n}\n\nResult if the time captured by the @sys-time entity is 8 AM: A half hour before 08:00:00 is 07:30:00.\n\nTo reformat the time that is returned, you can use the following expression:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"values\":\n{\n\"text\": \"6 hours ago was <? now().minusHours(6).reformatDateTime('h:mm a') ?>.\"\n}\n],\n\"response_type\": \"text\",\n\"selection_policy\": \"sequential\"\n}\n]\n}\n}\n\nResult if it is 2:19 PM: 6 hours ago was 8:19 AM.\n\n\n\n Working with time spans \n\nTo show a response based on whether today's date falls within a certain time frame, you can use a combination of time-related methods. For example, if you run a special offer during the holiday season every year, you can check whether today's date falls between November 25 and December 24 of this year. First, define the dates of interest as context variables.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-methods"}, {"document_id": "ibmcld_02877-24030-25506", "score": 14.512401, "text": "\n{\n\"output\": {\n\"generic\": [\n{\n\"values\":\n{\n\"text\": \"The current date and time is: <? now('Europe/London') ?>\"\n}\n],\n\"response_type\": \"text\",\n\"selection_policy\": \"sequential\"\n}\n]\n}\n}\n\nYou can substitute the hard-coded time zone value with a context variable to dynamically change the time based on a time zone that is passed to the expression. For example: <? now('$myzone') ?>. The $myzone context variable might be set to 'Australia/Sydney' in one conversation and to 'Mexico/BajaNorte' in another.\n\n\n\n\n\n .reformatDateTime(String format) \n\nFormats date and time strings to the format desired for user output.\n\nReturns a formatted string according to the specified format:\n\n\n\n* MM/dd/yyyy for 12/31/2016\n* h a for 10pm\n\n\n\nTo return the day of the week:\n\n\n\n* E for Tuesday\n* u for day index (1 = Monday, ..., 7 = Sunday)\n\n\n\nFor example, this context variable definition creates a $time variable that saves the value 17:30:00 as 5:30 PM.\n\n{\n\"context\": {\n\"time\": \"<? @sys-time.reformatDateTime('h:mm a') ?>\"\n}\n}\n\nFormat follows the Java [SimpleDateFormat](http://docs.oracle.com/javase/6/docs/api/java/text/SimpleDateFormat.html) rules.\n\nWhen trying to format time only, the date is treated as 1970-01-01.\n\n\n\n\n\n .sameMoment(String date/time) \n\n\n\n* Determines whether the date/time value is the same as the date/time argument.\n\n\n\n\n\n\n\n .sameOrAfter(String date/time) \n\n\n\n* Determines whether the date/time value is after or the same as the date/time argument.\n* Analogous to .after().", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-methods"}, {"document_id": "ibmcld_09701-1314-2591", "score": 14.501965, "text": "\n* <ALERT_ID> defines the ID of the alert that you want to modify.\n\n\n\nFor example, the response body for an alert looks as follows:\n\n{\n\"alert\": {\n\"autoCreated\": false,\n\"condition\": \"min(min(dallas_prod)) = 0\",\n\"createdOn\": 1551358413000,\n\"enabled\": false,\n\"id\": 23211,\n\"modifiedOn\": 1551634372000,\n\"name\": \"Monitoring Uptime Alert\",\n\"filter\": \"env in (\"prod\")\",\n\"notificationChannelIds\": [\n4\n],\n\"segmentBy\": [\n\"host.hostname\"\n],\n\"segmentCondition\": {\n\"type\": \"ANY\"\n},\n\"notificationCount\": 60,\n\"rateOfChange\": false,\n\"reNotify\": false,\n\"severity\": 0,\n\"severityLabel\": \"HIGH\",\n\"teamId\": 493,\n\"timespan\": 60000000,\n\"type\": \"MANUAL\",\n\"version\": 9\n}\n}\n\n\n\n\n\n Create an alert \n\nYou can use the following cURL command to create an alert:\n\ncurl -X POST <REST_API_ENDPOINT>/api/alerts -H \"Authorization: $AUTH_TOKEN\" -H \"IBMInstanceID: $GUID\" -H \"TeamID: $TEAM_ID\" -H \"content-type: application/json\" -d @alert.json\n\nWhere\n\n\n\n* <REST_API_ENDPOINT> indicates the endpoint targetted by the REST API call. For more information, see [Monitoring REST API endpoints](https://cloud.ibm.com/docs/monitoring?topic=monitoring-endpointsendpoints_rest_api). For example, the public endpoint for an instance that is available in us-south is the following: https://us-south.monitoring.cloud.ibm.com/api", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-alert_api"}, {"document_id": "ibmcld_09701-12088-14157", "score": 14.318, "text": "\nSeverity Severity status \n\n 0 HIGH \n 1 HIGH \n 2 MEDIUM \n 3 MEDIUM \n 4 LOW \n 5 LOW \n 6 INFO \n 7 INFO \n\n\n\n\n\n\n\n segmentBy (array of strings) \n\nDefines additional segmentation criteria.\n\nFor example, you can segment a CPU alert by ['host.mac', 'proc.name'] so the alert can report on any process in any machine for which you get data in the monitoring instance.\n\n\n\n\n\n segmentCondition (string) \n\nDefines when the alert is triggered for each monitored entity that is specified in the segmentBy parameter. This parameter is required for MANUAL alerts only.\n\nValid values are the following:\n\n\n\n* ANY: The alert is triggered when at least one of the monitored entities satisfies the condition.\n* ALL: The alert is triggered when all of the monitored entities satisfy the condition.\n\n\n\n\n\n\n\n teamId (string) \n\nDefines the GUID of the team that owns the alert.\n\n\n\n\n\n type (string) \n\nDefines the type of alert. Valid values are MANUAL, BASELINE, and HOST_COMPARISON.\n\nSet to MANUAL for alerts that you want to control when a notification is sent. You must define the threshold that determines when the alert is triggered.\n\nSet to BASELINE for alerts that you want to notify when unexpected metric values are detected. New metric data is compared with metric values that are collected over time.\n\nSet to HOST_COMPARISON for alerts that you want to notify when 1 host in a group reports metrics values that are different from the other hosts in the group.\n\n\n\n\n\n timespan (integer) \n\nMinimum time interval, in microseconds, for which the alert condition must be met before the alert is triggered.\n\nThe minimum value is 60000000 microseconds, that is, 1 minute.\n\nThe value of this parameter must be a multiple of 60000000 microseconds.\n\n\n\n\n\n version (integer) \n\nVersion of an alert.\n\nThe version changes every time you update an alert.\n\nThe version is used for optimistic locking.\n\n\n\n\n\n\n\n Query parameters \n\n\n\n alertId (integer) \n\nID of an alert.\n\n\n\n\n\n from (long) \n\nDefines the start timestamp, in microseconds, that is used when you request information about alerts that are defined.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-alert_api"}, {"document_id": "ibmcld_09276-7-2089", "score": 14.302552, "text": "\nWorking with alerts \n\nYou can configure alerts to notify about the state of your infrastructure, applications, and IBM Cloud services.\n\nA rule specifies the scope of the data that you want to monitor and be notified if certain conditions occur. Per alert rule, consider the following information:\n\n\n\n* You can define 1 or more notification channels.\n* You can configure different alert types for each notification channel that you configure for an alert.\n* You can configure different triggering conditions for each notification channel that you configure for an alert.\n\n\n\nA rule is also the basis of a view. You can see the data that is included by any rule by using it as a view. The two are interchangeable.\n\n\n\n Types of alerts \n\nYou can configure any of the following types of alerts for each notification channel that you configure for an alert:\n\n\n\n Presence alert \n\nYou can configure a presence alert to notify when the number of logs that show in a view is more than what you expect.\n\nFor example, you might have a view that shows logs that report payments that are rejected by your service. You can configure a presence alert that triggers an alert when 1 or more logs show in the view.\n\n\n\n\n\n Absence alert \n\nConfigure an absence alert to notify when the number of logs that show in a view is less than what you expect, or none.\n\nAn absence alert is triggered when the view that has an absence alert attached to it is active. A view is active when the view receives logs within the last 24 hours.\n\nFor example, you might have a view that does not get any logs for 2 days. Therefore, this view is not active. You have an absence alert attached to this view that is configured to send a notification after 30 minutes. Because the view is not active, the absence alert is muted and you do not get notifications. To make the view active and get notifications for the absence condition, logs need to start flowing into the view.\n\n\n\n\n\n\n\n Alert conditions \n\nYou can configure any of the following triggering conditions for each notification channel that you configure for an alert:", "title": "", "source": "https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-alerts"}, {"document_id": "ibmcld_12492-75604-76521", "score": 14.292265, "text": "\n\"locks\": [\"lock-name-1\", \"lock-name-2\"]\n}'\n\n\n\n\n\n Example response \n\nA request to remove all locks returns the following response:\n\n{\n\"request_id\": \"4708ebbf-eab0-e68a-9e72-d1c67a209fdc\",\n\"lease_id\": \"\",\n\"renewable\": false,\n\"lease_duration\": 0,\n\"data\": {\n\"secret_group_id\": \"default\",\n\"secret_id\": \"184408d6-8264-5ff3-c308-6922ed04ad88\",\n\"versions\": [\n{\n\"alias\": \"current\",\n\"id\": \"f2b68dbb-c291-87df-6026-7611c324c823\",\n\"locks\": ],\n\"payload_available\": true\n}\n]\n},\n\"wrap_info\": null,\n\"warnings\": null,\n\"auth\": null\n}\n\nA request to remove only specific locks lists the remaining locks in the response:\n\n{\n\"request_id\": \"4d954026-68b3-6506-dc1d-5e77574fd2f0\",\n\"lease_id\": \"\",\n\"renewable\": false,\n\"lease_duration\": 0,\n\"data\": {\n\"secret_group_id\": \"default\",\n\"secret_id\": \"184408d6-8264-5ff3-c308-6922ed04ad88\",\n\"versions\": [\n{\n\"alias\": \"current\",\n\"id\": \"f2b68dbb-c291-87df-6026-7611c324c823\",\n\"locks\":\n\"lock-for-app-1\"\n],", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-vault-api"}, {"document_id": "ibmcld_13780-4694-6868", "score": 14.167836, "text": "\n}\nShow more\n\nThe response is just an example. The service can return one or more text messages with timing information for the input. It can also return a separate text message for each word of the input. Moreover, the messages can be interspersed with responses that contain binary chunks of audio. But the text message that contains the timing information for a word always arrives before the audio chunk that contains that word.\n\n\n\n Timings for plain text \n\nThe service's synthesis process involves a text normalization step that spells out numbers, dates, times, monetary amounts, acronyms, and abbreviations. The results correspond to how such strings are spoken. For example, the string $200 is spoken as three words: two, hundred, and dollars. Because word timing information is used to synchronize the audio with the input text, the service returns timing information that corresponds to the non-normalized spelling of the input.\n\nFor example, consider the following input text:\n\nThe coldest recorded temperature is -89.2 degrees Celsius in Antarctica on July 21, 1983!\n\nThe service returns audio timings for the following strings:\n\nThe, coldest, recorded, temperature, is, -89.2, degrees, Celsius, in, Antarctica, on, July, 21,, 1983!\n\nAlthough \"-89.2\" is spoken in the audio as five separate words (minus, eighty, nine, point, two), the text message provides timing information for the string as a single unit with the start time of minus and the end time of two.\n\nAs in the previous example, non-normalized strings can also contain punctuation. The service includes the punctuation that precedes or follows a word in the text message that it returns with the timings. For instance, the strings \"21, and 1983!\" include punctuation that the service returns in its text message. Although the punctuation results in silence, the audio timing for the word does not include that silence.\n\nFor example, consider input text that contains the following conditional statement:\n\nIf it is sunny, I will go to the beach.\n\nThe service returns timing information for all strings of the input, including \"sunny, and beach., both of which end in punctuation that produces silence.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-timing"}]}
{"task_id": "1be66272113492407e814eaf21a761d4<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09785-2901-4576", "score": 14.693943, "text": "\nYou can still manage alerts by using the legacy editor. However, notice that new features are only available through the new editor.\n* New configuration settings to help you troubleshoot issues. You can configure a dashboard and a runbook with an alert.\n\n\n\nDeprecated features:\n\n\n\n* Deprecation of the Anomaly Detection and Group Outlier alert types. You can view and manage existing alerts but you cannot define new ones.\n\n\n\nFor more information, see [Configure alerts](https://docs.sysdig.com/en/docs/sysdig-monitor/alerts/configure-alerts/).\n\n\n\n\n\n 15 June 2022 \n\nIBM Cloud\u00ae Monitoring has made available a proprietary time series database that is designed for storing and serving metrics at scale. [Learn more](https://docs.sysdig.com/en/docs/release-notes/enhanced-metric-store/)\n: The following changes have been made:\n\n\n\n* [Metrics and labels are stored and displayed in a Prometheus compatible naming convention](https://docs.sysdig.com/en/docs/release-notes/enhanced-metric-store/prometheus-compatible-naming-conventions-for-metrics--labels).\n* Some metrics and labels have been deprecated. Deprecated metrics and labels will no longer be available 30 days after this release. See [Discontinued Metrics and Labels](https://docs.sysdig.com/en/docs/release-notes/enhanced-metric-store/discontinued-metrics-and-labels).\n* Classic metrics have been replaced with context-explicit metrics. See [Mapping Classic Metrics with Context-Specific PromQL Metrics](https://docs.sysdig.com/en/docs/sysdig-monitor/metrics-dictionary/metrics-and-label-mapping/mapping-classic-metrics-with-context-specific-promql-metrics/mapping-classic-metrics-with-context-specific-promql-metrics).", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-monitoring-release-notes"}, {"document_id": "ibmcld_09148-8939-9806", "score": 14.434458, "text": "\nTo setup a metric, complete the follow steps.\n\n\n\n1. Click Alerts on the side menu.\n2. Click Add Alert at the top of the page.\n3. Select Metric as the alert type.\n4. Select the aggregation and the metric that you would like to be performed on.\n5. Select the scope if applicable.\n6. Set the metric and time requirements for the alert to trigger.\n7. Configure and set up the notification channel and notification interval.\n8. Click the CREATE button.\n\n\n\nThe figure as shown provides an example of how to configure an alert when your service instance receives multiple 401 and 403 errors within a 10 minute time span.\n\nZoom\n\n![An example of a 401 and 403 configuration.](https://cloud.ibm.com/docs-content/v1/content/0bc8db34a3d90b2a5103c9c71b08a96de9525bbc/key-protect/images/monitor-401-alert.png)\n\nFigure 5. The configuration for a 401 alert in a Monitoring dashboard.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-operational-metrics"}, {"document_id": "ibmcld_09794-8223-9780", "score": 13.835888, "text": "\nTo save the scope, you must click Save at the panel level.\n\n\n\n\n\n\n\n Configuring an alert on a platform metric \n\n\n\n Configuring an alert from a panel \n\nComplete the following steps to define an alert on a metric:\n\n\n\n1. [Launch the monitoring UI](https://cloud.ibm.com/docs/monitoring?topic=monitoring-launch).\n2. Verify that you have a notification channel that defines how you want to be notified.\n\nYou can enabled 1 or more notification channels when you configure an alert. If you need multiple notification channels, check they are available.\n3. Navigate to the Dashboards section (![dashboard section](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/images/dashboards.png)) in the Web UI.\n4. Select a custom dashboard in the My Dashboards section.\n5. Select the panel for which you want to define the alert.\n\nBefore you create the alert, check the scope of the metric that is configured in the panel. This scope is automatically included in the alert definition.\n6. Click the Actions icon ![Three dots icon](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/images/actions.png) and select Create Alert.\n\nZoom\n\n![Panel options](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/platform/images/sysdig-platform-15.png)\n\nPanel options\n\nIf you have multiple queries defined in a panel, you are prompted to select the metric for which you want to create an alert.\n7. Configure the alert. Set the following fields:", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-platform_metrics_working"}, {"document_id": "ibmcld_09794-10912-12367", "score": 13.638438, "text": "\nYou can define a metric alert directly from the Alerts section.\n\nComplete the following steps to define an alert on a metric:\n\n\n\n1. [Launch the monitoring UI](https://cloud.ibm.com/docs/monitoring?topic=monitoring-launch).\n2. Verify that you have a notification channel that defines how you want to be notified.\n\nYou can enabled 1 or more notification channels when you configure an alert. If you need multiple notification channels, check they are available.\n3. Navigate to the Alerts section ![Alerts module](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/images/alerts.png)) in the Web UI.\n4. Select Add Alert.\n\nZoom\n\n![Add alert](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/platform/images/sysdig-platform-7.png)\n\nAdd alert\n5. Select your desired alert type.\n\nZoom\n\n![Choose alert type](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/platform/images/sysdig-platform-16.png)\n\nChoose alert type\n6. Configure the alert. Set the following fields:\n\nName: Enter a name for the alert.\n\nDescription: Add a description that other users can read to get more context. This field is optional.\n\nGroup: The alert group this alert will be part of. If not specified, the alert will be part of the default group.\n\nSeverity: Set the level of criticality of the alert. Valid values are High, Medium, Low, and Info.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-platform_metrics_working"}, {"document_id": "ibmcld_09794-11989-13744", "score": 13.409926, "text": "\nSet the following fields:\n\nName: Enter a name for the alert.\n\nDescription: Add a description that other users can read to get more context. This field is optional.\n\nGroup: The alert group this alert will be part of. If not specified, the alert will be part of the default group.\n\nSeverity: Set the level of criticality of the alert. Valid values are High, Medium, Low, and Info.\n\nMetric: Configure the metric.\n\nScope: Configure the scope\n\nTrigger: Define the condition and threshold value that must be evaluated. It also defines whether the alert sends a single alert or multiple alerts. Valid time scales are minute, hour, or day. A single alert fires an alert for the entire scope. Multiple Alerts are sent if 1 or more segments breach the threshold at once. An alert is sent for each segment that you specify.\n\nNotification Channel: Enable 1 or more notification channels.\n\n\n\n\n\n\n\n Controlling the access to platform metrics for a team \n\nYou can control the data that is visible to all the users that are members of a team.\n\nFirst navigate to the Settings section.\n\nZoom\n\n![Settings section](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/platform/images/sysdig-platform-12.png)\n\nSettings\n\nAs an administrator of the service, you can create, modify, and delete teams. When you configure a team, you can define the scope of the data in the Visibility section.\n\nTo allow a team to view platform metrics, you must select Platform metrics.\n\nZoom\n\n![Team platform metrics option](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/platform/images/sysdig-platform-10.png)\n\nTeam platform metrics\n\nEnabling platform metrics, grants access to all platform metrics.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-platform_metrics_working"}, {"document_id": "ibmcld_09794-9435-11301", "score": 13.383061, "text": "\n[Panel options](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/platform/images/sysdig-platform-15.png)\n\nPanel options\n\nIf you have multiple queries defined in a panel, you are prompted to select the metric for which you want to create an alert.\n7. Configure the alert. Set the following fields:\n\nName: Enter a name for the alert.\n\nDescription: Add a description that other users can read to get more context. This field is optional.\n\nGroup: The alert group this alert will be part of. If not specified, the alert will be part of the default group.\n\nSeverity: Set the level of criticality of the alert. Valid values are High, Medium, Low, and Info.\n\nMetric: This field is set to the metric that you have selected from the panel. Check that the metric and aggregation are the ones that you need.\n\nScope: This field is set to the scope that you have defined for the metric in the panel. Check that the scope is the one that you need.\n\nTrigger: Define the condition and threshold value that must be evaluated. It also defines whether the alert sends a single alert or multiple alerts. Valid time scales are minute, hour, or day. A single alert fires an alert for the entire scope. Multiple Alerts are sent if 1 or more segments breach the threshold at once. An alert is sent for each segment that you specify.\n\nNotification Channel: Enable 1 or more notification channels.\n\n\n\n\n\n\n\n\n\n Configuring an alert from the Alerts section \n\nYou can define a metric alert directly from the Alerts section.\n\nComplete the following steps to define an alert on a metric:\n\n\n\n1. [Launch the monitoring UI](https://cloud.ibm.com/docs/monitoring?topic=monitoring-launch).\n2. Verify that you have a notification channel that defines how you want to be notified.\n\nYou can enabled 1 or more notification channels when you configure an alert.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-platform_metrics_working"}, {"document_id": "ibmcld_09700-7-1797", "score": 13.208482, "text": "\nConfiguring an alert by using the legacy alert editor \n\nIn the IBM Cloud Monitoring service, you can configure single alerts and multi-condition alerts to notify about problems that may require attention. When an alert is triggered, you can be notified through 1 or more notification channels. An alert definition can generate multi-channel notifications.\n\nAn alert is a notification event that you can use to warn about situations that require attention. Each alert has a severity status. This status informs you about the criticality of the information it reports on. [Learn more](https://cloud.ibm.com/docs/monitoring?topic=monitoring-alerts).\n\nComplete the following steps to configure an alert:\n\n\n\n Step 1. Select the alert type \n\nFrom the Alert section of the UI, select Add Alert. Then, choose the alert type.\n\n\n\n\n\n Step 2. Name the alert \n\nEnter a name for the alert.\n\nYou can also add a description for the alert and the name of an alert group if you want to group you alerts. If an alert group is not specified, the alert will be created in the default group.\n\n\n\n\n\n Step 3. Define the severity \n\nAdd a severity level. Valid severity values are info, low, medium, and high.\n\n\n\n\n\n Step 4. Define the metric section \n\n\n\n1. Select a metric (entity) that you want to monitor.\n2. Define the alert condition. Choose any of the following options:\n\nOption 1: Choose a metric and a single condition such as average, sum, minimum or maximum.\n\nOption 2: Choose Create multi-condition alerts. Enter the condition, for example, min(min(cpu.used.percent)) < = 50 OR max(max(cpu.used.percent)) >= 80.\n\nZoom\n\n![Multi-condition alert](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/monitor/images/multi-condition-alerts.png)\n\nMulti-condition alert", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-alert-config"}, {"document_id": "ibmcld_09685-5899-7847", "score": 13.163532, "text": "\nFor more information, see [Collecting metrics](https://cloud.ibm.com/docs/monitoring?topic=monitoring-about-collect-metrics).\n\n\n\n\n\n Sending metrics \n\nYou can send metrics via the public or the private endpoints by using the appropriate ingestion URL. Details can be found in the [endpoints](https://cloud.ibm.com/docs/monitoring?topic=monitoring-endpointsendpoints) section.\n\n\n\n\n\n Viewing metrics \n\nYou can monitor and manage metrics through the Monitoring Web UI. For more information, see [Viewing metrics](https://cloud.ibm.com/docs/monitoring?topic=monitoring-monitoring).\n\nNotice that there is a delay showing metric data for new time series. Data is not ready until the initial indexing of a new metric source is completed. Therefore, new sources such as clusters, platform metrics, or systems that you configure, all take some time to become visible through the Monitoring UI.\n\n\n\n\n\n Sending notifications \n\nYou can configure single alerts and multi-condition alerts to notify about problems that may require attention. When an alert is triggered, you can be notified through 1 or more notification channels. An alert definition can generate multi-channel notifications.\n\nAn alert is a notification event that you can use to warn about situations that require attention. Each alert has a severity status. This status informs you about the criticality of the information it reports on.\n\nFor example, you can set up Monitoring to send alert notifications to IBM Cloud Event Notifications.\n\n\n\n* [Sending email notifications to IBM Cloud Event Notifications](https://cloud.ibm.com/docs/monitoring?topic=monitoring-tutorial)\n* [Sending SMS notifications to IBM Cloud Event Notifications](https://cloud.ibm.com/docs/monitoring?topic=monitoring-tutorial-en-sms)\n\n\n\nFor more information, see [Working with alerts and events](https://cloud.ibm.com/docs/monitoring?topic=monitoring-alerts).\n\n\n\n\n\n Data location \n\nMetric data is hosted on the IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-about-monitor"}, {"document_id": "ibmcld_09703-1640-3664", "score": 13.102463, "text": "\n* Alerts are executed in 1 minute or less from receipt, with the option to configure the trigger wait time by hour or day.\n* For PromQL alerts only, you can optionally configure a 0 minute wait time.\n\n\n\nYou can enable predefined alerts, modify alerts, and create custom alerts in the web UI and by using the IBM Cloud Monitoring API.\n\nYou manage alerts in the Alerts view of the web UI. You can configure the table columns that are displayed in the Alerts view. Valid column options are Name, Scope, Alert When, Segment By, Notifications, Enabled, Modified, Captures, Channels, Created, Description, Email recipients, For at least, OpsGenie, PagerDuty, Severity, Slack, WebHook, Type, and VictorOps.\n\n\n\n Types of alerts \n\nThe IBM Cloud Monitoring service includes pre-defined alerts that you can enable. In addition, you can configure custom alerts from panels in a dashboard, by using the REST API, or in the Alerts section of the web UI.\n\nIn the IBM Cloud Monitoring service, you can define any of the following types of alerts:\n\n\n\n* Downtime: Use this type of alert to monitor sources and alert when they are down, for example, a bare metal.\n* Metric: Use this type of alert to monitor time-series metrics and alert when they reach the thresholds defined.\n* PromQL: Use this type of metric to monitor metrics by using a PromQL query.\n* Event: Use this type of alert to monitor occurrences of specific events and alert when they reach the thresholds defined. For example, you can use this alert to monitor when a number of unauthorize access requests are reported.\n* Anomaly Detection: Use this type of alert to monitor hosts based on historical behaviors and alert when they deviate from the expected pattern.\n\nThis type of alert is deprecated. You can only manage existing alerts of this type.\n* Group Outlier: Use this type of alert to monitor hosts and be notified when 1 acts differently from the rest.\n\nThis type of alert is deprecated. You can only manage existing alerts of this type.\n\n\n\n\n\n\n\n Notification channels", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-alerts"}, {"document_id": "ibmcld_09794-7139-8619", "score": 12.998774, "text": "\nNavigate to the Dashboards section (![dashboard section](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/images/dashboards.png)) in the Web UI.\n3. Select a custom dashboard in the My Dashboards section.\n4. Select a panel where you want to change the scope of the data.\n5. Click the Pencil icon ![Pencil icon](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/images/pencil.png). Then, in the Scope section, click Dashboard scope.\n\nZoom\n\n![Panel scope](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/platform/images/sysdig-platform-6.png)\n\nPanel scope\n6. By default, Inherit Dashboard Scope is selected. To specify a custom scope, you must de-select this option.\n\nIn the drop-down box, enter ibm and select an attribute.\n\nSelect an operator.\n\nSelect 1 or more values.\n7. In a panel, you can configure 1 or more metrics. Select Apply to All Queries if you want the scope to apply to all the metrics that are configured for the panel.\n\n\n\nTo save the scope, you must click Save at the panel level.\n\n\n\n\n\n\n\n Configuring an alert on a platform metric \n\n\n\n Configuring an alert from a panel \n\nComplete the following steps to define an alert on a metric:\n\n\n\n1. [Launch the monitoring UI](https://cloud.ibm.com/docs/monitoring?topic=monitoring-launch).\n2. Verify that you have a notification channel that defines how you want to be notified.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-platform_metrics_working"}]}
{"task_id": "1be66272113492407e814eaf21a761d4<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09701-12088-14157", "score": 14.905944, "text": "\nSeverity Severity status \n\n 0 HIGH \n 1 HIGH \n 2 MEDIUM \n 3 MEDIUM \n 4 LOW \n 5 LOW \n 6 INFO \n 7 INFO \n\n\n\n\n\n\n\n segmentBy (array of strings) \n\nDefines additional segmentation criteria.\n\nFor example, you can segment a CPU alert by ['host.mac', 'proc.name'] so the alert can report on any process in any machine for which you get data in the monitoring instance.\n\n\n\n\n\n segmentCondition (string) \n\nDefines when the alert is triggered for each monitored entity that is specified in the segmentBy parameter. This parameter is required for MANUAL alerts only.\n\nValid values are the following:\n\n\n\n* ANY: The alert is triggered when at least one of the monitored entities satisfies the condition.\n* ALL: The alert is triggered when all of the monitored entities satisfy the condition.\n\n\n\n\n\n\n\n teamId (string) \n\nDefines the GUID of the team that owns the alert.\n\n\n\n\n\n type (string) \n\nDefines the type of alert. Valid values are MANUAL, BASELINE, and HOST_COMPARISON.\n\nSet to MANUAL for alerts that you want to control when a notification is sent. You must define the threshold that determines when the alert is triggered.\n\nSet to BASELINE for alerts that you want to notify when unexpected metric values are detected. New metric data is compared with metric values that are collected over time.\n\nSet to HOST_COMPARISON for alerts that you want to notify when 1 host in a group reports metrics values that are different from the other hosts in the group.\n\n\n\n\n\n timespan (integer) \n\nMinimum time interval, in microseconds, for which the alert condition must be met before the alert is triggered.\n\nThe minimum value is 60000000 microseconds, that is, 1 minute.\n\nThe value of this parameter must be a multiple of 60000000 microseconds.\n\n\n\n\n\n version (integer) \n\nVersion of an alert.\n\nThe version changes every time you update an alert.\n\nThe version is used for optimistic locking.\n\n\n\n\n\n\n\n Query parameters \n\n\n\n alertId (integer) \n\nID of an alert.\n\n\n\n\n\n from (long) \n\nDefines the start timestamp, in microseconds, that is used when you request information about alerts that are defined.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-alert_api"}, {"document_id": "ibmcld_09701-9031-10960", "score": 13.984706, "text": "\n400 The alert configuration is not valid. \n 401 Unauthorized access. \n 404 The alert ID is not recognized. \n 409 There is a version mismatch. \n 422 The alert name is not valid. The name is already used. \n\n\n\n\n\n\n\n Body parameters \n\n\n\n id (integer) \n\nID of an alert.\n\n\n\n\n\n condition (string) \n\nDefines the threshold that is configured for the alert. This parameter is required for MANUAL alerts only.\n\nFor example, you can defines a consition as follows: avg(timeAvg(uptime)) <= 0\n\n\n\n\n\n createdOn (integer) \n\nDefines the creation time of an alert in milliseconds.\n\nThis parameter returns the Unix-timestamp when the alert was created.\n\n\n\n\n\n description (string) \n\nThis parameter describes the alert.\n\nThe description is available when you view an alert in the Alerts section of the monitoring UI, and it is included in notification emails.\n\n\n\n\n\n enabled (boolean) \n\nDefines the status of an alert.\n\nBy default, this parameter is set to true and the alert is enabled when it is created.\n\n\n\n\n\n filter (string) \n\nDefines the scope of the alert by configuring segments.\n\nWhen this field is empty, all the metric sources are included. The scope is set to Everything.\n\nFor example, you can define filters like the following ones:\n\nkubernetes.namespace.name='production'\n\ncontainer.image='nginx'.\n\nkubernetes.namespace.name='production' and container.image='nginx'.\n\n\n\n\n\n name (string) \n\nName of the alert. Must be unique.\n\nThe name is used to identify the alert in the Alerts section of the monitoring UI, and it is included in notification emails.\n\n\n\n\n\n modifiedOn (integer) \n\nDefines when an alert was last modified in milliseconds.\n\nThis parameter defines the Unix-timestamp when the alert was last modified.\n\n\n\n\n\n notificationChannelIds (array) \n\nLists the notification channels that are configured to notify when an alert is triggered.\n\nValid options are EMAIL, PAGER_DUTY, WEBHOOK, VICTOROPS, and SLACK.\n\n\"notificationChannelIds\": [", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-alert_api"}, {"document_id": "ibmcld_09701-10445-12445", "score": 13.813641, "text": "\nThe name is used to identify the alert in the Alerts section of the monitoring UI, and it is included in notification emails.\n\n\n\n\n\n modifiedOn (integer) \n\nDefines when an alert was last modified in milliseconds.\n\nThis parameter defines the Unix-timestamp when the alert was last modified.\n\n\n\n\n\n notificationChannelIds (array) \n\nLists the notification channels that are configured to notify when an alert is triggered.\n\nValid options are EMAIL, PAGER_DUTY, WEBHOOK, VICTOROPS, and SLACK.\n\n\"notificationChannelIds\": [\n\"EMAIL\",\n\"WEBHOOK\"\n]\n\n\n\n\n\n notificationCount (integer) \n\nDefines the number of notifications that are sent for the alert during the past 2 weeks.\n\n\n\n\n\n reNotify (boolean) \n\nDefines whether you want to get follow up notifications until the alert condition is acknowledged and resolved.\n\nBy default, follow up notifications are not enabled and the field is set to false.\n\n\n\n\n\n reNotifyMinutes (integer) \n\nDefines how often do you want to receive notifications on an alert that is not resolved.\n\nYou specify the number of minutes before a reminder is sent.\n\n\n\n\n\n severity (integer) \n\nDefines the syslog-encoded alert severity.\n\nThe following table lists the values that you can set:\n\n\n\nTable 2. Severity values\n\n Severity Info \n\n 0 emergency \n 1 alert \n 2 critical \n 3 error \n 4 warning \n 5 notice \n 6 informational \n 7 debug \n\n\n\n\n\n\n\n severityLabel (string) \n\nDefines the criticality of an alert. Valid values are HIGH, MEDIUM, LOW, and INFO. A lesser value indicates a higher severity.\n\nThe following table shows the severity status that must be set depending on the severity parameter value:\n\n\n\nTable 3. Severity level values\n\n Severity Severity status \n\n 0 HIGH \n 1 HIGH \n 2 MEDIUM \n 3 MEDIUM \n 4 LOW \n 5 LOW \n 6 INFO \n 7 INFO \n\n\n\n\n\n\n\n segmentBy (array of strings) \n\nDefines additional segmentation criteria.\n\nFor example, you can segment a CPU alert by ['host.mac', 'proc.name'] so the alert can report on any process in any machine for which you get data in the monitoring instance.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-alert_api"}, {"document_id": "ibmcld_16274-12891-14794", "score": 13.69424, "text": "\nThe following example shows the structure of the warnings_and_errors object:\n\n\"warnings_and_errors\": [\n{\n\"message\": \"CWSMR0032W: A Watson Speech to Text final utterance has a confidence score of 0.1, which does not meet the confidence score threshold of 0.2. The utterance will be ignored.\",\n\"id\": \"CWSMR0032W\"\n},\n{\n\"message\": \"CWSMR0031W: The synthesis stream from the Watson Text To Speech service can't keep up with the playback rate to the caller, so audio might skip. transaction ID=a1b2c3d4e5\",\n\"id\": \"CWSMR0031W\"\n}\n]\n\nThe object for each warning contains the following properties:\n\n\n\nProperties of the warnings_and_errors object\n\n Property Type Description \n\n message String The text of the warning message. \n id String The unique message identifier. \n\n\n\n\n\n\n\n max_response_milliseconds \n\nThe max_response_milliseconds object contains the following properties:\n\n\n\nProperties of the max_response_milliseconds object\n\n Property Type Description \n\n assistant Number The maximum round-trip latency (in milliseconds), calculated from all Watson Assistant requests related to the call. \n text_to_speech Number The maximum time (in milliseconds) between when a text utterance is sent to the Text to Speech service and when the phone integration receives the first packet of synthesized audio. This value is calculated from all Text to Speech requests related to the call. \n speech_to_text Number The maximum latency (in milliseconds) between when silence is detected in the caller's speech and when a final result from the Speech to Text service is received. This value is calculated from all Speech to Text recognition results related to the call. \n\n\n\n\n\n\n\n realtime_transport_network_summary \n\nWhen RTCP is enabled, the realtime_transport_network_summary object provides statistics for the inbound stream in the inbound_stream object and statistics for the outbound stream in the outbound_stream object.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-cdr-log-reference"}, {"document_id": "ibmcld_09276-7-2089", "score": 13.648856, "text": "\nWorking with alerts \n\nYou can configure alerts to notify about the state of your infrastructure, applications, and IBM Cloud services.\n\nA rule specifies the scope of the data that you want to monitor and be notified if certain conditions occur. Per alert rule, consider the following information:\n\n\n\n* You can define 1 or more notification channels.\n* You can configure different alert types for each notification channel that you configure for an alert.\n* You can configure different triggering conditions for each notification channel that you configure for an alert.\n\n\n\nA rule is also the basis of a view. You can see the data that is included by any rule by using it as a view. The two are interchangeable.\n\n\n\n Types of alerts \n\nYou can configure any of the following types of alerts for each notification channel that you configure for an alert:\n\n\n\n Presence alert \n\nYou can configure a presence alert to notify when the number of logs that show in a view is more than what you expect.\n\nFor example, you might have a view that shows logs that report payments that are rejected by your service. You can configure a presence alert that triggers an alert when 1 or more logs show in the view.\n\n\n\n\n\n Absence alert \n\nConfigure an absence alert to notify when the number of logs that show in a view is less than what you expect, or none.\n\nAn absence alert is triggered when the view that has an absence alert attached to it is active. A view is active when the view receives logs within the last 24 hours.\n\nFor example, you might have a view that does not get any logs for 2 days. Therefore, this view is not active. You have an absence alert attached to this view that is configured to send a notification after 30 minutes. Because the view is not active, the absence alert is muted and you do not get notifications. To make the view active and get notifications for the absence condition, logs need to start flowing into the view.\n\n\n\n\n\n\n\n Alert conditions \n\nYou can configure any of the following triggering conditions for each notification channel that you configure for an alert:", "title": "", "source": "https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-alerts"}, {"document_id": "ibmcld_09552-3597-5166", "score": 13.504644, "text": "\n{\"notificationChannel\":{\"id\":39209,\"version\":1,\"customerId\":34292,\"enabled\":true,\"sendTestNotification\":true,\"createdOn\":1678967870764,\"modifiedOn\":1678967870764,\"name\":\"thursTest\",\"options\":{\"notifyOnOk\":true,\"emailRecipients\":[\"email@email.com\"],\"notifyOnResolve\":true},\"type\":\"EMAIL\"}}%\u00a0\n\nYou have now created a notification channel for your alerts.\n\nMake a note of the id field that is returned by the API call.\n\n\n\n\n\n Step 3: Create the alert \n\nNow that you have a notification channel, create your [alert rule](https://cloud.ibm.com/docs/monitoring?topic=monitoring-alert_api). Your alert rule describes the metric query to be monitored, the threshold value, and the action to take when the threshold is crossed. In this case, you're monitoring your ibm_service_instance_name to ensure that max utilization doesn't exceed 90%. If that happens, an alert is triggered and you're notified.\n\nThis alert is triggered at 90% disk utilization. However, 50-70% disk utilization is preferred.\n\nTo retrieve the name of the database instance you want to set up the alert for, list all your database instances with a command like:\n\nibmcloud cdb ls\n\nMake sure to select a database in the same region as the monitoring instance.\n\nYou see output like the following:\n\nRetrieving instances for all database types in all resource groups in all locations under IBM as \u2026\nOK\nName Location State\nDatabases for PostgreSQL-76 us-south inactive\ntestelastic eu-gb active\nDatabases for MySQL-9j us-south active\n\nNow, use the name of your database to create the alert by using a command like:", "title": "", "source": "https://cloud.ibm.com/docs/messages-for-rabbitmq?topic=messages-for-rabbitmq-disk-util-alert-tutorial"}, {"document_id": "ibmcld_09700-7-1797", "score": 13.486564, "text": "\nConfiguring an alert by using the legacy alert editor \n\nIn the IBM Cloud Monitoring service, you can configure single alerts and multi-condition alerts to notify about problems that may require attention. When an alert is triggered, you can be notified through 1 or more notification channels. An alert definition can generate multi-channel notifications.\n\nAn alert is a notification event that you can use to warn about situations that require attention. Each alert has a severity status. This status informs you about the criticality of the information it reports on. [Learn more](https://cloud.ibm.com/docs/monitoring?topic=monitoring-alerts).\n\nComplete the following steps to configure an alert:\n\n\n\n Step 1. Select the alert type \n\nFrom the Alert section of the UI, select Add Alert. Then, choose the alert type.\n\n\n\n\n\n Step 2. Name the alert \n\nEnter a name for the alert.\n\nYou can also add a description for the alert and the name of an alert group if you want to group you alerts. If an alert group is not specified, the alert will be created in the default group.\n\n\n\n\n\n Step 3. Define the severity \n\nAdd a severity level. Valid severity values are info, low, medium, and high.\n\n\n\n\n\n Step 4. Define the metric section \n\n\n\n1. Select a metric (entity) that you want to monitor.\n2. Define the alert condition. Choose any of the following options:\n\nOption 1: Choose a metric and a single condition such as average, sum, minimum or maximum.\n\nOption 2: Choose Create multi-condition alerts. Enter the condition, for example, min(min(cpu.used.percent)) < = 50 OR max(max(cpu.used.percent)) >= 80.\n\nZoom\n\n![Multi-condition alert](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/monitor/images/multi-condition-alerts.png)\n\nMulti-condition alert", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-alert-config"}, {"document_id": "ibmcld_09703-7-2026", "score": 13.418708, "text": "\nWorking with alerts and events \n\nIn the IBM Cloud Monitoring service, you can configure single alerts and multi-condition alerts to notify about problems that may require attention. When an alert is triggered, you can be notified through 1 or more notification channels. An alert definition can generate multi-channel notifications.\n\nAn alert is a notification event that you can use to warn about situations that require attention. Each alert has a severity status. This status informs you about the criticality of the information it reports on.\n\nWhen you define an alert, you must define the condition that triggers the notification, and one or more notification channels through which you want to be notified. You must also define the severity of the alert, and the type of alert. For more information about how to configure an alert, see [Configuring an alert](https://cloud.ibm.com/docs/monitoring?topic=monitoring-alert-config).\n\nBy default, severity is set to warning. You can set the severity of an alert to any of the following values: emergency, alert, critical, error, warning, notice, informational, debug*\n\nYou can define an alert on a single metric or a set of metrics to notify of events or issues that you want to monitor.\n\n\n\n* You can define a single condition alert.\n* You can define a multi-condition alert. The alert threshold is configured by using complex conditions.\n* You can define how the data is aggregated.\n* You can use boolean logic to define alerts that report on multiple metrics.\n* You get a notification when the alert condition is met.\n* You can configure multiple notification channels per alert.\n* Alerts are executed in 1 minute or less from receipt, with the option to configure the trigger wait time by hour or day.\n* For PromQL alerts only, you can optionally configure a 0 minute wait time.\n\n\n\nYou can enable predefined alerts, modify alerts, and create custom alerts in the web UI and by using the IBM Cloud Monitoring API.\n\nYou manage alerts in the Alerts view of the web UI.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-alerts"}, {"document_id": "ibmcld_09782-2779-4374", "score": 13.330778, "text": "\nALL indicates that the alert is triggered when all of the monitored entities satisfy the condition.\n\n--user-filter <USER_FILTER>\n: Boolean expression that you can set to reduce the scope of the alert. Use this parameter to configure segments, such as filters like kubernetes.namespace.name='production' or container.image='nginx'.\n\n--notify <NOTIFY>\n: Type of notification that you want this alert to generate. Options are EMAIL, SNS, PAGER_DUTY, and SYSDIG_DUMP.\n\n--file <FILE> | -f <JSON_FILE>\n: Name of the JSON file that contains the data set for a new alert creation. Make sure you create the alert.json file before invoking this command.\n\n--region <REGION> | -r <REGION>\n: Name of the region, for example, us-south or eu-gb. If not specified, the region logged into or targeted will be used.\n\n--output <FORMAT>\n: A comma-separated list of output preferences enclosed in double-quotes (\"). If only a single preference is specified, the double-quotes can be omitted. Supported options are WIDE and JSON.\n\nIf JSON is specified, output will be returned in JSON format. If JSON is not specified, output will be returned in a tabular format.\n\nWIDE returns additional details in the output.\n\n--team <TEAM_NAME>\n: The name of the IBM Cloud Monitoring team to be used for authorization. If no team is specified, the default team will be used.\n\n--help | -h\n: List options available for the command.\n\n\n\n\n\n Examples \n\nThe following are examples using the ibmcloud monitoring alert add command.\n\nAdd an alert for the IBM Cloud Monitoring abc instance to detect a CrashLoopBackOff in the last 5 minutes.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-monitor-cli"}, {"document_id": "ibmcld_09703-3207-5376", "score": 13.16917, "text": "\n* Anomaly Detection: Use this type of alert to monitor hosts based on historical behaviors and alert when they deviate from the expected pattern.\n\nThis type of alert is deprecated. You can only manage existing alerts of this type.\n* Group Outlier: Use this type of alert to monitor hosts and be notified when 1 acts differently from the rest.\n\nThis type of alert is deprecated. You can only manage existing alerts of this type.\n\n\n\n\n\n\n\n Notification channels \n\nA notification channel defines where you want to receive information when an alert is triggered.\n\nWhen you configure an alert, you can specify 1 or more notification channels.\n\nBy default, when an alert is triggered, you get a notification in the Events section.\n\nYou can configure any of the following notification channels:\n\n\n\n* Email\n* IBM Cloud Functions\n* IBM Event Notifications\n* Microsoft Teams\n* OpsGenie\n* PagerDuty\n* Slack\n* Teams Email\n* VictorOps\n* WebHook\n\n\n\n\n\n\n\n Events \n\nAn event is a notification that informs about something that occurs in any of the nodes that forward data to your Monitoring instance. Use events to review, track, and resolve issues.\n\nThe following list outlines different types of events:\n\n\n\n* Alert events are events that are triggered by user-configured alerts.\n* Infrastructure-based events are events that are collected from Docker and Kubernetes nodes. By default, the monitoring agent automatically discovers and collects data from a select group of events. You can edit the agent configuration file to enable more events.\n* Custom events that you configure through any of the following integrations: Slackbot, pre-built Python scripts, custom user-created Python scripts, or cURL requests.\n\n\n\nBy default, an event has a state:\n\n\n\n* Active: This state indicates that the circumstances that triggered the event remain in place, for example, a node continues to be down.\n* OK: This state indicates that the situation is back to normal, for example, a node is up and running.\n\n\n\nYou manage events in the Events section of the web UI.\n\n\n\n* You can view alert events through the Alert Events tab.\n* You can view infrastructure-based events through the Custom events tab.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-alerts"}]}
{"task_id": "1be66272113492407e814eaf21a761d4<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03363-1671-3630", "score": 12.805613, "text": "\nAn exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs-overview"}, {"document_id": "ibmcld_03107-5127-7134", "score": 11.857968, "text": "\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a /message API call. This property can be used to identify multiple /message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new /message API call.\n\n\n\nFor example, if the same person chats with your assistant on three separate occasions over the same billing period, how you represent that user in the API call impacts how the interactions are billed. If you identify the user interaction with a user_id, it counts as one use. If you identify the user interaction with a session_id, then it counts as three uses (because there is a separate session that is created for each interaction).\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle. For example, don't use a person's email address as the user ID. In fact, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https://tools.ietf.org/html/rfc7230section-3.2).\n\nThe built-in integrations derive the user ID in the following ways:\n\n\n\n* For Facebook integrations, the user_id property is set to the sender ID that Facebook provides in its payload.\n* For Slack integrations, the user_id property is a concatenation of the team ID, such as T09LVDR7Y, and the member ID of the user, such has W4F8K9JNF. For example: T09LVDR7YW4F8K9JNF.\n* For web chat, you can set the value of the user_id property.\n\n\n\nBilling is managed per monthly active user per service instance. If a single user interacts with assistants that are hosted by different service instances that belong to the same plan, each interaction is treated as a separate use.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-admin-managing-plan"}, {"document_id": "ibmcld_16274-8427-10190", "score": 11.816631, "text": "\nProperties of the assistant_interaction_summaries.turns[].response object\n\n Property Type Description \n\n type String The response type:<br><br><br><br> * text_to_speech: a command to play an utterance to the caller<br> * sms: a command to send an SMS message to the caller<br> * url: a command to play an audio file to the caller<br> * transfer: a command to transfer a call<br> * text_to_speech_config: a command to change the Text to Speech settings<br> * speech_to_text_config: a command to change the Speech to Text settings<br> * pause_speech_to_text: a command to stop speech recognition<br> * unpause_speech_to_text: a command to start speech recognition<br> * pause_dtmf: a command to stop processing of inbound DTMF signals<br> * unpause_dtmf: unpause_dtmf: a command to start processing of inbound DTMF signals<br> * enable_speech_barge_in: a command to enable speech barge-in so that callers can interrupt playback by speaking<br> * disable_speech_barge_in: a command to disable speech barge-in so that playback isn't interrupted when callers speak during audio playback<br> * enable_dtmf_barge_in: a command to enable DTMF barge-in so that callers can interrupt playback from the phone integration by pressing a key<br> * disable_dtmf_barge_in: a command to disable DTMF barge-in so that playback from the phone integration isn't interrupted when the caller presses a key<br> * dtmf: a command to send DTMF signals to the caller<br> * hangup: a command to disconnect the call <br> See [Mapping between CDR and Watson Assistant response types](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-cdr-log-referencecdr-log-reference-response-type-mapping).<br><br><br> \n barge_in_occurred Boolean Whether barge-in occurred during the turn.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-cdr-log-reference"}, {"document_id": "ibmcld_16274-11413-13206", "score": 11.6803465, "text": "\nenable_dtmf_barge_in dtmf, command_info.type : enable_barge_in \n disable_dtmf_barge_in dtmf, command_info.type : disable_barge_in \n hangup end_session \n\n\n\n\n\n\n\n assistant_interaction_summaries.turns[].response.streaming_statistics \n\nThe assistant_interaction_summaries.turns[].response.streaming_statistics object contains the following properties:\n\n\n\nProperties of the assistant_interaction_summaries.turns[].response.streaming_statistics object\n\n Property Type Description \n\n transaction_id String A unique identifier of the transaction. \n start_timestamp String The time when the transaction started, in ISO format (yyyy-MM-ddTHH:mm:ss.SSSZ). \n stop_timestamp String The time when the transaction ended, in ISO format (yyyy-MM-ddTHH:mm:ss.SSSZ). \n response_milliseconds Number The time (in milliseconds) between when a text utterance is sent to the assistant and when the phone integration receives the first packet of synthesized audio. \n\n\n\n\n\n\n\n\n\n\n\n\n\n warnings_and_errors \n\nThe warnings_and_errors object contains warnings and errors that were logged during the call, listed in order of occurrence. Warnings for the following conditions are included:\n\n\n\n* Messages when utterances are filtered out by the confidence score threshold.\n* Text to Speech underflows, which is when Text to Speech synthesis can't keep up with the phone integration streaming rate and audio might skip.\n* RTP network warnings, such as high packet loss or high average jitter, if RTCP is enabled.\n\n\n\nThe following example shows the structure of the warnings_and_errors object:\n\n\"warnings_and_errors\": [\n{\n\"message\": \"CWSMR0032W: A Watson Speech to Text final utterance has a confidence score of 0.1, which does not meet the confidence score threshold of 0.2. The utterance will be ignored.\",\n\"id\": \"CWSMR0032W\"\n},\n{", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-cdr-log-reference"}, {"document_id": "ibmcld_16274-5650-7471", "score": 11.3431835, "text": "\nSee [assistant_interaction_summaries.turns].request](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-cdr-log-referencecdr-log-reference-request). \n response Array An array of the response objects associated with the request. \n\n\n\n\n\n assistant_interaction_summaries.turns[].request \n\nThe assistant_interaction_summaries.turns[].request object contains the following properties:\n\n\n\nProperties of the assistant_interaction_summaries.turns[].request object\n\n Property Type Description \n\n type String The request type:<br><br><br><br> * start: an initial request is sent to the assistant<br> * speech_to_text: input is received from the Speech to Text service<br> * dtmf: DTMF collection completes<br> * sms: an SMS message is received from the caller<br> * post_response_timeout: the post-response timer expires<br> * redirect: a call is redirected<br> * transfer: a call is transferred<br> * transfer_failed: a call transfer fails<br> * final_utterance_timeout: the final utterance timer expires<br> * no_input_turn: no input turn is enabled<br> * sms_failure: an SMS message cannot be sent to the caller<br> * speech_to_text_result_filtered: an utterance is filtered due to low confidence level<br> * mrcp_recognition_unsuccessful: the MRCP recognition completes without a final utterance<br> * network_warning: a network error is detected<br> * media_capability_change: media capabilities change during a call<br><br><br> \n streaming_statistics Object Information and statistics related to the Speech to Text recognition. See [assistant_interaction_summaries.turns].request.streaming_statistics](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-cdr-log-referencecdr-log-reference-request-streaming_statistics). \n\n\n\n\n\n assistant_interaction_summaries.turns[].request.streaming_statistics", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-cdr-log-reference"}, {"document_id": "ibmcld_07578-48886-50993", "score": 11.082043, "text": "\n* What does \"pricing per minute\" mean?\n\nFor the Plus plan, pricing is based on the cumulative amount (number of minutes) of audio that you send to the service in any one month. The per-minute price of all audio that you recognize in a month is reduced once you reach the threshold of one million minutes of audio for that month. The price does not depend on how long the service takes to process the audio. (Per-minute pricing is different for the Standard plan.)\n\nFor information about pricing for the Plus and Standard plans, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https://%7BDomainName%7D/catalog/speech-to-text).\n* Do you round up to the nearest minute for every call to the API?\n\nIBM does not round up the length of the audio for every API call that the service receives. Instead, IBM aggregates all usage for the month and rounds to the nearest minute at the end of the month. For example, if you send two audio files that are each 30 seconds long, IBM sums the duration of the total audio for that month to one minute.\n* Am I charged for all audio that I send, even audio that does not include speech?\n\nYes, all audio that you send to the service contributes to your cumulative minutes of audio. This includes silence and noisy audio that does not contain or otherwise contribute to speech recognition. Because the service must process all audio that it receives, it does not distinguish between the type or quality of audio that you send. For pricing purposes, three seconds of silence is equivalent to three seconds of actual speech.\n* What advantages do I get by using a Speech to Text Premium plan?\n\nThe Premium plan offers developers and organizations all of the capabilities and features of the Plus plan. The plan also offers these additional features:\n\n\n\n* The ability to use IBM Watson\u00ae services in the IBM Cloud\u00ae with data isolation and added security features such as IBM\u00ae Key Protect for IBM Cloud\u00ae (also referred to as Bring your own keys (BYOK)), Service Endpoints, Mutual Authentication, and US Health Insurance Portability and Accountability Act (HIPAA) readiness.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-48871-50978", "score": 11.082043, "text": "\n* What does \"pricing per minute\" mean?\n\nFor the Plus plan, pricing is based on the cumulative amount (number of minutes) of audio that you send to the service in any one month. The per-minute price of all audio that you recognize in a month is reduced once you reach the threshold of one million minutes of audio for that month. The price does not depend on how long the service takes to process the audio. (Per-minute pricing is different for the Standard plan.)\n\nFor information about pricing for the Plus and Standard plans, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https://%7BDomainName%7D/catalog/speech-to-text).\n* Do you round up to the nearest minute for every call to the API?\n\nIBM does not round up the length of the audio for every API call that the service receives. Instead, IBM aggregates all usage for the month and rounds to the nearest minute at the end of the month. For example, if you send two audio files that are each 30 seconds long, IBM sums the duration of the total audio for that month to one minute.\n* Am I charged for all audio that I send, even audio that does not include speech?\n\nYes, all audio that you send to the service contributes to your cumulative minutes of audio. This includes silence and noisy audio that does not contain or otherwise contribute to speech recognition. Because the service must process all audio that it receives, it does not distinguish between the type or quality of audio that you send. For pricing purposes, three seconds of silence is equivalent to three seconds of actual speech.\n* What advantages do I get by using a Speech to Text Premium plan?\n\nThe Premium plan offers developers and organizations all of the capabilities and features of the Plus plan. The plan also offers these additional features:\n\n\n\n* The ability to use IBM Watson\u00ae services in the IBM Cloud\u00ae with data isolation and added security features such as IBM\u00ae Key Protect for IBM Cloud\u00ae (also referred to as Bring your own keys (BYOK)), Service Endpoints, Mutual Authentication, and US Health Insurance Portability and Accountability Act (HIPAA) readiness.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_03367-2935-4844", "score": 10.6960745, "text": "\nprivate.sip_request_uri string The SIP request URI that started the conversation session. \n private.sip_to_uri string The SIP To URI associated with the conversation session. \n private.user_phone_number string The phone number that the call was received from. \n assistant_phone_number string The phone number associated with the Watson Assistant side that received the phone call. \n\n\n\n\n\n\n\n Input parameters that are set by the phone channel \n\nThe following input parameters are only valid for the current conversation turn.\n\n\n\nInput parameters set by the phone channel\n\n Name Type Description \n\n post_response_timeout_occurred boolean Whether the post response timeout expired. \n barge_in_occurred boolean Whether barge-in occurred. \n final_utterance_timeout_occurred true or false Whether the final utterance timeout expired. \n dtmf_collection_succeeded boolean Whether the DTMF collection succeeded or failed. When true, a DTMF collection succeeded, and returns the expected number of digits. When false, a DTMF collection failed to collect the specified number of digits. Even when dtmf_collection_succeeded is false, all collected digits are passed to the dialog in the input string of the turn request. \n is_dtmf boolean Whether the input to Watson Assistant is dual-tone multi-frequency signaling (DTMF). \n speech_to_text_result object The final response from the Speech to Text service in JSON format, including the transcript and confidence score for the top hypothesis and any alternatives. The format matches exactly the format that is received from the Speech to Text service. (For more information, see the [Speech to Text API documentation](https://cloud.ibm.com/apidocs/speech-to-textrecognize).) \n\n\n\n\n\n Example \n\n{\n\"input\": {\n\"text\": \"agent \",\n\"integrations\": {\n\"voice_telephony\": {\n\"speech_to_text_result\": {\n\"result_index\": 0,\n\"stopTimestamp\": \"2021-09-29T17:43:31.036Z\",\n\"transaction_ids\": {", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-phone-context"}, {"document_id": "ibmcld_09795-1650-3805", "score": 10.557064, "text": "\nIn your monthly usage charges, consumption is measured hourly and your bill breaks down into the following concepts:\n\n\n\nTable 2. Billing usage metrics\n\n Metric Description \n\n NODE_HOURS Tracks the number of agents that are running in an agent for orchestrated environments.<br><br>This does not include the agents tracked by LITE_NODE_HOURS<br><br>For example, if you have 1 agent connected continuously, that agent will be billed 720 NODE_HOURS at the end of the month. \n TIME_SERIES_HOURS Reflects the total number of custom metrics time series you are sending to IBM Cloud Monitoring during a 1 hour time window. This is an aggregation of all time series from agents and other metrics sources. Platform metrics, Prometheus remote write, metric streaming and custom metrics collected with the agent (Prometheus, JMX or StatsD) contribute to TIME_SERIES_HOURS.<br><br>Only custom metrics are counted for TIME_SERIES_HOURS. Default infrastructure metrics (such as host, container, program, or Kubernetes state) and CPU, memory, disk, and network are included in the agent price and do not contribute to TIME_SERIES_HOURS. \n LITE_NODE_HOURS Tracks the number of agents that are monitoring non-containerized infrastructures such as VMs or bare metal servers, and are using the agent for non-orchestrated environments. \n API_CALL_HOURS Represents how many calls are being made to the API per month. All instances include 1M API calls. \n CONTAINER_HOURS Represents how many containers are monitored across all hosts that are being monitored by agents. \n\n\n\nTo monitor how the IBM Cloud Monitoring service is used and the costs associated to its usage, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusageviewingusage).\n\nAll metrics that start with sysdig_* and kube_ are collected automatically by an agent and are included in the agent price.\n\n\n\n\n\n Service plans \n\nThe following service plans are available when you provision an instance of the IBM Cloud Monitoring service:\n\n\n\n Lite plan \n\nYou can provision a Monitoring instance with the Lite service plan to try out the Monitoring service for free for 30 days.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-pricing_plans"}, {"document_id": "ibmcld_16349-5297-7599", "score": 10.464331, "text": "\nactionStarted Boolean Whether the action was started during the same conversation turn. \n actionTitle String The title of the action (for example, I want to pay my bill). \n assistantId String The ID of the assistant. \n browser String The browser that was used to send the message that triggered the action. \n channel String The channel the customer used to send the message that started the action (for example, phone or chat). \n device String The type of device that was used to send the message that triggered the action. \n environment String The environment in which the action completed (such as draft or live.) \n fallbackReason String The reason why the fallback action was called (for example, escalated to human agent or no action matches). \n handler String The name of any handler that was called by the action. \n language String The language of the assistant. \n pageUrl String The URL of the web page from which the message that triggered the action was sent. \n serviceInstance String The IBM Watson Assistant service instance. \n sessionId String The ID of the session during which the message that started the action was sent. \n skillsInvoked String[] An array of strings listing all skills that were invoked during handling of the message that started the action (for example, main skill or actions skill). \n stepsVisited String[] An array of strings listing the steps visited during processing of the action. \n subaction String The name of any other action that the action called during processing. \n\n\n\n\n\n\n\n Session Started \n\nSent when a new session is started.\n\nNote: The v2 stateless API does not generate events for starting sessions.\n\n\n\n Property Type Description \n\n accountId String The ID of the IBM account. \n assistantId String The ID of the assistant. \n browser String The browser that was used to send the message that started the session. \n channel String The channel that started the session (for example, phone or chat). \n device String The type of device that was used to send the message that started the session. \n environment String The environment in which the session was started (such as draft or live.) \n pageUrl String The URL of the web page from which the message that started the session was sent. \n serviceInstance String The IBM Watson Assistant service instance.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-segment-event-reference"}]}
{"task_id": "1be66272113492407e814eaf21a761d4<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03028-1501-3230", "score": 19.53717, "text": "\nYou can filter messages by Search user statements, Intents, Entities, and Last n days.\n\nSearch user statements - Type a word in the search bar. This searches the users' inputs, but not your assistant's replies.\n\nIntents - Select the drop-down menu and type an intent in the input field, or choose from the populated list. You can select more than one intent, which filters the results using any of the selected intents, including Irrelevant.\n\n![Intents drop-down menu](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/intents_filter.png)\n\nEntities - Select the drop-down menu and type an entity name in the input field, or choose from the populated list. You can select more than one entity, which filters the results by any of the selected entities. If you filter by intent and entity, your results will include the messages that have both values. You can also filter for results with No entities found.\n\n![Entities drop-down menu](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/entities_filter.png)\n\nMessages might take some time to update. Allow at least 30 minutes after a user's interaction with your assistant before attempting to filter for that content.\n\n\n\n\n\n Viewing individual messages \n\nFor any user input entry, click Open conversation to see the user input and the response made to it by the assistant within the context of the full conversation.\n\nThe time that is shown for each conversation is localized to reflect the time zone of your browser. This time might differ from the timestamp shown if you review the same conversation log via an API call; API log calls are always shown in UTC.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs"}, {"document_id": "ibmcld_03028-2666-4421", "score": 16.412857, "text": "\nAllow at least 30 minutes after a user's interaction with your assistant before attempting to filter for that content.\n\n\n\n\n\n Viewing individual messages \n\nFor any user input entry, click Open conversation to see the user input and the response made to it by the assistant within the context of the full conversation.\n\nThe time that is shown for each conversation is localized to reflect the time zone of your browser. This time might differ from the timestamp shown if you review the same conversation log via an API call; API log calls are always shown in UTC.\n\n![Open conversation panel](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/open_convo.png)\n\nYou can then choose to show the classification(s) for the message you selected.\n\n![Open conversation panel with classifications](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/open_convo_classes.png)\n\nIf the spell check feature is enabled for the skill, then any user utterances that were corrected are highlighted by the Auto-correct icon. The term that was corrected is underlined. You can hover over the underlined term to see the user's original input.\n\n![Open conversation panel that shows the original text for a term to which spelling correction logic was applied](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/open_convo_spellchecked.jpg)\n\n\n\n\n\n Improving across assistants \n\nCreating a dialog skill is an iterative process. While you develop your skill, you use the Try it out pane to verify that your assistant recognizes the correct intents and entities in test inputs, and to make corrections as needed.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs"}, {"document_id": "ibmcld_03354-1698-3275", "score": 16.35108, "text": "\n------------------------------------ | ------------------------------------\nEnterprise with Data Isolation | Last 90 days\nEnterprise | Last 30 days\nPremium (legacy) | Last 90 days\nPlus | Last 30 days\nTrial | Last 30 days\nLite | Last 7 days\n\n\n\n\n\n Filtering messages \n\nYou can filter messages by Search user statements, Intents, Entities, and Last n days.\n\nSearch user statements - Type a word in the search bar. This searches the users' inputs, but not your assistant's replies.\n\nIntents - Select the drop-down menu and type an intent in the input field, or choose from the populated list. You can select more than one intent, which filters the results using any of the selected intents, including Irrelevant.\n\n![Intents drop-down menu](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/intents_filter.png)\n\nEntities - Select the drop-down menu and type an entity name in the input field, or choose from the populated list. You can select more than one entity, which filters the results by any of the selected entities. If you filter by intent and entity, your results will include the messages that have both values. You can also filter for results with No entities found.\n\n![Entities drop-down menu](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/entities_filter.png)\n\n\n\n\n\n Viewing individual messages \n\nFor any user input entry, click Open conversation to see the user input and the response made to it by the assistant within the context of the full conversation.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs"}, {"document_id": "ibmcld_02991-7699-8461", "score": 15.602773, "text": "\n| [response.output.intents:intent::order,response.output.entities:entity::beverage] |\n\n\n\n\n\n Filtering v1 logs \n\nIf your application is still using the v1 API, you can query and filter logs using the v1 /logs method. The filtering syntax is the same, but the structure of v1 logs and message requests is different. For more information, see [API Reference](https://cloud.ibm.com/apidocs/assistant-data-v1listlogs).\n\nWith the v1 /logs API, you can filter on the following fields:\n\n\n\n* request.context.metadata.deployment\n* request.context.system.assistant_id\n* request.input.text\n* response.entities\n* response.input.text\n* response.intents\n* response.top_intent\n* meta.message.entities_count\n* workspace_id\n\n\n\nFiltering on other fields is not currently supported.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-filter-reference"}, {"document_id": "ibmcld_03037-7-1971", "score": 15.300423, "text": "\nAdvanced tasks \n\nLearn about APIs and other tools you can use to access and analyze log data.\n\n\n\n API \n\nYou can use the /logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For conversations created by using the v2 /message API, use the instance-level endpoint to [list log events in all workspaces](https://cloud.ibm.com/apidocs/assistant-data-v2listalllogs), and then filter by Assistant ID. For more information about filtering logs, see [Filter query reference](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-filter-reference).\n\nThe number of days that logs are stored differs by service plan type. See [Log limits](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logslogs-limits) for details.\n\nFor a Python script you can run to export logs and convert them to CSV format, download the export_logs_py.py file from the [Watson Assistant GitHub)](https://github.com/watson-developer-cloud/community/blob/master/watson-assistant/export_logs_py.py) repository.\n\n\n\n\n\n Logs-related terminology \n\nFirst, review the definitions of terms that are associated with Watson Assistant logs:\n\n\n\n* Assistant: An application - sometimes referred to as a 'chat bot' - that implements your Watson Assistant content.\n* Assistant ID: The unique identifier of an assistant.\n* Conversation: A set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back.\n* Conversation ID: Unique identifier that is added to individual message calls to link related message exchanges together. App developers using the V1 version of the Watson Assistant API add this value to the message calls in a conversation by including the ID in the metadata of the context object.\n* Customer ID: A unique ID that can be used to label customer data such that it can be subsequently deleted if the customer requests the removal of their data.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-resources"}, {"document_id": "ibmcld_05891-230244-232067", "score": 15.045287, "text": "\nAcceptable values in their canonical order are fatal, error, warn/warning, info, debug, and trace. As an example, if you filtered logs at the info level, debug, and trace are also filtered. Note: You can use this option only when log messages are in JSON format and contain a level field. Example output {\"log\": \"hello\", \"level\": \"info\"}\n\n--message MESSAGE\n: Optional: Filters out any logs that contain a specified message anywhere in the log. Example: The messages \"Hello\", \"!\", and \"Hello, World!\", would apply to the log \"Hello, World!\".\n\n--regex-message MESSAGE\n: Optional: Filters out any logs that contain a specified message that is written as a regular expression anywhere in the log. Example: The pattern \"hello [0-9]\" would apply to \"hello 1\", \"hello 2\", and \"hello 9\".\n\n--force-update\n: Force your Fluentd pods to update to the latest version. Fluentd must be at the latest version to change your logging configurations.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\nExamples:\n\nThis example filters out all logs that are forwarded from containers with the name test-container in the default namespace that are at the debug level or less, and have a log message that contains \"GET request\".\n\nibmcloud ks logging filter create --cluster example-cluster --type container --namespace default --container test-container --level debug --message \"GET request\"\n\nThis example filters out all the logs that are forwarded, at an info level or less, from a specific cluster. The output is returned as JSON.\n\nibmcloud ks logging filter create --cluster example-cluster --type all --level info --output json\n\n\n\n\n\n ibmcloud ks logging filter get \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nView a logging filter configuration.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli"}, {"document_id": "ibmcld_04489-230696-232519", "score": 15.045287, "text": "\nAcceptable values in their canonical order are fatal, error, warn/warning, info, debug, and trace. As an example, if you filtered logs at the info level, debug, and trace are also filtered. Note: You can use this option only when log messages are in JSON format and contain a level field. Example output {\"log\": \"hello\", \"level\": \"info\"}\n\n--message MESSAGE\n: Optional: Filters out any logs that contain a specified message anywhere in the log. Example: The messages \"Hello\", \"!\", and \"Hello, World!\", would apply to the log \"Hello, World!\".\n\n--regex-message MESSAGE\n: Optional: Filters out any logs that contain a specified message that is written as a regular expression anywhere in the log. Example: The pattern \"hello [0-9]\" would apply to \"hello 1\", \"hello 2\", and \"hello 9\".\n\n--force-update\n: Force your Fluentd pods to update to the latest version. Fluentd must be at the latest version to change your logging configurations.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\nExamples:\n\nThis example filters out all logs that are forwarded from containers with the name test-container in the default namespace that are at the debug level or less, and have a log message that contains \"GET request\".\n\nibmcloud ks logging filter create --cluster example-cluster --type container --namespace default --container test-container --level debug --message \"GET request\"\n\nThis example filters out all the logs that are forwarded, at an info level or less, from a specific cluster. The output is returned as JSON.\n\nibmcloud ks logging filter create --cluster example-cluster --type all --level info --output json\n\n\n\n\n\n ibmcloud ks logging filter get \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nView a logging filter configuration.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-kubernetes-service-cli"}, {"document_id": "ibmcld_00519-12531-14412", "score": 14.856215, "text": "\nIn particular, you must not use functions that generate random numbers or return the current time.\n\n\n\n\n\n\n\n Filter functions \n\nDesign documents with options.partitioned set to true can't contain a filters field.\n\nFilter functions are design documents that filter the [changes feed](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-databasesget-changes). They work by applying tests to each of the objects included in the changes feed.\n\nIf any of the function tests fail, the object is \"removed\" or \"filtered\" from the feed. If the function returns a true result when applied to a change, the change remains in the feed. In other words, filter functions \"remove\" or \"ignore\" changes that you don't want to monitor.\n\nFilter functions can also be used to modify a [replication task](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-advanced-replicationfiltered-replication-adv-repl).\n\nFilter functions require two arguments: doc and [req](https://docs.couchdb.org/en/stable/json-structure.htmlrequest-object).\n\nThe doc argument represents the document that is tested for filtering.\n\nThe req argument includes more information about the request. With this argument, you can create filter functions that are more dynamic because they're based on multiple factors such as query parameters or the user context.\n\nFor example, you could control aspects of the filter function tests by using dynamic values that are provided as part of the HTTP request. However, in many filter function use cases, only the doc parameter is used.\n\nSee the following example design document that includes a filter function:\n\n{\n\"_id\":\"_design/example_design_doc\",\n\"filters\": {\n\"example_filter\": \"function (doc, req) { ... }\"\n}\n}\n\nSee the following example of a filter function:\n\nfunction(doc, req){\n// we need only mail documents\nif (doc.type != 'mail'){\nreturn false;\n}\n// we're interested only in new ones", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-design-documents"}, {"document_id": "ibmcld_05832-21399-23084", "score": 14.84151, "text": "\nIf not provided, the filter is applied to all the cluster logging configurations that are passed to the filter. You can view log configurations that match the filter by using the --show-matching-configs option. \n <kubernetes_namespace> Optional: The Kubernetes namespace that you want to forward logs from. This option applies only when you are using log type container. \n <container_name> Optional: The name of the container from which you want to filter logs. \n <logging_level> Optional: Filters out logs that are at the specified level and less. Acceptable values in their canonical order are fatal, error, warn/warning, info, debug, and trace. As an example, if you filtered logs at the info level, debug, and trace are also filtered. Note: You can use this option only when log messages are in JSON format and contain a level field. To display your messages in JSON, append the --output json option to the command. \n <message> Optional: Filters out logs that contain a specified message that is written as a regular expression. \n <filter_ID> Optional: The ID of the log filter. \n --show-matching-configs Optional: Show the logging configurations that each filter applies to. \n --all Optional: Delete all your log forwarding filters. \n\n\n\n\n\n1. Create a logging filter.\n\nibmcloud ks logging filter create --cluster <cluster_name_or_ID> --type <log_type> --logging-configs <configs> --namespace <kubernetes_namespace> --container <container_name> --level <logging_level> --regex-message <message>\n2. View the log filter that you created.\n\nibmcloud ks logging filter get --cluster <cluster_name_or_ID> --id <filter_ID> --show-matching-configs\n3. Update the log filter that you created.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-health"}, {"document_id": "ibmcld_16310-7627-8554", "score": 14.841298, "text": "\nAn intent name in the response exactly matches order, and an entity name in the response exactly matches beverage. [response.output.intents:intent::order,response.output.entities:entity::beverage] \n\n\n\n\n\n\n\n Filtering v1 logs \n\nIf your application is still using the v1 API, you can query and filter logs using the v1 /logs method. The filtering syntax is the same, but the structure of v1 logs and message requests is different. For more information, see [API Reference](https://cloud.ibm.com/apidocs/assistant/assistant-v1listlogs).\n\nWith the v1 /logs API, you can filter on the following fields:\n\n\n\n* language\n* meta.message.entities_count\n* request.context.metadata.deployment\n* request.context.system.assistant_id\n* request.input.text\n* response.context.conversation_id\n* response.entities\n* response.input.text\n* response.intents\n* response.top_intent\n* workspace_id\n\n\n\nFiltering on other fields is not currently supported.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-filter-reference"}]}
{"task_id": "2f013337236ea4635ad106813275dab7<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04866-7-2136", "score": 15.752526, "text": "\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-7-2136", "score": 15.752526, "text": "\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_02361-24500-26305", "score": 14.6994095, "text": "\n[Information about Immutable Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time? [Information about archiving COS files for long term storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-archive) \n Encryption of data at-rest with my own key [5] Can I use my own key to encrypt data at-rest? [Information about encryption of data at-rest](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-encryption) \n Data resiliency [6] Do you need to store the data in a specific geographical location? [Information about resiliency](https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-endpoints) \n\n\n\n[1]: Data might sit untouched for long periods of time. For less active workloads, you can create buckets with different storage classes. For example, use the standard storage class for active workloads, where you need to access data at any time.\n\n[2]: You can choose Immutable Object Storage to preserve electronic records and maintain data integrity. When you define a retention policy for a bucket, you are specifying that the data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds. Notice that Immutable Object Storage is available in certain regions only.\n\n[3]: You can use an expiration rule to delete objects automatically after a defined period from the object creation date.", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-adoption"}, {"document_id": "ibmcld_04869-7924-8861", "score": 14.28007, "text": "\nYou can manage your keys manually by supplying your own encryption keys - referred to as Server-Side Encryption with Customer-Provided Keys (SSE-C).\n\n\n\n\n\n Archive rules \n\nIBM Cloud\u00ae Object Storage Archive is a low-cost option for data that is rarely accessed. You can migrate data from any of the storage tiers (Standard, Vault, Cold Vault, and Flex) to a long-term offline archive.\n\n\n\n\n\n Retention policies \n\nImmutable Object Storage maintains data integrity in a WORM (Write-Once-Read-Many) manner. Objects can't be modified until the end of their retention period and the removal of any legal holds.\n\n\n\n\n\n Aspera high-speed transfer \n\nAspera high-speed transfer improves data transfer performance under most conditions, especially in networks with high latency or packet loss. Instead of the standard HTTP PUT, Aspera high-speed transfer uploads the object by using the [FASP protocol](https://www.ibm.com/products/aspera/technology).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-sdk-about"}, {"document_id": "ibmcld_05126-7854-8791", "score": 14.28007, "text": "\nYou can manage your keys manually by supplying your own encryption keys - referred to as Server-Side Encryption with Customer-Provided Keys (SSE-C).\n\n\n\n\n\n Archive rules \n\nIBM Cloud\u00ae Object Storage Archive is a low-cost option for data that is rarely accessed. You can migrate data from any of the storage tiers (Standard, Vault, Cold Vault, and Flex) to a long-term offline archive.\n\n\n\n\n\n Retention policies \n\nImmutable Object Storage maintains data integrity in a WORM (Write-Once-Read-Many) manner. Objects can't be modified until the end of their retention period and the removal of any legal holds.\n\n\n\n\n\n Aspera high-speed transfer \n\nAspera high-speed transfer improves data transfer performance under most conditions, especially in networks with high latency or packet loss. Instead of the standard HTTP PUT, Aspera high-speed transfer uploads the object by using the [FASP protocol](https://www.ibm.com/products/aspera/technology).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-sdk-about"}, {"document_id": "ibmcld_04866-1541-3629", "score": 14.278825, "text": "\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https://cloud.ibm.com/docs/services/cloud-object-storage/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-1541-3629", "score": 14.278825, "text": "\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https://cloud.ibm.com/docs/services/cloud-object-storage/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_00469-2977-5094", "score": 14.171958, "text": "\nIt is more expensive in the end to mutate existing documents than to create new ones. IBM Cloudant always needs to keep the document tree structure around. This rule applies even if internal nodes in the tree are stripped of their payloads. If you find that you create long revision trees, your replication performance suffers. Moreover, if your update frequency is higher than, say, once or twice every few seconds, you\u2019re more likely to produce update conflicts.\n\nPrefer models that are immutable.\n\nWhen you read the following sections, Deleting documents doesn't delete them and Be careful with updates, they provoke an obvious question. That is, does the data set grow unbounded if my model is immutable? If you accept that deletes don\u2019t completely purge the deleted data and that updates are not updating in place in terms of data volume growth, not much difference exists. Managing data volume over time requires different techniques.\n\nThe only way to truly reclaim space is to delete databases, rather than documents. You can replicate only winning revisions to a new database and delete the old to get rid of lingering deletes and conflicts. Or perhaps you can build it into your model to regularly start new databases (say \u2018annual data\u2019) and archive off (or remove) outdated data, if your use case allows.\n\n\n\n\n\n Eventual consistency is a harsh taskmaster (also known as don\u2019t read your writes) \n\nEventual consistency is a great idea on paper, and a key contributor to IBM Cloudant\u2019s ability to scale out in practice. However, it\u2019s fair to say that the mindset required to develop against an eventually consistent data store does not feel natural to most people.\n\nYou often get stung when you write tests similar to the following ones:\n\n\n\n1. Create a database.\n2. Populate the database with some test data.\n3. Query the database for some subset of this test data.\n4. Verify that the data that you got back is the data that you expected to get back.\n\n\n\nNothing wrong with that test? That works on every other database that you ever used, correct?\n\nNot on IBM Cloudant.\n\nOr rather, it works 99 times out of 100.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-cloudant-in-practice"}, {"document_id": "ibmcld_16727-451250-453592", "score": 13.793631, "text": "\nAs always, successful modeling involves achieving a balance between ease of use versus the performance characteristics you're hoping to achieve.\n\n(The FAQ for modeling data to scale is based on a blog article by Mike Rhodes, My top five tips for modeling your data to scale.)\n\n\n\nIf you're changing the same piece of state at a rate of once per second or more, consider making your documents immutable. This practice significantly reduces the chance that you create conflicted documents.\n\nConversely, if you're updating a specific document less than once every 10 seconds, an update-in-place data model - that is, updating existing documents - simplifies your application code considerably.\n\nTypically, data models based on immutable data require the use of views to summarize the documents that include the current state. As views are precomputed, this process most likely doesn't adversely affect application performance.\n\n\n\n\n\nBehind the https://$ACCOUNT.cloudant.com/ interface is a distributed database. Within the cluster, documents are bucketed into a number of shards that collectively form the database. These shards are then distributed across nodes in the cluster. This practice allows the support of databases many terabytes in size.\n\nBy default, the database is split into shards. Each shard has three copies, or shard replicas, which reside on a different node of the database cluster. Sharding allows the database to continue serving requests if a node fails, so saving a document involves writing to three nodes. If two updates are made concurrently to the same document, a subset of nodes might accept the first update, and another subset might accept the second update. When the cluster detects this discrepancy, it combines the documents in the same way as normal replication does for concurrent updates by creating a conflict.\n\n\n\n\n\nConflicted documents harm performance. A highly concurrent update-in-place pattern also increases the likelihood that writes get rejected. In that situation, the _rev parameter isn\u2019t the expected one, which forces your application to retry and delay processing.\n\nThis conflicted-document scenario is significantly more likely to happen for updates that occur more often than once a second. Use immutable documents for updates that occur more than once every 10 seconds to be on the safe side.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-451268-453610", "score": 13.793631, "text": "\nAs always, successful modeling involves achieving a balance between ease of use versus the performance characteristics you're hoping to achieve.\n\n(The FAQ for modeling data to scale is based on a blog article by Mike Rhodes, My top five tips for modeling your data to scale.)\n\n\n\nIf you're changing the same piece of state at a rate of once per second or more, consider making your documents immutable. This practice significantly reduces the chance that you create conflicted documents.\n\nConversely, if you're updating a specific document less than once every 10 seconds, an update-in-place data model - that is, updating existing documents - simplifies your application code considerably.\n\nTypically, data models based on immutable data require the use of views to summarize the documents that include the current state. As views are precomputed, this process most likely doesn't adversely affect application performance.\n\n\n\n\n\nBehind the https://$ACCOUNT.cloudant.com/ interface is a distributed database. Within the cluster, documents are bucketed into a number of shards that collectively form the database. These shards are then distributed across nodes in the cluster. This practice allows the support of databases many terabytes in size.\n\nBy default, the database is split into shards. Each shard has three copies, or shard replicas, which reside on a different node of the database cluster. Sharding allows the database to continue serving requests if a node fails, so saving a document involves writing to three nodes. If two updates are made concurrently to the same document, a subset of nodes might accept the first update, and another subset might accept the second update. When the cluster detects this discrepancy, it combines the documents in the same way as normal replication does for concurrent updates by creating a conflict.\n\n\n\n\n\nConflicted documents harm performance. A highly concurrent update-in-place pattern also increases the likelihood that writes get rejected. In that situation, the _rev parameter isn\u2019t the expected one, which forces your application to retry and delay processing.\n\nThis conflicted-document scenario is significantly more likely to happen for updates that occur more often than once a second. Use immutable documents for updates that occur more than once every 10 seconds to be on the safe side.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}]}
{"task_id": "2f013337236ea4635ad106813275dab7<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04866-6428-8391", "score": 13.799576, "text": "\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https://cloud.ibm.com/docs/cloud-object-storage/images/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-6428-8442", "score": 13.535319, "text": "\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https://cloud.ibm.com/docs/images/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_14708-3638-5837", "score": 9.417282, "text": "\nThe [Compliance assessment report (by Cohasset)](https://www.veeam.com/wp-compliance-assessment-report-cohasset.html) describes the settings that must be configured to become compliant with the following regulations:\n\n\n\n* FINRA Rule 4511.\n* SEC Rule 17a-4(f).\n* CFTC Rule 1 .31 (c)-(d).\n\n\n\nThe previous assessment report considers the following details as best practice for a Linux hardened repository:\n\n\n\n* The Linux hardened repository can be independent or Scale-out backup repository. A repository that retains immutable backup files for compliance with SEC 17a-4(f) must be configured as a stand-alone backup repository as a Veeam Scale-Out backup Repository is not compliant with this rule.\n* It is recommended that the name and description attributes for the repository include the word \u201cimmutable\" when the Linux hardened repository feature is enabled.\n* To protect against the possibility of premature deletion of backup files that can result from accelerating the system time clock, Linux OS must be configured to synchronize with a secure time source. For example, with a network time protocol (NTP) clock.\n* Ensure separation of duties by assigning management of Linux hardened repositories to a team other than backup administrators.\n* Veeam recommends XFS for performance and space efficiency reasons (block cloning support). Due to the requirement for periodic full backups, means that due to fast cloning, synthetic full backups take no physical disk space, except for metadata.\n* Only backup job configurations with forward incremental with synthetic or active full are supported. Forward incremental with synthetic full is the default backup job setting.\n* For backup copy jobs, GFS must be enabled.\n* Encryption of backup files is available as follows:\n\n\n\n* When configured in a backup job, Veeam Backup and Replication can use 256-bit AES block cypher encryption.\n* For data in transit, a global network traffic rule can be configured to enable all traffic to be encrypted through 256-bit AES encryption. When enable and two backup infrastructure components need to communicate, a dynamic key is generated by the backup server and communicated to each node over a secure channel.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-lhr"}, {"document_id": "ibmcld_04939-64122-65726", "score": 8.450724, "text": "\nSystem.out.printf(\"New retention period on %s is %sn\", objectName, additionalSeconds);\n}\n\n\n\n\n\n List legal holds on a protected object \n\nThis operation returns:\n\n\n\n* Object creation date\n* Object retention period in seconds\n* Calculated retention expiration date based on the period and creation date\n* List of legal holds\n* Legal hold identifier\n* Timestamp when legal hold was applied\n\n\n\nIf there are no legal holds on the object, an empty LegalHoldSet is returned. If there is no retention period specified on the object, a 404 error is returned.\n\npublic static void listLegalHoldsOnObject(String bucketName, String objectName) {\nSystem.out.printf(\"List all legal holds on object %s in bucket %sn\", objectName, bucketName);\n\nListLegalHoldsResult result = cos.listLegalHolds(\nbucketName,\nobjectName\n);\n\nSystem.out.printf(\"Legal holds on bucket %s: n\", bucketName);\n\nList<LegalHold> holds = result.getLegalHolds();\nfor (LegalHold hold : holds) {\nSystem.out.printf(\"Legal Hold: %s\", hold);\n}\n}\n\n\n\n\n\n Create a hosted static website \n\nThis operation requires an import statement to be added:\n\nimport com.ibm.cloud.objectstorage.services.s3.model.model.BucketWebsiteConfiguration;\n\nThis operation provides the following upon configuration and requires a correctly configured client:\n\n\n\n* Bucket configuration for suffix (index document)\n* Bucket configuration for key (error document)\n\n\n\ncosClient.setBucketWebsiteConfiguration(\"<bucket_name>\", new BucketWebsiteConfiguration(\"index.html\", \"error.html\"));\n\n\n\n\n\n\n\n Next Steps \n\nFor more information, [see the Javadoc](https://ibm.github.io/ibm-cos-sdk-java/).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/libraries?topic=cloud-object-storage-java"}, {"document_id": "ibmcld_05044-64102-65706", "score": 8.450724, "text": "\nSystem.out.printf(\"New retention period on %s is %sn\", objectName, additionalSeconds);\n}\n\n\n\n\n\n List legal holds on a protected object \n\nThis operation returns:\n\n\n\n* Object creation date\n* Object retention period in seconds\n* Calculated retention expiration date based on the period and creation date\n* List of legal holds\n* Legal hold identifier\n* Timestamp when legal hold was applied\n\n\n\nIf there are no legal holds on the object, an empty LegalHoldSet is returned. If there is no retention period specified on the object, a 404 error is returned.\n\npublic static void listLegalHoldsOnObject(String bucketName, String objectName) {\nSystem.out.printf(\"List all legal holds on object %s in bucket %sn\", objectName, bucketName);\n\nListLegalHoldsResult result = cos.listLegalHolds(\nbucketName,\nobjectName\n);\n\nSystem.out.printf(\"Legal holds on bucket %s: n\", bucketName);\n\nList<LegalHold> holds = result.getLegalHolds();\nfor (LegalHold hold : holds) {\nSystem.out.printf(\"Legal Hold: %s\", hold);\n}\n}\n\n\n\n\n\n Create a hosted static website \n\nThis operation requires an import statement to be added:\n\nimport com.ibm.cloud.objectstorage.services.s3.model.model.BucketWebsiteConfiguration;\n\nThis operation provides the following upon configuration and requires a correctly configured client:\n\n\n\n* Bucket configuration for suffix (index document)\n* Bucket configuration for key (error document)\n\n\n\ncosClient.setBucketWebsiteConfiguration(\"<bucket_name>\", new BucketWebsiteConfiguration(\"index.html\", \"error.html\"));\n\n\n\n\n\n\n\n Next Steps \n\nFor more information, [see the Javadoc](https://ibm.github.io/ibm-cos-sdk-java/).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-java"}, {"document_id": "ibmcld_05070-27030-28536", "score": 8.108665, "text": "\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\n\n\n\n\n\n List legal holds on a protected object \n\nThis operation returns:\n\n\n\n* Object creation date\n* Object retention period in seconds\n* Calculated retention expiration date based on the period and creation date\n* List of legal holds\n* Legal hold identifier\n* Timestamp when legal hold was applied\n\n\n\nIf there are no legal holds on the object, an empty LegalHoldSet is returned. If there is no retention period specified on the object, a 404 error is returned.\n\nfunction listLegalHoldsOnObject(bucketName, objectName) {\nconsole.log(List all legal holds on object ${objectName} in bucket ${bucketName});\nreturn cos.listLegalHolds({\nBucket: bucketName,\nKey: objectId\n}).promise()\n.then((data) => {\nconsole.log(Legal holds on bucket ${bucketName}: ${data});\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\n\n\n\n\n\n Create a hosted static website \n\nThis operation requires permissions, as only the bucket owner is typically permitted to configure a bucket to host a static website. The parameters determine the default suffix for visitors to the site as well as an optional error document.\n\nvar websiteParams = {\nBucket: \"bucketName\",\nWebsiteConfiguration: {\nErrorDocument: {\nKey: \"error.html\"\n},\nIndexDocument: {\nSuffix: \"index.html\"\n}\n}\n};\nfunction putBucketWebsiteConfiguration(websiteParams) {\nreturn cos.putBucketWebsite({websiteParams}).promise()\n.then((data) => {\nconsole.log(Website configured for ${bucketName});", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-node"}, {"document_id": "ibmcld_04866-4961-6763", "score": 7.631941, "text": "\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https://www.ecfr.gov/cgi-bin/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https://www.finra.org/rules-guidance/rulebooks/finra-rules/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-4961-6763", "score": 7.631941, "text": "\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https://www.ecfr.gov/cgi-bin/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https://www.finra.org/rules-guidance/rulebooks/finra-rules/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_04866-24915-26158", "score": 7.252688, "text": "\ndef add_legal_hold_to_object(bucket_name, object_name, legal_hold_id):\nprint(\"Adding legal hold {0} to object {1} in bucket {2}n\".format(legal_hold_id, object_name, bucket_name))\n\ncos.add_legal_hold(\nBucket=bucket_name,\nKey=object_name,\nRetentionLegalHoldId=legal_hold_id\n)\n\nprint(\"Legal hold {0} added to object {1} in bucket {2}!n\".format(legal_hold_id, object_name, bucket_name))\n\ndef delete_legal_hold_from_object(bucket_name, object_name, legal_hold_id):\nprint(\"Deleting legal hold {0} from object {1} in bucket {2}n\".format(legal_hold_id, object_name, bucket_name))\n\ncos.delete_legal_hold(\nBucket=bucket_name,\nKey=object_name,\nRetentionLegalHoldId=legal_hold_id\n)\n\nprint(\"Legal hold {0} deleted from object {1} in bucket {2}!n\".format(legal_hold_id, object_name, bucket_name))\n\nfunction addLegalHoldToObject(bucketName, objectName, legalHoldId) {\nconsole.log(Adding legal hold ${legalHoldId} to object ${objectName} in bucket ${bucketName});\nreturn cos.client.addLegalHold({\nBucket: bucketName,\nKey: objectId,\nRetentionLegalHoldId: legalHoldId\n}).promise()\n.then(() => {\nconsole.log(Legal hold ${legalHoldId} added to object ${objectName} in bucket ${bucketName}!);\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-24894-26137", "score": 7.252688, "text": "\ndef add_legal_hold_to_object(bucket_name, object_name, legal_hold_id):\nprint(\"Adding legal hold {0} to object {1} in bucket {2}n\".format(legal_hold_id, object_name, bucket_name))\n\ncos.add_legal_hold(\nBucket=bucket_name,\nKey=object_name,\nRetentionLegalHoldId=legal_hold_id\n)\n\nprint(\"Legal hold {0} added to object {1} in bucket {2}!n\".format(legal_hold_id, object_name, bucket_name))\n\ndef delete_legal_hold_from_object(bucket_name, object_name, legal_hold_id):\nprint(\"Deleting legal hold {0} from object {1} in bucket {2}n\".format(legal_hold_id, object_name, bucket_name))\n\ncos.delete_legal_hold(\nBucket=bucket_name,\nKey=object_name,\nRetentionLegalHoldId=legal_hold_id\n)\n\nprint(\"Legal hold {0} deleted from object {1} in bucket {2}!n\".format(legal_hold_id, object_name, bucket_name))\n\nfunction addLegalHoldToObject(bucketName, objectName, legalHoldId) {\nconsole.log(Adding legal hold ${legalHoldId} to object ${objectName} in bucket ${bucketName});\nreturn cos.client.addLegalHold({\nBucket: bucketName,\nKey: objectId,\nRetentionLegalHoldId: legalHoldId\n}).promise()\n.then(() => {\nconsole.log(Legal hold ${legalHoldId} added to object ${objectName} in bucket ${bucketName}!);\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}]}
{"task_id": "2f013337236ea4635ad106813275dab7<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04866-1541-3629", "score": 23.200277, "text": "\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https://cloud.ibm.com/docs/services/cloud-object-storage/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-1541-3629", "score": 23.200277, "text": "\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https://cloud.ibm.com/docs/services/cloud-object-storage/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-3142-5463", "score": 21.914736, "text": "\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention \n\nAllows the user to set the object to be stored indefinitely until a new retention period is applied. This is set at a per object level.\n\n\n\n\n\n Event-based retention \n\nImmutable Object Storage allows users to set indefinite retention on the object if they are unsure of the final duration of the retention period, or want to use event-based retention. Once set to indefinite, user applications can then can change the object retention to a finite value later. For example, a company has a policy of retaining employee records for three years after the employee leaves the company. When an employee joins the company, the records that are associated with that employee can be indefinitely retained. When the employee leaves the company, the indefinite retention is converted to a finite value of three years from the current time, as defined by company policy. The object is then protected for three years after the retention period change. A user or third-party application can change the retention period from indefinite to finite retention that uses an SDK or REST API.\n\n\n\n\n\n Permanent retention \n\nPermanent retention ensures that data can not be deleted, ever, by anyone. Read the documentation carefully and do not use permanent retention unless there is a compelling regulatory or compliance need for permanent data storage.\n\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_04866-3142-5463", "score": 21.914736, "text": "\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention \n\nAllows the user to set the object to be stored indefinitely until a new retention period is applied. This is set at a per object level.\n\n\n\n\n\n Event-based retention \n\nImmutable Object Storage allows users to set indefinite retention on the object if they are unsure of the final duration of the retention period, or want to use event-based retention. Once set to indefinite, user applications can then can change the object retention to a finite value later. For example, a company has a policy of retaining employee records for three years after the employee leaves the company. When an employee joins the company, the records that are associated with that employee can be indefinitely retained. When the employee leaves the company, the indefinite retention is converted to a finite value of three years from the current time, as defined by company policy. The object is then protected for three years after the retention period change. A user or third-party application can change the retention period from indefinite to finite retention that uses an SDK or REST API.\n\n\n\n\n\n Permanent retention \n\nPermanent retention ensures that data can not be deleted, ever, by anyone. Read the documentation carefully and do not use permanent retention unless there is a compelling regulatory or compliance need for permanent data storage.\n\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_04866-7-2136", "score": 20.460327, "text": "\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-7-2136", "score": 20.460327, "text": "\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05075-5285-7227", "score": 20.352766, "text": "\n* You will need to pick a region where Object Lock is supported, refer to [Integrated Services](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-service-availability) for details.\n* A maximum default retention period of 100 years (or 36500 days) is supported.\n* When using the console, it is also possible to set a Retain Until Date in months, in addition to days or years.\n\n\n\nThe retention period for an object cannot be decreased. If you are using default retention for validation testing please use a lower duration (such as 1 day) as the default retention, increasing it to your desired setting as needed.\n\n\n\n Creating and setting up your new bucket for use with Object Lock \n\n\n\n1. Navigate to your desired Object Storage instance and use Create Bucket with Customize your bucket option\n2. Enter the required bucket configuration details as per your use case requirements\n3. Navigate to the Object Versioning section and set it to Enabled\n4. Look for Immutability, and under Object Lock click Add\n5. Set Object Lock to Enabled\n6. Optionally, set a default retention period.\n7. Click on Save\n8. Proceed with rest of the configuration settings and click Create bucket\n\n\n\n\n\n\n\n Enabling Object Lock on an existing bucket: \n\nA bucket can be set for Object Lock use as follows:\n\n\n\n1. Navigate to your bucket Configuration section\n2. Click on Object Versioning\n3. At the Object Versioning section click on Edit, set the configuration option to Enabled and Save\n4. Navigate to Object Lock section, click on Add\n5. Set Object Lock to Enabled\n6. Optionally, set a default retention period.\n7. Click on Save\n\n\n\n\n\n\n\n Adding a Retain Until Date or Legal Hold to an object \n\n\n\n1. Navigate to the bucket with the target object\n2. Toggle Display Versions\n3. Go to the details of the target version\n4. Add a retention period and/or toggle on a legal hold.\n\n\n\n\n\n\n\n\n\n Using Object Lock for business continuity and disaster recovery", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-ol-overview"}, {"document_id": "ibmcld_04866-4961-6763", "score": 20.345163, "text": "\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https://www.ecfr.gov/cgi-bin/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https://www.finra.org/rules-guidance/rulebooks/finra-rules/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-4961-6763", "score": 20.345163, "text": "\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https://www.ecfr.gov/cgi-bin/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https://www.finra.org/rules-guidance/rulebooks/finra-rules/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_07990-1593-3803", "score": 20.233652, "text": "\nThe storage should be configured as \u201cimmutable object storage.\u201d Retention policies are should be applied to the storage, so that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. The policy is set and enforced for a 12-month (minimum) retention period.\n\n\n\n* Authenticating users with MFA using a physical hardware-based security key that generates a six-digit numerical code. A smart card or hardware token designed and operated to FIPS 140-2 level 2 or above or equivalent (e.g., ANSI X9.24, ISO 13491-1:2007) is recommended.\n* Locking user accounts after three (3) consecutive failed logon attempts within 15 minutes.\n* Locking user accounts for 30 minutes when there have been more than three unsuccessful logon attempts. After the lockout period ends, the user will be able to reset their password. Internal privileged accounts must remain locked until released by an administrator.\n* Session timeout after 15 minutes of inactivity.\n* Providing a system use notification banner from either the bastion or the target system. The warning banner is displayed before the system grants access to the user and the usage conditions must be approved before proceeding. The banner will provide privacy and security notices consistent with applicable customer policies, regulations, standards, and guidance. The warning banner will state that:\n\n\n\n* Users are accessing a financial services information system.\n* Information system usage may be monitored, recorded, and subject to audit.\n* Unauthorized use of the information system is prohibited and subject to criminal and civil penalties.\n* Use of the information system indicates consent to monitoring and recording.\n\n\n\n\n\n\n\n Set up a bastion host \n\nYou need to install and manage your own bastion solution within your management VPC. There are various ways a bastion solution can be implemented. For one example that uses Teleport Enterprise Edition, see [Setting up a bastion host for secure connectivity](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-vpc-architecture-connectivity-bastion-tutorial-teleport).\n\n\n\n\n\n Related controls in IBM Cloud Framework for Financial Services", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-vpc-architecture-connectivity-bastion"}]}
{"task_id": "2f013337236ea4635ad106813275dab7<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04866-1541-3629", "score": 27.290436, "text": "\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https://cloud.ibm.com/docs/services/cloud-object-storage/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-1541-3629", "score": 27.290436, "text": "\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https://cloud.ibm.com/docs/services/cloud-object-storage/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05075-5285-7227", "score": 25.096651, "text": "\n* You will need to pick a region where Object Lock is supported, refer to [Integrated Services](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-service-availability) for details.\n* A maximum default retention period of 100 years (or 36500 days) is supported.\n* When using the console, it is also possible to set a Retain Until Date in months, in addition to days or years.\n\n\n\nThe retention period for an object cannot be decreased. If you are using default retention for validation testing please use a lower duration (such as 1 day) as the default retention, increasing it to your desired setting as needed.\n\n\n\n Creating and setting up your new bucket for use with Object Lock \n\n\n\n1. Navigate to your desired Object Storage instance and use Create Bucket with Customize your bucket option\n2. Enter the required bucket configuration details as per your use case requirements\n3. Navigate to the Object Versioning section and set it to Enabled\n4. Look for Immutability, and under Object Lock click Add\n5. Set Object Lock to Enabled\n6. Optionally, set a default retention period.\n7. Click on Save\n8. Proceed with rest of the configuration settings and click Create bucket\n\n\n\n\n\n\n\n Enabling Object Lock on an existing bucket: \n\nA bucket can be set for Object Lock use as follows:\n\n\n\n1. Navigate to your bucket Configuration section\n2. Click on Object Versioning\n3. At the Object Versioning section click on Edit, set the configuration option to Enabled and Save\n4. Navigate to Object Lock section, click on Add\n5. Set Object Lock to Enabled\n6. Optionally, set a default retention period.\n7. Click on Save\n\n\n\n\n\n\n\n Adding a Retain Until Date or Legal Hold to an object \n\n\n\n1. Navigate to the bucket with the target object\n2. Toggle Display Versions\n3. Go to the details of the target version\n4. Add a retention period and/or toggle on a legal hold.\n\n\n\n\n\n\n\n\n\n Using Object Lock for business continuity and disaster recovery", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-ol-overview"}, {"document_id": "ibmcld_05032-3142-5463", "score": 24.59963, "text": "\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention \n\nAllows the user to set the object to be stored indefinitely until a new retention period is applied. This is set at a per object level.\n\n\n\n\n\n Event-based retention \n\nImmutable Object Storage allows users to set indefinite retention on the object if they are unsure of the final duration of the retention period, or want to use event-based retention. Once set to indefinite, user applications can then can change the object retention to a finite value later. For example, a company has a policy of retaining employee records for three years after the employee leaves the company. When an employee joins the company, the records that are associated with that employee can be indefinitely retained. When the employee leaves the company, the indefinite retention is converted to a finite value of three years from the current time, as defined by company policy. The object is then protected for three years after the retention period change. A user or third-party application can change the retention period from indefinite to finite retention that uses an SDK or REST API.\n\n\n\n\n\n Permanent retention \n\nPermanent retention ensures that data can not be deleted, ever, by anyone. Read the documentation carefully and do not use permanent retention unless there is a compelling regulatory or compliance need for permanent data storage.\n\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_04866-3142-5463", "score": 24.59963, "text": "\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention \n\nAllows the user to set the object to be stored indefinitely until a new retention period is applied. This is set at a per object level.\n\n\n\n\n\n Event-based retention \n\nImmutable Object Storage allows users to set indefinite retention on the object if they are unsure of the final duration of the retention period, or want to use event-based retention. Once set to indefinite, user applications can then can change the object retention to a finite value later. For example, a company has a policy of retaining employee records for three years after the employee leaves the company. When an employee joins the company, the records that are associated with that employee can be indefinitely retained. When the employee leaves the company, the indefinite retention is converted to a finite value of three years from the current time, as defined by company policy. The object is then protected for three years after the retention period change. A user or third-party application can change the retention period from indefinite to finite retention that uses an SDK or REST API.\n\n\n\n\n\n Permanent retention \n\nPermanent retention ensures that data can not be deleted, ever, by anyone. Read the documentation carefully and do not use permanent retention unless there is a compelling regulatory or compliance need for permanent data storage.\n\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-7904-10153", "score": 24.48009, "text": "\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time. A Content-MD5 header is required to ensure data integrity, and is automatically sent when using an SDK.\n\n\n\n Add a retention policy on an existing bucket \n\nThis implementation of the PUT operation uses the protection query parameter to set the retention parameters for an existing bucket. This operation allows you to set or change the minimum, default, and maximum retention period. This operation also allows you to change the protection state of the bucket.\n\nObjects written to a protected bucket cannot be deleted until the protection period has expired and all legal holds on the object are removed. The bucket's default retention value is given to an object unless an object-specific value is provided when the object is created. Objects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\nA Content-MD5 header is required. This operation does not make use of extra query parameters.\n\nFor more information about endpoints, see [Endpoints and storage locations](https://cloud.ibm.com/docs/services/cloud-object-storage?topic=cloud-object-storage-endpointsendpoints)\n\nSyntax\n\nPUT https://{endpoint}/{bucket-name}?protection= path style\nPUT https://{bucket-name}.{endpoint}?protection= virtual host style\n\nExample request", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_04866-7925-10174", "score": 24.48009, "text": "\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time. A Content-MD5 header is required to ensure data integrity, and is automatically sent when using an SDK.\n\n\n\n Add a retention policy on an existing bucket \n\nThis implementation of the PUT operation uses the protection query parameter to set the retention parameters for an existing bucket. This operation allows you to set or change the minimum, default, and maximum retention period. This operation also allows you to change the protection state of the bucket.\n\nObjects written to a protected bucket cannot be deleted until the protection period has expired and all legal holds on the object are removed. The bucket's default retention value is given to an object unless an object-specific value is provided when the object is created. Objects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\nA Content-MD5 header is required. This operation does not make use of extra query parameters.\n\nFor more information about endpoints, see [Endpoints and storage locations](https://cloud.ibm.com/docs/services/cloud-object-storage?topic=cloud-object-storage-endpointsendpoints)\n\nSyntax\n\nPUT https://{endpoint}/{bucket-name}?protection= path style\nPUT https://{bucket-name}.{endpoint}?protection= virtual host style\n\nExample request", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_04831-50613-52356", "score": 22.540688, "text": "\nX-Clv-Request-Id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\nServer: Cleversafe/3.14.9.53\nX-Clv-S3-Version: 2.5\nx-amz-request-id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\n\nThe server responds with 204 No Content.\n\n\n\n\n\n Add a retention policy on an existing bucket \n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. The service also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nFind out more about Immutable Object Storage in the [documentation](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable).\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\nThis operation does not make use of extra query parameters. The required Content-MD5 header needs to be the binary representation of a base64-encoded MD5 hash. The following snippet shows one way to achieve the content for that particular header.\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nNot all operations are supported in Satellite environments.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/api-reference?topic=cloud-object-storage-compatibility-api-bucket-operations"}, {"document_id": "ibmcld_04991-50585-52328", "score": 22.540688, "text": "\nX-Clv-Request-Id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\nServer: Cleversafe/3.14.9.53\nX-Clv-S3-Version: 2.5\nx-amz-request-id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\n\nThe server responds with 204 No Content.\n\n\n\n\n\n Add a retention policy on an existing bucket \n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. The service also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nFind out more about Immutable Object Storage in the [documentation](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable).\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\nThis operation does not make use of extra query parameters. The required Content-MD5 header needs to be the binary representation of a base64-encoded MD5 hash. The following snippet shows one way to achieve the content for that particular header.\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nNot all operations are supported in Satellite environments.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-compatibility-api-bucket-operations"}, {"document_id": "ibmcld_05075-3718-5743", "score": 21.815172, "text": "\nHowever, legal holds are more flexible and don't have a defined temporal component. Instead they simply remain in effect until removed. Legal holds can be freely placed and removed by any user who has the cloud-object-storage.object.put_object_lock_legal_hold and cloud-object-storage.object.put_object_lock_legal_hold_version actions.\n\nLegal holds have the additional benefit of acting as method for applying indefinite retention on an object.\n\nLegal holds and retention periods operate independently. Legal holds have no impact on retention periods, and vice-versa.\n\nImagine an object with both a legal hold and a retention period. When the retention period ends, the object version remains protected until the legal hold is removed. If you remove a legal hold while an object version is subject to a retention period it remains protected until the retention period is complete.\n\nObjects locked and stored with a retention period cannot be deleted until retention period expires and any associated legal hold is removed.\n\nLocking objects with a Governance Mode is not supported.\n\n\n\n\n\n\n\n Getting started with Object Lock \n\nIn order to get started, there are some some prerequisites:\n\n\n\n* You'll need the Writer or Manager platform role on a bucket, or a custom role with the appropriate actions (such as cloud-object-storage.bucket.put_object_lock_configuration) assigned.\n* Object Versioning must be enabled\n* You will need to use Standard pricing plan, see [pricing](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-billing) for details.\n* You will need to pick a region where Object Lock is supported, refer to [Integrated Services](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-service-availability) for details.\n* A maximum default retention period of 100 years (or 36500 days) is supported.\n* When using the console, it is also possible to set a Retain Until Date in months, in addition to days or years.\n\n\n\nThe retention period for an object cannot be decreased.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-ol-overview"}]}
{"task_id": "2f013337236ea4635ad106813275dab7<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_08007-5991-8147", "score": 20.449232, "text": "\n[Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-about-cloud-object-storage) is an alternative storage option that is useful for certain use cases, including backup and recovery, data archiving, cloud-native application building, and AI and big data analytics. Object Storage stores encrypted and dispersed data across multiple geographic locations.\n\nBy default, all objects that are stored in Object Storage are encrypted by using randomly generated keys and an all-or-nothing-transform (AONT). While this default encryption model provides at-rest security, financial service workloads need full control over the data encryption keys used. Again, Hyper Protect Crypto Services should be used for this purpose.\n\n\n\n\n\n\n\n Using IBM Cloud services outside of a VPC \n\nTo connect to IBM Cloud services from your VPC, you need to use [Virtual Private Endpoints (VPE) for VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-about-vpe). In the reference architecture diagram, VPEs appear in the middle subnets of the workload VPC. With VPEs, you can connect to supported IBM Cloud services from your VPC network by using the IP addresses of your choosing, which is allocated from a subnet within your VPC.\n\nVPE is an evolution of the private connectivity to IBM Cloud services. VPEs are virtual IP interfaces that are bound to an endpoint gateway created on a per service, or service instance, basis (depending on the service operation model). The endpoint gateway is a virtualized function that scales horizontally, is redundant and highly available, and spans all availability zones of your VPC. Endpoint gateways enable communications from virtual server instances within your VPC and IBM Cloud service on the private backbone. VPE for VPC gives you the experience of controlling all the private addressing within your cloud.\n\n\n\n\n\n\n\n Variation with edge/transit VPC for public internet access \n\nYou might want to allow consumers to access your service through the public internet. This base architecture can be adapted to securely enable this type of access as shown in the following diagram, which introduces a new edge VPC.", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-vpc-architecture-detailed-vsi"}, {"document_id": "ibmcld_16729-316391-318406", "score": 19.510717, "text": "\nIBM Secure Content Store powered by IBM Cloud\u00ae Object Storage provides unparalleled agility in supporting fast, highly consistent application deployment around the world to help customers securely expand their business into new regions, from business-critical data to video archive solutions. It also offers immutable storage, immutable backup, and archive data with industry-leading security and controls for regulatory/compliance requirements.\n\nObject Storage\n\n\n\n* 15 minutes\n* 2023-06-29\n\n\n\n[Limiting access to a single Object Storage bucket](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-limit-access)Limiting access to a single Object Storage bucket\n\nIBM Cloud IAM resource groups and access groups allow administrators to restrict users access to various service instances, but what if a user needs to only access a limited number of buckets within a service instance? This can be accomplished using a custom role and a narrowly tailored IAM policy.\n\nObject Storage\n\n\n\n* 15 minutes\n* 2022-10-10\n\n\n\n[Encrypting a bucket with Key Protect ](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-tutorial-kp-encrypt-bucket)Encrypting a bucket with Key Protect\n\nWhile all data stored in Cloud Object Storage is automatically encrypted using randomly generated keys, some workloads require that the keys can be rotated, deleted, or otherwise controlled by a key management system (KMS) like Key Protect.\n\nObject Storage\n\n\n\n* 10 minutes\n* 2022-04-07\n\n\n\n[Building a Static Website](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-static-website-tutorial)Building a Static Website\n\nThis tutorial shows how to host a static website on IBM Cloud\u00ae Object Storage, including creating a bucket, uploading content, and configuring your new website.\n\nObject Storage\n\n\n\n* 15 minutes\n* 2020-11-07\n\n\n\n[Developing a web application](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-web-application)Developing a web application", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}, {"document_id": "ibmcld_05138-7-2415", "score": 18.950628, "text": "\nCreate a Secure Content Store \n\nAre you looking to store content securely (locally or globally) at an affordable cost, for things like cloud native apps, media storage, backup storage and archive data? IBM Secure Content Store powered by IBM Cloud\u00ae Object Storage provides unparalleled agility in supporting fast, highly consistent application deployment around the world to help customers securely expand their business into new regions, from business-critical data to video archive solutions. It also offers immutable storage, immutable backup, and archive data with industry-leading security and controls for regulatory/compliance requirements.\n\n\n\n* Gain security and control over your data with encryption options, governance policies, access permissions, and context-based restrictions.\n* Have immediate consistency across regions or locations for cloud-native apps, disaster recovery, storage backup, video content and delivery. etc.\n* Leverage your own encryption keys (BYOK) with Key Protect.\n* Monitor and retain your account & data activity with Activity Tracker and IBM Monitoring.\n* APIs & SDKs, Static Web Hosting, High Speed Transfer, Tagging, Replication.\n\n\n\n\n\n Promotion for new customers! \n\nIBM Cloud is offering a $500 promotional credit to quickly get started with our Secure Content Store with Object Storage. The credit has a duration of 90 days against your metered consumption of Object Storage. See instructions below for how to apply your promo code. To qualify for this offer you must be a new paid user of Object Storage. There is a limit of one promotion code per customer account. The USD 500 credit is for use with this offer only and cannot to be applied to other offers. Offer is subject to availability.\n\n\n\n\n\n Overview \n\nThis tutorial is for customers looking to set up a Secure Content Store using Object Storage, Activity Tracker, and Key Protect. In this tutorial, you are guided through the process of quickly getting started with these essential services to ensure the security and integrity of your content. Secure Content Store is comprised of the following services:\n\n\n\n* Object Storage: a scalable and flexible storage solution that allows you to store and manage your data securely.\n* Activity Tracker: a powerful tool that provides comprehensive visibility into the activities happening within your IBM Cloud environment and allows for ease of audit observability.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-secure-content-store"}, {"document_id": "ibmcld_06932-7-2330", "score": 18.443111, "text": "\nUsing IBM Cloud Direct Link to connect to IBM Cloud Object Storage \n\nYou can configure IBM Cloud\u00ae Direct Link so that you have access to IBM Cloud Object Storage (COS). Although the methods described here were designed and tested with COS, they can work for certain other IBM Cloud services.\n\nBy policy, IBM Cloud Direct Link denies access to IBM Cloud private service endpoints, including those endpoints used by COS. The technique that is described in this document relies on indirect access to COS through servers hosted in a customer's IBM Cloud account. After setup, each customer's server can forward traffic bidirectionally between IBM Cloud private service endpoints and their remote networks that are connected by Direct Link.\n\n\n\n What is IBM Cloud Object Storage? \n\nIBM Cloud Object Storage (COS) is a web-scale solution that stores unstructured data. It provides reliability, security, availability, and disaster recovery without manual replication.\n\nThe information that is stored within IBM Cloud Object Storage is encrypted and dispersed across many geographic locations. It's accessible through an implementation of the S3 API. This service uses distributed storage technologies that are provided by the IBM Cloud Object Storage service.\n\nIBM COS is available in three configurations:\n\n\n\n* Cross Region service provides higher durability and availability than using a single region, but at the cost of slightly higher latency. This service is available today in the US and the EU. By using a Virtual Router Appliance (VRA), you also might use Direct Link to connect to COS in the Asia Pacific region.\n* Regional service provides the reverse. It distributes objects across many availability zones within a single region. If a region or availability zone is inaccessible, the object store continues to function smoothly. Any missed changes are applied when the inaccessible data center comes back online.\n* Single Site service offers affordable access to COS in a selected data center.\n\n\n\n\n\n COS private and public endpoints \n\nEndpoints are URLs that applications use to issue COS commands and exchange data with COS. Every endpoint uses the same application programming interface (API) to interact with COS.\n\nServers that are provisioned within IBM Cloud use private API endpoints for services, including COS.", "title": "", "source": "https://cloud.ibm.com/docs/direct-link?topic=direct-link-using-ibm-cloud-direct-link-to-connect-to-ibm-cloud-object-storage"}, {"document_id": "ibmcld_08016-1485-3419", "score": 18.43553, "text": "\n[Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-about-cloud-object-storage) stores encrypted and dispersed data across multiple geographic locations. Object Storage is available with three types of resiliency: Cross Region, Regional, and Single Data Center. Cross Region provides higher durability and availability than using a single region at the cost of slightly higher latency. Regional service reverses those tradeoffs, and distributes objects across multiple availability zones within a single region. If a given region or availability zone is unavailable, the object store continues to function without impediment. Single Data Center distributes objects across multiple machines within the same physical location.\n\nUsers of Object Storage refer to their binary data, such as files, images, media, archives, or even entire databases as objects. Objects are stored in a bucket, the container for their unstructured data. Buckets contain both inherent and user-defined metadata. Finally, objects are defined by a globally unique combination of the bucket name and the object key, or name.\n\nAll Object Storage buckets must be encrypted with KYOK by using keys that are managed by Hyper Protect Crypto Services. For more information, see [Encryption at rest](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-shared-encryption-at-rest). In addition, a geographically separate region should be used as an [alternative storage site](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-shared-bcdryour-workloads-requirements-alternate-storage-site). This means you should use [cross region resiliency](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-endpointsendpoints-geo) for all of your Object Storage buckets.\n\nTo start working with Object Storage, see the following instructions:", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-vpc-architecture-storage"}, {"document_id": "ibmcld_04954-7-1868", "score": 18.329496, "text": "\nArchiving and accessing cold data \n\nIBM Cloud\u00ae Object Storage \"Archive\" and \"Accelerated Archive\" are [low cost](https://www.ibm.com/cloud/object-storage) options for data that is rarely accessed. You can store data by transitioning from any of the storage tiers (Standard, Vault, Cold Vault and Flex) to long-term offline archive or use the online Cold Vault option. With the new \"Accelerated Archive\" feature you can quickly access dormant data with restoration occurring in less than two hours.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nYou can archive objects using the web console, REST API, and 3rd party tools that are integrated with IBM Cloud Object Storage.\n\nFor more information about endpoints, see [Endpoints and storage locations](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-endpointsendpoints)\n\n\n\n Add or manage an archive policy on a bucket \n\nWhen creating or modifying an archive policy for a bucket, consider the following:\n\n\n\n* An archive policy can be added to a new or existing bucket at any time.\n* An existing archive policy can be modified or disabled.\n* A newly added or modified archive policy applies to new objects uploaded and does not affect existing objects.\n\n\n\nCreate a bucket in the console after you've logged in, and you can configure your archive policy using the fields shown in Figure 1.\n\nZoom\n\n![Create an archive policy](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/bucket-create-ui-archive-rule.png)\n\nFigure 1. Create an archive policy\n\nTo immediately archive new objects uploaded to a bucket, enter 0 days on the archive policy.\n\nArchive is available in certain regions only.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-archive"}, {"document_id": "ibmcld_04869-7924-8861", "score": 18.036873, "text": "\nYou can manage your keys manually by supplying your own encryption keys - referred to as Server-Side Encryption with Customer-Provided Keys (SSE-C).\n\n\n\n\n\n Archive rules \n\nIBM Cloud\u00ae Object Storage Archive is a low-cost option for data that is rarely accessed. You can migrate data from any of the storage tiers (Standard, Vault, Cold Vault, and Flex) to a long-term offline archive.\n\n\n\n\n\n Retention policies \n\nImmutable Object Storage maintains data integrity in a WORM (Write-Once-Read-Many) manner. Objects can't be modified until the end of their retention period and the removal of any legal holds.\n\n\n\n\n\n Aspera high-speed transfer \n\nAspera high-speed transfer improves data transfer performance under most conditions, especially in networks with high latency or packet loss. Instead of the standard HTTP PUT, Aspera high-speed transfer uploads the object by using the [FASP protocol](https://www.ibm.com/products/aspera/technology).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-sdk-about"}, {"document_id": "ibmcld_05126-7854-8791", "score": 18.036873, "text": "\nYou can manage your keys manually by supplying your own encryption keys - referred to as Server-Side Encryption with Customer-Provided Keys (SSE-C).\n\n\n\n\n\n Archive rules \n\nIBM Cloud\u00ae Object Storage Archive is a low-cost option for data that is rarely accessed. You can migrate data from any of the storage tiers (Standard, Vault, Cold Vault, and Flex) to a long-term offline archive.\n\n\n\n\n\n Retention policies \n\nImmutable Object Storage maintains data integrity in a WORM (Write-Once-Read-Many) manner. Objects can't be modified until the end of their retention period and the removal of any legal holds.\n\n\n\n\n\n Aspera high-speed transfer \n\nAspera high-speed transfer improves data transfer performance under most conditions, especially in networks with high latency or packet loss. Instead of the standard HTTP PUT, Aspera high-speed transfer uploads the object by using the [FASP protocol](https://www.ibm.com/products/aspera/technology).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-sdk-about"}, {"document_id": "ibmcld_13064-7-2233", "score": 17.942472, "text": "\nWhat is IBM Cloud Object Storage? \n\nIBM Cloud\u00ae Object Storage is a highly available, durable, and secure platform for storing unstructured data. Unstructured data (sometimes called binary or \"blob\" data) refers to data that is not highly structured in the manner of a database. Object storage is the most efficient way to store PDFs, media files, database backups, disk images, or even large structured datasets.\n\nThe files that are uploaded into IBM Cloud Object Storage are called objects. Objects can be anywhere from very small (a few bytes) [to very large] (up to 10TB). They are organized into buckets that serve as containers for objects, and which can be configured independently from one another in terms of locations, resiliency, billing rates, security, and object lifecycle. Objects themselves have their own metadata in the form of user-defined tags, legal holds, or archive status. Within a bucket, the hierarchy of objects is effectively \"flat\", although it is possible to add prefixes to object names to provide some organization and to provide flexibility in listing and other operations.\n\nIBM Cloud Object Storage is strongly consistent for all data operations, and eventually consistent for bucket configuration operations. This means that when an object is uploaded, the server responds with a 200 OK after the object is successfully written, and the object is immediately available for listing and reading. All data stored in IBM Cloud Object Storage is encrypted, erasure-coded, and dispersed across three locations (with the distance between locations ranging from within a single data center, across a Multi-Zone Region or MZR, or even across multiple MZRs). This geographic range of dispersal contributes to a bucket's resiliency.\n\nAll requests and responses are made over HTTPS and all requests support the use of hash-based integrity checks using a Content-MD5 header. If the provided MD5 hash does not match the checksum computed by the storage service, the object is discarded and an error is returned. All GET and HEAD requests made to objects return an Etag value with the MD5 hash of the object to ensure integrity on the client side.\n\nDevelopers use APIs to interact with their object storage.", "title": "", "source": "https://cloud.ibm.com/docs/services/cloud-object-storage?topic=cloud-object-storage-about-cloud-object-storage"}, {"document_id": "ibmcld_10885-21825-23148", "score": 17.912167, "text": "\nDatabases are deployed on a virtual server. Backup is enabled and replication is set up between regions. The alternative would be to use a database-as-service, a topic discussed later in the tutorial.\n5. IBM Cloud File Storage for Classic to store the application images and files, File Storage for Classic offers the capability to take a snapshot at a given time and date, this snapshot then can be reused within another region, something that you would do manually.\n\n\n\nThe tutorial [Use Virtual Servers to build highly available and scalable web app](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-highly-available-and-scalable-web-applicationhighly-available-and-scalable-web-application) implements this architecture.\n\n\n\n\n\n Back up and restore procedures \n\nRefer to the following backup and restore procedures:\n\n\n\n* [Managing backups for Databases for Elasticsearch](https://cloud.ibm.com/docs/services/databases-for-elasticsearch?topic=cloud-databases-dashboard-backups)\n* [Managing backups for Databases for PostgreSQL](https://cloud.ibm.com/docs/services/databases-for-postgresql?topic=cloud-databases-dashboard-backups)\n* [Backups and restoration for Databases for Redis](https://cloud.ibm.com/docs/services/databases-for-redis?topic=cloud-databases-dashboard-backupsbackups-and-restoration)", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-bcdr-app-recovery"}]}
{"task_id": "2f013337236ea4635ad106813275dab7<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10165-1884-4204", "score": 15.879123, "text": "\nCloud-based storage in IBM Cloudant ensures higher availability than when it was locked in an on-premises system. Since availability is essential, the apps are deployed across global data centers: for DR and for latency too.\n\nThey also accelerated their risk analysis and compliance. Their predictive and risk analytics functions, such as Monte Carlo calculations, are now constantly updated through iterative agile deployments. Container orchestration is handled by a managed Kubernetes so that operations costs are reduced too. Ultimately risk analysis for mortgages is more responsive to the fast-paced changes in the market.\n\n\n\n* Heightened need for better financial risk management drives increases in regulatory oversight. The same needs drive the associated review in risk assessment processes and disclosure of more granular, integrated, and abundant regulatory reporting.\n* High Performance Computing Grids are the key infrastructure components for financial modeling.\n\n\n\nThe problem of the company is scale and time to delivery.\n\nTheir current environment is 7+ years old, on-premises, and with limited compute, storage, and I/O capacity. Server refreshes are costly and take a long time to complete. Software and app updates follow an informal process and aren't repeatable. The actual HPC grid is hard to program against. The API is too complex for new Developers who join the team and requires non-documented knowledge. And major app upgrades take 6 - 9 months to complete.\n\n\n\n\n\n Solution \n\nCompute, storage, and I/O services that run in public cloud with secure access to on-premises enterprise assets as needed.\n\n\n\n* Secure and scalable document storage that supports structured and unstructured document query\n* Lift and shift existing enterprise assets and app while they enabled the integration to some on-premises systems that won't be migrated\n* Shorten time-to-deploy solutions and implement standard DevOps and monitoring processes to address bugs that affected reporting accuracy\n\n\n\nTechnical solution:\n\n\n\n* Red Hat OpenShift on IBM Cloud\n* IBM Cloud Object Storage\n* IBM Cloud Data Engine (Spark)\n* IBM Cloudant\n* Secure Gateway\n\n\n\nRed Hat OpenShift on IBM Cloud provides scalable compute resources and the associated DevOps dashboards to create, scale, and tear down apps and services as needed.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_finance"}, {"document_id": "ibmcld_07959-13107-14036", "score": 15.731815, "text": "\nPhysical servers and memory On-premises IaaS / data center provider On-premises IaaS / data center provider \n Physical storage On-premises IaaS / data center provider On-premises IaaS / data center provider \n Physical network and devices On-premises IaaS / data center provider On-premises IaaS / data center provider \n Facilities and data centers On-premises IaaS / data center provider On-premises IaaS / data center provider \n\n\n\n\n\n\n\n Other on-premises components outside of the IBM Cloud Satellite location \n\nThe workload provider and on-premises IaaS / data center provider are solely responsible for edge plane, management plane, and other applications that you run in the on-premises environment outside of the Satellite location.\n\n\n\n\n\n Next steps \n\n\n\n* [Satellite architecture best practices](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-satellite-architecture-best-practices)", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-satellite-architecture-shared-responsibilities"}, {"document_id": "ibmcld_11109-5333-7558", "score": 14.908404, "text": "\nFor short-term emergencies where the original site is unavailable for a period of time, but servers and storage remain intact, a delta-resynch might fit the need to bring the operation back to on premises.\n\nFor other emergencies, that have forced a change to the site, server, or storage in the original on premises, it might require a full resynchronization of data, so the fallback will happen tidily at the most convenient time after the sync point has been achieved.\n\n\n\n\n\n Cloud networking (LAN) \n\nHaving a DR on cloud might also imply that you need to rebuild your network structures to adapt to the network structures and constraints on the cloud provider. In some cases, you are be forced to use Software Defined Network (SDN) and Network Functions Virtualization (NFV) to reproduce your complex enterprise network layout. A careful planning and evaluation of performance and scalability limitation is essential to assure your reprovisioned compute can work properly.\n\n\n\n\n\n Cloud networking (WAN) \n\nAll the external networks connected to your primary (failed) site must be rerouted to the alternative cloud site. Different options are available, and you need to evaluate what options best fit your requirements. Consider the charges associated with the use of the network, such as download and upload charges, when using the cloud provider resources, as they might add a substantial cost to your DR total cost of ownership (TCO).\n\nWhen implementing a DR on cloud, the solution is simplified by leveraging the same technology in the primary and secondary sites.\n\n\n\n\n\n Full versus partial failover \n\nPartial failover is used to potentially increase the availability of the services by allowing to run and recover some of the services in DR while all the others are still running production on the customer data center.\n\nPartial failover carries a lot more complexity in the network design that is associated with the solution, as it requires an extension of production site networks to the DR site that can happen on Layer 2 (such as L2TPv3, Cisco Overlay Transport Virtualization), Layer 3 (such as Cisco Locator/ID Separation protocol (LISP), Virtual Private LAN Services (VPLS), or Software Defined Network technique.", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-networking-aspects"}, {"document_id": "ibmcld_08007-5991-8147", "score": 14.823243, "text": "\n[Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-about-cloud-object-storage) is an alternative storage option that is useful for certain use cases, including backup and recovery, data archiving, cloud-native application building, and AI and big data analytics. Object Storage stores encrypted and dispersed data across multiple geographic locations.\n\nBy default, all objects that are stored in Object Storage are encrypted by using randomly generated keys and an all-or-nothing-transform (AONT). While this default encryption model provides at-rest security, financial service workloads need full control over the data encryption keys used. Again, Hyper Protect Crypto Services should be used for this purpose.\n\n\n\n\n\n\n\n Using IBM Cloud services outside of a VPC \n\nTo connect to IBM Cloud services from your VPC, you need to use [Virtual Private Endpoints (VPE) for VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-about-vpe). In the reference architecture diagram, VPEs appear in the middle subnets of the workload VPC. With VPEs, you can connect to supported IBM Cloud services from your VPC network by using the IP addresses of your choosing, which is allocated from a subnet within your VPC.\n\nVPE is an evolution of the private connectivity to IBM Cloud services. VPEs are virtual IP interfaces that are bound to an endpoint gateway created on a per service, or service instance, basis (depending on the service operation model). The endpoint gateway is a virtualized function that scales horizontally, is redundant and highly available, and spans all availability zones of your VPC. Endpoint gateways enable communications from virtual server instances within your VPC and IBM Cloud service on the private backbone. VPE for VPC gives you the experience of controlling all the private addressing within your cloud.\n\n\n\n\n\n\n\n Variation with edge/transit VPC for public internet access \n\nYou might want to allow consumers to access your service through the public internet. This base architecture can be adapted to securely enable this type of access as shown in the following diagram, which introduces a new edge VPC.", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-vpc-architecture-detailed-vsi"}, {"document_id": "ibmcld_05138-7-2415", "score": 14.693126, "text": "\nCreate a Secure Content Store \n\nAre you looking to store content securely (locally or globally) at an affordable cost, for things like cloud native apps, media storage, backup storage and archive data? IBM Secure Content Store powered by IBM Cloud\u00ae Object Storage provides unparalleled agility in supporting fast, highly consistent application deployment around the world to help customers securely expand their business into new regions, from business-critical data to video archive solutions. It also offers immutable storage, immutable backup, and archive data with industry-leading security and controls for regulatory/compliance requirements.\n\n\n\n* Gain security and control over your data with encryption options, governance policies, access permissions, and context-based restrictions.\n* Have immediate consistency across regions or locations for cloud-native apps, disaster recovery, storage backup, video content and delivery. etc.\n* Leverage your own encryption keys (BYOK) with Key Protect.\n* Monitor and retain your account & data activity with Activity Tracker and IBM Monitoring.\n* APIs & SDKs, Static Web Hosting, High Speed Transfer, Tagging, Replication.\n\n\n\n\n\n Promotion for new customers! \n\nIBM Cloud is offering a $500 promotional credit to quickly get started with our Secure Content Store with Object Storage. The credit has a duration of 90 days against your metered consumption of Object Storage. See instructions below for how to apply your promo code. To qualify for this offer you must be a new paid user of Object Storage. There is a limit of one promotion code per customer account. The USD 500 credit is for use with this offer only and cannot to be applied to other offers. Offer is subject to availability.\n\n\n\n\n\n Overview \n\nThis tutorial is for customers looking to set up a Secure Content Store using Object Storage, Activity Tracker, and Key Protect. In this tutorial, you are guided through the process of quickly getting started with these essential services to ensure the security and integrity of your content. Secure Content Store is comprised of the following services:\n\n\n\n* Object Storage: a scalable and flexible storage solution that allows you to store and manage your data securely.\n* Activity Tracker: a powerful tool that provides comprehensive visibility into the activities happening within your IBM Cloud environment and allows for ease of audit observability.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-secure-content-store"}, {"document_id": "ibmcld_14292-7-2069", "score": 14.572051, "text": "\nVMware Systems storage options \n\nYou have several options when it comes to storage and VMware\u00ae. You can choose private, shared, or bring your own storage solutions. Use the following information to help you decide which storage solution works best with your workload.\n\nSee the following table for storage tiers and where your workload might fall.\n\n\n\nTable 1. Storage tiers\n\n Tier 1 Tier 2 Tier 3 \n\n Business use High performance and or high availability production applications, databases, and data Nonmission critical test and development application, databases, and data Nonmission critical data storage, backup, and archive \n Performance High (SSDs, SAS) Medium (SAS, SATA) Low (SATA) \n Guaranteed IOPS Yes No No \n High availability (HA) Yes No No \n Replication Yes Yes No \n Snapshots Yes No No \n\n\n\n\n\n Private and shared storage \n\nFor private storage, you can select local disk options, VSAN, or QuantaStor. For shared storage, you can select Endurance or Performance storage. If you decide to bring your storage, several \u201cprivate\u201d options are available, including NetApp OnTap Select, NetApp Private Storage (NPS), IBM\u00ae Spectrum Accelerate, and software defined storage. Table 2 and Table 3 offer a side-by-side comparison of the options for your convenience.\n\n\n\n\n\n Private storage options \n\nYou have several options for storage for connecting to VMware in a single-tenant environment:\n\n\n\n* Local\n* vSAN\n* QuantaStor\n* NetApp Data OnTap Edge\n* NPS\n* IBM Spectrum Accelerate\n\n\n\n\n\n Local storage \n\nOrder Bare Metal Servers from the IBM Cloud catalog with ESX and select the wanted disks [SATA, serial attached SCSI (SA SCSI), or SSD].\n\nYou can bring your own ESX license, but you need to open a ticket with Support to inform them of the change.\n\n\n\n* Recommended workloads - Tier 3\n* Performance - Limited dependent on RAID and disk type. SSDs present a cost increase for better performance.\n* Scalability - Limited to the number of drive slots in the chassis\n* Protocols - Not applicable\n* Cost: Low capital expenditure (CapEx) and operating expenditure (OpEx)", "title": "", "source": "https://cloud.ibm.com/docs/vmware?topic=vmware-vmware-storage"}, {"document_id": "ibmcld_03595-6075-8279", "score": 14.560592, "text": "\nFor more information about network options, see [Network options](https://cloud.ibm.com/docs/bare-metal?topic=bare-metal-network-options).\n\n\n\n\n\n Block and file storage add-on \n\nIf you need extra storage, IBM makes it easy! You can now order block and file storage (20 - 12,000 GB) when you provision a bare metal server.\n\nYour add-on storage isn't automatically connected to your bare metal server. You need to connect the add-on storage to your bare metal server after your server provisions.\n\nFor more information about block and file storage, see the following links.\n\n\n\n* [Getting started with Block Storage](https://cloud.ibm.com/docs/BlockStorage?topic=BlockStorage-getting-started)\n* [Getting started with File Storage](https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-getting-started)\n\n\n\n\n\n\n\n\n\n Bare metal server add-ons \n\nThe following add-ons are available when you provision a bare metal server.\n\n\n\nTable 5. Bare metal server provisioning options\n\n Option Description \n\n Power supply You can provision your bare metal server with two independent power supply units. These redundant units alternate power sources within the data center to help maintain uptime during unplanned or planned electrical maintenance. \n IBM Cloud Backup IBM Cloud Backup is an automated, agent-based backup and recovery system that is managed through the Cloud Backup WebCC browser utility. For more information, see [Getting started with IBM Cloud Backup](https://cloud.ibm.com/docs/Backup?topic=Backup-getting-started). \n Server security Intel Trusted Execution Technology (TXT) provides hardware-assisted security technologies to enhance your security portfolio and act as an extra security for your infrastructure. \n Business continuance insurance (BCI) Business continuance insurance helps you avoid overage charges if you experience a network attack (DDOS) that uses all of your allowed bandwidth. \n Firewall A hardware firewall provides an extra layer of security that is provisioned on demand without service interruptions. This firewall prevents unwanted traffic from reaching your servers by reducing your attack surface, and by enabling your server resources to be dedicated for their intended use.", "title": "", "source": "https://cloud.ibm.com/docs/bare-metal?topic=bare-metal-about-bm"}, {"document_id": "ibmcld_11568-1424-2437", "score": 14.412631, "text": "\n* [SAP Commerce (on-premises) Installation and Upgrades](https://help.sap.com/viewer/a74589c3a81a4a95bf51d87258c0ab15/2005/en-US/8bf5a611866910149242e1a3a41eb9af.html)\n* [SAP Commerce (on-premises) Architecture options are Single Node, Cluster Node, and Multi-Tenant Node](https://help.sap.com/viewer/b490bb4e85bc42a7aa09d513d0bcb18e/1905/en-US/8b5588d8866910149d4eb5f99c75b6b4.html)\n\n\n\nFor a typical development environment of SAP Commerce, it is straightforward (compared to other SAP software) to shut down the instantiation/s and reduce costs outside of business hours through less Cloud resource consumption; however, depending on the implementation the time to start again can be significant. This decision is required by the project team, and might not be suitable if a worldwide development team is in-place.\n\nMore information is available on [cxwiki.sap.com](https://cxwiki.sap.com) and [sap.com/cxworks](https://www.sap.com/cxworks).\n\nIBM Power Systems Virtual Servers are not available for SAP Commerce", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-commerce"}, {"document_id": "ibmcld_01115-0-1337", "score": 14.362298, "text": "\n\n\n\n\n\n\n  Loading data from on-premises systems with IBM Lift CLI \n\n[IBM Lift CLI](https://www.lift-cli.cloud.ibm.com) is a free ground-to-cloud data migration tool that securely moves your data from on-premises systems to IBM\u00ae Db2\u00ae Warehouse on Cloud plans hosted on IBM Cloud. IBM Lift CLI is available for the Flex One, Flex, and Flex Performance plans hosted on IBM Cloud.\n\nThe Lift application migrates your data to the IBM Cloud from the various data sources listed in Table 1.\n\n\n\nTable 1. Migration data sources\n\n Target database on IBM Cloud  Data source                       \n\n IBM Db2 Warehouse on Cloud    IBM Db2                           \n                               IBM Db2 Warehouse                 \n                               IBM Integrated Analytics System   \n                               IBM PureData System for Analytics \n                               Oracle Database                   \n                               Microsoft SQL Server              \n                               CSV file format                   \n\n\n\nTo download and install Lift, see: [Download Lift](https://www.lift-cli.cloud.ibm.com/download).\n\nFor step-by-step instructions about migrating your data to the IBM Cloud by using Lift, see: [Migrate data to IBM\u00ae Db2\u00ae Warehouse on Cloud](https://www.lift-cli.cloud.ibm.com/docs).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/Db2whc?topic=Db2whc-onprem"}, {"document_id": "ibmcld_10165-7-2413", "score": 14.211351, "text": "\nFinancial services use cases for IBM Cloud \n\nThese use cases highlight how workloads on Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae can take advantage of high availability, high-performance compute, easy spin-up of clusters for faster development, and AI from IBM Watson\u00ae.\n\n\n\n Mortgage company trims costs and accelerates regulatory compliance \n\nA Risk Management VP for a residential mortgage company processes 70 million records a day, but the on-premises system was slow and also inaccurate. IT expenses soared because hardware quickly went out of date and wasn't utilized fully. While they waited for hardware provisioning, their regulatory compliance slowed.\n\n\n\n Context \n\nTo improve risk analysis, the company looked to Red Hat OpenShift on IBM Cloud and IBM Cloud Analytic services to reduce costs, increase worldwide availability, and ultimately accelerate regulatory compliance. With Red Hat OpenShift on IBM Cloud in multiple regions, their analysis apps can be containerized and deployed across the globe, improving availability and addressing local regulations. Those deployments are accelerated with familiar open source tools, already part of Red Hat OpenShift on IBM Cloud.\n\nThey started by containerizing the analysis apps and putting them in the cloud. In a flash, their hardware headaches went away. They were able to easily design Kubernetes clusters to fit their high-performance CPU, RAM, storage, and security needs. And when their analysis apps change, they can add or shrink compute without huge hardware investments. With the Red Hat OpenShift on IBM Cloud horizontal scaling, their apps scale with the growing number of records, resulting in faster regulatory reports. Red Hat OpenShift on IBM Cloud provides elastic compute resources around the world that are secure and capable.\n\nNow those apps receive high-volume data from a data warehouse on IBM Cloudant. Cloud-based storage in IBM Cloudant ensures higher availability than when it was locked in an on-premises system. Since availability is essential, the apps are deployed across global data centers: for DR and for latency too.\n\nThey also accelerated their risk analysis and compliance. Their predictive and risk analytics functions, such as Monte Carlo calculations, are now constantly updated through iterative agile deployments. Container orchestration is handled by a managed Kubernetes so that operations costs are reduced too.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_finance"}]}
{"task_id": "2f013337236ea4635ad106813275dab7<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04866-7-2136", "score": 19.383085, "text": "\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-7-2136", "score": 19.383085, "text": "\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_04866-1541-3629", "score": 19.019468, "text": "\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https://cloud.ibm.com/docs/services/cloud-object-storage/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-1541-3629", "score": 19.019468, "text": "\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https://cloud.ibm.com/docs/services/cloud-object-storage/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_02361-24500-26305", "score": 18.787891, "text": "\n[Information about Immutable Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time? [Information about archiving COS files for long term storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-archive) \n Encryption of data at-rest with my own key [5] Can I use my own key to encrypt data at-rest? [Information about encryption of data at-rest](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-encryption) \n Data resiliency [6] Do you need to store the data in a specific geographical location? [Information about resiliency](https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-endpoints) \n\n\n\n[1]: Data might sit untouched for long periods of time. For less active workloads, you can create buckets with different storage classes. For example, use the standard storage class for active workloads, where you need to access data at any time.\n\n[2]: You can choose Immutable Object Storage to preserve electronic records and maintain data integrity. When you define a retention policy for a bucket, you are specifying that the data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds. Notice that Immutable Object Storage is available in certain regions only.\n\n[3]: You can use an expiration rule to delete objects automatically after a defined period from the object creation date.", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-adoption"}, {"document_id": "ibmcld_05032-6428-8442", "score": 18.609306, "text": "\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https://cloud.ibm.com/docs/images/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_04866-4961-6763", "score": 18.452488, "text": "\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https://www.ecfr.gov/cgi-bin/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https://www.finra.org/rules-guidance/rulebooks/finra-rules/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-4961-6763", "score": 18.452488, "text": "\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https://www.ecfr.gov/cgi-bin/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https://www.finra.org/rules-guidance/rulebooks/finra-rules/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_09275-49118-51096", "score": 18.409994, "text": "\n[Learn more](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutableimmutable-terminology-indefinite).\n\n\n\nAdd a legal hold flag or an indefinite retention flag to individual archived files if you need to keep a file longer than the default retention period specified at the bucket level.\n\n\n\n\n\n\n\n Define the strategy to query archived data \n\nYou can download data locally, and then use your own tools to query the data. When you download data for analysis, you are responsible for ensuring that your users comply with the regulations and compliance requirements that may be required for your organization. For example, if you must comply with GDPR, you need to control that users are following the download guidelines per GDPR rules.\n\nYou can use the Data Engine service to query IBM Log Analysis archived files that are stored in a COS bucket in your account. You can run queries from the IBM Cloud UI, or programmatically.\n\nAvoid downloading data locally. Use the Data Engine service to query archived data.\n\nThe Data Engine service provides a server-less, no-ETL solution to easily query data stored in Object Storage. Underneath, SQL Query uses Apache Spark SQL as its underlying query engine. You can use the Data Engine to run SQL queries (that is, SELECT statements) to analyze, transform structured and semi-structured data, or clean up rectangular data. You cannot run actions such as CREATE, DELETE, INSERT, and UPDATE.\n\nThe Data Engine service can process input data that is read from CSV, JSON, ORC, Parquet, or AVRO files. Archived files from an IBM Cloud Activity Tracker instance contain data in JSON format. When you use the Data Engine service, each query result can be written to a CSV, JSON, ORC, PARQUET, or AVRO file in an Object Storageinstance of your choice.\n\nWhen you query an IBM Cloud Activity Tracker archive file, you must convert the JSON formatted file into PARQUET format to be able to query the contents successfully.", "title": "", "source": "https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-adoption"}, {"document_id": "ibmcld_16729-316391-318406", "score": 18.342358, "text": "\nIBM Secure Content Store powered by IBM Cloud\u00ae Object Storage provides unparalleled agility in supporting fast, highly consistent application deployment around the world to help customers securely expand their business into new regions, from business-critical data to video archive solutions. It also offers immutable storage, immutable backup, and archive data with industry-leading security and controls for regulatory/compliance requirements.\n\nObject Storage\n\n\n\n* 15 minutes\n* 2023-06-29\n\n\n\n[Limiting access to a single Object Storage bucket](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-limit-access)Limiting access to a single Object Storage bucket\n\nIBM Cloud IAM resource groups and access groups allow administrators to restrict users access to various service instances, but what if a user needs to only access a limited number of buckets within a service instance? This can be accomplished using a custom role and a narrowly tailored IAM policy.\n\nObject Storage\n\n\n\n* 15 minutes\n* 2022-10-10\n\n\n\n[Encrypting a bucket with Key Protect ](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-tutorial-kp-encrypt-bucket)Encrypting a bucket with Key Protect\n\nWhile all data stored in Cloud Object Storage is automatically encrypted using randomly generated keys, some workloads require that the keys can be rotated, deleted, or otherwise controlled by a key management system (KMS) like Key Protect.\n\nObject Storage\n\n\n\n* 10 minutes\n* 2022-04-07\n\n\n\n[Building a Static Website](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-static-website-tutorial)Building a Static Website\n\nThis tutorial shows how to host a static website on IBM Cloud\u00ae Object Storage, including creating a bucket, uploading content, and configuring your new website.\n\nObject Storage\n\n\n\n* 15 minutes\n* 2020-11-07\n\n\n\n[Developing a web application](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-web-application)Developing a web application", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}]}
{"task_id": "2f013337236ea4635ad106813275dab7<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16692-1490-3300", "score": 11.309315, "text": "\nThe Stack Overflow forum, for technical questions, and the IBM Developer Answers forum, for general questions, both provide a wide variety of searchable answers to your IBM Cloud questions.\n\nIf you don't find an existing answer to a question, ask a new one.\n\nYou can access Stack Overflow and IBM Developer Answers from the Support Center, or use the following links:\n\n\n\n* Go to [Stack Overflow](https://stackoverflow.com/questions/tagged/ibm-cloud) to ask technical questions about the IBM Cloud Security and Compliance Center Workload Protection service.\n* Go to [IBM Developer Answers](https://developer.ibm.com/answers/topics/ibm-cloud/) to ask general questions about the IBM Cloud Security and Compliance Center Workload Protection service and about getting started instructions.\n\n\n\nTag your questions with ibm-cloud and workload-protection.\n\nIBM Cloud development and support teams actively monitor Stack Overflow and IBM Developer Answers, and follow the questions that are tagged with ibm-cloud. When you create a question in either forum, add the ibm-cloud tag to your question to ensure that it's seen by the IBM Cloud development and support teams.\n\n\n\n\n\n Opening a support case \n\nIf you don't find answers to your questions, and you experience problems with IBM Cloud, you can use support cases to get help with technical, account and access, billing and invoice or sales inquiry issues.\n\nYou can [create](https://cloud.ibm.com/docs/get-support?topic=get-support-open-case) and [manage](https://cloud.ibm.com/docs/get-support?topic=get-support-managing-support-cases) a support case by using the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter). After you submit a support case, the support team works to investigate and resolve the issue depending on your type of support plan.", "title": "", "source": "https://cloud.ibm.com/docs/workload-protection?topic=workload-protection-gettinghelp"}, {"document_id": "ibmcld_09755-1450-3171", "score": 11.204196, "text": "\nThe Stack Overflow forum, for technical questions, and the IBM Developer Answers forum, for general questions, both provide a wide variety of searchable answers to your IBM Cloud questions.\n\nIf you don't find an existing answer to a question, ask a new one.\n\nYou can access Stack Overflow and IBM Developer Answers from the Support Center, or use the following links:\n\n\n\n* Go to [Stack Overflow](https://stackoverflow.com/questions/tagged/ibm-cloud) to ask technical questions about the IBM Cloud Monitoring service.\n* Go to [IBM Developer Answers](https://developer.ibm.com/answers/topics/ibm-cloud/) to ask general questions about the IBM Cloud Monitoring service and about getting started instructions.\n\n\n\nTag your questions with ibm-cloud and monitoring.\n\nIBM Cloud development and support teams actively monitor Stack Overflow and IBM Developer Answers, and follow the questions that are tagged with ibm-cloud. When you create a question in either forum, add the ibm-cloud tag to your question to ensure that it's seen by the IBM Cloud development and support teams.\n\n\n\n\n\n Opening a support case \n\nIf you don't find answers to your questions, and you experience problems with IBM Cloud, you can use support cases to get help with technical, account and access, billing and invoice or sales inquiry issues.\n\nYou can [create](https://cloud.ibm.com/docs/get-support?topic=get-support-open-case) and [manage](https://cloud.ibm.com/docs/get-support?topic=get-support-managing-support-cases) a support case by using the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter). After you submit a support case, the support team works to investigate and resolve the issue depending on your type of support plan.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-gettinghelp"}, {"document_id": "ibmcld_07098-6745-8808", "score": 10.397135, "text": "\n* find_answers is optional and defaults to false. If it is set to true (and the natural_language_query parameter is set to a query string), the answer-finding feature is enabled.\n* max_answers_per_passage is optional and defaults to 1. In this case, the answer-finding feature finds the number of answers that are specified at most from any one passage.\n\n\n\nA section is also added to the return value within each passage object. That section is called answers, and it is a list of answer objects. The list can be up to max_answers_per_passage in length. Each answer object contains the following fields:\n\n\n\n* answer_text is the text of the concise answer to the query.\n* confidence is a number between 0 and 1 that is an estimate of the probability that the answer is correct. Some answers have low confidence and are unlikely to be correct. Be selective about what you do with answers based on this value. The confidence and order of documents in the search results are adjusted based on this combination if the per_document parameter of passage retrieval is set to true (which is the default).\n* start_offset is the start character offset (the index of the first character) of the answer within the field that the passage came from. It is greater than or equal to the start offset of the passage (since the answer must be within the passage).\n* end_offset is the end character offset (the index of the last character, plus one) of the answer within the field that the passage came from. It is less than or equal to the end offset of the passage.\n\n\n\nTo find answers across the entire project:\n\n\n\n* Set passages.enabled to true\n* Set passages.find_answers to true\n\n\n\nTo find answers within a single known document (for example, a document review application with long, complex documents):\n\n\n\n* Set passages.enabled to true\n* Set passages.find_answers to true\n* Set filter to select the document_id for the document\n\n\n\nThe following example shows a query that uses this API:\n\nPOST /v2/projects/{project_id}/query{\n\"natural_language_query\": \"Why did Nixon resign?\",", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-parameters"}, {"document_id": "ibmcld_07098-3231-5441", "score": 10.34046, "text": "\n* Works well with questions with longer phrase or clause answers.\n\n\n\n* Example question: How do I flip a pancake?\n* Passage: The key to getting a world-class pancake is flipping it properly. The best way to flip a pancake is to stick a spatula under it, lift it at least 4 inches in the air, and quickly rotate the spatula 180 degrees.\n\n\n\n* Many how or why questions are only fully answered by much longer spans of text. The answer-finding feature does not return a whole document as the answer (and it doesn't summarize a document length answer).\n* Handles yes or no questions that are factual and have a concise answer in the text\n\n\n\n* Example question: Is there a library in Timbuktu\n* Passage: Timbuktu's main library, officially called the Ahmed Baba Institute of Higher Islamic Studies and Research, is a treasure house that contains more than 20,000 manuscripts that cover centuries of Mali's history.\n\n\n\n* Handles questions with very short answers, such as names and dates, especially when the type of answer that is required is explicit in the text.\n* Handles opinion questions, but only by finding a statement of that opinion; it does not assess the validity of the opinion.\n\n\n\n* Example question: Should I try blue eyeshadow?\n* Passage: We think blue eye shadow is trending this year.\n\n\n\n\n\n\n\n How the answer-finding feature works \n\nAfter a user submits a query, the query is analyzed by the Discovery service. Query analysis transforms the user's original query in ways that improve the chances of finding the best search results. For example, it lemmatizing words, removes stop words, and adds query expansions. The search is performed and the resulting documents and passages are returned.\n\nAnswer finding is applied to the returned passages. Up to 60 passages are sent to the answer-finding service. How these 60 passages are chosen differs based on the passages.per_document parameter value.\n\n\n\n* If passages.per_document is false, the top 60 passages from all of the documents that are returned by search are chosen based on their passage scores only.\n* If passages.per_document is true, the returned documents are ranked first, and then the top 60 passages from these top documents are chosen.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-parameters"}, {"document_id": "ibmcld_07098-1507-3651", "score": 10.057668, "text": "\nWhen the answer-finding feature is enabled, Discovery also provides a \"short answer\" within the passage, and a confidence score to show whether the \"short answer\" answers the question that is explicit or implicit in the user query. Applications that use the answer-finding feature can display the short answer alone or can display the short answer emphasized in the context of the full passage. For most applications, displaying the short answer emphasized within the full passage is preferable, because answers generally make more sense in context.\n\nThe answer finding feature behaves in the following ways:\n\nIn the passage examples that follow, the short answers are shown in bold font.\n\n\n\n* Finds answers. It doesn\u2019t create answers. The answer must be part of the text; it can't be inferred.\n\n\u201cWhat was IBM\u2019s revenue in 2022?\u201d can get a correct answer if you have a document that states what IBM\u2019s revenue was in 2022. However, if you have a document that lists what IBM\u2019s revenue was in each quarter of 2022, it doesn't add them up and give you a total.\n* Handles synonyms and lexical variations if the answer is available.\n\n\n\n* Example question: \u201cWhen did IBM purchase Red Hat?\u201d\n* Passage: \u201cIBM closed its $34 billion acquisition of Red Hat in July of 2019.\"\n\n\n\n* Combines information across multiple sentences if they are close together (within approximately 2,000 characters).\n\n\n\n* Example question: \u201cWhen did IBM purchase Red Hat?\u201d\n* Passage: \u201cIBM acquired Red Hat for $34 billion. The deal closed in July of 2019.\"\n\n\n\n* Handles implicit questions similar to the way it would handle the equivalent explicit question.\n\nExample questions:\n\n\n\n* company that developed the AS/400\n* What company developed the AS/400?\n\n\n\n* Works well with questions with longer phrase or clause answers.\n\n\n\n* Example question: How do I flip a pancake?\n* Passage: The key to getting a world-class pancake is flipping it properly. The best way to flip a pancake is to stick a spatula under it, lift it at least 4 inches in the air, and quickly rotate the spatula 180 degrees.\n\n\n\n* Many how or why questions are only fully answered by much longer spans of text.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-parameters"}, {"document_id": "ibmcld_16340-8232-10560", "score": 9.972338, "text": "\nSearch result messages\n\n Tab Scenario Example message \n\n Message Search results are returned I found this information that might be helpful: \n No results found No search results are found I searched my knowledge base for information that might address your query, but did not find anything useful to share. \n Connectivity issue I was unable to complete the search for some reason I might have information that could help address your query, but am unable to search my knowledge base at the moment. \n\n\n\n4. Choose whether to enable Emphasize the answer.\n\nThis option is available only if your Discovery instance uses the v2 Discovery API.\n\nWhen you enable this feature, the sentence that is determined by Discovery to be the exact answer to the customer's question is highlighted in the block of text that is displayed to the customer as the search result.\n5. In the Adjust result quantity section, specify the number of results to return.\n\nThe top three results are returned automatically. You can choose to show fewer or more (up to 10) results in the response.\n\nBy default, customers can choose to see more results. If you don't want to give customers this choice, clear the Include link for customers to view up to 10 results checkbox.\n6. In the Set result selectivity section, decide whether to be more selective with the answers that are returned. By increasing result selectivity, Search returns fewer but more accurate results. In most cases, Search is accurate enough that the default setting (off) is sufficient.\n7. Click Preview. Enter a test message to see the results that are returned when your configuration choices are applied to the search. Make adjustments as necessary.\n8. Click Create.\n\n\n\n\n\n\n\n Edit the search integration configuration \n\nIf you want to change the configuration of the search result card later, open the search integration again, and make edits. You do not need to save changes as you make them; they are automatically applied. When you are happy with the search results, click Save to finish configuring the search integration.\n\nIf you decide you want to connect to a different Discovery service instance or project, open the search integration and click *Edit Discovery Settings. You can choose either a new project from the same instance, or a new instance and project.\n\n\n\n\n\n Troubleshooting", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-search-add"}, {"document_id": "ibmcld_11601-6079-6736", "score": 9.924081, "text": "\n* and for SAP HANA also use full-system-info-dump on [SAP Note 1732157](https://launchpad.support.sap.com//notes/1732157)\n\n\n\n\n\n\n\n\n\n\n\n Stack Overflow \n\nThe Stack Overflow forum provides a wide variety of searchable answers for your IBM Cloud questions. If you don't find an existing answer, ask a new question. Go to [Stack Overflow](https://stackoverflow.com/questions/tagged/ibm-cloud).\n\nIBM Cloud development and support teams actively monitor Stack Overflow and follow the questions that are tagged with ibm-cloud. When you create a question, add the ibm-cloud tag to your question to ensure that it's seen by the IBM Cloud development and support teams.", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-help-support"}, {"document_id": "ibmcld_06953-7-2041", "score": 9.798932, "text": "\nSearching Discovery data from Watson Assistant \n\nYour Discovery project can provide answers to questions that stump your assistant. Instead of answering with \u201cI don't know\u201d, your assistant can say, \u201cI'm not sure, but I searched my knowledge base and found these answers which might help.\u201d\n\nFor more information about how to search a Discovery project from an assistant, read the appropriate Watson Assistant documentation for your situation.\n\n\n\n* From the new experience user interface, see [Search trigger](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-search-addsearch-add-trigger).\n* From an actions skill in the classic user interface, see [Configuring the search for an answer](https://cloud.ibm.com/docs/assistant?topic=assistant-actionsactions-what-next-search).\n* From a dialog skill, see [Adding a search skill response type](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n\n\n\nIf you use the built-in web chat, you can use answer finding by enabling the Emphasize the answer feature. Answer finding highlights the word or phrase in the search result that is determined to be the exact answer to the customer's question.\n\nFor a more detailed look at the steps to take to connect to a Discovery project from Watson Assistant, take a tutorial that walks you through them. For more information, see [Power your assistant with answers from web resources](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-tutorial-assistant-fred).\n\nAlternatively, you can add a generative language service named NeuralSeek between the Watson Discovery and Watson Assistant services. For more information, see [Use NeuralSeek to return polished answers from existing help content](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-tutorial-neuralseek).\n\n\n\n How the assistant calls Discovery \n\nWhen a user asks your assistant a question that triggers a search, the following API request is sent to Discovery if Emphasize the answer is enabled.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-chat-choose-project"}, {"document_id": "ibmcld_07118-8957-10609", "score": 9.551657, "text": "\nNow that the assistant can recognize questions about a subject, let's give it access to data from which it can retrieve accurate answers.\n\nIn Discovery, create a Conversational Search project type. This project type is optimized for retrieving answers during dialog-driven interactions. For example, unlike other project types, it does not apply prebuilt enrichments that aren't needed.\n\n\n\n1. Open a new web browser page.\n\nKeep the Watson Assistant page open in a separate tab so you can switch between the two applications.\n2. From the Discovery Plus plan service page in IBM Cloud, click Launch Discovery.\n3. From the My Projects page, click New Project.\n4. Name your project Federal Reserve research, and then click the Conversational Search tile.\n\nZoom\n\n![Shows the project type options](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/tut-convo-project.png)\n\nFigure 18. Project type options\n5. Click Next.\n\n\n\nYou'll configure the data source for the project in the next step.\n\n\n\n\n\n Step 4: Connect to a website \n\nWe want the virtual assistant to be able to answer questions about the latest working papers from the US Federal Reserve, so we will connect our project to the Federal Reserve Economic Data website that hosts the working papers.\n\n\n\n1. From the Select data source page, click Web crawl, and then click Next.\n\nZoom\n\n![Shows the data source options](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/tut-convo-web-crawl-0.png)\n\nFigure 19. Data source options\n2. In the Collection name field, add FRED papers.\n\nZoom\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-tutorial-assistant-fred"}, {"document_id": "ibmcld_07098-8412-9823", "score": 9.524257, "text": "\nTo find answers within a single known document (for example, a document review application with long, complex documents):\n\n\n\n* Set passages.enabled to true\n* Set passages.find_answers to true\n* Set filter to select the document_id for the document\n\n\n\nThe following example shows a query that uses this API:\n\nPOST /v2/projects/{project_id}/query{\n\"natural_language_query\": \"Why did Nixon resign?\",\n\"passages\": {\n\"enabled\": true, \"find_answers\":true\n}\n}\n\nExample response:\n\n{\n\"matching_results\": 74, \"retrieval_details\": { \"document_retrieval_strategy\": \"untrained\"},\n\"results\": [\n{\n\"document_id\": \"63919442-7d5b-4cae-ab7e-56f58b1390fe\",\n\"result_metadata\":{\"collection_id\": \"collection_id1234\",\"document_retrieval_source\":\"search\",\"confidence\": 0.78214},\n\"metadata\": {\"parent_document_id\": \"63919442-7d5b-4cae-ab7e-56f58b1390fg\"},\n\"title\": \"Watergate scandal\",\n\"document_passages\":\n{\n\"passage_text\": \"With his complicity in the cover-up made public and his political support completely eroded, Nixon resigned from office on August 9, 1974. It is believed that, had he not done so, he would have been impeached by the House and removed from office by a trial in the Senate.\",\n\"field\": \"text\",\n\"start_offset\": 281,\n\"end_offset\": 553,\n\"answers\":\n{\n\"answer_text\": \"his complicity in the cover-up made public and his political support completely eroded\",\n\"start_offset\": 286, \"end_offset\": 373, \"confidence\": 0.78214\n}", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-parameters"}]}
{"task_id": "2f013337236ea4635ad106813275dab7<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03313-6149-8039", "score": 18.46761, "text": "\n[Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-system-entities). \n Try it out A chat window that you use to test as you build. For example, from the dialog skill's \"Try it out\" pane, you can mimic the behavior of a customer and enter a query to see how the assistant responds. You can test only the current skill; you cannot test your assistant and all attached skills from end to end. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-tasks). \n Variable A variable is data that a customer shares with the assistant, which is collected and saved so it can be referenced later. In an actions skill, you can collect action and session variables. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-actions-overviewactions-overview-step-variables). \n Web chat An integration that you can use to embed your assistant in your company website. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat). \n Webhook A mechanism for calling out to an external program during a conversation. For example, your assistant can call an external service to translate a string from English to French and back again in the course of the conversation. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-webhook-overview). \n\n\n\n\n\n\n\n I can't log in \n\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-faqs"}, {"document_id": "ibmcld_16727-5954-7906", "score": 17.708828, "text": "\nYou can add these to your skill and start using them immediately. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-system-entities). \n Try it out A chat window that you use to test as you build. For example, from the dialog skill's \"Try it out\" pane, you can mimic the behavior of a customer and enter a query to see how the assistant responds. You can test only the current skill; you cannot test your assistant and all attached skills from end to end. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-tasks). \n Variable A variable is data that a customer shares with the assistant, which is collected and saved so it can be referenced later. In an actions skill, you can collect action and session variables. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-actions-overviewactions-overview-step-variables). \n Web chat An integration that you can use to embed your assistant in your company website. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat). \n Webhook A mechanism for calling out to an external program during a conversation. For example, your assistant can call an external service to translate a string from English to French and back again in the course of the conversation. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-webhook-overview). \n\n\n\n* I can't log in\n\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-5954-7906", "score": 17.708828, "text": "\nYou can add these to your skill and start using them immediately. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-system-entities). \n Try it out A chat window that you use to test as you build. For example, from the dialog skill's \"Try it out\" pane, you can mimic the behavior of a customer and enter a query to see how the assistant responds. You can test only the current skill; you cannot test your assistant and all attached skills from end to end. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-tasks). \n Variable A variable is data that a customer shares with the assistant, which is collected and saved so it can be referenced later. In an actions skill, you can collect action and session variables. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-actions-overviewactions-overview-step-variables). \n Web chat An integration that you can use to embed your assistant in your company website. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat). \n Webhook A mechanism for calling out to an external program during a conversation. For example, your assistant can call an external service to translate a string from English to French and back again in the course of the conversation. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-webhook-overview). \n\n\n\n* I can't log in\n\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_03006-3162-5290", "score": 17.553164, "text": "\nThe dialog gathers any information it needs to respond or perform a transaction on the user's behalf.\n\nThe dialog can interact with the following resources:\n\n\n\n* Other IBM services: Connect with additional Watson services to analyze user input, such as Speech to Text.\n* Back-end systems: Based on the user's intent and additional information, extract information or perform transactions by interacting with your back-end systems. For example, answer question, open tickets, update account information, or place orders.\n\n\n\n* Any questions that cannot be answered by the dialog skill are sent to the search skill, which finds relevant answers by searching the company knowledge bases that you configure for the purpose. The search skill routes complex customer inquiries to IBM Watson\u00ae Discovery for IBM Cloud Pak\u00ae for Data. Discovery treats the user input as a search query. It finds information that is relevant to the query from the configured data sources and returns it so the assistant can share the information with the user as its response.\n\n\n\n\n\n\n\n Implementation \n\nThis diagram shows the implementation in more detail:\n\n![Flow diagram of the service](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/cp4d-diagram.png)\n\nHere's how you implement your assistant:\n\n\n\n1. Create an assistant.\n2. Create a dialog skill. Use the intuitive graphical tool to define the training data and dialog for the conversation between your assistant and your customers.\n\nThe training data consists of the following artifacts:\n\n\n\n* Intents: Goals that you anticipate your users have when they interact with your assistant. Define one intent for each goal that can be identified in a user's input. For example, you might define an intent that is named store_hours that answers questions about store hours. For each intent, you add sample utterances that reflect the input customers might use to ask for the information they need, such as, What time do you open?\n\nOr use prebuilt content catalogs that are provided by IBM to get started with data that addresses common customer goals.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-index"}, {"document_id": "ibmcld_03028-8841-10718", "score": 17.498695, "text": "\nIf log sharing is enabled, only someone with Manager service access to the current instance can view logs. The person can view logs from all of the instances that are being shared. Logs from across all of the participating instances are displayed, regardless of the current user's service level access to the other instances. Similarly, when someone with Manager service access to an instance sends a GET request to the v1 /logs API endpoint, logs from all instances that participate in log sharing are returned, regardless of the user's service level access to each instance.\n\n\n\n\n\n\n\n Making training data improvements \n\nUse insights from real user conversations to correct the model associated with your dialog skill.\n\nIf you use data from another data source, any improvements you make to the model are applied to the current dialog skill only. The Data source field shows the source of the messages you are using to improve this dialog skill, and the header of the page shows the dialog skill you are applying changes to.\n\n\n\n Correcting an intent \n\n\n\n1. To correct an intent, select the ![Edit](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/edit_icon.png) edit icon for the chosen #intent.\n2. From the list provided, select the correct intent for this input.\n\n\n\n* Begin typing in the entry field and the list of intents is filtered.\n* You can also choose Mark as irrelevant from this menu. (For more information, see [Teaching your assistant about topics to ignore](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logslogs-mark-irrelevant).) Or, you can choose Do not train on intent, which does not save this message as an example for training.\n\n\n\n![Select intent](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/select_intent.png)\n3.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs"}, {"document_id": "ibmcld_03176-2528-4126", "score": 17.461292, "text": "\nFor more information, see [Changing the inactivity timeout setting](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-settingsassistant-settings-change-timeout).\n5. To test the assistant from a separate web page, copy and paste the Share this link URL into a web browser.\n\nA simple IBM-branded web page is displayed that contains a chat window where you can interact with your assistant. You can share the page with others by sending them the Share this link URL. If necessary, you can click the toggle on the Preview page to disable the link.\n\nPreviewing your assistant within the Watson Assistant user interface does not incur any charges. If you use the Share this link URL to preview the assistant from elsewhere, you might be charged for messages that you submit, according to the terms of your plan. You can review metrics about the test user conversations from the Analytics page.\n6. Click X to close the Preview page.\n\n\n\n\n\n\n\n Dialog considerations \n\nThe rich responses that you add to a dialog are displayed in the web-hosted chat widget as expected, with the following exceptions:\n\n\n\n* Connect to human agent: This response type is ignored.\n* Pause: This response type pauses the assistant's activity in the chat widget. However, activity does not resume after the pause until another response is triggered. Whenever you include a pause response type, add another, different response type, such as text, after it.\n\n\n\nSee [Rich responses](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-multimedia) for more information about response types.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-link"}, {"document_id": "ibmcld_03329-8550-10308", "score": 17.29933, "text": "\n[Preview button](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/preview-button.png)\n4. Copy the URL from Share this link and use it in a new tab. You can start submitting message to see how your assistant responds.\n\nWith a Lite plan, you can use the service for free. With other plans, you are charged for messages that you submit from the preview link. You can review metrics about the test user conversations from the Analytics page. You are not charged for messages that you submit from the \"Try it out\" pane, and the exchanges you have there are not logged.\n5. Type hello into the text field, and watch your assistant respond.\n\n![The widget in the preview link integration showing a single dialog exchange.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-test-from-preview-link.png)\n\nYou can share the URL with others who might want to try out your assistant.\n6. After testing, close the web page. Click the X to close the preview link integration page.\n\n\n\n\n\n\n\n Next steps \n\nThis tutorial is built around a simple example. For a real application, you need to define some more interesting intents, some entities, and a more complex dialog that uses them both. When you have a polished version of the assistant, you can integrate it with web sites or channels, such as Slack, that your customers already use. As traffic increases between the assistant and your customers, you can use the tools that are provided in the Analytics page to analyze real conversations, and identify areas for improvement.\n\n\n\n* Complete follow-on tutorials that build more advanced dialogs:\n\n\n\n* Add more dialog nodes to design complex conversational exchanges.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-gs-dialog"}, {"document_id": "ibmcld_13042-10425-12696", "score": 17.254211, "text": "\nAs you add field mappings, a preview of the search result is displayed with information from the corresponding fields of your data collection. This preview shows you what gets included in the search result response that is returned to users.\n\nTo get help with configuring the search, see [Troubleshooting](https://cloud.ibm.com/docs/services/assistant?topic=assistant-skill-search-addskill-search-add-troubleshoot).\n3. Use the Message, No results found and Connectivity issue tabs to customize different messages to share with users based on the successfulness of the search.\n\n\n\nSearch result messages\n\n Tab Scenario Example message \n\n Message Search results are returned I found this information that might be helpful: \n No results found No search results are found I searched my knowledge base for information that might address your query, but did not find anything useful to share. \n Connectivity issue I was unable to complete the search for some reason I might have information that could help address your query, but am unable to search my knowledge base at the moment. \n\n\n\n4. Choose whether to enable Emphasize the answer.\n\nThis option is available only if your Discovery instance uses the v2 Discovery API.\n\nWhen you enable this feature, the sentence that is determined by Discovery to be the exact answer to the customer's question is highlighted in the block of text that is displayed to the customer as the search result.\n5. In the Adjust result quantity section, specify the number of results to return.\n\nThe top three results are returned automatically. You can choose to show fewer or more (up to 10) results in the response.\n\nBy default, customers can choose to see more results. If you don't want to give customers this choice, clear the Include link for customers to view up to 10 results checkbox.\n6. In the Set result selectivity section, decide whether to be more selective with the answers that are returned. By increasing result selectivity, Search returns fewer but more accurate results. In most cases, Search is accurate enough that the default setting (off) is sufficient.\n7. Click Preview to open the Preview pane for testing. Enter a test message to see the results that are returned when your configuration choices are applied to the search.", "title": "", "source": "https://cloud.ibm.com/docs/services/assistant?topic=assistant-skill-search-add"}, {"document_id": "ibmcld_02961-2870-4843", "score": 17.238941, "text": "\nYou can change how someone reacts to your system based simply on how you phrase a response. Changing one line of text can prevent you from having to write multiple lines of code to implement a complex programmatic solution.\n* Back up your skill frequently. See [Downloading a skill](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-dialog-addskill-dialog-add-download).\n\n\n\n\n\n\n\n Tips for capturing information from user input \n\nIt can be difficult to know the syntax to use in your dialog node to accurately capture the information you want to find in the user input. Here are some approaches you can use to address common goals.\n\n\n\n* Returning the user's input: You can capture the exact text uttered by the user and return it in your response. Use the following SpEL expression in a response to repeat the text that the user specified back in the response:\n\nYou said: <? input.text ?>.\n\nIf autocorrection is on, and you want to return the user's original input before it was corrected, you can use <? input.original_text ?>. But, be sure to use a response condition that checks whether the original_text field exists first.\n* Determining the number of words in user input: You can perform any of the supported String methods on the input.text object. For example, you can find out how many words there are in a user utterance by using the following SpEL expression:\n\ninput.text.split(' ').size()\n\nSee [Expression language methods for String](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-methodsdialog-methods-strings) to learn about more methods you can use.\n* Dealing with multiple intents: A user enters input that expresses a wish to complete two separate tasks. I want to open a savings account and apply for a credit card. How does the dialog recognize and address both of them? See the [Compound questions](https://sodoherty.ai/2017/02/06/compound-questions/) entry from Simon O'Doherty's blog for strategies you can try.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-tips"}, {"document_id": "ibmcld_02855-6718-8435", "score": 17.109581, "text": "\nSubmit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.\n\n\n\nYou can apply more advanced customizations to the style of the web chat by using the Watson Assistant web chat toolkit on [GitHub](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configuration). For example, the text that is displayed in the chat window uses the fonts: IBMPlexSans, Arial, Helvetica, sans-serif. If you want to use a different font, you can specify it by using the instance.updateCSSVariables() method.\n\n\n\n\n\n Adding a home screen ![Beta](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/beta.png) \n\nCustomers often don't know how to interact with your assistant at first. They aren't sure how to format a question or what types of things they can ask. Don't make them guess. Show them by adding a home screen to the web chat window.\n\n![An example of the home screen](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/home-screen.png)\n\n\n\n1. From the Home screen tab, turn the home screen feature On.\n2. Add a greeting that is engaging and invites the user to interact with your assistant.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01660-8584-10307", "score": 28.449621, "text": "\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accountfaqs"}, {"document_id": "ibmcld_01705-7-1620", "score": 26.57926, "text": "\nAccount types \n\nWhen you register with IBM Cloud\u00ae, you are set up with a Pay-As-You-Go account. Even though you provide your credit card information for account security and identity verification purposes, you can still use IBM Cloud for free by selecting products in the catalog that offer Free and Lite pricing plans. Another account type, called a Subscription account, is also available. With a Subscription account, you get many of the same features of a Pay-As-You-Go account, plus discounts for platform services and support with a more consistent billing structure that uses subscriptions.\n\n\n\n Comparing accounts \n\nThe following table provides a comparison of Trial, Pay-As-You-Go, and Subscription accounts. For more details about each account, see the sections that follow.\n\n\n\nTable 1. Comparison of IBM Cloud accounts\nThis table has row and column headers. The row headers identify the feature. The column headers identify the account type. To understand which features apply to the account types, navigate to the row, and find the feature that you're interested in.\n\n Trial Pay-As-You-Go Subscription \n\n [Free community buildpacks](https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-available_buildpacks) 186 GBH 186 GBH 186 GBH \n Access to [Lite service plans](https://cloud.ibm.com/catalog/?search=label:lite) ![Feature available](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/icon_enabled.svg) ![Feature available](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/icon_enabled.svg) !", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accounts"}, {"document_id": "ibmcld_16727-1079289-1081125", "score": 26.039698, "text": "\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-1076793-1078629", "score": 26.039698, "text": "\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_01705-13208-15001", "score": 24.490168, "text": "\nIf you created a Lite account before 25 October 2021, your account doesn't expire and you can work in IBM Cloud for free by accessing services with select Lite plans, which are displayed with a Lite tag ![Lite tag](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/Lite.svg) in the catalog. To gain access to all Free plans, you can go ahead and [upgrade to a Pay-As-You-Go account](https://cloud.ibm.com/docs/account?topic=account-accountfaqschangeacct) by adding your credit card information.\n\nStarting 25 October 2021, all new accounts are created as Pay-As-You-Go based on an update to our account registration process. As part of this update, you're asked to provide credit card information for identity verification. You have full access to the catalog, including all Free and Lite plans, and you get a $200 credit that you can apply in your first 30 days. You pay only for billable services that you use, with no long-term contracts or commitments.\n\nLite accounts have access to a single resource group that's created for you with the name Default. All of your service's instances are automatically added to this resource group. You can update the name of this resource group at any time. See [Renaming a resource group](https://cloud.ibm.com/docs/account?topic=account-rgsrename_rgs) for the detailed steps.\n\n\n\n What's available in a lite account? \n\nCheck out the following list of key features that are available in a Lite account:\n\n\n\n* The account is free - no credit card required.\n* The account never expires.\n* You receive email notifications about your account status and quota limits.\n* You can create one instance of any service in the [IBM Cloud catalog](https://cloud.ibm.com/catalog/?search=label:lite%20lite) that has a Lite plan.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accounts"}, {"document_id": "ibmcld_01660-7085-8964", "score": 24.042477, "text": "\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https://cloud.ibm.com/account/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https://cloud.ibm.com/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accountfaqs"}, {"document_id": "ibmcld_12824-7-1978", "score": 23.910494, "text": "\nFAQs for migrated products \n\nFAQs about products that are migrated from the Resource Management Console might include questions about Lite plans, changing pricing plans, and brokers connected to approved pricing plans.\n\nTo find all FAQs for IBM Cloud, see our [FAQ library](https://cloud.ibm.com/docs/faqs).\n\n\n\n Why can't I add new block tier usage-based plans? \n\nBlock tier pricing plans are not currently supported in Partner Center. If you set up a block tier pricing plan in the Resource Management Console and the plan was approved and published, no changes have been made and it was migrated as-is with your product. However, you can't edit the plan or set up a new block tier pricing plan. If you have any questions, open a support case. For information about opening a support case, see [Creating a Partner Center support case](https://cloud.ibm.com/docs/sell?topic=sell-get-pc-supportpc-support-case).\n\n\n\n\n\n What changed with Lite plan support? \n\nLite plans are not supported in Partner Center. You can create a new free plan, and all users with Pay-As-You-Go and Subscription accounts can try out your product for free.\n\nIf you set up a Lite plan in the resource management console, and it was approved and published, no changes have been made and it was migrated as-is with your product. If you need to change a published pricing plan, open a support case. For information about opening a support case, see [Creating a Partner Center support case](https://cloud.ibm.com/docs/sell?topic=sell-get-pc-supportpc-support-case).\n\n\n\n\n\n Can I add a broker per location? \n\nNo. Brokers are added per pricing plan, not per location. And, brokers can't be disconnected from already approved plans.\n\n\n\n\n\n Can I set different locations per plan for a single product? \n\nYes. But, all plans for a single product must be set as either global or per location. Therefore, you can't have a plan that is set to global and then another plan set to be available for specific regions.", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-migrated-products"}, {"document_id": "ibmcld_01705-2818-4572", "score": 23.886314, "text": "\n[Feature available](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/icon_enabled.svg) \n Invoiced on monthly consumption ![Feature available](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/icon_enabled.svg) \n\n\n\nNew accounts as of 25 October 2021 are created as Pay-As-You-Go or Subscription accounts. You're asked to provide credit card information for identity verification or a code for a purchased subscription. If you created an account before this date, you might be using a [Lite account](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount) and Lite pricing plans, which aren't affected by the recent account registraton update.\n\n\n\n\n\n Trial account \n\nTrial accounts offer timed access to a limited range of service plans and allow you to test out the platform without financial commitment. You can access Lite service plans and Free plans for a limited time with a trial account. To qualify for a trial account, go to [Harness the Power of IBM](https://ibm.biz/academic) and validate your institution credentials or reach out to your educational program or course leader. If you don't have an account, select 'Register with a Code' during IBM Cloud registration to apply a code. If you have an account, go to the [Account settings](https://cloud.ibm.com/account/settings) page in the console to apply the code.\n\nIf you upgrade your trial account to a Pay-As-You-Go account by entering a credit card, it can't be converted back to a trial account. IBM Cloud trial accounts are available for faculty and students at accredited academic institutions. Trial accounts expire after 30 days. Your account is deactivated when the trial period ends.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accounts"}, {"document_id": "ibmcld_11142-7-1829", "score": 23.329092, "text": "\nTry out IBM Cloud, for free \n\nLooking to try out IBM Cloud\u00ae? Create an account and start building proof of concepts (POCs) with the many components available in IBM Cloud. You can try Lite and Free service plans to explore IBM Cloud at no cost while learning how to work in the cloud, use Watson, and more. This quick start guide is intended to help you get up and running on IBM Cloud without having to think about costs until you're ready.\n\n\n\n Before you begin \n\nGo to the [IBM Cloud console](https://cloud.ibm.com) and create an account. You're asked to enter your credit card information to secure your account and verify your identity. There are no costs that are associated with signing up, and you can try out IBM Cloud for free. You pay only for billable services that you choose to use, with no long-term contracts or commitments.\n\nYou're set up with a [Pay-As-You-Go account](https://cloud.ibm.com/docs/account?topic=account-accountspaygo), and you can access the full IBM Cloud catalog, including all Lite and Free plans. You receive a $200 credit to help get you started. You can use the $200 credit on IBM Cloud products that are used in the first 30 days.\n\n\n\n\n\n Step 1: Explore the catalog \n\nExplore the catalog for services that are free to use by filtering for Lite and Free pricing plans. You can work on your projects worry free, without the risk of generating a bill.\n\n\n\n1. Go to the [catalog](https://cloud.ibm.com/catalog).\n2. Select the Lite and Free pricing plan options.\n\n\n\n\n\n\n\n Step 2: Create an instance \n\nCreate an instance of product that includes a free Lite plan or a Free tier pricing plan.\n\n\n\n1. Select the tile from the catalog after reviewing the filtered list of products.\n2. Enter any required information to create the instance.\n3. Click Create.\n\n\n\n\n\n\n\n Step 3: Check out the tutorials", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-tutorial-try-for-free"}, {"document_id": "ibmcld_01660-23838-25711", "score": 23.26886, "text": "\nFor more information, see [Adding orgs and spaces](https://cloud.ibm.com/docs/account?topic=account-orgsspacesuserscreateorg).\n\n\n\n\n\n Why do I get logged out of my account? \n\nThe administrator of your account has customized the duration of active and inactive accounts, which requires users to enter their credentials after a specific time. For more information, see [Managing user's login session durations](https://cloud.ibm.com/docs/account?topic=account-iam-work-sessions).\n\n\n\n\n\n Why can't I create a Lite account? \n\nBased on an update to our account registration that released starting 25 October 2021, new accounts are created as Pay-As-You-Go. As part of this update, you're asked to provide credit card information for identity verification. After you register and create your new account, you can access the full IBM Cloud catalog, including all Free and Lite plans. And, you get a $200 credit that you can use on products in the first 30 days. You pay only for billable services that you use, with no long-term contracts or commitments.\n\nIf you created a Lite account before 25 October 2021, you can continue working as you always have. However, you can go ahead and [upgrade to a Pay-As-You-Go account](https://cloud.ibm.com/docs/account?topic=account-accountfaqschangeacct) by adding your credit card information. This way, you can gain access to all Free service plans in the catalog.\n\n\n\n\n\n How do I see who created a service instance and when? \n\nFrom the [Resource list](https://cloud.ibm.com/resources), expand the appropriate section, and click the row for the instance that you want more details about. Additional details about the resource display including when the resource was created and by whom.\n\nFor classic infrastructure services, you can get similar information by using the [Audit log](https://cloud.ibm.com/docs/account?topic=account-audit-log).", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accountfaqs"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03729-3519-5413", "score": 22.445257, "text": "\nThese resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings\n* Encrypted data storage limit, for example 1 GB\n* Provisioned throughput capacity\n\n\n\nYou can easily find services for Lite plans in the catalog. By default, all services with a Lite plan are displayed with a Lite tag ![Lite tag](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/Lite.svg). Select a service to view the quota details for the associated Lite plan.\n\n\n\n\n\n Charges for compute resources \n\nYou're charged for the time that your apps run and the memory that's used in GB-hours. GB-hours is the calculation of the number of application instances that are multiplied by the memory per instance and by the hours that the instances run. You can customize the number of instances and the amount of memory per instance based on your needs. You can also add memory or instances to scale for more users. To get the amount charged, take your application instances that are multiplied by memory per instance and by hours running.\n\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges"}, {"document_id": "ibmcld_16727-1079289-1081125", "score": 21.805815, "text": "\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-1076793-1078629", "score": 21.805815, "text": "\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_07103-31052-33321", "score": 21.103151, "text": "\nYou cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, and Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 24 September 2021 \n\nNew scoring for NLU enrichments\n: Relevance and confidence scores are displayed for NLU enrichments that are returned by search. For example, when you open the JSON view of the document preview from a query result, you can see confidence scores for Entities mentions and relevance scores for Keyword mentions.\n\n\n\n\n\n 9 September 2021 \n\nNew location for Plus plan\n: The Plus plan is now available from the Sydney location. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product. For more information, see [Getting the most from Discovery](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-version-choose).\n\nChange to Lite and Advanced plans in most locations\n: Lite and Advanced plans are discontinued. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\n\n\n\n\n 26 August 2021 \n\nNew locations for the Plus plan\n: The Plus plan is now available from the London and Washington DC locations, in addition to Dallas, Frankfurt, and Tokyo.\n\nChange to Lite and Advanced plans in some locations\n: You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\nNew answer finding feature\n: Answer finding is now generally available for managed deployments.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-release-notes"}, {"document_id": "ibmcld_05013-2864-3381", "score": 20.911709, "text": "\nCan I create more than one Object Storage service with a Lite account? \n\nIf you already have a Lite plan instance created, you may create other Standard plan instances, but only one Lite plan instance is allowed.\n\n\n\n\n\n What happens if I exceed the maximum usage allowed for a Lite plan? \n\nOnce you exceed the allowed usage, the service instance associated with the Lite plan becomes inaccessible. You will receive a warning notification email with corrective steps. If you do not take action, the instance is removed.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-faq-provision"}, {"document_id": "ibmcld_01660-8584-10307", "score": 20.529123, "text": "\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accountfaqs"}, {"document_id": "ibmcld_02143-0-1216", "score": 20.338026, "text": "\n\n\n\n\n\n\n  Why can't I create a new Lite plan instance? \n\nYou try to create more than one instance in your Lite account.\n\n  What\u2019s happening \n\nYou receive the following error message when you try to create a new Lite plan instance:\n\n> Unable to provision new Lite instance\n>\n> The account already has an instance created with the Lite plan\n\n  Why it\u2019s happening \n\nThere's a limit of one instance per Lite plan to ensure that these plans stay free. For more information about Lite account features, see [Lite account](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n\n  How to fix it \n\nYou can create more instances of the service by selecting one of the billable service plans, which are available in the billable accounts. To upgrade to a billable account from the console, go to Manage > Account in the IBM Cloud console, and select Account settings.\n\nIf you don't want to upgrade from a Lite account and are no longer using your existing Lite service instance, you can delete the existing Lite plan instance from the dashboard and then create a new instance. When you delete the Lite plan instance, all of the data that is associated with that instance is deleted and isn't recoverable.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-nosecondlite"}, {"document_id": "ibmcld_02660-1509-3609", "score": 20.108461, "text": "\nCurrently, Dallas (us-south), Washington DC (us-east), London (eu-gb), and Sydney (au-syd) regions are supported.\n4. Select a pricing plan - Based on your business requirements, select a pricing plan: Lite, Standard, and Enterprise.\n\n\n\n* Lite - Includes all App Configuration capabilities for evaluation only. Not to be used for production. Lite plan services are deleted after 30 days of inactivity.\n* Standard - The standard plan includes feature flags and property management capabilities. You can use simple and uniform REST APIs to configure, enable, segment, and monitor features to mobile devices and web applications.\n* Enterprise - The enterprise plan includes targeting segment in addition to the property management and feature flags that are found in the Standard plan. The enterprise plan now supports by using private endpoints.\n\n\n\nFor more information about App Configuration usage and billing, see [Usage and billing](https://cloud.ibm.com/docs/app-configuration?topic=app-configuration-ac-faqs-usage).\n5. Configure your resource by providing a Service name for your instance, or use the preset name.\n6. Select a resource group - The resource group selection helps how you want resources to be organized in your account. The resource group that you select cannot be changed after the service instance is created.\n7. Optionally, define Tags to help you to identify and organize the instance in your account. If your tags are billing related, consider writing tags as key:value pairs to help group-related tags, such as costctr:124.\n8. Optionally, define Access management tags that are needed to apply flexible access policies on specific resources. For example, access:dev, proj:version-1.\n9. If you selected the Enterprise plan, then specify the Service endpoints. The following options are available:\n\n\n\n* Public network - The public network service endpoints are accessible from anywhere on the internet.\n* Both Public & Private network - use of both public and private service endpoint network access.\n\n\n\n10. Accept the licensing agreements and terms by clicking the checkbox.\n11.", "title": "", "source": "https://cloud.ibm.com/docs/app-configuration?topic=app-configuration-ac-create-an-instance"}, {"document_id": "ibmcld_09813-0-1771", "score": 19.885765, "text": "\n\n\n\n\n\n\n  Service plans \n\nThis topic includes information about the IBM Cloud Monitoring service plans.\n\nWhen you provision an instance of the Monitoring service, you can choose any of the following service plans:\n\n\n\nTable 1. Service plans\n\n Plans                                       Plan ID                                 Plan Name                                   \n\n Lite                                        367a3918-9efc-43c5-bef9-20553051b7af    lite                                        \n Graduated tier                              231bb072-1b2f-4d7e-ae9e-9574d382be32    graduated-tier                              \n Graduated Tier - Sysdig Secure + Monitor    35784193-e918-42d9-9598-4e842ed75192    graduated-tier-sysdig-secure-plus-monitor   \n\n\n\nYou can provision a Monitoring instance with the Lite service plan to try out the Monitoring service for free for 30 days.\n\nThe Graduated tier service plan includes features that you can use to gain operational visibility into the performance and health of your applications, services, and platforms. It offers administrators, DevOps teams and developers full-stack telemetry with advanced features to monitor and troubleshoot, define alerts, and design custom dashboards.\n\nThe Graduated Tier - Sysdig Secure + Monitor service plan includes the same features that are available through the Graduated tier service plan and the [IBM Cloud Security and Compliance Center Workload Protection](https://cloud.ibm.com/docs/workload-protection) service that you can use to protect, monitor, and enhance forensic analysis of your pipeline and runtime components. Combining the monitoring features and the security features, DevOps teams can quickly troubleshoot, analyze, and perform forensics on an incident.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-service_plans"}, {"document_id": "ibmcld_13036-6759-8621", "score": 19.762117, "text": "\n* SERVICE_PLAN_NAME is the type of plan. Valid values are lite, 7-day, 14-day, 30-day\n* LOCATION is the region where the auditing instance is created. To get the latest list of locations that are available for the IBM Cloud Activity Tracker service, see [Locations](https://cloud.ibm.com/docs/services/activity-tracker?topic=activity-tracker-regions).\n* PRIVATE_ENDPOINT is either true or false. If true only [private endpoints](https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-endpoints) can be used to access the instance.\n\nUnless otherwise specified when provisioning an instance, the default is for the instance to be accessible by both public and private endpoints.\n\n\n\nFor example, to provision an instance with the 7 days retention plan that can be accessed only by private endpoints, run the following command:\n\nibmcloud resource service-instance-create my-instance logdnaat 7-day us-south -p '{\"private_endpoints_only\": true}'\n\nTo provision an instance with the 14 days retention plan that can be accessed only by both public and private endpoints, run one of the following commands:\n\nibmcloud resource service-instance-create my-instance logdnaat 14-day us-south -p '{\"private_endpoints_only\": false}'\n\nor\n\nibmcloud resource service-instance-create my-instance logdnaat 14-day us-south\n\n\n\n\n\n\n\n Step 2. Create the credentials for your instance \n\nRun the following command to create a service ID:\n\nibmcloud resource service-key-create NAME ROLE_NAME --instance-name SERVICE_INSTANCE_NAME\n\nWhere\n\n\n\n* SERVICE_INSTANCE_NAME is the name of the instance that you provisioned in the previous step.\n* NAME is the name of the service ID. Use the following format to name the key <SERVICE_INSTANCE_NAME>-key-admin\n* ROLE_NAME is the permission that you grant this service ID. Set it to Manager.\n\n\n\nFor example, you can run the following command:", "title": "", "source": "https://cloud.ibm.com/docs/services/activity-tracker?topic=activity-tracker-provision"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16727-1079289-1081125", "score": 18.060179, "text": "\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-1076793-1078629", "score": 18.060179, "text": "\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_01660-8584-10307", "score": 17.436148, "text": "\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accountfaqs"}, {"document_id": "ibmcld_01660-23838-25711", "score": 17.417974, "text": "\nFor more information, see [Adding orgs and spaces](https://cloud.ibm.com/docs/account?topic=account-orgsspacesuserscreateorg).\n\n\n\n\n\n Why do I get logged out of my account? \n\nThe administrator of your account has customized the duration of active and inactive accounts, which requires users to enter their credentials after a specific time. For more information, see [Managing user's login session durations](https://cloud.ibm.com/docs/account?topic=account-iam-work-sessions).\n\n\n\n\n\n Why can't I create a Lite account? \n\nBased on an update to our account registration that released starting 25 October 2021, new accounts are created as Pay-As-You-Go. As part of this update, you're asked to provide credit card information for identity verification. After you register and create your new account, you can access the full IBM Cloud catalog, including all Free and Lite plans. And, you get a $200 credit that you can use on products in the first 30 days. You pay only for billable services that you use, with no long-term contracts or commitments.\n\nIf you created a Lite account before 25 October 2021, you can continue working as you always have. However, you can go ahead and [upgrade to a Pay-As-You-Go account](https://cloud.ibm.com/docs/account?topic=account-accountfaqschangeacct) by adding your credit card information. This way, you can gain access to all Free service plans in the catalog.\n\n\n\n\n\n How do I see who created a service instance and when? \n\nFrom the [Resource list](https://cloud.ibm.com/resources), expand the appropriate section, and click the row for the instance that you want more details about. Additional details about the resource display including when the resource was created and by whom.\n\nFor classic infrastructure services, you can get similar information by using the [Audit log](https://cloud.ibm.com/docs/account?topic=account-audit-log).", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accountfaqs"}, {"document_id": "ibmcld_01660-7085-8964", "score": 16.983212, "text": "\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https://cloud.ibm.com/account/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https://cloud.ibm.com/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accountfaqs"}, {"document_id": "ibmcld_01705-13208-15001", "score": 16.835032, "text": "\nIf you created a Lite account before 25 October 2021, your account doesn't expire and you can work in IBM Cloud for free by accessing services with select Lite plans, which are displayed with a Lite tag ![Lite tag](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/Lite.svg) in the catalog. To gain access to all Free plans, you can go ahead and [upgrade to a Pay-As-You-Go account](https://cloud.ibm.com/docs/account?topic=account-accountfaqschangeacct) by adding your credit card information.\n\nStarting 25 October 2021, all new accounts are created as Pay-As-You-Go based on an update to our account registration process. As part of this update, you're asked to provide credit card information for identity verification. You have full access to the catalog, including all Free and Lite plans, and you get a $200 credit that you can apply in your first 30 days. You pay only for billable services that you use, with no long-term contracts or commitments.\n\nLite accounts have access to a single resource group that's created for you with the name Default. All of your service's instances are automatically added to this resource group. You can update the name of this resource group at any time. See [Renaming a resource group](https://cloud.ibm.com/docs/account?topic=account-rgsrename_rgs) for the detailed steps.\n\n\n\n What's available in a lite account? \n\nCheck out the following list of key features that are available in a Lite account:\n\n\n\n* The account is free - no credit card required.\n* The account never expires.\n* You receive email notifications about your account status and quota limits.\n* You can create one instance of any service in the [IBM Cloud catalog](https://cloud.ibm.com/catalog/?search=label:lite%20lite) that has a Lite plan.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accounts"}, {"document_id": "ibmcld_02143-0-1216", "score": 16.33684, "text": "\n\n\n\n\n\n\n  Why can't I create a new Lite plan instance? \n\nYou try to create more than one instance in your Lite account.\n\n  What\u2019s happening \n\nYou receive the following error message when you try to create a new Lite plan instance:\n\n> Unable to provision new Lite instance\n>\n> The account already has an instance created with the Lite plan\n\n  Why it\u2019s happening \n\nThere's a limit of one instance per Lite plan to ensure that these plans stay free. For more information about Lite account features, see [Lite account](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n\n  How to fix it \n\nYou can create more instances of the service by selecting one of the billable service plans, which are available in the billable accounts. To upgrade to a billable account from the console, go to Manage > Account in the IBM Cloud console, and select Account settings.\n\nIf you don't want to upgrade from a Lite account and are no longer using your existing Lite service instance, you can delete the existing Lite plan instance from the dashboard and then create a new instance. When you delete the Lite plan instance, all of the data that is associated with that instance is deleted and isn't recoverable.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-nosecondlite"}, {"document_id": "ibmcld_01705-2818-4572", "score": 15.841595, "text": "\n[Feature available](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/icon_enabled.svg) \n Invoiced on monthly consumption ![Feature available](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/icon_enabled.svg) \n\n\n\nNew accounts as of 25 October 2021 are created as Pay-As-You-Go or Subscription accounts. You're asked to provide credit card information for identity verification or a code for a purchased subscription. If you created an account before this date, you might be using a [Lite account](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount) and Lite pricing plans, which aren't affected by the recent account registraton update.\n\n\n\n\n\n Trial account \n\nTrial accounts offer timed access to a limited range of service plans and allow you to test out the platform without financial commitment. You can access Lite service plans and Free plans for a limited time with a trial account. To qualify for a trial account, go to [Harness the Power of IBM](https://ibm.biz/academic) and validate your institution credentials or reach out to your educational program or course leader. If you don't have an account, select 'Register with a Code' during IBM Cloud registration to apply a code. If you have an account, go to the [Account settings](https://cloud.ibm.com/account/settings) page in the console to apply the code.\n\nIf you upgrade your trial account to a Pay-As-You-Go account by entering a credit card, it can't be converted back to a trial account. IBM Cloud trial accounts are available for faculty and students at accredited academic institutions. Trial accounts expire after 30 days. Your account is deactivated when the trial period ends.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accounts"}, {"document_id": "ibmcld_07578-1075256-1077185", "score": 15.486175, "text": "\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel/close/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https://cloud.ibm.com/account/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https://cloud.ibm.com/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1077752-1079681", "score": 15.486175, "text": "\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel/close/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https://cloud.ibm.com/account/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https://cloud.ibm.com/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_11163-21956-23909", "score": 17.282877, "text": "\nUse feature and subscription codes to create new accounts\n: When you [register for a new IBM Cloud account](https://cloud.ibm.com/registration), you can use a feature code that you received from participating in a special event or a subscription code that you received by email. Instead of verifying your identity by entering your credit card information, click the option to Register with a code to complete the set up of your new account.\n\n\n\n\n\n\n\n February 2022 \n\n\n\n 28 February 2022 \n\n365 days of status history is now available\n: You can now easily view events that were completed in the past year on the IBM Cloud Status page. Previously, you could view only the history of completed events from the past month. For more information about the IBM Cloud Status page, see [Viewing cloud status](https://cloud.ibm.com/docs/get-support?topic=get-support-viewing-cloud-status).\n\n\n\n\n\n 7 February 2022 \n\nSupport for onboarding third-party services in Partner Center\n: Onboarding new services in the resource management console is no longer supported. You must use Partner Center to onboard new services to the IBM Cloud console. You can continue to manage existing services in the resource management console.\n\n\n\n\n\n\n\n December 2021 \n\n\n\n 17 December 2021 \n\nRestricting domains for account invitations\n: You can now restrict membership to your account based on the domain of the users by creating an allowlist. This way, only users with a specific domain or domains can be invited to the account. For more information, see [Restricting domains for account invitations](https://cloud.ibm.com/docs/account?topic=account-restrict-acct-invite).\n\n\n\n\n\n\n\n November 2021 \n\n\n\n 8 November 2021 \n\nData centers closed in 2021\n: The following list shows the locations with the associated data centers and specific PODs that were closed by 08 November 2021.\n\n\n\n* Dallas: DAL05 \u2013 POD2\n* Houston: HOU02\n* Melbourne: MEL01\n* Oslo: OSL01\n* Washington DC: WDC01 \u2013 POD3 and POD4", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-whatsnew"}, {"document_id": "ibmcld_01623-1601-3527", "score": 17.07059, "text": "\nGo to the [IBM Cloud login page](https://cloud.ibm.com/), and click Create an IBM Cloud account.\n2. Enter your IBMid email address. If you don't have an existing IBMid, an ID is created based on the email that you enter.\n3. Complete the remaining fields with your information.\n\nYou are prompted for your credit card information to verify your identity and secure your account. You can [try out IBM Cloud for free](https://cloud.ibm.com/docs/overview?topic=overview-tutorial-try-for-free) and pay only for the billable services that you choose to use, with no long-term contracts or commitments.\n4. Click Create account.\n5. Confirm your account by clicking the link in the confirmation email that's sent to your provided email address.\n\n\n\nSee [Account types](https://cloud.ibm.com/docs/account?topic=account-accounts) to compare and choose an account type.\n\n\n\n\n\n Personal use availability \n\n\n\n\n\n Personal use availability \n\nThe following table shows the countries where personal use of our platform that is not related to business, trade, craft, or professional purposes are not supported\n\nAfrica\n\nAsia\n\nEurope\n\n\n\nTable 2. Countries in Africa that are not supported\n\n Country \n\n Algeria \n Cameroon \n Canary Islands \n Egypt \n Ghana \n Ivory Coast \n Kenya \n Mauritania \n Nigeria \n Seychelles \n Tanzania \n Uganda \n\n\n\nIBM\u00ae Norway and IBM\u00ae Switzerland are able to contract with local customers to offer personal use accounts.\n\nTo work with a local Business Partner, go to the [IBM Business Partner Directory](https://www.ibm.com/partnerworld/bpdirectory/). Customers are not required to have a VAT ID to work with a local Business Partner.\n\n\n\n\n\n Using a federated ID \n\nA federated ID is an ID within a company's domain that is registered with IBM so that the domain and user credentials can be used to access IBM web applications. You can sign up for IBM Cloud with a federated ID only if your company is already registered with IBM.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-account-getting-started"}, {"document_id": "ibmcld_12559-6637-8921", "score": 16.68596, "text": "\nIf you want to assign a different user as the account owner, enter their IBMid in the Owner field. The account owner has full access to manage the account.\n5. Select Marketing as the parent of this account.\n6. Click Create.\n\n\n\nAfter you create the account, the account owner can log in to the account to invite other users and manage their access.\n\nRepeat the steps to create more accounts. As an example, the Example Corp enterprise has the following child account and parent account group hierarchy.\n\n\n\nTable 1. Child account and parent account group hierarchy\n\n Child Parent \n\n Print Marketing \n Frontend Engineering \n Backend Engineering \n Direct Sales \n Online Sales \n Enablement Sales \n\n\n\n\n\n\n\n Step 5: Explore subscriptions \n\nYou can explore subscriptions in the enterprise from the enterprise dashboard. Any existing subscriptions from accounts that are imported into the enterprise are moved to the enterprise account and added to the enterprise [credit pool](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-enterprisecredit-pool).\n\n\n\n1. Go back to the Enterprise dashboard by clicking Dashboard. In the Billing section, you can view available credit, remaining credit, and subscription expiration dates.\n2. To view details about all subscriptions in the enterprise, click View subscriptions.\n\nIn the Platform subscription section, you can view the subscription start date, end date, starting credit and available credit. To add more credit, you can purchase additional subscriptions and apply the subscription code.\n\n\n\n\n\n\n\n Step 6: Invite users to manage your enterprise \n\nIn a large organization like Example Corp., there are likely other people who you want to give access to manage the enterprise so they can do their jobs. In this case, you want to give department leads of the Marketing, Development, and Sales account groups access to manage their accounts and resource usage, and you want the Example Corp. financial officer to have access to view the entire enterprise's billing and usage. To give other users access, you invite them to the enterprise account and assign them the appropriate access.\n\nFirst, invite the department leads and assign them access.\n\n\n\n1. Go to the Enterprise dashboard by clicking Manage > Enterprise in the IBM Cloud console.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-tutorial&interface=ui"}, {"document_id": "ibmcld_00696-1740-4173", "score": 16.63619, "text": "\nWhen you log in, any of the following types of accounts might be associated with your user credentials:\n\n\n\n* Personal account\n* Corporate account\n* Corporate individual account\n\n\n\n\n\n Personal accounts \n\nTypically, each user has their own account that is their personal account. You can easily identify your personal account because it usually contains your name, for example, John Smith's Account.\n\nYou have full rights over all objects that are created in your personal account. You can invite other users to join your account, assign them rights over objects that you create, and assign them rights to create objects in your account. Because of these rights, the personal data of other users might be in your account, and your personal data might be in other user's accounts.\n\nIf you have permission to create an object in an account, you also have the right to modify and delete it, regardless of which account the object is stored in. When two users collaborate, they often share a personal account.\n\n\n\n\n\n Corporate accounts \n\nA corporate account is set up by your company. Typically, you are added automatically to the account, rather than being invited. Although corporate accounts provide users with a place to work, communicate, and share resources and charging, this set up is just a convention. A corporate account is really no different than a personal account. Objects that are created in a corporate account are associated with the account and users can be invited to the account.\n\nTeams of people who work for a corporation often collaborate by using a corporate account.\n\n\n\n\n\n Corporate individual accounts \n\nWhen you work for a corporation, the work in your account might be legally owned by the corporation. Many users who work for a corporation have a corporate individual account. If you log in to your account by using credentials that contain your corporation's name and also have what appears to be a personal account, the work within your personal account might belong to the corporation.\n\nA corporate individual account is no different from any other account. You can invite users to a corporate individual account and objects that are created in a corporate individual account are owned by the account.\n\nIf you work for a corporation that owns your work, a personal account that usually contains your name is considered a corporate individual account.\n\n\n\n\n\n\n\n Modifying, exporting, and deleting personal data", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-cd_personal_data"}, {"document_id": "ibmcld_01660-23838-25711", "score": 16.273235, "text": "\nFor more information, see [Adding orgs and spaces](https://cloud.ibm.com/docs/account?topic=account-orgsspacesuserscreateorg).\n\n\n\n\n\n Why do I get logged out of my account? \n\nThe administrator of your account has customized the duration of active and inactive accounts, which requires users to enter their credentials after a specific time. For more information, see [Managing user's login session durations](https://cloud.ibm.com/docs/account?topic=account-iam-work-sessions).\n\n\n\n\n\n Why can't I create a Lite account? \n\nBased on an update to our account registration that released starting 25 October 2021, new accounts are created as Pay-As-You-Go. As part of this update, you're asked to provide credit card information for identity verification. After you register and create your new account, you can access the full IBM Cloud catalog, including all Free and Lite plans. And, you get a $200 credit that you can use on products in the first 30 days. You pay only for billable services that you use, with no long-term contracts or commitments.\n\nIf you created a Lite account before 25 October 2021, you can continue working as you always have. However, you can go ahead and [upgrade to a Pay-As-You-Go account](https://cloud.ibm.com/docs/account?topic=account-accountfaqschangeacct) by adding your credit card information. This way, you can gain access to all Free service plans in the catalog.\n\n\n\n\n\n How do I see who created a service instance and when? \n\nFrom the [Resource list](https://cloud.ibm.com/resources), expand the appropriate section, and click the row for the instance that you want more details about. Additional details about the resource display including when the resource was created and by whom.\n\nFor classic infrastructure services, you can get similar information by using the [Audit log](https://cloud.ibm.com/docs/account?topic=account-audit-log).", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accountfaqs"}, {"document_id": "ibmcld_12546-8763-10375", "score": 16.186644, "text": "\n6. Click Create.\n\n\n\nAfter you create the account, the account owner can log in to the account to invite other users and manage their access.\n\n\n\n\n\n Creating accounts by using the CLI \n\n\n\n1. If you want to add the account to an account group, find the names and IDs of existing account groups.\n\nibmcloud enterprise account-groups --recursive\n2. Create the account by running the following command. If you don't specify a parent account group, the account is added directly under the enterprise. To make a different user the account owner, specify their IBMid on the --owner option.\n\nibmcloud enterprise account-create NAME\n[--parent-account-group ACCOUNT_GROUP_NAME] [--owner USER_ID]\n\n\n\n\n\n\n\n Creating accounts by using the API \n\nTo create a new account in the enterprise, call the Enterprise Management API as shown in the following sample request, replacing the IAM token and ID variables with the values from your enterprise. For detailed information about the API, see [Enterprise Management API](https://cloud.ibm.com/apidocs/enterprise-apis/enterprisecreate-a-new-account-in-an-enterprise).\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -X POST \"https://enterprise.cloud.ibm.com/v1/accounts\n-H \"Authorization: Bearer <IAM_Token>\"\n-H 'Content-Type: application/json'\n-d '{\n\"parent\":\n\"crn:v1:bluemix:public:enterprise::a/$ENTERPRISE_ACCOUNT_ID::account-group:$ACCOUNT_GROUP_ID\",\n\"name\": \"Example Account\",\n\"owner_iam_id\": \"$OWNER_IAM_ID\"\n}'\n\nCreateAccountOptions createAccountOptions = new CreateAccountOptions.Builder()\n.parent(parentCRN)\n.name(\"Example Account\")\n.ownerIamId(enterpriseAccountIamId)\n.build();", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-add"}, {"document_id": "ibmcld_10906-6063-7827", "score": 16.048353, "text": "\nThe email address that is used to register becomes the account owner, but you can change this if required later on by following the steps in [Transferring ownership of your account](https://cloud.ibm.com/docs/account?topic=account-transfer&interface=ui).<br><br>When setting up an account for your company or organization, it is best to use a functional ID, some teams call them service accounts, associated with your company. Keep in mind that you will need to monitor for automated emails sent to this email address for warnings about service usage, services being deprecated, new services available, and more.<br><br>When you log in to the account for the first time, you are required to provide a credit card or subscription code to complete your account set up. Later, you can add users by inviting them to the account or by federating to your own corporate directory.<br><br>Users that are added to your account are not required to create their own account.<br><br>For more account-related FAQs, visit [FAQ library for managing your account, resources, and access](https://cloud.ibm.com/docs?tab=faqs&tags=account). \n <br><br> * Set up SAML federation<br><br><br> By default, when you create an account you use an IBMid for user identity. IBMid is the ID as a Service (IDaaS) from IBM\u00ae used to access IBM web-based services, including IBM Cloud resources. The IBMid is based on your company's email address and a password that is managed by IBMid. IBMid allows you to federate to your own corporate directory or a third-party Identity Provider (IdP) service that you might already be using such as Okta.<br><br>Federating to your own directory simplifies the process of adding users to your account as they will not require an IBMid with a separate password.", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-get-started-checklist"}, {"document_id": "ibmcld_01705-2818-4572", "score": 15.540028, "text": "\n[Feature available](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/icon_enabled.svg) \n Invoiced on monthly consumption ![Feature available](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/icon_enabled.svg) \n\n\n\nNew accounts as of 25 October 2021 are created as Pay-As-You-Go or Subscription accounts. You're asked to provide credit card information for identity verification or a code for a purchased subscription. If you created an account before this date, you might be using a [Lite account](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount) and Lite pricing plans, which aren't affected by the recent account registraton update.\n\n\n\n\n\n Trial account \n\nTrial accounts offer timed access to a limited range of service plans and allow you to test out the platform without financial commitment. You can access Lite service plans and Free plans for a limited time with a trial account. To qualify for a trial account, go to [Harness the Power of IBM](https://ibm.biz/academic) and validate your institution credentials or reach out to your educational program or course leader. If you don't have an account, select 'Register with a Code' during IBM Cloud registration to apply a code. If you have an account, go to the [Account settings](https://cloud.ibm.com/account/settings) page in the console to apply the code.\n\nIf you upgrade your trial account to a Pay-As-You-Go account by entering a credit card, it can't be converted back to a trial account. IBM Cloud trial accounts are available for faculty and students at accredited academic institutions. Trial accounts expire after 30 days. Your account is deactivated when the trial period ends.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accounts"}, {"document_id": "ibmcld_01802-0-2084", "score": 15.0280695, "text": "\n\n\n\n\n\n\n  Managing multiple accounts with your IBMid \n\nAs the owner or administrator of an IBM Cloud\u00ae account, you can create and manage multiple accounts that are associated with a single IBMid to access and manage details about each account from one email address. For example, you might be responsible for managing several departments in your company that have different billing requirements. By creating multiple accounts, you can switch between them without having to log in and out of the IBM Cloud console each time.\n\nOnly Pay-As-You-Go and Subscription accounts can create multiple accounts by using one email. Lite accounts can create only one account per email.\n\nManaging multiple accounts with a single IBMid is different from using an enterprise account. With an enterprise account, you can have several child accounts attached to a parent account, and all associated charges roll up to the parent account in the enterprise. See [What is an enterprise?](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-what-is-enterprise) for more information.\n\nTo create multiple accounts associated with your IBMid, complete the following steps:\n\n\n\n1.  In the console, go to the Avatar icon ![Avatar icon](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/i-avatar-icon.svg) > Log out, and click Log out.\n2.  From the login screen, click Create an account.\n3.  From the registration page, enter your email address, complete the necessary information, and click Create account.\n\n\n\nAfter you create the accounts, you can switch to a specific account from the console menu bar as shown in the following image.\n\nZoom\n\n![A screen capture of the account selector in the console menu bar. The account selector displays the account name and account number, and you select the current account to display a list of other accounts that you can access.](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/account/images/account-faq.svg)\n\nFigure 1. Using the account selector to switch accounts\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-create-mult-accounts"}, {"document_id": "ibmcld_12553-1374-3480", "score": 14.876033, "text": "\nTo create an account group, you need the Administrator or Editor role on the Enterprise service in the enterprise account.\n\n\n\n Creating account groups in the console \n\n\n\n1. From the Enterprise dashboard in the IBM Cloud console, click Accounts to view the accounts and account groups in the enterprise.\n2. In the Account groups section, click Create.\n3. Enter a name for the account group that reflects the accounts that it will contain. See [How can I use an enterprise?](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-what-is-enterpriseenterprise-use-cases) for examples of how you might organize accounts.\n4. If you want an enterprise user other than yourself to be the primary contact for the account group, select their IBMid from the Contact menu. If a user that you want to assign as the contact isn't in the enterprise, first invite the user to the enterprise account. See [Inviting users](https://cloud.ibm.com/docs/account?topic=account-iamuserinv) for more information.\n\nThe contact is different from an account owner in that they don't have any additional access within the account group or its accounts. The user that you select as a contact acts as a focal point for any account group issues. For example, if a financial officer notices that the account group's usage costs are unexpectedly high, they might notify the account group contact.\n5. If you want the account group to be in a different part of your enterprise hierarchy, select a different parent.\n\nAccount groups can't be deleted or moved from where you create them.\n6. Click Create.\n\n\n\nTo create a new tier in your enterprise hierarchy, create new account groups within the account group. You can move accounts that are already in the enterprise into the account group, or you can import or create accounts within it. See [Adding accounts to an enterprise](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-add) for more information about importing and creating accounts.\n\n\n\n\n\n Creating account groups by using the CLI \n\nCreate an account group by running the following command.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-organize"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01660-8584-10307", "score": 32.017864, "text": "\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accountfaqs"}, {"document_id": "ibmcld_03729-3519-5413", "score": 31.917088, "text": "\nThese resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings\n* Encrypted data storage limit, for example 1 GB\n* Provisioned throughput capacity\n\n\n\nYou can easily find services for Lite plans in the catalog. By default, all services with a Lite plan are displayed with a Lite tag ![Lite tag](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/Lite.svg). Select a service to view the quota details for the associated Lite plan.\n\n\n\n\n\n Charges for compute resources \n\nYou're charged for the time that your apps run and the memory that's used in GB-hours. GB-hours is the calculation of the number of application instances that are multiplied by the memory per instance and by the hours that the instances run. You can customize the number of instances and the amount of memory per instance based on your needs. You can also add memory or instances to scale for more users. To get the amount charged, take your application instances that are multiplied by memory per instance and by hours running.\n\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges"}, {"document_id": "ibmcld_16727-1079289-1081125", "score": 30.395494, "text": "\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-1076793-1078629", "score": 30.395494, "text": "\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_01447-9266-11226", "score": 28.788301, "text": "\nIf you're on the standard plan, you're charged by GB of usage per month. The first 5 GB each month is free. If you're on the free plan, you can pull images from your namespace until you reach the quota limit for the free plan.\n\nPull traffic across public connections counts toward usage and quota. Pull traffic across private connections doesn't count.\n\nThe following example is for the standard plan:\n: In the month, you pulled images that contain layers with a total size of 14 GB. Your monthly usage is calculated as shown in the following example:\n\nIn the standard plan, the first 5 GB per month is free, so you get charged for 9 GB (14 GB - 5 GB).\n\n\n\n\n\n\n\n Quota limits for storage and pull traffic \n\nDepending on the service plan that you choose, you can push and pull images to and from your namespace until you reach your plan-specific or custom quota limits for each region.\n\n\n\n Storage quota limits \n\nWhen you reach or exceed the quota limits for your plan, you can't push any images to the namespaces in your IBM Cloud account until you complete one of the following tasks.\n\n\n\n* [Free up space by removing images](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_quotaregistry_quota_freeup) from your namespaces.\n* [Upgrade to the standard plan](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_plan_upgrade).\n* If you set quota limits for storage in your free or standard plan, you can also [increase this quota limit](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_quotaregistry_quota_set) to enable the pushing of new images again.\n\n\n\nThe following example is for the standard plan:\n: Your current quota limit for storage is set to 1 GB. All private images that are stored in the namespaces of your IBM Cloud account already use 900 MB of this storage. You have 100 MB storage available until you reach your quota limit. One user wants to push an image with a size of 2 GB on the local computer.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overview"}, {"document_id": "ibmcld_01468-1672-3502", "score": 28.661215, "text": "\nIf you are on the free plan, you cannot set your quota to an amount that exceeds the free tier. The free tier allowance for storage is 512 MB and traffic is 5120 MB.\n\nibmcloud cr quota-set --traffic <traffic_quota> --storage <storage_quota>\n\nExample to set your quota limit for storage to 600 megabytes, and the pull traffic to 7000 megabytes:\n\nibmcloud cr quota-set --storage 600 --traffic 7000\n\n\n\n\n\n\n\n Reviewing quota limits and usage \n\nYou can review your quota limits and check your current storage and pull traffic usage for your account.\n\n\n\n1. Log in to IBM Cloud.\n\nibmcloud login\n2. Review your current quota limits for storage and pull traffic.\n\nibmcloud cr quota\n\nYour output looks similar to the following example.\n\nGetting quotas and usage for the current month, for account '<account_owner> Account'...\n\nQUOTA LIMIT USED\nPull traffic 5.1 GB 0 B\nStorage 512 MB 511 MB\n\nOK\n\n\n\n\n\n\n\n Staying within quota limits \n\nIf you exceed the quota limits that are set for your IBM Cloud account, you can free up storage and change your service plan or quota limits so that you can continue pushing and pulling images to and from your namespace.\n\nFrom 1 February 2022, both [tagged](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_tag) and [untagged](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_untagged) images are charged for.\n\nTo free up image storage in your IBM Cloud account, complete the following steps.\n\nDepending on the size of the image, it might take a while for the image to be removed and for the storage to be available.\n\n\n\n1. Find the names of the images that you want to remove.\n\n\n\n* To list only tagged images, run the [ibmcloud cr image-list](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregclibx_cr_image_list) command.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_quota"}, {"document_id": "ibmcld_00558-20425-22479", "score": 28.171612, "text": "\nThe data storage that is measured for billable purposes for an IBM Cloudant instance is inclusive of both JSON data, indexes, and attachments.\n\n\n\n Data storage included \n\nThis value is the storage capacity that is included in the plan. The Lite plan has a hard limit of 1 GB allowed. The paid Standard plan includes 20 GB for free and any additional data that is stored is metered for billing.\n\n\n\n\n\n Data overage \n\nAll Lite and Standard plans are monitored for disk space used. When you use more data than the plan allocates, you can expect the conditions that are described in the following sections to apply:\n\n\n\n Lite plan \n\n\n\n* Disk usage is capped on the Lite plan at 1 GB.\n* After you reach the cap, you receive a warning on the IBM Cloudant Dashboard and can't write new data. If you try to write new data, a 402: payment required response occurs.\n* To write new data, you must either upgrade to the Standard plan or delete data, and wait until the next check runs for your account to be reactivated.\n\n\n\n\n\n\n\n Standard plan \n\n\n\n* If the account uses more than the 20 GB of storage that is included in the Standard plan, the excess is considered \"disk overage\". Overage causes the account to be billed at the indicated price for each extra GB used beyond the plan allocation.\n* The cost for the amount of disk overage is calculated on an hourly basis.\n\n\n\nFor example, assume your Standard plan increases disk usage to 107 GB for half a day (12 hours). This change means that your instance caused overflow of 87 GB more than the 20 GB plan allocation, for 12 hours. As the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-public"}, {"document_id": "ibmcld_12904-20515-22569", "score": 28.171612, "text": "\nThe data storage that is measured for billable purposes for an IBM Cloudant instance is inclusive of both JSON data, indexes, and attachments.\n\n\n\n Data storage included \n\nThis value is the storage capacity that is included in the plan. The Lite plan has a hard limit of 1 GB allowed. The paid Standard plan includes 20 GB for free and any additional data that is stored is metered for billing.\n\n\n\n\n\n Data overage \n\nAll Lite and Standard plans are monitored for disk space used. When you use more data than the plan allocates, you can expect the conditions that are described in the following sections to apply:\n\n\n\n Lite plan \n\n\n\n* Disk usage is capped on the Lite plan at 1 GB.\n* After you reach the cap, you receive a warning on the IBM Cloudant Dashboard and can't write new data. If you try to write new data, a 402: payment required response occurs.\n* To write new data, you must either upgrade to the Standard plan or delete data, and wait until the next check runs for your account to be reactivated.\n\n\n\n\n\n\n\n Standard plan \n\n\n\n* If the account uses more than the 20 GB of storage that is included in the Standard plan, the excess is considered \"disk overage\". Overage causes the account to be billed at the indicated price for each extra GB used beyond the plan allocation.\n* The cost for the amount of disk overage is calculated on an hourly basis.\n\n\n\nFor example, assume your Standard plan increases disk usage to 107 GB for half a day (12 hours). This change means that your instance caused overflow of 87 GB more than the 20 GB plan allocation, for 12 hours. As the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3.", "title": "", "source": "https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-ibm-cloud-public"}, {"document_id": "ibmcld_00558-1499-3456", "score": 28.083904, "text": "\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-public"}, {"document_id": "ibmcld_07578-474233-476319", "score": 27.568274, "text": "\nHere you can see the total charges and usage for the month by service, plan, or instance. Only the hourly costs that are accrued for the current month and time are available. At the end of the month, you can see the average provisioned throughput capacity for each field: LOOKUPS_PER_MONTH, WRITES_PER_MONTH, and QUERIES_PER_MONTH.\n\n\n\n* Can I change my capacity setting?\n\nYou can change your provisioned throughput capacity and see your current capacity settings in the IBM Cloudant Dashboard. Launch IBM Cloudant Dashboard > Account > Capacity to view and change your provisioned throughput capacity and see the hourly and approximate monthly costs. You can also use the IBM Cloud\u00ae pricing calculator to see estimates in other currencies.\n* How do I know I exceeded the capacity limit that I set?\n\nThe Lite plan includes 1 GB of storage. If you exceed the limit, IBM Cloudant blocks your account from writing new data until you delete enough data to be under the 1-GB limit, or upgrade to a higher plan.\n\nThe first 20 GB of storage comes free with the Standard plan. You can store as much data as you want. Any storage over the 20 GB limit costs $0.0014 per GB per hour, which is approximately $1 per GB per month.\n* Where can I see my usage data?\n\nYou can see your current and historical usage bills in the IBM Cloud Dashboard. Go to Manage > Billing and usage > Usage. Here you can see the total charges and usage for the month by service, plan, or instance. Only the hourly costs that are accrued for the current month and time are available. At the end of the month, you can see the average provisioned throughput capacity for each field: LOOKUPS_PER_MONTH, WRITES_PER_MONTH, and QUERIES_PER_MONTH.\n* Provisioned throughput capacity model FAQ\n\n Provisioned throughput capacity model FAQ \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae calculates your provisioned throughput capacity based on these operation types: Read, Write, and Global Query.\n\n\n\nIBM Cloudant calculates provisioned throughput capacity by totaling the usage for each request class per second, where 1 second is a sliding window.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_12824-7-1978", "score": 21.573702, "text": "\nFAQs for migrated products \n\nFAQs about products that are migrated from the Resource Management Console might include questions about Lite plans, changing pricing plans, and brokers connected to approved pricing plans.\n\nTo find all FAQs for IBM Cloud, see our [FAQ library](https://cloud.ibm.com/docs/faqs).\n\n\n\n Why can't I add new block tier usage-based plans? \n\nBlock tier pricing plans are not currently supported in Partner Center. If you set up a block tier pricing plan in the Resource Management Console and the plan was approved and published, no changes have been made and it was migrated as-is with your product. However, you can't edit the plan or set up a new block tier pricing plan. If you have any questions, open a support case. For information about opening a support case, see [Creating a Partner Center support case](https://cloud.ibm.com/docs/sell?topic=sell-get-pc-supportpc-support-case).\n\n\n\n\n\n What changed with Lite plan support? \n\nLite plans are not supported in Partner Center. You can create a new free plan, and all users with Pay-As-You-Go and Subscription accounts can try out your product for free.\n\nIf you set up a Lite plan in the resource management console, and it was approved and published, no changes have been made and it was migrated as-is with your product. If you need to change a published pricing plan, open a support case. For information about opening a support case, see [Creating a Partner Center support case](https://cloud.ibm.com/docs/sell?topic=sell-get-pc-supportpc-support-case).\n\n\n\n\n\n Can I add a broker per location? \n\nNo. Brokers are added per pricing plan, not per location. And, brokers can't be disconnected from already approved plans.\n\n\n\n\n\n Can I set different locations per plan for a single product? \n\nYes. But, all plans for a single product must be set as either global or per location. Therefore, you can't have a plan that is set to global and then another plan set to be available for specific regions.", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-migrated-products"}, {"document_id": "ibmcld_16727-1079289-1081125", "score": 20.893932, "text": "\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-1076793-1078629", "score": 20.893932, "text": "\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_13336-1484-3613", "score": 20.75882, "text": "\n* Use of all available models (same as the Lite plan).\n* Unlimited creation and use of custom language and custom acoustic models at no extra charge.\n* A maximum of one hundred concurrent transcription requests from all interfaces, WebSocket and HTTP, combined.\n\n\n\nThe plan uses a simple tiered pricing model to give high-volume users further discounts as they use the service more heavily. Pricing is based on the aggregate number of minutes of audio that you recognize per month:\n\n\n\n* Users who recognize 1 to 999,999 minutes of audio in a given month pay $0.02 (USD) per minute of audio for that month.\n* Users who recognize at least 1,000,000 minutes of audio in a given month pay $0.01 (USD) per minute of audio for that month.\n\n\n\nThe Plus plan is intended for small businesses. It is also a good choice for large enterprises that want to develop and test larger applications before considering moving to a Premium plan. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https://cloud.ibm.com/catalog/speech-to-text).\n\n\n\n\n\n Can I continue to use the Speech to Text Standard plan? \n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https://cloud.ibm.com/catalog/speech-to-text). They will continue to have access to all of their settings and custom models after upgrading. And, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n\n\n\n\n\n What pricing plan do I need to use the service's customization interface? \n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n\n\n\n\n\n How do I upgrade from the Lite plan to the Plus plan?", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-faq-pricing"}, {"document_id": "ibmcld_01660-8584-10307", "score": 20.692663, "text": "\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accountfaqs"}, {"document_id": "ibmcld_02660-1509-3609", "score": 20.385422, "text": "\nCurrently, Dallas (us-south), Washington DC (us-east), London (eu-gb), and Sydney (au-syd) regions are supported.\n4. Select a pricing plan - Based on your business requirements, select a pricing plan: Lite, Standard, and Enterprise.\n\n\n\n* Lite - Includes all App Configuration capabilities for evaluation only. Not to be used for production. Lite plan services are deleted after 30 days of inactivity.\n* Standard - The standard plan includes feature flags and property management capabilities. You can use simple and uniform REST APIs to configure, enable, segment, and monitor features to mobile devices and web applications.\n* Enterprise - The enterprise plan includes targeting segment in addition to the property management and feature flags that are found in the Standard plan. The enterprise plan now supports by using private endpoints.\n\n\n\nFor more information about App Configuration usage and billing, see [Usage and billing](https://cloud.ibm.com/docs/app-configuration?topic=app-configuration-ac-faqs-usage).\n5. Configure your resource by providing a Service name for your instance, or use the preset name.\n6. Select a resource group - The resource group selection helps how you want resources to be organized in your account. The resource group that you select cannot be changed after the service instance is created.\n7. Optionally, define Tags to help you to identify and organize the instance in your account. If your tags are billing related, consider writing tags as key:value pairs to help group-related tags, such as costctr:124.\n8. Optionally, define Access management tags that are needed to apply flexible access policies on specific resources. For example, access:dev, proj:version-1.\n9. If you selected the Enterprise plan, then specify the Service endpoints. The following options are available:\n\n\n\n* Public network - The public network service endpoints are accessible from anywhere on the internet.\n* Both Public & Private network - use of both public and private service endpoint network access.\n\n\n\n10. Accept the licensing agreements and terms by clicking the checkbox.\n11.", "title": "", "source": "https://cloud.ibm.com/docs/app-configuration?topic=app-configuration-ac-create-an-instance"}, {"document_id": "ibmcld_07152-7-1723", "score": 20.258484, "text": "\nDiscovery pricing plans \n\nIBM Watson\u2122 Discovery offers three plans -- Lite, Advanced, and Premium -- that provide different levels of resources and capabilities to suit your needs.\n\nFor more information about Premium plans that were created after 16 July 2020 or about Plus plans (including Plus Trial), see [these docs](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-pricing-plans).\n\nPrivate data use cases have the following features, limits, and prices:\n\n\n\n Lite \n\n\n\n Size Number of Docs* Price \n\n N/A 1,000 docs total Free \n\n\n\nThe Lite plan is a starter plan, so do not use it in your production environment. When you upgrade to a paid plan, you can keep all ingested documents. Lite plan instances are deleted after 30 days of inactivity.\n\nAttributes:\n\n\n\n* 1 environment\n* Up to 2 collections\n* Free NLU enrichments**\n\n\n\nAdditional options:\n[Custom Models](https://cloud.ibm.com/docs/discovery?topic=discovery-integrating-with-wks):\nOne IBM Watson\u2122 Knowledge Studio model included. Additional models: Not available\n[Element Classification](https://cloud.ibm.com/docs/discovery?topic=discovery-element-classification)***: 500 pages included per month. Additional pages: Not available\n[News Queries](https://cloud.ibm.com/docs/discovery?topic=discovery-watson-discovery-news): 200 News queries included per month. Additional queries: Not available\n[Query Expansions](https://cloud.ibm.com/docs/discovery?topic=discovery-query-conceptsquery-expansion): 500 query expansions with 1,000 total terms. Additional expansions: Not available\n[Document splitting](https://cloud.ibm.com/docs/discovery?topic=discovery-configservicedoc-segmentation): 250 segments per plan. Additional segments: Not available", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-discovery-pricing-plans"}, {"document_id": "ibmcld_12838-6162-8037", "score": 19.937683, "text": "\nClick the IBM Digital Platform Reseller Agreement link to review the agreement.\n5. Select I read and agree to the IBM Digital Platform Reseller Agreement, and click Save.\n\n\n\n\n\n\n\n\n\n\n\n Adding pricing plans \n\nYou can choose to add free and paid pricing plans. Ensure that you review and finalize all details of the pricing plan before you submit it. Changing a submitted pricing plan can take at least a full billing cycle to change, and you must open a support case to change a published pricing plan. For more information on how to change a submitted pricing plan, see [Changing a pricing plan](https://cloud.ibm.com/docs/sell?topic=sell-change-plan).\n\nYou must complete all of the prerequisites from the Before you begin section to finalize a pricing plan.\n\n\n\n Adding a free plan \n\nBy adding a free plan, you are indicating that your product does not require any payment or license to use. To add a free plan for your service, complete the following steps:\n\n\n\n1. In the IBM Cloud console, click the Navigation Menu icon ![Navigation Menu icon](https://cloud.ibm.com/docs-content/v1/content/ff5860bfede49db3197c4bbba7f7123769bdc068/icons/icon_hamburger.svg) > Partner Center > Sell > My products.\n2. Select the product that you're onboarding, and click Pricing.\n3. Click Add plan.\n4. Select Free from the Type section.\n5. Enter a name for your new plan.\n6. Describe the details of your plan.\n7. Choose the locations where your plan is available. All plans for a product use either global or per location. By selecting per location, you can specify different regions or data centers for each plan that you add.\n8. Link a broker to the plan.\n\nIf you haven't finished adding a broker to your account, you will not see this option, and you can continue and save your pricing plan. However, you can't complete your pricing plan until the broker is added and linked to your plan.\n9.", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-service-pricing-info"}, {"document_id": "ibmcld_07152-7168-8788", "score": 19.844992, "text": "\nPremium \n\nPremium plans offer developers and organizations a single tenant instance of one or more Watson services for better isolation and security. These plans offer compute-level isolation on the existing shared platform, as well as end-to-end encrypted data while in transit and at rest.\n\nFor more information, or to purchase a Premium plan, contact [Sales](https://ibm.biz/contact-wdc-premium).\n\n\n\n\n\n Additional information \n\nFor information about calculating costs, see the [IBM Cloud Pricing Calculator](https://cloud.ibm.com/estimator/review).\n\nFor additional pricing information, see the [Discovery catalog](https://cloud.ibm.com/catalog/services/discovery).\n\n\n\n\n\n Notes for Customers with Existing Plans \n\n\n\n* Beginning 1 August 2018, your billing and usage is based on this pricing plan.\n* The Lite plan is now reduced from 2,000 documents/400 Discovery News queries per month to 1,000 documents/200 Discovery News queries per month. If you already exceeded the new Lite plan limits, you cannot add any more documents. However, you can continue using it or upgrade to an Advanced or Premium plan.\n* The Standard plan is retired and is no longer available to new users. If you are currently on an existing Standard plan, you can continue using it or upgrade to an Advanced or Premium plan.\n* The Advanced and Premium plans are now based on document tiers. They are no longer based on document hours. Your monthly bill will not fluctuate, based on the number of documents, unless you switch between tiers.\n* Premium customers, contact [Sales](https://ibm.biz/contact-wdc-premium) for details on billing changes.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-discovery-pricing-plans"}, {"document_id": "ibmcld_07578-45764-47767", "score": 19.443087, "text": "\nYou must use a paid plan to use customization.\n\nThe Lite plan is intended for any user who wants to try out the service before committing to a purchase. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https://%7BDomainName%7D/catalog/speech-to-text). Services that are created with the Lite plan are deleted after 30 days of inactivity.\n* What is the price for using the Speech to Text Plus plan?\n\nThe Plus plan provides access to all of the service's features:\n\n\n\n* Use of all available models (same as the Lite plan).\n* Unlimited creation and use of custom language and custom acoustic models at no extra charge.\n* A maximum of one hundred concurrent transcription requests from all interfaces, WebSocket and HTTP, combined.\n\n\n\nThe plan uses a simple tiered pricing model to give high-volume users further discounts as they use the service more heavily. Pricing is based on the aggregate number of minutes of audio that you recognize per month:\n\n\n\n* Users who recognize 1 to 999,999 minutes of audio in a given month pay $0.02 (USD) per minute of audio for that month.\n* Users who recognize at least 1,000,000 minutes of audio in a given month pay $0.01 (USD) per minute of audio for that month.\n\n\n\nThe Plus plan is intended for small businesses. It is also a good choice for large enterprises that want to develop and test larger applications before considering moving to a Premium plan. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https://%7BDomainName%7D/catalog/speech-to-text).\n* Can I continue to use the Speech to Text Standard plan?\n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https://%7BDomainName%7D/catalog/speech-to-text).", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16727-1079289-1081125", "score": 20.756508, "text": "\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-1076793-1078629", "score": 20.756508, "text": "\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_01660-8584-10307", "score": 20.729652, "text": "\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accountfaqs"}, {"document_id": "ibmcld_07152-7-1723", "score": 18.22048, "text": "\nDiscovery pricing plans \n\nIBM Watson\u2122 Discovery offers three plans -- Lite, Advanced, and Premium -- that provide different levels of resources and capabilities to suit your needs.\n\nFor more information about Premium plans that were created after 16 July 2020 or about Plus plans (including Plus Trial), see [these docs](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-pricing-plans).\n\nPrivate data use cases have the following features, limits, and prices:\n\n\n\n Lite \n\n\n\n Size Number of Docs* Price \n\n N/A 1,000 docs total Free \n\n\n\nThe Lite plan is a starter plan, so do not use it in your production environment. When you upgrade to a paid plan, you can keep all ingested documents. Lite plan instances are deleted after 30 days of inactivity.\n\nAttributes:\n\n\n\n* 1 environment\n* Up to 2 collections\n* Free NLU enrichments**\n\n\n\nAdditional options:\n[Custom Models](https://cloud.ibm.com/docs/discovery?topic=discovery-integrating-with-wks):\nOne IBM Watson\u2122 Knowledge Studio model included. Additional models: Not available\n[Element Classification](https://cloud.ibm.com/docs/discovery?topic=discovery-element-classification)***: 500 pages included per month. Additional pages: Not available\n[News Queries](https://cloud.ibm.com/docs/discovery?topic=discovery-watson-discovery-news): 200 News queries included per month. Additional queries: Not available\n[Query Expansions](https://cloud.ibm.com/docs/discovery?topic=discovery-query-conceptsquery-expansion): 500 query expansions with 1,000 total terms. Additional expansions: Not available\n[Document splitting](https://cloud.ibm.com/docs/discovery?topic=discovery-configservicedoc-segmentation): 250 segments per plan. Additional segments: Not available", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-discovery-pricing-plans"}, {"document_id": "ibmcld_13336-1484-3613", "score": 17.475712, "text": "\n* Use of all available models (same as the Lite plan).\n* Unlimited creation and use of custom language and custom acoustic models at no extra charge.\n* A maximum of one hundred concurrent transcription requests from all interfaces, WebSocket and HTTP, combined.\n\n\n\nThe plan uses a simple tiered pricing model to give high-volume users further discounts as they use the service more heavily. Pricing is based on the aggregate number of minutes of audio that you recognize per month:\n\n\n\n* Users who recognize 1 to 999,999 minutes of audio in a given month pay $0.02 (USD) per minute of audio for that month.\n* Users who recognize at least 1,000,000 minutes of audio in a given month pay $0.01 (USD) per minute of audio for that month.\n\n\n\nThe Plus plan is intended for small businesses. It is also a good choice for large enterprises that want to develop and test larger applications before considering moving to a Premium plan. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https://cloud.ibm.com/catalog/speech-to-text).\n\n\n\n\n\n Can I continue to use the Speech to Text Standard plan? \n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https://cloud.ibm.com/catalog/speech-to-text). They will continue to have access to all of their settings and custom models after upgrading. And, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n\n\n\n\n\n What pricing plan do I need to use the service's customization interface? \n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n\n\n\n\n\n How do I upgrade from the Lite plan to the Plus plan?", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-faq-pricing"}, {"document_id": "ibmcld_12824-7-1978", "score": 16.78659, "text": "\nFAQs for migrated products \n\nFAQs about products that are migrated from the Resource Management Console might include questions about Lite plans, changing pricing plans, and brokers connected to approved pricing plans.\n\nTo find all FAQs for IBM Cloud, see our [FAQ library](https://cloud.ibm.com/docs/faqs).\n\n\n\n Why can't I add new block tier usage-based plans? \n\nBlock tier pricing plans are not currently supported in Partner Center. If you set up a block tier pricing plan in the Resource Management Console and the plan was approved and published, no changes have been made and it was migrated as-is with your product. However, you can't edit the plan or set up a new block tier pricing plan. If you have any questions, open a support case. For information about opening a support case, see [Creating a Partner Center support case](https://cloud.ibm.com/docs/sell?topic=sell-get-pc-supportpc-support-case).\n\n\n\n\n\n What changed with Lite plan support? \n\nLite plans are not supported in Partner Center. You can create a new free plan, and all users with Pay-As-You-Go and Subscription accounts can try out your product for free.\n\nIf you set up a Lite plan in the resource management console, and it was approved and published, no changes have been made and it was migrated as-is with your product. If you need to change a published pricing plan, open a support case. For information about opening a support case, see [Creating a Partner Center support case](https://cloud.ibm.com/docs/sell?topic=sell-get-pc-supportpc-support-case).\n\n\n\n\n\n Can I add a broker per location? \n\nNo. Brokers are added per pricing plan, not per location. And, brokers can't be disconnected from already approved plans.\n\n\n\n\n\n Can I set different locations per plan for a single product? \n\nYes. But, all plans for a single product must be set as either global or per location. Therefore, you can't have a plan that is set to global and then another plan set to be available for specific regions.", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-migrated-products"}, {"document_id": "ibmcld_07152-7168-8788", "score": 16.547808, "text": "\nPremium \n\nPremium plans offer developers and organizations a single tenant instance of one or more Watson services for better isolation and security. These plans offer compute-level isolation on the existing shared platform, as well as end-to-end encrypted data while in transit and at rest.\n\nFor more information, or to purchase a Premium plan, contact [Sales](https://ibm.biz/contact-wdc-premium).\n\n\n\n\n\n Additional information \n\nFor information about calculating costs, see the [IBM Cloud Pricing Calculator](https://cloud.ibm.com/estimator/review).\n\nFor additional pricing information, see the [Discovery catalog](https://cloud.ibm.com/catalog/services/discovery).\n\n\n\n\n\n Notes for Customers with Existing Plans \n\n\n\n* Beginning 1 August 2018, your billing and usage is based on this pricing plan.\n* The Lite plan is now reduced from 2,000 documents/400 Discovery News queries per month to 1,000 documents/200 Discovery News queries per month. If you already exceeded the new Lite plan limits, you cannot add any more documents. However, you can continue using it or upgrade to an Advanced or Premium plan.\n* The Standard plan is retired and is no longer available to new users. If you are currently on an existing Standard plan, you can continue using it or upgrade to an Advanced or Premium plan.\n* The Advanced and Premium plans are now based on document tiers. They are no longer based on document hours. Your monthly bill will not fluctuate, based on the number of documents, unless you switch between tiers.\n* Premium customers, contact [Sales](https://ibm.biz/contact-wdc-premium) for details on billing changes.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-discovery-pricing-plans"}, {"document_id": "ibmcld_02660-1509-3609", "score": 16.49233, "text": "\nCurrently, Dallas (us-south), Washington DC (us-east), London (eu-gb), and Sydney (au-syd) regions are supported.\n4. Select a pricing plan - Based on your business requirements, select a pricing plan: Lite, Standard, and Enterprise.\n\n\n\n* Lite - Includes all App Configuration capabilities for evaluation only. Not to be used for production. Lite plan services are deleted after 30 days of inactivity.\n* Standard - The standard plan includes feature flags and property management capabilities. You can use simple and uniform REST APIs to configure, enable, segment, and monitor features to mobile devices and web applications.\n* Enterprise - The enterprise plan includes targeting segment in addition to the property management and feature flags that are found in the Standard plan. The enterprise plan now supports by using private endpoints.\n\n\n\nFor more information about App Configuration usage and billing, see [Usage and billing](https://cloud.ibm.com/docs/app-configuration?topic=app-configuration-ac-faqs-usage).\n5. Configure your resource by providing a Service name for your instance, or use the preset name.\n6. Select a resource group - The resource group selection helps how you want resources to be organized in your account. The resource group that you select cannot be changed after the service instance is created.\n7. Optionally, define Tags to help you to identify and organize the instance in your account. If your tags are billing related, consider writing tags as key:value pairs to help group-related tags, such as costctr:124.\n8. Optionally, define Access management tags that are needed to apply flexible access policies on specific resources. For example, access:dev, proj:version-1.\n9. If you selected the Enterprise plan, then specify the Service endpoints. The following options are available:\n\n\n\n* Public network - The public network service endpoints are accessible from anywhere on the internet.\n* Both Public & Private network - use of both public and private service endpoint network access.\n\n\n\n10. Accept the licensing agreements and terms by clicking the checkbox.\n11.", "title": "", "source": "https://cloud.ibm.com/docs/app-configuration?topic=app-configuration-ac-create-an-instance"}, {"document_id": "ibmcld_07578-512956-514877", "score": 16.392529, "text": "\nYou might use the same instance of App Configuration for both scenarios for a total cost of just over $1600 per month.\n\n\n\n* What are the capabilities, quotas, and limits for various aspects of the App Configuration plans?\n\n\n\nTable 2. Capabilities, quotas, and limits for various pricing plans\n\n Lite Standard Enterprise \n\n Number of collaborators (team members) No restriction No restriction No restriction \n Max number of instances 1 No restriction No restriction \n Instance life 30 days of inactivity No restriction No restriction \n Base price for instance (monthly) Free Charge (see catalog page) Charge (see catalog page) \n Monthly active entity IDs included with instance 10 1000 10,000 \n Monthly active entity ID overage Overage not allowed overage allowed overage allowed \n Max monthly active entity IDs per instance 10 Unlimited Unlimited \n API calls included with instance 5,000 100,000 1,000,000 \n API call overage price Overage not allowed Overage allowed Overage allowed \n Max monthly API calls per instance 5,000 Unlimited Unlimited \n Environments 1 15 15 \n Collections 1 20 Unlimited \n Properties 10 (properties + flags) 1000 Unlimited \n Property types All All All \n Max property size 10 kB 10 kB 10 kB \n Max storage size (all properties) 0.1 MB 10 MB 10 MB \n Flags 10 (properties + flags) 100 Unlimited \n Attributes Glean from response and custom attributes Glean from response and custom attributes Glean from response and custom attributes \n Segments 3 <br><br> * <br><br><br> Unlimited \n Segment definition rules per segment 3 <br><br> * <br><br><br> 25 \n Max targeting definition rules per instance 3 <br><br> * <br><br><br> 100 \n Targeting definition rules per feature <br><br> * <br><br><br> <br><br> * <br><br><br> 50 \n Delivery mode Websocket (server)pull or get (client) Websocket (server) pull or get(client) Websocket(server)pull or get (client) \n Role-based access Env-level Env-level Env-level", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-512910-514831", "score": 16.392529, "text": "\nYou might use the same instance of App Configuration for both scenarios for a total cost of just over $1600 per month.\n\n\n\n* What are the capabilities, quotas, and limits for various aspects of the App Configuration plans?\n\n\n\nTable 2. Capabilities, quotas, and limits for various pricing plans\n\n Lite Standard Enterprise \n\n Number of collaborators (team members) No restriction No restriction No restriction \n Max number of instances 1 No restriction No restriction \n Instance life 30 days of inactivity No restriction No restriction \n Base price for instance (monthly) Free Charge (see catalog page) Charge (see catalog page) \n Monthly active entity IDs included with instance 10 1000 10,000 \n Monthly active entity ID overage Overage not allowed overage allowed overage allowed \n Max monthly active entity IDs per instance 10 Unlimited Unlimited \n API calls included with instance 5,000 100,000 1,000,000 \n API call overage price Overage not allowed Overage allowed Overage allowed \n Max monthly API calls per instance 5,000 Unlimited Unlimited \n Environments 1 15 15 \n Collections 1 20 Unlimited \n Properties 10 (properties + flags) 1000 Unlimited \n Property types All All All \n Max property size 10 kB 10 kB 10 kB \n Max storage size (all properties) 0.1 MB 10 MB 10 MB \n Flags 10 (properties + flags) 100 Unlimited \n Attributes Glean from response and custom attributes Glean from response and custom attributes Glean from response and custom attributes \n Segments 3 <br><br> * <br><br><br> Unlimited \n Segment definition rules per segment 3 <br><br> * <br><br><br> 25 \n Max targeting definition rules per instance 3 <br><br> * <br><br><br> 100 \n Targeting definition rules per feature <br><br> * <br><br><br> <br><br> * <br><br><br> 50 \n Delivery mode Websocket (server)pull or get (client) Websocket (server) pull or get(client) Websocket(server)pull or get (client) \n Role-based access Env-level Env-level Env-level", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03749-1776-3774", "score": 12.544012, "text": "\n(https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/billing-usage/images/enterprise-billing-usage.svg)\n\nFigure 1.Enterprise billing and usage management\n\n\n\n\n\n Billing options \n\nEnterprises require subscription billing or an account with the [Enterprise Savings Plan billing model](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-committed-use). In subscription billing, you purchase a subscription for an amount of credit to spend during the subscription term, and usage is deducted from the subscription credit at a discounted rate. The Enterprise Savings Plan billing model is similar to subscription billing. You commit to spend a certain amount on IBM Cloud and receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount.\n\nThe account that you use to create the enterprise must be a [Subscription account](https://cloud.ibm.com/docs/account?topic=account-accountssubscription-account) or an account with the [Enterprise Savings Plan billing model](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-committed-use). After the enterprise is created, you can add more accounts to the enterprise. If you add a Lite or trial account, the account is automatically upgraded to a Pay-As-You-Go account.\n\nSome Pay-As-You-Go accounts can't be directly imported into an enterprise, such as many Pay-As-You-Go accounts that are billed in United States dollars (USD). However, you can still import these accounts into your enterprise by converting them to Subscription accounts and then importing them. To convert an account, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule).\n\nEach enterprise supports only a single billing currency. All accounts must use the enterprise billing currency before you add them to the enterprise. Existing accounts that are imported into the enterprise no longer separately manage their billing.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-enterprise&interface=ui"}, {"document_id": "ibmcld_16364-89533-91701", "score": 12.514143, "text": "\n: The Enterprise plan includes all of the market differentiating features of the Plus plan, but with higher capacity limits, additional security features, custom onboarding support to get you going, and a lower overall cost at higher volumes.\n\nTo have a dedicated environment provisioned for your business, request the Enterprise with Data Isolation plan. To submit a request online, go to [http://ibm.biz/contact-wa-enterprise](http://ibm.biz/contact-wa-enterprise).\n\nThe Enterprise plan is replacing the Premium plan. The Premium plan is being retired today. Existing Premium plan users are not impacted. They can continue to work in their Premium instances and create instances up to the 30-instance limit. New users do not see the Premium plan as an option when they create a service instance.\n\nFor more information, see the [Pricing](https://www.ibm.com/cloud/watson-assistant/pricing/) page.\n\nOther plan changes\n: Our pricing has been revised to reflect the features we've added that help you build an assistant that functions as a powerful omnichannel SaaS application.\n\nStarting on 1 March 2021, the Plus plan starts at $140 per month and includes your first 1,000 monthly users. You pay $14 for each additional 100 active users per month. Use of the voice capabilities that are provided by the Phone integration are available for an additional $9 per 100 users per month.\n\nThe Plus Trial plan was renamed to Trial.\n\nSOC 2 compliance\n: Watson Assistant is SOC 2 Type 2 compliant, so you know your data is secure.\n\nThe System and Organization Controls framework, developed by the American Institute of Certified Public Accountants (AICPA), is a standard for controls that protect information stored in the cloud. SOC 2 reports provide details about the nature of internal controls that are implemented to protect customer-owned data. For more information, see [IBM Cloud compliance programs](https://www.ibm.com/cloud/compliance/global).\n\n\n\n\n\n 25 February 2021 \n\nSearch skill can emphasize the answer\n: You can configure the search skill to highlight text in the search result passage that Discovery determines to be the exact answer to the customer's question.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_02660-1509-3609", "score": 12.474913, "text": "\nCurrently, Dallas (us-south), Washington DC (us-east), London (eu-gb), and Sydney (au-syd) regions are supported.\n4. Select a pricing plan - Based on your business requirements, select a pricing plan: Lite, Standard, and Enterprise.\n\n\n\n* Lite - Includes all App Configuration capabilities for evaluation only. Not to be used for production. Lite plan services are deleted after 30 days of inactivity.\n* Standard - The standard plan includes feature flags and property management capabilities. You can use simple and uniform REST APIs to configure, enable, segment, and monitor features to mobile devices and web applications.\n* Enterprise - The enterprise plan includes targeting segment in addition to the property management and feature flags that are found in the Standard plan. The enterprise plan now supports by using private endpoints.\n\n\n\nFor more information about App Configuration usage and billing, see [Usage and billing](https://cloud.ibm.com/docs/app-configuration?topic=app-configuration-ac-faqs-usage).\n5. Configure your resource by providing a Service name for your instance, or use the preset name.\n6. Select a resource group - The resource group selection helps how you want resources to be organized in your account. The resource group that you select cannot be changed after the service instance is created.\n7. Optionally, define Tags to help you to identify and organize the instance in your account. If your tags are billing related, consider writing tags as key:value pairs to help group-related tags, such as costctr:124.\n8. Optionally, define Access management tags that are needed to apply flexible access policies on specific resources. For example, access:dev, proj:version-1.\n9. If you selected the Enterprise plan, then specify the Service endpoints. The following options are available:\n\n\n\n* Public network - The public network service endpoints are accessible from anywhere on the internet.\n* Both Public & Private network - use of both public and private service endpoint network access.\n\n\n\n10. Accept the licensing agreements and terms by clicking the checkbox.\n11.", "title": "", "source": "https://cloud.ibm.com/docs/app-configuration?topic=app-configuration-ac-create-an-instance"}, {"document_id": "ibmcld_12623-6811-8811", "score": 12.437695, "text": "\n* A single invoice for all usage within the enterprise, so understanding costs is easier\n* A single place to manage payment methods, so you can update once for all accounts\n\n\n\nLearn more in [Centrally manage billing and usage with enterprises](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-enterprise).\n\n\n\n\n\n Enterprise support \n\nThe level of support that is assigned to an IBM Cloud enterprise defaults to the highest support plan within the enterprise. All child accounts within the enterprise also default to the highest support plan. For more information about the support experience, see [Basic, Advanced, and Premium Support plans](https://cloud.ibm.com/docs/get-support?topic=get-support-support-planssupport_level_enterprise).\n\n\n\n\n\n Resource management \n\nResources and services within an enterprise function the same as in stand-alone accounts. Each account in an enterprise can contain resources in resource groups. Account groups can't contain resources. For more information, see [Managing resources](https://cloud.ibm.com/docs/account?topic=account-manage_resource).\n\nZoom\n\n![A diagram that shows that resources are contained in accounts in the enterprise.](https://cloud.ibm.com/docs-content/v1/content/d4595e5202a9a27767cf034e81b038cdf772e0d5/secure-enterprise/images/enterprise-resources.svg)\n\nFigure 3. Resources in an enterprise\n\nAs with all accounts, resources are tied to the resource group and account in which they're created, so they can't be moved between accounts in the enterprise. However, the enterprise's flexible account structure means you can move resources within the enterprise by moving the accounts that contain them.\n\n\n\n\n\n Top-down usage reporting \n\nFrom the enterprise account, you can view resource usage from all accounts in the enterprise. Starting at the enterprise level, you see estimated usage costs that are broken down by account and account groups. You can navigate down within the enterprise structure to see the costs within each level.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-what-is-enterprise&interface=ui"}, {"document_id": "ibmcld_16727-756469-758485", "score": 12.392787, "text": "\n* What happened to Enterprise Package plans?\n\nStarting on 21 June 2023, you can no longer configure the Enterprise package plan. The functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https://cloud.ibm.com/docs/cis?topic=cis-transitioning-next-plan).\n* How do I delete my CIS instance?\n\nTo delete a CIS instance, you must first delete all global load balancers, pools, and health checks. Then delete the associated domain (zone). Go to the Overview page and click the trash can icon next to the domain name located in the Service Details section to start the deletion process.\n\nIf you are moving your domain to a different provider, be sure to migrate your DNS records and other configuration information to the new provider before activating the domain there. Activating the domain before migrating from CIS can cause your domain to changed to a [Moved state](https://cloud.ibm.com/docs/cis?topic=cis-domain-moved-status).\n* I added a user to my account and gave that user permission to manage Internet Services instance(s). Why is that user facing authentication issues?\n\nIt's possible that you did not assign \"service access roles\" to the user. Note that there are two separate sets of roles:\n\n\n\n* Platform access\n* Service access\n\n\n\nYou need platform access roles to create and manage service instances, while service access roles perform service-specific operations on service instances. In the console, these settings can be updated by selecting Manage > Security > Identity and Access.\n* Why is my domain in Pending state? How do I activate it?\n\nWhen you add a domain to CIS, we give you a couple of name servers to configure at your registrar (or at your DNS provider, if you are adding a subdomain). The domain or subdomain remains in pending state until you configure the name servers correctly. Make sure you add both the name servers to your registrar or DNS provider.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_12559-1521-3753", "score": 12.139819, "text": "\nTo create an enterprise, you must be the account owner or have the Administrator role on the Billing account management service.\n\nCreating an enterprise from an account and importing existing accounts cannot be undone. This tutorial is provided as an example of the steps you can follow to set up an enterprise by department, but you should carefully plan your enterprise structure around your organization's needs.\n\n\n\n\n\n Step 1: Create the enterprise \n\nEnterprises are created from an existing Subscription account. When you create the enterprise, the account is added to the enterprise hierarchy. Billing transitions to being managed by the enterprise, but its users and resources remain the same and are completely unaffected. For a complete description of account impacts, see [Creating an enterprise](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-create-enterprise).\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Enterprise, and click Create.\n2. Enter the name of your company, such as Example Corp, to identify your enterprise.\n3. Enter your company's domain, such as examplecorp.com.\n4. Review the information about the impact to your account, and select I understand the impact to my account. Then, click Create. The account is now permanently part of the enterprise and can't be removed.\n\n\n\nAfter your enterprise is created, you are directed to the enterprise dashboard. From here, you can view the enterprise details, accounts, users, and billing information. Go to the Accounts page to view your enterprise structure, where you see the following accounts:\n\n\n\n* An enterprise account with the same name as your enterprise. This account is used for enterprise management.\n* The account that you created the enterprise from. Users can continue working with resources in the account unaffected.\n\n\n\n\n\n\n\n Step 2: Create an enterprise structure with account groups \n\nUse account groups to [organize related accounts](https://cloud.ibm.com/docs/account?topic=account-enterprise-organize). The second and third tier of the Example Corp. enterprise hierarchy contain the Marketing, Development, Sales, Design, and Engineering account groups. Complete the following steps to create the account groups:\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-tutorial&interface=ui"}, {"document_id": "ibmcld_07103-27797-30073", "score": 12.1349535, "text": "\nFor more information, see [Discovery pricing plans](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-pricing-plans).\n\n\n\n\n\n 11 November 2021 \n\nNew locations for Enterprise plan now available\n: The Enterprise plan is available from the Frankfurt, London, Sydney, and Tokyo locations in addition to the Dallas location.\n\n\n\n\n\n 3 November 2021 \n\nNew Enterprise plan\n: Scale and secure your Discovery application with enterprise-grade support and performance and address more use cases, including contract analysis and content mining to explore insights across documents. Currently, the Enterprise plan is available only from the Dallas location. For more information, see [Discovery pricing plans](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-pricing-plans).\n\nNew beta entity extractor enrichment\n: The Extract entities enrichment brings the powerful ability to build a custom type system into Discovery. Use the tool to label entity examples within your industry data to build a machine learning model that Discovery can use to recognize meaningful terms for your business. Currently, this beta feature is available for English-language projects that are created in Premium plan service instances only. For more information, see [Customizing the terms that Discovery can recognize](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-entity-extractor).\n\nNew Helpful links tab\n: The home page includes a Helpful links tab that has quick links to documentation, a community site, and other resources.\n\nImproved field selection choices\n: When you apply an enrichment to a field or choose a field to use as the source for a facet, the fields that are displayed for you to choose from now include only fields that are valid choices. Previously, the list included fields that were not valid choices.\n\n\n\n\n\n 14 October 2021 \n\nNew Discovery home page\n: A new home page is displayed when you start Discovery and gives you quick access to a product overview video, and tours. You can collapse the home page welcome banner to see more projects.\n\nNew plan usage section\n: Stay informed about plan usage and check your usage against the limits for your plan type from the Plan limits and usage page. From the product page header, click the user icon !", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-release-notes"}, {"document_id": "ibmcld_12623-5165-7280", "score": 12.077295, "text": "\nEnterprises require [subscription billing](https://cloud.ibm.com/docs/account?topic=account-accountssubscription-account) or an account with the [Enterprise Savings Plan billing model](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-committed-use). Subscription billing means that you purchase a subscription for an amount of credit to spend during the subscription term, and usage is deducted from the subscription credit at a discounted rate. Subscription credit, as well as credit from any promotions, is added to the enterprise credit pool, which is shared across all accounts in the enterprise. As accounts use resources, credit is spent from the credit pool. The Pay as you go with Committed Use billing model is similar to the billing model for Subscription accounts. You commit to spend a certain amount on IBM Cloud and receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount.\n\nZoom\n\n![A diagram that shows that credit from accounts is added to the enterprise credit pool, which is managed by the billing administrator in the enterprise account.](https://cloud.ibm.com/docs-content/v1/content/d4595e5202a9a27767cf034e81b038cdf772e0d5/secure-enterprise/images/enterprise-billing.svg)\n\nFigure 2. Enterprise billing management\n\nBecause billing is consolidated, enterprises make managing invoicing and payments across multiple accounts easier with these key benefits:\n\n\n\n* A credit pool of subscriptions that span multiple accounts, so you can size your subscriptions for all of your usage rather than usage per account\n* A single invoice for all usage within the enterprise, so understanding costs is easier\n* A single place to manage payment methods, so you can update once for all accounts\n\n\n\nLearn more in [Centrally manage billing and usage with enterprises](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-enterprise).\n\n\n\n\n\n Enterprise support \n\nThe level of support that is assigned to an IBM Cloud enterprise defaults to the highest support plan within the enterprise.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-what-is-enterprise&interface=ui"}, {"document_id": "ibmcld_12623-7-2328", "score": 11.917069, "text": "\nWhat is an enterprise? \n\nIBM Cloud\u00ae\n\nenterprisesprovide a way to centrally manage billing and resource usage across multiple accounts. Within an enterprise, you create a multitiered hierarchy of accounts, with billing and payments for all accounts managed at the enterprise level.\n\nWhen compared to using multiple stand-alone accounts, enterprises offer the following key benefits:\n\n\n\n* Centralized account management: View your entire enterprise hierarchy at a glance, without needing to switch accounts. You can add existing accounts or create new accounts directly within the enterprise.\n* Consolidated subscription billing: Track your subscriptions and credit spending for all accounts from a single view. Your subscription credit is pooled and shared among accounts in the enterprise.\n* Top-down usage reporting: From your enterprise account, you can view usage of all accounts in your enterprise, which is organized by account group.\n\n\n\n\n\n Watch and learn \n\n\n\n* Video transcript\n\nYour IBM Cloud account is your home for collaboration in the cloud. As you scale up your workloads, you might find that you're managing multiple IBM Cloud accounts. For example, your company might have many teams, each with one or more of their own accounts for development, testing, and production environments. Or, you might isolate certain workloads in separate accounts to meet security or compliance guidelines. As the number of accounts grows, it can become more difficult to track resource usage and associated costs.\n\nIBM Cloud enterprises offer a simpler way to centrally manage billing and usage across multiple accounts. Within an enterprise, you can create a multi-tiered hierarchy of accounts by adding new or existing accounts and nesting them in account groups. How you structure your enterprise is up to you. For example, for a large organization, you might organize your accounts by geography, or by department. You can choose the structure that best fits how you want to track your usage. If your teams change, no problem - you can move accounts within the enterprise as needed.\n\nConsolidated billing simplifies invoicing and payment within your enterprise. Usage costs are deducted from a subscription credit pool that's shared between all accounts, so you can add and manage subscription credit from a single place.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-what-is-enterprise&interface=ui"}, {"document_id": "ibmcld_07122-2739-4685", "score": 11.902642, "text": "\nThe IBM Cloud page does not show progress information and doesn't indicate when the plan upgrade process is finished. To check whether the new plan is in effect, you must refresh the service instance overview page, and then check for the new plan name to be displayed in the Plan tile.\n\nDuring the plan upgrade process, you can continue to submit search queries in your existing projects. However, avoid the following actions:\n\n\n\n* Adding new projects or collections\n* Deleting or changing existing collections, including adding documents, editing fields, and changing enrichment settings.\n\n\n\n\n\n* If you are creating an Enterprise plan in the same data center location where you have an existing Premium plan, you must create a new resource group for the new plan. You cannot use the same resource group for Enterprise and Premium plans that are hosted in the same location. For more information, see [Managing resource groups](https://cloud.ibm.com/docs/account?topic=account-rgs&interface=ui).\n* You cannot do an in-place upgrade from a Plus or Enterprise plan to a Premium plan.\n\nA Premium plan instance must be provisioned for you. To start the process, contact [Sales](https://www.ibm.com/account/reg/us-en/signup?formid=MAIL-watson&disableCookie=Yes). You will be asked to provide the following details:\n\n\n\n* Customer name\n* Customer email\n* Planned deployment date\n* Data center location, such as Dallas or Frankfurt\n* Account ID\n* Resource group name\n* Resource group ID\n\nThe resource group is created by the account holder. For more information, see [Managing resource groups](https://cloud.ibm.com/docs/account?topic=account-rgs&interface=ui).\n\n\n\n\n\n\n\nYou cannot directly downgrade from one plan to another. If you want to move from an Enterprise plan to a Plus plan, for example, you must provision a new Plus plan and then move data to it from your existing Enterprise plan. After the data is moved, you can delete the Enterprise plan.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-upgrade"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07037-7-2002", "score": 21.66992, "text": "\nGetting help \n\nGet help to solve issues that you encounter when you use the product.\n\nUse these resources to get answers to your questions:\n\n\n\n* Walk through a guided tour to learn about a project type or a feature. Click Guided tours from the page header to see a list of available tours.\n* For answers to frequently asked questions, see the [FAQ](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-faqs).\n* Find answers to common questions or ask questions where experts and other community members can answer. Go to the [Watson Discovery Community forum](https://community.ibm.com/community/user/watsonai/communities/community-home?CommunityKey=80650291-2ff4-4a43-9ff8-5188fdb9552f).\n\n\n\n\n\n IBM Cloud Contacting IBM Cloud Support for managed deployments \n\nManaged deployments are deployments that are hosted on IBM Cloud, including IBM Cloud Pak for Data as a Service deployments.\n\nIf your service plan covers it, you can get help by opening a case from [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\nBe ready to share the following information with IBM Support:\n\n\n\n Account information \n\n\n\n* Account name or customer name.\n* Business impact so IBM Support understands the urgency of the issue and can prioritize it.\n* Case information for any related cases or a parent case.\n* Cloud location where the service instance is hosted (Dallas, Frankfurt, and so on).\n* Your service plan (Plus, Premium and so on).\n\n\n\n\n\n\n\n Problem description \n\n\n\n* What outcome were you expecting and what happened?\n* Message text that is displayed when the error occurs, especially the document ID, if specified.\n* Steps to take to reproduce the issue.\n* Any screen captures that illustrate the problem.\n* When did the problem occur?\n* Instance ID. (The instance ID is part of the URL that is specified in the Credentials section of the service page on IBM Cloud. You can copy the full URL and provide that.)\n* Collect and share the HTTP archive (HAR) file from your browser.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-get-help"}, {"document_id": "ibmcld_11601-1712-3717", "score": 21.66801, "text": "\nIf you need support but are unable to log in to your account, start a chat by going to the [IBM Cloud Support](https://www.ibm.com/cloud/support) page and clicking Let's talk.\n\n\n\n New support case with IBM Cloud Support \n\nIf you need to open a support case, collect as much information as possible to help the IBM Cloud Support team to analyze, triage and diagnose your problem as quickly as possible.\n\n\n\n\n\n Requesting support for SAP-certified IBM Power Virtual Servers \n\nAll performance-related issues need to be checked by IBM Power Systems and IBM Cloud support first, to establish whether any infrastructure-related issues exist, before a case of the software stack (SAP Workloads) can be opened.\n\nIf the issue is operating system (OS) related, go the support portal of the distribution (AIX or Linux\u00ae) to open a case.\n\nYou can check whether the infrastructure is set up correctly by running a python script on Linux\u00ae: python chk_numa_lpm.py. For more information, see [SAP Note 2923962 - - Check SAP HANA NUMA Layout on IBM Power Systems Virtual Servers](https://launchpad.support.sap.com//notes/2923962).\n\n\n\n\n\n Requesting support for resources in the European Union \n\nEuropean Union (EU) support is available to customers who choose to enable the EU supported setting. EU Support is provided 24 hours a day and 7 days a week by engineers that are located in Europe.\n\nGlobal teams provide support at the discretion of the EU support team. Global teams might be contacted, for example, when issues are not resolved by the Advanced Customer Support (ACS) team in the EU, and more expertise is needed.\n\nYou can specify that you want EU support for your account if the following criteria are true:\n\n\n\n* The EU Supported setting is enabled for your account by the primary user or account owner. For more information, see [Enabling the EU Supported setting](https://cloud.ibm.com/docs/account?topic=account-eu-hipaa-supportedbill_eusupported).\n* Your resources are in the appropriate European data center.", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-help-support"}, {"document_id": "ibmcld_08091-2715-4739", "score": 21.090668, "text": "\nFor more information, see [Assigning user access for working with support center](https://cloud.ibm.com/docs/get-support?topic=get-support-access&interface=ui).\n\n\n\n Asking a question \n\nThe Stack Overflow forum provides a wide variety of searchable answers for your IBM Cloud questions. If you don't find an existing answer, ask a new question. Go to [Stack Overflow](https://stackoverflow.com/questions/tagged/ibm-cloud) to ask technical questions about developing apps with the IBM Cloud platform and services.\n\nIBM Cloud development and support teams actively monitor Stack Overflow and follow the questions that are tagged with ibm-cloud. When you create a question, add the ibm-cloud tag to your question to ensure that it's seen by the IBM Cloud development and support teams.\n\n\n\n\n\n\n\n Getting support for IBM Cloud Dedicated or Bluemix Local \n\nIf your account is either IBM Cloud Dedicated or Bluemix Local, support is provided by the IBM Cloud support team.\n\n\n\n* Open a new case by using the [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter) page and click Create a case. Mention that your account is either IBM Cloud Dedicated or Bluemix Local in the Subject and Description of the support case.\n* If you don't have an IBMid, contact someone in your organization that does, or work with your IBM representative.\n\n\n\n\n\n\n\n Requesting support for resources in the European Union \n\nEuropean Union (EU) support is available to customers who choose to enable the EU supported setting. EU Support is provided 24 hours a day and 7 days a week by engineers that are located in Europe. Global teams provide support at the discretion of the EU support team. Global teams might be contacted, for example, when issues are not resolved by the Advanced Customer Support (ACS) team in the EU, and more expertise is needed.\n\nYou can specify that you want EU support for your account if the following criteria are true:\n\n\n\n* The EU Supported setting is enabled for your account by the master user or account owner.", "title": "", "source": "https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar&interface=ui"}, {"document_id": "ibmcld_08063-2713-4328", "score": 21.005535, "text": "\n* Attach files and resources to provide more details about the issue you're experiencing.\n* If you'd like a user in you account to be updated about the case, add them by using the Contact watchlist. For more information about assigning users access to your account, see [Adding users to your case management access group](https://cloud.ibm.com/docs/get-support?topic=get-support-accessadd-user-access-group).\n* Select Email me updates about this case to receive support case notifications.\n\n\n\n7. Click Next, review your case summary, and click Submit case. After you receive email verification for the case, follow the instructions for further communication on the issue.\n\n\n\nAfter your support case is created, you can follow its progress on the [Manage cases page](https://cloud.ibm.com/unifiedsupport/cases).\n\n\n\n\n\n Creating a support case by using the API \n\nYou can programmatically open a support case by calling the Case Management API as shown in the following sample requests. For more information about the API, see [Case Management](https://cloud.ibm.com/apidocs/case-managementcasemanagement-createcase).\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl --location --request POST 'support-center.cloud.ibm.com/case-management/v1/cases' --header 'Content-Type: application/json' --header 'Content-Type: text/plain' --data-raw '{ \"type\": \"technical\",\n\"subject\": \"Case subject\",\n\"description\": \"Case description\",\n\"severity\":4,\n\"offering\": {\n\"name\": \"Cloud Object Storage\",\n\"type\": {\n\"group\": \"crn_service_name\",\n\"key\": \"cloud-object-storage\",\n\"kind\": \"service\",\n\"id\": \"dff97f5c-bc5e-4455-b470-411c3edbe49c\"\n}\n},", "title": "", "source": "https://cloud.ibm.com/docs/get-support?topic=get-support-open-case&interface=ui"}, {"document_id": "ibmcld_03761-0-1497", "score": 20.17032, "text": "\n\n\n\n\n\n\n  Getting help and support \n\nIf you experience an issue or have questions when you're working in the IBM Cloud\u00ae console, you can use the following resources before you open a support case.\n\n\n\n*  Review the [FAQs](https://cloud.ibm.com/docs?tab=faqs&tags=get-support%2Cbilling-usage%2Caccount%2Csell) in the product documentation.\n*  Review the troubleshooting documentation for [accounts](https://cloud.ibm.com/docs/account?topic=account-ts_logintoibm), [billing](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cannot-access-billing-info), [selling on IBM Cloud](https://cloud.ibm.com/docs/sell?topic=sell-ts-view-usage), and [using the Support Center](https://cloud.ibm.com/docs/get-support?topic=get-support-ts_tech-support-case) to troubleshoot and resolve common issues.\n*  Check the status of the IBM Cloud platform and resources by going to the [Status page](https://cloud.ibm.com/status).\n*  Review [Stack Overflow](https://stackoverflow.com/questions/tagged/ibm-cloud) to see whether other users experienced the same problem. When you ask a question, tag the question with ibm-cloud, so that it's seen by the IBM Cloud development teams.\n\n\n\nIf you still can't resolve the problem, you can open a support case. For more information, see [Creating support cases](https://cloud.ibm.com/docs/get-support?topic=get-support-open-case). And, if you're looking to provide feedback, see [Submitting feedback](https://cloud.ibm.com/docs/overview?topic=overview-feedback).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-gettinghelp"}, {"document_id": "ibmcld_07578-18457-20516", "score": 20.148596, "text": "\n5. Under Time Frame, select the month you need.\n6. Select your Plus plans or Plus Trial plans to see monthly active users and the API calls.\n\n\n\n* Error: New Off Topic not supported\n\nYou see the error New Off Topic not supported after editing the JSON file for a dialog skill and changing the skill language from English to another language.\n\nTo resolve this issue, modify the JSON file by setting off_topic to false. For more information about this feature, see [Defining what's irrelevant](https://cloud.ibm.com/docs/assistant?topic=assistant-irrelevance-detection).\n* Is it possible to increase the number of intents per skill\n\nNo, it is not possible to increase the number of intents per skill.\n\n\n\nDiscovery v1\n\n\n\n* Where can I get technical support for Discovery?\n\nIf you cannot find a solution to the issue you are having, search this documentation. You can also try the resources available from the Developer community section of the table of contents.\n\nIf your service plan covers it, you can get help by creating a case from [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n* How do you interpret the confidence score that appears in query results?\n\nDiscovery returns a confidence score for both natural language queries and those written in the Discovery Query Language. For more information, see [Confidence scores](https://cloud.ibm.com/docs/services/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n* How do you integrate Watson Discovery with Watson Assistant?\n\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https://cloud.ibm.com/docs/services/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-18457-20516", "score": 20.148596, "text": "\n5. Under Time Frame, select the month you need.\n6. Select your Plus plans or Plus Trial plans to see monthly active users and the API calls.\n\n\n\n* Error: New Off Topic not supported\n\nYou see the error New Off Topic not supported after editing the JSON file for a dialog skill and changing the skill language from English to another language.\n\nTo resolve this issue, modify the JSON file by setting off_topic to false. For more information about this feature, see [Defining what's irrelevant](https://cloud.ibm.com/docs/assistant?topic=assistant-irrelevance-detection).\n* Is it possible to increase the number of intents per skill\n\nNo, it is not possible to increase the number of intents per skill.\n\n\n\nDiscovery v1\n\n\n\n* Where can I get technical support for Discovery?\n\nIf you cannot find a solution to the issue you are having, search this documentation. You can also try the resources available from the Developer community section of the table of contents.\n\nIf your service plan covers it, you can get help by creating a case from [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n* How do you interpret the confidence score that appears in query results?\n\nDiscovery returns a confidence score for both natural language queries and those written in the Discovery Query Language. For more information, see [Confidence scores](https://cloud.ibm.com/docs/services/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n* How do you integrate Watson Discovery with Watson Assistant?\n\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https://cloud.ibm.com/docs/services/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_02151-3659-5143", "score": 19.911535, "text": "\nFor more information about creating and by using custom domains, see [Managing your domains](https://cloud.ibm.com/docs/apps?topic=apps-update-domain).\n* To manage the allocated quota for an org, click the Actions icon ![Action icon](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/action-menu-icon.svg) for the respective org, and select Quotas.\n\nFrom here, you can view the quota details for the number of apps, amount of memory, number of services, and plan details. The quota represents the resource limits for the org, which is assigned when the organization is created. The resources that are available to an org vary depending on whether you have a free account or a billable account. Any application or service that is included in a space within the org contributes to the usage of the allocated quota.\n\nTo change the quota that is allocated to an org, you must create a support case. For more information, see [Working with support cases](https://cloud.ibm.com/docs/get-support?topic=get-support-open-case).\n\nTo view the quota details at the space level for each location, click the Actions icon ![Action icon](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/action-menu-icon.svg) for the respective org, and select Quotas. Then, expand each row accordingly.\n\n\n\n\n\n\n\n Updating orgs and spaces by using the CLI \n\n\n\n Renaming orgs \n\n\n\n1. Log in, and select the account.\n\nibmcloud login\n2.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-orgupdates"}, {"document_id": "ibmcld_08063-4-1806", "score": 19.911188, "text": "\n* UI\n* API\n\n\n\n\n\n\n\n Creating support cases \n\nIf you experience problems with IBM Cloud\u00ae, you can use the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter) to create a support case. Users with a Basic, Advanced, or Premium [support plan](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans) can create a technical support case by attaching a specific resource or product to ensure that the case gets to the correct support engineer faster. This allows for a more efficient and effective resolution.\n\nIf your account is deactivated or if you don't have access to your account, you can create a support case by completing the [Create an Account, Login or Billing Request](https://watson.service-now.com/x_ibmwc_open_case_app.do!/create) form.\n\nYou can also create support cases for issues that are associated with access (IAM), billing & usage, account, and invoice or sales inquiries. The types of available support depend on the support level of the account. Your support plan also determines the severity level that you can assign to support cases. For more information, see [Case severity and response time](https://cloud.ibm.com/docs/get-support?topic=get-support-support-case-severity).\n\nUsers with a Lite account can also create support cases, but are limited to issues associated with access (IAM), billing & usage, account, and invoice or sales inquiries. Technical support for Lite accounts with free support is provided by the [IBM Cloud docs](https://cloud.ibm.com/docs) and [Stack Overflow](https://stackoverflow.com/questions/tagged/ibm-cloud?tab=Newest).\n\nBy default, account users don't have access to create, update, search, or view cases. The account owner must provide users access by assigning an Identity and Access Management (IAM) access policy.", "title": "", "source": "https://cloud.ibm.com/docs/get-support?topic=get-support-open-case&interface=ui"}, {"document_id": "ibmcld_11601-7-2113", "score": 19.88534, "text": "\nGetting help and support from IBM Cloud or SAP \n\nIf you experience problems with IBM Cloud, you have several options to get help with determining the cause of the problem and finding a solution.\n\nWhich support option depends on the level of support (and urgency), and whether the problem is with the Offering or running SAP Workloads using the Offering.\n\nOptions include:\n\n\n\n* IBM Cloud Support Case, using the [IBM Cloud Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter)\n* SAP support incident, using the [SAP ONE Support Launchpad](https://launchpad.support.sap.com/)\n* IBM Cloud Docs\n\n\n\nFor previous users of IBM Cloud Classic Infrastructure (formerly Softlayer), please be aware these Support Cases were previously termed Support Tickets.\n\n\n\n IBM Cloud Support \n\nIBM Cloud Support handles any support questions and issues that might arise - available through live web chat, phone, and case-based support.\n\nEach IBM Cloud account automatically comes with customer support at no cost and covers most cases which are placed each day; this is the Basic level of support.\n\nThe types of available and response time of support, depends on the support level of the account. Your support plan also determines the severity level that you can assign to support cases. For more information, see [Basic, Advanced, and Premium Support plans](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans).\n\nYou can change your current support plan at any time by contacting IBM Cloud sales expert.\n\nFor full information about opening an IBM Cloud Support case, or about support levels and ticket severities, see [IBM Cloud Support documentation](https://cloud.ibm.com/docs/get-support).\n\nIf you need support but are unable to log in to your account, start a chat by going to the [IBM Cloud Support](https://www.ibm.com/cloud/support) page and clicking Let's talk.\n\n\n\n New support case with IBM Cloud Support \n\nIf you need to open a support case, collect as much information as possible to help the IBM Cloud Support team to analyze, triage and diagnose your problem as quickly as possible.", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-help-support"}]}
{"task_id": "1c041ce47a81941c26899fdf08bde961<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09989-0-1547", "score": 15.059842, "text": "\n\n\n\n\n\n\n  Query editor \n\nWith the query editor, you can run SQL queries on a specific host and database. You can also save any of the queries that you create.\n\n\n\n  Creating queries \n\n\n\n1.  Go to Query editor.\n2.  From Data objects, select the database and schema in which you want to run the query.\nIf you do not pick a schema, the default database schema is selected.\n3.  Type the SQL query that you want to run.\nIf your query is a select statement, a Set Limit option shows up to allow you to specify how many rows of data you would like to retrieve. The default is No limit.\n\nIn the Worksheet settings you can specify your Default maximum number of rows limit in result. If you decide, however, to add a limit clause in a select statement that is greater than your Default maximum number of rows limit in result, for example: select * from table1 limit 10;, the Results field shows the smaller value of these two parameters.\n\nIn the Worksheet settings you can also specify the Statement separator you want to use. A semicolon (\";\") is the default Statement separator and you must change it to an ampersand (\"&\") when your queries contain semicolons (\";\") to avoid errors.\n4.  When you input the information, you can do one of the following:\n\n\n\n*  Click Run to run the query.\nThe results of the query are displayed in the panel.\n*  Click the floppy disk icon that is in the SQLworksheet toolbar to save the query as a template.\nThe saved query is added to Saved queries and Queries > Recent Queries.\n*  Click Clear to clear the query.\n\n\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-query-editor"}, {"document_id": "ibmcld_13493-7-1679", "score": 14.550806, "text": "\nRunning a query \n\nWatch the following video to learn more about Data Engine and how you can get started to run a basic query.\n\nIn SQL, the term query is just another way of saying SELECT statement. To run a query:\n\n\n\n1. In the SQL editor field of the Data Engine UI, enter a SELECT statement.\n\n\n\n* After the FROM keyword, specify one or more [unique resource identifiers](https://cloud.ibm.com/docs/sql-query?topic=sql-query-runningunique) (URIs). Each URI can be thought of as a table. It specifies one or more input objects; each input object can be thought of as a table partition. You must have at least 'Reader' access to the buckets that contain the input objects.\n* If the format of the input objects is CSV, and no special options are required, it is not necessary to specify a STORED AS clause. However, if the format is JSON, ORC, Parquet, or AVRO, after the FROM clause, specify STORED AS JSON, STORED AS ORC, STORED AS PARQUET, or STORED AS AVRO.\n* If text formats, such as JSON and CSV, are compressed with either gzip or bzip2 and have the extensions .gz and .bz, they automatically get recognized as compressed files. However, do not use these kinds of compressed files due to performance reasons.\n* If the format of the input objects is CSV and a delimiter other than the default , (comma) is used, you must specify the delimiter by using the FIELDS TERMINATED BY option of the [STORED AS](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause. All single Unicode characters are allowed as delimiters.\n* By default, it is assumed that CSV input objects have a header line that specifies the names of the input columns.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-running"}, {"document_id": "ibmcld_16662-0-1981", "score": 14.33641, "text": "\n\n\n\n\n\n\n  Running SQL queries \n\nSQL is a standardized language for defining and manipulating data in a relational database. You can use the Query workspace interface in IBM\u00ae watsonx.data to run SQL queries and scripts against your data.\n\nThe Query workspace has the following components:\n\n\n\n*  Data objects: To view the engines, catalogs, schemas, tables, and columns.\n*  Engine: To select an engine and view the associated catalogs.\n*  Saved queries: To view the saved queries.\n*  Worksheet: To write SQL queries.\n\n\n\nThe Query workspace page provides basic options to undo, redo, cut, copy, paste, save, clear, and delete.\n\nFormat selection option is enabled only when an SQL statement in a query worksheet is selected. The Format worksheet option formats all the content in the worksheet. Comment selection is used to explain sections of SQL statements.\n\nThe Delete option is enabled only after an SQL query is saved.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1.  Log in to the watsonx.data console.\n2.  From the navigation menu, select SQL. The Query workspace page opens.\n3.  Select an engine from the Engine drop-down.\n4.  Select the catalog, schema, table, or column in which you want to run the query.\n5.  Click the overflow menu and select the required query.\n\n\n\n*  For a catalog and schema, you can run the Generate Path query.\n*  For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n*  For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\n6.  Click the Save icon to save the query. A Save query confirmation dialog appears.\n7.  Click Save.\n8.  Click the Run button to run the query.\n9.  Select Result set or Details tab to view the results.\n10. Click Saved queries to view the saved queries.\n11. Click [Explain](https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-explain_sql_query) to view the logical or distributed plan of execution for a specified SQL query.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-run_sql"}, {"document_id": "ibmcld_05152-4777-6005", "score": 14.151511, "text": "\n[SQL Query Window](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/select-with-sql.jpg)\n\nFigure 7. Access with SQL query window\n\nThe entry representing the job of the SELECT statement run previously is shown in Figure 8. There are two tabs, \"Results\" and \"Details,\" at the top of the list that allow you to switch between seeing the results and more detailed information.\n\nZoom\n\n![SQL Query Results](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/results-from-sql.jpg)\n\nFigure 8. Access with SQL query jobs\n\nThe entry representing the details of running the SELECT statement run previously is shown in Figure 9.\n\nZoom\n\n![SQL Query Details](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/details-from-sql.jpg)\n\nFigure 9. Access with SQL query jobs\n\n\n\n\n\n Next Steps \n\nFor more information on using Data Engine see the [Data Engine documentation](https://cloud.ibm.com/docs/sql-query?topic=sql-query-overview) and [Analyzing Data with IBM Cloud SQL Query](https://www.ibm.com/cloud/blog/analyzing-data-with-ibm-cloud-sql-query).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-sql-query"}, {"document_id": "ibmcld_13498-7-2240", "score": 14.013243, "text": "\nSQL reference \n\n\n\n Introduction \n\nWith IBM Cloud\u00ae Data Engine, you can analyze and transform open data with SQL. It supports the various types of SELECT statements from the ANSI SQL standard.\n\nThe SELECT statement (or query statement) is used to read object data from IBM Cloud\u00ae Object Storage (COS), process the data, and store it back on Cloud Object Storage eventually.\n\nYou can use Data Engine as a data transformation service, as it always writes the results of a query to a specified location in either Object Storage or Db2 tables. Data Engine provides extended SQL syntax inside a special INTO clause to control how the result data is stored physically. This extended SQL syntax includes control over data location, format, layout, and partitioning.\n\nA query statement can be submitted through Data Engine's web UI or programmatically, either by using the service's REST API, or by using the Python or Node.JS SDK. You can also use IBM Watson\u00ae Studio and the Python SDK to use Data Engine interactively with Jupyter Notebooks. In addition, you can submit SQL queries that use IBM Cloud\u00ae Functions.\n\nIn addition to the ad hoc usage of data in IBM Cloud\u00ae Object Storage, you can also register and manage your data in a catalog as tables, consisting of columns and partitions.\n\nSeveral benefits to cataloging your data exist:\n\n\n\n* It simplifies SQL SELECT statements because the SQL author does not need not know and specify exactly where and how the data is stored.\n* The SQL execution can skip the inference of schema and partitioning because this information is available in the metastore. Thus, cataloging improves your query performance, especially for text-based data formats, such as CSV and JSON, where the schema inference requires a full scan of the data before the actual query execution.\n\n\n\n\n\n\n\n Select \n\nSee the following examples for an outline of the general syntax of an SQL query statement that uses the query clause and the namedQuery clause.\n\n\n\n query \n\n\n\n\n\n namedQuery \n\n\n\n\n\n intoClause \n\nThe query statement supports common table expressions. A common table expression permits defining a result table with a table name that can be specified as a table name in any FROM clause of the fullselect that follows.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-reference"}, {"document_id": "ibmcld_16353-2640-4846", "score": 13.781716, "text": "\nYou can select any step that precedes the step you are editing.\n\nNote that only the selected steps will repeat, regardless of their And then settings. Therefore, if you want to repeat the entire action up to this point, you must select all of the previous steps.\n\nThe current step you are editing is automatically included in the list of steps to be repeated. To avoid an infinite loop, use step conditions to ensure that this step only executes when it is appropriate for previous steps to be repeated. For example, you might have a step that repeats previous steps only if the user answered No to a confirmation question; this way, if the user answers Yes, nothing is repeated and the action continues.\n3. Click Apply.\n\n\n\nAny session variable values that were defined based on choices that the customer made in the repeated steps are cleared and replaced with the new responses.\n\nThere is no option to jump to a later step. Instead of jumping directly to a later step, control the flow through the intervening steps with step conditions or skipping steps.\n\n\n\n\n\n Go to a subaction \n\nAn action that is called from another action is referred to as a subaction. This option switches the conversation flow to another action. If you have an action flow that can be applied across multiple actions, you can use a subaction to build it once and then call it from each action that needs it. For example, as part of an action to place an order, you might call a subaction that enables a new customer to create an account.\n\nTo call a subaction:\n\n\n\n1. In the And then field, select Go to a subaction.\n2. In the Settings window, click the Go to field and select the action that you want to call.\n3. If you do not want to continue with the current action, click End this action after the other action is completed. You might use this option in cases where the customer decides to do something different; in this case, you want the conversation flow to switch to the subaction and not return.\n\nBy default, the assistant returns to the current action after the subaction completes. Any action variables or session variables that are defined in the subaction are accessible from subsequent steps in the calling action.\n4.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-step-what-next"}, {"document_id": "ibmcld_16666-11924-13606", "score": 13.366434, "text": "\nFor the steps to perform ingestion, see the [Ingesting data through the command-line interface (CLI)](https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-ingest_data_cli)\n\n\n\n\n\n Step 7: Querying data \n\nIn this section of the tutorial, you learn how to navigate to the Query workspace, and create SQL queries to query your data from the bucket.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1. From the navigation menu, select SQL. The Query workspace page opens.\n2. Select the Presto engine from the Engine drop-down.\n3. Select a catalog, for example, default schema, and a table, for example, order_detail, to run the query.\n4. Click the overflow menu and select the required query.\n\n\n\n* For a catalog and schema, you can run the Generate Path query.\n* For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n* For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\nConsider the following sample query to view the details from the table:\n\nExample:\n\n!/bin/bash\nSELECT * FROM \"iceberg-beta\".\"default\".\"order_detail\" LIMIT 10;\n5. Click Run on to run the query.\n6. Select Result set or Details tab to view the results. If required, you can save the query.\n7. Click Saved queries to view the saved queries.\n8. Click [Explain](https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-explain_sql_query) to view the logical or distributed plan of execution for a specified SQL query.\n\n\n\n\n\n\n\n Step 8: Keep exploring \n\n\n\n1. Explore the other tutorials in the documentation.\n2. Monitor the promo code consumption to decide whether to buy, build on (default), decline or manually delete your instance.", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-tutorial_hp_intro"}, {"document_id": "ibmcld_05152-1176-2997", "score": 13.321432, "text": "\nFigure 3 shows the panel that opens when the card is selected. This panel give you control over the location and costs regarding your new instance of IBM Cloud Data Engine. Select the region appropriate for your buckets and the plan suitable for your projects. If you want more information you can use the documentation to [get started](https://cloud.ibm.com/docs/sql-query?topic=sql-query-overview).\n\nZoom\n\n![Create SQL Instance](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/create-sql-instance-cos.jpg)\n\nFigure 3. Fill out form fields to configure your instance\n\n\n\n Querying Object Storage with SQL Query \n\nYou can use SQL Query to create SELECT statements only; actions such as CREATE, DELETE, INSERT, and UPDATE are not possible.\n\nInput data for your queries are read from ORC, CSV, JSON, or Parquet files located in one or more IBM Cloud Object Storage instances. Each query result is written by default to a CSV file in a Cloud Object Storage instance where you created the integration. But you can freely override and customise the format and Object Storage location as part of the SQL statement that you run.\n\nYou can use a custom INTO clause of a SELECT statement to control where and how result data from a SELECT statement is written to IBM Cloud Object Storage.\n\nGetting started using SQL Query SELECT statements from inside your instance is as easy as creating an integration. Objects of queryable data formats, as well as folders with multiple objects of a consistent queryable format (when shown in the \"folders\" view) are labeled as shown in Figure 4.\n\nZoom\n\n![Object with SQL label](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/accessible-using-sql.jpg)\n\nFigure 4.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-sql-query"}, {"document_id": "ibmcld_13493-2289-4276", "score": 12.797178, "text": "\n* Use the INTO clause of a [query](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referencechapterSQLQueryStatement) to specify the output [URI](https://cloud.ibm.com/docs/sql-query?topic=sql-query-runningunique), that is, the location to which the result is to be written and the wanted result format.\n\n\n\n2. The Target location field displays where the result is stored. An initial bucket in one of your Object Storage instances is automatically created for you when you open the UI. It is then chosen as your default location, if your query does not specify an INTO clause. To ensure the automatic setup of an initial bucket, do the following steps in advance:\n\n\n\n* You must create an Object Storage instance.\n* You must have at least 'Writer' access to the corresponding Object Storage bucket.\n\n\n\nIn the Details tab of the selected job, you can set any location that you specified in the INTO clause as your default location.\n3. Click Run.\n\nWhen the query completes, a preview of the query result is displayed in the query result tab of the UI. The preview function is only available for CSV and JSON result formats. You can run up to five queries simultaneously with a Standard plan instance of Data Engine.\n\n\n\n\n\n Sample queries \n\nWhat does a typical query look like? The following sample queries give you an idea to get you started:\n\n\n\n Example of a table exploration query \n\nThe following query selects all columns of a table and limits the result to 50 rows. Use it to explore a particular table.\n\nSELECT \nFROM cos://us-geo/sql/customers.csv STORED AS CSV\nORDER BY CustomerID\nLIMIT 50\n\n\n\n\n\n Example of an exact target path specification \n\nThe following query writes an SQL result into an exact result path. Normally, Data Engine always appends jobid=<jobid> to the provided target path to ensure a unique result location with each query execution. However, in the following sample query, this suffix is eliminated by adding JOBPREFIX NONE to the path in the INTO clause.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-running"}, {"document_id": "ibmcld_13471-1147-2628", "score": 12.771815, "text": "\nThe following SELECT statement combines the observations that have identical time-stamps into a single observation whose value is the original values that are separated by an underscore (_) character:\n\nSELECT TS_COMBINE_DUPLICATE_TIMETICKS(ts1a, TS_COMBINER_CONCATENATE(\"_\"))\nFROM cos://us/sql/timeseries.parquet STORED AS PARQUET\nINTO <your target location> STORED AS PARQUET\n\nFollowing, see the result of the example query:\n\n[(1,\"a\"), (3, \"b\"), (5, \"c_d_e\"), (7, \"f\"), (9, \"g\")]\n\nConsider the following input DoubleTimeSeries, which is stored in a table column with the name ts1b:\n\n[(1,7.0), (3, 8.5), (5, 9.1), (5, 9.3), (5, 9.8), (7, 10.7), (9, 12.2)]\n\nThe following SELECT statement combines the observations that have identical time-stamps into a single observation whose value is the average of the original values.\n\nSELECT TS_COMBINE_DUPLICATE_TIMETICKS(ts1b, TS_COMBINER_AVERAGE())\nFROM cos://us/sql/timeseries.parquet STORED AS PARQUET\nINTO <your target location> STORED AS PARQUET\n\nFollowing, see the result of the example query:\n\n[(1,7.0), (3, 8.5), (5, 9.8), (7, 10.7), (9, 12.2)]\n\n\n\n\n\n Segmentation \n\nSegmentation functions create, as output, a segmented version of a time series. Consider the following input DoubleTimeSeries, which is stored in a table column with the name ts2:\n\n[(1, 1.0), (3, 2.0), (5, 3.0), (7, 4.0), (9, 5.0)]\n\nThe following SELECT statement uses column ts2 and a window size of 2 and a step size of 1 to generate a new DoubleSegmentTimeSeries:", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-examples_common"}]}
{"task_id": "1c041ce47a81941c26899fdf08bde961<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13493-7-1679", "score": 18.048046, "text": "\nRunning a query \n\nWatch the following video to learn more about Data Engine and how you can get started to run a basic query.\n\nIn SQL, the term query is just another way of saying SELECT statement. To run a query:\n\n\n\n1. In the SQL editor field of the Data Engine UI, enter a SELECT statement.\n\n\n\n* After the FROM keyword, specify one or more [unique resource identifiers](https://cloud.ibm.com/docs/sql-query?topic=sql-query-runningunique) (URIs). Each URI can be thought of as a table. It specifies one or more input objects; each input object can be thought of as a table partition. You must have at least 'Reader' access to the buckets that contain the input objects.\n* If the format of the input objects is CSV, and no special options are required, it is not necessary to specify a STORED AS clause. However, if the format is JSON, ORC, Parquet, or AVRO, after the FROM clause, specify STORED AS JSON, STORED AS ORC, STORED AS PARQUET, or STORED AS AVRO.\n* If text formats, such as JSON and CSV, are compressed with either gzip or bzip2 and have the extensions .gz and .bz, they automatically get recognized as compressed files. However, do not use these kinds of compressed files due to performance reasons.\n* If the format of the input objects is CSV and a delimiter other than the default , (comma) is used, you must specify the delimiter by using the FIELDS TERMINATED BY option of the [STORED AS](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause. All single Unicode characters are allowed as delimiters.\n* By default, it is assumed that CSV input objects have a header line that specifies the names of the input columns.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-running"}, {"document_id": "ibmcld_13498-7-2240", "score": 17.332872, "text": "\nSQL reference \n\n\n\n Introduction \n\nWith IBM Cloud\u00ae Data Engine, you can analyze and transform open data with SQL. It supports the various types of SELECT statements from the ANSI SQL standard.\n\nThe SELECT statement (or query statement) is used to read object data from IBM Cloud\u00ae Object Storage (COS), process the data, and store it back on Cloud Object Storage eventually.\n\nYou can use Data Engine as a data transformation service, as it always writes the results of a query to a specified location in either Object Storage or Db2 tables. Data Engine provides extended SQL syntax inside a special INTO clause to control how the result data is stored physically. This extended SQL syntax includes control over data location, format, layout, and partitioning.\n\nA query statement can be submitted through Data Engine's web UI or programmatically, either by using the service's REST API, or by using the Python or Node.JS SDK. You can also use IBM Watson\u00ae Studio and the Python SDK to use Data Engine interactively with Jupyter Notebooks. In addition, you can submit SQL queries that use IBM Cloud\u00ae Functions.\n\nIn addition to the ad hoc usage of data in IBM Cloud\u00ae Object Storage, you can also register and manage your data in a catalog as tables, consisting of columns and partitions.\n\nSeveral benefits to cataloging your data exist:\n\n\n\n* It simplifies SQL SELECT statements because the SQL author does not need not know and specify exactly where and how the data is stored.\n* The SQL execution can skip the inference of schema and partitioning because this information is available in the metastore. Thus, cataloging improves your query performance, especially for text-based data formats, such as CSV and JSON, where the schema inference requires a full scan of the data before the actual query execution.\n\n\n\n\n\n\n\n Select \n\nSee the following examples for an outline of the general syntax of an SQL query statement that uses the query clause and the namedQuery clause.\n\n\n\n query \n\n\n\n\n\n namedQuery \n\n\n\n\n\n intoClause \n\nThe query statement supports common table expressions. A common table expression permits defining a result table with a table name that can be specified as a table name in any FROM clause of the fullselect that follows.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-reference"}, {"document_id": "ibmcld_16662-0-1981", "score": 16.258675, "text": "\n\n\n\n\n\n\n  Running SQL queries \n\nSQL is a standardized language for defining and manipulating data in a relational database. You can use the Query workspace interface in IBM\u00ae watsonx.data to run SQL queries and scripts against your data.\n\nThe Query workspace has the following components:\n\n\n\n*  Data objects: To view the engines, catalogs, schemas, tables, and columns.\n*  Engine: To select an engine and view the associated catalogs.\n*  Saved queries: To view the saved queries.\n*  Worksheet: To write SQL queries.\n\n\n\nThe Query workspace page provides basic options to undo, redo, cut, copy, paste, save, clear, and delete.\n\nFormat selection option is enabled only when an SQL statement in a query worksheet is selected. The Format worksheet option formats all the content in the worksheet. Comment selection is used to explain sections of SQL statements.\n\nThe Delete option is enabled only after an SQL query is saved.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1.  Log in to the watsonx.data console.\n2.  From the navigation menu, select SQL. The Query workspace page opens.\n3.  Select an engine from the Engine drop-down.\n4.  Select the catalog, schema, table, or column in which you want to run the query.\n5.  Click the overflow menu and select the required query.\n\n\n\n*  For a catalog and schema, you can run the Generate Path query.\n*  For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n*  For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\n6.  Click the Save icon to save the query. A Save query confirmation dialog appears.\n7.  Click Save.\n8.  Click the Run button to run the query.\n9.  Select Result set or Details tab to view the results.\n10. Click Saved queries to view the saved queries.\n11. Click [Explain](https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-explain_sql_query) to view the logical or distributed plan of execution for a specified SQL query.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-run_sql"}, {"document_id": "ibmcld_13498-1605-3435", "score": 16.046898, "text": "\nThus, cataloging improves your query performance, especially for text-based data formats, such as CSV and JSON, where the schema inference requires a full scan of the data before the actual query execution.\n\n\n\n\n\n\n\n Select \n\nSee the following examples for an outline of the general syntax of an SQL query statement that uses the query clause and the namedQuery clause.\n\n\n\n query \n\n\n\n\n\n namedQuery \n\n\n\n\n\n intoClause \n\nThe query statement supports common table expressions. A common table expression permits defining a result table with a table name that can be specified as a table name in any FROM clause of the fullselect that follows.\n\nCommon table expressions are defined by using the reserved keyword WITH followed by one or more named queries. Each common table expression that is specified can also be referenced by name in the FROM clause of subsequent common table expressions.\n\nCreating a common table expression avoids the overhead of creating and dropping an intermediate result object on Cloud Object Storage that is needed only for a certain query.\n\nMoreover, a common table expression is beneficial when the same result table must be shared in a fullselect.\n\n\n\n\n\n Examples \n\nThe common table expression examples use values clauses to define tables inline. For more information about the values clause, see [valuesClause](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referencevaluesClause).\n\n-- find the department with the highest total pay\nWITH dtotal AS (\nSELECT\ncol1 AS deptno,\nSUM(col3+col4) AS totalpay\nFROM VALUES -- deptno, empid, salary, bonus\n(1, 1, 1000, 0), (1, 2, 2000, 500), (1, 3, 3000, 0),\n(2, 4, 5000, 200), (2, 5, 6000, 0), (2, 6, 4000, 0),\n(3, 7, 2000, 500), (3, 8, 2000, 500), (3, 9, 8000, 0)\nGROUP BY col1\n)\nSELECT deptno\nFROM dtotal\nWHERE totalpay = (SELECT MAX(totalpay) FROM dtotal)", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-reference"}, {"document_id": "ibmcld_09994-7-1823", "score": 15.9087715, "text": "\nTime travel query syntax and timestamps \n\n\n\n Query syntax \n\nA SELECT query with one or more temporal clauses is a time travel query. Time travel queries might appear as sub-SELECTs in the INSERT, UPDATE, DELETE, MERGE, or CREATE TABLE AS SELECT (CTAS) statements.\n\nAlso, time travel queries might appear in a view definition (CREATE VIEW, with or without OR REPLACE) or a stored procedure definition (CREATE PROCEDURE, with or without OR REPLACE). In either case, timestamp expressions in the syntax (for example, CURRENT_TIMESTAMP - INTERVAL \u20181 day\u2019) are not evaluated at view or procedure definition time, but at the time a user or application queries the view or calls the procedure.\n\nAny base table reference (the table name, with or without database and schema name, and with or without an alias) in a SELECT or sub-SELECT might have an optional temporal clause, which consists of the keywords FOR SYSTEM_TIME followed by one of the following values:\n\n\n\n* AS OF <TIMESTAMP EXPRESSION>\n* BEFORE <TIMESTAMP EXPRESSION>\n* BETWEEN <TIMESTAMP EXPRESSION 1> AND <TIMESTAMP EXPRESSION 2>\n* FROM <TIMESTAMP EXPRESSION 1> TO <TIMESTAMP EXPRESSION 2>\n\n\n\nEach TIMESTAMP EXPRESSION must be one of the following:\n\n\n\n* A literal timestamp value. For example, \u20182022-10-31 20:00:00\u2019.\n* A query parameter or host variable whose value is a timestamp.\n* A built-in function that returns or implicitly converts to a timestamp. For example, CURRENT_DATE, CURRENT_TIMESTAMP or (equivalently) NOW(), or CURRENT_TIMESTAMP(subsecond-digits) or (equivalently) NOW(subsecond-digits).\n* An expression that evaluates to a single timestamp for all rows in the table. For example, CURRENT_TIMESTAMP - INTERVAL \u20181 day\u2019. The expression cannot refer to table columns or to a non-deterministic function (for example, RANDOM()) or be a sub-SELECT.", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-runningqueries_tt"}, {"document_id": "ibmcld_09989-0-1547", "score": 15.137011, "text": "\n\n\n\n\n\n\n  Query editor \n\nWith the query editor, you can run SQL queries on a specific host and database. You can also save any of the queries that you create.\n\n\n\n  Creating queries \n\n\n\n1.  Go to Query editor.\n2.  From Data objects, select the database and schema in which you want to run the query.\nIf you do not pick a schema, the default database schema is selected.\n3.  Type the SQL query that you want to run.\nIf your query is a select statement, a Set Limit option shows up to allow you to specify how many rows of data you would like to retrieve. The default is No limit.\n\nIn the Worksheet settings you can specify your Default maximum number of rows limit in result. If you decide, however, to add a limit clause in a select statement that is greater than your Default maximum number of rows limit in result, for example: select * from table1 limit 10;, the Results field shows the smaller value of these two parameters.\n\nIn the Worksheet settings you can also specify the Statement separator you want to use. A semicolon (\";\") is the default Statement separator and you must change it to an ampersand (\"&\") when your queries contain semicolons (\";\") to avoid errors.\n4.  When you input the information, you can do one of the following:\n\n\n\n*  Click Run to run the query.\nThe results of the query are displayed in the panel.\n*  Click the floppy disk icon that is in the SQLworksheet toolbar to save the query as a template.\nThe saved query is added to Saved queries and Queries > Recent Queries.\n*  Click Clear to clear the query.\n\n\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-query-editor"}, {"document_id": "ibmcld_05152-4777-6005", "score": 14.545433, "text": "\n[SQL Query Window](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/select-with-sql.jpg)\n\nFigure 7. Access with SQL query window\n\nThe entry representing the job of the SELECT statement run previously is shown in Figure 8. There are two tabs, \"Results\" and \"Details,\" at the top of the list that allow you to switch between seeing the results and more detailed information.\n\nZoom\n\n![SQL Query Results](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/results-from-sql.jpg)\n\nFigure 8. Access with SQL query jobs\n\nThe entry representing the details of running the SELECT statement run previously is shown in Figure 9.\n\nZoom\n\n![SQL Query Details](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/details-from-sql.jpg)\n\nFigure 9. Access with SQL query jobs\n\n\n\n\n\n Next Steps \n\nFor more information on using Data Engine see the [Data Engine documentation](https://cloud.ibm.com/docs/sql-query?topic=sql-query-overview) and [Analyzing Data with IBM Cloud SQL Query](https://www.ibm.com/cloud/blog/analyzing-data-with-ibm-cloud-sql-query).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-sql-query"}, {"document_id": "ibmcld_13499-7-1400", "score": 14.187573, "text": "\nSQL functions \n\nYou can use any of the following functions in your query.\n\n\n\n ! \n\nexpr\n: Logical not.\n\n\n\n\n\n % \n\nexpr1 % expr2\n: Returns the remainder after expr1/expr2.\n: Example of an SQL function usage fragment\n\n> SELECT 2 % 1.8\n: Result value\n\n0.2\n: Example of an SQL function usage fragment\n\n> SELECT MOD(2, 1.8)\n: Result value\n\n0.2\n\n\n\n\n\n & \n\nexpr1 & expr2\n: Returns the result of bitwise AND of expr1 and expr2.\n: Example of an SQL function usage fragment\n\n> SELECT 3 & 5\n: Result value\n\n1\n\n\n\n\n\n * \n\nexpr1 * expr2\n: Returns expr1*expr2.\n: Example of an SQL function usage fragment\n\n> SELECT 2 * 3\n: Result value\n\n6\n\n\n\n\n\n + \n\nexpr1 + expr2\n: Returns expr1+expr2.\n: Example of an SQL function usage fragment\n\n> SELECT 1 + 2\n: Result value\n\n3\n\n\n\n\n\n - \n\nexpr1 - expr2\n: Returns expr1-expr2.\n: Example of an SQL function usage fragment\n\n> SELECT 2 - 1\n: Result value\n\n1\n\n\n\n\n\n / \n\nexpr1 / expr2\n: Returns expr1/expr2. It always performs floating point division.\n: Example of an SQL function usage fragment\n\n> SELECT 3 / 2\n: Result value\n\n1.5\n: Example of an SQL function usage fragment\n\n> SELECT 2L / 2L\n: Result value\n\n1.0\n\n\n\n\n\n < \n\nexpr1 < expr2\n: Returns true if expr1 is less than expr2.\n: Arguments\n\nexpr1, expr2 - The two expressions must be same type or can be cast to a common type, and must be a type that can be ordered. For example, map type is not orderable, so it is not supported.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-sqlfunctions"}, {"document_id": "ibmcld_13498-48160-49912", "score": 14.065309, "text": "\nSELECT statements can retrieve and join column values from two or more tables into a single row. The retrieval is based on a specified condition, typically of matching column values.\n\nThe main characteristic of a join is, typically, matching column values in rows of each table that participates in the join. The result of a join associates rows from one table with rows from another table. Depending on the type of join operation, some rows might be formed that contain column values in one table that do not match column values in another table.\n\nA joined table specifies an intermediate result table that is the result of either an INNER join, an OUTER join, a CROSS join, or an ANTI join. The table is derived by applying one of the join operators to its operands.\n\n\n\n\n\n joinType \n\n\n\n Inner join \n\nAn INNER join combines each row of the left table with each row of the right table, keeping only the rows in which the join condition is true.\n\n-- inner join query\nSELECT\nleft_table.col1 AS l_col1,\nleft_table.col2 AS l_col2,\nright_table.col1 AS r_col1,\nright_table.col2 AS r_col2\nFROM\nVALUES (0, 10), (1, 11), (2, 12), (3,13), (4, 14), (5, 14) AS left_table\nINNER JOIN\nVALUES (0, 10), (2, 12), (4, 14), (6, 16) AS right_table\nON left_table.col1 = right_table.col1\n\nThe result of the example query is shown in the following table.\n\n\n\nTable 18. Query result for example.\n\n L_COL1 L_COL2 R_COL1 R_COL2 \n\n 0 10 0 10 \n 2 12 2 12 \n 4 14 4 14 \n\n\n\n\n\n\n\n Outer join \n\nAn OUTER join includes the rows that are produced by the inner join, plus the missing rows, depending on the type of outer join.\n\nA LEFT OUTER or LEFT join includes the rows from the left table that were missing from the inner join.\n\n-- left outer join query\nSELECT\nleft_table.col1 AS l_col1,", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-reference"}, {"document_id": "ibmcld_13498-39344-41146", "score": 13.868619, "text": "\nWith this function, you can write results, for example, into Parquet, without the need to provide column by column alias names in your SQL when your input data has columns with these characters. A typical situation is the existence of space () in input columns.\n\nFor example, you can use SELECT * FROM CLEANCOLS(cos://us-geo/sql/iotmessages STORED AS JSON) INTO cos://us-geo/mybucket/myprefix STORED AS PARQUET to produce a result set that can be stored as is into Parquet target format.\n\nIf you wrap your external table definition with the DESCRIBE table transformer, the table does not show its actual content but the schema that is inferred from the objects in IBM Cloud\u00ae Object Storage instead. With this function, you can explore the schema before you author your actual SQL statements against it.\n\nWhen you use the DESCRIBE table transformer in your SQL statement, the default output format is JSON instead of CSV.\n\nYou can also wrap DESCRIBE around the other table transformers to explore the transformed table schema. However, you cannot wrap other table transformers around the DESCRIBE transformer.\n\n\n\n\n\n tableValuedFunction \n\nA table-valued function returns a relation, which is a set of rows. An example of a table-valued function is range(). For more information, see [SQL functions](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sqlfunctionssqlfunctions).\n\n\n\n\n\n More topics - relation clause \n\nFor more information about the clauses that are used in relation clauses, see the following topics:\n\n\n\n* [booleanExpression](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referencebooleanExpression)\n* [COSURI](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referenceCOSURI)\n* [expression](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referenceexpression)", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-reference"}]}
{"task_id": "1c041ce47a81941c26899fdf08bde961<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07045-7-2118", "score": 13.834069, "text": "\nImproving your query results \n\nLearn about actions you can take to improve the quality of your query results.\n\nYou can use the tools that are built in to Discovery to make improvements.\n\n\n\n Results include more than exact matches \n\nUnlike some other search applications, adding quotation marks to a phrase that you submit does not return only exact matches. Queries that are submitted from the product user interface are natural language queries. When quoted text is submitted in a natural language query, the phrase is used to boost result scores. However, results are not limited to documents that contain the entire phrase.\n\nIf you want more control over how queries are handled, you must use the query API. For more information about the phrase operator of the query API, see [Query operators](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-operatorsphrase).\n\n\n\n\n\n A short query returns irrelevant results \n\nIt might be that your query contains too many stop words and not enough distinct terms to trigger a meaningful search. When you submit a query, the query text is analyzed and optimized before it is submitted to the project. One of the changes that occurs is the removal of any stop words from the text. A stop word is a word that is considered to be not useful in distinguishing the semantic meaning of the content. Examples of stop words include terms such as and, the, and about. Discovery defines a list of stop words that it ignores automatically both when the data is indexed and when it is searched. When you submit a query that contains mostly or only stop words, such as About us, it is equivalent to submitting an empty query.\n\nAlthough us is not included in the stop words list, it is lemmatized to we, which is listed as a stop word.\n\nYou can edit the stop words that are used by your collection. However, you can only augment the stop words list; you cannot remove stop words. And the stop words that you define are used only at query time. They do not affect the stop word list that is used by Discovery when data is added to a collection and the index is created.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-improvements"}, {"document_id": "ibmcld_07046-1542-3607", "score": 13.6342535, "text": "\nMost of the content that is returned in search results that you submit from the Improve and customize page originates from this one field. How to parse and return only relevant chunks of information from this field is determined by the query result configuration that is used by the project. For more information, see [Previewing the default query results](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-results).\n\nMore processing adds more fields. And more processing is applied automatically depending on the project type. When processes run on documents in a collection, extra fields are added to store information that is associated with the process. For example, when the built-in Entities enrichment is applied to a collection, it starts a process that adds fields with names that begin with enriched_{field_name}.entities to the documents in the collection.\n\n\n\n* For more information about the enrichments that are applied by default, see [Default project settings](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-project-defaults).\n\n\n\n\n\n How fields are handled \n\nFor most unstructured file types, the bulk of the content from the file is added to a field named text. For file types that have an inherent data structure, such JSON files, names from the source file are used to name the fields in which the content is stored. When you upload files of this type, be aware of some naming limitations that exist for fields.\n\nThe following field names have special meaning. If possible, do not use these names in your structured source files.\n\n\n\n* document_id\n* highlight\n* html\n* metadata\n* parent_document_id\n* result_metadata\n* score\n* spans\n\n\n\nAvoid field names that meet the following conditions. Field names with these restricted characters are not queried.\n\n\n\n* Start with the characters _, +, and -. For example, +extracted-content.\n* Contain the characters ., ,, , ?, (, ), or : or spaces. For example, extracted content or new:extracted-content.\n* End with numbers, for example, extracted-content2.\n\n\n\n\n\n HTML fields", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-index-overview"}, {"document_id": "ibmcld_13075-7-2200", "score": 13.344766, "text": "\nImproving result relevance with the tooling \n\nThe relevance of natural language query results can be improved in IBM Watson\u2122 Discovery with training. You can train your private collections using either the Discovery tooling, or the Discovery APIs. See [Improving the relevance of your query results with the API](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-api) if you would prefer to use the APIs.\n\nRelevancy training is optional; if the results of your queries meet your needs, no further training is necessary. For information about use cases for relevancy training, see [Improve your natural language query results from Watson Discovery](https://developer.ibm.com/blogs/improving-your-natural-language-query-results-from-watson-discovery/).\n\nTo train Watson, you must provide the following:\n\n\n\n* Example queries that are representative of the queries your users enter\n* Ratings that indicate which results for each query are relevant and not relevant\n\n\n\nAfter Watson has enough training input, the information that you provide about which results are good and bad for each query is used to learn about your collection. Watson does not just memorize, but it also learns from the specific information about individual queries and applies the patterns it detects to all new queries. It does so, using machine-learning Watson techniques that find signals in your content and questions. After training, Discovery then reorders the query results to display the most relevant results at the top. As you add more and more training data, Discovery becomes more accurate in the ordering of query results.\n\nRelevance training currently applies only to natural language queries in private collections. It is not intended for use with structured Discovery Query Language queries. For more about the Discovery Query Language, see [Query concepts](https://cloud.ibm.com/docs/discovery?topic=discovery-query-concepts).\n\nAll private collections return a confidence score in the query results in most cases. For more information, see [Confidence scores](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).", "title": "", "source": "https://cloud.ibm.com/docs/services/discovery?topic=discovery-improving-result-relevance-with-the-tooling"}, {"document_id": "ibmcld_07163-7-1995", "score": 13.20191, "text": "\nImproving result relevance with the API \n\nYou can train Discovery to improve the relevance of query results for your particular organization or subject area. When you provide a Discovery instance with training data, the service uses machine-learning Watson techniques to find signals in your content and questions. The service then reorders query results to display the most relevant results at the top. As you add more training data, the service instance becomes more accurate and sophisticated in the ordering of results it returns.\n\nRelevancy training is optional; if the results of your queries meet your needs, no further training is necessary. For information about use cases for relevancy training, see [Improve your natural language query results from Watson Discovery](https://developer.ibm.com/blogs/improving-your-natural-language-query-results-from-watson-discovery/).\n\nFor comprehensive information about the training APIs, see the [API reference](https://cloud.ibm.com/apidocs/discovery).\n\nIf you would prefer to use the Discovery tooling to train Discovery, see [Improving result relevance with the tooling](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\nRelevance training currently applies only to natural language queries in private collections. It is not intended for use with structured Discovery Query Language queries. For more about the Discovery Query Language, see [Query concepts](https://cloud.ibm.com/docs/discovery?topic=discovery-query-concepts).\n\nTrained collections return a confidence score in the result of a natural language query. See [Confidence scores](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence) for details.\n\nAdding a custom stopwords list can improve the relevance of results for natural language queries. See [Defining stopwords](https://cloud.ibm.com/docs/discovery?topic=discovery-query-conceptsstopwords) for more information.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-api"}, {"document_id": "ibmcld_07108-2897-3942", "score": 13.147641, "text": "\nYou can use the [expansions.json](https://watson-developer-cloud.github.io/doc-tutorial-downloads/discovery/expansions.json) file as a starting point when you build a query expansion list.\n2. From the navigation pane, open the Improve and customize page.\n3. Expand Improve relevance from the Improvement tools pane.\n4. Click Synonyms, and then click Upload synonyms for the collection.\n\nDo not upload a synonyms file while documents are being added to your collection. The ingestion processing that occurs when documents are added can cause the index to be unavailable.\n\nOnly one synonyms list can be uploaded per collection. If a second expansion list is uploaded, the second list replaces the first.\n5. Run a test query to verify that the query expansion is working as expected.\n\nQuery expansions are applied at query time, not during indexing, so you can add synonyms without reprocessing your collection.\n\n\n\nTo disable query expansion, delete the synonyms file. However, do not delete a synonyms file while new documents are being processed.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-search-settings"}, {"document_id": "ibmcld_07175-1564-2340", "score": 13.060373, "text": "\nFor more about training requirements and options, see [Improving result relevance with the tooling](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\n\n\n\n\n Query overview \n\nThe Query overview section displays:\n\n\n\n* The total number of queries made by users\n* The percentage of queries with one or more results clicked\n* The percentage of queries with no results clicked\n* The percentage of queries with no results returned\n* A graph that displays these results over time, so that you can track how adding more data and relevancy training are improving performance\n\n\n\nThese results are gathered using the Events and Feedback API. See the [API reference](https://cloud.ibm.com/apidocs/discoverycreate-event) for more information.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-performance-dashboard"}, {"document_id": "ibmcld_07115-7009-9068", "score": 13.029379, "text": "\n* The rating that you apply to the result that indicates whether the result is relevant or not relevant\n\n\n\nTo apply relevancy training to a project, complete the following steps:\n\n\n\n1. Go to the Improve and customize page. On the Improvement tools panel, select Improve relevance, then Relevancy training.\n2. Enter a natural language query in the Enter a question to train field.\n\nDo not include a question mark in your query. Use the same wording as your users. For example, IBM Watson in healthcare. Write queries that include some of the terms that are mentioned in the target answer. Term overlap improves the initial results when the natural language query is evaluated.\n3. Click Add+.\n4. Click Rate results.\n5. After the results are displayed, assess each result, and then select Relevant or Not relevant, whichever option applies given the quality of the result.\n\nWhen you select Relevant, you apply a score of 10 to the result. Not relevant applies a score of 0. You can use a different scoring scale if you use the API to rate results, but you can't mix scoring scales within the same project.\n\nIf the result shows the message, \u201cNo content preview available for this document\u201d, it means that the document that was returned does not contain a text field or that its text field is empty. If none of the documents in your collection have a text field, use the API to train the project instead of training it from the product user interface.\n6. When you are finished, click Back to queries.\n7. Continue adding queries and rating them.\n\nAs you rate results, your progress is shown. Check your progress to see when enough rating information is available to meet the training threshold needs. Your progress is broken into the following tasks:\n\n\n\n* Add more queries\n* Rate more results\n* Add more variety to your ratings\n\n\n\nYou must evaluate at least 50 unique queries, maybe more, depending on the complexity of your data. You cannot add more than 10,000 training queries.\n8. You can continue adding queries and rating results after you reach the threshold.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-train"}, {"document_id": "ibmcld_13075-1823-3835", "score": 12.868484, "text": "\nFor more about the Discovery Query Language, see [Query concepts](https://cloud.ibm.com/docs/discovery?topic=discovery-query-concepts).\n\nAll private collections return a confidence score in the query results in most cases. For more information, see [Confidence scores](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n\nAdding a custom stopwords list can improve the relevance of results for natural language queries. See [Defining stopwords](https://cloud.ibm.com/docs/discovery?topic=discovery-query-conceptsstopwords) for more information.\n\nSee [Training data requirements](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-apireqs) for the minimum requirements for training, as well as the training limits.\n\nSee [Usage monitoring](https://cloud.ibm.com/docs/discovery?topic=discovery-usage) for details on tracking usage and using this data to help you understand and improve your applications.\n\n\n\n Adding queries and rating the relevancy of results \n\nTraining consists of three parts: a natural language query, the results of the query, and the ratings you apply to those results.\n\n\n\n1. There are two ways to access the training page in the Discovery tooling:\n\n\n\n* For an individual collection, on the Build queries screen, click Train Watson to improve results on the upper right. You don't need to enter a query on the Build queries screen to start training.\n* From the Performance dashboard. Click on the View data metrics icon on the left to open the dashboard. You are prompted to choose a collection to train.\n\n\n\n2. On the Train Watson screen, click Add a natural language query, for example: \"IBM Watson in healthcare\", and add it. Make sure your queries are written the way your users would ask them. Also, it is recommended that training queries be written with some term overlap between the query and the desired answer. This overlap improves initial results, when the natural language query is run.", "title": "", "source": "https://cloud.ibm.com/docs/services/discovery?topic=discovery-improving-result-relevance-with-the-tooling"}, {"document_id": "ibmcld_07086-8636-10851", "score": 12.827746, "text": "\nSuch operations include queries that are submitted by using the API. It does not include queries that are submitted from the search bar on the Improve and customize page of the product user interface.\n\nA query is counted only if the request is successful, meaning it returns a response (with message code 200).\n\nThe number of search queries that you can submit per month per service instance depends on your Discovery plan type.\n\n\n\nNumber of queries per month\n\n Plan Queries per month per service instance \n\n Cloud Pak for Data Unlimited \n Premium Unlimited \n Enterprise Unlimited \n Plus (includes Trial) 500,000 \n\n\n\nFor Enterprise plans only, your bill labels requests that are generated from both query searches and analyze API calls as \"Queries\". For more information about Analyze API calls, see [Analyze API limits](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-analyzeapianalyzeapi-limits).\n\nThe number of queries that can be processed per second per service instance depends on your Discovery plan type.\n\n\n\nNumber of concurrent queries\n\n Plan Concurrent queries per service instance \n\n Cloud Pak for Data Unlimited \n Premium 50 \n Enterprise 5 \n Plus (includes Trial) 5 \n\n\n\nFor information about pricing, see [Discovery pricing plans](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-pricing-plans).\n\n\n\n\n\n Estimating query usage \n\nHow to estimate the number of queries your application will use per month depends on your use case.\n\n\n\n* For use cases that focus more on data enrichment and analysis or where the output from the document processing is not heavily searched, you can estimate query numbers based on the total number of documents.\n* For use cases where many users interact with the application that uses Discovery, you can estimate by calculating the number of searches per user times the number of expected users. For example, 50% of the questions that are submitted by users to a virtual assistant are likely to be answered by Discovery. With 100,000 users per month and an average of 3 questions per user, you can expect 15,000 queries per month. (10,000 users/mo * 3 queries/user * 50% to Discovery = 15,000)\n\n\n\n\n\n\n\n Querying with document-level security enabled", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-concepts"}, {"document_id": "ibmcld_07175-7-2035", "score": 12.824603, "text": "\nViewing metrics and improving query results with the Performance dashboard \n\nThe Performance dashboard in the Discovery tooling can be used to view query metrics, as well as improve query results, including query relevance.\n\nYou can access the Performance dashboard by clicking the View data metrics icon. The dashboard is not available in Premium or Dedicated environments.\n\nThere are two options to improve natural language query results:\n\n\n\n* [Fix queries with no results by adding more data](https://cloud.ibm.com/docs/discovery?topic=discovery-performance-dashboardaddmore)\n* [Bring relevant results to the top by training your data](https://cloud.ibm.com/docs/discovery?topic=discovery-performance-dashboardtraindata)\n\n\n\nYou can view the data metrics in the [query overview](https://cloud.ibm.com/docs/discovery?topic=discovery-performance-dashboardoverview).\n\n\n\n Fix queries with no results by adding more data \n\nIn this section of the dashboard, you can review queries that returned zero results and add more data so that the query returns results in the future. Click the View all and add data button to get started.\n\n\n\n\n\n Bring relevant results to the top by training your data \n\nIn this section, you can train your collections to improve the relevance of natural language query results. Click the View all and perform relevancy training button to get started. Then see [Adding queries and rating the relevancy of results](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-toolingresults) for instructions.\n\nFor more about training requirements and options, see [Improving result relevance with the tooling](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\n\n\n\n\n Query overview \n\nThe Query overview section displays:\n\n\n\n* The total number of queries made by users\n* The percentage of queries with one or more results clicked\n* The percentage of queries with no results clicked\n* The percentage of queries with no results returned", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-performance-dashboard"}]}
{"task_id": "1c041ce47a81941c26899fdf08bde961<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13498-7-2240", "score": 20.353827, "text": "\nSQL reference \n\n\n\n Introduction \n\nWith IBM Cloud\u00ae Data Engine, you can analyze and transform open data with SQL. It supports the various types of SELECT statements from the ANSI SQL standard.\n\nThe SELECT statement (or query statement) is used to read object data from IBM Cloud\u00ae Object Storage (COS), process the data, and store it back on Cloud Object Storage eventually.\n\nYou can use Data Engine as a data transformation service, as it always writes the results of a query to a specified location in either Object Storage or Db2 tables. Data Engine provides extended SQL syntax inside a special INTO clause to control how the result data is stored physically. This extended SQL syntax includes control over data location, format, layout, and partitioning.\n\nA query statement can be submitted through Data Engine's web UI or programmatically, either by using the service's REST API, or by using the Python or Node.JS SDK. You can also use IBM Watson\u00ae Studio and the Python SDK to use Data Engine interactively with Jupyter Notebooks. In addition, you can submit SQL queries that use IBM Cloud\u00ae Functions.\n\nIn addition to the ad hoc usage of data in IBM Cloud\u00ae Object Storage, you can also register and manage your data in a catalog as tables, consisting of columns and partitions.\n\nSeveral benefits to cataloging your data exist:\n\n\n\n* It simplifies SQL SELECT statements because the SQL author does not need not know and specify exactly where and how the data is stored.\n* The SQL execution can skip the inference of schema and partitioning because this information is available in the metastore. Thus, cataloging improves your query performance, especially for text-based data formats, such as CSV and JSON, where the schema inference requires a full scan of the data before the actual query execution.\n\n\n\n\n\n\n\n Select \n\nSee the following examples for an outline of the general syntax of an SQL query statement that uses the query clause and the namedQuery clause.\n\n\n\n query \n\n\n\n\n\n namedQuery \n\n\n\n\n\n intoClause \n\nThe query statement supports common table expressions. A common table expression permits defining a result table with a table name that can be specified as a table name in any FROM clause of the fullselect that follows.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-reference"}, {"document_id": "ibmcld_05152-4777-6005", "score": 17.68099, "text": "\n[SQL Query Window](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/select-with-sql.jpg)\n\nFigure 7. Access with SQL query window\n\nThe entry representing the job of the SELECT statement run previously is shown in Figure 8. There are two tabs, \"Results\" and \"Details,\" at the top of the list that allow you to switch between seeing the results and more detailed information.\n\nZoom\n\n![SQL Query Results](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/results-from-sql.jpg)\n\nFigure 8. Access with SQL query jobs\n\nThe entry representing the details of running the SELECT statement run previously is shown in Figure 9.\n\nZoom\n\n![SQL Query Details](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/details-from-sql.jpg)\n\nFigure 9. Access with SQL query jobs\n\n\n\n\n\n Next Steps \n\nFor more information on using Data Engine see the [Data Engine documentation](https://cloud.ibm.com/docs/sql-query?topic=sql-query-overview) and [Analyzing Data with IBM Cloud SQL Query](https://www.ibm.com/cloud/blog/analyzing-data-with-ibm-cloud-sql-query).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-sql-query"}, {"document_id": "ibmcld_09437-1591-3613", "score": 17.621296, "text": "\nUsers need the platform viewer role to launch the UI, and the service writer role to run queries. For more information about roles, see [Required user roles](https://cloud.ibm.com/docs/sql-query?topic=sql-query-overviewuser-roles).\n* When you open the UI, the Data Engine service automatically generates a unique COS bucket that will store all of the results as CSV files from your SQL queries.\n\n\n\nUse the Data Engine user interface (UI) to develop and test your queries, and the SQL Query REST API to automate them.\n\nYou can use the Data Engine to run SQL queries (that is, SELECT statements) to analyze, transform structured and semi-structured data, or clean up rectangular data. You cannot run actions such as CREATE, DELETE, INSERT, and UPDATE. The Data Engine service can process input data that is read from CSV, JSON, ORC, Parquet, or AVRO files.\n\nThe archive files from an Log Analysis instance contain data in JSON format.\n\n\n\n* If your log data consists of rectangular data with heterogeneous data types, you should transform the format to partitioned JSON objects to query successfully the data.\n* If your log data consists of rectangular data with homogeneous data types, you should transform the format to PARQUET to query successfully the data and obtain better performance. Parquet is an open source file format that stores nested data structures into a flat columnar format, and preserves the schema of the original data.\n* Each query result can be written to a CSV, JSON, ORC, PARQUET, or AVRO file in a Object Storage instance of your choice.\n\n\n\nFor more information, see [Data Engine overview](https://cloud.ibm.com/docs/sql-query?topic=sql-query-overview).\n\n\n\n Prerequisites \n\nTo be able to use the Data Engine service to query archived event files, check the following prerequisites:\n\n\n\n* You must have access to the COS instance where the logging data is available.\n\nYou must have access to a bucket that contains the Log Analysis archive files and a bucket to use to store results from your queries.", "title": "", "source": "https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-sqlquery"}, {"document_id": "ibmcld_05152-7-1585", "score": 17.256266, "text": "\nUsing SQL Query \n\nIBM Cloud\u00ae Data Engine is a fully-managed service that lets you run SQL queries (that is, SELECT statements) to analyze, transform, or clean up rectangular data using the full ANSI SQL standard.\n\nWhen you use the console to interact with your instance of IBM Cloud Object Storage, there are instances of IBM Cloud SQL Query automatically recognised in the new \"Integrations\" panel. You can also create new instances of IBM Cloud Data Engine directly from the \"Integrations\" panel in your browser. See Figure 1, showing the option to integrate services like Data Engine next to your credentials and buckets.\n\nZoom\n\n![Integrations in COS](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/integrate-from-cos.jpg)\n\nFigure 1. Integrate SQL Query from COS instance\n\nSelect the card detailing the options and offering for IBM Cloud Data Engine. This is shown in Figure 2.\n\nZoom\n\n![Integrate SQL Query](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/integrate-with-sql.jpg)\n\nFigure 2. Select the SQL Query card to integrate\n\nFigure 3 shows the panel that opens when the card is selected. This panel give you control over the location and costs regarding your new instance of IBM Cloud Data Engine. Select the region appropriate for your buckets and the plan suitable for your projects. If you want more information you can use the documentation to [get started](https://cloud.ibm.com/docs/sql-query?topic=sql-query-overview).\n\nZoom\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-sql-query"}, {"document_id": "ibmcld_13490-941-2651", "score": 17.155663, "text": "\nUse the Data Engine user interface (UI) to [develop your queries](https://cloud.ibm.com/docs/sql-query?topic=sql-query-running) and the [Data EngineREST API](https://cloud.ibm.com/docs/sql-query?topic=sql-query-overviewrestapi) to automate them.\n\n\n\n Input and output of queries \n\nBefore you can use the Data Engine service to run SQL queries, the input data must be uploaded to one or more Cloud Object Storage instances. You must also have at least 'Writer' access to at least one Cloud Object Storage bucket, so that result objects (that is, the objects that contain output data) can be written there. For more information about Cloud Object Storage, including how to provision an instance, create buckets, and upload data, see the [Cloud Object Storage Getting Started Guide](https://cloud.ibm.com/docs/cloud-object-storage/getting-started.htmlgetting-started-console) and [Reading and writing to Cloud Object Storage](https://cloud.ibm.com/docs/sql-query/blob/draft/reading_cos.md). You can also [write to databases](https://cloud.ibm.com/docs/sql-query/blob/draft/writing_databases.md) and take advantage of [index management](https://cloud.ibm.com/docs/sql-query?topic=sql-query-index_management).\n\n\n\n\n\n Programmatic access \n\n\n\n REST API \n\nYou can use the [Data Engine service REST API](https://cloud.ibm.com/apidocs/sql-query/sql-query-v3) to run queries and retrieve information about their status. This is especially helpful when you write code that automatically queries data.\n\nNote: The Cloud Resource Name (CRN) is a mandatory part of a Data Engine REST endpoint call. The CRN Copy button copies your CRN to clipboard and you can paste it into your API call.\n\n\n\n\n\n Python applications and Notebooks", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-overview"}, {"document_id": "ibmcld_09989-0-1547", "score": 17.146235, "text": "\n\n\n\n\n\n\n  Query editor \n\nWith the query editor, you can run SQL queries on a specific host and database. You can also save any of the queries that you create.\n\n\n\n  Creating queries \n\n\n\n1.  Go to Query editor.\n2.  From Data objects, select the database and schema in which you want to run the query.\nIf you do not pick a schema, the default database schema is selected.\n3.  Type the SQL query that you want to run.\nIf your query is a select statement, a Set Limit option shows up to allow you to specify how many rows of data you would like to retrieve. The default is No limit.\n\nIn the Worksheet settings you can specify your Default maximum number of rows limit in result. If you decide, however, to add a limit clause in a select statement that is greater than your Default maximum number of rows limit in result, for example: select * from table1 limit 10;, the Results field shows the smaller value of these two parameters.\n\nIn the Worksheet settings you can also specify the Statement separator you want to use. A semicolon (\";\") is the default Statement separator and you must change it to an ampersand (\"&\") when your queries contain semicolons (\";\") to avoid errors.\n4.  When you input the information, you can do one of the following:\n\n\n\n*  Click Run to run the query.\nThe results of the query are displayed in the panel.\n*  Click the floppy disk icon that is in the SQLworksheet toolbar to save the query as a template.\nThe saved query is added to Saved queries and Queries > Recent Queries.\n*  Click Clear to clear the query.\n\n\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-query-editor"}, {"document_id": "ibmcld_13111-941-2660", "score": 17.094555, "text": "\nUse the Data Engine user interface (UI) to [develop your queries](https://cloud.ibm.com/docs/sql-query?topic=sql-query-running) and the [Data EngineREST API](https://cloud.ibm.com/docs/services/sql-query?topic=sql-query-overviewrestapi) to automate them.\n\n\n\n Input and output of queries \n\nBefore you can use the Data Engine service to run SQL queries, the input data must be uploaded to one or more Cloud Object Storage instances. You must also have at least 'Writer' access to at least one Cloud Object Storage bucket, so that result objects (that is, the objects that contain output data) can be written there. For more information about Cloud Object Storage, including how to provision an instance, create buckets, and upload data, see the [Cloud Object Storage Getting Started Guide](https://cloud.ibm.com/docs/cloud-object-storage/getting-started.htmlgetting-started-console) and [Reading and writing to Cloud Object Storage](https://cloud.ibm.com/docs/sql-query/blob/draft/reading_cos.md). You can also [write to databases](https://cloud.ibm.com/docs/sql-query/blob/draft/writing_databases.md) and take advantage of [index management](https://cloud.ibm.com/docs/sql-query?topic=sql-query-index_management).\n\n\n\n\n\n Programmatic access \n\n\n\n REST API \n\nYou can use the [Data Engine service REST API](https://cloud.ibm.com/apidocs/sql-query/sql-query-v3) to run queries and retrieve information about their status. This is especially helpful when you write code that automatically queries data.\n\nNote: The Cloud Resource Name (CRN) is a mandatory part of a Data Engine REST endpoint call. The CRN Copy button copies your CRN to clipboard and you can paste it into your API call.\n\n\n\n\n\n Python applications and Notebooks", "title": "", "source": "https://cloud.ibm.com/docs/services/sql-query?topic=sql-query-overview"}, {"document_id": "ibmcld_16662-0-1981", "score": 17.076834, "text": "\n\n\n\n\n\n\n  Running SQL queries \n\nSQL is a standardized language for defining and manipulating data in a relational database. You can use the Query workspace interface in IBM\u00ae watsonx.data to run SQL queries and scripts against your data.\n\nThe Query workspace has the following components:\n\n\n\n*  Data objects: To view the engines, catalogs, schemas, tables, and columns.\n*  Engine: To select an engine and view the associated catalogs.\n*  Saved queries: To view the saved queries.\n*  Worksheet: To write SQL queries.\n\n\n\nThe Query workspace page provides basic options to undo, redo, cut, copy, paste, save, clear, and delete.\n\nFormat selection option is enabled only when an SQL statement in a query worksheet is selected. The Format worksheet option formats all the content in the worksheet. Comment selection is used to explain sections of SQL statements.\n\nThe Delete option is enabled only after an SQL query is saved.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1.  Log in to the watsonx.data console.\n2.  From the navigation menu, select SQL. The Query workspace page opens.\n3.  Select an engine from the Engine drop-down.\n4.  Select the catalog, schema, table, or column in which you want to run the query.\n5.  Click the overflow menu and select the required query.\n\n\n\n*  For a catalog and schema, you can run the Generate Path query.\n*  For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n*  For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\n6.  Click the Save icon to save the query. A Save query confirmation dialog appears.\n7.  Click Save.\n8.  Click the Run button to run the query.\n9.  Select Result set or Details tab to view the results.\n10. Click Saved queries to view the saved queries.\n11. Click [Explain](https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-explain_sql_query) to view the logical or distributed plan of execution for a specified SQL query.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-run_sql"}, {"document_id": "ibmcld_02522-1317-3277", "score": 17.005995, "text": "\nUse the Data Engine user interface (UI) to develop and test your queries, and the [SQL Query REST API](https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-sqlqueryrestapi) to automate them.\n\nThe Data Engine service provides a serverless, no-ETL solution to easily query data stored in Object Storage. Underneath, SQL Query uses Apache Spark SQL as its underlying query engine.\n\nYou can use the Data Engine to run SQL queries (that is, SELECT statements) to analyze, transform structured and semi-structured data, or clean up rectangular data. You cannot run actions such as CREATE, DELETE, INSERT, and UPDATE.\n\nThe Data Engine service can process input data that is read from CSV, JSON, ORC, Parquet, or AVRO files. The archive files from an IBM Cloud Activity Tracker instance contain data in JSON format.\n\nEach query result can be written to a CSV, JSON, ORC, PARQUET, or AVRO file in a Object Storage instance of your choice.\n\nWhen you query an IBM Cloud Activity Tracker archive file, you must convert the JSON formatted file into PARQUET format to be able to query the contents successfully.\n\n\n\n Prerequisites \n\nTo be able to use the Data Engine service to query archived event files, check the following prerequites:\n\n\n\n* You must have access to a COS instance in your account.\n\nYou must have access to a bucket that contains the IBM Cloud Activity Tracker archive files and a bucket to use to store results from your queries.\n* You must have an IBM Cloud Activity Tracker instance provisioned in your account that has [archiving configured to a bucket in the COS instance in your account](https://cloud.ibm.com/docs/services/activity-tracker?topic=activity-tracker-archiving).\n\nEvents are archived daily to a file in a COS bucket.\n\nNotice that if archiving is not configured, you must wait at least 24 hours before an archive file is available after archiving is configured.\n* You must have 1 or more archive files uploaded in the bucket.", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-sqlquery"}, {"document_id": "ibmcld_00512-5160-7348", "score": 16.965006, "text": "\nSee also a brief overview of the underlying querying mechanism that you use to select the query mechanism that is best for each query your application needs to make.\n\n\n\n Global querying \n\nYou can make global queries to the following index types:\n\n\n\n* IBM Cloudant Query\n* Views\n* Search\n\n\n\nWhen you make a global query, the database must perform a scatter-gather operation across all data in the database. This action means making requests of many individual database servers. The API coordination node receives the responses from all these servers and combines them to form a single response to the client. This response might involve buffering data and delaying the response to the client if, for example, data requires sorting.\n\n\n\n\n\n Partition querying \n\nYou can make partition queries to the following index types:\n\n\n\n* IBM Cloudant Query\n* Views\n* Search\n\n\n\nWhen you make a partition query, the database can query just the data within a single partition. A partition's data resides in just one shard (with three replicas). The API coordination node can make a request directly to servers that host that data rather than needing to combine responses from many servers. The API coordination node is also free from buffering the response since it has no combination step to carry out. As a result, the data arrives at the client more quickly.\n\nAs the size of a database increases, the number of shards must also increase. The increase in shards directly increases the number of queries that the API coordination node needs to make to servers that host data when you use global queries. However, when you use partition queries, the number of shards has no effect on the number of servers the API coordination node needs to contact. As this number stays small, increasing data size has no effect on query latency, unlike global queries.\n\n\n\n\n\n\n\n Partitioned databases tutorials \n\nYou can see two examples of using partitioned databases:\n\n\n\n1. Read about [partitioned databases and Node.js](https://blog.cloudant.com/2019/05/24/Partitioned-Databases-with-Cloudant-Libraries.html) in this blog article that includes how to create a partitioned database, search, views, and a global index.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-database-partitioning"}]}
{"task_id": "1c041ce47a81941c26899fdf08bde961<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16551-0-1579", "score": 24.21787, "text": "\n\n\n\n\n\n\n  How can I address storage space limits? \n\nDepending on your subscription plan, you might reach the storage limit that is specified for your plan and be prevented from completing tasks.\n\n  What\u2019s happening \n\nYou might see a message about exceeding the allowed storage space when you attempt to perform one of these tasks:\n\n\n\n*  Upload documents or dictionaries\n*  Deploy a model or version a model\n*  Run a pre-annotator on documents\n\n\n\n  Why it\u2019s happening \n\nThe storage limit is met or exceeded if the action proceeds.\n\n  How to fix it \n\nThe largest consumers of storage space are machine learning and rule-based models. To free up space, you can take the following actions:\n\n\n\n*  Delete snapshot versions of any models that you do not expect to need to revert to.\n*  Delete any models that you do not need.\n*  If your models are too important to delete, consider upgrading your plan to one that provides a larger allotment of storage space.\n\n\n\nAfter you remove models or model versions, wait an hour before you retry the action that resulted in the error message. It can take up to an hour for the storage space that you freed up to be available for use.\n\nTo manage your monthly bill, if the Admin role is assigned to you and you have a Premium or Standard account, you can set a storage limit on the Service Details page in Knowledge Studio. To see the Service Details page and set the storage limit, from the top navigation bar in Knowledge Studio, click the Settings icon, click the View/modify service details link, and then click the Set storage limit link.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_ts_storage"}, {"document_id": "ibmcld_05149-4519-6367", "score": 19.993504, "text": "\nIf not, follow the [getting started tutorial](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-getting-started-cloud-object-storage) to obtain the prerequisites and become familiar with the console.\n\n\n\n Set a list of authorized IP addresses using a legacy firewall \n\n\n\n1. Start by selecting Storage to view your resource list.\n2. Next, select the service instance with your bucket from within the Storage menu. This takes you to the Object Storage Console.\n3. Choose the bucket that you want to limit access to authorized IP addresses.\n4. Select Access policies from the navigation menu.\n5. Select the Authorized IPs tab.\n6. Click Add IP addresses, then choose Add.\n7. Specify a list of IP addresses in [CIDR notation](https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing), for example 192.168.0.0/16, fe80:021b::0/64. Addresses can follow either IPv4 or IPv6 standards.\n8. Click Add.\n9. The firewall will not be enforced until the address is saved in the console. Click Save all to enforce the firewall.\n10. Note that all objects in this bucket are only accessible from those IP addresses.\n\n\n\n\n\n\n\n Remove any IP address restrictions using a legacy firewall \n\n\n\n1. From the Authorized IPs tab, check the boxes next to any IP addresses or ranges to remove from the authorized list.\n2. Select Delete, and then confirm the dialog box by clicking Delete again.\n3. The updated list won't be enforced until the changes are saved in the console. Click Save all to enforce the new rules.\n4. Now all objects in this bucket are only accessible from these IP addresses!\n\n\n\nIf there are no authorized IP addresses listed this means that normal IAM policies will apply to the bucket, with no restrictions on the user's IP address, unless there are context-based restrictions in place.\n\n\n\n\n\n Set a legacy firewall through an API", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-setting-a-firewall"}, {"document_id": "ibmcld_11910-18283-20023", "score": 19.531929, "text": "\nFrom the Satellite storage dashboard, select the storage configuration you want to delete.\n2. Select Actions > Delete\n3. Enter the name of your storage configuration.\n4. Select Delete.\n\n\n\n\n\n\n\n\n\n Parameter reference \n\n\n\n 21.04 parameter reference \n\n\n\nTable 1. 21.04 parameter reference\n\n Display name CLI option Type Description Required? Default value \n\n Management LIF managementLIF Config The IP address of the Management LIF. true N/A \n Data LIF dataLIF Config The IP address of the Data LIF. true N/A \n SVM svm Config The name of the SVM. true N/A \n User Name username Secret The username to connect to the storage device. true N/A \n User Password password Secret The password to connect to the storage device. true N/A \n Export Policy exportPolicy Config The NAS option for the NFS export policy. true default \n Limit Volume Size limitVolumeSize Config Maximum requestable volume size (in Gibibytes) and qtree parent volume size true 50Gi \n Limit AggregateUsage limitAggregateUsage Config Fail provisioning if usage is above this percentage. true 80% \n NFS Mount Options nfsMountOptions Config The NFS mount options. true nfsvers=4 \n\n\n\n\n\n\n\n 22.04 parameter reference \n\n\n\nTable 2. 22.04 parameter reference\n\n Display name CLI option Type Description Required? Default value \n\n Management LIF managementLIF Config The IP address of the Management LIF. true N/A \n Data LIF dataLIF Config The IP address of the Data LIF. true N/A \n SVM svm Config The name of the SVM. true N/A \n User Name username Secret The username to connect to the storage device. true N/A \n User Password password Secret The password to connect to the storage device. true N/A \n Export Policy exportPolicy Config The NAS option for the NFS export policy. true default", "title": "", "source": "https://cloud.ibm.com/docs/satellite?topic=satellite-storage-netapp-ontap-nas"}, {"document_id": "ibmcld_01241-14983-16623", "score": 19.41456, "text": "\nslcli file snapshot-delete --help\nUsage: slcli file snapshot-delete [OPTIONS] SNAPSHOT_ID\n\nOptions:\n-h, --help Show this message and exit.\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Restoring storage volume to a specific point in time by using a snapshot in the UI \n\nYou might need to take your storage volume back to a specific point in time because of user-error or data corruption.\n\n\n\n1. Unmount and detach your storage volume from the host.\n\nFor more information about mounting and unmounting storage, see [connecting your new storage](https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-mountingLinux).\n2. Go to the [IBM Cloud\u00ae console](https://cloud.ibm.com/login). From the menu, select Classic Infrastructure![Classic icon](https://cloud.ibm.com/docs-content/v1/content/04e9937a86546143babfc65ea21fdd4ea2d12d13/icons/classic.svg).\n3. Click Storage, File Storage for Classic.\n4. Scroll on the list, and click your volume to be restored. The Snapshots page displays the list of all saved snapshots along with their size and creation date.\n5. Click Actions![Actions icon](https://cloud.ibm.com/docs-content/v1/content/04e9937a86546143babfc65ea21fdd4ea2d12d13/icons/action-menu-icon.svg) next to the snapshot to be used and click Restore.\n\nCompleting the restore results in the loss of the data that was created or modified after the snapshot was taken. This data loss occurs because your storage volume returns to the same state that it was in of the time of the snapshot.\n6. Click Yes to start the restore.", "title": "", "source": "https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-managingSnapshots"}, {"document_id": "ibmcld_07214-62508-64603", "score": 19.121874, "text": "\nAs a result of this transition, existing users might meet or exceed the lite plan limit on documents (2000), storage (200Mb), or number of collections (2). If you exceed the limit of the Lite plan, you cannot add any additional content into the service, but you can still query collections. : View the current status of all these limits by using the Discovery tooling or API. To resume adding content to the Discovery instance, you must complete one of the following actions: : Remove collections or documents so that limits of the Lite plan are not exceeded. : You can delete documents either individually in the API, using the [delete-doc](https://cloud.ibm.com/apidocs/discoverydelete-a-document) method, or you can delete whole collections, using the tooling or API, by using the [delete-collection](https://cloud.ibm.com/apidocs/discoverydelete-a-collection) method. : Upgrade your plan to a level that meets your storage needs. : Customers with size 12 or 3 environments will be automatically migrated to the Advanced plan.\n\n\n\n\n\n 17 July 2017 \n\nUpdate to relevancy training, natural language query, and highlighting : Relevancy training announced on 23 June 2017 moved from beta to GA status. : Natural language query announced on 19 June 2017 movedd from beta to GA status. : Highlighting announced on 25 May 2017 moved from beta to GA status.\n\nUpdate to enrichment mechanism : IBM Watson\u2122 Discovery is changing its enrichment mechanism from AlchemyLanguage to Natural Language Understanding as of this release. : AlchemyLanguage is in the process of being deprecated, so it is recommended that you start using Natural Language Understanding as soon as possible. : If you integrate with Watson Knowledge Studio, you must still use the AlchemyLanguage enrichment configuration. For details, see [Integrating with IBM Watson\u2122 Knowledge Studio](https://cloud.ibm.com/docs/discovery?topic=discovery-integrating-with-wks).\n\nUpdate to version string : The version string for all API calls changed to 2017-07-19 from 2017-06-25. This version enables an NLU default config on collection creation.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-release-notes"}, {"document_id": "ibmcld_00241-8998-11208", "score": 18.438028, "text": "\nOptions: id, name, created, size_bytes\n-h, --help Show this message and exit.\n\nNotifications are sent when you reach three different space thresholds \u2013 75 percent, 90 percent, and 95 percent.\n\n\n\n* At 75 percent capacity, a warning is sent that snapshot space usage exceeded 75 percent. To remediate, you can manually add space, or delete retained unnecessary snapshots. You can reduce the number of retained snapshots in the schedule. If you reduce the snapshot data or increase the space, the warning system is reset, and no autodeletion occurs.\n* At 90 percent capacity, a second warning is sent when snapshot space usage exceeded 90 percent. Like with reaching 75 percent capacity, if you take the necessary actions to decrease the snapshot data or increase the space, the warning system is reset and no autodeletion occurs.\n* At 95 percent capacity, a final warning is sent. If no action is taken to bring your space usage under the threshold, automatic deletion starts so that future snapshots can be created. Scheduled snapshots are deleted, starting with the oldest, until usage drops under 95 percent. Snapshots continue to be deleted each time usage exceeds 95 percent until it drops under the threshold. If the space is manually increased or snapshots are manually deleted, the warning is reset and reissued if the threshold is exceeded again. If no actions are taken, this notification is the only warning that you receive.\n\n\n\nIf snapshot space utilization increases too rapidly, then you might receive one notification before autodeletion of the oldest scheduled snapshot occurs. For example, if utilization jumps from 76% to 96% within 15 minutes, you receive one notification about exceeding 75% and one notification about exceeding 95%. The system skips the 90%-exceeded warning.\n\nBy default, snapshot warning notifications are enabled for every customer. However, you can choose to disable them. When this feature is disabled, all ticket generation and notifications are stopped. You can disable and enable notifications for the volume at any time.\n\nTo check whether the notifications are enabled for the storage volume, use the following command.\n\n slcli block snapshot-get-notification-status", "title": "", "source": "https://cloud.ibm.com/docs/BlockStorage?topic=BlockStorage-managingSnapshots"}, {"document_id": "ibmcld_01241-8897-11095", "score": 18.343258, "text": "\nOptions: id, name, created, size_bytes\n-h, --help Show this message and exit.\n\nNotifications are sent when you reach three different space thresholds \u2013 75 percent, 90 percent, and 95 percent.\n\n\n\n* At 75 percent capacity, a warning is sent that snapshot space usage exceeded 75 percent. To remediate, you can manually add space, or delete retained unnecessary snapshots. You can reduce the number of retained snapshots in the schedule. If you reduce the snapshot data or increase the space, the warning system is reset, and no autodeletion occurs.\n* At 90 percent capacity, a second warning is sent when snapshot space usage exceeded 90 percent. Like with reaching 75 percent capacity, if you take the necessary actions to decrease the snapshot data or increase the space, the warning system is reset and no autodeletion occurs.\n* At 95 percent capacity, a final warning is sent. If no action is taken to bring your space usage under the threshold, automatic deletion starts so that future snapshots can be created. Scheduled snapshots are deleted, starting with the oldest, until usage drops under 95 percent. Snapshots continue to be deleted each time usage exceeds 95 percent until it drops under the threshold. If the space is manually increased or snapshots are manually deleted, the warning is reset, and reissued if the threshold is exceeded again. If no actions are taken, this notification is the only warning that you receive.\n\n\n\nIf snapshot space usage increases too rapidly, then you might receive one notification before autodeletion of the oldest scheduled snapshot occurs. For example, if usage jumps from 76% to 96% within 15 minutes, you receive one notification about exceeding 75% and one notification about exceeding 95%. The system skips the 90%-exceeded warning.\n\nBy default, snapshot warning notifications are enabled for every customer. However, you can choose to disable them. When this feature is disabled, all ticket generation and notifications are stopped. You can disable and enable notifications for the volume at any time.\n\nTo check whether the notifications are enabled for the storage volume, use the following command.\n\n slcli file snapshot-get-notification-status", "title": "", "source": "https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-managingSnapshots"}, {"document_id": "ibmcld_00241-15158-16579", "score": 18.215652, "text": "\nslcli block snapshot-delete\nUsage: slcli block snapshot-delete [OPTIONS] SNAPSHOT_ID\n\nOptions:\n-h, --help Show this message and exit.\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Restoring storage volume to a specific point in time by using a snapshot in the UI \n\nYou might need to take your storage volume back to a specific point in time because of user-error or data corruption.\n\n\n\n1. Unmount and detach your storage volume from the host to ensure the host is not connecting to the volume during the restore for any reason.\n\n\n\n* [Unmounting Block Storage for Classic volumes on Linux\u00ae server](https://cloud.ibm.com/docs/BlockStorage?topic=BlockStorage-mountingLinuxunmountingLin)\n* [Unmounting Block Storage for Classic volumes on Microsoft\u00ae server](https://cloud.ibm.com/docs/BlockStorage?topic=BlockStorage-mountingWindowsunmountingWin)\n\n\n\n2. Go to the [IBM Cloud\u00ae console](https://cloud.ibm.com/login). From the menu, select Classic Infrastructure![Classic icon](https://cloud.ibm.com/docs-content/v1/content/14cf2f2f32b430cf4ed67ad14b3cecc010f91c45/icons/classic.svg).\n3. Click Storage, Block Storage for Classic.\n4. Scroll on the list, and click your volume to be restored. The Snapshots page displays the list of all saved snapshots along with their size and creation date.\n5. Click Actions!", "title": "", "source": "https://cloud.ibm.com/docs/BlockStorage?topic=BlockStorage-managingSnapshots"}, {"document_id": "ibmcld_01245-4-1307", "score": 18.019316, "text": "\n* CLI\n* API\n\n\n\n\n\n\n\n Managing storage limits \n\nBy default, you can provision a combined total of 700 Block Storage for Classic and File Storage for Classic volumes globally. By following this process, you can increase the number of volumes you can provision.\n\nFor more information about increasing your storage volume capacity beyond 12 TB, see [expanding File Storage for Classic capacity](https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-expandCapacityincreasecapacityover12TB).\n\nIf you're unsure how many volumes you have, you can confirm the numbers by using multiple methods.\n\n\n\n Confirming your current limit and provisioning count from the CLI \n\n\n\n SLCLI \n\nYou can list the number of your volumes by using the [volume-limits](https://softlayer-python.readthedocs.io/en/latest/cli/file/file-volume-limits) command in slcli (version 5.8.5 or higher).\n\n slcli file volume-limits\n\nThe output looks similar to the following example.\n\n[{'datacenterName': 'global', 'maximumAvailableCount': 700, 'provisioned Count':117}]\n:............:.......................:..................:\n: Datacenter : maximumAvailableCount : ProvisionedCount :\n:............:.......................:..................:\n: global : 700 : 117 :\n:............:.......................:..................:\n\n\n\n\n\n IBM Cloud CLI", "title": "", "source": "https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-managinglimits"}, {"document_id": "ibmcld_00241-7269-9432", "score": 18.000536, "text": "\nLike with reaching 75 percent capacity, if you take the necessary actions to decrease the snapshot data or increase the space, the warning system is reset and no autodeletion occurs.\n* At 95 percent capacity, a final warning is sent. If no action is taken to bring your space usage under the threshold, automatic deletion starts so that future snapshots can be created. Scheduled snapshots are deleted, starting with the oldest, until usage drops under 95 percent. Snapshots continue to be deleted each time usage exceeds 95 percent until it drops under the threshold. If the space is manually increased or snapshots are manually deleted, the warning is reset and reissued if the threshold is exceeded again. If no actions are taken, this notification is the only warning that you receive.\n\n\n\nBy default, snapshot warning notifications are enabled for every customer. However, you can choose to disable them. When this feature is disabled, all ticket generation and notifications are stopped. You can disable and enable notifications for the volume at any time from the CLI.\n\nIf snapshot space utilization increases too rapidly, then you might receive one notification before autodeletion of the oldest scheduled snapshot occurs. For example, if utilization jumps from 76% to 96% within 15 minutes, you receive one notification about exceeding 75% and one notification about exceeding 95%.\n\n\n\n\n\n Listing all Snapshots with Space Used Information and Management functions from the SLCLI \n\nYou can accomplish this task from the SLCLI by using the following command.\n\n slcli block snapshot-list --help\nUsage: slcli block snapshot-list [OPTIONS] VOLUME_ID\n\nOptions:\n--sortby TEXT Column to sort by\n--columns TEXT Columns to display. Options: id, name, created, size_bytes\n-h, --help Show this message and exit.\n\nNotifications are sent when you reach three different space thresholds \u2013 75 percent, 90 percent, and 95 percent.\n\n\n\n* At 75 percent capacity, a warning is sent that snapshot space usage exceeded 75 percent. To remediate, you can manually add space, or delete retained unnecessary snapshots. You can reduce the number of retained snapshots in the schedule.", "title": "", "source": "https://cloud.ibm.com/docs/BlockStorage?topic=BlockStorage-managingSnapshots"}]}
{"task_id": "1c041ce47a81941c26899fdf08bde961<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09984-0-1283", "score": 19.826094, "text": "\n\n\n\n\n\n\n  Overview \n\nData lakes are an essential tool for storing structured and unstructured data on the cloud. With IBM\u00ae Netezza\u00ae Performance Server for IBM Cloud Pak\u00ae for Data as a Service, you can use external tables to access parquet files that are stored outside of your database in data lakes (on AWS S3). Also, you can analyze this data by using the robust and massively parallel Netezza Performance Server execution engine.\n\nExternal data sources use connection strings to specify how you can access an external system. Each connection string describes where your data is placed and how to authenticate to your data source. Each external data source has a definition (schema), but the actual data exists external to the Netezza Performance Server database.\n\nYou cannot backup (nzbackup) and restore (nzrestore) external data source objects.\n\nUse cases for external data source include:\n\n\n\n*  [Running queries against parquet data that is stored in a data lake](https://cloud.ibm.com/docs/netezza?topic=netezza-querying_singularity).\n*  [Ingesting data into Netezza Performance Server](https://cloud.ibm.com/docs/netezza?topic=netezza-ingest_singularity).\n*  [Querying both local and remote data](https://cloud.ibm.com/docs/netezza?topic=netezza-merging_singularity).\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-overview_singularity"}, {"document_id": "ibmcld_16728-6533-8457", "score": 19.355572, "text": "\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Build a database-driven Slackbot](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson)Build a database-driven Slackbot Solution tutorial\n\nIn this tutorial, you are going to build a Slackbot which allows to search and create entries in a backend Db2 on Cloud database. The Slackbot is backed by the IBM Watson\u00ae Assistant service. You will integrate Slack and IBM Watson\u00ae Assistant using an Assistant integration. Db2 on Cloud is made available to Watson Assistant as custom extension.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Build, deploy, test and monitor a predictive machine learning model](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-create-deploy-retrain-machine-learning-model)Build, deploy, test and monitor a predictive machine learning model Solution tutorial\n\nThis tutorial walks you through the process of building a predictive machine learning model, deploying the generated model as an API to be used in your applications and testing the model all of this happening in an integrated and unified self-service experience on IBM Cloud. You will then monitor the deployed model with IBM Watson OpenScale.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs?tab=solutions"}, {"document_id": "ibmcld_16729-11586-13439", "score": 17.915478, "text": "\n* 15 minutes\n* 2023-01-31\n\n\n\n[Build a data lake using object storage](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\nObject Storage Data Engine\n\n\n\n* 1 hour\n* 2023-06-14\n\n\n\nBlockchain[Setting up multiregion High Availability (HA) deployments for the ordering service](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-hadr-mr-os)Setting up multiregion High Availability (HA) deployments for the ordering service\n\nIn this tutorial, you learn how to set up a Raft ordering service with five ordering nodes that span multiple regions for maximum high availability.\n\nIBM Blockchain Platform\n\n\n\n* 2023-02-17\n\n\n\n[Using certificates from an external Certificate Authority](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-tutorial-extca)Using certificates from an external Certificate Authority\n\nIn this tutorial, you learn how to use certificates that were generated by an external Certificate Authority (CA) with your IBM\u00ae Blockchain Platform network. After you gather the required certificates for a peer or ordering node, you build a Membership Service Provider (MSP) definition that is used by your blockchain components.\n\nIBM Blockchain Platform\n\n\n\n* 30 minutes\n* 2023-02-17", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}, {"document_id": "ibmcld_13162-7-1878", "score": 16.411194, "text": "\nBuild a data lake using object storage \n\nThis tutorial may incur costs. Use the [Cost Estimator](https://cloud.ibm.com/estimator/review) to generate a cost estimate based on your projected usage.\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n\n\n Objectives \n\n\n\n* Use Object Storage to store raw data files\n* Query data directly from Object Storage using Data Engine (previously SQL Query)\n* Refine and analyze data in IBM Watson\u00ae Studio\n\n\n\nZoom\n\n![Architecture](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution29/Smart-Data-Lake-Architecture.png)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. Raw data is stored on Object Storage.\n2. Data is reduced, enhanced or refined with Data Engine.\n3. Data analysis occurs in Watson Studio.\n4. Non-technical users access data through application(s).\n5. Refined data is pulled from Object Storage.\n\n\n\n\n\n\n\n Before you begin \n\nThis tutorial requires:\n\n\n\n* IBM Cloud CLI.\n\n\n\nYou will find instructions to download and install these tools for your operating environment in the [Getting started with tutorials](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-tutorials) guide.\n\nTo avoid the installation of these tools you can use the [Cloud Shell](https://cloud.ibm.com/shell) from the IBM Cloud console.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-smart-data-lake"}, {"document_id": "ibmcld_13162-12751-14416", "score": 16.071909, "text": "\nCongratulations, you have built a data lake using Object Storage. Below are additional suggestions to enhance your data lake.\n\n\n\n* Experiment with additional datasets using Data Engine\n* Stream data from multiple sources into your data lake by completing [Big data logs with streaming analytics and SQL](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-big-data-log-analyticsbig-data-log-analytics)\n* Build a web app with a dashboard for line of business users utilizing [IBM Cognos Dashboard Embedded](https://cloud.ibm.com/docs/cognos-dashboard-embedded?topic=cognos-dashboard-embedded-gettingstartedtutorial).\n\n\n\n\n\n\n\n Step 8: Remove resources \n\nRun the following commands to remove services, applications and keys you created and used.\n\nibmcloud resource service-instance-delete data-lake-sql\n\nibmcloud resource service-instance-delete data-lake-studio\n\nibmcloud iam api-key-delete data-lake-cos-key\n\nibmcloud resource service-instance-delete data-lake-cos\n\nIf the deletion of data-lake-cos is not successful delete it from the storage section of the [Resource List](https://cloud.ibm.com/resources).\n\nDepending on the resource it might not be deleted immediately, but retained (by default for 7 days). You can reclaim the resource by deleting it permanently or restore it within the retention period. See this document on how to [use resource reclamation](https://cloud.ibm.com/docs/account?topic=account-resource-reclamation).\n\n\n\n\n\n Related content \n\n\n\n* [ibmcloudsql](https://github.com/IBM-Cloud/sql-query-clients/tree/master/Python)\n* [Jupyter Notebooks](https://jupyter.org/)\n* [Folium](https://python-visualization.github.io/folium/)", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-smart-data-lake"}, {"document_id": "ibmcld_09976-7-1778", "score": 15.636387, "text": "\nMerging and querying data \n\nYou might keep only the most recent data locally in a database and use data lakes as your long term storage. With Netezza Performance Server, you can seamlessly query both local and remote data without having to load the remote data into a database first.\n\n\n\n Before you begin \n\nIn the examples, the publicly available [New York taxi trip record data](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page) for yellow taxis in January 2021 and 2022 is used. To follow this example, make sure that the data is in an accessible S3 bucket.\n\n\n\n\n\n 1. Create an external data source. \n\nExternal datasources allow an administrator to grant access to S3 without providing the keys directly to a user.\n\na) Set ENABLE_EXTERNAL_DATASOURCE.\n\nset ENABLE_EXTERNAL_DATASOURCE = 1;\n\nb) Create an external data source.\n\ncreate EXTERNAL DATASOURCE 'DATA SOURCE' on 'REMOTE SOURCE'\nusing (\nACCESSKEYID 'ACCESS KEY ID' SECRETACCESSKEY 'SECRET ACCESS KEY' BUCKET 'BUCKET' REGION 'REGION'\n);\n\nExample:\n\ncreate EXTERNAL DATASOURCE EXAMPLEDATALAKE\u00a0on AWSS3\u00a0\nusing (\nACCESSKEYID 'XXXX' SECRETACCESSKEY 'XXXX' BUCKET 'exampledatalakebucket' REGION 'US-EAST-1'\n);\n\nFor more information, see [CREATE EXTERNAL DATASOURCE command](https://www.ibm.com/docs/en/netezza?topic=tables-create-external-datasource-command).\n\n\n\n\n\n 2. Identify the data from Netezza Performance Server to merge and compare. \n\nIn this example, data that was loaded into Netezza Performance Server (YELLOW_TAXI_JANUARY_2022) is compared with data from a data like (YELLOW_TAXI_JANUARY_2021).\n\nTo follow this example, ensure that YELLOW_TAXI_JANUARY_2022 is in your Netezza Performance Server database.\n\na) Create an external table for the data that you want to load (YELLOW_TAXI_JANUARY_2022).", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-merging_singularity"}, {"document_id": "ibmcld_16728-5097-7108", "score": 15.611758, "text": "\n[solution icon](https://cloud.ibm.com/media/docs/images/homepage/magic-wand.svg) [Best practices for organizing users, teams, applications](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-users-teams-applications)Best practices for organizing users, teams, applications Solution tutorial\n\nThis tutorial gives an overview of the concepts available in IBM Cloud for identity and access management and how they can be implemented to support the multiple development stages of an application.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Bring Your Own IP Address](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-byoip)Bring Your Own IP Address Solution tutorial\n\nThis tutorial presents a brief overview of BYOIP implementation patterns that can be used with IBM Cloud and a decision tree for identifying the appropriate pattern when realizing the secure enclosure as described in the Isolate workloads with a secure private network tutorial. Setup may require additional input from your onsite network team, IBM Cloud technical support or IBM Services.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Build a data lake using object storage](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage Solution tutorial\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs?tab=solutions"}, {"document_id": "ibmcld_13162-3985-5744", "score": 15.226099, "text": "\nCloud High-Speed Transfer Service protects data as it is uploaded to the bucket and [can greatly reduce transfer time](https://www.ibm.com/cloud/blog/announcements/ibm-cloud-object-storage-simplifies-accelerates-data-to-the-cloud).\n\n\n\n1. Download the [City of Los Angeles / Traffic Collision Data from 2010](https://data.lacity.org/api/views/d5tf-ez2w/rows.csv?accessType=DOWNLOAD) CSV file. The file is 81MB and may take a few minutes to download.\n2. In your browser, access the data-lake-cos service instance from the [Resource List](https://cloud.ibm.com/resources) under the Storage section.\n3. Create a new bucket to store data.\n\n\n\n* Click Create a bucket.\n* Select Custom bucket/Customize your bucket.\n* Close to the top of the form, provide a bucket Name.\n* Select Regional in the Resiliency section.\n* Select a Location.\n* At the bottom of the form click Create bucket.\n\n\n\n4. Upload the CSV file to Object Storage.\n\n\n\n* From your bucket, click Upload.\n* Select Standard transfer to use regular http file transfer or select the Aspera high-speed transfer radio button, you may need to install the Aspera plugin to your machine.\n* Click Upload files.\n* Browse and select the previously downloaded CSV file and click Upload.\n\n\n\n\n\n\n\n\n\n Step 3: Working with data \n\nIn this section, you will convert the original, raw dataset into a targeted cohort based on time and age attributes. This is helpful to consumers of the data lake who have specific interests or would struggle with very large datasets.\n\nYou will use Data Engine to manipulate the data where it resides in Object Storage using familiar SQL statements. Data Engine has built-in support for CSV, JSON and Parquet - no additional computation services or extract-transform-load is necessary.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-smart-data-lake"}, {"document_id": "ibmcld_13162-11690-13171", "score": 15.001968, "text": "\nHeatMap(locations, radius=15).add_to(m)\nm\n\nZoom\n\n![Notebook](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution29/notebook-mapbox.png)\n\nNotebook\n3. Click File > Save to save your Notebook to Object Storage.\n\n\n\n\n\n\n\n Step 6: Share your dataset with the organization \n\nNot every user of the data lake is a data scientist. You can allow non-technical users to gain insight from the data lake. Tools with analytic capabilities or for visualization can import data stored in CSV files. Application developers can make use of [IBM Cognos Dashboard Embedded](https://cloud.ibm.com/docs/cognos-dashboard-embedded?topic=cognos-dashboard-embedded-gettingstartedtutorial) to let users build and use feature-rich dashboards. Such a dashboard for the traffic data is shown below.\n\nZoom\n\n![Dashboard Chart](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution29/dashboard-chart.png)\n\nDashboard Chart\n\n\n\n\n\n Step 7: Expand the tutorial \n\nCongratulations, you have built a data lake using Object Storage. Below are additional suggestions to enhance your data lake.\n\n\n\n* Experiment with additional datasets using Data Engine\n* Stream data from multiple sources into your data lake by completing [Big data logs with streaming analytics and SQL](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-big-data-log-analyticsbig-data-log-analytics)", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-smart-data-lake"}, {"document_id": "ibmcld_09969-7-1689", "score": 14.987403, "text": "\nIngesting data from data lakes \n\nIf you plan on regularly querying your data, load it into Netezza Performance Server first to get the best performance benefits.\n\n\n\n Before you begin \n\nIn the examples, the publicly available [New York taxi trip record data](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page) for yellow taxis in January 2022 is used. To follow this example, make sure that the data is in an accessible S3 bucket.\n\n\n\n\n\n 1. Create an external data source. \n\nExternal datasources allow an administrator to grant access to S3 without providing the keys directly to a user.\n\na) Set ENABLE_EXTERNAL_DATASOURCE.\n\nset ENABLE_EXTERNAL_DATASOURCE = 1;\n\nb) Create an external data source.\n\ncreate EXTERNAL DATASOURCE 'DATA SOURCE' on 'REMOTE SOURCE'\nusing (\nACCESSKEYID 'ACCESS KEY ID' SECRETACCESSKEY 'SECRET ACCESS KEY' BUCKET 'BUCKET' REGION 'REGION'\n);\n\nExample:\n\ncreate EXTERNAL DATASOURCE EXAMPLEDATALAKE\u00a0on AWSS3\u00a0\nusing (\nACCESSKEYID 'XXXX' SECRETACCESSKEY 'XXXX' BUCKET 'exampledatalakebucket' REGION 'US-EAST-1'\n);\n\nFor more information, see [CREATE EXTERNAL DATASOURCE command](https://www.ibm.com/docs/en/netezza?topic=tables-create-external-datasource-command).\n\n\n\n\n\n 2. Create an external table for the data from a data lake. \n\nAfter you created an external data source, you can create an external table that accesses the yellow taxi data from January 2022.\n\nEnsure that you have the necessary privileges as described in [Privileges for creating external tables](https://www.ibm.com/docs/en/netezza?topic=et-create-external-table-command-2).\n\ncreate EXTERNAL table 'TABLE NAME' on 'DATA SOURCE'\nusing (\u00a0\nDATAOBJECT ('DATA OBJECT') FORMAT 'PARQUET'\u00a0\n);", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-ingest_singularity"}]}
{"task_id": "1c041ce47a81941c26899fdf08bde961<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13480-1642-3813", "score": 17.505262, "text": "\nSo, if you are either familiar with the schema, or want to repetitively use the data for queries, create a table in the catalog. Such a table improves performance for repeated query executions.\n\nAnother advantage of creating a table in the catalog is that the table name serves as an alias and is decoupled from the data location. Hence, you can separate the tasks of data engineers and SQL authors. Data engineers deal with the data location and publish registered tables in the catalog by using descriptive table names. Hence, SQL authors are able to compose queries without having to know the exact location and format of data on Object Storage. If the data location changes, only the table in the catalog must be updated, but the table name remains unchanged. Updates of the physical data structure are simplified and the robustness of SQL statements and applications is increased.\n\n\n\n\n\n Usage \n\nYou manage the database catalog in Data Engine with Database Definition Language (DDL) statements that you submit just like any other SQL query statement. The catalog is stored independently of Object Storage: No data is written to Object Storage when you create or change table definitions, and no data is deleted from Object Storage when you drop a table definition. To call the catalog management statements, you need the Manager user role assigned.\n\nTo register a new table in the catalog, use the CREATE TABLE statement, as in the following example:\n\nCREATE TABLE employees\nUSING PARQUET\nLOCATION cos://us-geo/sql/employees.parquet\n\nThe statement automatically detects the schema of the data at the location that is indicated. See the [SQL reference](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referencecreateTable) for options that can be set on the table.\n\nUse the DESCRIBE TABLE statement to verify the detected table schema:\n\nDESCRIBE TABLE employees\n\nIf the DESCRIBE TABLE output shows partition information, you must run an ALTER TABLE ... RECOVER PARTITIONS statement to attach the partitions. For more information, see the section on [partitioned tables](https://cloud.ibm.com/docs/sql-query?topic=sql-query-getting_started_catalogpartitioned).", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-getting_started_catalog"}, {"document_id": "ibmcld_16638-0-764", "score": 16.971636, "text": "\n\n\n\n\n\n\n  Creating table from a file \n\nFiles can also be ingested or imported to IBM\u00ae watsonx.data through the overflow menu of schema in the Data explorer page to create tables.\n\n\n\n1.  Log in to the watsonx.data console.\n2.  From the navigation menu, select Data manager.\n3.  Select the engine from the Engine drop-down. Catalogs that are associated with the selected engine are listed.\n4.  Select a schema under a catalog where you want to import a file to create table.\n5.  Click the overflow menu of the selected schema and select Create table from a file. The Create table from a file page opens.\n6.  Follow the steps in the [Creating tables](https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-create_table) topic to complete importing the file.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-import_data"}, {"document_id": "ibmcld_09950-7-1844", "score": 16.780075, "text": "\nTables \n\nIn the table from the Tables tab, the value that is displayed in the row count column is an approximate. The exact row count is available after you run the GENERATE STATISTICS ON <table_name> command.\n\n\n\n Creating tables \n\n\n\n1. Go to Databases.\n2. Select the database in which you want to create a table.\n3. Select the schema in which you want to create a table.\n4. Ensure that you are in the DB Objects > Tables tab.\n5. Click Create table.\n6. Type a name for the table.\nIf the name contains special characters, enclose it in double quotation marks. The dot character (\".\") is not supported.\nYou can select a name that has up to 128 characters. The name must begin with a letter or an underscore and can't contain embedded spaces. The name must be unique.\n7. Optional: Specify the retention time interval (in days) for the table.\nYou can select between 1 day and up to 99 days, or zero to alter a temporal table to nontemporal.\n8. Add columns to the table:\n\n\n\n1. In the Columns section, under Name, type a name for the column. The name must start with a letter.\n2. Select your column type.\nThe data type restricts the type of data that can be stored in a column. For example, preventing entry of alphanumeric characters into a numeric field.\nData types also help sort data correctly and play a role in optimizing storage. For all these reasons, it is important to pick the appropriate data type.\n3. Specify whether Not null is true or false.\nA column that allows NULL values also allows rows to be inserted with no value in that column. A column that does not allow NULL values does not accept rows with no value.\n4. Specify the default value to be used if no value is specified when a row is inserted.\n5. In the Distribute on and Organize on sections, specify the distribution key for the table by selecting up to four columns.", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-create-tables"}, {"document_id": "ibmcld_13512-5424-5881", "score": 16.543644, "text": "\nThe <table name> part specifies the table that is created in your database. It has the format <schemaname>.<tablename>. If you omit the <schemaname> part, the table is created in the schema of database user that was created for the IBMid of the SQL user. The table name is case-preserving, so use uppercase to match database defaults.\n\nThe following URI is an example of a Db2 table URI:\n\ndb2://db2w-vqplkwx.us-south.db2w.cloud.ibm.com/MYSCHEMA.QUERY_RESULT", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-writing-databases"}, {"document_id": "ibmcld_13480-3420-5386", "score": 16.35678, "text": "\nUse the DESCRIBE TABLE statement to verify the detected table schema:\n\nDESCRIBE TABLE employees\n\nIf the DESCRIBE TABLE output shows partition information, you must run an ALTER TABLE ... RECOVER PARTITIONS statement to attach the partitions. For more information, see the section on [partitioned tables](https://cloud.ibm.com/docs/sql-query?topic=sql-query-getting_started_catalogpartitioned).\n\nYou can then query the table by name instead of specifying the Object Storage URI directly in the SQL statement:\n\nSELECT * FROM employees LIMIT 10\n\nIf you want to use more specific data types than the data types inferred by automatic schema detection, you can also specify the table schema explicitly:\n\nCREATE TABLE employees (\nemployeeID int,\nlastName string,\nfirstName string,\ntitle string,\ntitleOfCourtesy string,\nbirthDate timestamp,\nhireDate timestamp,\naddress string,\ncity string,\nregion string,\npostalCode string,\ncountry string,\nhomePhone string,\nextension int,\nphoto string,\nnotes string,\nreportsTo string,\nphotoPath string\n)\nUSING PARQUET\nLOCATION cos://us-geo/sql/employees.parquet\nShow more\n\nIf accessing the table in a SELECT statement does not work as expected, it is possibly caused by improper specification of the table schema in the CREATE TABLE statement. The column names and their data types in your CREATE TABLE statement must match the result of the following query:\n\nSELECT * FROM describe (<data-location> stored as <storage-format>)\n\nColumn names are case-sensitive. Incorrect column name specification results in an empty column, that is, the column seems to contain no data. To solve such a problem, use the automatic schema detection, reorder the columns, or omit some columns.\n\nThe SHOW TABLES statement provides you with an overview of the existing tables in your instance. This statement allows an optional search filter to limit the number of results:\n\nSHOW TABLES LIKE 'cus'\n\nIt is not possible to use a different namespace than default.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-getting_started_catalog"}, {"document_id": "ibmcld_07070-4161-5805", "score": 15.634015, "text": "\n* [Contracts](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-contracts-schema)\n* [Table Understanding](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-understanding_tables)\n\n\n\nFor more information about how to create custom enrichments, see [Adding domain-specific resources](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-domain).\n\nFor more information about how to get the most from enrichments, read the [Enriching your documents can make search more effective](https://community.ibm.com/community/user/watsonai/blogs/bill-murdock1/2022/01/14/enriching-your-documents-can-make-search-more-effe) blog post.\n\nFor more information about how to apply enrichments by using the API, see [Applying enrichments by using the API](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-manage-enrichmentsenrichments-api-task).\n\n\n\n\n\n Add enrichments \n\nTo add an NLP enrichment, complete the following steps:\n\n\n\n1. Open your project and go to the Manage collections page.\n2. Click to open the collection that you want to enrich.\n3. Open the Enrichments tab.\n4. Scroll to find the NLP enrichment that you want to apply to your documents.\n\nBoth built-in enrichments and custom enrichments are listed. Built-in enrichments have a type value of System.\n5. Choose one or more fields to apply the enrichment to.\n\nYou can apply enrichments to the text and html fields, and to custom fields that were added from uploaded JSON or CSV files or from the Smart Document Understanding (SDU) tool.\n6. Click Apply changes and reprocess.\n\n\n\nEnrichments that you enable are applied to the documents in random order.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-nlu"}, {"document_id": "ibmcld_07121-7-2075", "score": 15.360786, "text": "\nUnderstand tables \n\nApply the Table Understanding enrichment to get detailed information about tables and table-related data within documents.\n\nThe following tasks generate an HTML field with table information and apply the Table Understanding enrichment to it for your collection automatically:\n\n\n\n* If you use the Smart Document Understanding tool to define a user-trained or pretrained SDU model, the Table Understanding enrichment is applied to the html field that is generated for the collection.\n* If you create a Document Retrieval for Contracts project type, a pretrained SDU model is applied to your collection automatically. As a result, the Table Understanding enrichment is applied to the html field that is generated for the collection.\n\nFor more information, see [Smart Document Understanding](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-configuring-fieldsidentify-fields).\n\n\n\n\n\n Before you begin \n\nThe documents in your collection must contain a field with HTML representations of your tables. This information often is stored in the html field. If your collection consists of CSV or JSON files, it might have a field other than the html field that contains table information in HTML format.\n\n\n\n\n\n Applying the table understanding enrichment \n\nYou can apply the enrichment only to a field that contains an HTML representation of the table.\n\nTo apply the enrichment, complete the following steps:\n\n\n\n1. From the navigation pane, open the Manage collections page, and then click a collection to open it.\n2. Click the Enrichments tab.\n3. Find the Table Understanding enrichment.\n4. Select the html field from the field list.\n\nChoose the field that contains HTML representations of the tables.\n\n\n\nAfter the enrichment is applied, you can get valid results when you submit queries that require Discovery to find information that is stored in tables.\n\nA developer can query tables by using the API. For more information, see [Query parameters](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-parameterstable_retrieval).", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-understanding_tables"}, {"document_id": "ibmcld_07121-2973-4076", "score": 14.947931, "text": "\nFor more information, read the [Structured Information Extraction from Tables in PDF Documents with Pandas and IBM Watson](https://medium.com/ibm-data-ai/structured-information-extraction-from-tables-in-pdf-documents-with-pandas-and-ibm-watson-fac302fd25bd) blog post on Medium.com.\n\n\n\n\n\n\n\n Output schema \n\nThe output schema from the Table Understanding enrichment is as follows.\n\n{\n\"tables\": [\n{\n\"location\" : {\n\"begin\" : int,\n\"end\" : int\n},\n\"text\": string,\n\"section_title\": {\n\"text\": string,\n\"location\": {\n\"begin\" : int,\n\"end\" : int\n}\n},\n\"title\": {\n\"location\": {\n\"begin\": int,\n\"end\": int,\n},\n\"text\": string\n},\n\"table_headers\" :\n{\n\"cell_id\" : string,\n\"location\" : {\n\"begin\" : int,\n\"end\" : int\n},\n\"text\" : string,\n\"row_index_begin\" : int,\n\"row_index_end\" : int,\n\"column_index_begin\" : int,\n\"column_index_end\" : int\n},\n...\n],\n\"column_headers\" :\n{\n\"cell_id\" : string,\n\"location\" : {\n\"begin\" : int,\n\"end\" : int\n},\n\"text\" : string,\n\"text_normalized\" : string,\n\"row_index_begin\" : int,\n\"row_index_end\" : int,\n\"column_index_begin\" : int,\n\"column_index_end\" : int\n},\n...\n],\n\"row_headers\" :\n{\n\"cell_id\" : string,", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-understanding_tables"}, {"document_id": "ibmcld_07121-1620-3479", "score": 14.49356, "text": "\nSelect the html field from the field list.\n\nChoose the field that contains HTML representations of the tables.\n\n\n\nAfter the enrichment is applied, you can get valid results when you submit queries that require Discovery to find information that is stored in tables.\n\nA developer can query tables by using the API. For more information, see [Query parameters](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-parameterstable_retrieval).\n\nFor more information about how to apply the table understanding enrichment by using the API, see [Applying enrichments by using the API](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-manage-enrichmentsenrichments-api-task).\n\n\n\n Working with tabular data in Python \n\nUse [Text Extensions for Pandas](https://text-extensions-for-pandas.readthedocs.io/en/latest/io.htmlmodule-text_extensions_for_pandas.io.watson.tables), an open-source library from IBM, to read the tables that were parsed from documents in Discovery into pandas DataFrame objects. A pandas DataFrame is an object that represents two-dimensional tabular data in a form that can be transformed and manipulated for downstream analysis in Python.\n\nFor example, you can extract content from tables in many annual report documents and reconstruct it into a single table that includes multiyear data points of interest. For more information, read the [Structured Information Extraction from Tables in PDF Documents with Pandas and IBM Watson](https://medium.com/ibm-data-ai/structured-information-extraction-from-tables-in-pdf-documents-with-pandas-and-ibm-watson-fac302fd25bd) blog post on Medium.com.\n\n\n\n\n\n\n\n Output schema \n\nThe output schema from the Table Understanding enrichment is as follows.\n\n{\n\"tables\": [\n{\n\"location\" : {\n\"begin\" : int,\n\"end\" : int\n},\n\"text\": string,\n\"section_title\": {\n\"text\": string,\n\"location\": {", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-understanding_tables"}, {"document_id": "ibmcld_13498-108109-110305", "score": 14.387159, "text": "\nnew partitions can add data for that column\nALTER TABLE customers_addcol ADD COLUMNS (priority INTEGER)\n\nDo not use the ADD COLUMNS option with CSV tables. The CSV data format identifies columns by order (not by name), so any schema change leads to a schema mismatch with existing data.\n\nAlternatively, you can perform schema changes by dropping and re-creating catalog tables. It does not affect the stored data in Object Storage. This allows you to reexecute the automatic schema detection when the underlying data is extended with new objects containing more columns. You can also use this method to remove columns from the schema that you do not want to appear in the catalog.\n\n\n\n\n\n\n\n Describe table \n\n\n\n describeTable \n\nReturn the schema (column names and data types) of a table or view definition. If the table or view does not exist, you receive an error.\n\n-- returns detailed information about the customer table\nDESCRIBE TABLE customers_partitioned\n\n\n\n\n\n\n\n Show tables \n\n\n\n showTables \n\nReturns the list of the defined tables and views in the catalog. The LIKE option allows to filter for an indicated pattern. Use * as wildcard character.\n\n-- returns all defined tables in the catalog for this instance\nSHOW TABLES\n\n\n\n\n\n\n\n Show Partitions \n\n\n\n showPartitions \n\nList the defined partitions of a table when a table was created as partitioned. You can filter the returned partitions by using the partitionSpec option.\n\n-- returns all partitions for the table customers_partitioned\nSHOW PARTITIONS customers_partitioned\n\n\n\n\n\n\n\n\n\n Index management \n\nWith the following commands, you can create indexes for data skipping during SQL execution to improve performance and lower the costs of your SQL queries. The indexes store summary metadata for each partition of your table to avoid scanning data that is not needed for the query execution. For more information, see [index management](https://cloud.ibm.com/docs/sql-query?topic=sql-query-index_management).\n\n\n\n Create index \n\n\n\n createIndex \n\nCreate an index on the objects in the specified Object Storage location or on the specified table. Define the required index type for each column that you want to calculate the summary metadata for.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-reference"}]}
{"task_id": "1c041ce47a81941c26899fdf08bde961<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00539-3574-5364", "score": 23.26699, "text": "\nThe [POST /{db}/_explain](https://cloud.ibm.com/apidocs/cloudant?code=javapostexplain) API endpoint when passed a JSON object that is usually sent to the [POST /{db}/_find](https://cloud.ibm.com/apidocs/cloudantpostfind) endpoint, explains how such a query is handled and which indexes, if any, might be used.\n\nIf the index object in the response indicates that \"all_docs\" is being used, a full database scan is required to service the query. We recommend that you use the _explain mechanism to check each IBM Cloudant query to ensure it is using an index before you deploy to production.\n\nFor example, a type=json index on firstname, surname and date is suitable for finding documents for:\n\n\n\n* A known firstname, lastname, and date.\n* A known firstname, lastname, and a range of date values (that use $lt, $lte, $gt, $gte operators).\n* A known firstname and lastname sorted by date.\n\n\n\nIt can also be used to assist queries on firstname, surname, date, and other attributes. In other words, it might be able to answer only part of the query but it can help reduce the number of documents that are scanned to find the answer.\n\n\n\n\n\n How can I ensure that my query is efficent? \n\nIdeally, an IBM Cloudant Query execution would need to scan only one document for each document returned. If a query has to scan a million documents for each one returned, it is clearly not optimal, and is in need of a secondary index to help.\n\nWhen you execute a query, passing execution_stats: true as an extra parameter forces IBM Cloudant to enumerate the number of documents it scanned in performing the query, for example:\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"sort\": [\"date\"],\n\"limit\": 10,\n\"execution_stats\": true\n}\n\nThe returned data now includes an extra JSON object:\n\n{\n...", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-faq-using-cloudant-query"}, {"document_id": "ibmcld_00580-39512-41555", "score": 22.288363, "text": "\nThe Query is a standard JavaScript object, which is passed to the db.find function which it POSTs to the _find endpoint on your behalf.\n\nNow, time for a practical exercise. Devise your own IBM Cloudant Query that finds the titles of books that are written in the 20th Century. The IBM Cloudant Query documentation is at the on-screen URL if you need it.\n\nPause the presentation here if you don't want to know the answer...\n\nSee one solution:\n\nI use the $and operator to combine two clauses on the date attribute. One clause to locate documents whose date >= 1900, the other to find documents whose date is < the year 2000. Both clauses have to be true to select a document. As we need only the title of the matching books, we can supply a fields attribute instead of being returned the entire document.\n\nTo summarize, IBM Cloudant Query is a query language that is inspired by MongoDB where the syntax is expressed in JSON form.\n\nQueries select subsets of documents from the database by using clauses that operate on data inside the document - not just the document's _id.\n\nQueries are sent to the database's _find endpoint, either programmatically, by using curl, or by using the Dashboard.\n\nThe query's selector decides which cut of data is required,\n\nThat's the end of this part. The next part is called Indexing.\n\n\n\n\n\n\n\n Indexing video \n\nLearn how indexing can speed up your query process.\n\n\n\n* Indexing video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 11 - Indexing.\n\nThe queries that we executed in the previous part were not optimal: to get the answer, IBM Cloudant had to spool through every document in the database in turn to see whether it met with the search criteria.\n\nTo make queries that are run in a performant and scalable way, we need Indexing.\n\nWith IBM Cloudant, you can specify any number of Indexes (or indices).\n\nAn index is a secondary data structure that is built from the document list.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-learning-center"}, {"document_id": "ibmcld_00580-37889-39953", "score": 22.162249, "text": "\nIf you need to access objects within documents, you can use standard dot notation for example, address.zipcode to access a postal code string inside an address object.\n\nWe can also add the following parameters:\n\nFields\n: Specifies the document attributes that we want returned (the default is the entire document).\n\nSort\n: Defines how the data is to be sorted. Sort is an array, allowing the sort to be calculated on multiple attributes.\n\nLimit\n: The number of documents to return.\n\nIf you are from a relational database background, this query is the equivalent SQL query to that last IBM Cloudant query example.\n\nThe WHERE clause is the equivalent of SELECTOR in IBM Cloudant Query. ORDER and LIMIT are exactly equivalent, and the IBM Cloudant Query FIELDS list is equivalent to the comma-separated list of attributes after the SELECT keyword.\n\nThe JSON syntax might take a bit of getting used to, but MongoDB users might find it familiar.\n\nIBM Cloudant queries can be executed in the IBM Cloudant Dashboard. Select the database that you are working with, for example, books then choose the Query tab.\n\nEnter your IBM Cloudant Query JSON in the box that is provided, and click Run Query when you're ready. The result set appears on the page.\n\nThe Explain button is used to provide an explanation on how the database interprets the supplied query. This explanation becomes more important when we get to Indexing in the next part.\n\nQueries can be triggered from curl too. The Query JSON, in this case, is stored in a file and we POST to the _find endpoint by using the -d@ command-line syntax.\n\nThe Node.js code is similar. The Query is a standard JavaScript object, which is passed to the db.find function which it POSTs to the _find endpoint on your behalf.\n\nNow, time for a practical exercise. Devise your own IBM Cloudant Query that finds the titles of books that are written in the 20th Century. The IBM Cloudant Query documentation is at the on-screen URL if you need it.\n\nPause the presentation here if you don't want to know the answer...\n\nSee one solution:", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-learning-center"}, {"document_id": "ibmcld_00580-64080-66194", "score": 22.1131, "text": "\nTo summarize, IBM Cloudant Search indexes are defined with a supplied JavaScript function. They are built on Apache Lucene and are primarily used for free-text search matching, but the query language is useful for building flexible queries on a fixed set of indexed fields. It also has some powerful counting aggregations suitable for drill-down user interfaces.\n\nIBM Cloudant Search also powers type=text IBM Cloudant Query indexes, so a subset of its capabilities is surfaced by using the _find API.\n\nThat's the end of this part. The next part is called Under the hood.\n\n\n\n\n\n\n\n Under the hood video \n\nLearn how the IBM Cloudant service is organized.\n\n\n\n* Under the hood video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 17 - Under the hood.\n\nLet's look at how an IBM Cloudant service is organized: This overview applies to the IBM Cloudant services that map to CouchDB 2 and 3. CouchDB 4 is built on different technology.\n\nIBM Cloudant is a distributed database with data that is stored around a cluster of storage nodes. Picture the IBM Cloudant service as ring of nodes, in this case twelve. Every node can deal with incoming API calls and every node has responsibility for storing some of the data: shards and associated secondary indexes of databases that exist in the cluster.\n\nWhen data is written to IBM Cloudant, one of the nodes in the ring handles the request: Its job is to instruct three copies of the data to be stored in three storage nodes. Data is stored in triplicate in IBM Cloudant, so each shard of a database is stored multiple times, often across a region's availability zones.\n\nWhen you make an API call to write data and get a response back, we write the data to at least two of the three storage nodes. Data is flushed to disk - it isn't cached in memory to be flushed data. We consider that technique too risky and prone to data loss.\n\nWhen you create a database, a number of database shards are created (16 by default) which are spread around the cluster.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-learning-center"}, {"document_id": "ibmcld_00539-7-1755", "score": 21.995678, "text": "\nUsing IBM Cloudant Query FAQ \n\n[IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Query](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-query) is an API for querying slices of data based on the values of a database's document attributes. It is a flexible API that must be used carefully to ensure that database performance can be maintained as the data size grows over time.\n\n\n\n How do I use IBM Cloudant Query? \n\nIBM Cloudant Query is accessed through the [POST /{db}/_find](https://cloud.ibm.com/apidocs/cloudantpostfind) API endpoint where the JSON specification of the query is passed in the HTTP POST body. For example, this query finds up to 10 documents where the firstname is \"Charles\" and the surname is \"Dickens\":\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"limit\": 10\n}\n\nFor more information, see [Selector Syntax](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-queryselector-syntax).\n\n\n\n\n\n How do I create an index to support an IBM Cloudant Query? \n\nWithout a suitable secondary index, IBM Cloudant Query scans each document in the database in turn until it has enough matches to satisfy the query. The larger the data set and the more documents it has to scan to find matching documents, the slower the response time. For faster performance, an IBM Cloudant Query _find must be backed by a suitable secondary index. A secondary index is a pre-calculated data structure that allows IBM Cloudant to quickly jump to the slice of data it needs without scanning irrelevant documents. For the surname fields, we call the [POST /{db}/_index](https://cloud.ibm.com/apidocs/cloudantpostindex) endpoint to pass the JSON index definition as the HTTP POST body:\n\n{\n\"index\": {\n\"fields\": [\"firstname\", \"surname\"]\n},\n\"ddoc\": \"jsonindexes\",", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-faq-using-cloudant-query"}, {"document_id": "ibmcld_00491-7-1604", "score": 21.919725, "text": "\nUsing IBM Cloudant Query \n\nIn this tutorial, we demonstrate how to create an index and use the index to query the database. You also learn to create different types of queries to more easily find data.\n\nHere you run the commands from the command line, but you can also complete these tasks with the IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Dashboard, which gives you a visual example of each task. For more information about the dashboard, see [Using the IBM Cloudant Dashboard](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-query) tutorial.\n\n\n\n Before you begin \n\nBefore you begin, follow these tutorials to create an instance, and then create and populate a database.\n\n\n\n1. [Create an IBM Cloudant instance](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-getting-started-with-cloudantcreating-an-ibm-cloudant-instance-on-ibm-cloud).\n2. [Create a database](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-creating-and-populating-a-simple-ibm-cloudant-database-on-ibm-cloudcreating-a-database-within-the-service-instance).\n3. [Populate the database](https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-creating-and-populating-a-simple-ibm-cloudant-database-on-ibm-cloudstoring-a-small-collection-of-data-as-documents-within-the-database).\n4. (Optional) [Create an acurl alias](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-working-with-curlencode-user-name-and-password).\n\n\n\nIf you decide not to set up acurl, use the following URL with curl instead of the one provided in the exercises, curl \"https://$USERNAME:$PASSWORD@$ACCOUNT.cloudant.com/databasedemo\".", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-query"}, {"document_id": "ibmcld_00522-2652-4218", "score": 21.776848, "text": "\nOpen the service instance that you created in the prerequisite section.\n3. Open the database that you created.\n4. Go to the Query tab.\n5. Paste the query JSON from the previous section into the Cloudant Query window.\n6. Click Run Query. See the results in the following screen capture:\n\nZoom\n\n![Run the query, and the results show the _id, author, pages, publisher, and year.](https://cloud.ibm.com/docs-content/v1/content/522c6f62358b063f921283400a601c3f9bc66f08/Cloudant/images/indexingdashboard1.png)\n\nFigure 1. Window for running queries\n\n\n\nIBM Cloudant matches the documents that meet your criteria and it seems to do it quickly, but there's a catch. IBM Cloudant isn't using an index to service this query, meaning that the database has to scan every document in the database to get your answer. This scan is fine for small data sets. But if you're running a production application where the data set is expanding all the time, you definitely don't want to rely on unindexed queries.\n\n\n\n\n\n Creating an index \n\nTo create an index, we can tell IBM Cloudant to create an index on the publisher and year fields that we are using in our query.\n\n\n\n1. From the IBM Cloudant Dashboard, select the books database.\n2. Select the Design Documents tab.\n3. Select New Indexes from the Design Documents menu.\n4. Copy and paste the following index definition:\n\n{\n\"index\": {\n\"fields\": [\n\"publisher\", \"year\"\n]\n},\n\"name\": \"publisher-year-index\",indexingdashboard5\n\"type\": \"json\"\n}\n\nSee an example in the following screen capture:\n\nZoom\n\n![Click Create index to create an index.]", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-dig-deeper-dashboard"}, {"document_id": "ibmcld_00491-1283-3050", "score": 21.754042, "text": "\n(Optional) [Create an acurl alias](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-working-with-curlencode-user-name-and-password).\n\n\n\nIf you decide not to set up acurl, use the following URL with curl instead of the one provided in the exercises, curl \"https://$USERNAME:$PASSWORD@$ACCOUNT.cloudant.com/databasedemo\".\n\nThe acurl alias is more secure. It prevents someone from reading your password over your shoulder as you type. It also makes sure that your password isn\u2019t sent in plain text over the network by enforcing HTTPS.\n\nNow, we're ready to learn how to run queries against the database you created in step two of [Before you begin](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-querybefore-you-begin-qt).\n\n\n\n\n\n Step 1: Creating an index \n\nIBM Cloudant Query uses Mongo-style query syntax to search for documents by using logical operators. IBM Cloudant Query is a combination of a view and a search index.\n\nWhen you use IBM Cloudant Query, the query planner looks at the selector (your query) to determine the correct index to choose from. In memory, you filter out the documents by the selector, which is why, even without an index, you can still query with various fields.\n\nIf no available defined index matches the specified query, then IBM Cloudant uses the _all_docs index, which looks up documents by ID. In the worst case scenario, it returns all the documents by ID (full table scan). Full table scans are expensive to process. It is recommended that you create an index.\n\nTo create an index, follow these steps:\n\n\n\n1. Copy the following sample JSON data into a file named query-demo-index.json:\n\n{\n\"index\": {\n\"fields\": [\n\"descriptionField\",\n\"temperatureField\"\n],\n\"partial_filter_selector\": {\n\"descriptionField\": {", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-query"}, {"document_id": "ibmcld_00580-42802-44973", "score": 21.531235, "text": "\nThis practice saves IBM Cloudant from having to choose which index to use from the available ones, and it makes it easy for you to remember which index is which.\n\nLet's create an index on our books database from the dashboard. Select the database, then choose the Design Documents tab and Query Indexes from the menu.\n\nAny existing indexes are listed on the side: A special index must exist that represents the primary index, based on the document's _id.\n\nComplete the index definition with the JSON:\n\nClick Create Index when you're done.\n\nClicking the button sends a POST request to the _index endpoint (other API calls are available to update and delete existing indexes).\n\nIndexes are built asynchronously by IBM Cloudant in the background. For large databases, it can take IBM Cloudant some time to construct the index for the first time. The index cannot use the database until that initial build is ready.\n\nWe can repeat our query for books in the 20th century. This time we specify the index name with the use_index field. The answer returns - this time powered by our index. You might not notice a speed improvement for a small database, but the benefit is definitely felt as your data size and query volume grows. Indexing helps your queries remain performant as your application scales.\n\nWhen you tell IBM Cloudant to create a secondary index, it starts a background task that looks at all the documents in turn and creates a new data structure on disk: the index. The index is a balanced tree which pairs the keys (the attribute or attributes that you need indexed) with the document _id they came from.\n\nThe index can be used to efficiently lookup known keys and ranges of keys without having to rescan the entire database.\n\nAnother trick that you can employ at index time is the partial filter. You can optionally supply a partial filter in your index definition. This IBM Cloudant Query selector is executed at index time to decide which documents' data makes it to the index and which are ignored.\n\nIn this example, a selector is employed that allows only dates that fall on a weekend to make it to the index. Smaller indexes are faster and more efficient.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-learning-center"}, {"document_id": "ibmcld_00580-41116-43256", "score": 21.407156, "text": "\nThe queries that we executed in the previous part were not optimal: to get the answer, IBM Cloudant had to spool through every document in the database in turn to see whether it met with the search criteria.\n\nTo make queries that are run in a performant and scalable way, we need Indexing.\n\nWith IBM Cloudant, you can specify any number of Indexes (or indices).\n\nAn index is a secondary data structure that is built from the document list. It contains data that is sorted by the fields you specify, for example, books that are sorted by date and title. If you perform a query that asks for data that matches a document's date and title, the indexed data structure can be used to speed up the query process. Instead of scanning through every document in turn, IBM Cloudant can jump to the relevant part of the index (say, the section on 20th century books) and retrieve the data much more quickly.\n\nIBM Cloudant Query indexes include two types of indexes: type=json and type=text. These indexes are backed by two underlying indexing technologies that we meet in subsequent parts of this course.\n\nAn index is defined when you POST some JSON to a database's _index endpoint.\n\nThe index object contains a fields array, which specifies which document attributes to index. Usually, the fields that need indexing are equivalent to the attributes used in the selector of a query you're going to use to retrieve the data. That is, if you need to query by the date field, we need to index the date field.\n\nAlthough the name of an index is optional, it's good practice and we follow this convention. It's good to ask IBM Cloudant a question and specify the name of the index you intend it to use. This practice saves IBM Cloudant from having to choose which index to use from the available ones, and it makes it easy for you to remember which index is which.\n\nLet's create an index on our books database from the dashboard. Select the database, then choose the Design Documents tab and Query Indexes from the menu.\n\nAny existing indexes are listed on the side: A special index must exist that represents the primary index, based on the document's _id.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-learning-center"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01533-4546-6910", "score": 22.846573, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-4585-6962", "score": 22.509169, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_09410-1574-3779", "score": 18.507006, "text": "\n* IBM Cloud Container Registry provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM.\n* The IBM Cloud Container Registry includes Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\n\n\nTo get details about the logging agent images, see [Getting information about logging agent images](https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-log_analysis_agent_image).\n\n\n\n Resource Limits for agents deployed on Kubernetes \n\nThe agent is deployed as a Kubernetes DaemonSet, creating one pod for each node selected. The agent collects logs of all the pods in the node. The resource requirements of the agent are in direct relation to the number of pods for each node and the amount of logs produced for each pod.\n\nThe agent requires at least 128 MB and no more than 512 MB of memory. It requires at least twenty millicpu (20m).\n\nDifferent features can also increase resource utilization. When line exclusion, inclusion or redaction rules are specified, you can expect additional CPU consumption for each line and regex rule defined. When Kubernetes event logging is enabled (disabled by default), additional CPU usage will occur on the oldest agent pod.\n\nPlacing traffic shaping or CPU limits on the agent is not recommended to ensure data can be sent to the log ingestion service.\n\n\n\n\n\n Understanding image tags \n\nThe tag that is associated to a logging image indicates whether the logging agent is automatically updated.\n\nA tag consists of multiple parts:\n\nX.Y.Z-<date>.[hash]\n\nWhere\n\n\n\n* X represents the major version of an image.\n* Y represents the minor version of an image.\n* Z represents an incremental ID that determines the latest patched minor version.\n* <date> represents the date that the image is built and available. The format is YYYYMMDD.", "title": "", "source": "https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-log_analysis_agent"}, {"document_id": "ibmcld_01533-6329-8623", "score": 18.21994, "text": "\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-6381-8675", "score": 18.21994, "text": "\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_06063-53153-55320", "score": 18.20439, "text": "\nImage Vulnerability Scanner: By default, Vulnerability Advisor scans images that are stored in IBM Cloud Container Registry to find potential security vulnerabilities. For more information, see [Managing image security with Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index).\n4. IBM Cloud Security and Compliance Center: When you enable IBM Cloud Security and Compliance Center, you can view reports about suspicious incoming and outgoing network traffic. For more information, see [What is IBM Cloud Security and Compliance Center?](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n5. IBM Cloud\u00ae Secrets Manager: You can store your Ingress and Kubernetes secrets in IBM Cloud\u00ae Secrets Manager. When you integrate Secrets Manager into your cluster, you set a default Secrets Manager instance where all Ingress subdomain secrets are uploaded. For more information, see [Setting up Secrets Manager in your Kubernetes Service cluster](https://cloud.ibm.com/docs/containers?topic=containers-secrets-mgr).\n\n\n\n\n\n\n\n Image and registry \n\nEvery deployment is based on an image that holds the instructions for how to spin up the container that runs your app. These instructions include the operating system inside the container and extra software that you want to install. To protect your app, you must protect the image and establish checks to ensure the image's integrity.\n\nShould I use a public or a private registry to store my images?\n: Public registries, such as Docker Hub, can be used to get started with Docker images and Kubernetes to create your first containerized app in a cluster. But when it comes to enterprise applications, avoid registries that you don't know or don't trust to protect your cluster from malicious images. Keep your images in a private registry, like the one provided in IBM Cloud Container Registry and make sure to control access to the registry and the image content that can be pushed.\n\nWhy is it important to check images against vulnerabilities?\n: Research shows that most malicious attacks leverage known software vulnerabilities and weak system configurations.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-security"}, {"document_id": "ibmcld_01415-6473-8616", "score": 18.202818, "text": "\nFor more information, see [Billing for storage and pull traffic](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_faq&interface=ui"}, {"document_id": "ibmcld_01535-4-2366", "score": 18.079916, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01533-4-2366", "score": 18.079916, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-1902-3811", "score": 17.845213, "text": "\nFor more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nThe following functions are available in version 3:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.\n* Provides recommendations to secure configuration files for a subset of application types.\n* Provides instructions about how to fix a reported [vulnerable package](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages) or [configuration issue](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiapp_configurations) in its reports.\n* Applies exemption policies to reports at an account, [namespace](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe following functions are available in version 4:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01533-4546-6910", "score": 23.770184, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-4585-6962", "score": 23.369707, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01535-4-2366", "score": 19.845263, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01533-4-2366", "score": 19.845263, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01533-6329-8623", "score": 19.509068, "text": "\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-6381-8675", "score": 19.509068, "text": "\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01415-6473-8616", "score": 19.480022, "text": "\nFor more information, see [Billing for storage and pull traffic](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_faq&interface=ui"}, {"document_id": "ibmcld_06063-53153-55320", "score": 19.343021, "text": "\nImage Vulnerability Scanner: By default, Vulnerability Advisor scans images that are stored in IBM Cloud Container Registry to find potential security vulnerabilities. For more information, see [Managing image security with Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index).\n4. IBM Cloud Security and Compliance Center: When you enable IBM Cloud Security and Compliance Center, you can view reports about suspicious incoming and outgoing network traffic. For more information, see [What is IBM Cloud Security and Compliance Center?](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n5. IBM Cloud\u00ae Secrets Manager: You can store your Ingress and Kubernetes secrets in IBM Cloud\u00ae Secrets Manager. When you integrate Secrets Manager into your cluster, you set a default Secrets Manager instance where all Ingress subdomain secrets are uploaded. For more information, see [Setting up Secrets Manager in your Kubernetes Service cluster](https://cloud.ibm.com/docs/containers?topic=containers-secrets-mgr).\n\n\n\n\n\n\n\n Image and registry \n\nEvery deployment is based on an image that holds the instructions for how to spin up the container that runs your app. These instructions include the operating system inside the container and extra software that you want to install. To protect your app, you must protect the image and establish checks to ensure the image's integrity.\n\nShould I use a public or a private registry to store my images?\n: Public registries, such as Docker Hub, can be used to get started with Docker images and Kubernetes to create your first containerized app in a cluster. But when it comes to enterprise applications, avoid registries that you don't know or don't trust to protect your cluster from malicious images. Keep your images in a private registry, like the one provided in IBM Cloud Container Registry and make sure to control access to the registry and the image content that can be pushed.\n\nWhy is it important to check images against vulnerabilities?\n: Research shows that most malicious attacks leverage known software vulnerabilities and weak system configurations.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-security"}, {"document_id": "ibmcld_01535-1902-3811", "score": 19.26072, "text": "\nFor more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nThe following functions are available in version 3:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.\n* Provides recommendations to secure configuration files for a subset of application types.\n* Provides instructions about how to fix a reported [vulnerable package](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages) or [configuration issue](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiapp_configurations) in its reports.\n* Applies exemption policies to reports at an account, [namespace](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe following functions are available in version 4:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01533-1902-3785", "score": 19.224361, "text": "\nFor more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nThe following functions are available in version 3:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.\n* Provides recommendations to secure configuration files for a subset of application types.\n* Provides instructions about how to fix a reported [vulnerable package](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexpackages) or [configuration issue](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexapp_configurations) in its reports.\n* Applies exemption policies to reports at an account, [namespace](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe following functions are available in version 4:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01533-8109-9900", "score": 18.40072, "text": "\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https://gitlab.alpinelinux.org/) and [CVE](https://cve.mitre.org/data/downloads/index.html). \n CentOS Version 7 [CentOS announce archives](https://lists.centos.org/pipermail/centos-announce/) and [CentOS CR announce archives](https://lists.centos.org/pipermail/centos-cr-announce/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https://lists.debian.org/debian-security-announce/) and [Debian LTS Security Information](https://www.debian.org/lts/security/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https://github.com/GoogleContainerTools/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL/UBI 7, RHEL/UBI 8, and RHEL/UBI 9 [Red Hat Security Data API](https://access.redhat.com/labsinfo/securitydataapi). \n Ubuntu All stable versions with vendor security support.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-8161-9952", "score": 18.40072, "text": "\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https://gitlab.alpinelinux.org/) and [CVE](https://cve.mitre.org/data/downloads/index.html). \n CentOS Version 7 [CentOS announce archives](https://lists.centos.org/pipermail/centos-announce/) and [CentOS CR announce archives](https://lists.centos.org/pipermail/centos-cr-announce/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https://lists.debian.org/debian-security-announce/) and [Debian LTS Security Information](https://www.debian.org/lts/security/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https://github.com/GoogleContainerTools/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL/UBI 7, RHEL/UBI 8, and RHEL/UBI 9 [Red Hat Security Data API](https://access.redhat.com/labsinfo/securitydataapi). \n Ubuntu All stable versions with vendor security support.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01329-59746-61590", "score": 18.299976, "text": "\nFor more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr vulnerability-assessment [--extended | -e] [--vulnerabilities | -v] [--configuration-issues | -c] [--output FORMAT | -o FORMAT] IMAGE [IMAGE...]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\nIMAGE\n: The name of the image for which you want to get a report. The report states whether the image has any known package vulnerabilities. You can request reports for multiple images at the same time by listing each image in the command with a space between each name.\n\nTo find the names of your images, run ibmcloud cr image-list. Combine the content of the Repository column (repository) and Tag column (tag) separated by a colon (:) to create the image name in the format repository:tag. If a tag is not specified in the image name, the report assesses the image that is tagged latest.\n\nFor information about supported Docker base images, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n\nFor more information, see [Managing image security with Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui).\n\n--extended, -e\n: (Optional) The command output shows additional information about fixes for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcli"}, {"document_id": "ibmcld_01329-14955-16723", "score": 17.787725, "text": "\nIf you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr image-digests [--format FORMAT | --quiet | -q | --json] [--restrict RESTRICTION] [--include-ibm] [--no-va] [--va]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\n--format FORMAT\n: (Optional) Format the output elements by using a Go template. For more information, see [Formatting and filtering the Container Registry CLI output](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_cli_list).\n\n--quiet, -q\n: (Optional) Each image is listed in the format: repository@digest\n\n--json\n: (Optional) Outputs the list in JSON format.\n\n--restrict RESTRICTION\n: (Optional) Limit the output to display only images in the specified namespace or repository.\n\n--include-ibm\n: (Optional) Includes IBM-provided public images in the output. By default only private images are listed. You can view IBM-provided images in the global registry only.\n\n--no-va\n: (Optional) Excludes the security status (Vulnerability Advisor) results from the output.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcli"}, {"document_id": "ibmcld_01535-4-2366", "score": 17.766645, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01533-4-2366", "score": 17.766645, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01442-1679-3832", "score": 17.72632, "text": "\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui"}, {"document_id": "ibmcld_01535-4585-6962", "score": 17.625612, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01533-4546-6910", "score": 17.622393, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_07578-370529-372403", "score": 17.558043, "text": "\n* To list the metadata for a specific installed package, run either of the following commands:\n\nrpm -qi <package_name>\n\nyum info <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\nrpm -qa\n\nyum list installed\n\n\n\n\n\n* Does Vulnerability Advisor have versions?\n\n Does Vulnerability Advisor have versions? \n\nVulnerability Advisor is available in two versions, version 3 and version 4. For more information, see [Managing image security with Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\n\n\nKubernetes service\n\n\n\n* What is Kubernetes?\n\nKubernetes is an open source platform for managing containerized workloads and services across multiple hosts, and offers managements tools for deploying, automating, monitoring, and scaling containerized apps with minimal to no manual intervention. All containers that make up your microservice are grouped into pods, a logical unit to ensure easy management and discovery. These pods run on compute hosts that are managed in a Kubernetes cluster that is portable, extensible, and self-healing in case of failures.\n\nFor more information about Kubernetes, see the [Kubernetes documentation](https://kubernetes.io/docs/home/?path=users&persona=app-developer<=vel=foundational).\n* How does IBM Cloud Kubernetes Service work?\n\nWith IBM Cloud Kubernetes Service, you can create your own Kubernetes cluster to deploy and manage containerized apps on IBM Cloud. Your containerized apps are hosted on IBM Cloud infrastructure compute hosts that are called worker nodes.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01533-8109-9900", "score": 20.872574, "text": "\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https://gitlab.alpinelinux.org/) and [CVE](https://cve.mitre.org/data/downloads/index.html). \n CentOS Version 7 [CentOS announce archives](https://lists.centos.org/pipermail/centos-announce/) and [CentOS CR announce archives](https://lists.centos.org/pipermail/centos-cr-announce/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https://lists.debian.org/debian-security-announce/) and [Debian LTS Security Information](https://www.debian.org/lts/security/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https://github.com/GoogleContainerTools/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL/UBI 7, RHEL/UBI 8, and RHEL/UBI 9 [Red Hat Security Data API](https://access.redhat.com/labsinfo/securitydataapi). \n Ubuntu All stable versions with vendor security support.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-8161-9952", "score": 20.872574, "text": "\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https://gitlab.alpinelinux.org/) and [CVE](https://cve.mitre.org/data/downloads/index.html). \n CentOS Version 7 [CentOS announce archives](https://lists.centos.org/pipermail/centos-announce/) and [CentOS CR announce archives](https://lists.centos.org/pipermail/centos-cr-announce/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https://lists.debian.org/debian-security-announce/) and [Debian LTS Security Information](https://www.debian.org/lts/security/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https://github.com/GoogleContainerTools/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL/UBI 7, RHEL/UBI 8, and RHEL/UBI 9 [Red Hat Security Data API](https://access.redhat.com/labsinfo/securitydataapi). \n Ubuntu All stable versions with vendor security support.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_07578-368912-370964", "score": 19.238747, "text": "\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run the following command:\n\napk info <package_name>\n* To list all installed packages and their versions, run the following command:\n\napk list\n\n\n\n\n\n\n\n Debian and Ubuntu package manager commands \n\nOn Debian and Ubuntu, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\napt show <package_name>\n\ndpkg-query -l <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\napt list\n\ndpkg-query -W\n\n\n\n\n\n\n\n Red Hat and CentOS package manager commands \n\nOn Red Hat\u00ae OpenShift\u00ae and CentOS, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\nrpm -qi <package_name>\n\nyum info <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\nrpm -qa\n\nyum list installed\n\n\n\n\n\n* Does Vulnerability Advisor have versions?\n\n Does Vulnerability Advisor have versions? \n\nVulnerability Advisor is available in two versions, version 3 and version 4.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-368886-370938", "score": 19.238747, "text": "\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run the following command:\n\napk info <package_name>\n* To list all installed packages and their versions, run the following command:\n\napk list\n\n\n\n\n\n\n\n Debian and Ubuntu package manager commands \n\nOn Debian and Ubuntu, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\napt show <package_name>\n\ndpkg-query -l <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\napt list\n\ndpkg-query -W\n\n\n\n\n\n\n\n Red Hat and CentOS package manager commands \n\nOn Red Hat\u00ae OpenShift\u00ae and CentOS, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\nrpm -qi <package_name>\n\nyum info <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\nrpm -qa\n\nyum list installed\n\n\n\n\n\n* Does Vulnerability Advisor have versions?\n\n Does Vulnerability Advisor have versions? \n\nVulnerability Advisor is available in two versions, version 3 and version 4.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_01410-2747-3497", "score": 19.03556, "text": "\nVersion 1.0.0 of the CLI was released on 15 September 2022.\n\nThis release has the following changes:\n\n\n\n* Vulnerability Advisor v4 is now available, see [Vulnerability Advisor 4 is available from Container Registry plug-in 1.0.0](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_release_notes15sep2022_va_version_4).\n* Image and digest list output no longer includes security status by default. You can either add the --va argument to include security status for all the listed images, or you can use the ibmcloud cr va command to query security status for an individual image.\n\n\n\n\n\n\n\n Version 0.1.582 \n\nVersion 0.1.582 of the CLI was released on 15 September 2022.\n\nThis release has the following changes:\n\n\n\n* Vulnerability remediations.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_cli_change_log"}, {"document_id": "ibmcld_01329-59746-61590", "score": 18.715689, "text": "\nFor more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr vulnerability-assessment [--extended | -e] [--vulnerabilities | -v] [--configuration-issues | -c] [--output FORMAT | -o FORMAT] IMAGE [IMAGE...]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\nIMAGE\n: The name of the image for which you want to get a report. The report states whether the image has any known package vulnerabilities. You can request reports for multiple images at the same time by listing each image in the command with a space between each name.\n\nTo find the names of your images, run ibmcloud cr image-list. Combine the content of the Repository column (repository) and Tag column (tag) separated by a colon (:) to create the image name in the format repository:tag. If a tag is not specified in the image name, the report assesses the image that is tagged latest.\n\nFor information about supported Docker base images, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n\nFor more information, see [Managing image security with Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui).\n\n--extended, -e\n: (Optional) The command output shows additional information about fixes for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcli"}, {"document_id": "ibmcld_01441-7-2257", "score": 18.24475, "text": "\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4"}, {"document_id": "ibmcld_01442-7-2257", "score": 18.24475, "text": "\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui"}, {"document_id": "ibmcld_01329-14955-16723", "score": 18.173027, "text": "\nIf you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr image-digests [--format FORMAT | --quiet | -q | --json] [--restrict RESTRICTION] [--include-ibm] [--no-va] [--va]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\n--format FORMAT\n: (Optional) Format the output elements by using a Go template. For more information, see [Formatting and filtering the Container Registry CLI output](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_cli_list).\n\n--quiet, -q\n: (Optional) Each image is listed in the format: repository@digest\n\n--json\n: (Optional) Outputs the list in JSON format.\n\n--restrict RESTRICTION\n: (Optional) Limit the output to display only images in the specified namespace or repository.\n\n--include-ibm\n: (Optional) Includes IBM-provided public images in the output. By default only private images are listed. You can view IBM-provided images in the global registry only.\n\n--no-va\n: (Optional) Excludes the security status (Vulnerability Advisor) results from the output.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcli"}, {"document_id": "ibmcld_01535-4-2366", "score": 17.796913, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01533-8109-9900", "score": 19.029814, "text": "\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https://gitlab.alpinelinux.org/) and [CVE](https://cve.mitre.org/data/downloads/index.html). \n CentOS Version 7 [CentOS announce archives](https://lists.centos.org/pipermail/centos-announce/) and [CentOS CR announce archives](https://lists.centos.org/pipermail/centos-cr-announce/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https://lists.debian.org/debian-security-announce/) and [Debian LTS Security Information](https://www.debian.org/lts/security/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https://github.com/GoogleContainerTools/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL/UBI 7, RHEL/UBI 8, and RHEL/UBI 9 [Red Hat Security Data API](https://access.redhat.com/labsinfo/securitydataapi). \n Ubuntu All stable versions with vendor security support.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-8161-9952", "score": 19.029814, "text": "\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https://gitlab.alpinelinux.org/) and [CVE](https://cve.mitre.org/data/downloads/index.html). \n CentOS Version 7 [CentOS announce archives](https://lists.centos.org/pipermail/centos-announce/) and [CentOS CR announce archives](https://lists.centos.org/pipermail/centos-cr-announce/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https://lists.debian.org/debian-security-announce/) and [Debian LTS Security Information](https://www.debian.org/lts/security/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https://github.com/GoogleContainerTools/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL/UBI 7, RHEL/UBI 8, and RHEL/UBI 9 [Red Hat Security Data API](https://access.redhat.com/labsinfo/securitydataapi). \n Ubuntu All stable versions with vendor security support.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_07578-368912-370964", "score": 18.067139, "text": "\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run the following command:\n\napk info <package_name>\n* To list all installed packages and their versions, run the following command:\n\napk list\n\n\n\n\n\n\n\n Debian and Ubuntu package manager commands \n\nOn Debian and Ubuntu, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\napt show <package_name>\n\ndpkg-query -l <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\napt list\n\ndpkg-query -W\n\n\n\n\n\n\n\n Red Hat and CentOS package manager commands \n\nOn Red Hat\u00ae OpenShift\u00ae and CentOS, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\nrpm -qi <package_name>\n\nyum info <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\nrpm -qa\n\nyum list installed\n\n\n\n\n\n* Does Vulnerability Advisor have versions?\n\n Does Vulnerability Advisor have versions? \n\nVulnerability Advisor is available in two versions, version 3 and version 4.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-368886-370938", "score": 18.067139, "text": "\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run the following command:\n\napk info <package_name>\n* To list all installed packages and their versions, run the following command:\n\napk list\n\n\n\n\n\n\n\n Debian and Ubuntu package manager commands \n\nOn Debian and Ubuntu, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\napt show <package_name>\n\ndpkg-query -l <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\napt list\n\ndpkg-query -W\n\n\n\n\n\n\n\n Red Hat and CentOS package manager commands \n\nOn Red Hat\u00ae OpenShift\u00ae and CentOS, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\nrpm -qi <package_name>\n\nyum info <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\nrpm -qa\n\nyum list installed\n\n\n\n\n\n* Does Vulnerability Advisor have versions?\n\n Does Vulnerability Advisor have versions? \n\nVulnerability Advisor is available in two versions, version 3 and version 4.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_01441-7-2257", "score": 18.02133, "text": "\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4"}, {"document_id": "ibmcld_01442-7-2257", "score": 18.02133, "text": "\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui"}, {"document_id": "ibmcld_01410-2747-3497", "score": 17.895721, "text": "\nVersion 1.0.0 of the CLI was released on 15 September 2022.\n\nThis release has the following changes:\n\n\n\n* Vulnerability Advisor v4 is now available, see [Vulnerability Advisor 4 is available from Container Registry plug-in 1.0.0](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_release_notes15sep2022_va_version_4).\n* Image and digest list output no longer includes security status by default. You can either add the --va argument to include security status for all the listed images, or you can use the ibmcloud cr va command to query security status for an individual image.\n\n\n\n\n\n\n\n Version 0.1.582 \n\nVersion 0.1.582 of the CLI was released on 15 September 2022.\n\nThis release has the following changes:\n\n\n\n* Vulnerability remediations.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_cli_change_log"}, {"document_id": "ibmcld_01442-1679-3832", "score": 17.855251, "text": "\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui"}, {"document_id": "ibmcld_01329-14955-16723", "score": 17.74852, "text": "\nIf you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr image-digests [--format FORMAT | --quiet | -q | --json] [--restrict RESTRICTION] [--include-ibm] [--no-va] [--va]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\n--format FORMAT\n: (Optional) Format the output elements by using a Go template. For more information, see [Formatting and filtering the Container Registry CLI output](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_cli_list).\n\n--quiet, -q\n: (Optional) Each image is listed in the format: repository@digest\n\n--json\n: (Optional) Outputs the list in JSON format.\n\n--restrict RESTRICTION\n: (Optional) Limit the output to display only images in the specified namespace or repository.\n\n--include-ibm\n: (Optional) Includes IBM-provided public images in the output. By default only private images are listed. You can view IBM-provided images in the global registry only.\n\n--no-va\n: (Optional) Excludes the security status (Vulnerability Advisor) results from the output.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcli"}, {"document_id": "ibmcld_01441-1679-3819", "score": 17.548616, "text": "\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01533-4546-6910", "score": 21.397156, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-4585-6962", "score": 21.139874, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_06063-53153-55320", "score": 17.797567, "text": "\nImage Vulnerability Scanner: By default, Vulnerability Advisor scans images that are stored in IBM Cloud Container Registry to find potential security vulnerabilities. For more information, see [Managing image security with Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index).\n4. IBM Cloud Security and Compliance Center: When you enable IBM Cloud Security and Compliance Center, you can view reports about suspicious incoming and outgoing network traffic. For more information, see [What is IBM Cloud Security and Compliance Center?](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n5. IBM Cloud\u00ae Secrets Manager: You can store your Ingress and Kubernetes secrets in IBM Cloud\u00ae Secrets Manager. When you integrate Secrets Manager into your cluster, you set a default Secrets Manager instance where all Ingress subdomain secrets are uploaded. For more information, see [Setting up Secrets Manager in your Kubernetes Service cluster](https://cloud.ibm.com/docs/containers?topic=containers-secrets-mgr).\n\n\n\n\n\n\n\n Image and registry \n\nEvery deployment is based on an image that holds the instructions for how to spin up the container that runs your app. These instructions include the operating system inside the container and extra software that you want to install. To protect your app, you must protect the image and establish checks to ensure the image's integrity.\n\nShould I use a public or a private registry to store my images?\n: Public registries, such as Docker Hub, can be used to get started with Docker images and Kubernetes to create your first containerized app in a cluster. But when it comes to enterprise applications, avoid registries that you don't know or don't trust to protect your cluster from malicious images. Keep your images in a private registry, like the one provided in IBM Cloud Container Registry and make sure to control access to the registry and the image content that can be pushed.\n\nWhy is it important to check images against vulnerabilities?\n: Research shows that most malicious attacks leverage known software vulnerabilities and weak system configurations.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-security"}, {"document_id": "ibmcld_01533-6329-8623", "score": 17.784933, "text": "\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-6381-8675", "score": 17.784933, "text": "\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01415-6473-8616", "score": 17.721159, "text": "\nFor more information, see [Billing for storage and pull traffic](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_faq&interface=ui"}, {"document_id": "ibmcld_01535-1902-3811", "score": 17.41535, "text": "\nFor more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nThe following functions are available in version 3:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.\n* Provides recommendations to secure configuration files for a subset of application types.\n* Provides instructions about how to fix a reported [vulnerable package](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages) or [configuration issue](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiapp_configurations) in its reports.\n* Applies exemption policies to reports at an account, [namespace](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe following functions are available in version 4:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01533-1902-3785", "score": 17.338257, "text": "\nFor more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nThe following functions are available in version 3:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.\n* Provides recommendations to secure configuration files for a subset of application types.\n* Provides instructions about how to fix a reported [vulnerable package](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexpackages) or [configuration issue](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexapp_configurations) in its reports.\n* Applies exemption policies to reports at an account, [namespace](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe following functions are available in version 4:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-4-2366", "score": 17.252964, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01533-4-2366", "score": 17.252964, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07949-12261-14447", "score": 20.998259, "text": "\nCombined with an intuitive user experience, built-in security and isolation, and advanced tools to secure, manage, and monitor your cluster workloads, you can rapidly deliver highly available and secure containerized apps in the public cloud.\n\n\n\n\n\n IBM Cloud Container Registry \n\nUse [Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overview) to store and access private container images. Container Registry provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM\u00ae. You can use Container Registry by setting up your own image namespace and pushing container images to your namespace. This service is required if using Red Hat OpenShift on IBM Cloud.\n\n\n\n\n\n\n\n Storage \n\n\n\n IBM Cloud Object Storage \n\n[Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-about-cloud-object-storage) stores encrypted and dispersed data across multiple geographic locations. Object Storage is available with three types of resiliency: Cross Region, Regional, and Single Data Center. Cross Region provides higher durability and availability than using a single region at the cost of slightly higher latency. Regional service reverses those tradeoffs, and distributes objects across multiple availability zones within a single region. If a given region or availability zone is unavailable, the object store continues to function without impediment. Single Data Center distributes objects across multiple machines within the same physical location.\n\nUsers of Object Storage refer to their binary data, such as files, images, media, archives, or even entire databases as objects. Objects are stored in a bucket, the container for their unstructured data. Buckets contain both inherent and user-defined metadata. Finally, objects are defined by a globally unique combination of the bucket name and the object key, or name.\n\n\n\n\n\n\n\n Security \n\n\n\n IBM Cloud Hyper Protect Crypto Services \n\n[Hyper Protect Crypto Services](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-overview) is a dedicated key management service and hardware security module (HSM) based on IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-satellite-architecture-about"}, {"document_id": "ibmcld_01390-0-434", "score": 20.98447, "text": "\n\n\n\n\n\n\n  Managing security and compliance for Container Registry \n\nIBM Cloud\u00ae Container Registry is integrated with the Security and Compliance Center to help you manage security and compliance for your organization.\n\nFor more information about managing security and compliance, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-manage-security-compliance"}, {"document_id": "ibmcld_01408-7-1878", "score": 20.709188, "text": "\nIBM Cloud Container Registry architecture and workload \n\nIBM Cloud\u00ae Container Registry is a multi-tenant, highly available, scalable, and encrypted private image\n\nregistrythat is hosted and managed by IBM.\n\nBoth the control plane (management of images and configuration) and data plane (pushing and pulling your images) are multi-tenant. All parts of the service are hosted in an IBM service account, which is not shared with users or other services.\n\nIn each regional instance of the [registry](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_registry), the service runs in three physically separate data centers to ensure availability. All data and the configuration for each instance of the registry is retained within the region in which it is hosted. The global instance is also hosted in physically separate data centers. The data centers might not be in the same region as each other. For more information about regions, see [Regions](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_regions).\n\nIBM Cloud Container Registry runs in IBM Cloud Kubernetes Service clusters, and uses IBM Cloud Object Storage to store images. Image data in IBM Cloud Object Storage is encrypted at rest.\n\nZoom\n\n![Diagram showing deployment.](https://cloud.ibm.com/docs-content/v1/content/cbb80bf851fb762a838129cba09d5674f8bfffda/Registry/images/container_registry_architecture_mul.svg)\n\nFigure 1. Diagram showing deployment\n\n\n\n Segmentation of data \n\nSegmentation of data within IBM Cloud Container Registry is achieved by using private\n\nnamespaces, which are strictly owned by single accounts.\n\nYou can control access to [namespaces](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_namespace) within the account by using Cloud Identity and Access Management (IAM) access policies.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_architecture"}, {"document_id": "ibmcld_09715-1298-2911", "score": 20.516739, "text": "\n[IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-started) IBM Cloud\u00ae Container Registry provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM\u00ae. [Platform metrics](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_monitor) \n [IBM Cloud\u00ae Kubernetes Service](https://cloud.ibm.com/docs/containers?topic=containers-getting-started) You can use the IBM Cloud Kubernetes Service service to deploy highly available apps in Docker containers that run in Kubernetes clusters. [Metrics sent by agent](https://cloud.ibm.com/docs/containers?topic=containers-health-monitormonitoring) \n [Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https://cloud.ibm.com/docs/openshift?topic=openshift-getting-started) With Red Hat OpenShift on IBM Cloud, you can deploy apps on highly available clusters that come installed with the Red Hat OpenShift on IBM Cloud Container Platform software installed on Red Hat Enterprise Linux. [Metrics sent by agent](https://cloud.ibm.com/docs/openshift?topic=openshift-health-monitoropenshift_monitoring) \n\n\n\n\n\n\n\n Database services \n\nThe following table lists database services that are enabled for IBM Cloud Monitoring:\n\n\n\nTable 3. List of database services\n\n Service Description Metrics \n\n [IBM Cloudant](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-getting-started-with-cloudant) IBM Cloudant is a document-oriented database as a service (DBaaS). It stores data as documents in JSON format. [Platform metrics](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-monitor-ibm-cloud-pm)", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-cloud_services"}, {"document_id": "ibmcld_01471-18622-20271", "score": 20.392208, "text": "\nAs an alternative approach, Container Registry supports the [Red Hat Signing](https://www.redhat.com/en/blog/container-image-signing) model. For more information, see [Signing images for trusted content by using Red Hat signatures](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_trustedcontentregistry_trustedcontent_red_hat_sig).\n\n\n\n\n\n 21 June 2021 \n\nGlobal registry\n: The global registry (icr.io) is now available for hosting user images and namespaces. Previously the global registry hosted only public images that are provided by IBM. For more information, see [Global registry](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_regions_global).\n\n\n\n\n\n 10 May 2021 \n\nNew region in Canada\n: A new region in Toronto, Canada is available. The new region is ca-tor and the domain name is ca.icr.io. For more information, see [Local regions](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_regions_local).\n\n\n\n\n\n 4 May 2021 \n\nThe ibmcloud cr ppa-archive-load command is discontinued\n: The ibmcloud cr ppa-archive-load command is discontinued. Containerized software is distributed in IBM Cloud Paks, see [IBM Cloud Paks](https://www.ibm.com/cloud-paks). To run IBM Cloud Paks on Red Hat OpenShift on IBM Cloud, see [Adding Cloud Paks](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_cloud_paks). For more information about setting up your IBM Cloud Kubernetes Service cluster to pull entitled software, see [Setting up a cluster to pull entitled software](https://cloud.ibm.com/docs/containers?topic=containers-registrysecret_entitled_software).\n\n\n\n\n\n 18 February 2021", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_release_notes"}, {"document_id": "ibmcld_16729-71418-73421", "score": 20.260843, "text": "\nIBM Cloud\u00ae Container Registry provides a multi-tenant private image registry that you can use to store and share your container images with users in your IBM Cloud account.\n\nKubernetes service Container Registry\n\n\n\n* 45 minutes\n* 2023-06-02\n\n\n\n[Encrypting images for content confidentiality](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_encrypt)Encrypting images for content confidentiality\n\nYou can protect the confidentiality of your IBM Cloud\u00ae Container Registry images, and ensure that hosts that aren't trusted can't run the images.\n\nKey Protect Container Registry\n\n\n\n* 2 hours\n* 2023-01-25\n\n\n\n[Granting access to Container Registry resources tutorial](https://cloud.ibm.com/docs/Registry?topic=Registry-iam_access)Granting access to Container Registry resources tutorial\n\nUse this tutorial to find out how to grant access to your resources by configuring IBM Cloud\u00ae Identity and Access Management (IAM) for IBM Cloud\u00ae Container Registry.\n\nContainer Registry\n\n\n\n* 45 minutes\n* 2023-01-31\n\n\n\n[Container Registry and Vulnerability Advisor workflow tutorial](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_tutorial_workflow)Container Registry and Vulnerability Advisor workflow tutorial\n\nUse this tutorial to find out about the basic functions of both IBM Cloud\u00ae Container Registry and Vulnerability Advisor.\n\nKubernetes service Container Registry\n\n\n\n* 2 hours\n* 2023-06-19\n\n\n\n[Onboarding a Certified Operator from a Red Hat registry](https://cloud.ibm.com/docs/account?topic=account-catalog-opbundle-tutorial)Onboarding a Certified Operator from a Red Hat registry\n\nThis tutorial walks you through how to onboard a sample Operator bundle from a Red Hat\u00ae registry to your account. By completing this tutorial, you learn how to create a private catalog in your account, import the Operator bundle, and validate that it can be installed on a Red Hat OpenShift on IBM Cloud cluster.\n\nContainer Registry Managing your account, resources, and access\n\n\n\n* 45 minutes\n* 2022-10-26", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}, {"document_id": "ibmcld_01370-7-2012", "score": 20.244795, "text": "\nManaging your data in Container Registry \n\nInformation about your data and how it is stored in IBM Cloud\u00ae Container Registry.\n\nThe IBM Cloud platform provides layered security controls across network and infrastructure. IBM Cloud provides a group of security services that can be used by application developers to secure their mobile and web apps. For more information, see [How do I know that my data is safe?](https://cloud.ibm.com/docs/overview?topic=overview-security)\n\n\n\n How your data is stored \n\n\n\n Image data \n\nImage data is stored in IBM Cloud Object Storage, which is encrypted at rest, and encrypted in transit between IBM Cloud Container Registry and IBM Cloud Object Storage. For more information about IBM Cloud Object Storage, see [About IBM Cloud Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-about-cloud-object-storage).\n\nData that is stored in IBM Cloud Container Registry is backed up regularly. For more information, see [High availability and disaster recovery](https://cloud.ibm.com/docs/Registry?topic=Registry-ha-dr).\n\n\n\n\n\n Scanning data \n\nTo scan images and containers in your account for security issues, IBM Cloud Container Registry collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names ([registry](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_registry), [namespace](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_repository) name, and image [tag](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_tag))\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-delete-data"}, {"document_id": "ibmcld_01438-3222-5394", "score": 20.121675, "text": "\n* You're using an IBM Cloud Kubernetes Service cluster in a [configuration](https://cloud.ibm.com/docs/containers?topic=containers-registrycluster_registry_auth_private) that automatically talks to the registry over a private connection.\n* You're accessing Container Registry through a virtual private cloud (VPC) virtual private endpoint gateway (VPE gateway).\n* You're using the Container Registry private IP addresses for configuring network access, for example, in firewalls or Access Control Lists (ACL).\n\n\n\nIf any of the previous statements is true when this change takes effect, the IP addresses in the IBM Cloud Activity Tracker logs change, but you don't need to do anything unless you are also using IAM IP address access restrictions.\n\n\n\n\n\n What actions you need to take \n\nYou must take the appropriate actions before 23 June 2022. If you don\u2019t make the appropriate updates, your requests to push and pull from Container Registry might fail.\n\nDepending on which of the following scenarios you fit, take the appropriate action.\n\nYou access Container Registry over the private network and maintain a list of restricted IP addresses in IAM.\n: You must update your IAM restricted IP address list to include any IP addresses or subnets of hosts in your account that make requests to Container Registry. You must keep the current Container Registry private IP addresses in your restricted IP list until an announcement indicates it is safe to remove them. For more information about how to update a restricted IP address list, see [Allowing specific IP addresses](https://cloud.ibm.com/docs/account?topic=account-ips) in the Cloud Identity and Access Management (IAM) documentation.\n\nYour firewalls are configured with the Container Registry private IP addresses.\n: You must include the new private IP addresses in your firewall configuration. For more information about connecting to Container Registry over the private network, see [Securing your connection to Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_private).\n\nFor more information about the new and current Container Registry private IP addresses, see the following topics:", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_iam_private_network"}, {"document_id": "ibmcld_01471-8047-9956", "score": 20.107742, "text": "\nFor more information, see [Container Registry CLI stops returning security status results in lists by default from version 1.0.0](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_lists).\n\n\n\n\n\n 8 July 2022 \n\nContext-based restrictions\n: You can use context-based restrictions to define and enforce access restrictions for IBM Cloud resources based on the network location of access requests.\n\nFor more information, see [Context-based restrictions](https://cloud.ibm.com/docs/Registry?topic=Registry-iam&interface=uiiam_cbr).\n\n\n\n\n\n 5 July 2022 \n\nChange to Container Registry private IP addresses in all regions\n: If you are using Cloud Identity and Access Management (IAM) restricted IP address lists and you are connecting to Container Registry over the private network, your lists of allowed IP addresses must now include the private subnet and IP addresses of your own hosts. The IBM Cloud Container Registry private IP addressees also changed. This change also affects you if you have allowlists or a firewall rule.\n\nFor more information, see [Container Registry private IP addresses changed on 5 July 2022](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_iam_private_network) and [Using IAM IP address access restrictions](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_iam_ip).\n\nAll accounts require IAM access policies\n: To access IBM Cloud Container Registry, you must be using Cloud Identity and Access Management (IAM) access policies. You must ensure that you are using IAM access policies to manage access to the Container Registry service.\n\nPolicy-free authorization is discontinued in the following Container Registry regions:\n\n\n\n* us-south (us.icr.io)\n* uk-south (uk.icr.io)\n* eu-central (de.icr.io)\n* ap-south (au.icr.io)\n* ap-north (jp.icr.io)\n\n\n\nOther regions are unaffected because they already require IAM access policies for all accounts.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_release_notes"}, {"document_id": "ibmcld_09410-1574-3779", "score": 20.105152, "text": "\n* IBM Cloud Container Registry provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM.\n* The IBM Cloud Container Registry includes Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\n\n\nTo get details about the logging agent images, see [Getting information about logging agent images](https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-log_analysis_agent_image).\n\n\n\n Resource Limits for agents deployed on Kubernetes \n\nThe agent is deployed as a Kubernetes DaemonSet, creating one pod for each node selected. The agent collects logs of all the pods in the node. The resource requirements of the agent are in direct relation to the number of pods for each node and the amount of logs produced for each pod.\n\nThe agent requires at least 128 MB and no more than 512 MB of memory. It requires at least twenty millicpu (20m).\n\nDifferent features can also increase resource utilization. When line exclusion, inclusion or redaction rules are specified, you can expect additional CPU consumption for each line and regex rule defined. When Kubernetes event logging is enabled (disabled by default), additional CPU usage will occur on the oldest agent pod.\n\nPlacing traffic shaping or CPU limits on the agent is not recommended to ensure data can be sent to the log ingestion service.\n\n\n\n\n\n Understanding image tags \n\nThe tag that is associated to a logging image indicates whether the logging agent is automatically updated.\n\nA tag consists of multiple parts:\n\nX.Y.Z-<date>.[hash]\n\nWhere\n\n\n\n* X represents the major version of an image.\n* Y represents the minor version of an image.\n* Z represents an incremental ID that determines the latest patched minor version.\n* <date> represents the date that the image is built and available. The format is YYYYMMDD.", "title": "", "source": "https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-log_analysis_agent"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01388-7-1807", "score": 25.503609, "text": "\nGranting access to Container Registry resources tutorial \n\nUse this tutorial to find out how to grant access to your resources by configuring IBM Cloud\u00ae Identity and Access Management (IAM) for IBM Cloud\u00ae Container Registry.\n\nAll accounts require IAM access policies. To set up and manage IAM access policies, see [Defining IAM access policies](https://cloud.ibm.com/docs/Registry?topic=Registry-useruser).\n\nFor more information about how to use IAM to manage access to your resources, see [Managing access to resources](https://cloud.ibm.com/docs/account?topic=account-assign-access-resources).\n\n\n\n Before you begin \n\nBefore you begin, you must complete the following tasks:\n\n\n\n* Complete the instructions in [Getting started with IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started).\n* Ensure that you have the most recent version of the container-registry CLI plug-in for the IBM Cloud CLI, see [Updating the container-registry CLI plug-in](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_setup_cli_namespaceregistry_cli_update).\n* Ensure that you have access to two [IBM Cloud accounts](https://cloud.ibm.com/login) that you can use for this tutorial, one for User A and one for User B, each must use a unique email address. You work in your own account, User A, and invite another user, User B, to use your account. You can choose to create a second IBM Cloud account, or you can work with a colleague that has an IBM Cloud account.\n* Ensure that you have the correct access permissions for adding and removingnamespaces, see [Access roles for configuring IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iamaccess_roles_configure).\n\n\n\n\n\n\n\n Step 1: Authorize a user to configure the registry", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-iam_access"}, {"document_id": "ibmcld_16729-71418-73421", "score": 24.855497, "text": "\nIBM Cloud\u00ae Container Registry provides a multi-tenant private image registry that you can use to store and share your container images with users in your IBM Cloud account.\n\nKubernetes service Container Registry\n\n\n\n* 45 minutes\n* 2023-06-02\n\n\n\n[Encrypting images for content confidentiality](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_encrypt)Encrypting images for content confidentiality\n\nYou can protect the confidentiality of your IBM Cloud\u00ae Container Registry images, and ensure that hosts that aren't trusted can't run the images.\n\nKey Protect Container Registry\n\n\n\n* 2 hours\n* 2023-01-25\n\n\n\n[Granting access to Container Registry resources tutorial](https://cloud.ibm.com/docs/Registry?topic=Registry-iam_access)Granting access to Container Registry resources tutorial\n\nUse this tutorial to find out how to grant access to your resources by configuring IBM Cloud\u00ae Identity and Access Management (IAM) for IBM Cloud\u00ae Container Registry.\n\nContainer Registry\n\n\n\n* 45 minutes\n* 2023-01-31\n\n\n\n[Container Registry and Vulnerability Advisor workflow tutorial](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_tutorial_workflow)Container Registry and Vulnerability Advisor workflow tutorial\n\nUse this tutorial to find out about the basic functions of both IBM Cloud\u00ae Container Registry and Vulnerability Advisor.\n\nKubernetes service Container Registry\n\n\n\n* 2 hours\n* 2023-06-19\n\n\n\n[Onboarding a Certified Operator from a Red Hat registry](https://cloud.ibm.com/docs/account?topic=account-catalog-opbundle-tutorial)Onboarding a Certified Operator from a Red Hat registry\n\nThis tutorial walks you through how to onboard a sample Operator bundle from a Red Hat\u00ae registry to your account. By completing this tutorial, you learn how to create a private catalog in your account, import the Operator bundle, and validate that it can be installed on a Red Hat OpenShift on IBM Cloud cluster.\n\nContainer Registry Managing your account, resources, and access\n\n\n\n* 45 minutes\n* 2022-10-26", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}, {"document_id": "ibmcld_01415-3669-5394", "score": 24.312342, "text": "\nFor more information, see [Granting access to IBM Cloud Container Registry resources tutorial](https://cloud.ibm.com/docs/Registry?topic=Registry-iam_access) and [Managing IAM access for Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iam).\n\n\n\n\n\n How can I share an image with many users? \n\nYou can create an IBM Cloud account and invite all the users to it. They can then all have access to any\n\nnamespacethat is created in the account. You can create a subset of the users and set an IAM access policy to differentiate access at the namespace level. Users can be members of many accounts, but you can't give access outside the account, that is, you can't share a namespace to multiple accounts.\n\nFor more information, see [Defining IAM access policies](https://cloud.ibm.com/docs/Registry?topic=Registry-user).\n\n\n\n\n\n Do I have any untagged images? \n\nTo find out whether you have any [untagged](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_untagged) images, list your images by running the [ibmcloud cr image-digests](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregclibx_cr_image_digests) command. Untagged images have a hyphen (-) in the Tags column.\n\n\n\n\n\n Do I need untagged images? \n\nIf you have active containers that are running [untagged](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_untagged) images, you must retain the untagged images. If you delete untagged images that are in use, you can cause problems with scaling or automated restarts. Deleting untagged images might cause a problem in the following circumstances:\n\n\n\n* The image was deployed by referencing the image by using the digest.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_faq&interface=ui"}, {"document_id": "ibmcld_07578-363349-365063", "score": 24.10369, "text": "\nFor more information, see [Granting access to IBM Cloud Container Registry resources tutorial](https://cloud.ibm.com/docs/Registry?topic=Registry-iam_access) and [Managing IAM access for Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iam).\n* How can I share an image with many users?\n\n How can I share an image with many users? \n\nYou can create an IBM Cloud account and invite all the users to it. They can then all have access to any namespace A collection of repositories that store images in a registry. A namespace is associated with an IBM Cloud account, which can include multiple namespaces. that is created in the account. You can create a subset of the users and set an IAM access policy to differentiate access at the namespace level. Users can be members of many accounts, but you can't give access outside the account, that is, you can't share a namespace to multiple accounts.\n\nFor more information, see [Defining IAM access policies](https://cloud.ibm.com/docs/Registry?topic=Registry-user).\n* Do I have any untagged images?\n\n Do I have any untagged images? \n\nTo find out whether you have any [untagged](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_untagged) images, list your images by running the [ibmcloud cr image-digests](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregclibx_cr_image_digests) command. Untagged images have a hyphen (-) in the Tags column.\n* Do I need untagged images?\n\n Do I need untagged images? \n\nIf you have active containers that are running [untagged](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_untagged) images, you must retain the untagged images.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-363323-365037", "score": 24.10369, "text": "\nFor more information, see [Granting access to IBM Cloud Container Registry resources tutorial](https://cloud.ibm.com/docs/Registry?topic=Registry-iam_access) and [Managing IAM access for Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iam).\n* How can I share an image with many users?\n\n How can I share an image with many users? \n\nYou can create an IBM Cloud account and invite all the users to it. They can then all have access to any namespace A collection of repositories that store images in a registry. A namespace is associated with an IBM Cloud account, which can include multiple namespaces. that is created in the account. You can create a subset of the users and set an IAM access policy to differentiate access at the namespace level. Users can be members of many accounts, but you can't give access outside the account, that is, you can't share a namespace to multiple accounts.\n\nFor more information, see [Defining IAM access policies](https://cloud.ibm.com/docs/Registry?topic=Registry-user).\n* Do I have any untagged images?\n\n Do I have any untagged images? \n\nTo find out whether you have any [untagged](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_untagged) images, list your images by running the [ibmcloud cr image-digests](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregclibx_cr_image_digests) command. Untagged images have a hyphen (-) in the Tags column.\n* Do I need untagged images?\n\n Do I need untagged images? \n\nIf you have active containers that are running [untagged](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_untagged) images, you must retain the untagged images.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_04335-195545-197316", "score": 23.950462, "text": "\nFor example, IBM Cloud Container Registry and Docker Hub are container registries. A container registry can be public or private. A container registry that is public does not require credentials to access. In contrast, accessing a private registry does require credentials.\n\nYou must be within the context of a [project](https://cloud.ibm.com/docs/cli?topic=cli-clicli-project) before you use registry commands.\n\nFor more information about accessing registries, see [Adding access to a private container registry](https://cloud.ibm.com/docs/codeengine?topic=codeengine-add-registry).\n\nTo see CLI help for the registry commands, run ibmcloud ce registry -h.\n\nBeginning with CLI version 1.42.0, defining and working with secrets in the CLI is unified under the secret command group. See [ibmcloud ce secret](https://cloud.ibm.com/docs/codeengine?topic=codeengine-clicli-secret-create) commands. Use the --format option to specify the category of secret, such as basic_auth, generic, ssh, tls, or registry. While you can continue to use the registry command group, take advantage of the unified secret command group. To create a secret to access a container registry, use the [ibmcloud ce secret create --format registry](https://cloud.ibm.com/docs/codeengine?topic=codeengine-clicli-secret-create) command. To learn more about working with secrets in Code Engine, see [Working with secrets](https://cloud.ibm.com/docs/codeengine?topic=codeengine-secret).\n\n\n\n ibmcloud ce registry create \n\nCreate an image registry access secret.\n\nibmcloud ce registry create --name NAME (--password PASSWORD | --password-from-file PASSWORD_FILE | --password-from-json-file) [--email EMAIL] [--output OUTPUT] [--quiet] [--server SERVER] [--username USERNAME]\n\n\n\n Command Options \n\n-n, --name", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cli"}, {"document_id": "ibmcld_06260-2563-4421", "score": 23.940758, "text": "\nThe global registry stores IBM-provided public images, and regional registries store your own private or public images. If your allowlist is IP-based, you can see which IP addresses are opened when you allow access to the IBM Cloud Container Registry regional service endpoints by reviewing [this table](https://cloud.ibm.com/docs/containers?topic=containers-firewallfirewall_registry).\n6. Verify your connection. The following is an example for the US East and US South regional registry. If access is configured correctly, a message of the day is returned in the output. Note that if there are no messages, a 204 is returned.\n\ncurl -i https://us.icr.io/api/v1/messages\n\n\n\n\n\n\n\n Running kubectl commands from behind an allowlist \n\nIf corporate network policies prevent access from your local system to public endpoints via proxies or allowlists, to run kubectl commands, you must allow TCP access for the cluster.\n\nWhen a cluster is created, the port in the service endpoint URLs is randomly assigned from within 30000-32767. You can either choose to open port range 30000-32767 for any cluster that might get created or you can choose to allow access for a specific existing cluster.\n\nBefore you begin, allow access to [run ibmcloud ks commands](https://cloud.ibm.com/docs/containers?topic=containers-vpc-firewallvpc-firewall_bx).\n\nTo allow access for a specific cluster:\n\n\n\n1. Log in to the IBM Cloud CLI. Enter your IBM Cloud credentials when prompted. If you have a federated account, include the --sso option.\n\nibmcloud login [--sso]\n2. If the cluster is in a resource group other than default, target that resource group. To see the resource group that each cluster belongs to, run ibmcloud ks cluster ls. Note: You must have at least the [Viewer role](https://cloud.ibm.com/docs/containers?topic=containers-userschecking-perms) for the resource group.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-vpc-firewall"}, {"document_id": "ibmcld_01387-13496-15060", "score": 23.924294, "text": "\ncontainer-registry.settings.set [ibmcloud cr platform-metrics](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcliic_cr_platform_metrics) Update registry service settings for the targeted account, such as enabling platform metrics. Manager \n\n\n\n\n\n\n\n Access roles for using Container Registry \n\nTo grant a user permission to access Container Registry content in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you can restrict access to a specific namespace by specifying the resource type namespace and the namespace name as the resource. If you don't specify a resource-type and a resource, the policy grants access to all resources in the account. Alternatively, if your namespace is within a resource group, permission can be granted by using an IAM access policy on that resource group.\n\nFor example, use the following command to create a user policy. Where <user_email> is the user's email address, <region> is the region, <roles> is the role, or roles, that you want the user to have, and <namespace_name> is the name of the namespace.\n\nibmcloud iam user-policy-create <user_email> --service-name container-registry --region <region> --roles <roles> [--resource-type namespace --resource <namespace_name>]\n\nThe following table details actions that are mapped to operations on the service and to the service access roles for using Container Registry.\n\n\n\nTable 5. Service actions and operations for using Container Registry\n\n Action Operation on service Role Status", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-iam&interface=ui"}, {"document_id": "ibmcld_01377-13470-15034", "score": 23.924294, "text": "\ncontainer-registry.settings.set [ibmcloud cr platform-metrics](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcliic_cr_platform_metrics) Update registry service settings for the targeted account, such as enabling platform metrics. Manager \n\n\n\n\n\n\n\n Access roles for using Container Registry \n\nTo grant a user permission to access Container Registry content in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you can restrict access to a specific namespace by specifying the resource type namespace and the namespace name as the resource. If you don't specify a resource-type and a resource, the policy grants access to all resources in the account. Alternatively, if your namespace is within a resource group, permission can be granted by using an IAM access policy on that resource group.\n\nFor example, use the following command to create a user policy. Where <user_email> is the user's email address, <region> is the region, <roles> is the role, or roles, that you want the user to have, and <namespace_name> is the name of the namespace.\n\nibmcloud iam user-policy-create <user_email> --service-name container-registry --region <region> --roles <roles> [--resource-type namespace --resource <namespace_name>]\n\nThe following table details actions that are mapped to operations on the service and to the service access roles for using Container Registry.\n\n\n\nTable 5. Service actions and operations for using Container Registry\n\n Action Operation on service Role Status", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-iam"}, {"document_id": "ibmcld_01428-0-1510", "score": 23.908873, "text": "\n\n\n\n\n\n\n  Using IAM IP address access restrictions \n\nYou can enable IAM IP address access restrictions when you're using IBM Cloud\u00ae Container Registry.\n\nTo enable IAM IP address access restrictions, you must ensure that the Cloud Identity and Access Management (IAM) access list is configured so that the Container Registry OAuth service can still function. The OAuth service is used to authenticate image pulls and pushes in Container Registry.\n\nYou must ensure that the IP addresses of any computers that can originate pulls and pushes are added to the IAM IP address access list, see [Allowing specific IP addresses](https://cloud.ibm.com/docs/account?topic=account-ips).\n\n\n\n  Granting access if you are using a public network \n\nIf you're using IBM Cloud Container Registry over a public network, you must ensure that the Public IP addresses of any computers that can originate pulls and pushes are added to the IAM IP allowlist.\n\n\n\n\n\n  Granting access if you are using a private network \n\nIf you're using IBM Cloud Container Registry in one of the following scenarios, you must add the private IP addresses of any computers that can originate pulls and pushes to the allowlist.\n\n\n\n*  You're using one of the private. domains, for example, private.us.icr.io.\n*  You're using an IBM Cloud Kubernetes Service cluster in a [configuration](https://cloud.ibm.com/docs/containers?topic=containers-registrycluster_registry_auth_private) that automatically talks to the registry over a private connection.\n\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_iam_ip"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01471-25013-26745", "score": 17.251554, "text": "\nFor more information, see [Set up a namespace](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgs_registry_namespace_add) and [ibmcloud cr namespace-add](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregclibx_cr_namespace_add).\n* Namespaces created in version 0.1.484 of the Container Registry CLI or earlier, or in the IBM Cloud console before 29 July 2020 aren't assigned to resource groups. You can assign an existing namespace to a resource group so that you can configure access to resources within a namespace at the resource group level. For more information, see [Assigning existing namespaces to resource groups](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_setup_cli_namespaceregistry_namespace_assign) and [ibmcloud cr namespace-assign](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcliic_cr_namespace_assign).\n* You can find out which namespaces are assigned to resource groups and which are unassigned by running the [ibmcloud cr namespace-list](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregclibx_cr_namespace_list) command with the -v option.\n\n\n\n\n\n\n\n 13 July 2020 \n\nTo work with namespaces, you must have the Manager role at the account level\n: If you want to add or remove namespaces, you must have the Manager role, see [Access roles for configuring Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iamaccess_roles_configure).\n\n\n\n\n\n 24 June 2020 \n\nRestoring all tags for a digest in a repository is now an option\n: When you want to restore an image, you can restore either by tag or by digest. Restoring by digest restores the digest and all its tags in the repository that aren't already in the live repository.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_release_notes"}, {"document_id": "ibmcld_01484-4131-5923", "score": 17.10113, "text": "\nFor more information about resource groups, see [Assigning existing namespaces to resource groups](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_setup_cli_namespaceregistry_namespace_assign).\n\nNamespaces that are assigned to a resource group show in the Resource list page of the IBM Cloud console.\n\nYou can set up multiple namespaces, for example, to have separate repositories for your production and staging environments. If you want to use the registry in multiple IBM Cloud regions, you must set up a namespace for each region. Namespace names are unique within regions. You can use the same namespace name for each region, unless someone else already has a namespace with that name in that region.\n\nYou can have 100 namespaces in each region.\n\nTo work with the IBM-provided public images only, you do not need to set up a namespace.\n\nIf you're unsure whether a namespace is already set for your account, run the ibmcloud cr namespace-list command with the -v option to retrieve existing namespace information.\n\nConsider the following rules when you choose a namespace:\n\n\n\n* Your namespace must be unique across all IBM Cloud accounts in the same region.\n* Your namespace must have 4 - 30 characters.\n* Your namespace must start and end with a letter or number.\n* Your namespace must contain lowercase letters, numbers, hyphens (-), and underscores (_) only.\n\n\n\nDo not put personal information in your namespace names.\n\nAfter you set your first namespace, you are assigned to the free IBM Cloud Container Registry service plan unless you [upgrade your plan](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_plan_upgrade).\n\n\n\n User permissions for working with namespaces \n\nYou can control which users can work with namespaces by using IAM roles.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_setup_cli_namespace&interface=ui"}, {"document_id": "ibmcld_01477-4118-5910", "score": 17.10113, "text": "\nFor more information about resource groups, see [Assigning existing namespaces to resource groups](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_setup_cli_namespaceregistry_namespace_assign).\n\nNamespaces that are assigned to a resource group show in the Resource list page of the IBM Cloud console.\n\nYou can set up multiple namespaces, for example, to have separate repositories for your production and staging environments. If you want to use the registry in multiple IBM Cloud regions, you must set up a namespace for each region. Namespace names are unique within regions. You can use the same namespace name for each region, unless someone else already has a namespace with that name in that region.\n\nYou can have 100 namespaces in each region.\n\nTo work with the IBM-provided public images only, you do not need to set up a namespace.\n\nIf you're unsure whether a namespace is already set for your account, run the ibmcloud cr namespace-list command with the -v option to retrieve existing namespace information.\n\nConsider the following rules when you choose a namespace:\n\n\n\n* Your namespace must be unique across all IBM Cloud accounts in the same region.\n* Your namespace must have 4 - 30 characters.\n* Your namespace must start and end with a letter or number.\n* Your namespace must contain lowercase letters, numbers, hyphens (-), and underscores (_) only.\n\n\n\nDo not put personal information in your namespace names.\n\nAfter you set your first namespace, you are assigned to the free IBM Cloud Container Registry service plan unless you [upgrade your plan](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_plan_upgrade).\n\n\n\n User permissions for working with namespaces \n\nYou can control which users can work with namespaces by using IAM roles.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_setup_cli_namespace"}, {"document_id": "ibmcld_10863-1737-3164", "score": 16.543318, "text": "\nFor more information about namespaces, see [Managing namespaces](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-namespaces).\n\n\n\n Step 1: Create the cos-access actioncos-access action \n\nThe cos-access action is a Node.js program that simulates code to access IBM Cloud Object Storage by setting a timeout that resolves after 10 seconds.\n\n\n\n1. Go to the [Create page](https://cloud.ibm.com/functions/create) in the Cloud Functions console.\n2. Select Action.\n3. Create the cos-access action:\n\n\n\n1. Name your action cos-access.\n2. Click Create Package. Name your package action-tutorial and click Create.\n3. Select Node.js 10 for the runtime.\n4. Click Create.\n5. Paste in the following code example:\n\n/\n* main() will be run when you invoke this action\n* @param Cloud Functions actions accept a single parameter, which must be a JSON object.\n* @return The output of this action, which must be a JSON object.\n/\nfunction main(params) {\nreturn new Promise((resolve, reject) => {\n// simulate a COS access by resolving after 10s\nsetTimeout(() => {\nconsole.log('fake COS bucket access done. Resolving Promise...');\nresolve({ cos_message: 'SUCCESS'});\n}, 10000);\n});\n}\nShow more\n6. Click Save.\n7. Test your action by clicking Invoke and waiting for the following output to display.\n\nExample output\n\nResults:\n{\n\"cos_message\": \"SUCCESS\"\n}\n\nLogs:\n[\n\"2020-04-21T01:51:49.464941Z stdout: fake COS bucket access done. Resolving Promise...\"", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-tutorial_action"}, {"document_id": "ibmcld_06128-23630-25505", "score": 16.242863, "text": "\nWhen you create a deployment, limit it so that your app's pod deploys only on machines with the best mix of resources. For example, you might want to limit a database application to a bare metal machine with a significant amount of local disk storage like the md1c.28x512.4x4tb.\n\n\n\n\n\n Set up multiple namespaces when you have multiple teams and projects that share the cluster \n\nNamespaces are kind of like a cluster within the cluster. They are a way to divide up cluster resources by using [resource quotas](https://kubernetes.io/docs/concepts/policy/resource-quotas/) and [default limits](https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/memory-default-namespace/). When you make new namespaces, be sure to set up proper [RBAC policies](https://cloud.ibm.com/docs/containers?topic=containers-usersrbac) to control access. For more information, see [Share a cluster with namespaces](https://kubernetes.io/docs/tasks/administer-cluster/namespaces/) in the Kubernetes documentation.\n\nIf you have a small cluster, a couple dozen users, and resources that are similar (such as different versions of the same software), you probably don't need multiple namespaces. You can use labels instead.\n\n\n\n\n\n Set resource quotas so that users in your cluster must use resource requests and limits \n\nTo ensure that every team has the necessary resources to deploy services and run apps in the cluster, you must set up [resource quotas](https://kubernetes.io/docs/concepts/policy/resource-quotas/) for every namespace. Resource quotas determine the deployment constraints for a namespace, such as the number of Kubernetes resources that you can deploy, and the amount of CPU and memory that can be consumed by those resources. After you set a quota, users must include resource requests and limits in their deployments.\n\n\n\n\n\n Organize your Kubernetes objects with labels", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-strategy"}, {"document_id": "ibmcld_01496-0-1282", "score": 16.239935, "text": "\n\n\n\n\n\n\n  Why can't I add a namespace? \n\nSetting up a namespace fails in IBM Cloud\u00ae Container Registry.\n\n  What\u2019s happening \n\nWhen you run ibmcloud cr namespace-add, you're unable to set your entered value as the namespace.\n\n  Why it\u2019s happening \n\nThe following alternatives are possible causes:\n\n\n\n*  You entered a namespace value that is already being used by another IBM Cloud organization.\n*  A namespace was recently deleted and you're reusing its name. If the namespace that was deleted contained many resources, the deletion might not yet be fully processed by Container Registry.\n*  You used invalid characters in the namespace value.\n\n\n\n  How to fix it \n\nYou can fix this problem in the following ways:\n\n\n\n*  Follow any instructions that are in the returned error message.\n*  Check that you entered a valid namespace:\n\n\n\n*  Your namespace must be unique across all IBM Cloud accounts in the same region.\n*  Your namespace must be 4 - 30 characters long.\n*  Your namespace must start and end with a letter or number.\n*  Your namespace must contain lowercase letters, numbers, hyphens (-), and underscores (_) only.\n\n\n\n*  Choose a different value for your namespace.\n*  If you're re-creating a namespace that was deleted, and it contained many images, try again later.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-troubleshoot-add-namespace"}, {"document_id": "ibmcld_10568-24168-25905", "score": 15.848579, "text": "\nIf you have a small cluster, a couple dozen users, and resources that are similar (such as different versions of the same software), you probably don't need multiple namespaces. You can use labels instead.\n\n\n\n\n\n Set resource quotas so that users in your cluster must use resource requests and limits \n\nTo ensure that every team has the necessary resources to deploy services and run apps in the cluster, you must set up [resource quotas](https://kubernetes.io/docs/concepts/policy/resource-quotas/) for every namespace. Resource quotas determine the deployment constraints for a project, such as the number of Kubernetes resources that you can deploy, and the amount of CPU and memory that can be consumed by those resources. After you set a quota, users must include resource requests and limits in their deployments.\n\n\n\n\n\n Organize your Kubernetes objects with labels \n\nTo organize and select your Kubernetes resources such as pods or nodes, [use Kubernetes labels](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/). By default, Red Hat OpenShift on IBM Cloud applies some labels, including arch, os, region, zone, and machine-type.\n\nExample use cases for labels include [limiting network traffic to edge worker nodes](https://cloud.ibm.com/docs/openshift?topic=openshift-edge), [deploying an app to a GPU machine](https://cloud.ibm.com/docs/containers?topic=containers-deploy_appgpu_app), and [restricting your app workloads](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/) to run on worker nodes that meet certain flavor or SDS capabilities, such as bare metal worker nodes. To see what labels are already applied to a resource, use the oc get command with the --show-labels option.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-strategy"}, {"document_id": "ibmcld_01477-6761-8558", "score": 15.8281145, "text": "\n* To view and analyze namespaces, you must have the Reader or Manager role in the IBM Cloud Container Registry service, see [Access roles for using IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\nFor more information about user roles, [Defining IAM access policies](https://cloud.ibm.com/docs/Registry?topic=Registry-useruser).\n\n\n\n\n\n\n\n Setting up a namespace \n\nYou must create a namespace to store your Docker images in IBM Cloud Container Registry.\n\nBefore you begin, complete the following tasks:\n\n\n\n* [Install the IBM Cloud CLI and the container-registry CLI plug-in](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgs_registry_cli_install).\n* [Plan how to use and name your registry namespaces](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_setup_cli_namespaceregistry_setup_cli_namespace_plan).\n\n\n\nTo create a namespace, see [Set up a namespace](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgs_registry_namespace_add). Namespaces are created in the resource group that you specify so that you can configure access to resources within the namespace at the resource group level. If you don't specify a resource group, and a resource group isn't targeted, the default resource group is used. For more information about resource groups, see [Managing resource groups](https://cloud.ibm.com/docs/account?topic=account-rgs).\n\nNamespaces that are assigned to a resource group show in the Resource list page of the IBM Cloud console.\n\nThe namespace must be unique across all IBM Cloud accounts in the same region. Namespaces must have 4 - 30 characters, and contain lowercase letters, numbers, hyphens (-), and underscores (_) only. Namespaces must start and end with a letter or number.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_setup_cli_namespace"}, {"document_id": "ibmcld_01494-43537-45041", "score": 15.6923485, "text": "\n* [Assigning existing namespaces to resource groups](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_setup_cli_namespaceregistry_namespace_assign)\n* [Removing namespaces](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_setup_cli_namespaceregistry_remove)\n\n\n\n\n\n\n\n Setting up Container Registry as a private registry on Red Hat OpenShift \n\n[Setting up Container Registry as a private registry on Red Hat OpenShift](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_rhosregistry_rhos)\n\n\n\n* [Set up Red Hat OpenShift on IBM Cloud to use Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_rhosregistry_rhos_rhoks)\n* [Set up Red Hat OpenShift Container Platform to use Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_rhosregistry_rhos_os)\n\n\n\n* [Set up the Red Hat OpenShift Container Platform internal registry to pull from Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_rhosregistry_rhos_os_pull)\n* [Set up the Red Hat OpenShift Container Platform build to push images to Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_rhosregistry_rhos_os_push)\n\n\n\n\n\n\n\n\n\n Adding images to your namespace \n\n[Adding images to your namespace](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_images_registry_images_)\n\n\n\n* [Pulling images from another registry](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_images_registry_images_pulling_reg)", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-sitemap"}, {"document_id": "ibmcld_01484-6774-8584", "score": 15.578452, "text": "\n* To view and analyze namespaces, you must have the Reader or Manager role in the IBM Cloud Container Registry service, see [Access roles for using IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\nFor more information about user roles, [Defining IAM access policies](https://cloud.ibm.com/docs/Registry?topic=Registry-useruser).\n\n\n\n\n\n\n\n Setting up a namespace \n\nYou must create a namespace to store your Docker images in IBM Cloud Container Registry.\n\nBefore you begin, complete the following tasks:\n\n\n\n* [Install the IBM Cloud CLI and the container-registry CLI plug-in](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgs_registry_cli_install).\n* [Plan how to use and name your registry namespaces](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_setup_cli_namespace&interface=uiregistry_setup_cli_namespace_plan).\n\n\n\nTo create a namespace, see [Set up a namespace](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgs_registry_namespace_add). Namespaces are created in the resource group that you specify so that you can configure access to resources within the namespace at the resource group level. If you don't specify a resource group, and a resource group isn't targeted, the default resource group is used. For more information about resource groups, see [Managing resource groups](https://cloud.ibm.com/docs/account?topic=account-rgs).\n\nNamespaces that are assigned to a resource group show in the Resource list page of the IBM Cloud console.\n\nThe namespace must be unique across all IBM Cloud accounts in the same region. Namespaces must have 4 - 30 characters, and contain lowercase letters, numbers, hyphens (-), and underscores (_) only. Namespaces must start and end with a letter or number.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_setup_cli_namespace&interface=ui"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10407-1492-3206", "score": 23.864126, "text": "\nContainer-native virtualization The Red Hat OpenShift [container-native virtualization add-on](https://docs.openshift.com/container-platform/4.11/virt/about-virt.html) to run VM workloads alongside container workloads is not supported by IBM. If you choose to install the add-on yourself, you must use bare metal machines, not virtual machines. You are responsible for resolving any issues and impact to your workloads from using container-native virtualization. \n Calico network plug-in Changing the Calico plug-in, components, or default Calico settings is not supported. For example, don't deploy a new Calico plug-in version, or modify the daemon sets or deployments for the Calico components, default IPPool resources, or Calico nodes. Instead, you can follow the documentation to [create a Calico NetworkPolicy or GlobalNetworkPolicy](https://cloud.ibm.com/docs/openshift?topic=openshift-network_policies), to [change the Calico MTU](https://cloud.ibm.com/docs/openshift?topic=openshift-kernelcalico-mtu), or to [disable the port map plug-in for the Calico CNI](https://cloud.ibm.com/docs/openshift?topic=openshift-kernelcalico-portmap). \n Cluster quota You can't exceed 100 clusters per region and per [infrastructure provider](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providers). If you need more of the resource, [contact IBM Support](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar). In the support case, include the new quota limit for the region and infrastructure provider that you want. \n IAM access groups You can't scope IBM Cloud IAM service access roles to an IAM access group because the roles are not synced to the RBAC roles within the cluster.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_limitations"}, {"document_id": "ibmcld_10154-17039-18368", "score": 23.84329, "text": "\nContainer-native virtualization You can set up [container-native virtualization add-on](https://docs.openshift.com/container-platform/4.11/virt/about-virt.html) on bare metal machines, but not on virtual machines. Container-native virtualization is not supported by IBM. If you experience issues, you are responsible for resolving the issues and any impact to your workloads. \n Serverless workloads You can set up [Red Hat OpenShift Serverless](https://www.redhat.com/en/topics/microservices/why-choose-openshift-serverless). You can also set up Red Hat OpenShift Serverless. \n Service mesh You can set up the [Red Hat OpenShift Service Mesh](https://docs.openshift.com/container-platform/4.11/service_mesh/v1x/installing-ossm.html). You can also set up the Red Hat OpenShift Service Mesh, but you must [apply a network policy](https://gist.githubusercontent.com/kitch/39c504a2ed9e381c2aadea436d5b52e4/raw/d8efa69f41d41425b16bb363a881a98d40d3708c/mesh-policy.yaml) for the service mesh ingress to work. \n API and CLI tools OpenShift Container Platform clusters are set up with access to Kubernetes and Red Hat OpenShift API resources. You can also install command line tools such as oc and odo. Red Hat OpenShift on IBM Cloud clusters come with the same capabilities to use the Kubernetes and Red Hat OpenShift API and CLI tools.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov"}, {"document_id": "ibmcld_11282-0-1290", "score": 23.039835, "text": "\n\n\n\n\n\n\n  Cloud native development and application modernization by using Red Hat OpenShift on Power Systems Virtual Server \n\nCloud-native applications are the applications that are born in the cloud, which means that the applications use microservice-based architecture, containers, and a corresponding container orchestration platform. Red Hat\u00ae OpenShift\u00ae is enterprise Kubernetes platform enabling IT organizations to develop applications faster, deploy them reliably, and manage them efficiently.\n\nIn addition to developing new cloud-native applications, IT organizations are modernizing older, monolithic core business applications to support the faster delivery of new function to the business.\n\nFor information on application modernization on Power Systems, see [Field Guide to Application Modernization on IBM Power Systems](https://www.ibm.com/downloads/cas/D9POQ3YR).\n\nFor information on deploying Red Hat OpenShift on Power Systems Virtual Server and tutorials to explore the platform, see [Deploying Red Hat OpenShift Container Platform 4.x on IBM Power Systems Virtual Servers](https://developer.ibm.com/series/deploy-ocp-cloud-paks-power-virtual-server/?mhsrc=ibmsearch_a&mhq=%20Deploying%20Red%20Hat%20OpenShift%20Container%20Platform%20on%20Power%20Virtual%20Servers).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-app-modernization-using-RedHat-openshift"}, {"document_id": "ibmcld_14682-7-2113", "score": 23.02254, "text": "\nVMware vCenter Server and Red Hat OpenShift architecture overview \n\nThe IBM Cloud\u00ae for VMware Solutions offering includes fully automated, rapid deployments of VMware\u00ae vCenter Server\u00ae. This offering complements the on-premises infrastructure and allows existing and future workloads to run on IBM Cloud without conversion by using the same tools, skills, and processes that are used on-premises. For more information, see [Virtualization for extending virtualized private cloud](https://www.ibm.com/cloud/architecture/architectures/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud for VMware Solutions provides the capability to deploy a Red Hat OpenShift Cluster by using an automated deployment of the VMware Software Defined Data Center (SDDC) architecture. The Red Hat OpenShift Cluster on IBM Cloud components are deployed as virtual machines (VM) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThis reference architecture is for Red Hat OpenShift clusters deployed on a vCenter Server instance. It provides the foundation for customers who are starting their application modernization journey to the IBM Cloud.\n\n\n\n* vCenter Server is an offering from IBM Cloud for VMware Solutions and is a VMware-based platform that is automatically provisioned on IBM Cloud.\n* Red Hat OpenShift is an application platform for developing and managing containerized applications, which are deployed onto virtualized infrastructure platforms, such as VMware.\n\n\n\nZoom\n\n![IBM Cloud for VMware Solutions and Red Hat OpenShift](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/openshift-sddc.svg)\n\nFigure 1. IBM Cloud for VMware Solutions and OpenShift\n\n\n\n Application modernization on IBM Cloud \n\nApplication modernization is a term that describes the process of transitioning existing applications to use new approaches on the cloud. Customers today are seeking innovative, efficient approaches that help them make this transition based on business and application complexity.\n\nBusiness pressures demand faster time to market.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro"}, {"document_id": "ibmcld_14497-7-1724", "score": 22.763542, "text": "\nVMware Solutions and Red Hat OpenShift overview \n\nIBM Cloud\u00ae for VMware Solutions includes fully automated, rapid deployments of VMware vCenter Server\u00ae in the IBM Cloud. These offerings complement the on-premises infrastructure and allow existing and future workloads to run in the IBM Cloud without conversion by using the same tools, skills, and processes they use on-premises. For more information, see [Virtualization for extending virtualized private cloud](https://www.ibm.com/cloud/architecture/architectures/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae for VMware Solutions is a reference architecture and a manual build process to deploy a Red Hat OpenShift cluster 4.7 on to an existing vCenter Server instance. The components of Red Hat OpenShift cluster are deployed as virtual machines (VMs) and appliances by using NSX software-defined networking.\n\n\n\n* Reference architecture - [vCenter Server and Red Hat OpenShift architecture overview](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* Build process - The current document. The process and steps that are needed to install Red Hat OpenShift 4.7 on to an existing vCenter Server instance.\n\n\n\nZoom\n\n![VMware Solutions and Red Hat OpenShift](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"}, {"document_id": "ibmcld_10495-9135-10569", "score": 22.50485, "text": "\n(https://cognitiveclass.ai/courses/docker-essentials)\n\n\n\n\n\n What is Red Hat OpenShift? \n\nRed Hat OpenShift is a Kubernetes container platform that provides a trusted environment to run enterprise workloads. It extends the Kubernetes platform with built-in software to enhance app lifecycle development, operations, and security. With Red Hat OpenShift, you can consistently deploy your workloads across hybrid cloud providers and environments. For more information about the differences between the community Kubernetes and Red Hat OpenShift cluster offerings, see the [comparison table](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\n\n\n\n\n What compute host infrastructure does the service offer? \n\nYou can create clusters on Classic or IBM Cloud\u00ae Virtual Private Cloud infrastructure. You can also bring your own hosts by using Satellite.\n\nFor more information, see [Supported infrastructure providers](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providers).\n\n\n\n\n\n Related resources \n\nReview how you can learn about Kubernetes concepts and the terminology.\n\n\n\n* Familiarize yourself with the product by completing the [Creating clusters tutorial](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_tutorial).\n* Learn how Kubernetes and Red Hat OpenShift on IBM Cloud work together by completing this [course](https://cognitiveclass.ai/courses/kubernetes-course).", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-roks-overview"}, {"document_id": "ibmcld_10489-7-1763", "score": 22.054657, "text": "\nSetting up the Red Hat Marketplace \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite\n\nWith [Red Hat\u00ae Marketplace](https://marketplace.redhat.com/en-us), you can deploy certified Red Hat software from an operator-based catalog to your OpenShift Container Platform clusters, including Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae.\n\nRequired permissions:\n\n\n\n* The IAM Operator platform access role for the cluster in Kubernetes Service.\n* The IAM Manager service access role in all namespaces (cluster-admin RBAC) for the cluster in Kubernetes Service.\n\n\n\nRed Hat Marketplace is available for clusters that run Red Hat OpenShift version 4 only.\n\nBefore you begin:\n\n\n\n* Register for a [Red Hat Marketplace account](https://marketplace.redhat.com/en-us/registration/redhat-marketplace).\n* [Access your Red Hat OpenShift cluster](https://cloud.ibm.com/docs/openshift?topic=openshift-access_cluster).\n* Make sure that the Operator Lifecycle Manager (OLM) pods in the openshift-operator-lifecycle-manager project and marketplace pods in the openshift-marketplace project are ready and running. You might have to restart a pod to return the pod to a healthy state.\n\noc get pods -n openshift-operator-lifecycle-manager\n\noc get pods -n openshift-marketplace\n\n\n\nTo set up your cluster with Red Hat Marketplace:\n\n\n\n1. Follow the [Red Hat Marketplace instructions](https://marketplace.redhat.com/en-us/workspace/clusters/add/register) to create a namespace, operator, and global pull secret for the Red Hat Marketplace.\n2. Verify that the global pull secret for the cluster is updated with the registry.marketplace.redhat.com secret.\n\noc get secret pull-secret -n openshift-config --output=\"jsonpath={.data..dockerconfigjson}\" | base64 --decode | grep \"marketplace\" -A4\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-rh-marketplace"}, {"document_id": "ibmcld_10154-15474-17414", "score": 21.986776, "text": "\nRed Hat OpenShift on IBM Cloud clusters come with all the same configurable project and build components as OCP clusters. You can also choose to integrate your cluster with IBM Cloud services like [Continuous Delivery](https://cloud.ibm.com/docs/openshift?topic=openshift-cicd). \n Cluster health You can also set up logging, monitoring, and metering tools by installing and configuring various operators. These solutions are cluster-specific and not highly available unless you back them up. Your clusters feature one-click integrations with IBM Log Analysis and IBM Cloud Monitoring for enterprise-grade, persistent monitoring and logging solutions across clusters. You can also install the logging and monitoring operators as with standard OCP, but you might have to adjust the configuration settings. For more information, see [Logging and monitoring cluster health](https://cloud.ibm.com/docs/openshift?topic=openshift-health). \n Migrating clusters You can use the cluster migrator operator to migrate clusters from one major version to another. Migration requires separate clusters; you can't update a cluster from one major version to another. Various open source tools might be used, but are not officially supported. As with standard OpenShift Container Platform, you can't update a cluster from one major version to another. If you use a third-party open source tool such as the [cluster migrator operator](https://github.com/migtools/mig-operator), the tool is not supported by IBM and might have limitations such as the migration UI being unavailable. \n Container-native virtualization You can set up [container-native virtualization add-on](https://docs.openshift.com/container-platform/4.11/virt/about-virt.html) on bare metal machines, but not on virtual machines. Container-native virtualization is not supported by IBM. If you experience issues, you are responsible for resolving the issues and any impact to your workloads.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov"}, {"document_id": "ibmcld_14492-7-1792", "score": 21.889843, "text": "\nRed Hat OpenShift for VMware overview \n\nThe Red Hat\u00ae OpenShift\u00ae for VMware\u00ae service deploys an Red Hat OpenShift cluster by using an automated deployment of the VMware SDDC (Software Defined Data Center) architecture. The Red Hat OpenShift components are deployed as virtual machines (VMs) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThe Red Hat OpenShift version available for deployment is 4.12.\n\nReview the following information before you install the Red Hat OpenShift for VMware service:\n\n\n\n* Red Hat OpenShift for VMware cannot be installed on multiple VMware vCenter Server\u00ae instances in a multisite configuration. Before you install Red Hat OpenShift for VMware on an instance, verify that the service is not installed on any other instances in the multisite configuration.\n* Red Hat OpenShift for VMware is supported for vCenter Server instances with VMware vSphere\u00ae 7.0 and VMware NSX-T\u2122 3.1 or later.\n* Red Hat OpenShift for VMware is not supported for new deployments or for ordering post-deployment for vCenter Server with NSX-V instances with vSphere 6.7.\n\n\n\nExisting installations of Red Hat OpenShift for VMware can be used or deleted for vSphere 6.7 instances.\n\nIBM Cloud\u00ae for VMware Solutions offers promotions for some services. Promotional pricing offers a number of months without charge for a service licenses, if the service has license charges. For more information, see [Promotions for VMware Solutions services](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vc_addingservicesvc_addingservices-service-promotions).\n\nThe cluster consists of the following components:\n\n\n\n* Three primary nodes\n* Three worker nodes, all running Red Hat\u00ae CoreOS\n* Two VMware NSX\u00ae VMs\n* A Red Hat CoreOS template\n* A bastion VM running CoreOS", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-ocp_overview"}, {"document_id": "ibmcld_11950-7-2002", "score": 21.71947, "text": "\nSetting up virtualization on a Satellite location \n\nYou can set up your Bare Metal Servers to use Red Hat OpenShift virtualization in your Satellite location. By using virtualization, you can provision Windows or other virtual machines on your Bare Metal Servers in a managed Red Hat OpenShift space.\n\nSupported host operating systems\n: Red Hat CoreOS (RHCOS)\n\n\n\n Prerequisites \n\n\n\n* Create a RHCOS-enabled location. To check whether your location is RHCOS-enabled, see [Is my location enabled for Red Hat CoreOS?](https://cloud.ibm.com/docs/satellite?topic=satellite-locationsverify-coreos-location). If your location is not enabled, [create a new one with RHCOS](https://cloud.ibm.com/docs/satellite?topic=satellite-locations).\n* Attach hosts to your location and set up your [location control plane](https://cloud.ibm.com/docs/satellite?topic=satellite-setup-control-plane).\n* Find and record your bare metal host name.\n* Find your bare metal server network information. Record the CIDR and gateway information for the public and private interfaces for your system.\n* If you want to use IBM Cloud Object Storage to store your ignition file, create or identify a bucket.\n* Create or identify a cluster within the Satellite location that runs a supported operating system; for example, this tutorial uses a Red Hat OpenShift cluster that is running 4.11.\n* If you want to use OpenShift Data Foundation as your storage solution, add 2 storage disks to each of your Bare Metal Servers when you provision them.\n\n\n\n\n\n\n\n Bare Metal Server requirements for Satellite \n\nTo set up virtualization, your Bare Metal Server must meet the following requirements.\n\n\n\n* Must support virtualization technology.\n\n\n\n* For Intel CPUs, support for virtualization is referred to as Intel VT or VT-x.\n* For AMD CPUs, support for virtualization is referred to as AMD Virtualization or AMD-V.\n\n\n\n* Must have a minimum of minimum of 8 cores and 32 GB RAM, plus any additional cores that you need for your vCPU overhead.", "title": "", "source": "https://cloud.ibm.com/docs/satellite?topic=satellite-virtualization-location"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10154-7-1896", "score": 28.066841, "text": "\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https://www.ibm.com/products/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov"}, {"document_id": "ibmcld_10495-9135-10569", "score": 27.655756, "text": "\n(https://cognitiveclass.ai/courses/docker-essentials)\n\n\n\n\n\n What is Red Hat OpenShift? \n\nRed Hat OpenShift is a Kubernetes container platform that provides a trusted environment to run enterprise workloads. It extends the Kubernetes platform with built-in software to enhance app lifecycle development, operations, and security. With Red Hat OpenShift, you can consistently deploy your workloads across hybrid cloud providers and environments. For more information about the differences between the community Kubernetes and Red Hat OpenShift cluster offerings, see the [comparison table](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\n\n\n\n\n What compute host infrastructure does the service offer? \n\nYou can create clusters on Classic or IBM Cloud\u00ae Virtual Private Cloud infrastructure. You can also bring your own hosts by using Satellite.\n\nFor more information, see [Supported infrastructure providers](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providers).\n\n\n\n\n\n Related resources \n\nReview how you can learn about Kubernetes concepts and the terminology.\n\n\n\n* Familiarize yourself with the product by completing the [Creating clusters tutorial](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_tutorial).\n* Learn how Kubernetes and Red Hat OpenShift on IBM Cloud work together by completing this [course](https://cognitiveclass.ai/courses/kubernetes-course).", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-roks-overview"}, {"document_id": "ibmcld_10167-8650-10995", "score": 27.508123, "text": "\nInstead, their work's isolated in pockets across the globe due to regional compliance regulations and centralized databases.\n\nRed Hat OpenShift on IBM Cloud delivers secure compute that can host sensitive and data processing on an open platform. That global platform is hosted in near-by regions. So it's tied to local regulations that inspire patients\u2019 and researchers\u2019 confidence that their data is both protected locally and makes a difference in better health outcomes.\n\n\n\n Context \n\nSecurely hosting and sharing disease data for Research Nonprofit\n\n\n\n* Disparate groups of researchers from various institutions don\u2019t have a unified way to share data, slowing down collaboration.\n* The security concern adds to the collaboration burden that causes even less shared research.\n* Developers and Researchers are spread across the globe and across organizational boundaries, which make PaaS and SaaS the best option for each user group.\n* Regional differences in health regulations require some data and data processing to remain within that region.\n\n\n\n\n\n\n\n Solution \n\nSecurely hosting and sharing disease data for Research Nonprofit.\n\nThe research nonprofit wants to aggregate cancer research data across the globe. So they create a division that is dedicated to solutions for their researchers.\n\n\n\n* INGEST - Apps to ingest research data. Researchers today use spreadsheets, documents, commercial products, and proprietary or home-grown databases to record research results. This situation is unlikely to change with the nonprofit's attempt to centralize data analysis.\n* ANONYMIZE - Apps to anonymize the data. SPI must be removed to comply with regional health regulations.\n* ANALYZE - Apps to analyze the data. The basic pattern is to store the data in a regular format and then to query and process it by using AI and machine learning (ML) technology, simple regressions, and so forth.\n\n\n\nResearchers need to affiliate with a regional cluster, and apps ingest, transform, and anonymize the data.\n\n\n\n1. Syncing the anonymized data across regional clusters or shipping them to a centralized data store\n2. Processing the data, by using ML like PyTorch on bare metal worker nodes that provide GPUs\n\n\n\nINGEST\n: IBM Cloudant is used at each regional cluster that stores researchers\u2019 rich data documents and can be queried and processed as needed.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_health"}, {"document_id": "ibmcld_10214-1438-3413", "score": 26.832012, "text": "\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovbenefits).\n\n\n\n\n\n What container platforms are available for my cluster? \n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https://cloud.ibm.com/docs/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform. If you want to use multiple container platforms, create a separate cluster for each.\n\nFor more information, see [Comparison between Red Hat OpenShift and community Kubernetes clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\nKubernetes\n: [Kubernetes](https://kubernetes.io/) is a production-grade, open source container orchestration platform that you can use to automate, scale, and manage your containerized apps that run on an Ubuntu operating system.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-faqs"}, {"document_id": "ibmcld_04644-7-1968", "score": 26.712845, "text": "\nRed Hat OpenShift on IBM Cloud \n\nIBM\u00ae Cloud Foundry is deprecated and no longer supported as of 1 June 2023. For more information, see the [deprecation details](https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-deprecationdep_details).\n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae is a managed offering to create your own OpenShift cluster of compute hosts to deploy and manage containerized apps on IBM Cloud. The managed OpenShift offering combines the built-in industry leading OpenShift capabilities including RHEL-based infrastructure, enterprise hardened Kubernetes, validated integrations, integrated container registry, developer workflow tools, and easy access to services through service brokers with the operational cluster lifecycle excellence from IBM Cloud SRE.\n\nAs a managed offering, IBM deploys the compute, networks, and storage based on the customer's requirements through the UI, CLI, API, or automation through IBM Cloud Schematics. Additionally, IBM provides the tooling for updates including OS patches, vulnerability remediation, and updates to any component in the stack with the customer determining when they should upgrade. Red Hat OpenShift on IBM Cloud supports HA masters, multi-zone clusters, compute isolation choices including bare metal worker nodes, customer managed keys using IBM Key Protect or industry leading HyperProtect Crypto Services using FIPS 140-2 Level 4 encryption, and secure access to IBM Cloud services to enhance your application's capabilities including Watson, IoT, and Analytics.\n\n\n\n Resources \n\nThe following resources are available to help you learn more about the OpenShift on IBM Cloud:\n\n\n\n* [IBM information page](https://www.ibm.com/cloud/openshift)\n* [Overview](https://cloud.ibm.com/docs/openshift?topic=openshift-roks-overview)\n* [IBM Cloud service creation](https://cloud.ibm.com/kubernetes/overview?platformType=openshift)\n* [Documentation](https://cloud.ibm.com/docs/openshift)", "title": "", "source": "https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-deprecation_openshift"}, {"document_id": "ibmcld_10166-1787-3965", "score": 26.490576, "text": "\nTo bust bureaucracy and transform government\u2019s relationship with its constituency, they turned to open standards to build a platform for co-creation.\n\n\n\n* OPEN DATA \u2013 data storage where citizens, government agencies, and businesses access, share, and enhance data freely\n* OPEN APIs \u2013 a development platform where APIs are contributed by and reused with all community partners\n* OPEN INNOVATION \u2013 a set of cloud services that allow developers to use plug-in innovation instead of manually coding it\n\n\n\nTo start, the government uses IBM Cloud Object Storage to store its public data in the cloud. This storage is free to use and reuse, shareable by anyone, and subject only to attribution and share alike. Sensitive data can be sanitized before it\u2019s pushed to the cloud. Besides that, access controls are set up so that the cloud caps new data storage, where the community can demonstrate POCs of enhanced existing free data.\n\nThe government\u2019s next step for the public-private partnerships was to establish an API economy that is hosted in IBM\u00ae API Connect. There, community and enterprise Developers make data easily accessible in API form. Their goals are to have publicly available REST APIs, to enable interoperability, and to accelerate app integration. They use IBM Secure Gateway to connect back to private data sources on-premises.\n\nFinally, apps based on those shared APIs are hosted in Red Hat OpenShift on IBM Cloud, where it\u2019s easy to spin up clusters. Then, Developers across the community, private sector, and the government can co-create apps easily. In short, Developers need to focus on coding instead of managing the infrastructure. Thus, they chose Red Hat OpenShift on IBM Cloud because IBM simplifies infrastructure management.\n\n\n\n* Managing Kubernetes master, IaaS, and operational components, such as Ingress and storage\n* Monitoring health and recovery for worker nodes\n* Providing global compute, so Developers don\u2019t have to stand up infrastructure in worldwide regions where they need workloads and data to be located\n\n\n\nMoving compute workloads into the IBM Cloud isn't enough though. The government needs to go through a method transformation as well.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_gov"}, {"document_id": "ibmcld_10392-6380-7520", "score": 26.405796, "text": "\n: Red Hat OpenShift on IBM Cloud clusters are connected to [remote health monitoring](https://docs.openshift.com/container-platform/4.13/support/remote_health_monitoring/about-remote-health-monitoring.html) by default. This means clusters report health and usage data to Red Hat unless you opt out. With connected clusters, IBM Cloud is better positioned to support customers when there are issues specific to Red Hat which impact them. Additionally, remote health reporting gives Red Hat insights into how clusters are impacted by product upgrades. If you do not want to send cluster data to Red Hat, you must opt out. For more information, see [Understanding remote health monitoring](https://cloud.ibm.com/docs/openshift?topic=openshift-remote-health-monitoring-opt-out).\n\n\n\n\n\n 9 June 2023 \n\nNew! OpenShift Data Foundation add-on versions 4.12.5, 4.11.11, 4.10.26, and 4.9.28.\n: For more information, see the [change log](https://cloud.ibm.com/docs/openshift?topic=openshift-odf_addon_changelog).\n\n\n\n\n\n 5 June 2023 \n\nWorker node fix packs 4.9.59_1592_openshift, 4.10.60_1571_openshift, 4.11.42_1558_openshift, and 4.12.19_1546_openshift.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-relnotes"}, {"document_id": "ibmcld_11282-0-1290", "score": 26.39116, "text": "\n\n\n\n\n\n\n  Cloud native development and application modernization by using Red Hat OpenShift on Power Systems Virtual Server \n\nCloud-native applications are the applications that are born in the cloud, which means that the applications use microservice-based architecture, containers, and a corresponding container orchestration platform. Red Hat\u00ae OpenShift\u00ae is enterprise Kubernetes platform enabling IT organizations to develop applications faster, deploy them reliably, and manage them efficiently.\n\nIn addition to developing new cloud-native applications, IT organizations are modernizing older, monolithic core business applications to support the faster delivery of new function to the business.\n\nFor information on application modernization on Power Systems, see [Field Guide to Application Modernization on IBM Power Systems](https://www.ibm.com/downloads/cas/D9POQ3YR).\n\nFor information on deploying Red Hat OpenShift on Power Systems Virtual Server and tutorials to explore the platform, see [Deploying Red Hat OpenShift Container Platform 4.x on IBM Power Systems Virtual Servers](https://developer.ibm.com/series/deploy-ocp-cloud-paks-power-virtual-server/?mhsrc=ibmsearch_a&mhq=%20Deploying%20Red%20Hat%20OpenShift%20Container%20Platform%20on%20Power%20Virtual%20Servers).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-app-modernization-using-RedHat-openshift"}, {"document_id": "ibmcld_14683-7-2001", "score": 26.259655, "text": "\nRed Hat OpenShift architecture \n\nThe IBM Cloud\u00ae for VMware Solutions offerings provide automation to deploy VMware\u00ae technology components in IBM Cloud data centers across the globe. The architecture consists of a single cloud region. It supports the ability to extend into more cloud regions that are located in another geography or into another IBM Cloud pod within the same data center.\n\nZoom\n\n![Red Hat OpenShift architecture](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/openshift-components.svg)\n\nFigure 1. Red Hat OpenShift architecture\n\n\n\n Bastion hosts \n\nThe Management host is a Red Hat\u00ae Enterprise Linux\u00ae 8.0 virtual machine (VM). This VM hosts services to install and configure the Red Hat\u00ae OpenShift\u00ae instance and provides utilities to manage the Red Hat OpenShift environment. This host is normally deployed in the VXLAN Subnet.\n\n\n\n\n\n Bootstrap hosts \n\nThe bootstrap node is a Red Hat Enterprise Linux CoreOS (RHCOS), a new container-oriented operating system designed for running containers. The node is a temporary node that is used to start the installation.\n\n\n\n\n\n Control Plane hosts \n\nThe control plane hosts are Red Hat Enterprise Linux CoreOS (RHCOS), a new container-oriented operating system designed for running containers. The control plane nodes are known as the control plane, where Kubernetes services such as API server, etcd, and controller manager are defined. An NSX\u00ae load balancer is configured to spread load across these VMs for ports 6443 and 22623, exposing the api and api-int functions.\n\n\n\n\n\n Worker hosts \n\nThe worker hosts are Red Hat Enterprise Linux CoreOS (RHCOS), a new container-oriented operating system designed for running containers. The worker nodes are known as the data-plane, where the actual Kubernetes workloads are deployed. An NSX load balancer is configured to spread load across these VMs for ports 80 and 443, exposing the wildcard DNS and *.apps.\n\n\n\n\n\n Common services", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-redhat-arch"}, {"document_id": "ibmcld_10404-16822-17831", "score": 26.126501, "text": "\nRed Hat OpenShift on IBM Cloud. 4.8.55 4.8.57 For more information, see the [change log](https://docs.openshift.com/container-platform/4.8/release_notes/ocp-4-8-release-notes.htmlocp-4-8-57). \n HAProxy 508bf6 8d6ea6 [CVE-2022-42010](https://nvd.nist.gov/vuln/detail/CVE-2022-42010), [CVE-2022-42011](https://nvd.nist.gov/vuln/detail/CVE-2022-42011), [CVE-2022-42012](https://nvd.nist.gov/vuln/detail/CVE-2022-42012), [CVE-2022-40303](https://nvd.nist.gov/vuln/detail/CVE-2022-40303), [CVE-2022-40304](https://nvd.nist.gov/vuln/detail/CVE-2022-40304), [CVE-2022-3821](https://nvd.nist.gov/vuln/detail/CVE-2022-3821), [CVE-2022-35737](https://nvd.nist.gov/vuln/detail/CVE-2022-35737), [CVE-2022-43680](https://nvd.nist.gov/vuln/detail/CVE-2022-43680), [CVE-2021-46848](https://nvd.nist.gov/vuln/detail/CVE-2021-46848). \n\n\n\n\n\n\n\n Change log for worker node fix pack 4.8.55_1586_openshift, released 16 January 2023 \n\nThe following table shows the changes that are in the worker node fix pack 4.8.55_1586_openshift.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_changelog_48"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10154-7-1896", "score": 30.851904, "text": "\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https://www.ibm.com/products/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov"}, {"document_id": "ibmcld_10166-7-2382", "score": 29.362728, "text": "\nGovernment use cases for IBM Cloud \n\nThese use cases highlight how workloads on Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae benefit from the public cloud. These workloads are isolated in global regions for data sovereignty, use Watson machine learning instead of net-new code, and connect to on-premises databases.\n\n\n\n Regional government improves collaboration and velocity with community Developers who combine public-private data \n\nAn Open-Government Data Program Executive needs to share public data with the community and private sector, but the data is locked in an on-premises monolithic system.\n\nWith Red Hat OpenShift on IBM Cloud, the Exec delivers the value of combined public-private data. Likewise, the service provides the public cloud platform to refactor and expose microservices from monolithic on-premises apps. Also, the public cloud allows government and the public partnerships to use external cloud services and collaboration-friendly open-source tools.\n\n\n\n Context \n\n\n\n* An \u201copen government\u201d model is the future, but this regional government agency can't make the leap with their on-premises systems.\n* They want to support innovation and foster co-development between private sector, citizens, and public agencies.\n* Disparate groups of Developers from the government and private organizations don\u2019t have a unified open-source platform where they can share APIs and data easily.\n* Government data is locked in on-premises systems with no easy public access.\n\n\n\n\n\n\n\n Solution \n\nAn open-government transformation must be built on a foundation that provides performance, resilience, business continuity, and security. As innovation and co-development move ahead, agencies and citizens depend on software, services, and infrastructure companies to \u201cprotect and serve.\u201d\n\nTo bust bureaucracy and transform government\u2019s relationship with its constituency, they turned to open standards to build a platform for co-creation.\n\n\n\n* OPEN DATA \u2013 data storage where citizens, government agencies, and businesses access, share, and enhance data freely\n* OPEN APIs \u2013 a development platform where APIs are contributed by and reused with all community partners\n* OPEN INNOVATION \u2013 a set of cloud services that allow developers to use plug-in innovation instead of manually coding it\n\n\n\nTo start, the government uses IBM Cloud Object Storage to store its public data in the cloud.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_gov"}, {"document_id": "ibmcld_10167-8650-10995", "score": 29.017334, "text": "\nInstead, their work's isolated in pockets across the globe due to regional compliance regulations and centralized databases.\n\nRed Hat OpenShift on IBM Cloud delivers secure compute that can host sensitive and data processing on an open platform. That global platform is hosted in near-by regions. So it's tied to local regulations that inspire patients\u2019 and researchers\u2019 confidence that their data is both protected locally and makes a difference in better health outcomes.\n\n\n\n Context \n\nSecurely hosting and sharing disease data for Research Nonprofit\n\n\n\n* Disparate groups of researchers from various institutions don\u2019t have a unified way to share data, slowing down collaboration.\n* The security concern adds to the collaboration burden that causes even less shared research.\n* Developers and Researchers are spread across the globe and across organizational boundaries, which make PaaS and SaaS the best option for each user group.\n* Regional differences in health regulations require some data and data processing to remain within that region.\n\n\n\n\n\n\n\n Solution \n\nSecurely hosting and sharing disease data for Research Nonprofit.\n\nThe research nonprofit wants to aggregate cancer research data across the globe. So they create a division that is dedicated to solutions for their researchers.\n\n\n\n* INGEST - Apps to ingest research data. Researchers today use spreadsheets, documents, commercial products, and proprietary or home-grown databases to record research results. This situation is unlikely to change with the nonprofit's attempt to centralize data analysis.\n* ANONYMIZE - Apps to anonymize the data. SPI must be removed to comply with regional health regulations.\n* ANALYZE - Apps to analyze the data. The basic pattern is to store the data in a regular format and then to query and process it by using AI and machine learning (ML) technology, simple regressions, and so forth.\n\n\n\nResearchers need to affiliate with a regional cluster, and apps ingest, transform, and anonymize the data.\n\n\n\n1. Syncing the anonymized data across regional clusters or shipping them to a centralized data store\n2. Processing the data, by using ML like PyTorch on bare metal worker nodes that provide GPUs\n\n\n\nINGEST\n: IBM Cloudant is used at each regional cluster that stores researchers\u2019 rich data documents and can be queried and processed as needed.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_health"}, {"document_id": "ibmcld_10170-10609-12793", "score": 28.595621, "text": "\nThus, the annual rollout of benefits is a key aspect of fostering an employee-centered culture.\n\nThey need a solution that helps the Developers and their users.\n\n\n\n* FRONT-END TO EXISTING BENEFITS: insurance, educational offerings, wellness, and more\n* REGION-SPECIFIC FEATURES: each country has unique HR policies so that the overall site might look similar but show region-specific benefits\n* DEVELOPER-FRIENDLY TOOLS that accelerate rollout of features and bug fixes\n* CHATBOT to provide authentic conversations about benefits and resolve users requests and questions efficiently.\n\n\n\nTechnical solution:\n\n\n\n* Red Hat OpenShift on IBM Cloud\n* IBM Cloud\u00ae Continuous Delivery\n* IBM Logging and Monitoring\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae\n* IBM Cloud App ID\n\n\n\nAccelerated development is a key win for the HR Exec. The team gets started by containerizing their apps and putting them in the cloud. With the use of modern containers, Developers can experiment easily with Node.js SDK and push changes to Development and Test systems, which are scaled out on separate clusters. Those pushes were automated with open toolchains and IBM Cloud\u00ae Continuous Delivery. No longer were updates to the HR site languishing in slow, error-prone build processes. They can deliver incremental updates to their site, daily or even more frequently. Moreover, logging and monitoring for the HR site is rapidly integrated, especially for how the site pulls personalized data from back-end benefit systems. Developers don\u2019t waste time building complex logging systems, just to be able to troubleshoot live systems. Developers don't need to become experts in cloud security, they can enforce policy driven authentication easily by using IBM Cloud App ID.\n\nWith Red Hat OpenShift on IBM Cloud, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the HR site, they could easily design Kubernetes clusters to fit their CPU, RAM, and storage needs. Another factor for less personnel costs is that IBM manages Kubernetes, so the Developers can focus on delivering better employee experience for benefits enrollment.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_transport"}, {"document_id": "ibmcld_10166-5191-7552", "score": 28.213127, "text": "\n* Create clusters for public-private apps, which are driven by the APIs.\n* Structure apps into a set of cooperative microservices that run within Red Hat OpenShift on IBM Cloud, which is based on functional areas of apps and their dependencies.\n* Deploy the apps to containers that run in Red Hat OpenShift on IBM Cloud. Built-in HA tools in Red Hat OpenShift on IBM Cloud balance the workloads, including self-healing and load balancing.\n* Provide standardized DevOps dashboards through Kubernetes, open-source tools familiar to all types of Developers.\n\n\n\n\n\n\n\n Step 3: Innovate with IBM Garage and cloud services \n\n\n\n* Adopt the agile and iterative development practices from the IBM Garage Method to enable frequent releases of features, patches, and fixes without downtime.\n* Whether developers are in the public or private sector, IBM Cloud\u00ae Continuous Delivery helps them to quickly provision an integrated toolchain, by using customizable, shareable templates.\n* After Developers build and test the apps in their Dev and Test clusters, they use the IBM Cloud\u00ae Continuous Delivery toolchains to deploy apps into production clusters.\n* With Watson AI, machine learning, and deep learning tools available from the IBM Cloud catalog, Developers focus on domain problems. Instead of custom unique ML code, ML logic is snapped into apps with service bindings.\n\n\n\n\n\n\n\n\n\n Results \n\n\n\n* Normally slow public-private partnerships now quickly spin up apps in weeks instead of months. These development partnerships now deliver features and bug fixes up to 10 times per week.\n* Development is accelerated when all participants use well-known open-source tools, such as Kubernetes. Long learning curves are no longer a blocker.\n* Transparency in activities, information, and plans is provided to citizens and private sector. And, citizens are integrated into government processes, services, and support.\n* Public-private partnerships conquer Herculean tasks, such as Zika virus tracking, smart electricity distribution, analysis of crime statistics, and university \"new collar\" education.\n\n\n\n\n\n\n\n\n\n Large public port secures exchange of port data and shipping manifests that connect public and private organizations \n\nIT Execs for a private shipping company and the government-operated port need to connect, provide visibility, and securely exchange port information.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_gov"}, {"document_id": "ibmcld_10168-7-1603", "score": 28.115662, "text": "\nOverview of use cases \n\nVarious use cases show the strengths of Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae and IBM Cloud services when used together. These stories highlight several industries as well as types of workloads. Even though each use case is presented through the lens of a particular industry, these workloads are typical across various industries. You see workload themes, such as one of the following areas.\n\n\n\n* AI and machine learning\n* Data and storage\n* DevOps\n* Identity management\n\n\n\n\n\nTable 1. Use cases\n\n Industry Use case \n\n Financial services <br><br> * [Trim IT costs and accelerate regulatory compliance](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_financeuc_mortgage)<br> * [Streamline developer productivity to deploy AI tools to partners 4 times faster](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_financeuc_payment_tech)<br><br><br> \n Government <br><br> * [Secure the exchange of data, connecting public and private organizations](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_govuc_port)<br> * [Improve collaboration velocity with community Developers, combining public-private data](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_govuc_data_mashup)<br><br><br> \n Healthcare <br><br> * [Migrate workloads from inefficient VMs to easily operated containers for patient systems](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_healthuc_migrate)<br> * [Securely host sensitive data while you grow research with partners](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_healthuc_research)<br><br><br>", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_intro"}, {"document_id": "ibmcld_10170-12206-14575", "score": 28.018148, "text": "\nDevelopers don't need to become experts in cloud security, they can enforce policy driven authentication easily by using IBM Cloud App ID.\n\nWith Red Hat OpenShift on IBM Cloud, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the HR site, they could easily design Kubernetes clusters to fit their CPU, RAM, and storage needs. Another factor for less personnel costs is that IBM manages Kubernetes, so the Developers can focus on delivering better employee experience for benefits enrollment.\n\nRed Hat OpenShift on IBM Cloud provides scalable compute resources and the associated DevOps dashboards to create, scale, and tear down apps and services as needed. Using industry-standard containers technology apps can be quickly developed and shared across multiple Development, Test, and Production environments. This setup provides the immediate benefit of scalability. Using Kubernetes rich set of deployment and runtime objects, the HR team can monitor and manage upgrades to apps reliably. They can also replicate and scale the apps, by using defined rules and the automated Kubernetes orchestrator.\n\n\n\n Step 1: Containers, microservices, and the Garage Method \n\n\n\n* Apps are built in a set of cooperative microservices that run in Red Hat OpenShift on IBM Cloud. The architecture represents the functional areas of the app with the most quality problems.\n* Deploy apps to container in Red Hat OpenShift on IBM Cloud, continuously scanned with IBM Vulnerability Advisor.\n* Provide standardized DevOps dashboards through Kubernetes.\n* Adopt the essential agile and iterative development practices within the IBM Garage Method to enable frequent releases of new functions, patches, and fixes without downtime.\n\n\n\n\n\n\n\n Step 2: Connections to existing benefits back-end \n\n\n\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae is used to create a secure tunnel to on-premises systems that host the benefits systems.\n* Combination of on-premises data and Red Hat OpenShift on IBM Cloud lets them access sensitive data while they adhere to regulations.\n* Chatbot conversations fed back into HR policies, allowing the benefits site to reflect which benefits were most and least popular, including targeted improvements to poorly performing initiatives.\n\n\n\n\n\n\n\n Step 3: Chatbot and personalization", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_transport"}, {"document_id": "ibmcld_10165-7426-9964", "score": 27.942846, "text": "\nA Development Exec has Developers that use on-premises application tools that slow down prototyping while they wait for hardware procurement.\n\nRed Hat OpenShift on IBM Cloud provides spin-up of compute by using open-source standard technology. After the company moved to Red Hat OpenShift on IBM Cloud, Developers have access to DevOps friendly tools, such as portable and easily shared containers.\n\nThen, Developers can experiment easily, pushing changes to Development and Test systems quickly with open toolchains. Their application development tools get a new face when they add on AI cloud services to apps with a click.\n\n\n\n Context \n\nStreamlining developer productivity and deploying AI tools to partners 4 times faster**\n\n\n\n* Disruption is rampant in the payment industry that also has dramatic growth both in the consumer and business-to-business segments. But updates to payment tools were slow.\n* Cognitive features are needed to target fraudulent transactions in new and faster ways.\n* With the growing numbers of partners and their transactions, the tool traffic increases, but their infrastructure budget needs to decrease, by maximizing efficiency of the resources.\n* Their technical debt is growing, not shrinking from an inability to release quality software to keep up with market demands.\n* Capital expense budgets are under tight control, and IT feels they don't have the budget or staff to create the testing and staging landscapes with their in-house systems.\n* Security is increasingly a primary concern, and this concern only adds to the delivery burden that all cause even more delays.\n\n\n\n\n\n\n\n Solution \n\nThe Development Exec is faced with many challenges in the dynamic payment industry. Regulations, consumer behaviors, fraud, competitors, and market infrastructures are all rapidly evolving. Fast-paced development is essential to being part of the future payment world.\n\nTheir business model is to provide payment tools to business partners, so they can help these financial institutions and other organizations deliver security-rich digital payment experiences.\n\nThey need a solution that helps the Developers and their business partners:\n\n\n\n* FRONT-END TO PAYMENT TOOLS: fee systems, payment tracking including cross-border, regulatory compliance, biometrics, remittance, and more\n* REGULATION-SPECIFIC FEATURES: each country has unique regulations so that the overall toolset might look similar but show country-specific benefits\n* DEVELOPER-FRIENDLY TOOLS that accelerate roll-out of features and bug fixes", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_finance"}, {"document_id": "ibmcld_10167-7-2256", "score": 27.589481, "text": "\nHealthcare use cases for IBM Cloud \n\nThese use cases highlight how workloads on Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae benefit from the public cloud. They have secure compute on isolated bare metal, easy spin-up of clusters for faster development, migration from virtual machines, and data sharing in cloud databases.\n\n\n\n Healthcare provider migrates workloads from inefficient VMs to Ops-friendly containers for reporting and patient systems \n\nAn IT Exec for a healthcare provider has business reporting and patient systems on-premises. Those systems go through slow enhancement cycles, which leads to stagnant patient service levels.\n\nTo improve patient service, the provider looked to Red Hat OpenShift on IBM Cloud and IBM Cloud\u00ae Continuous Delivery to reduce IT expenses and accelerate development, all on a secure platform. The provider\u2019s high-use SaaS systems, which held both patient record systems and business report apps, needed updates frequently. Yet, the provider's developers were overwhelmed with administering the hardware, network, and even the Kubernetes stack on their own. The provider also wanted to counteract increasing labor costs and a decreasing budget.\n\nThey started by containerizing their SaaS systems and putting them in the cloud. From that first step, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the SaaS apps, they easily designed Kubernetes clusters to fit their CPU, RAM, and storage needs. They used IBM Cloud Pak for Data to provide the familiar analytics tools from their on-prem environment. Another factor for decreased staff costs is that IBM manages Kubernetes, so the provider can focus on delivering better customer service.\n\nAccelerated development is a key win for the IT Exec. With the move to public cloud, Developers can experiment easily with Node.js SDK, pushing changes to Development and Test systems, scaled out on separate clusters. Those pushes were automated with open toolchains and IBM Cloud\u00ae Continuous Delivery. Updates to the SaaS system no longer languished in slow, error-prone build processes. The Developers can deliver incremental updates to their users, daily or even more frequently.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_health"}, {"document_id": "ibmcld_10165-11108-13549", "score": 27.565163, "text": "\nAccelerated development is a key win for the Exec. With the use of modern containers, Developers can experiment easily in the languages of their choice, pushing changes to Development and Test systems, scaled out on separate clusters. Those pushes were automated with open toolchains and IBM Cloud\u00ae Continuous Delivery. No longer were updates to the tools languishing in slow, error-prone build processes. They can deliver incremental updates to their tools, daily or even more frequently.\n\nAlso, logging and monitoring for the tools, especially where they used Watson AI, rapidly integrate into the system. Developers don\u2019t waste time building complex logging systems, just to be able to troubleshoot their live systems. A key factor for less staffing costs is that IBM manages Kubernetes, so the Developers can focus on better payment tools.\n\nSecurity first: With bare metal for Red Hat OpenShift on IBM Cloud, the sensitive payment tools now have familiar isolation but within the flexibility of public cloud. Scans for vulnerabilities are run continuously.\n\n\n\n Step 1: Lift and shift to secure compute \n\n\n\n* Migrate virtual machine images to container images that run in Red Hat OpenShift on IBM Cloud in the public IBM Cloud. Deploy IBM Cloud Pak for Applications, so that developers have their familiar application development tools on the cloud.\n* From that core, Vulnerability Advisor provides image, policy, container, and packaging vulnerability scanning.\n* Private data center / on-premises capital costs are greatly reduced and replaced with a utility computing model that scales based on workload demand.\n* Consistently enforce policy-driven authentication to your services and APIs with a simple Ingress annotation. With declarative security you can ensure user authentication and token validation by using App ID.\n\n\n\n\n\n\n\n Step 2: Operations and connections to existing payment systems back-end \n\n\n\n* Use IBM Secure Gateway to maintain secure connections to remaining on-premises tool systems.\n* Provide standardized DevOps dashboards and practices through Kubernetes.\n* After Developers build and test apps in Development and Test clusters, they use the IBM Cloud\u00ae Continuous Delivery toolchains to deploy apps into the Red Hat OpenShift on IBM Cloud clusters across the globe.\n* Built-in HA tools in Red Hat OpenShift on IBM Cloud balance the workload within each geographic region, including self-healing and load balancing.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_finance"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10154-17039-18368", "score": 23.646479, "text": "\nContainer-native virtualization You can set up [container-native virtualization add-on](https://docs.openshift.com/container-platform/4.11/virt/about-virt.html) on bare metal machines, but not on virtual machines. Container-native virtualization is not supported by IBM. If you experience issues, you are responsible for resolving the issues and any impact to your workloads. \n Serverless workloads You can set up [Red Hat OpenShift Serverless](https://www.redhat.com/en/topics/microservices/why-choose-openshift-serverless). You can also set up Red Hat OpenShift Serverless. \n Service mesh You can set up the [Red Hat OpenShift Service Mesh](https://docs.openshift.com/container-platform/4.11/service_mesh/v1x/installing-ossm.html). You can also set up the Red Hat OpenShift Service Mesh, but you must [apply a network policy](https://gist.githubusercontent.com/kitch/39c504a2ed9e381c2aadea436d5b52e4/raw/d8efa69f41d41425b16bb363a881a98d40d3708c/mesh-policy.yaml) for the service mesh ingress to work. \n API and CLI tools OpenShift Container Platform clusters are set up with access to Kubernetes and Red Hat OpenShift API resources. You can also install command line tools such as oc and odo. Red Hat OpenShift on IBM Cloud clusters come with the same capabilities to use the Kubernetes and Red Hat OpenShift API and CLI tools.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov"}, {"document_id": "ibmcld_10407-1492-3206", "score": 23.55406, "text": "\nContainer-native virtualization The Red Hat OpenShift [container-native virtualization add-on](https://docs.openshift.com/container-platform/4.11/virt/about-virt.html) to run VM workloads alongside container workloads is not supported by IBM. If you choose to install the add-on yourself, you must use bare metal machines, not virtual machines. You are responsible for resolving any issues and impact to your workloads from using container-native virtualization. \n Calico network plug-in Changing the Calico plug-in, components, or default Calico settings is not supported. For example, don't deploy a new Calico plug-in version, or modify the daemon sets or deployments for the Calico components, default IPPool resources, or Calico nodes. Instead, you can follow the documentation to [create a Calico NetworkPolicy or GlobalNetworkPolicy](https://cloud.ibm.com/docs/openshift?topic=openshift-network_policies), to [change the Calico MTU](https://cloud.ibm.com/docs/openshift?topic=openshift-kernelcalico-mtu), or to [disable the port map plug-in for the Calico CNI](https://cloud.ibm.com/docs/openshift?topic=openshift-kernelcalico-portmap). \n Cluster quota You can't exceed 100 clusters per region and per [infrastructure provider](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providers). If you need more of the resource, [contact IBM Support](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar). In the support case, include the new quota limit for the region and infrastructure provider that you want. \n IAM access groups You can't scope IBM Cloud IAM service access roles to an IAM access group because the roles are not synced to the RBAC roles within the cluster.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_limitations"}, {"document_id": "ibmcld_11282-0-1290", "score": 22.65718, "text": "\n\n\n\n\n\n\n  Cloud native development and application modernization by using Red Hat OpenShift on Power Systems Virtual Server \n\nCloud-native applications are the applications that are born in the cloud, which means that the applications use microservice-based architecture, containers, and a corresponding container orchestration platform. Red Hat\u00ae OpenShift\u00ae is enterprise Kubernetes platform enabling IT organizations to develop applications faster, deploy them reliably, and manage them efficiently.\n\nIn addition to developing new cloud-native applications, IT organizations are modernizing older, monolithic core business applications to support the faster delivery of new function to the business.\n\nFor information on application modernization on Power Systems, see [Field Guide to Application Modernization on IBM Power Systems](https://www.ibm.com/downloads/cas/D9POQ3YR).\n\nFor information on deploying Red Hat OpenShift on Power Systems Virtual Server and tutorials to explore the platform, see [Deploying Red Hat OpenShift Container Platform 4.x on IBM Power Systems Virtual Servers](https://developer.ibm.com/series/deploy-ocp-cloud-paks-power-virtual-server/?mhsrc=ibmsearch_a&mhq=%20Deploying%20Red%20Hat%20OpenShift%20Container%20Platform%20on%20Power%20Virtual%20Servers).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-app-modernization-using-RedHat-openshift"}, {"document_id": "ibmcld_14682-7-2113", "score": 22.58025, "text": "\nVMware vCenter Server and Red Hat OpenShift architecture overview \n\nThe IBM Cloud\u00ae for VMware Solutions offering includes fully automated, rapid deployments of VMware\u00ae vCenter Server\u00ae. This offering complements the on-premises infrastructure and allows existing and future workloads to run on IBM Cloud without conversion by using the same tools, skills, and processes that are used on-premises. For more information, see [Virtualization for extending virtualized private cloud](https://www.ibm.com/cloud/architecture/architectures/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud for VMware Solutions provides the capability to deploy a Red Hat OpenShift Cluster by using an automated deployment of the VMware Software Defined Data Center (SDDC) architecture. The Red Hat OpenShift Cluster on IBM Cloud components are deployed as virtual machines (VM) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThis reference architecture is for Red Hat OpenShift clusters deployed on a vCenter Server instance. It provides the foundation for customers who are starting their application modernization journey to the IBM Cloud.\n\n\n\n* vCenter Server is an offering from IBM Cloud for VMware Solutions and is a VMware-based platform that is automatically provisioned on IBM Cloud.\n* Red Hat OpenShift is an application platform for developing and managing containerized applications, which are deployed onto virtualized infrastructure platforms, such as VMware.\n\n\n\nZoom\n\n![IBM Cloud for VMware Solutions and Red Hat OpenShift](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/openshift-sddc.svg)\n\nFigure 1. IBM Cloud for VMware Solutions and OpenShift\n\n\n\n Application modernization on IBM Cloud \n\nApplication modernization is a term that describes the process of transitioning existing applications to use new approaches on the cloud. Customers today are seeking innovative, efficient approaches that help them make this transition based on business and application complexity.\n\nBusiness pressures demand faster time to market.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro"}, {"document_id": "ibmcld_14497-7-1724", "score": 22.422169, "text": "\nVMware Solutions and Red Hat OpenShift overview \n\nIBM Cloud\u00ae for VMware Solutions includes fully automated, rapid deployments of VMware vCenter Server\u00ae in the IBM Cloud. These offerings complement the on-premises infrastructure and allow existing and future workloads to run in the IBM Cloud without conversion by using the same tools, skills, and processes they use on-premises. For more information, see [Virtualization for extending virtualized private cloud](https://www.ibm.com/cloud/architecture/architectures/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae for VMware Solutions is a reference architecture and a manual build process to deploy a Red Hat OpenShift cluster 4.7 on to an existing vCenter Server instance. The components of Red Hat OpenShift cluster are deployed as virtual machines (VMs) and appliances by using NSX software-defined networking.\n\n\n\n* Reference architecture - [vCenter Server and Red Hat OpenShift architecture overview](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* Build process - The current document. The process and steps that are needed to install Red Hat OpenShift 4.7 on to an existing vCenter Server instance.\n\n\n\nZoom\n\n![VMware Solutions and Red Hat OpenShift](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"}, {"document_id": "ibmcld_10495-9135-10569", "score": 21.890976, "text": "\n(https://cognitiveclass.ai/courses/docker-essentials)\n\n\n\n\n\n What is Red Hat OpenShift? \n\nRed Hat OpenShift is a Kubernetes container platform that provides a trusted environment to run enterprise workloads. It extends the Kubernetes platform with built-in software to enhance app lifecycle development, operations, and security. With Red Hat OpenShift, you can consistently deploy your workloads across hybrid cloud providers and environments. For more information about the differences between the community Kubernetes and Red Hat OpenShift cluster offerings, see the [comparison table](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\n\n\n\n\n What compute host infrastructure does the service offer? \n\nYou can create clusters on Classic or IBM Cloud\u00ae Virtual Private Cloud infrastructure. You can also bring your own hosts by using Satellite.\n\nFor more information, see [Supported infrastructure providers](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providers).\n\n\n\n\n\n Related resources \n\nReview how you can learn about Kubernetes concepts and the terminology.\n\n\n\n* Familiarize yourself with the product by completing the [Creating clusters tutorial](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_tutorial).\n* Learn how Kubernetes and Red Hat OpenShift on IBM Cloud work together by completing this [course](https://cognitiveclass.ai/courses/kubernetes-course).", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-roks-overview"}, {"document_id": "ibmcld_10154-15474-17414", "score": 21.884233, "text": "\nRed Hat OpenShift on IBM Cloud clusters come with all the same configurable project and build components as OCP clusters. You can also choose to integrate your cluster with IBM Cloud services like [Continuous Delivery](https://cloud.ibm.com/docs/openshift?topic=openshift-cicd). \n Cluster health You can also set up logging, monitoring, and metering tools by installing and configuring various operators. These solutions are cluster-specific and not highly available unless you back them up. Your clusters feature one-click integrations with IBM Log Analysis and IBM Cloud Monitoring for enterprise-grade, persistent monitoring and logging solutions across clusters. You can also install the logging and monitoring operators as with standard OCP, but you might have to adjust the configuration settings. For more information, see [Logging and monitoring cluster health](https://cloud.ibm.com/docs/openshift?topic=openshift-health). \n Migrating clusters You can use the cluster migrator operator to migrate clusters from one major version to another. Migration requires separate clusters; you can't update a cluster from one major version to another. Various open source tools might be used, but are not officially supported. As with standard OpenShift Container Platform, you can't update a cluster from one major version to another. If you use a third-party open source tool such as the [cluster migrator operator](https://github.com/migtools/mig-operator), the tool is not supported by IBM and might have limitations such as the migration UI being unavailable. \n Container-native virtualization You can set up [container-native virtualization add-on](https://docs.openshift.com/container-platform/4.11/virt/about-virt.html) on bare metal machines, but not on virtual machines. Container-native virtualization is not supported by IBM. If you experience issues, you are responsible for resolving the issues and any impact to your workloads.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov"}, {"document_id": "ibmcld_11272-4255-5961", "score": 21.533432, "text": "\nWhen you provision a Red Hat OpenShift Cluster on Power Systems Virtual Server, it is easier to use the IBM\u2122 provided automation to create the entire cluster of servers and install Red Hat OpenShift rather than individually provisioning Power Systems Virtual Server instances. For instructions to deploy a Red Hat OpenShift Cluster on Power Systems Virtual Server, including preparation of the required Operation System images for the cluster, see [Deploying Red Hat OpenShift Container Platform 4.x on IBM Power Systems Virtual Servers](https://developer.ibm.com/components/ibm-power/series/deploy-ocp-cloud-paks-power-virtual-server/).\n\n\n\n\n\n\n\n Hardware specifications \n\nThe following IBM Power Systems can host a Power Systems Virtual Server: IBM Power System S922 (9009-22A), IBM Power System S922 (9009-22G), IBM Power System E980 (9080-M9S), IBM Power System E1080 (9080-HEX), and IBM Power System S1022 (9105-22A). For more information about these systems and how they're used inside the Power Systems Virtual Server, see their data sheets and the hardware overview table.\n\nIf you'd like to compare your current environment's performance to what's available through the Power Systems Virtual Server, see the [IBM Power Systems performance report](https://www.ibm.com/downloads/cas/K90RQOW8). For a more condensed comparison, see [IBM Power Systems CPW performance data comparison](https://www.itechsol.com/wp-content/uploads/2018/07/IBM-Power-Systems-CPW-Performance-Data-Comparison-P7-vs-P8-vs-P9-rev3-July-2018.pdf).\n\n\n\n Data sheets \n\n\n\n* [IBM Power System S922 (9009-22A)](https://www.ibm.com/downloads/cas/KQ4BOJ3N)\n* [IBM Power System E980 (9080-M9S)](https://www.ibm.com/downloads/cas/VX0AM0EP)", "title": "", "source": "https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-about-virtual-server"}, {"document_id": "ibmcld_14683-7-2001", "score": 21.479292, "text": "\nRed Hat OpenShift architecture \n\nThe IBM Cloud\u00ae for VMware Solutions offerings provide automation to deploy VMware\u00ae technology components in IBM Cloud data centers across the globe. The architecture consists of a single cloud region. It supports the ability to extend into more cloud regions that are located in another geography or into another IBM Cloud pod within the same data center.\n\nZoom\n\n![Red Hat OpenShift architecture](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/openshift-components.svg)\n\nFigure 1. Red Hat OpenShift architecture\n\n\n\n Bastion hosts \n\nThe Management host is a Red Hat\u00ae Enterprise Linux\u00ae 8.0 virtual machine (VM). This VM hosts services to install and configure the Red Hat\u00ae OpenShift\u00ae instance and provides utilities to manage the Red Hat OpenShift environment. This host is normally deployed in the VXLAN Subnet.\n\n\n\n\n\n Bootstrap hosts \n\nThe bootstrap node is a Red Hat Enterprise Linux CoreOS (RHCOS), a new container-oriented operating system designed for running containers. The node is a temporary node that is used to start the installation.\n\n\n\n\n\n Control Plane hosts \n\nThe control plane hosts are Red Hat Enterprise Linux CoreOS (RHCOS), a new container-oriented operating system designed for running containers. The control plane nodes are known as the control plane, where Kubernetes services such as API server, etcd, and controller manager are defined. An NSX\u00ae load balancer is configured to spread load across these VMs for ports 6443 and 22623, exposing the api and api-int functions.\n\n\n\n\n\n Worker hosts \n\nThe worker hosts are Red Hat Enterprise Linux CoreOS (RHCOS), a new container-oriented operating system designed for running containers. The worker nodes are known as the data-plane, where the actual Kubernetes workloads are deployed. An NSX load balancer is configured to spread load across these VMs for ports 80 and 443, exposing the wildcard DNS and *.apps.\n\n\n\n\n\n Common services", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-redhat-arch"}, {"document_id": "ibmcld_11950-7-2002", "score": 21.45078, "text": "\nSetting up virtualization on a Satellite location \n\nYou can set up your Bare Metal Servers to use Red Hat OpenShift virtualization in your Satellite location. By using virtualization, you can provision Windows or other virtual machines on your Bare Metal Servers in a managed Red Hat OpenShift space.\n\nSupported host operating systems\n: Red Hat CoreOS (RHCOS)\n\n\n\n Prerequisites \n\n\n\n* Create a RHCOS-enabled location. To check whether your location is RHCOS-enabled, see [Is my location enabled for Red Hat CoreOS?](https://cloud.ibm.com/docs/satellite?topic=satellite-locationsverify-coreos-location). If your location is not enabled, [create a new one with RHCOS](https://cloud.ibm.com/docs/satellite?topic=satellite-locations).\n* Attach hosts to your location and set up your [location control plane](https://cloud.ibm.com/docs/satellite?topic=satellite-setup-control-plane).\n* Find and record your bare metal host name.\n* Find your bare metal server network information. Record the CIDR and gateway information for the public and private interfaces for your system.\n* If you want to use IBM Cloud Object Storage to store your ignition file, create or identify a bucket.\n* Create or identify a cluster within the Satellite location that runs a supported operating system; for example, this tutorial uses a Red Hat OpenShift cluster that is running 4.11.\n* If you want to use OpenShift Data Foundation as your storage solution, add 2 storage disks to each of your Bare Metal Servers when you provision them.\n\n\n\n\n\n\n\n Bare Metal Server requirements for Satellite \n\nTo set up virtualization, your Bare Metal Server must meet the following requirements.\n\n\n\n* Must support virtualization technology.\n\n\n\n* For Intel CPUs, support for virtualization is referred to as Intel VT or VT-x.\n* For AMD CPUs, support for virtualization is referred to as AMD Virtualization or AMD-V.\n\n\n\n* Must have a minimum of minimum of 8 cores and 32 GB RAM, plus any additional cores that you need for your vCPU overhead.", "title": "", "source": "https://cloud.ibm.com/docs/satellite?topic=satellite-virtualization-location"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02569-1678-3309", "score": 9.209318, "text": "\nmessage String This field MUST contain a plainly-written, developer-oriented explanation of the solution to the problem in complete, well-formed sentences. \n more_info URL This field SHOULD contain a publicly-accessible URL where information about the error can be read in a web browser. \n target Error Target Model This field MAY contain an error target model. Otherwise, it MUST be omitted. \n\n\n\nThe error model MAY be extended with additional fields to better specify the error. The target field can be considered a standardized example of such an extension.\n\n\n\n\n\n Error target model \n\nAn error target model MUST contain the fields outlined below:\n\n\n\nError target model\n\n Field Type Description \n\n type Enumeration This field MUST contain field, parameter, or header. \n name String This field MUST contain the name of the problematic field (with dot-syntax if necessary), query parameter, or header. \n\n\n\n\n\n Example error response \n\n{\n\"trace\": \"9daee671-916a-4678-850b-10b911f0236d\",\n\"errors\": [\n{\n\"code\": \"missing_field\",\n\"message\": \"The first_name field is required.\",\n\"more_info\": \"https://docs.api.example.com/v2/users/create_userfirst_name\",\n\"target\": {\n\"type\": \"field\",\n\"name\": \"first_name\"\n}\n},\n{\n\"code\": \"reserved_value\",\n\"message\": \"The value provided for username is already in use.\",\n\"more_info\": \"https://docs.api.example.com/v2/users/create_userusername\",\n\"target\": {\n\"type\": \"field\",\n\"name\": \"username\"\n}\n}\n]\n}\nShow more\n\n\n\n\n\n\n\n Codes and messages \n\nError code values SHOULD specify the problem that caused an error; message values SHOULD describe the problem and MAY also provide suggestions or solutions.\n\n\n\n Codes", "title": "", "source": "https://cloud.ibm.com/docs/api-handbook?topic=api-handbook-errors"}, {"document_id": "ibmcld_02569-2974-5046", "score": 9.035545, "text": "\n\"more_info\": \"https://docs.api.example.com/v2/users/create_userusername\",\n\"target\": {\n\"type\": \"field\",\n\"name\": \"username\"\n}\n}\n]\n}\nShow more\n\n\n\n\n\n\n\n Codes and messages \n\nError code values SHOULD specify the problem that caused an error; message values SHOULD describe the problem and MAY also provide suggestions or solutions.\n\n\n\n Codes \n\nError code values MUST be snake case strings, descriptive of the problem encountered, as succinct as possible, and absent of any non-standard or proprietary terms, brands, codenames, abbreviations, or acronyms.\n\ncode values SHOULD NOT prescribe solutions to problems. For example, color_must_be_red_or_blue is not a good code. A better code would be invalid_color, leaving solutions to message values. This allows code values to remain constant even if a field becomes more permissive in the future.\n\nA code value, along with any other machine-readable fields included in an error, SHOULD be specific enough for client code to take any required action. Client code should not be forced to parse a human-readable message value in order to take action on a specific error condition.\n\nThe documentation for specific requests SHOULD enumerate possible error code values. Adding a possible error code for a request SHOULD be considered a breaking change. For this reason, the documentation MAY include possible error code values which are not yet used.\n\n\n\n\n\n Messages \n\nError message values SHOULD describe the problems identified by code values in complete, well-formed sentences and MAY provide suggestions or solutions. It is expected for message values to duplicate information from code, target, and custom extensions to the error model.\n\nImportantly, message values are still meant for developers and for this reason SHOULD NOT be localized or written for use in a user interface. Fields mentioned within a message SHOULD be mentioned by exact field name (e.g., first_name, not \"first name\").\n\nConsider the example above of an error code with value invalid_color. A poor message would be:\n\n\"The color provided for paint was invalid.\"", "title": "", "source": "https://cloud.ibm.com/docs/api-handbook?topic=api-handbook-errors"}, {"document_id": "ibmcld_02952-7-2097", "score": 8.65014, "text": "\nConnecting customers with support \n\nNo matter where you deploy your assistant, give your customers a way to get additional support when they need it.\n\nBuild your dialog to recognize when customers need help that cannot be provided by the assistant. Add logic that can connect your customers to whatever type of professional support you offer. Your solutions might include:\n\n\n\n* A toll-free phone number to a call center that is manned by human agents\n* An online support ticket form that customers fill out and submit\n* A service desk solution that is configured to work with your custom client application. The built-in Zendesk and Salesforce integrations aren\u2019t supported.\n\n\n\nDesign your dialog to recognize customer requests for help and address them. Add an intent that understands the customer request, and then add a dialog branch that handles the request.\n\nYou might add an intent and use it in a dialog node like these example intents:\n\n\n\nAlternative support request intent examples\n\n Intent name Intent user example 1 Intent user example 2 Response from dialog node that conditions on intent \n\n call_support How do I reach support? What's your toll-free number? Call 1-800-555-0123 to reach a call center agent at any time. \n support_ticket How do I get help? Who can help me with an issue I'm having? Go to [Support Center](https://example.com/support) and open a support ticket. \n\n\n\n\n\n Adding chat transfer support \n\nDesign your dialog so that it can transfer customers to human agents. Consider adding support for initiating a transfer in the following scenarios:\n\n\n\n* Any time a user asks to speak to a person.\n\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-support"}, {"document_id": "ibmcld_16526-1727-2644", "score": 7.6946964, "text": "\nIf there is no guideline, consider starting one. The first entry can address the question you are debating now, and can describe the resolution that you come to. This entry will save time for the next human annotator who stumbles upon the same issue.\n* Discuss the question with other human annotators involved in the workspace, and try to decide together on the optimal solution. This type of discussion is expected and beneficial to the workspace overall. It will encourage you to all follow the same methodology as you annotate the documents.\n\n\n\n\n\n\n\n Related information \n\n\n\n* [Annotating documents](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-user-guide)\n* [Dictionaries](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-dictionaries)\n* [Type systems](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-typesystem)", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-ts_user_contactingsupport"}, {"document_id": "ibmcld_16692-7-2046", "score": 7.45852, "text": "\nGetting help and support \n\nIf you have problems or questions when using the IBM Cloud Security and Compliance Center Workload Protection service, you have several options to get help with determining the cause of the problem and finding a solution. If you're logged in, you can go directly to the [Support center](https://cloud.ibm.com/unifiedsupport/supportcenter) to review common FAQs, open a support case, or search community content.\n\n\n\n Using the Support Center search field \n\nYou can use the Support Center search field to find answers to your questions from across the IBM Cloud documentation and Stack Overflow forum. You can also manage support cases from the Support Center. You can find links to both the Stack Overflow forum for technical questions and the developerWorks (IBM Developer Answers) forum for all other questions under the Forums section of the Support Center.\n\nTo access the Support Center, log in to the IBM Cloud console, and click Support from the menu bar.\n\nIf you have a basic, advanced, or premium [support plan](https://cloud.ibm.com/docs/get-support?topic=get-support-support-planssupport-plans), you can find call-in numbers and a chat option to get help.\n\nThe Support Center is the preferred method for getting support, but if you can't log in to IBM Cloud, you can use the [New support case](https://cloud.ibm.com/unifiedsupport/cases/add) page to submit a case.\n\n\n\n\n\n Searching forums \n\nYou can search forums to find answers to your questions. The Stack Overflow forum, for technical questions, and the IBM Developer Answers forum, for general questions, both provide a wide variety of searchable answers to your IBM Cloud questions.\n\nIf you don't find an existing answer to a question, ask a new one.\n\nYou can access Stack Overflow and IBM Developer Answers from the Support Center, or use the following links:\n\n\n\n* Go to [Stack Overflow](https://stackoverflow.com/questions/tagged/ibm-cloud) to ask technical questions about the IBM Cloud Security and Compliance Center Workload Protection service.", "title": "", "source": "https://cloud.ibm.com/docs/workload-protection?topic=workload-protection-gettinghelp"}, {"document_id": "ibmcld_14516-7-2358", "score": 7.416037, "text": "\nTroubleshooting \n\nReview the following information to troubleshoot your VMware vCenter Server\u00ae instance issues. Your system administrators must identify the symptoms of the issue, determine which of the solution components are affected, research, and propose a fix or workaround, and test the fix.\n\n\n\n* Identifying Symptoms. A number of potential causes might lead to the under-performance or non-performance of your instance. The first step in efficient troubleshooting is to identify exactly what is going wrong. These symptoms might be reported from VMware vSphere\u00ae events and alarms, Operations Management in IBM Cloud\u00ae, or reported from your Service Desk from one of your users.\n* Isolating the affected components. After you identify the symptoms of the issue, you must identify the software or hardware components that are affected. Identify whether they might be causing the issue and those components that are not involved. Tools such as vCenter Operations Management in IBM Cloud assist with this step.\n* Proposing a fix or workaround. After you understand the symptoms and isolate the components, you can research possible fixes and workarounds. Your system administrators also use the IBM Cloud portal, including the troubleshooting scenarios in this document, IBM ServiceNow, and VMware Knowledgebase. In addition, you can find many wikis and blogs that might help. For even quicker resolutions, Operations Management in IBM Cloud includes a number of remediations for identified issues.\n* Testing Possible Solutions. When you know the symptoms, involved components, and have a fix or workaround, your system administrators systematically test the solutions until the issue is resolved.\n\n\n\nvSphere includes a user-configurable events and alarms subsystem, which tracks events that occur throughout the vSphere environment and stores the data in log files and the vCenter database. This subsystem also enables system administrators to specify the conditions under which alarms are triggered. Alarms change state from warnings to more serious alerts as system conditions change, and can trigger automated alarm actions such as to email the system administrator team. This function is useful when you want to be informed, or take immediate action, when certain events or conditions occur for a specific inventory object, or group of objects.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-opsprocs-trouble"}, {"document_id": "ibmcld_16452-7-2383", "score": 7.295115, "text": "\nTroubleshooting, support, and FAQs \n\nTo isolate and resolve problems with your IBM products, you can use the troubleshooting and support information. This information contains instructions for using the problem-determination resources that are provided with your IBM products, including IBM Watson\u2122 Knowledge Studio.\n\n\n\n Techniques for troubleshooting problems \n\nTroubleshooting is a systematic approach to solving a problem. The goal of troubleshooting is to determine why something does not work as expected and how to resolve the problem. Certain common techniques can help with the task of troubleshooting.\n\nThe first step in the troubleshooting process is to describe the problem completely. Problem descriptions help you and the IBM technical-support representative know where to start to find the cause of the problem. This step includes asking yourself basic questions:\n\n\n\n* What are the symptoms of the problem?\n* Where does the problem occur?\n* When does the problem occur?\n* Under which conditions does the problem occur?\n* Can the problem be reproduced?\n\n\n\nThe answers to these questions typically lead to a good description of the problem, which can then lead you to a problem resolution.\n\n\n\n What are the symptoms of the problem? \n\nWhen starting to describe a problem, the most obvious question is \"What is the problem?\" This question might seem straightforward; however, you can break it down into several more-focused questions that create a more descriptive picture of the problem. These questions can include:\n\n\n\n* Who, or what, is reporting the problem?\n* What are the error codes and messages?\n* How does the system fail? For example, is it a loop, hang, crash, performance degradation, or incorrect result?\n\n\n\n\n\n\n\n Where does the problem occur? \n\nDetermining where the problem originates is not always easy, but it is one of the most important steps in resolving a problem. Many layers of technology can exist between the reporting and failing components. Networks, disks, and drivers are only a few of the components to consider when you are investigating problems.\n\nThe following questions help you to focus on where the problem occurs to isolate the problem layer:\n\n\n\n* Is the problem specific to one platform or operating system, or is it common across multiple platforms or operating systems?\n* Is the current environment and configuration supported?", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-troubleshooting"}, {"document_id": "ibmcld_16728-1-1595", "score": 7.2577286, "text": "\nSolution library\n\nFilter:\n\nContent type\n\n\n\n1. Deployment guide\n2. Reference architecture\n3. Solution guide\n4. Solution tutorial\n5. White paper\n\n\n\nAutomation available\n\n\n\n1. Deployable\n\n\n\nUse case\n\n\n\n1. AI and ML\n2. Analytics\n3. Application integration\n4. Application modernization\n5. Application performance management\n6. Business process automation\n7. Chatbots\n8. Cloud infrastructure\n9. Containers\n10. Cybersecurity\n11. DevOps\n12. Identity and access management\n13. IT service management\n14. Virtual private cloud\n15. VMware\n\n\n\nIndustry\n\n\n\n1. Banking\n2. Financial services\n3. Software and platform applications\n4. Technology\n\n\n\nCompliance\n\n\n\n1. FedRAMP\n2. IBM Cloud Framework for Financial Services\n3. SAP certified\n\n\n\nFeatured[Centralize communication through a VPC transit hub and spoke architecture](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vpc-transit1)![IBM Title Image](https://cloud.ibm.com/media/docs/images/homepage/tutorial-default.svg)Centralize communication through a VPC transit hub and spoke architecture Solution tutorial\n\nSet up a VPC transit hub to centralize traffic routing and monitoring between an enterprise network and the cloud.\n\n[DevSecOps Application Lifecycle Management](https://cloud.ibm.com/docs/deployable-reference-architectures?topic=deployable-reference-architectures-deploy-arch-ibm-devsecops-alm)![IBM Title Image](https://cloud.ibm.com/media/docs/images/homepage/tutorial-default.svg)DevSecOps Application Lifecycle Management Reference architecture\n\nSecurity and compliance requirements in the Cloud native app development.", "title": "", "source": "https://cloud.ibm.com/docs?tab=solutions"}, {"document_id": "ibmcld_09755-7-1966", "score": 7.2003098, "text": "\nGetting help and support \n\nIf you have problems or questions when using the IBM Cloud Monitoring service, you have several options to get help with determining the cause of the problem and finding a solution. If you're logged in, you can go directly to the [Support center](https://cloud.ibm.com/unifiedsupport/supportcenter) to review common FAQs, open a support case, or search community content.\n\n\n\n Using the Support Center search field \n\nYou can use the Support Center search field to find answers to your questions from across the IBM Cloud documentation and Stack Overflow forum. You can also manage support cases from the Support Center. You can find links to both the Stack Overflow forum for technical questions and the developerWorks (IBM Developer Answers) forum for all other questions under the Forums section of the Support Center.\n\nTo access the Support Center, log in to the IBM Cloud console, and click Support from the menu bar.\n\nIf you have a basic, advanced, or premium [support plan](https://cloud.ibm.com/docs/get-support?topic=get-support-support-planssupport-plans), you can find call-in numbers and a chat option to get help.\n\nThe Support Center is the preferred method for getting support, but if you can't log in to IBM Cloud, you can use the [New support case](https://cloud.ibm.com/unifiedsupport/cases/add) page to submit a case.\n\n\n\n\n\n Searching forums \n\nYou can search forums to find answers to your questions. The Stack Overflow forum, for technical questions, and the IBM Developer Answers forum, for general questions, both provide a wide variety of searchable answers to your IBM Cloud questions.\n\nIf you don't find an existing answer to a question, ask a new one.\n\nYou can access Stack Overflow and IBM Developer Answers from the Support Center, or use the following links:\n\n\n\n* Go to [Stack Overflow](https://stackoverflow.com/questions/tagged/ibm-cloud) to ask technical questions about the IBM Cloud Monitoring service.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-gettinghelp"}, {"document_id": "ibmcld_11601-7-2113", "score": 7.1570454, "text": "\nGetting help and support from IBM Cloud or SAP \n\nIf you experience problems with IBM Cloud, you have several options to get help with determining the cause of the problem and finding a solution.\n\nWhich support option depends on the level of support (and urgency), and whether the problem is with the Offering or running SAP Workloads using the Offering.\n\nOptions include:\n\n\n\n* IBM Cloud Support Case, using the [IBM Cloud Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter)\n* SAP support incident, using the [SAP ONE Support Launchpad](https://launchpad.support.sap.com/)\n* IBM Cloud Docs\n\n\n\nFor previous users of IBM Cloud Classic Infrastructure (formerly Softlayer), please be aware these Support Cases were previously termed Support Tickets.\n\n\n\n IBM Cloud Support \n\nIBM Cloud Support handles any support questions and issues that might arise - available through live web chat, phone, and case-based support.\n\nEach IBM Cloud account automatically comes with customer support at no cost and covers most cases which are placed each day; this is the Basic level of support.\n\nThe types of available and response time of support, depends on the support level of the account. Your support plan also determines the severity level that you can assign to support cases. For more information, see [Basic, Advanced, and Premium Support plans](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans).\n\nYou can change your current support plan at any time by contacting IBM Cloud sales expert.\n\nFor full information about opening an IBM Cloud Support case, or about support levels and ticket severities, see [IBM Cloud Support documentation](https://cloud.ibm.com/docs/get-support).\n\nIf you need support but are unable to log in to your account, start a chat by going to the [IBM Cloud Support](https://www.ibm.com/cloud/support) page and clicking Let's talk.\n\n\n\n New support case with IBM Cloud Support \n\nIf you need to open a support case, collect as much information as possible to help the IBM Cloud Support team to analyze, triage and diagnose your problem as quickly as possible.", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-help-support"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10167-8650-10995", "score": 19.58681, "text": "\nInstead, their work's isolated in pockets across the globe due to regional compliance regulations and centralized databases.\n\nRed Hat OpenShift on IBM Cloud delivers secure compute that can host sensitive and data processing on an open platform. That global platform is hosted in near-by regions. So it's tied to local regulations that inspire patients\u2019 and researchers\u2019 confidence that their data is both protected locally and makes a difference in better health outcomes.\n\n\n\n Context \n\nSecurely hosting and sharing disease data for Research Nonprofit\n\n\n\n* Disparate groups of researchers from various institutions don\u2019t have a unified way to share data, slowing down collaboration.\n* The security concern adds to the collaboration burden that causes even less shared research.\n* Developers and Researchers are spread across the globe and across organizational boundaries, which make PaaS and SaaS the best option for each user group.\n* Regional differences in health regulations require some data and data processing to remain within that region.\n\n\n\n\n\n\n\n Solution \n\nSecurely hosting and sharing disease data for Research Nonprofit.\n\nThe research nonprofit wants to aggregate cancer research data across the globe. So they create a division that is dedicated to solutions for their researchers.\n\n\n\n* INGEST - Apps to ingest research data. Researchers today use spreadsheets, documents, commercial products, and proprietary or home-grown databases to record research results. This situation is unlikely to change with the nonprofit's attempt to centralize data analysis.\n* ANONYMIZE - Apps to anonymize the data. SPI must be removed to comply with regional health regulations.\n* ANALYZE - Apps to analyze the data. The basic pattern is to store the data in a regular format and then to query and process it by using AI and machine learning (ML) technology, simple regressions, and so forth.\n\n\n\nResearchers need to affiliate with a regional cluster, and apps ingest, transform, and anonymize the data.\n\n\n\n1. Syncing the anonymized data across regional clusters or shipping them to a centralized data store\n2. Processing the data, by using ML like PyTorch on bare metal worker nodes that provide GPUs\n\n\n\nINGEST\n: IBM Cloudant is used at each regional cluster that stores researchers\u2019 rich data documents and can be queried and processed as needed.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_health"}, {"document_id": "ibmcld_08255-0-309", "score": 19.097918, "text": "\n\n\n\n\n\n\n  Getting help and support \n\nIf you have problems or questions when you are using the Red Hat\u00ae OpenShift\u00ae for HPC offering on IBM Cloud\u00ae, you can:\n\n\n\n*  Call IBM Cloud technical support. For a list of country-based numbers, see [https://www.ibm.com/planetwide](https://www.ibm.com/planetwide).\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/hpc-openshift?topic=hpc-openshift-getting-help-and-support"}, {"document_id": "ibmcld_10154-7-1896", "score": 19.059687, "text": "\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https://www.ibm.com/products/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov"}, {"document_id": "ibmcld_13150-27249-28976", "score": 18.991667, "text": "\nRefer to this [link](https://docs.openshift.com/container-platform/4.12/registry/registry-third-party-registries_registry-overview) for more info.\n\n\n\n\n\n\n\n\n\n Step 7: (Optional) Use your own custom domain \n\nThis section requires you to own a custom domain and to be able to modify the DNS records of the domain. You will need to create a CNAME record pointing to the IBM-provided domain.\n\nSteps for setting up the CNAME record vary depending on your DNS provider. Under DNS Management/Zone of your domain, add a new CNAME record, set Host(name) to openshiftapp or any subdomain you like and set Points to to IBM-provided domain without HTTP or HTTPS\n\n\n\n With HTTP \n\n\n\n1. Create a route exposing the service at a hostname by replacing <HOSTNAME> with your hostname(e.g.,www.example.com or openshiftapp.example.com), so that external clients can reach it by name.\n\noc expose svc/$MYPROJECT --hostname=<HOSTNAME> --name=$MYPROJECT-domain --port=3000\n2. Access your application at http://<HOSTNAME>/\n\n\n\n\n\n\n\n With HTTPS \n\n\n\n1. To create a secured HTTPS route, you can use your own certificate and key files from a CA like [Let's Encrypt](https://letsencrypt.org/) or order through [Secrets Manager](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificates&interface=ui). Pass them with the create route command\n\noc create route edge $MYPROJECT-httpsca --service=$MYPROJECT --cert=example.pem --key=example.key --hostname=<www.HOSTNAME> --port=3000\n\nHere, you have used Edge termination. To learn about other secured routes and termination types like passthrough and re-encryption, run oc create route --help command)\n\n\n\n\n\n\n\n\n\n Step 8: Remove resources \n\n\n\n* Delete all resource objects specific to an application:", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-scalable-webapp-openshift"}, {"document_id": "ibmcld_10358-3632-5051", "score": 18.796028, "text": "\n* [Deploying apps through the CLI](https://cloud.ibm.com/docs/openshift?topic=openshift-deploy_appdeploy_apps_cli).\n* [Deploying apps to specific worker nodes by using labels](https://cloud.ibm.com/docs/openshift?topic=openshift-deploy_appnode_affinity).\n\n\n\nNeed help? Check out [Troubleshooting apps and integrations](https://cloud.ibm.com/docs/openshift?topic=openshift-debug_apps).\n\n\n\n\n\n Test, log, and monitor \n\nWhile you conduct performance testing on your app, set up logging and monitoring to help you troubleshoot issues, gain visibility into your workloads, and improve the health and performance of your apps.\n\nIn a test environment, deliberately create various non-ideal scenarios, such as deleting all worker nodes in a zone to replicate a zonal failure. Review the logs and metrics to check how your app recovers.\n\n\n\n1. Test access: Test access to your app by creating a public or private [NodePort](https://cloud.ibm.com/docs/openshift?topic=openshift-nodeport) on your worker nodes.\n2. Understand logging and monitoring options: [Choose solutions for app and cluster logging, audit logging, and monitoring](https://cloud.ibm.com/docs/openshift?topic=openshift-healthoc_logmet_options) based on your needs.\n3. Monitoring through the console: Open the [OpenShift web console](https://cloud.ibm.com/docs/openshift?topic=openshift-deploy_appopenshift_console) to view information about your app resources.\n4.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-learning-path-dev"}, {"document_id": "ibmcld_10169-8515-10516", "score": 18.773394, "text": "\n* Red Hat OpenShift on IBM Cloud provides scalable compute, so that the inventory and cross-sales API workloads can grow during high-volume periods of the year, such as the fall holidays.\n\n\n\n\n\n\n\n\n\n Traditional grocer increases customer traffic and sales with digital insights \n\nA Chief Marketing Officer (CMO) needs to increase customer traffic by 20% in stores by making the stores a differentiating asset. Large retail competitors and online retailers are stealing sales. At the same time, the CMO needs to reduce inventory without markdowns because holding inventory too long locks up millions in capital.\n\nRed Hat OpenShift on IBM Cloud provides easy spin-up of more compute, where Developers quickly add Cloud Analytics services for sales behavior insights and digital market adaptability.\n\nKey technologies:\n\n\n\n* [Horizontal scaling to accelerate development](https://cloud.ibm.com/docs/openshift?topic=openshift-plan_deployhighly_available_apps)\n* [Clusters that fit varied CPU, RAM, storage needs](https://cloud.ibm.com/docs/openshift?topic=openshift-planning_worker_nodesplanning_worker_nodes)\n* [Insights to market trends with Watson Discovery](https://www.ibm.com/products/watson-discovery)\n* [DevOps native tools, including open toolchains in IBM Cloud\u00ae Continuous Delivery](https://www.ibm.com/cloud/architecture/toolchains/)\n* [Inventory management with IBM\u00ae Event Streams for IBM Cloud\u00ae](https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-aboutabout)\n\n\n\n\n\n Context \n\nTraditional grocer increases customer traffic and sales with digital insights.\n\n\n\n* Competitive pressures from online retailers and large retail stores disrupted traditional grocery retail models. Sales are declining, evidenced by low foot traffic in physical stores.\n* Their loyalty program needs a boost in the arm with a modern take on the printed coupons at check out. So Developers must constantly evolve the related apps, but traditional tools slow their ability to deploy updates and features frequently.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_retail"}, {"document_id": "ibmcld_10463-3157-4800", "score": 18.767483, "text": "\n* [Any platform access role](https://cloud.ibm.com/docs/openshift?topic=openshift-userschecking-perms)\n* [The Writer or Manager service access role](https://cloud.ibm.com/docs/openshift?topic=openshift-userschecking-perms)\n\n\n\n\n\n\n\n\n\n Step 1: Deploy an app and expose it by using an NLB \n\nThe first lesson shows you how your app is exposed from multiple IP addresses and ports, and where public traffic is coming into your cluster.\n\nStart by deploying a sample web server app to use throughout the tutorial. The echoserver web server shows data about the connection that is made to the cluster from the client, and you can test access to the PR firm's cluster. Then, expose the app by creating a network load balancer (NLB) 1.0 service. An NLB 1.0 service makes your app available over both the NLB service IP address and the worker nodes' node ports.\n\nWant to use an Ingress application load balancer (ALB)? Instead of creating an NLB in steps 3 and 4, [create a service for the web server app](https://cloud.ibm.com/docs/containers?topic=containers-managed-ingress-setup) and [create an Ingress resource for the web server app](https://cloud.ibm.com/docs/containers?topic=containers-managed-ingress-setup). Then get the public IPs of your ALBs by running ibmcloud oc ingress alb ls --cluster <cluster_name> and use these IPs throughout the tutorial in place of the <loadbalancer_IP>.\n\nThe following image shows how the web server app is exposed to the internet by the public node port and public NLB at the end of Lesson 1.\n\nZoom\n\n![At the end of Lesson 1, the web server app is exposed to the internet by the public node port and public NLB.]", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-policy_tutorial"}, {"document_id": "ibmcld_10392-6380-7520", "score": 18.755999, "text": "\n: Red Hat OpenShift on IBM Cloud clusters are connected to [remote health monitoring](https://docs.openshift.com/container-platform/4.13/support/remote_health_monitoring/about-remote-health-monitoring.html) by default. This means clusters report health and usage data to Red Hat unless you opt out. With connected clusters, IBM Cloud is better positioned to support customers when there are issues specific to Red Hat which impact them. Additionally, remote health reporting gives Red Hat insights into how clusters are impacted by product upgrades. If you do not want to send cluster data to Red Hat, you must opt out. For more information, see [Understanding remote health monitoring](https://cloud.ibm.com/docs/openshift?topic=openshift-remote-health-monitoring-opt-out).\n\n\n\n\n\n 9 June 2023 \n\nNew! OpenShift Data Foundation add-on versions 4.12.5, 4.11.11, 4.10.26, and 4.9.28.\n: For more information, see the [change log](https://cloud.ibm.com/docs/openshift?topic=openshift-odf_addon_changelog).\n\n\n\n\n\n 5 June 2023 \n\nWorker node fix packs 4.9.59_1592_openshift, 4.10.60_1571_openshift, 4.11.42_1558_openshift, and 4.12.19_1546_openshift.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-relnotes"}, {"document_id": "ibmcld_10168-7-1603", "score": 18.707428, "text": "\nOverview of use cases \n\nVarious use cases show the strengths of Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae and IBM Cloud services when used together. These stories highlight several industries as well as types of workloads. Even though each use case is presented through the lens of a particular industry, these workloads are typical across various industries. You see workload themes, such as one of the following areas.\n\n\n\n* AI and machine learning\n* Data and storage\n* DevOps\n* Identity management\n\n\n\n\n\nTable 1. Use cases\n\n Industry Use case \n\n Financial services <br><br> * [Trim IT costs and accelerate regulatory compliance](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_financeuc_mortgage)<br> * [Streamline developer productivity to deploy AI tools to partners 4 times faster](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_financeuc_payment_tech)<br><br><br> \n Government <br><br> * [Secure the exchange of data, connecting public and private organizations](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_govuc_port)<br> * [Improve collaboration velocity with community Developers, combining public-private data](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_govuc_data_mashup)<br><br><br> \n Healthcare <br><br> * [Migrate workloads from inefficient VMs to easily operated containers for patient systems](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_healthuc_migrate)<br> * [Securely host sensitive data while you grow research with partners](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_healthuc_research)<br><br><br>", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_intro"}, {"document_id": "ibmcld_10166-5191-7552", "score": 18.675312, "text": "\n* Create clusters for public-private apps, which are driven by the APIs.\n* Structure apps into a set of cooperative microservices that run within Red Hat OpenShift on IBM Cloud, which is based on functional areas of apps and their dependencies.\n* Deploy the apps to containers that run in Red Hat OpenShift on IBM Cloud. Built-in HA tools in Red Hat OpenShift on IBM Cloud balance the workloads, including self-healing and load balancing.\n* Provide standardized DevOps dashboards through Kubernetes, open-source tools familiar to all types of Developers.\n\n\n\n\n\n\n\n Step 3: Innovate with IBM Garage and cloud services \n\n\n\n* Adopt the agile and iterative development practices from the IBM Garage Method to enable frequent releases of features, patches, and fixes without downtime.\n* Whether developers are in the public or private sector, IBM Cloud\u00ae Continuous Delivery helps them to quickly provision an integrated toolchain, by using customizable, shareable templates.\n* After Developers build and test the apps in their Dev and Test clusters, they use the IBM Cloud\u00ae Continuous Delivery toolchains to deploy apps into production clusters.\n* With Watson AI, machine learning, and deep learning tools available from the IBM Cloud catalog, Developers focus on domain problems. Instead of custom unique ML code, ML logic is snapped into apps with service bindings.\n\n\n\n\n\n\n\n\n\n Results \n\n\n\n* Normally slow public-private partnerships now quickly spin up apps in weeks instead of months. These development partnerships now deliver features and bug fixes up to 10 times per week.\n* Development is accelerated when all participants use well-known open-source tools, such as Kubernetes. Long learning curves are no longer a blocker.\n* Transparency in activities, information, and plans is provided to citizens and private sector. And, citizens are integrated into government processes, services, and support.\n* Public-private partnerships conquer Herculean tasks, such as Zika virus tracking, smart electricity distribution, analysis of crime statistics, and university \"new collar\" education.\n\n\n\n\n\n\n\n\n\n Large public port secures exchange of port data and shipping manifests that connect public and private organizations \n\nIT Execs for a private shipping company and the government-operated port need to connect, provide visibility, and securely exchange port information.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_gov"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10835-7-2112", "score": 15.07291, "text": "\nPreparing apps for actions \n\nWhether you bring an app with you, or you write a script specifically to respond to an event, your code must meet certain requirements before you create an action from it.\n\nEach programming language has specific requirements to run, but most have the following general requirements:\n\n\n\n* The expected name for the entry point into the code is main by default. If your entry point is not main, a custom name can be specified when the action is created, so take note of that name.\n* Input parameters into your app and output results from your app must be formatted into a specific structure that can be passed between entities. The structure depends on your code language. For example, with Python apps, the input parameters must be a dictionary and the result of your app must be structured as a dictionary. Because you can also pass parameters in a structured object to your action. In JSON, for example, you might structure your code to expect an input parameter with JSON values from certain fields, like name and place.\n\nJSON input example\n\n{\"name\": \"Dorothy\", \"place\": \"Kansas\"}\n\nJavaScript example\n\nfunction main(params) {\nreturn {payload: 'Hello, ' + params.person.name + ' from ' + params.person.place};\n}\n* If your app contains multiple files, they must be combined into one single file to be used in an action. You can either rewrite your code into one file or you can package the files and dependencies into a single archive file. If your runtime is not supported, you can package your app in a Docker image.\n\nCode compilation is not required, but if possible for your runtime, compiling your code in advance can improve performance.\n\n\n\n\n\n Preparing JavaScript apps \n\nBefore you create an action, get your JavaScript code ready. Confirm that your code is structured properly, then decide whether it needs packaged.\n\n\n\n Structuring JavaScript code \n\n\n\n* The expected name for the entry point function is main. If the function in your code is not main, take note of the name to specify it when the action is created.\n* The input parameters are passed as a JSON object.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-prep"}, {"document_id": "ibmcld_06836-7-1886", "score": 14.808708, "text": "\nCustom scripts \n\nCustom scripts are extension points in the pipeline where adopters, teams, and users can provide scripts to run custom tasks that are required by their continuous integration and continuous deployment strategies.\n\nCustom scripts control the pipeline stages. You can use a configuration file (pipeline-config.yaml) to configure the behavior of stages, script content, and the base image that runs the scripts. The scripts and configuration for pipeline stages are loaded from a Git repository (repo) that can either be the application (app) repo (similar to .travis.yml or Jenkinsfile) or a custom repo.\n\nWhen any of the custom scripts are started, the complete URL of the custom script file, including the file name and the commit hash, is printed at the beginning of the pipeline logs as follows: The custom script can be viewed using the following link: 'https://<source repo url>/<organization name>/<repository name>/blob/<commit hash>/.pipeline-config.yaml'. This positioning improves traceability.\n\n\n\n Stages \n\nStages in pull request, continuous integration, and continuous deployment pipelines run custom scripts.\n\n\n\n* Pull request pipeline stages: setup, test, and finish. For more information, see [Pull request pipeline](https://cloud.ibm.com/docs/devsecops?topic=devsecops-cd-devsecops-pr-pipeline).\n* Continuous integration pipeline stages: setup, peer-review, test, static-scan, containerize, sign-artifact, deploy, acceptance-test, scan-artifact, release, and finish. For more information, see [Continuous integration pipeline](https://cloud.ibm.com/docs/devsecops?topic=devsecops-cd-devsecops-ci-pipeline).\n* continuous deployment pipeline stages: setup, verify-artifact, deploy, acceptance-test, and finish. For more information, see [continuous deployment pipeline](https://cloud.ibm.com/docs/devsecops?topic=devsecops-cd-devsecops-cd-pipeline).", "title": "", "source": "https://cloud.ibm.com/docs/devsecops?topic=devsecops-custom-scripts"}, {"document_id": "ibmcld_06861-14970-16613", "score": 13.820809, "text": "\nTo evaluate if you have any failures in your pipeline run, check the final step of your pipeline, which has a pipeline evaluator.\n\n\n\n\n\n Customizing the pipeline \n\nCustom scripts are extension points in the pipeline where adopters, teams, and users can provide scripts to run custom tasks that are required by their continuous integration and continuous deployment strategies.\n\nCustom scripts control the pipeline stages. Use the pipeline-config.yaml configuration file to configure the behavior of stages, script content, and the base image that runs the scripts. The scripts and configuration for pipeline stages are loaded from a Git repository (repo) that can either be the application (app) repo (similar to .travis.yml or Jenkinsfile) or a custom repo.\n\nFor more information on customizing the CI pipelines, see [Custom scripts](https://cloud.ibm.com/docs/devsecops?topic=devsecops-custom-scripts).\n\n\n\n\n\n Wrapping up \n\nBy completing the CI part of this tutorial, you:\n\n\n\n* Created a DevSecOps CI toolchain for Terraform.\n* Modified some code in the infrastructure code repository.\n* Ran the pr pipeline before you merge your changes.\n* Ran the ci-pipeline to build, test, and deploy your changes to your dev environment.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [Getting started with toolchains](https://cloud.ibm.com/devops/getting-started)\n* [Getting started with Continuous Delivery](https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-getting-started)\n\n\n\n\n\n\n\n Next steps \n\nContinue to [Part 3: Set up a CD toolchain for Infrastructure as Code](https://cloud.ibm.com/docs/devsecops?topic=devsecops-devsecops-tutorial-iac-cd).", "title": "", "source": "https://cloud.ibm.com/docs/devsecops?topic=devsecops-devsecops-tutorial-iac-ci"}, {"document_id": "ibmcld_11552-1740-3927", "score": 13.702584, "text": "\nThe scripts include Ansible scripts for:\n\n\n\n* OS requirements installation and configuration for SAP applications\n* Cluster components installation\n* Ansible scripts for SAP application cluster configuration and SAP HANA cluster configuration\n* HANA installation\n* HANA DB backup\n* HANA system replica configuration\n* ASCS and ERS instances installation\n* DB load\n* Primary and extra application servers installation\n\n\n\nAnsible is started by Terraform and must be available on the same host.\n\n\n\n\n\n SAP Solution implemented \n\nSAP S/4HANA is an ERP system from SAP's ERP software product line. The software is based on the innovative SAP HANA database technology and was started as the fourth product generation in 2015. Users can choose between the SAP S/4HANA Cloud and On-Premise solution.\n\nAn ERP system is used for demand-oriented business resource planning. It is used to control processes and to link departments and functional areas in a meaningful way. Individual modules include applications for accounting, sales, production, and marketing. More complex tasks in customer or supply chain management can also be done by ERP software. As the successor to the core product SAP ECC, SAP S/4HANA was presented as the intelligent ERP system of the new generation. Thanks to modern technologies, the Software as Service (SaaS) version is designed to help companies standardize processes and make the leap to digitalization.\n\nWhile previous SAP ERP solutions support the most common databases, SAP S/4HANA uses exclusively the SAP HANA in-memory database developed by SAP. This in-memory database offers users the greatest technical benefit and they benefit from increased performance. The \"S\" in S/4HANA stands for \"simple\", while the \"4\" refers to the generation sequence. Compared to the SAP core product SAP ECC, which is still used in most companies, SAP S/4HANA offers many innovative functions that revolutionize the system landscape from the ground up. As SAP plans to discontinue the mainstream maintenance of its existing ERP solutions by 2027, many SAP ECC users are already considering a migration to SAP HA SZ S/4HANA\n\n\n\n\n\n What is created \n\nThe scripts work in two phases.", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-automate-s4hana-ha-terraform-ansible"}, {"document_id": "ibmcld_06846-7-1399", "score": 13.673917, "text": "\nCommon scripts \n\nSome stages run default scripts if they are not specified in the DevSecOps config YAML file.\n\nThese scripts are part of a commons library, which can be used as a source to copy code from and customize them for specific edge cases for adopters. This library also serves as an example of some pipeline mechanics.\n\nEvery script that is included in the commons library performs the following actions:\n\n\n\n* Iterates over assets (repos or artifacts).\n* Runs the scan / check job.\n* Collects evidence by using the [collect-evidence script](https://cloud.ibm.com/docs/devsecops?topic=devsecops-devsecops-collect-evidence).\n\n\n\nTo see which script is running, examine the logs from a stage that is running a default script. For example, the default scripts that are running in scan-artifact:\n\n=== Executing custom script for stage 'scan-artifact' ===\n\nThe custom script can be viewed using the following link: '<SCRIPT URL>'\n\nYou can customize this stage in your pipeline config. For more information, see [Custom scripts](/docs/devsecops?topic=devsecops-custom-scripts).\n\nThe script(s) used in this stage can be found at the following location(s):\n\n- path: scan-artifact\nrepo: <REPO URL>\nsha: b0fff29d715e0f9a33b3c84e649777cfb9d40738\n- path: icr-va\nrepo: <REPO URL>\nsha: de693814ba2bd992941b432fc71111efb54e2b27\n\nUsing the following defaults for stage \"scan-artifact\":\n\nscan-artifact:", "title": "", "source": "https://cloud.ibm.com/docs/devsecops?topic=devsecops-devsecops-common-scripts"}, {"document_id": "ibmcld_00684-81765-83594", "score": 13.52361, "text": "\nFor more information about setting up the custom script, see [Example custom scripts for DevSecOps](https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-cd-configure-cra-reposdevsecops-custom-script-examples).\n\nFAILED\nError executing docker build cmd for stage-0: exit status 1\n...\nCOPY file-to-copy.js file-to-copy.js:\n------\nfailed to compute cache key: \"/file-to-copy.js\" not found: not found\n\nBy default, the Code Risk Analyzer bom-generate command builds the Dockerfiles from the context of the location of the Dockerfile itself. If you want to build the Dockerfiles from the context of the root project directory, use the cra-docker-build-context parameter to allow the Code Risk Analyzer to build the Dockerfiles from this context.\n\n\n\n\n\n\n\n Removing stored Code Risk Analyzer data \n\nThe Code Risk Analyzer plug-in does not store any client data in its databases. However, earlier versions of Code Risk Analyzer Tekton tasks securely stored the results of vulnerability scans in its database.\n\nTo request the removal of any client data that might be stored in the Code Risk Analyzer, contact [IBM Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\n\n\n\n\n FAQs \n\nGet answers to frequently asked questions about using the Code Risk Analyzer CLI.\n\n\n\n How can I determine why the CLI failed? \n\nBefore you call the Code Risk Analyzer CLI, set the IBMCLOUD_TRACE environment variable to true to turn on the debug log.\n\nexport IBMCLOUD_TRACE=true\n\nObserve the API calls and the responses that are shown in the log to determine the exact reason for failure.\n\n\n\n\n\n How can I debug a BOM command that fails to pull a base image from a private registry. \n\nMake sure that you are authenticated with the registry where the base image resides by using the ibmcloud cr login command or the docker login command.", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-cd-configure-cra-repos"}, {"document_id": "ibmcld_04170-1738-2974", "score": 13.423179, "text": "\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under /cdn-cgi/challenge-platform/ is allowed. Your CSP should allow scripts that are served from your origin domain (script-src self).\n* If your CSP uses a nonce for script tags, CIS adds these nonces to the scripts it injects by parsing your CSP response header.\n* If your CSP does not use nonce for script tags and JavaScript Detection is enabled, you might see a console error such as\n\nRefused to execute inline script because it violates the following Content Security Policy directive: \"script-src 'self'\". Either the 'unsafe-inline' keyword, a hash ('sha256-b123b8a70+4jEj+d6gWI9U6IilUJIrlnRJbRR/uQl2Jc='), or a nonce ('nonce-...') is required to enable inline execution.\n* It is not recommended to use unsafe-inline. Instead, it is recommend that you use CSP nonces in script tags which are parsed and supported in the CDN.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections"}, {"document_id": "ibmcld_11573-4755-6312", "score": 13.363971, "text": "\nThe scripts are designed to create a new VPC and install SAP (SAP NW 7.x release) solution together with its dedicated DB SAP HANA box in one task flow.\n\n\n\n\n\n SAP Kits \n\nFor each IBM Cloud region, IBM allocates temporary storage on a dedicated temporary Deployment server (Bastion Server) that is used for terraform environment. It is your responsibility to download the necessary SAP and DB kits to your Deployment (Bastion) Server. All file archives are decompressed by Ansible during the automatic deploying process. For more information, see the readme file in the dedicated GitHub repository.\n\n\n\n\n\n Terraform deployment \n\nThe configuration and script files are provided on the GitHub repository:\n\n\n\n* For JAVA stack : [https://github.com/IBM-Cloud/sap-netweaver-java-hana](https://github.com/IBM-Cloud/sap-netweaver-java-hana).\n* For ABAP stack : [https://github.com/IBM-Cloud/sap-netweaver-abap-hana](https://github.com/IBM-Cloud/sap-netweaver-abap-hana)\n\n\n\nFor SAP HANA stand-alone virtual server instance on IBM Cloud Virtual Private Cloud, you modify the:\n\n\n\n* The input.auto.tfvars file to customize the resources for your solution. You specify zones, resource names, SSH keys, and SAP variables.\n\n\n\nAll of the other configuration files are provided and do not need to be modified.\n\n\n\n\n\n Schematics deployment \n\nThe configuration and script files are provided on the GitHub repository:\n\n\n\n* ABAP: [https://github.com/IBM-Cloud/sap-netweaver-abap-hana/tree/main/schematics](https://github.com/IBM-Cloud/sap-netweaver-abap-hana/tree/main/schematics)", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-create-terraform-3tier-nw-hana-vpc-ansible"}, {"document_id": "ibmcld_00708-81741-83562", "score": 13.275257, "text": "\nFor more information about setting up the custom script, see [Example custom scripts for DevSecOps](https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-cra-cli-plugindevsecops-custom-script-examples).\n\nFAILED\nError executing docker build cmd for stage-0: exit status 1\n...\nCOPY file-to-copy.js file-to-copy.js:\n------\nfailed to compute cache key: \"/file-to-copy.js\" not found: not found\n\nBy default, the Code Risk Analyzer bom-generate command builds the Dockerfiles from the context of the location of the Dockerfile itself. If you want to build the Dockerfiles from the context of the root project directory, use the cra-docker-build-context parameter to allow the Code Risk Analyzer to build the Dockerfiles from this context.\n\n\n\n\n\n\n\n Removing stored Code Risk Analyzer data \n\nThe Code Risk Analyzer plug-in does not store any client data in its databases. However, earlier versions of Code Risk Analyzer Tekton tasks securely stored the results of vulnerability scans in its database.\n\nTo request the removal of any client data that might be stored in the Code Risk Analyzer, contact [IBM Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\n\n\n\n\n FAQs \n\nGet answers to frequently asked questions about using the Code Risk Analyzer CLI.\n\n\n\n How can I determine why the CLI failed? \n\nBefore you call the Code Risk Analyzer CLI, set the IBMCLOUD_TRACE environment variable to true to turn on the debug log.\n\nexport IBMCLOUD_TRACE=true\n\nObserve the API calls and the responses that are shown in the log to determine the exact reason for failure.\n\n\n\n\n\n How can I debug a BOM command that fails to pull a base image from a private registry. \n\nMake sure that you are authenticated with the registry where the base image resides by using the ibmcloud cr login command or the docker login command.", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-cra-cli-plugin"}, {"document_id": "ibmcld_06885-16589-17887", "score": 13.187347, "text": "\nUse that url to verify that the app is running.\n\n\n\n\n\n Pipeline customization \n\nCustom scripts are extension points in the pipeline where adopters, teams, and users can provide scripts to run custom tasks that are required by their continuous integration and continuous deployment strategies.\n\nCustom scripts control the pipeline stages. You can use a configuration file (pipeline-config.yaml) to configure the behavior of stages, script content, and the base image that runs the scripts. The scripts and configuration for pipeline stages are loaded from a Git repository (repo) that can either be the application (app) repo (similar to .travis.yml or Jenkinsfile) or a custom repo.\n\nMore detailed information on customizing the CI pipelines can be found [here](https://cloud.ibm.com/docs/devsecops?topic=devsecops-custom-scripts).\n\n\n\n\n\n Wrapping up \n\nBy completing the CI part of this tutorial, you:\n\n\n\n* Created a DevSecOps CI toolchain\n* Modified some code in the application repository\n* Ran the ci-pr pipeline before you merge your changes\n* Ran the ci-pipeline to build, test, and deploy your changes to your dev environment.\n\n\n\n\n\n\n\n\n\n Next steps \n\nContinue to [Part 3: Set up a Continuous Deployment (CD) toolchain](https://cloud.ibm.com/docs/devsecops?topic=devsecops-tutorial-cd-toolchain).", "title": "", "source": "https://cloud.ibm.com/docs/devsecops?topic=devsecops-tutorial-ci-toolchain"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09525-3541-4700", "score": 12.671998, "text": "\nA temporary license file is installed. The client will need to supply the final license file.\n\n\n\n\n\n Provisioning of the Individual Products \n\nAt this point, the products the client has selected is provisioned based on the sizing parameters that were specified. This includes deploying the appropriate containers within OpenShift and configuring the products to be available to the client. This includes the application, database, any network configuration required, DNS registrations and set up of client administration users.\n\nAt this stage, all operational configuration is finalized including ensuring backups are configured properly, monitoring in place and security scans completed. Alerting is configured and the sites added to the MAS-SaaS escalation process.\n\n\n\n\n\n Final Verification of the Provisioning \n\nA final review of the install is done to ensure what has been deployed meets the order and the additional information gathered. At this point, the order is marked complete and a [welcome letter](https://cloud.ibm.com/docs/mas-ms?topic=mas-ms-getting-started-with-ibm-maximo-application-suite-managed-servicewelcome-letter) is sent to the client.", "title": "", "source": "https://cloud.ibm.com/docs/mas-saas?topic=mas-saas-provisioning"}, {"document_id": "ibmcld_11587-1459-3556", "score": 12.4086685, "text": "\nSummary of an SAP landscape installation onto Cloud IaaS \n\nThis table summarizes the SAP landscape installation steps for you and your team:\n\n\n\nTable 1. Overview of your SAP landscape installation steps\n\n Task Details \n\n Read the [Overview of IBM Cloud\u00ae for SAP](https://cloud.ibm.com/docs/sap?topic=sap-overview) Identify the various offerings that are available for your SAP landscape. Provides a high-level comparison of your options. \n Read the relevant documents in the following topic groups: <br><br> * Infrastructure environments section for your specific environment, such as [IBM Power Systems Infrastructure environment introduction](https://cloud.ibm.com/docs/sap?topic=sap-power-env-introduction)<br> * [Infrastructure certified for SAP](https://cloud.ibm.com/docs/sap?topic=sap-iaas-offerings)<br> * [Sizing process for SAP Systems](https://cloud.ibm.com/docs/sap?topic=sap-sizing) <br> Read these documents to identify the detailed infrastructure options and design considerations that apply to your SAP landscape.<br><br><br> \n Read the relevant SAP software documentation. Short lists of planning considerations are available to assist under topic groups:<br><br><br><br> * SAP Business Applications<br> * SAP Technical Applications<br> * SAP AnyDB databases <br> Lists of usage, network, storage, database, and OS considerations are available for SAP Business Applications, SAP Technical Applications, SAP AnyDB databases, SAP Development Applications. References to SAP installation documents are also included.<br><br><br> \n Optional: Read the relevant SAP Business Partner certified solutions documents Various SAP Open Ecosystem Partners are available from IBM Cloud, with documents on how to best use these solutions for your SAP deployment. \n Optional: Read the relevant IBM-SAP innovation solutions documents IBM Cloud\u00ae for SAP \n Read and follow the documents in the Pre-Requisites for SAP Workloads topic group Prepare the credentials, account structure, connectivity, software downloads, support procedures, and licensing that is needed before you begin your deployment.", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-get-started"}, {"document_id": "ibmcld_04002-23561-25925", "score": 12.31929, "text": "\nNavigate to the Channels tab, open the channel, and click Propose smart contract definition. This single action actually performs two tasks. It installs a smart contract on one or more of your peers and proposes the smart contract definition to the channel.\n2. Because the console allows you to act as multiple organizations from a single console, you must first select the organization that is proposing this smart contract definition and the associated peer admin identity. A peer admin identity is required to install a smart contract. Not sure? Open the peer CA and verify that the identity associated with the peer has the type admin in the list of CA users.\n3. On the next panel, browse to your smart contract package and click Add file. You can install a new package or browse to an existing package that was installed on another peer in your organization. Smart contract packages can also be installed on a peer node directly by using the Install smart contract button. If you used that option, instead of clicking Add file, click the Existing package tab and select the package that you installed on your peer.\n4. On the Smart contract details panel you can specify a unique name and version to use for this smart contract definition. The console extracts these values from the package name itself but you can override them and specify any values that your organization prefers. Be careful how you name your proposal. If a proposal with the same name already exists on the channel, this proposal replaces it.\n5. On the Install smart contract panel, you can install the smart contract on all your peers on the channel or just a subset. In a production network, for redundancy reasons, you should install the smart contract on at least two peers, or three when you want to maintain redundancy but still allow for one peer to go down for maintenance. Since you are proposing the smart contract, it must be installed on at least one peer.\n6. On the Smart contract endorsement policy panel, you can designate how many organizations need to endorse a smart contract transaction before it can be committed to the ledger. The default smart contract endorsement policy is inherited from the application endorsement policy of the channel, but can be overridden here by selecting specific organizations and the required number, or by pasting in your own policy JSON.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-smart-contracts-v2"}, {"document_id": "ibmcld_09503-16826-19188", "score": 12.252927, "text": "\nIBM GBS, Expert Services or other 3rd party services projects that leverage IBM Cloud or AWS based MAS environments should avoid including infrastructure based deliverables in any contract or statement of work. This would include promising deliverables of the following nature:\n\n\n\n* Infrastructure diagrams or design documents\n* Network Diagrams\n* Clustering Diagrams\n* Hardware sizing and resource allocations (Cores, Memory, Storage)\n* Listing of O/S, Middleware or other specific Software Versions\n* IT security documents or diagrams\n* Installation checklists or certifications\n\n\n\nIn the IBM MAS-Dedicated model, the IT stack is the responsibility and domain of the IBM SRE team. IBM's MAS architecture is based on best practices and empirical experience supporting a large existing customer base. With a MAS subscription, the responsibility of IBM SRE is to deliver the application in accordance with the customer's MAS subscription terms and Service Level Agreement (SLA). IBM is not obligated to provide technical details of the infrastructure used to meet it's subscription commitments. As a result, specific infrastructure based deliverables should be avoided in consulting services contracts. Technical details regarding customer infrastructure can, in some cases, be provided by the SRE team depending on the nature of the request.\n\n\n\n\n\n\n\n Provisioning \n\nBe sure both you an your customer are aware of IBM SRE provisioning lead times and have scheduled accordingly. Make sure the customer's MAS environments are ordered and will be available prior to any scheduled meetings or on-site engagements that require access to the environments. IBM's objective is to provision MAS environments within 1-2 weeks of their corresponding sales order being placed, approved and fully processed. The overall amount of time can vary depending on the size (user license) of the environment(s), total number of environments needed (for example DEV, TEST, PROD), number and type of industry solutions within each environment, number & type of add-on components such as Maximo Anywhere, availability of resources in the target data center location, and amount of orders in the queue.\n\n\n\n\n\n Onboarding & Implementation \n\n\n\n 3.1 Onboarding Roles \n\nThe following onboarding roles should be defined:\n\n\n\n* Client Business Leader - provides formal sign off of completed phases", "title": "", "source": "https://cloud.ibm.com/docs/mas-ms?topic=mas-ms-operations"}, {"document_id": "ibmcld_13615-3438-5686", "score": 11.975762, "text": "\n* anticipated sizing information for each product - this can be based on users, I/O or other metrics specific to each product\n* URL's being requested\n* Languages required\n* Add On and/or Industry Solutions required\n* location of the majority of users to determine optimal placement of the Suite in the proper IBM Cloud data center\n\n\n\nIf this information is missing or incorrect it can cause delays in the provisioning process while this information is being confirmed.\n\n\n\n\n\n Initial Provisioning \n\nThe initial provisioning covers several key aspects of the TRIRIGA Application Suite deployment.\n\nThe base architecture is finalized regarding the size and number of OpenShift clusters needed. The provisioning of all based components and configuration is performed and the initial DNS registration for the TRIRIGA Application Suite done. A temporary license file is installed. The client will need to supply the final license file (described below).\n\n\n\n\n\n Provisioning of the Individual Products \n\nAt this point, the products the client has selected is provisioned based on the sizing parameters that were specified. This includes deploying the appropriate containers within OpenShift and configuring the products to be available to the client. This includes the application, database, any network configuration required, DNS registrations and set up of client administration users.\n\nAt this stage, all operational configuration is finalized including ensuring backups are configured properly, monitoring in place and security scans completed. Alerting is configured and the sites added to the TAS-MS escalation process.\n\n\n\n\n\n Final Verification of the Provisioning \n\nA final review of the install is done to ensure what has been deployed meets the order and the additional information gathered. At this point, the order is marked complete.\n\n\n\n\n\n Welcome Letter sent to the client \n\nA welcome letter is then sent to the client which will include the URL's to access each environments, usernames and instructions on how to supply the license file the customer would have received when they purchased the TRIRIGA Application Suite product.\n\nThe letter will contain similar instructions to below:\n\n\n\n* Some IBM products require license keys to use them.", "title": "", "source": "https://cloud.ibm.com/docs/tas-ms?topic=tas-ms-provisioning"}, {"document_id": "ibmcld_04002-38577-40586", "score": 11.895873, "text": "\n<br> <br>Or, if you want to install the package that the proposal originator included, click Add file to upload the smart contract package shared with you by the proposal originator out of band. <br> <br>Lastly, you can install your own version of the smart contract, by clicking Add file to upload your own package or Existing package if the package is already installed on another peer in your organization. <br> <br>If you upload or select a new package, you can choose which peers to install it on. \n Install the smart contract on additional or newly added peers after I approved it Forgot to install the package on a peer? Or perhaps you've added new peers? Open the smart contract tile on the Channels tab. Next to your organization, click Update package details. If you want to install the same package on the newly added peers, click Existing package and browse to the package that you want to install. Otherwise, you can click Add file to upload a new package. Then, select which peers to install the package on. \n Reject a smart contract proposal or definition Fabric does not include an option to reject a smart contract proposal. Rather, you can abstain from approving, which can prevent the proposal from ever satisfying the lifecycle endorsement policy. Or, you can make a new proposal with a new smart contract definition name, and include the terms that you prefer. \n Commit a smart contract definition After the proposal has reached the required number of approvals, the status of the proposal on the Channels tab changes to Ready to commit. Any channel member can click the tile and then click Commit to commit the definition to the channel. At that point, the associated smart contract can begin accepting transactions on the peers. \n Update a smart contract definition that has been committed to the channel All updates to smart contract definitions have to be approved by channel members, according to the channel lifecycle endorsement policy, before they can be committed to the channel.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-smart-contracts-v2"}, {"document_id": "ibmcld_04002-43529-45898", "score": 11.768981, "text": "\nLater, you decide you do want to run the package on your peers. From the Channels tab, open the smart contract tile and click Update package details next to your organization. If you want to install the existing package, select it from the Existing package tab. Or, upload your own version of the smart contract package. Then select the peers to install it on. Since the smart contract definition is committed, the peer can immediately begin to process requests for the smart contract. \n Install the smart contract on additional or new peers after it is committed to the channel After the smart contract definition is committed, maybe you need to install the smart contract package on additional peers or newly created peers. From the Channels tab, open the smart contract tile and click Update package details next to your organization. If you want to install the existing package, select it from the Existing package tab. Or, upload your own version of the smart contract package. Then select the peers to install it on. Since the smart contract definition is committed, the peer can immediately begin to process requests for the smart contract. \n Change the smart contract endorsement policy of a smart contract definition Because the smart contract endorsement policy of a smart contract is agreed to by members of the channel before the smart contract can be committed to the channel, the endorsement policy cannot be updated without approval of other channel members, as defined in the channel lifecycle endorsement policy. Therefore, if you need to update the endorsement policy of a smart contract proposal or a committed smart contract, then you need to [submit a new proposal](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-smart-contracts-v2ibp-console-smart-contracts-v2-install-propose) with the updated endorsement policy. You do not have to update the smart contract package in this case, but it is required to increment the smart contract version. \n Change the lifecycle endorsement policy for the channel From the Channels tab, click Channel details and click the Settings icon and then click through to the Lifecycle endorsement policy step. \n A new organization joins the channel and wants to approve a smart contract proposal. From the Channels tab, click the tile of the proposed smart contract and click Begin approval process.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-smart-contracts-v2"}, {"document_id": "ibmcld_04002-36866-39079", "score": 11.730028, "text": "\nIf it does, it will get replaced by this proposal. \n Install a different smart contract package than what is included in the smart contract proposal If there are no differences in the agreed to business logic in your smart contract package, you can use your own package instead. From the Channels tab, open the smart contract tile and click either Begin approval process next to your organization. Click Add file to upload your own package or Existing package to select a package that is already installed on a peer in your organization. <br> <br>Note: If the smart contract business logic has changed, you need to submit a new proposal for approval and attach the new smart contract package. \n Update a smart contract package after I submitted the proposal I submitted the proposal, but need to update the smart contract package. If the agreed to business logic has not changed, from the Channels tab, open the smart contract tile and click Update package details next to your organization. Click Add file to upload a [new version](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-smart-contracts-v2ibp-console-smart-contracts-v2-pkg-best-practice) of the smart contract. \n Approve a smart contract definition Open the smart contract tile on the Channels tab. Next to your organization, click Begin approval process. You are required to select which admin identity from your organization will submit the approval. <br> <br>If you are ready to approve the smart contract but are not ready to install it on your peers at this time, when prompted to upload or select an existing package, simply click No to skip this step. A package is not required when you approve a smart contract definition. <br> <br>Or, if you want to install the package that the proposal originator included, click Add file to upload the smart contract package shared with you by the proposal originator out of band. <br> <br>Lastly, you can install your own version of the smart contract, by clicking Add file to upload your own package or Existing package if the package is already installed on another peer in your organization. <br> <br>If you upload or select a new package, you can choose which peers to install it on.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-smart-contracts-v2"}, {"document_id": "ibmcld_13615-5104-6687", "score": 11.462832, "text": "\nA final review of the install is done to ensure what has been deployed meets the order and the additional information gathered. At this point, the order is marked complete.\n\n\n\n\n\n Welcome Letter sent to the client \n\nA welcome letter is then sent to the client which will include the URL's to access each environments, usernames and instructions on how to supply the license file the customer would have received when they purchased the TRIRIGA Application Suite product.\n\nThe letter will contain similar instructions to below:\n\n\n\n* Some IBM products require license keys to use them. The [IBM License Key Center](https://licensing.subscribenet.com/control/ibmr/login) is an online software license key delivery tool that provides easy access to your license keys 24 hours a day, 7 days a week.\n\n\n\n\n\n\n\n How to log in \n\n\n\n* To access your license keys:\n\n\n\n* Please click [here](https://urldefense.proofpoint.com/v2/url?u=https-3A__licensing.subscribenet.com_service_ibmr_passwordfindertoken-3Ftoken-3DiBQqgLdNUxyuxE8Ik8PMKSMDo79ubDnPVuLzb6G50e8V6us7ubXZDYizfshmUft4n9qHifp1xZluaMEBCauDmw-253D-253D&d=DwMDaQ&c=jf_iaSHvJObTbx-siA1ZOg&r=bSeOIO3coRE67_IGnJbSkmdGrML0r3fDG4JKYOYSpt4&m=vXEs4tQw0jGZbxoe8CB4_ay45BzQckFiKIIZfFXQ8oI&s=sUdq8LY1rpYBZyrgdqQXnmvo4BePM0scOTmmhvZXUzE&e=) to create your Password\n* Once you have created your password click on the Attempt to Login link.\n* Select the link to log in to the License Key Center.\n* Select Continue to navigate to the IBM Rational License Key Center.\n* Log in to the License Key Center using your email address as your ID and your password.", "title": "", "source": "https://cloud.ibm.com/docs/tas-ms?topic=tas-ms-provisioning"}, {"document_id": "ibmcld_07011-21108-23747", "score": 11.229678, "text": "\nThis category does not extend to specifications of a party's obligations or rights regarding any purchased goods, services, licenses, and so on, as those goods are the party's own assets, rather than assets of another party. \n Assignments Elements that describe the transfer of rights, obligations, or both to a third party. \n Audits Elements referring to either the right of a party to examine or review compliance, or requirements that a party be available for inspection or compliance review. This category includes references to record keeping (primarily as it relates to the right of inspection) and the maintenance and retention of activity records that may be examined. \n Business Continuity Elements referring to the consequences if the entire business of one of the parties is sold. \n Communication Elements referring to requirements to communicate, respond, notify, or provide notice; contact information; or information regarding changes to the contract. Also includes references to details about communication methods, the act or process of exchanging information, and acceptable means of exchanging information between parties (and others who are not necessarily direct parties to the contract). \n Confidentiality Elements describing how parties can or cannot use information that is learned in the course of completing the contract and going forward. Also includes discussion of information that must be kept confidential, such as maintaining trade secrets or nondisclosure of business information. \n Deliverables Elements specifying the items, such as goods or services, that one party provides to another under the terms of the contract, usually in exchange for payment. Includes discussion of preparation of deliverables. \n Delivery Elements that specify the means or modes of transferring deliverables (things, as opposed to personal services) from one party to another. Includes discussions of characteristics of delivery, such as scheduling or location. \n Dispute Resolution Elements discussing provisions for settling any dispute (for example, regarding labor, invoices, or billing) arising between contracting parties. Provision examples may include settlement by a defined procedure such as an arbitration panel, a process for obtaining an injunction, waiving a right to trial, or prohibiting the pursuit of a class action. Also includes references to the contract's governing law or choice of law, such as a particular country or jurisdiction. \n Force Majeure Elements that refer to unexpected or disruptive events outside a party's control that would relieve the party from performing their contractual obligation.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-contracts-schema"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10166-8569-11030", "score": 27.310339, "text": "\n* [SDK for Node.js](https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-getting-started-node)\n\n\n\n\n\n Context \n\nPort secures exchange of port data and shipping manifests that connects public and private organizations.\n\n\n\n* Disparate groups of Developers from the government and shipping company don\u2019t have a unified platform where they can collaborate, which slows down deployments of updates and features.\n* Developers are spread across the globe and across organizational boundaries, which means open-source and PaaS the best option.\n* Security is a primary concern, and this concern increases the collaboration burden that impacts features and updates to the software, especially after the apps are in production.\n* Just-in-time data meant that the worldwide systems must be highly available to reduce lags in transit operations. Time tables for shipping terminals are highly controlled and sometimes inflexible. Web usage is growing, so instability might cause poor user experience.\n\n\n\n\n\n\n\n Solution \n\nThe port and the shipping company co-develop a unified trading system to electronically submit compliance-related information for the clearance of goods and ships once, rather than to multiple agencies. Manifest and customs apps can quickly share contents of a particular shipment and ensure that all paperwork is electronically transferred and processed by agencies for the port.\n\nSo they create a partnership that is dedicated to solutions for the trade system.\n\n\n\n* DECLARATIONS - App to take in shipping manifests and digitally process typical customs paperwork and to option out-of-policy items for investigation and enforcement\n* TARIFFS \u2013 App to calculate tariffs, submit charges electronically to shipper, and receive digital payments\n* REGULATIONS \u2013 Flexible and configurable app that feeds previous two apps with ever-changing policies and regulations that affect imports, exports, and tariff processing\n\n\n\nDevelopers started by deploying their apps in containers with Red Hat OpenShift on IBM Cloud. They created clusters for a shared Dev environment that allow worldwide Developers to collaboratively deploy app improvements quickly. Containers allow each development team to use the language of their choice.\n\nSecurity first: The IT Execs chose bare metal clusters. With bare metal for Red Hat OpenShift on IBM Cloud, the sensitive customs workloads now have familiar isolation but within the flexibility of public cloud.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_gov"}, {"document_id": "ibmcld_10392-6380-7520", "score": 27.118526, "text": "\n: Red Hat OpenShift on IBM Cloud clusters are connected to [remote health monitoring](https://docs.openshift.com/container-platform/4.13/support/remote_health_monitoring/about-remote-health-monitoring.html) by default. This means clusters report health and usage data to Red Hat unless you opt out. With connected clusters, IBM Cloud is better positioned to support customers when there are issues specific to Red Hat which impact them. Additionally, remote health reporting gives Red Hat insights into how clusters are impacted by product upgrades. If you do not want to send cluster data to Red Hat, you must opt out. For more information, see [Understanding remote health monitoring](https://cloud.ibm.com/docs/openshift?topic=openshift-remote-health-monitoring-opt-out).\n\n\n\n\n\n 9 June 2023 \n\nNew! OpenShift Data Foundation add-on versions 4.12.5, 4.11.11, 4.10.26, and 4.9.28.\n: For more information, see the [change log](https://cloud.ibm.com/docs/openshift?topic=openshift-odf_addon_changelog).\n\n\n\n\n\n 5 June 2023 \n\nWorker node fix packs 4.9.59_1592_openshift, 4.10.60_1571_openshift, 4.11.42_1558_openshift, and 4.12.19_1546_openshift.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-relnotes"}, {"document_id": "ibmcld_10167-8650-10995", "score": 26.930328, "text": "\nInstead, their work's isolated in pockets across the globe due to regional compliance regulations and centralized databases.\n\nRed Hat OpenShift on IBM Cloud delivers secure compute that can host sensitive and data processing on an open platform. That global platform is hosted in near-by regions. So it's tied to local regulations that inspire patients\u2019 and researchers\u2019 confidence that their data is both protected locally and makes a difference in better health outcomes.\n\n\n\n Context \n\nSecurely hosting and sharing disease data for Research Nonprofit\n\n\n\n* Disparate groups of researchers from various institutions don\u2019t have a unified way to share data, slowing down collaboration.\n* The security concern adds to the collaboration burden that causes even less shared research.\n* Developers and Researchers are spread across the globe and across organizational boundaries, which make PaaS and SaaS the best option for each user group.\n* Regional differences in health regulations require some data and data processing to remain within that region.\n\n\n\n\n\n\n\n Solution \n\nSecurely hosting and sharing disease data for Research Nonprofit.\n\nThe research nonprofit wants to aggregate cancer research data across the globe. So they create a division that is dedicated to solutions for their researchers.\n\n\n\n* INGEST - Apps to ingest research data. Researchers today use spreadsheets, documents, commercial products, and proprietary or home-grown databases to record research results. This situation is unlikely to change with the nonprofit's attempt to centralize data analysis.\n* ANONYMIZE - Apps to anonymize the data. SPI must be removed to comply with regional health regulations.\n* ANALYZE - Apps to analyze the data. The basic pattern is to store the data in a regular format and then to query and process it by using AI and machine learning (ML) technology, simple regressions, and so forth.\n\n\n\nResearchers need to affiliate with a regional cluster, and apps ingest, transform, and anonymize the data.\n\n\n\n1. Syncing the anonymized data across regional clusters or shipping them to a centralized data store\n2. Processing the data, by using ML like PyTorch on bare metal worker nodes that provide GPUs\n\n\n\nINGEST\n: IBM Cloudant is used at each regional cluster that stores researchers\u2019 rich data documents and can be queried and processed as needed.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_health"}, {"document_id": "ibmcld_10166-10513-12864", "score": 26.617836, "text": "\nDevelopers started by deploying their apps in containers with Red Hat OpenShift on IBM Cloud. They created clusters for a shared Dev environment that allow worldwide Developers to collaboratively deploy app improvements quickly. Containers allow each development team to use the language of their choice.\n\nSecurity first: The IT Execs chose bare metal clusters. With bare metal for Red Hat OpenShift on IBM Cloud, the sensitive customs workloads now have familiar isolation but within the flexibility of public cloud.\n\nBecause the shipping company also wants to work with other ports, app security is crucial. Shipping manifests and customs information are highly confidential. From that secure core, Vulnerability Advisor provides these scans:\n\n\n\n* Image vulnerability scans\n* Policy scans that are based on ISO 27k\n\n\n\nAt the same time, IBM Cloud\u00ae Identity and Access Management helps to control who has which level of access to the resources.\n\nDevelopers focus on domain problems, by using existing tools: Instead of Developers that write unique logging and monitoring code, they snap it into apps, by binding IBM Cloud services to clusters. Developers are also freed up from infrastructure management tasks because IBM takes care of Kubernetes and infrastructure upgrades, security, and more.\n\nCompute, storage, and apps run in the public cloud with secure access to shipping data across the globe, as needed. Compute in clusters is tamper-proof and isolated to bare metal.\n\nTechnical solution:\n\n\n\n* Red Hat OpenShift on IBM Cloud\n* IBM Cloud\u00ae Functions\n* IBM Cloudant\n* IBM Secure Gateway\n\n\n\n\n\n Step 1: Containerize apps, by using microservices \n\n\n\n* Create a Node.js app or deploy an example.\n* Structure apps into a set of cooperative microservices that run within Red Hat OpenShift on IBM Cloud based on functional areas of the app and its dependencies.\n* Deploy the manifest and shipment apps to container that run in Red Hat OpenShift on IBM Cloud.\n* Provide standardized DevOps dashboards through Kubernetes.\n* Use IBM Secure Gateway to maintain secure connections to existing on-premises databases.\n\n\n\n\n\n\n\n Step 2: Ensure global availability \n\n\n\n* After Developers deploy the apps in their Dev and Test clusters, they use the IBM Cloud\u00ae Continuous Delivery toolchains and Helm to deploy country-specific apps into clusters across the globe.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_gov"}, {"document_id": "ibmcld_10154-7-1896", "score": 26.478222, "text": "\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https://www.ibm.com/products/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov"}, {"document_id": "ibmcld_10235-1083-2772", "score": 26.38051, "text": "\nClusters with public network connectivity: [Multiple clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-ha_clustersmultiple-clusters-glb) that are set up across zones or regions and that are connected via a global load balancer.\n\n\n\n\n\n Single zone clusters \n\nSingle zone clusters can be created in one of the supported [single zone locations](https://cloud.ibm.com/docs/openshift?topic=openshift-regions-and-zoneszones-sz). To improve availability for your app and to allow failover for the case that one worker node is not available in your cluster, add additional worker nodes to your single zone cluster.\n\nVPC clusters are supported only in [multizone metro locations](https://cloud.ibm.com/docs/openshift?topic=openshift-regions-and-zoneszones-vpc). If your cluster must reside in one of the single zone cities, create a classic cluster instead.\n\nZoom\n\n![High availability for clusters in a single zone.](https://cloud.ibm.com/docs-content/v1/content/bce0f0917a9eea684d1b4b704ac6343a1f65f446/openshift/images/ha-cluster-singlezone.svg)\n\nFigure 1. High availability for clusters in a single zone\n\nYou can add more worker nodes to your cluster by [resizing an existing worker pool](https://cloud.ibm.com/docs/openshift?topic=openshift-add_workersresize_pool) or by [adding a new worker pool](https://cloud.ibm.com/docs/openshift?topic=openshift-add_workersadd_pool). When you add more worker nodes, app instances can be distributed across multiple worker nodes. If one worker node goes down, app instances on available worker nodes continue to run. Red Hat OpenShift automatically reschedules pods from unavailable worker nodes to ensure performance and capacity for your app.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ha_clusters"}, {"document_id": "ibmcld_10568-21131-23284", "score": 26.34873, "text": "\nInstead of making more clusters, you can add worker pools for different flavors of computing resources available for the app and service components that you want to use. When you develop the app, the resources it uses are in the same zone, or otherwise closely connected in a multizone, so that you can make assumptions about latency, bandwidth, or correlated failures. However, it becomes even more important for you to organize your cluster by using namespaces, resource quotas, and labels.\n\n\n\n\n\n How can I set up my resources within the cluster? \n\n\n\n Consider your worker node capacity \n\nTo get the most out of your worker node's performance, consider the following: - Keep up your core strength: Each machine has a certain number of cores. Depending on your app's workload, set a limit for the number of pods per core, such as 10. - Avoid node overload: Similarly, just because a node can contain more than 100 pods doesn't mean that you want it to. Depending on your app's workload, set a limit for the number of pods per node, such as 40. - Don't tap out your cluster bandwidth**: Keep in mind that network bandwidth on scaling virtual machines is around 1000 Mbps. If you need hundreds of worker nodes in a cluster, split it up into multiple clusters with fewer nodes, or order bare metal nodes. - Sorting out your services: Plan out how many services that you need for your workload before you deploy. Networking and port forwarding rules are put into Iptables. If you anticipate a larger number of services, such as more than 5,000 services, split up the cluster into multiple clusters.\n\n\n\n\n\n Provision different types of machines for a mix of computing resources \n\nEveryone likes choices, right? With Red Hat OpenShift on IBM Cloud, you have [a mix of flavors](https://cloud.ibm.com/docs/openshift?topic=openshift-planning_worker_nodesplanning_worker_nodes) that you can deploy: from bare metal for intensive workloads to virtual machines for rapid scaling. Use labels or namespaces to organize deployments to your machines. When you create a deployment, limit it so that your app's pod deploys only on machines with the best mix of resources.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-strategy"}, {"document_id": "ibmcld_10235-7-1701", "score": 26.10609, "text": "\nPlanning your cluster for high availability \n\nDesign your standard cluster for maximum availability and capacity for your app with Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae.\n\nYour users are less likely to experience downtime when you distribute your apps across multiple worker nodes, zones, and clusters. Built-in capabilities, like load balancing and isolation, increase resiliency against potential failures with hosts, networks, or apps. Review these potential cluster setups that are ordered with increasing degrees of availability.\n\nZoom\n\n![High availability for clusters](https://cloud.ibm.com/docs-content/v1/content/bce0f0917a9eea684d1b4b704ac6343a1f65f446/openshift/images/cs_cluster_ha_roadmap_multizone_public.png)\n\nFigure 1. High availability for clusters\n\n\n\n1. A [single zone cluster](https://cloud.ibm.com/docs/openshift?topic=openshift-ha_clusterssingle_zone) with multiple worker nodes in a worker pool.\n2. A [multizone cluster](https://cloud.ibm.com/docs/openshift?topic=openshift-ha_clustersmz-clusters) that spreads worker nodes across zones within one region.\n3. Clusters with public network connectivity: [Multiple clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-ha_clustersmultiple-clusters-glb) that are set up across zones or regions and that are connected via a global load balancer.\n\n\n\n\n\n Single zone clusters \n\nSingle zone clusters can be created in one of the supported [single zone locations](https://cloud.ibm.com/docs/openshift?topic=openshift-regions-and-zoneszones-sz). To improve availability for your app and to allow failover for the case that one worker node is not available in your cluster, add additional worker nodes to your single zone cluster.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ha_clusters"}, {"document_id": "ibmcld_10392-147082-148053", "score": 26.055101, "text": "\n: You can create or [update](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versions) your cluster to Red Hat OpenShift version 4.6, which includes Kubernetes 1.19. With Red Hat OpenShift 4.6, you get the latest stable enhancements from the community. For more information, see the [blog announcement](https://www.ibm.com/cloud/blog/announcements/openshift-version-46-now-available-in-red-hat-openshift-on-ibm-cloud).\n\nDeprecated Red Hat OpenShift 4.4\n: With the release of Red Hat OpenShift 4.6, clusters that run version 4.4 are deprecated, with an unsupported date of 31 May 2021. Update your cluster to at least [version 4.5](https://cloud.ibm.com/docs/openshift?topic=openshift-changelog_archive) as soon as possible.\n\n\n\n\n\n 15 February 2021 \n\nNew! Osaka multizone region\n: You can now create classic or VPC clusters in the Osaka, Japan (jp-osa) [location](https://cloud.ibm.com/docs/openshift?topic=openshift-regions-and-zones).\n\nWorker node versions", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-relnotes"}, {"document_id": "ibmcld_10392-183275-184540", "score": 26.037682, "text": "\n: Red Hat OpenShift [4.4.16_1513_openshift](https://cloud.ibm.com/docs/openshift?topic=openshift-changelog_archive4416_1513_master), [4.3.31_1534_openshift](https://cloud.ibm.com/docs/openshift?topic=openshift-changelog_archive4331_1534_master), and [3.11.248_1564_openshift](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_changelog_311311248_1564_master).\n\n\n\n\n\n 17 August 2020 \n\nLocations\n: You can create [clusters on VPC infrastructure](https://cloud.ibm.com/docs/openshift?topic=openshift-regions-and-zoneszones-vpc) in the Tokyo multizone region.\n\nVersions\n: Worker node fix pack update change log documentation is available.\n: Red Hat OpenShift [4.4.16_1513_openshift](https://cloud.ibm.com/docs/openshift?topic=openshift-changelog_archive4416_1513), [4.3.31_1534_openshift](https://cloud.ibm.com/docs/openshift?topic=openshift-changelog_archive4331_1534), and [3.11.248_1564_openshift](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_changelog_311311248_1564)..\n\n\n\n\n\n 6 August 2020 \n\nCLI change log\n: Updated the Red Hat OpenShift on IBM Cloud CLI plug-in change log page for the [release of version 1.0.143](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_cli_changelog10).\n\n\n\n\n\n 5 August 2020 \n\nIngress ALB change log", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-relnotes"}]}
{"task_id": "1065ea5ad1ae2b90e6fce67d851a7a66<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10817-2884-4620", "score": 17.101849, "text": "\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in /Library/Developer/Xcode/DerivedData/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_10817-7-1802", "score": 17.06231, "text": "\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_10852-44214-45420", "score": 16.54102, "text": "\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_02772-2964-4516", "score": 16.193567, "text": "\nThis can be found in the Service Credentials tab of your service dashboard.\n* Your instance's deployment IBM Cloud region. You can find your region by looking at the console.\n\n\n\nTable 1. IBM Cloud regions and corresponding SDK values\n\n IBM Cloud Region SDK value \n\n US South AppID.REGION_US_SOUTH \n Sydney AppID.REGION_SYDNEY \n United Kingdom AppID.REGION_UK \n Germany AppID.REGION_GERMANY \n\n\n\n\n\n\n\n\n\n\n\n Authenticating with the Android SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you can get started:\n\n\n\n* API 27 or higher\n* Java 8.x\n* Android SDK Tools 26.1.1+\n* Android SDK Platform Tools 27.0.1+\n* Android Build Tools version 27.0.0+\n\n\n\n\n\n\n\n Installing the SDK \n\n\n\n1. Create an Android Studio project or open an existing project.\n2. Add the JitPack repository to your root build.gradle file.\n\nallprojects {\nrepositories {\n...\nmaven { url 'https://jitpack.io' }\n}\n}\n3. Find your application's build.gradle file. Note: Be sure to open the file for your app, not the project build.gradle file.\n\n\n\n1. Add the App ID client SDK to the dependencies section.\n\ndependencies {\ncompile group: 'com.github.ibm-cloud-security:appid-clientsdk-android:4.+'\n}\n2. In the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-mobile-apps"}, {"document_id": "ibmcld_02772-4213-5899", "score": 15.979497, "text": "\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-mobile-apps"}, {"document_id": "ibmcld_10817-6582-8092", "score": 15.84234, "text": "\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http://localhost:8080\"\n\nIn this example, you use an installation that is running at http://localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https://us-south.functions.cloud.ibm.com](https://us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n// create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n// create an NSURLSession that uses the trusting delegate", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_04518-7-1743", "score": 15.549691, "text": "\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https://cocoapods.org) or [Carthage](https://github.com/Carthage/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_07546-7265-8726", "score": 15.091539, "text": "\nimport com.ibm.mobilefirstplatform.clientsdk.android.push.api.MFPPush;\n\n// with this\n\nimport com.ibm.cloud.eventnotifications.destination.android.ENPush;\n3. Initialize the new SDK\n\n// Replace the below section\n\nBMSClient.getInstance().initialize(this, \"ibmCloudRegionSuffix\");\nMFPPush push = MFPPush.getInstance();\npush.initialize(getApplicationContext(), \"appGUID\", \"clientSecret\");\n\n// with this\n\nString instanceGUID = \"<instance_guid>>\";\nString destinationID = \"<instance_destination_id>\";\nString apiKey = \"<instance_apikey>\";\n\nENPush enPush = ENPush.getInstance();\npush.setCloudRegion(ENPush.REGION_US_SOUTH); // Set your region\n\npush.initialize(getApplicationContext(),instanceGUID,destinationID, apiKey);\nShow more\n\nThere are additional fields like destinationID and apikey in the new initialize() method.\n\nFor more information, on getting the apikey for client SDK see [Managing service access](https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-service-access-management).\n4. The callback class in the new SDK has changes. Make these changes in the listener.\n\n// Replace the below section\n\nMFPPushNotificationListener notificationListener = new MFPPushNotificationListener() {\n\n@Override\npublic void onReceive (final MFPSimplePushNotification message){\n// Handle Push Notification\n}\n};\n\npush.listen(notificationListener)\n\n// with this\n\nENPushNotificationListener notificationListener = new ENPushNotificationListener() {\n\n@Override", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-migrate-apps"}, {"document_id": "ibmcld_12339-0-1594", "score": 14.951637, "text": "\n\n\n\n\n\n\n  Java \n\nAs a standard bearer for enterprise application development and the native application language for Android, Java is a key language to support for your IBM Cloud service.\n\n\n\n  Content \n\n\n\n  Methods \n\nMethod parameters MUST be encapsulated into an \u201coptions\u201d object that can be constructed with a \"Builder\".\n\n\n\n\n\n  Streaming \n\nThe SDK SHOULD accept parameters with potentially large memory requirements as InputStream values, to allow the value to be streamed to the service.\n\n\n\n\n\n\n\n  Style guidelines \n\nFor services that support both a traditional Java SDK and an Android SDK, the Java SDK SHOULD be designed to be Android compatible, to minimize duplication of code.\n\nYou should follow a coding style based on the [Google Java Style Guide](https://google.github.io/styleguide/javaguide.html).\n\nYou should use the standard [development tools](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-devtools) for Java to check style and code coverage.\n\n\n\n\n\n  Documentation \n\nYour SDK is not useful if your audience cannot understand how to consume it in order to do the basic operations for your service. Your SDK needs to contain the following resources to help your users:\n\n\n\n*  README.md\n*  [Contributor guidelines](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-documentationsdk-contributor-docs)\n*  Code Samples\n*  [Service documentation](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-documentation)\n\n\n\n\n\n\n\n  Distribution \n\n\n\n  Package management \n\nOfficial SDK releases MUST be published in [Maven Central](https://search.maven.org/).\n\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-java"}, {"document_id": "ibmcld_10817-1342-3184", "score": 14.889403, "text": "\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage/build/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}]}
{"task_id": "1065ea5ad1ae2b90e6fce67d851a7a66<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10852-44214-45420", "score": 26.889296, "text": "\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_10817-1342-3184", "score": 24.884077, "text": "\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage/build/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_04518-7-1743", "score": 24.272055, "text": "\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https://cocoapods.org) or [Carthage](https://github.com/Carthage/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_04518-1426-3052", "score": 22.949425, "text": "\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https://github.com/Carthage/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https://github.com/Carthage/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_07551-15747-17355", "score": 22.511463, "text": "\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https://github.com/IBM/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n/Register iOS devices/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_10817-7-1802", "score": 22.127214, "text": "\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_12332-1034-2510", "score": 19.386768, "text": "\nYour Go SDK should be packaged as a [Go Module](https://blog.golang.org/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https://search.maven.org/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https://www.npmjs.com/) package within the [ibm-cloud](https://www.npmjs.com/org/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https://pypi.python.org/) / [pip](https://pypi.python.org/pypi/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https://swift.org/package-manager/) / [CocoaPods](https://cocoapods.org/) / [Carthage](https://github.com/Carthage/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https://github.com/IBM/ibm-cloud-sdk-common).", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-devtools"}, {"document_id": "ibmcld_10852-43319-44485", "score": 18.962902, "text": "\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_10817-2884-4620", "score": 18.595867, "text": "\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in /Library/Developer/Xcode/DerivedData/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_07551-14062-16080", "score": 17.257563, "text": "\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https://jsonpath.com/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}]}
{"task_id": "1065ea5ad1ae2b90e6fce67d851a7a66<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10852-44214-45420", "score": 18.880928, "text": "\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_10817-1342-3184", "score": 17.436277, "text": "\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage/build/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_04518-1426-3052", "score": 16.820354, "text": "\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https://github.com/Carthage/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https://github.com/Carthage/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_07551-15747-17355", "score": 16.646627, "text": "\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https://github.com/IBM/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n/Register iOS devices/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_12332-1034-2510", "score": 14.858658, "text": "\nYour Go SDK should be packaged as a [Go Module](https://blog.golang.org/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https://search.maven.org/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https://www.npmjs.com/) package within the [ibm-cloud](https://www.npmjs.com/org/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https://pypi.python.org/) / [pip](https://pypi.python.org/pypi/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https://swift.org/package-manager/) / [CocoaPods](https://cocoapods.org/) / [Carthage](https://github.com/Carthage/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https://github.com/IBM/ibm-cloud-sdk-common).", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-devtools"}, {"document_id": "ibmcld_04518-7-1743", "score": 14.2721, "text": "\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https://cocoapods.org) or [Carthage](https://github.com/Carthage/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_10852-43319-44485", "score": 12.487228, "text": "\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_07551-14062-16080", "score": 12.324797, "text": "\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https://jsonpath.com/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_10817-7-1802", "score": 11.676287, "text": "\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_05427-6937-8885", "score": 11.547931, "text": "\nExamples of such workloads are websites, chatbots, and mobile applications. Use [applications](https://cloud.ibm.com/docs/codeengine?topic=codeengine-application-workloads).\n\nIs your computation lightweight and does it require low CPU, memory, and I/O?\n: If your workload is lightweight and requires low CPU, memory, and I/O, then the concurrency option, available for applications might be helpful. A typical example is an API Server that provides basic operations and is backed with a NoSQL database. These types of requests typically have a small amount of data and require low memory or fewer CPU cycles. With higher concurrency, the application can process the data of a first request while the second request is waiting for I/O. Because the CPU and memory requirements are low, many requests can be run concurrently. Use [applications](https://cloud.ibm.com/docs/codeengine?topic=codeengine-application-workloads).\n\nIs your computation bound to CPU, memory, or I/O?\n: To process a specific amount of data, where each chunk of the data is large and requires a large amount of CPU and memory, jobs are typically the better choice. However, if the workload requires a request-response pattern, it's also possible to use apps. In both cases, the computation task runs with single concurrency. Each application instance or job task processes only one request or chunk of data concurrently to fully leverage the resources that are configured for the instance. Parallelism is achieved by the number of instances or tasks, where the cost of creating an additional task is negligible due to the high resource constraints. A typical example is the processing of image data in a Object Storage bucket or serving machine learning models. Use [applications](https://cloud.ibm.com/docs/codeengine?topic=codeengine-application-workloads) or [jobs](https://cloud.ibm.com/docs/codeengine?topic=codeengine-job-plan).\n\nDoes your computation run for a long time?", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-plan-codeengine"}]}
{"task_id": "1065ea5ad1ae2b90e6fce67d851a7a66<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07549-9127-11441", "score": 9.66686, "text": "\nA \"Major Component\", in this context, means a major essential component (kernel, window system, and so on) of the specific operating system (if any) on which the executable work runs, or a compiler used to produce the work, or an object code interpreter used to run it.The \"Corresponding Source\" for a work in object code form means all the source code needed to generate, install, and (for an executable work) run the object code and to modify the work, including scripts to control those activities. However, it does not include the work's System Libraries, or general-purpose tools or generally available free programs which are used unmodified in performing those activities but which are not part of the work. For example, Corresponding Source includes interface definition files associated with source files for the work, and the source code for shared libraries and dynamically linked subprograms that the work is specifically designed to require, such as by intimate data communication or control flow between those subprograms and other parts of the work.The Corresponding Source need not include anything that users can regenerate automatically from other parts of the Corresponding Source.The Corresponding Source for a work in source code form is that same work.<-- </section \"id=\"section-en-notice-source-code\" \"> --><-- <section \"id=\"section-en-notice-permissions\" \"> --> 2. Basic Permissions All rights granted under this License are granted for the term of copyright on the Program, and are irrevocable provided the stated conditions are met. This License explicitly affirms your unlimited permission to run the unmodified Program. The output from running a covered work is covered by this License only if the output, given its content, constitutes a covered work. This License acknowledges your rights of fair use or other equivalent, as provided by copyright law.You may make, run and propagate covered works that you do not convey, without conditions so long as your license otherwise remains in force. You may convey covered works to others for the sole purpose of having them make modifications exclusively for you, or provide you with facilities for running those works, provided that you comply with the terms of this License in conveying all material for which you do not control copyright.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-notices"}, {"document_id": "ibmcld_07549-7562-9628", "score": 9.5918045, "text": "\nMere interaction with a user through a computer network, with no transfer of a copy, is not conveying.An interactive user interface displays \"Appropriate Legal Notices\" to the extent that it includes a convenient and prominently visible feature that (1) displays an appropriate copyright notice, and (2) tells the user that there is no warranty for the work (except to the extent that warranties are provided), that licensees may convey the work under this License, and how to view a copy of this License. If the interface presents a list of user commands or options, such as a menu, a prominent item in the list meets this criterion.<-- </section \"id=\"section-en-notice-def\" \"> --><-- <section \"id=\"section-en-notice-source-code\" \"> --> 1. Source Code The \"source code\" for a work means the preferred form of the work for making modifications to it. \"Object code\" means any non-source form of a work. A \"Standard Interface\" means an interface that either is an official standard defined by a recognized standards body, or, in the case of interfaces specified for a particular programming language, one that is widely used among developers working in that language.The \"System Libraries\" of an executable work include anything, other than the work as a whole, that (a) is included in the normal form of packaging a Major Component, but which is not part of that Major Component, and (b) serves only to enable use of the work with that Major Component, or to implement a Standard Interface for which an implementation is available to the public in source code form. A \"Major Component\", in this context, means a major essential component (kernel, window system, and so on) of the specific operating system (if any) on which the executable work runs, or a compiler used to produce the work, or an object code interpreter used to run it.The \"Corresponding Source\" for a work in object code form means all the source code needed to generate, install, and (for an executable work) run the object code and to modify the work, including scripts to control those activities.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-notices"}, {"document_id": "ibmcld_05345-10257-10916", "score": 9.536362, "text": "\nFor example, you might choose to let Code Engine handle the build of your local source while you evolve the development of your source for the job. Then, after the image is matured, you can update the job to reference the specific image that you want. You can repeat this process as needed.\n\nWhen you run your updated job, the latest version of your referenced container image is used for the job run, unless a tag is specified for the image. If a tag is specified for the image, then the tagged image is used for the job run.\n\n\n\nLooking for more code examples? Check out the [Samples for IBM Cloud Code Engine GitHub repo](https://github.com/IBM/CodeEngine).", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-create-job-crimage"}, {"document_id": "ibmcld_05381-12009-12668", "score": 9.536362, "text": "\nFor example, you might choose to let Code Engine handle the build of your local source while you evolve the development of your source for the job. Then, after the image is matured, you can update the job to reference the specific image that you want. You can repeat this process as needed.\n\nWhen you run your updated job, the latest version of your referenced container image is used for the job run, unless a tag is specified for the image. If a tag is specified for the image, then the tagged image is used for the job run.\n\n\n\nLooking for more code examples? Check out the [Samples for IBM Cloud Code Engine GitHub repo](https://github.com/IBM/CodeEngine).", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-job-local-source-code"}, {"document_id": "ibmcld_05479-10852-12364", "score": 9.4615755, "text": "\nIn the prior example, specify the SSH URL by using the git@ prefix for your source, such as --source git@github.com:IBM/CodeEngine.git.\n\n\n\n\n\n\n\n\n\n Resolution for a wrong revision during build \n\nA build configuration specifies the source repository by using its URL and optionally a revision. The revision can be either the name of a branch or tag, or a commit identifier. By default, the main branch is built. Review the error message for information about something that was specified but does not exist.\n\n\n\n1. Use the [ibmcloud ce build update](https://cloud.ibm.com/docs/codeengine?topic=codeengine-clicli-build-update) command to update the build configuration to use a correct revision (or commit); for example,\n\nibmcloud ce build update --name <BUILD_NAME> --commit <COMMIT>\n2. Use the [ibmcloud ce buildrun submit](https://cloud.ibm.com/docs/codeengine?topic=codeengine-clicli-buildrun-submit) command to submit a new build run. For the buildrun submit command, you must specify the --build option to provide the name of your build configuration. You can optionally specify the --name option to provide the name for this build run. If you specify the --name option, make sure that you use a different build run name from the failed build run, or ensure that you delete the failed build run by using the [ibmcloud ce buildrun delete](https://cloud.ibm.com/docs/codeengine?topic=codeengine-clicli-buildrun-delete) command. For example,\n\nibmcloud ce buildrun submit --build <BUILD_NAME> --name <BUILDRUN_NAME>", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-ts-build-gitsource-stepfail"}, {"document_id": "ibmcld_05272-18290-20032", "score": 9.249037, "text": "\n* Code Engine automatically determines whether your source resides in a repo or on a local workstation, based on the value of the --source option.\n\n\n\nThe following table summarizes the options that are used with the buildrun submit command in this example. For more information about the command and its options, see the [ibmcloud ce buildrun submit](https://cloud.ibm.com/docs/codeengine?topic=codeengine-clicli-buildrun-submit) command.\n\n\n\nTable 3. Command description\n\n Option Description \n\n --name The name of the build run. Use a name that is unique within the project. This value is required.<br><br><br><br> * The name must begin and end with a lowercase letter.<br> * The name must be 63 characters or fewer and can contain lowercase alphanumeric characters and hyphens (-).<br><br><br> \n --source The URL of the Git repository or the path to the local source that contains your source code; for example, git@github.com:myprivaterepo/builds.git. \n --context-dir The directory in the repository that contains the buildpacks file or the Dockerfile. Specify this value if your buildpacks file or Dockerfile is contained in a subdirectory. \n --strategy The strategy to use for building the image. Valid values are dockerfile and buildpacks. \n --git-repo-secret The name of the SSH secret, which contains the credentials to access the private repository that contains the source code to build your container image. Run the secret create --ssh command to create this secret. An SSH secret is also used as a Git repository access secret. \n\n\n\n2. Use the buildrun get command to check the status of your build run.\n\nibmcloud ce buildrun get --name helloworld-buildrun-private\n\nExample output\n\nGetting build run 'helloworld-buildrun-private'...", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-build-standalone"}, {"document_id": "ibmcld_05264-8497-9782", "score": 9.065492, "text": "\n--build-source The URL of the Git repository that contains your source code; for example, https://github.com/IBM/CodeEngine. \n --build-context-dir The directory in the repository that contains the buildpacks file or the Dockerfile. This value is optional. \n\n\n\nThe following output shows the result of the application get command for this example, including information about the build.\n\nExample output\n\n[...]\nName: myapp\nID: abcdefgh-abcd-abcd-abcd-1a2b3c4d5e6f\nProject Name: myproject\nProject ID: 01234567-abcd-abcd-abcd-abcdabcd1111\nAge: 2d15h\nCreated: 2022-04-14T16:10:11-04:00\nURL: https://myapp.4svg40kna19.us-south.codeengine.appdomain.cloud\nCluster Local URL: http://myapp.4svg40kna19.svc.cluster.local\nConsole URL: https://cloud.ibm.com/codeengine/project/us-south/01234567-abcd-abcd-abcd-abcdabcd1111/application/myapp/configuration\nStatus Summary: Application deployed successfully\n\nEnvironment Variables:\nType Name Value\nLiteral CE_APP myapp\nLiteral CE_DOMAIN us-south.codeengine.appdomain.cloud\nLiteral CE_SUBDOMAIN 4svg40kna19\nImage: private.us.icr.io/ce--27fe9-4svg40kna19/app-myapp:220414-2010-sqsoj\nResource Allocation:\nCPU: 1\nEphemeral Storage: 400M\nMemory: 4G\nRegistry Secrets:\nce-auto-icr-private-us-south\n\nRevisions:\nmyapp-00001:\nAge: 23m\nLatest: true\nTraffic: 100%", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-app-source-code"}, {"document_id": "ibmcld_07549-15470-17876", "score": 9.037603, "text": "\nConveying Non-Source Forms You may convey a covered work in object code form under the terms of sections 4 and 5, provided that you also convey the machine-readable Corresponding Source under the terms of this License, in one of these ways:a) Convey the object code in, or embodied in, a physical product (including a physical distribution medium), accompanied by the Corresponding Source fixed on a durable physical medium customarily used for software interchange.b) Convey the object code in, or embodied in, a physical product (including a physical distribution medium), accompanied by a written offer, valid for at least three years and valid for as long as you offer spare parts or customer support for that product model, to give anyone who possesses the object code either (1) a copy of the Corresponding Source for all the software in the product that is covered by this License, on a durable physical medium customarily used for software interchange, for a price no more than your reasonable cost of physically performing this conveying of source, or (2) access to copy the Corresponding Source from a network server at no charge.c) Convey individual copies of the object code with a copy of the written offer to provide the corresponding Source. This alternative is allowed only occasionally and noncommercially, and only if you received the object code with such an offer, in accord with subsection 6b.d) Convey the object code by offering access from a designated place (gratis or for a charge), and offer equivalent access to the Corresponding Source in the same way through the same place at no further charge. You need not require recipients to copy the Corresponding Source along with the object code. If the place to copy the object code is a network server, the Corresponding Source may be on a different server (operated by you or a third party) that supports equivalent copying facilities, provided you maintain clear directions next to the object code saying where to find the Corresponding Source. Regardless of what server hosts the Corresponding Source, you remain obligated to ensure that it is available for as long as needed to satisfy these requirements.e) Convey the object code using peer-to-peer transmission, provided you inform other peers where the object code and Corresponding Source of the work are being offered to the general public at no charge under subsection 6d.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-notices"}, {"document_id": "ibmcld_05413-7276-9171", "score": 8.949966, "text": "\nThis service ID must be authorized to read and write to IBM Cloud Container Registry. If no service ID exists, Code Engine creates one for you. Note that this service ID is used for subsequent Code Engine build requests that are run from the same project.\n3. This example builds code from a local source (--build-source .). The source code is packed into an archive file and uploaded to a managed namespace within the IBM Cloud Container Registry instance in your account. Note that you can target only IBM Cloud Container Registry for your local builds. For more information about IBM Container Registry, including information about quota limits and access, see [Getting started with IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-started).\n4. Code Engine builds your source code into an image. The source image is created in the same namespace as your source archive file.\n5. After the build completes, your application is deployed. You can access your application from the provided URL.\n\n\n\nWith Code Engine, you automatically get many of the same features as Cloud Foundry, such as autoscaling and blue-green roll-out of updates, but you'll also enjoy the benefits of newer features such as scaling down-to-zero, ensuring that you are not charged if your application is not active.\n\nWant to learn more about your options for building your source code? See the [application create](https://cloud.ibm.com/docs/codeengine?topic=codeengine-clicli-application-create) and the [job create](https://cloud.ibm.com/docs/codeengine?topic=codeengine-clicli-job-create) commands.\n\nWant to learn more about applications and jobs? See [Working with apps in Code Engine](https://cloud.ibm.com/docs/codeengine?topic=codeengine-application-workloads) and [Working with jobs and jobruns](https://cloud.ibm.com/docs/codeengine?topic=codeengine-job-plan).\n\n\n\n\n\n Clean up", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-migrate-cf-ce-tutorial"}, {"document_id": "ibmcld_05367-1325-3446", "score": 8.889778, "text": "\nWhether your code exists as source in a local file or in a Git repository, or your code is a container image that exists in a public or private registry, Code Engine provides a streamlined way for you to run your code as a Function.\n\n\n\n* If you are starting with source code that is located in a Git repository, you can choose to point to the location of your source, and Code Engine takes care of building the code bundle from your source and creating the Function with a single operation. In this scenario, Code Engine uploads your code to IBM Cloud\u00ae Container Registry. To learn more, see [Creating a Function from repository source code](https://cloud.ibm.com/docs/codeengine?topic=codeengine-fun-create-repo).\n* If you are starting with source code on a local workstation, you can choose to point to the location of your source, and Code Engine takes care of building the image from your source and creating the Function with a single CLI command. In this scenario, Code Engine uploads your code to IBM Cloud\u00ae Container Registry. To learn more, see [Creating your Function from local source code with the CLI](https://cloud.ibm.com/docs/codeengine?topic=codeengine-fun-create-local).\n* If you are starting with source code, you can also run your source code inline. In this scenario, you paste in your source code when you create your Function. For more information, see [Creating your Function with inline code](https://cloud.ibm.com/docs/codeengine?topic=codeengine-fun-create-inlinecode).\n\n\n\nAfter you create and run your Function, you can also update your Function by using any of the preceding ways, independent of how you created or previously updated your Function.\n\n\n\n\n\n Requests and responses \n\nFunctions are invoked with the HTTP protocol. When you invoke your Function, you can specify the custom request parameters, custom request body and headers, as well as the HTTP method. The request parameters are made available to the Function code as input parameters. The Function code can set the response body, response headers, and response code, which are returned to the caller from the Functions endpoint.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-fun-work"}]}
{"task_id": "1065ea5ad1ae2b90e6fce67d851a7a66<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07578-1055073-1057117", "score": 21.301237, "text": "\nIf you are not subject to tax, you can provide us with a tax identification number by using the contact information that is found on your most recent invoice. After your tax identification number is accepted, you are not charged taxes on any future invoices. The removal of tax charges from your account is not retroactive and can't be refunded.\n\nIBM Cloud complies with all tax regulations. Taxes are assessed based on the laws that correspond to the address on your account.\n* How can I monitor spending?\n\nYou can view your monthly runtime and service usage by clicking Manage > Billing and usage > Usage. Learn more in [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n* Can I receive notifications when my spending reaches specific levels?\n\nYou can set separate spending thresholds for the account, container, runtime, all services, and specific services. You automatically receive notifications when your monthly spending reaches 80%, 90%, and 100% of those thresholds. To set spending notifications, click Manage > Billing and usage and select Spending notifications. For more information, see [Setting spending notifications](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-spending).\n\nSpending notifications don't stop charges from incurring. You continue to incur charges if your usage exceeds 100% of the spending threshold.\n* Does the price of the product that I'm ordering reflect the discounted price?\n\nYes, if your account includes any discounts, the price of the product that is displayed in your infrastructure order summary does reflect the discounted price of that product.\n* How do I confirm that I received an expected credit?\n\nCredit might take a few hours to appear in your account. To see whether a credit was added, go to Manage > Billing and usage, and select Usage. The credit might be listed in the Active subscriptions and credits section.\n\nIf the credit isn't on the Usage page, go to Invoices and click link with the date for your next recurring invoice.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1054944-1056988", "score": 21.301237, "text": "\nIf you are not subject to tax, you can provide us with a tax identification number by using the contact information that is found on your most recent invoice. After your tax identification number is accepted, you are not charged taxes on any future invoices. The removal of tax charges from your account is not retroactive and can't be refunded.\n\nIBM Cloud complies with all tax regulations. Taxes are assessed based on the laws that correspond to the address on your account.\n* How can I monitor spending?\n\nYou can view your monthly runtime and service usage by clicking Manage > Billing and usage > Usage. Learn more in [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n* Can I receive notifications when my spending reaches specific levels?\n\nYou can set separate spending thresholds for the account, container, runtime, all services, and specific services. You automatically receive notifications when your monthly spending reaches 80%, 90%, and 100% of those thresholds. To set spending notifications, click Manage > Billing and usage and select Spending notifications. For more information, see [Setting spending notifications](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-spending).\n\nSpending notifications don't stop charges from incurring. You continue to incur charges if your usage exceeds 100% of the spending threshold.\n* Does the price of the product that I'm ordering reflect the discounted price?\n\nYes, if your account includes any discounts, the price of the product that is displayed in your infrastructure order summary does reflect the discounted price of that product.\n* How do I confirm that I received an expected credit?\n\nCredit might take a few hours to appear in your account. To see whether a credit was added, go to Manage > Billing and usage, and select Usage. The credit might be listed in the Active subscriptions and credits section.\n\nIf the credit isn't on the Usage page, go to Invoices and click link with the date for your next recurring invoice.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_03729-4932-7001", "score": 21.287848, "text": "\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges\n: You select a plan and pay on a flat rate basis. For example, the Bare Metal Servers are charged at a flat-rate.\n\nMetered charges\n: You pay based on your runtime and service consumption. For example, with the Push service, any usage over the free monthly allowance is charged.\n\nReserved charges\n: As the account owner of a Pay As You Go account or a Subscription account, you can reserve a service instance, with a long-term commitment, for a discounted price. For example, you can reserve the standard large Db2 on Cloud offering for 12 months.\n: Some IBM Cloud services offer reserved plans. You can request a reserved plan from the IBM Cloud catalog by clicking the tile of the service. Then, select the service plan that best meets your needs. If a reserved plan is available, click Request, and follow the prompts to send your request. You receive an email that contains the price information of the reserved plan. An IBM Cloud sales representative also contacts you soon to complete the purchase.\n\nTiered charges\n: Similar to metered charges, you pay based on your runtime and service consumption. However, tiered charges add more pricing tiers, often offering discounted charges in tiers with larger consumption. Tiered pricing is offered in simple, graduated, or block.\n\n\n\n Simple tier \n\nIn the simple tier model, the unit price is determined by the tier that the quantity of your usage falls into. The total price is your quantity that is multiplied by the unit price in that tier, for example:\n\n\n\nTable 2. Simple tier pricing table\n\n Quantity of Items Unit Price for All Items", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges"}, {"document_id": "ibmcld_16727-1053307-1055450", "score": 21.229794, "text": "\nEnsure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https://cloud.ibm.com/docs/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product. For example, this includes buildpacks, Platform as a Service, and Infrastructure as a Service.\n\nIf you believe that charges on your invoice are incorrect, [contact Support](https://cloud.ibm.com/unifiedsupport/supportcenter) within 30 calendar days of the invoice due date or use the contact information that is found on your invoice.\n* Why did I get billed for a resource I deleted?\n\nA resource A physical or logical component that can be provisioned or reserved for an application or service instance. Examples of resources can include storage, processors, memory, clusters, and VMs. is anything that you can create from the catalog that is managed by and contained within a resource group. You're billed for resources in your account until you cancel them. If you deleted a resource or have resources in your account that are no longer used, make sure to cancel all billing items associated with those resources. Billing items can't be recovered after they are canceled. For more information, see [Cancelling your billing items](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cancel-billing-items).\n* Can I add a tax identification number to my account?\n\nIf you are not subject to tax, you can provide us with a tax identification number by using the contact information that is found on your most recent invoice. After your tax identification number is accepted, you are not charged taxes on any future invoices. The removal of tax charges from your account is not retroactive and can't be refunded.\n\nIBM Cloud complies with all tax regulations. Taxes are assessed based on the laws that correspond to the address on your account.\n* How can I monitor spending?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-1053436-1055579", "score": 21.229794, "text": "\nEnsure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https://cloud.ibm.com/docs/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product. For example, this includes buildpacks, Platform as a Service, and Infrastructure as a Service.\n\nIf you believe that charges on your invoice are incorrect, [contact Support](https://cloud.ibm.com/unifiedsupport/supportcenter) within 30 calendar days of the invoice due date or use the contact information that is found on your invoice.\n* Why did I get billed for a resource I deleted?\n\nA resource A physical or logical component that can be provisioned or reserved for an application or service instance. Examples of resources can include storage, processors, memory, clusters, and VMs. is anything that you can create from the catalog that is managed by and contained within a resource group. You're billed for resources in your account until you cancel them. If you deleted a resource or have resources in your account that are no longer used, make sure to cancel all billing items associated with those resources. Billing items can't be recovered after they are canceled. For more information, see [Cancelling your billing items](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cancel-billing-items).\n* Can I add a tax identification number to my account?\n\nIf you are not subject to tax, you can provide us with a tax identification number by using the contact information that is found on your most recent invoice. After your tax identification number is accepted, you are not charged taxes on any future invoices. The removal of tax charges from your account is not retroactive and can't be refunded.\n\nIBM Cloud complies with all tax regulations. Taxes are assessed based on the laws that correspond to the address on your account.\n* How can I monitor spending?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_03704-12015-14084", "score": 20.89126, "text": "\nEnsure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https://cloud.ibm.com/docs/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product. For example, this includes buildpacks, Platform as a Service, and Infrastructure as a Service.\n\nIf you believe that charges on your invoice are incorrect, [contact Support](https://cloud.ibm.com/unifiedsupport/supportcenter) within 30 calendar days of the invoice due date or use the contact information that is found on your invoice.\n\n\n\n\n\n Why did I get billed for a resource I deleted? \n\nA\n\nresourceis anything that you can create from the catalog that is managed by and contained within a resource group. You're billed for resources in your account until you cancel them. If you deleted a resource or have resources in your account that are no longer used, make sure to cancel all billing items associated with those resources. Billing items can't be recovered after they are canceled. For more information, see [Cancelling your billing items](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cancel-billing-items).\n\n\n\n\n\n Can I add a tax identification number to my account? \n\nIf you are not subject to tax, you can provide us with a tax identification number by using the contact information that is found on your most recent invoice. After your tax identification number is accepted, you are not charged taxes on any future invoices. The removal of tax charges from your account is not retroactive and can't be refunded.\n\nIBM Cloud complies with all tax regulations. Taxes are assessed based on the laws that correspond to the address on your account.\n\n\n\n\n\n How can I monitor spending? \n\nYou can view your monthly runtime and service usage by clicking Manage > Billing and usage > Usage.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-billusagefaqs"}, {"document_id": "ibmcld_01705-5444-7439", "score": 20.816437, "text": "\nWhen you register with IBM Cloud, you get a Pay-As-You-Go account, and you receive a [$200 credit](https://cloud.ibm.com/docs/account?topic=account-upgrading-account) to help get you started. You can use the $200 credit on IBM Cloud products.\n\nYour resource usage consists of recurring and fluctuating costs. If you purchase classic infrastructure services, you're billed on an hourly or monthly recurring basis in advance of use, like a rent bill. If you purchase platform services, your invoice fluctuates as your resource usage fluctuates, similar to a utility bill. You will receive invoices for recurring resources in your account until you cancel them. Turning a resource \"off\" does not cancel the resource in your account. See [Cancelling your billing items](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cancel-billing-items) for more information.\n\nYou can create multiple resource groups to easily manage quota and view billing usage for a set of resources. Your charges are based on your use of IBM Cloud computing and services. If you use more than the free runtime and service allowances, you receive a monthly invoice that provides details about your resource charges. You can [set up spending notifications](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-spending) to get notified when your account or a particular service reaches a specific spending threshold that you set.\n\nBasic support is included with your IBM Cloud Pay-As-You-Go. It is provided for non-production environments or workloads where traditional severities are not used and specific response times are not stipulated. Also, with a Pay-As-You-Go account, you can order Advanced or Premium support plans to get extra help with your production workloads. Learn more in [Basic, Advanced, and Premium Support plans](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans).\n\nA subset of Pay-As-You-Go accounts are eligible for the new Enterprise Savings Plan billing model.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accounts"}, {"document_id": "ibmcld_11133-3534-5483", "score": 20.816435, "text": "\nApplicable Additional SDs for any service ordered using your IBM Cloud account are available at [https://www.ibm.com/terms/?id=i126-6605](https://www.ibm.com/terms/?id=i126-6605) . The additional SDs contain links to the applicable Data Sheet for each service.\n\n\n\n\n\n Exchange Rate Policy \n\nEffective 1 February 2023, IBM Cloud will adjust the exchange rates used to provide pricing in non-US dollar currencies on a monthly basis. Charges for cloud services are based on US dollars. Non-US dollar pricing is calculated by converting the US dollar rate by using market exchange rates published by leading financial institutions. Market exchange rates will be adjusted monthly, except as prohibited or controlled by applicable law.\n\nIBM uses leading financial institution benchmark rates set at the end of the month to go into effect for consumption starting the first day of the next month. The corresponding invoice will be sent 30 days later. For example, IBM will set the exchange rate at the end of January effective for consumption in February. Customers will see the impact of the new rates in their March invoice.\n\n\n\n\n\n IBM Business Associate Addendum \n\nIf you or your company is a covered entity as defined by the US Health Insurance Portability and Accountability Act (HIPAA) and intend to order Cloud Services that might process protected health information (PHI), you must accept the IBM\u00ae Business Associate Addendum (BAA) available at [https://www-03.ibm.com/software/sla/sladb.nsf/sla/baa?OpenDocument](https://www-03.ibm.com/software/sla/sladb.nsf/sla/baa?OpenDocument). The BAA can be digitally accepted as described in [Enabling the HIPAA Supported setting](https://cloud.ibm.com/docs/account?topic=account-enabling-hipaa).\n\n\n\n\n\n Legal contact information \n\nFor subpoenas or for reporting abuse on IBM Cloud, contact the following:\n\nIBM Cloud c/o SoftLayer Inc.\n14001 North Dallas Parkway, Suite M100\nDallas, TX 75240\n214.442.0600 Main", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-terms"}, {"document_id": "ibmcld_03729-7-2197", "score": 20.712606, "text": "\nHow you're charged \n\nIBM Cloud\u00ae charges vary depending on the resources that are used by a particular service, runtime, container, or support option. The resources can be the number of API calls, the number of instances, memory, or storage. In addition, tiered pricing is offered in simple, graduated, or block.\n\nIBM Cloud provides detailed [cost estimators](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cost) to help you plan for charges.\n\nAfter you build your resources, you can check the actual cost. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization used. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage of the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations. You can see more information about a specific charge from each resource details page.\n\nDifferent types of charges apply depending on the features of IBM Cloud that you're using. The following table provides a high-level overview:\n\n\n\nTable 1. Charges based on features\n\n Type of Charge Description Resource Type Example \n\n Fixed Fixed-rate pricing is based on an agreed upon monthly charge. If you buy an additional bare metal server, virtual server, or storage resource after the start of the monthly billing period, the cost of the resource for the first month is prorated based on the number of days remaining in the billing period. The prorated cost is billed in a separate invoice. Services For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges"}, {"document_id": "ibmcld_11131-0-412", "score": 20.564404, "text": "\n\n\n\n\n\n\n  Service Level Agreements (SLAs) \n\nIBM Cloud\u00ae aims to deliver the highest levels of availability and offers a service level agreement (SLA), which provides credits against service charges should a service fail to meet its stated availability target. For more information, see [IBM Cloud Service Level Agreements](https://www.ibm.com/support/customer/csol/terms/?id=i126-9268&lc=endetail-document).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-slas"}]}
{"task_id": "1065ea5ad1ae2b90e6fce67d851a7a66<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16340-8232-10560", "score": 12.487721, "text": "\nSearch result messages\n\n Tab Scenario Example message \n\n Message Search results are returned I found this information that might be helpful: \n No results found No search results are found I searched my knowledge base for information that might address your query, but did not find anything useful to share. \n Connectivity issue I was unable to complete the search for some reason I might have information that could help address your query, but am unable to search my knowledge base at the moment. \n\n\n\n4. Choose whether to enable Emphasize the answer.\n\nThis option is available only if your Discovery instance uses the v2 Discovery API.\n\nWhen you enable this feature, the sentence that is determined by Discovery to be the exact answer to the customer's question is highlighted in the block of text that is displayed to the customer as the search result.\n5. In the Adjust result quantity section, specify the number of results to return.\n\nThe top three results are returned automatically. You can choose to show fewer or more (up to 10) results in the response.\n\nBy default, customers can choose to see more results. If you don't want to give customers this choice, clear the Include link for customers to view up to 10 results checkbox.\n6. In the Set result selectivity section, decide whether to be more selective with the answers that are returned. By increasing result selectivity, Search returns fewer but more accurate results. In most cases, Search is accurate enough that the default setting (off) is sufficient.\n7. Click Preview. Enter a test message to see the results that are returned when your configuration choices are applied to the search. Make adjustments as necessary.\n8. Click Create.\n\n\n\n\n\n\n\n Edit the search integration configuration \n\nIf you want to change the configuration of the search result card later, open the search integration again, and make edits. You do not need to save changes as you make them; they are automatically applied. When you are happy with the search results, click Save to finish configuring the search integration.\n\nIf you decide you want to connect to a different Discovery service instance or project, open the search integration and click *Edit Discovery Settings. You can choose either a new project from the same instance, or a new instance and project.\n\n\n\n\n\n Troubleshooting", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-search-add"}, {"document_id": "ibmcld_13360-1543-3265", "score": 12.397406, "text": "\nIt can also return no result if the input clearly does not match one of the two phrases.\n\nFor instance, if the user replies yes, the service likely returns a response that is very much like the following result. The score in the confidence field indicates a perfectly reliable match.\n\n{\n\"result_index\": 0,\n\"results\": [\n{\n\"alternatives\":\n{\n\"confidence\": 1.0,\n\"transcript\": \"yes\"\n}\n],\n\"final\": true\n}\n]\n}\n\nBut suppose, for example, the user replies nope. The service can return either a result with a very low confidence score or no result at all. An empty result is the clearest indication that the response does not match the grammar. An empty response is more likely to occur with complex grammars, where a valid response must match a specific multi-phrase sequence.\n\n\n\n\n\n Multi-phrase matches: The names grammar \n\nWith a multi-phrase grammar, the user's response must be complete to be recognized. The user cannot omit a word or stop in the middle of the response. The absence of even a single word can cause the service to return an empty result.\n\nMoreover, the service can return multiple transcripts if the user speaks phrases that are separated by sufficient silence to indicate that they are independent utterances. For example, consider the simple names grammar, which can match one of three multi-word names.\n\nABNF 1.0 ISO-8859-1;\nlanguage en-US;\nmode voice;\nroot $names;\n\n$names = Yi Wen Tan | Yon See | Youngjoon Lee ;\n\nSuppose the user speaks one of the names from the grammar's rules, Yon See. The service returns a response that indicates a very high level of confidence in the match.\n\n{\n\"result_index\": 0,\n\"results\": [\n{\n\"alternatives\":\n{\n\"confidence\": 0.92,\n\"transcript\": \"Yon See\"\n}\n],\n\"final\": true\n}\n]\n}", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-grammarUnderstand"}, {"document_id": "ibmcld_10863-7246-8495", "score": 11.768393, "text": "\n// returning the result here, makes sure that the top-most promise, we returned in main() returns the combined results of all\n// chained action invokes\n\n// since the result needs to be a valid JSON object, we cannot directly return the array, so we wrap it\nreturn {\naction_results: chained_action_results\n};\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));\n\nconsole.log('Custom SEQUENCE with openwhisk-node-js-sdk FAILED');\n\n// This last throw is absolutely important to make the top-most promise, which we initially returned at the\n// top of the main() function REJECTS with the given error. If we did not throw here, it would still RESOLVE\n// even though the code herein failed.\nthrow error;\n});\n}\nShow more\n6. Click Save.\n7. Test your action by clicking Invoke and waiting for the following output to display.\n\nExample output\n\nResults:\n{\n\"action_results\": [\n{\n\"cos_message\": \"SUCCESS\"\n},\n{\n\"cloudant_result\": \"SUCCESS\"\n},\n{\n\"cos_message\": \"SUCCESS\"\n}\n]\n}\n\nLogs:\n[\n\"2020-04-17T04:31:20.965176Z stdout: Building custom sequence, using openwhisk node-js SDK...\",\n\"2020-04-17T04:31:31.670466Z stdout: Result from cos-access {\"cos_message\":\"SUCCESS\"}\",\n\"2020-04-17T04:31:31.670501Z stdout: Now invoking db-access...\",", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-tutorial_action"}, {"document_id": "ibmcld_13455-24911-26512", "score": 11.116534, "text": "\n\"content-type\": \"audio/l16;rate=22050\",\n\"interim_results\": true\n}\n<binary audio data>\n{\n\"action\": \"stop\"\n}\n* The service responds:\n\n{\"results\": [{\"alternatives\": {\"transcript\": \"name \"}],\n\"final\": false}], \"result_index\": 0}\n{\"results\": [{\"alternatives\": {\"transcript\": \"name may \"}],\n\"final\": false}], \"result_index\": 0}\n{\"results\": [{\"alternatives\": {\"transcript\": \"name may flour \"}],\n\"final\": false}], \"result_index\": 0}\n{\"results\": [{\"alternatives\": {\"transcript\": \"name the mayflower \",\n\"confidence\": 0.91}], \"final\": true}], \"result_index\": 0}\n{\"state\":\"listening\"}\n\n\n\n\n\n\n\n\n\n WebSocket return codes \n\nThe service can send the following return codes to the client over the WebSocket connection:\n\n\n\n* 1000 indicates normal closure of the connection, meaning that the purpose for which the connection was established has been fulfilled.\n* 1002 indicates that the service is closing the connection due to a protocol error.\n* 1006 indicates that the connection closed abnormally.\n* 1009 indicates that the frame size exceeded the 4 MB limit.\n* 1011 indicates that the service is terminating the connection because it encountered an unexpected condition that prevents it from fulfilling the request.\n\n\n\nIf the socket closes with an error, the client receives an informative message of the form {\"error\":\"{message}\"} before the socket closes. Use the onerror event handler to respond appropriately. For more information about WebSocket return codes, see [IETF RFC 6455](https://tools.ietf.org/html/rfc6455).\n\nThe WebSocket implementations of the SDKs can return different or additional response codes.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets"}, {"document_id": "ibmcld_13042-10425-12696", "score": 10.98577, "text": "\nAs you add field mappings, a preview of the search result is displayed with information from the corresponding fields of your data collection. This preview shows you what gets included in the search result response that is returned to users.\n\nTo get help with configuring the search, see [Troubleshooting](https://cloud.ibm.com/docs/services/assistant?topic=assistant-skill-search-addskill-search-add-troubleshoot).\n3. Use the Message, No results found and Connectivity issue tabs to customize different messages to share with users based on the successfulness of the search.\n\n\n\nSearch result messages\n\n Tab Scenario Example message \n\n Message Search results are returned I found this information that might be helpful: \n No results found No search results are found I searched my knowledge base for information that might address your query, but did not find anything useful to share. \n Connectivity issue I was unable to complete the search for some reason I might have information that could help address your query, but am unable to search my knowledge base at the moment. \n\n\n\n4. Choose whether to enable Emphasize the answer.\n\nThis option is available only if your Discovery instance uses the v2 Discovery API.\n\nWhen you enable this feature, the sentence that is determined by Discovery to be the exact answer to the customer's question is highlighted in the block of text that is displayed to the customer as the search result.\n5. In the Adjust result quantity section, specify the number of results to return.\n\nThe top three results are returned automatically. You can choose to show fewer or more (up to 10) results in the response.\n\nBy default, customers can choose to see more results. If you don't want to give customers this choice, clear the Include link for customers to view up to 10 results checkbox.\n6. In the Set result selectivity section, decide whether to be more selective with the answers that are returned. By increasing result selectivity, Search returns fewer but more accurate results. In most cases, Search is accurate enough that the default setting (off) is sufficient.\n7. Click Preview to open the Preview pane for testing. Enter a test message to see the results that are returned when your configuration choices are applied to the search.", "title": "", "source": "https://cloud.ibm.com/docs/services/assistant?topic=assistant-skill-search-add"}, {"document_id": "ibmcld_03383-10407-12669", "score": 10.895054, "text": "\nAs you add field mappings, a preview of the search result is displayed with information from the corresponding fields of your data collection. This preview shows you what gets included in the search result response that is returned to users.\n\nTo get help with configuring the search, see [Troubleshooting](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-search-addskill-search-add-troubleshoot).\n3. Use the Message, No results found and Connectivity issue tabs to customize different messages to share with users based on the successfulness of the search.\n\n\n\nSearch result messages\n\n Tab Scenario Example message \n\n Message Search results are returned I found this information that might be helpful: \n No results found No search results are found I searched my knowledge base for information that might address your query, but did not find anything useful to share. \n Connectivity issue I was unable to complete the search for some reason I might have information that could help address your query, but am unable to search my knowledge base at the moment. \n\n\n\n4. Choose whether to enable Emphasize the answer.\n\nThis option is available only if your Discovery instance uses the v2 Discovery API.\n\nWhen you enable this feature, the sentence that is determined by Discovery to be the exact answer to the customer's question is highlighted in the block of text that is displayed to the customer as the search result.\n5. In the Adjust result quantity section, specify the number of results to return.\n\nThe top three results are returned automatically. You can choose to show fewer or more (up to 10) results in the response.\n\nBy default, customers can choose to see more results. If you don't want to give customers this choice, clear the Include link for customers to view up to 10 results checkbox.\n6. In the Set result selectivity section, decide whether to be more selective with the answers that are returned. By increasing result selectivity, Search returns fewer but more accurate results. In most cases, Search is accurate enough that the default setting (off) is sufficient.\n7. Click Preview to open the Preview pane for testing. Enter a test message to see the results that are returned when your configuration choices are applied to the search.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-search-add"}, {"document_id": "ibmcld_03184-5949-7876", "score": 10.818721, "text": "\n* <result_variable_name>: The name of the context variable you want to use to store the JSON object that is returned by the client action. The client application is expected to use the specified variable to send the return value in the context of the next /message input, and subsequent dialog nodes can then access it. You can specify the result_variable_name by using the following syntax:\n\n\n\n* my_result\n* $my_result\n\n\n\nThe name cannot be longer than 64 characters. The variable name cannot contain the following characters: parentheses (), brackets ([]), a single quotation mark ('), a quotation mark (\"), or a backslash ().\n\nYou can optionally specify a context. location keyword prefix for this variable (for example, context.my_result). However, this is not necessary, because all context variables are stored in this location by default.\n\nYou can include periods in the variable name to create a nested JSON object. For example, you can define these variables to capture results from two separate requests to a weather service for forecasts for today and tomorrow:\n\n\n\n* context.weather.today\n* context.weather.tomorrow\n\n\n\nThe results (in this example, temp and rain properties) are stored in the context in this structure:\n\n{\n\"weather\": {\n\"today\": {\n\"temp\": \"20\",\n\"rain\": \"30\"\n},\n\"tomorrow\": {\n\"temp\": \"23\",\n\"rain\": \"80\"\n}\n}\n}\n\nIf multiple actions in a single JSON action array add the result of their programmatic call to the same context variable, then the order in which the context is updated matters. Per action type, the order in which the actions are defined in the array determines the order in which the context variable's value is set. The context variable value returned by the last action in the array overwrites the values calculated by any other actions.\n\nThe result_variable property is required. If the client action does not return any result, specify null as the value.\n\n\n\n\n\n\n\n\n\n Client action example", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-actions-client"}, {"document_id": "ibmcld_07096-2877-4735", "score": 10.606986, "text": "\nBecause we are using the wildcard operator, we also changed the term to lowercase.\n\n{\n\"query\":\"test_results:p53\"\n}\n\nWith this syntax, occurrences of p53, tp53, P53, or TP53 are all returned.\n\n\n\n\n\n \"\" (Phrase query) \n\nPhrase queries only match occurrences of the whole phrase. The order of the words in the phrase must match.\n\nFor example, the following query returns only documents that contain a field named quotation with the text, There's no crying in baseball.\n\n{\n\"query\":\"quotation:There's no crying in baseball\"\n}\n\nA document with a quotation field that says Jimmy Dugan said there's no crying in baseball is also returned. However, documents that only mention baseball or crying without the entire phrase are not matched. Neither is a document with In baseball, there's no crying. Documents that contain the right text in the wrong field also are not matched. For example, a document with the text There's no crying in baseball in the text field is not returned.\n\nSingle quotation marks (') are not supported. You cannot use wildcards (*) in phrase queries.\n\n\n\n\n\n :: (Exact match) \n\nThis operator specifies an exact match for the query term. Exact matches are case-sensitive.\n\nFor example, the following query searches for documents that contain entities of type Organization:\n\n{\n\"query\":\"enriched_text.entities.type::Organization\"\n}\n\nThe entire content of the field that you specify must match the phrase you specify. For example, the following query finds documents in which only entity mentions of IBM Cloud are detected, not IBM Cloud Pak for Data or IBM cloud or Cloud.\n\n{\n\"query\":\"enriched_text.entities.text::\"IBM Cloud\"\"\n}\n\n\n\n\n\n :! (Does not include) \n\nThis operator specifies that the results do not contain a match for the query term.\n\nFor example:\n\n{\n\"query\":\"enriched_text.entities.text:!\"cloud computing\"\"\n}\n\n\n\n\n\n ::! (Not an exact match)", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-operators"}, {"document_id": "ibmcld_10863-6347-7636", "score": 10.298434, "text": "\nresult: true,\nparams: {}\n});\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));\n// IMPORTANT! Re-throw the error, to avoid following .then() block to be executed!\nthrow error;\n})\n.then((result) => {\nconsole.log('Result from db-access ' + JSON.stringify(result));\n\n// storing result\nchained_action_results.push(result);\n\nconsole.log('Now invoking cos-access...');\n\nreturn ow.actions.invoke({\nname: 'action-tutorial/cos-access',\nblocking: true,\nresult: true,\nparams: {}\n});\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));\n// IMPORTANT! Re-throw the error, to avoid following .then() block to be executed!\nthrow error;\n})\n.then((result) => {\nconsole.log('Result from cos-access ' + JSON.stringify(result));\n\n// storing result\nchained_action_results.push(result);\n\nconsole.log('Custom SEQUENCE with openwhisk-node-js-sdk completed.');\n\n// returning the result here, makes sure that the top-most promise, we returned in main() returns the combined results of all\n// chained action invokes\n\n// since the result needs to be a valid JSON object, we cannot directly return the array, so we wrap it\nreturn {\naction_results: chained_action_results\n};\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-tutorial_action"}, {"document_id": "ibmcld_07115-14730-16983", "score": 9.853482, "text": "\nIf it is not, then you might want to check two things:\n\n\n\n* If the document is not returned in the top 100, it might not be an example of a high-quality result. Reevaluate whether to use the document.\n* If the document is not returned at all, then review why it is not returned and see whether any text in the document matches portions of the query.\n\n\n\nThis warning indicates that you might have one or more failed queries. It doesn't mean that the training cannot be completed.\n\n\n\n\n\n Error: Invalid training data found: Syntax error when parsing query \n\nA syntax error means that the query is invalid. Syntax errors can occur when you increase the complexity of the query by adding a filter to the natural language query, for example. Run the query against the collection outside of relevancy training by using the API. After you confirm that the query is valid and returns results, you can add it as a relevancy training query.\n\n\n\n\n\n Error: Training data quality standards not met: You will need additional training queries with labeled examples. (To be considered for training, each example must appear in the top 100 search results for its query.) \n\nYou need to add more training data to train successfully. You need at least 49 unique training queries at a minimum, and each one needs at least one rated document. Minimum does not mean optimal; the size of the collection and other factors can increase the number of training examples that are needed to meet the minimum.\n\n\n\n\n\n Error: Training data quality standards not met: Insufficient number of unique training queries. Expected at least n, but found m. \n\nTo meet the minimum training requirements, you need at least 50 unique training queries, and each query must have at least one rated document. If you have more queries than the minimum and are still receiving this error message, check your notices for other errors.\n\n\n\n\n\n Error: Training data quality standards not met: No documents found with non-zero relevance labels. \n\nTraining data needs enough labeled data that specifies what documents are high value. Therefore, you need to rate some documents with nonzero values. You need to rate some documents as Relevant and some as Not relevant. At least one document must be rated Relevant.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-train"}]}
{"task_id": "1065ea5ad1ae2b90e6fce67d851a7a66<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10817-6582-8092", "score": 20.925161, "text": "\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http://localhost:8080\"\n\nIn this example, you use an installation that is running at http://localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https://us-south.functions.cloud.ibm.com](https://us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n// create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n// create an NSURLSession that uses the trusting delegate", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_16702-1380-3273", "score": 20.070082, "text": "\nFor more information, see [Configure IBM Cloud Function Channel](https://docs.sysdig.com/en/configure-ibm-cloud-functions-channel.html).\n* For a Webhook notification channel, add the Webhook URL. Note: When an alert is triggered, the notification is sent as a POST in JSON format to your webhook endpoint. For more information, see [Configuring a Webhook channel](https://docs.sysdig.com/en/configure-a-webhook-channel.html). For example, IBM Cloud Security and Compliance Center Workload Protection can be integrated with ServiceNow using a custom webhook. To learn about configuring IBM Cloud Security and Compliance Center Workload Protection with ServiceNow, see [Configure ServiceNow](https://docs.sysdig.com/en/configure-servicenow.html).\n* For a VictorOps notification channel, add the API Key and the Routing Key.\n* For an OpsGenie notification channel, add the OpsGenie API key. Notice that you must configure in OpsGenie the integration with IBM Cloud Security and Compliance Center Workload Protection. For more information, see [Add IBM Cloud Security and Compliance Center Workload Protection} Integration in Opsgenie](https://docs.opsgenie.com/v1.0/docs/sysdig-cloud-integration).\n* For an Amazon SNS Topic notification channel, add the SNS Topic.\n* For a Microsoft Teams notification channel, add the Microsoft Teams URL.\n* For a PagerDuty notification channel, first you must authorize IBM Cloud Security and Compliance Center Workload Protection to integrate with your account. When you select PagerDuty, a wizard to configure the integration with IBM Cloud Security and Compliance Center Workload Protection opens. Click either Authorize Integration or Sign In Using Your Identity Provider to authorize PagerDuty. Choose an existing service or set up a new service for IBM Cloud Security and Compliance Center Workload Protection notifications, then click Finish Integration.", "title": "", "source": "https://cloud.ibm.com/docs/workload-protection?topic=workload-protection-notifications"}, {"document_id": "ibmcld_10835-32519-34249", "score": 19.011559, "text": "\nCloud Functions has a size limit for the app code, see maximum codeSize described in the [Action Limits](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-limitslimits_actions). However, you can install large packages and dependencies into a custom Docker image and deploy it with your app code when you create an action. You can then import the packages at run time.\n\nIn this example, install large Python packages such as matplotlib and seaborn to build a Cloud Functions web action that generates a PNG file of a joint plot with seaborn.\n\nBefore you begin\n\n\n\n* Review the packages that are included with the [Python runtime](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-runtimesopenwhisk_ref_python_environments) to see whether a dependency of your app is already included with the runtime. If your dependency is not included, you must package it with your app.\n* The following steps assume that you are running the commands on a Linux-based distribution on a processor with AMD64-based architecture.\n\n\n\nOnly public Docker images are supported.\n\nPackage the app in a custom Docker image by completing the following steps.\n\n\n\n1. Create a directory that you can use to create your Dockerfile. In this example, a functions directory is created on the desktop. After you create the functions directory, cd to it.\n\ncd desktop; mkdir functions; cd functions\n2. Create a [Dockerfile ![External link icon](https://cloud.ibm.com/docs-content/v1/content/adc643f3bedeea02b638bc1c34732852dcb40a45/icons/launch-glyph.svg)](https://docs.docker.com/engine/reference/builder/) in your functions directory.\n\ntouch Dockerfile\n3. Use vim to edit the Dockerfile file. Enter the names of the pip modules and versions you want to install.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-prep"}, {"document_id": "ibmcld_09787-1364-3084", "score": 18.712767, "text": "\nFor more information, see [Configure IBM Cloud Function Channel](https://docs.sysdig.com/en/configure-ibm-cloud-functions-channel.html).\n* For a Webhook notification channel, add the Webhook URL. Note: When an alert is triggered, the notification is sent as a POST in JSON format to your webhook endpoint. For more information, see [Configuring a Webhook channel](https://docs.sysdig.com/en/configure-a-webhook-channel.html). For example, IBM Cloud Monitoringcan be integrated with ServiceNow using a custom webhook. To learn about configuring IBM Cloud Monitoring with ServiceNow, see [Configure ServiceNow](https://docs.sysdig.com/en/configure-servicenow.html).\n* For a VictorOps notification channel, add the API Key and the Routing Key.\n* For an OpsGenie notification channel, add the OpsGenie API key. Notice that you must configure in OpsGenie the integration with IBM Cloud Monitoring. For more information, see [Add IBM Cloud Monitoring Integration in Opsgenie](https://docs.opsgenie.com/v1.0/docs/sysdig-cloud-integration).\n* For a Microsoft Teams notification channel, add the Microsoft Teams URL.\n* For a PagerDuty notification channel, first you must authorize IBM Cloud Monitoring to integrate with your account. When you select PagerDuty, a wizard to configure the integration with IBM Cloud Monitoring opens. Click either Authorize Integration or Sign In Using Your Identity Provider to authorize PagerDuty. Choose an existing service or set up a new service for IBM Cloud Monitoring notifications, then click Finish Integration. Select the escalation policy to use for IBM Cloud Monitoring incidents. Then, on the Notifications tab, confirm your PagerDuty account, your service name, and the service key.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-notifications"}, {"document_id": "ibmcld_10762-7-1641", "score": 18.483883, "text": "\nInstalling the CLI and plug-in \n\nIBM Cloud\u00ae Functions offers a powerful plug-in for the IBM Cloud CLI that allows complete management of the Cloud Functions system. You can use the Cloud Functions CLI plug-in to manage your code snippets in actions, create triggers and rules to enable your actions to respond to events, and bundle actions into packages.\n\n\n\n Setting up the IBM Cloud CLI \n\nInstall the latest version of the IBM Cloud CLI.\n\nBefore you begin\n\nYou must create an [IBM Cloud account](https://cloud.ibm.com/).\n\n\n\n1. Download and install the [IBM Cloud CLI](https://cloud.ibm.com/docs/cli?topic=cli-install-ibmcloud-cli).\n2. Log in to the IBM Cloud CLI.\n\nibmcloud login\n3. If you have more than one account, you are prompted to select which account to use. Follow the prompts or use the target command to select your IBM Cloud account.\n\nibmcloud target -c <account_id>\n4. You must also specify a region. You can use the target command to target or change regions.\n\nibmcloud target -r <region>\n5. You must specify a resource group. To get a list of your resource groups, run the following command.\n\nibmcloud resource groups\n\nExample output\n\nRetrieving all resource groups under account <account_name> as email@ibm.com...\nOK\nName ID Default Group State\ndefault a8a12accd63b437bbd6d58fb8b462ca7 true ACTIVE\ntest a8a12abbbd63b437cca6d58fb8b462ca7 false ACTIVE\n6. Target a resource group by running the following command.\n\nibmcloud target -g <resource_group>\n\nExample output\n\nTargeted resource group default\n\n\n\n\n\n\n\n Setting up the Cloud Functions CLI plug-in \n\nTo work with Cloud Functions, download and install the CLI plug-in.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-cli_install"}, {"document_id": "ibmcld_10762-5241-7066", "score": 18.33267, "text": "\nFor more information, see the [Cloud Functions CLI reference](https://cloud.ibm.com/docs/openwhisk?topic=cloud-functions-cli-plugin-functions-cli).\n\n\n\n\n\n API Authentication and Host \n\nWith the Cloud Functions CLI plug-in, you don't need to explicitly configure the API key and API host. Instead, you can log in with the ibmcloud login command. You can target an IAM-enabled namespace by running ibmcloud fn property set --namespace <namespace_name_or_ID> or a Cloud Foundry-based namespace by running ibmcloud target --cf. After you log in, all commands begin with ibmcloud fn.\n\nIf you need to use the authentication API key for Cloud Functions in an external HTTP client such as cURL or Postman, you can retrieve it with the following commands.\n\n\n\n* Get the current IAM tokens. You must pass the IAM token in the Authorization header.\n\nibmcloud iam oauth-tokens\n* Get the current Cloud Foundry API key by running the following command.\n\nibmcloud fn property get --auth\n* Get the current API host by running the following command.\n\nibmcloud fn property get --apihost\n\n\n\nThe API key is specific per region, organization, and space targeted by the Cloud Functions CLI plug-in. The IBM Cloud\u00ae Functions web actions API endpoint changed. To align with other customer services, a new functions.appdomain.cloud API endpoint is available for web actions. The API endpoint functions.cloud.ibm.com is still active, but now returns response data as content type text/plain instead of text/html. Other content types are not changing. Migrate your web actions to use the new API endpoint. The previous endpoints are deprecated and will be deactivated at some point.\n\n\n\n\n\n Migrating deployment scripts \n\nIf you have scripts that use the OpenWhisk CLI with the wsk commands, all commands work the same way by using the command ibmcloud fn.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-cli_install"}, {"document_id": "ibmcld_07526-1370-3301", "score": 18.299154, "text": "\nCopy api_key and use it in Destination Configuration in Event Notifications instance.\n\n\n\nIBM Cloud Functions Cloud Foundary based namespace is not supported. Only IAM-based namespace is supported.\n\n\n\n\n\n Configuring a Cloud Functions destination \n\nYou can configure a Cloud Functions destination in the Destinations tab.\n\nTo configure a Cloud Functions destination, do the following steps:\n\n\n\n1. From your Event Notifications instance dashboard, click Destinations.\n2. Click Add + to add new destination.\n3. In the Add a destination side panel, provide the following details.\n\n\n\n* Name - Enter a name for your destination.\n* Description - Optionally, enter a description for your destination.\n* Type - Under Destination, for the Type, select IBM Cloud Functions from the drop-down as your destination type.\n* URL - Enter the Cloud Functions incoming webhook URL. This is the URL that you have [generated](https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-destinations-cloud-functionsen-generate-cf-incoming-webhook-url) earlier.\n* API key - Enter the API key that you have [generated](https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-destinations-cloud-functionsen-generate-cf-api-key) earlier.\n\n\n\n4. Click Add.\n\n\n\n\n\n\n\n Cloud Functions retry policy \n\nWhen calling a webhook, issues such as network errors and application glitches can cause the requests to fail. A retry is used to provide resiliency to external requests. Attempt to retry the requests in such situations by using the following values:\n\n\n\n* Limit = 60 seconds: total time that the service retries.\n* Step = 5 seconds: after each failure, the service waits 5 seconds before retrying. This delay prevents bombarding of the external services (webhook).\n\n\n\nIn addition, the following timeout conditions cause the Cloud Functions call to fail:\n\n\n\n* A connection timeout of 10 seconds\n* A response timeout of 60 seconds", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-destinations-cloud-functions"}, {"document_id": "ibmcld_07526-7-1834", "score": 18.293995, "text": "\nIBM Cloud Functions \n\nA Cloud Functions represents a service destination, where an incoming notification can be consumed programmatically to actions.\n\n\n\n Generate IBM Cloud Functions endpoint \n\nTo post a Cloud Functions notification, you need to generate an endpoint. To generate the endpoint, follow these steps:\n\n\n\n1. Create a [IBM Cloud Functions](https://cloud.ibm.com/functions/create) instance. If you already have an Cloud Functions instance, go to step 3.\n2. Create a Namespace. For more information, see [here](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-namespacescreate_iam_namespace).\n3. Create an Action. For more information, see [here](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-actions).\n4. Select Endpoints from the left menu.\n\nMake sure to uncheck Enable as Web Action and Raw HTTP handling options in the Web Action section for an effective usage of Cloud Functions as a destination.\n5. Copy the URL mentioned and use it in Destination Configuration in Event Notifications instance.\n\n\n\n\n\n\n\n Generate API key for your namespace \n\n\n\n1. From your IBM Cloud dashboard, go to Manage > Access (IAM).\n2. Select Service IDs.\n3. Select your namespace.\n4. Select API keys.\n5. Unlock if the API key is locked by going to Actions > Unlock.\n6. Click Create and provide a Name. This gives you the apikey for the namespace you selected.\n7. Copy api_key and use it in Destination Configuration in Event Notifications instance.\n\n\n\nIBM Cloud Functions Cloud Foundary based namespace is not supported. Only IAM-based namespace is supported.\n\n\n\n\n\n Configuring a Cloud Functions destination \n\nYou can configure a Cloud Functions destination in the Destinations tab.\n\nTo configure a Cloud Functions destination, do the following steps:\n\n\n\n1. From your Event Notifications instance dashboard, click Destinations.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-destinations-cloud-functions"}, {"document_id": "ibmcld_10817-7-1802", "score": 18.264584, "text": "\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_10762-1269-2843", "score": 17.958187, "text": "\ndefault a8a12accd63b437bbd6d58fb8b462ca7 true ACTIVE\ntest a8a12abbbd63b437cca6d58fb8b462ca7 false ACTIVE\n6. Target a resource group by running the following command.\n\nibmcloud target -g <resource_group>\n\nExample output\n\nTargeted resource group default\n\n\n\n\n\n\n\n Setting up the Cloud Functions CLI plug-in \n\nTo work with Cloud Functions, download and install the CLI plug-in.\n\nYou can use the Cloud Functions CLI plug-in to perform the following tasks.\n\n\n\n* Run your code snippets, or actions, on Cloud Functions. See [Creating and invoking actions](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-actions).\n* Create triggers and rules to enable your actions to respond to events. See [Creating triggers and rules](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-triggers).\n* Bundle actions and configure external events sources. See [Create and use packages](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_ov).\n* Explore the catalog of packages and enhance your applications with external services. See [Adding IBM Cloud](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-services).\n\n\n\nComplete the following steps to install the Cloud Functions CLI plug-in\n\n\n\n1. Install the Cloud Functions plug-in.\n\nibmcloud plugin install cloud-functions\n2. Verify that the plug-in is installed.\n\nibmcloud plugin list\n\nExample Output\n\nPlugin Name Version\ncloud-functions/wsk/functions/fn 1.0.32\n3. All Cloud Functions commands begin with ibmcloud fn. To see everything that you can do with the Cloud Functions plug-in, run ibmcloud fn with no arguments.\n\nibmcloud fn", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-cli_install"}]}
{"task_id": "c01c8cf11437e6bb3bc93efac26528c2<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10817-2884-4620", "score": 17.101849, "text": "\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in /Library/Developer/Xcode/DerivedData/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_10817-7-1802", "score": 17.06231, "text": "\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_10852-44214-45420", "score": 16.54102, "text": "\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_02772-2964-4516", "score": 16.193567, "text": "\nThis can be found in the Service Credentials tab of your service dashboard.\n* Your instance's deployment IBM Cloud region. You can find your region by looking at the console.\n\n\n\nTable 1. IBM Cloud regions and corresponding SDK values\n\n IBM Cloud Region SDK value \n\n US South AppID.REGION_US_SOUTH \n Sydney AppID.REGION_SYDNEY \n United Kingdom AppID.REGION_UK \n Germany AppID.REGION_GERMANY \n\n\n\n\n\n\n\n\n\n\n\n Authenticating with the Android SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you can get started:\n\n\n\n* API 27 or higher\n* Java 8.x\n* Android SDK Tools 26.1.1+\n* Android SDK Platform Tools 27.0.1+\n* Android Build Tools version 27.0.0+\n\n\n\n\n\n\n\n Installing the SDK \n\n\n\n1. Create an Android Studio project or open an existing project.\n2. Add the JitPack repository to your root build.gradle file.\n\nallprojects {\nrepositories {\n...\nmaven { url 'https://jitpack.io' }\n}\n}\n3. Find your application's build.gradle file. Note: Be sure to open the file for your app, not the project build.gradle file.\n\n\n\n1. Add the App ID client SDK to the dependencies section.\n\ndependencies {\ncompile group: 'com.github.ibm-cloud-security:appid-clientsdk-android:4.+'\n}\n2. In the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-mobile-apps"}, {"document_id": "ibmcld_02772-4213-5899", "score": 15.979497, "text": "\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-mobile-apps"}, {"document_id": "ibmcld_10817-6582-8092", "score": 15.84234, "text": "\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http://localhost:8080\"\n\nIn this example, you use an installation that is running at http://localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https://us-south.functions.cloud.ibm.com](https://us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n// create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n// create an NSURLSession that uses the trusting delegate", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_04518-7-1743", "score": 15.549691, "text": "\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https://cocoapods.org) or [Carthage](https://github.com/Carthage/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_07546-7265-8726", "score": 15.091539, "text": "\nimport com.ibm.mobilefirstplatform.clientsdk.android.push.api.MFPPush;\n\n// with this\n\nimport com.ibm.cloud.eventnotifications.destination.android.ENPush;\n3. Initialize the new SDK\n\n// Replace the below section\n\nBMSClient.getInstance().initialize(this, \"ibmCloudRegionSuffix\");\nMFPPush push = MFPPush.getInstance();\npush.initialize(getApplicationContext(), \"appGUID\", \"clientSecret\");\n\n// with this\n\nString instanceGUID = \"<instance_guid>>\";\nString destinationID = \"<instance_destination_id>\";\nString apiKey = \"<instance_apikey>\";\n\nENPush enPush = ENPush.getInstance();\npush.setCloudRegion(ENPush.REGION_US_SOUTH); // Set your region\n\npush.initialize(getApplicationContext(),instanceGUID,destinationID, apiKey);\nShow more\n\nThere are additional fields like destinationID and apikey in the new initialize() method.\n\nFor more information, on getting the apikey for client SDK see [Managing service access](https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-service-access-management).\n4. The callback class in the new SDK has changes. Make these changes in the listener.\n\n// Replace the below section\n\nMFPPushNotificationListener notificationListener = new MFPPushNotificationListener() {\n\n@Override\npublic void onReceive (final MFPSimplePushNotification message){\n// Handle Push Notification\n}\n};\n\npush.listen(notificationListener)\n\n// with this\n\nENPushNotificationListener notificationListener = new ENPushNotificationListener() {\n\n@Override", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-migrate-apps"}, {"document_id": "ibmcld_12339-0-1594", "score": 14.951637, "text": "\n\n\n\n\n\n\n  Java \n\nAs a standard bearer for enterprise application development and the native application language for Android, Java is a key language to support for your IBM Cloud service.\n\n\n\n  Content \n\n\n\n  Methods \n\nMethod parameters MUST be encapsulated into an \u201coptions\u201d object that can be constructed with a \"Builder\".\n\n\n\n\n\n  Streaming \n\nThe SDK SHOULD accept parameters with potentially large memory requirements as InputStream values, to allow the value to be streamed to the service.\n\n\n\n\n\n\n\n  Style guidelines \n\nFor services that support both a traditional Java SDK and an Android SDK, the Java SDK SHOULD be designed to be Android compatible, to minimize duplication of code.\n\nYou should follow a coding style based on the [Google Java Style Guide](https://google.github.io/styleguide/javaguide.html).\n\nYou should use the standard [development tools](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-devtools) for Java to check style and code coverage.\n\n\n\n\n\n  Documentation \n\nYour SDK is not useful if your audience cannot understand how to consume it in order to do the basic operations for your service. Your SDK needs to contain the following resources to help your users:\n\n\n\n*  README.md\n*  [Contributor guidelines](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-documentationsdk-contributor-docs)\n*  Code Samples\n*  [Service documentation](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-documentation)\n\n\n\n\n\n\n\n  Distribution \n\n\n\n  Package management \n\nOfficial SDK releases MUST be published in [Maven Central](https://search.maven.org/).\n\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-java"}, {"document_id": "ibmcld_10817-1342-3184", "score": 14.889403, "text": "\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage/build/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}]}
{"task_id": "c01c8cf11437e6bb3bc93efac26528c2<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10817-1342-3184", "score": 19.121124, "text": "\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage/build/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_10817-7-1802", "score": 18.43359, "text": "\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_04518-1426-3052", "score": 17.583286, "text": "\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https://github.com/Carthage/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https://github.com/Carthage/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_02772-4213-5899", "score": 16.354685, "text": "\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-mobile-apps"}, {"document_id": "ibmcld_04518-7-1743", "score": 16.286596, "text": "\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https://cocoapods.org) or [Carthage](https://github.com/Carthage/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_07551-14062-16080", "score": 16.009815, "text": "\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https://jsonpath.com/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_10852-43319-44485", "score": 13.702537, "text": "\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_06805-52775-54523", "score": 11.633209, "text": "\nIf there are any issues found, while the --current-status was passed as success, the command closes those issues.\n\nIf --read-only is set, the command does not create new issues or amend existing ones. Results are processed, and existing issues are collected for results. The output contains the issue URL list that are supposed to be tracked in issues if the read-only mode is not activated.\n\nUsage:\n\ncocoa incident process-legacy <options>\n\nOptions:\n\n--type (Required) Tool type\n--subject (Required) Subject of scans (repo, or image name)\n--drilldown-url (Required) URL to the point where the incident was found (can be a pipeline run, a commit hash or an image URL with digest)\n--set-grace-period Should the created incidents have Grace period set\n--git-provider Git service provider [github] Default is \"github\"\n--org The incident issue repository org\n--repo The incident issue repository name\n--label Label(s) to add to the incident issue (optional) e.g: --label=foo --label=bar\n--assignee (Optional) Assignee(s) for the incident issue (github username) e.g: --assignee=jane-doe --assignee=john-smith\n--git-token-path (Optional) Github Token's path\n--git-api-url (Optional) Github API url\n--close-resolved-issues (Optional) Checking and closing resolved issues\n--pipeline-run-url (Optional) The url to the pipeline run running the CLI command\n--is-prod (Optional) Flag for whether or not the command was run in production environment. Default is false.\n--read-only (Optional) Process result file in read-only mode (return found and existing issues, do not create new ones, set processed status to failure or success). Default is false\n--custom-exempt-label (Optional) Defines the custom label with which the incident has been marked as exempted", "title": "", "source": "https://cloud.ibm.com/docs/devsecops?topic=devsecops-cd-devsecops-cli"}, {"document_id": "ibmcld_06805-51238-53254", "score": 11.518535, "text": "\nIf both of them are provided, --git-token-path and --git-api-url take precedence.\n\nReturn values:\n\n\n\n* The command lists incident issue URLs found or created according to the result file and subject.\n* If no issues are found, or all found issues have either Exempt or Grace period set, the command exits with zero status.\n* If any of the issues that are found have no Exempt or Grace Period set, the command exits with a nonzero status.\n\n\n\nRunning the command:\n\n$ cocoa incident process --type va --subject us.icr.io/service-image --drilldown-url us.icr.io/service-image@sha256:digest path/to/scan-result.json\n\n\n\n\n\n cocoa incident process-legacy \n\nThis command creates incident issues in the provided repository for scenarios when a scan file isn't available. Typically, such scenarios would be non-vulnerability related failures like unit-test failure, branch protection failure, acceptance test failure, and image signing failure. These failures would be non-vulnerabilities, yet they would be a deviation from the compliance posture. If issues exist already for incident-subject-tool combinations, the command does not create new ones. By default, high severity rating is set to issues created.\n\nIf --set-due-date is set, the command either creates issues, or updates existing issues with due dates. The due dates are calculated from the grace period of the issue, based on the severity.\n\nIf --close-resolved-issues flag is set, the command searches for open issues with the same tool, subject and the incident ID as the current run. If there are any issues found, while the --current-status was passed as success, the command closes those issues.\n\nIf --read-only is set, the command does not create new issues or amend existing ones. Results are processed, and existing issues are collected for results. The output contains the issue URL list that are supposed to be tracked in issues if the read-only mode is not activated.\n\nUsage:\n\ncocoa incident process-legacy <options>\n\nOptions:\n\n--type (Required) Tool type", "title": "", "source": "https://cloud.ibm.com/docs/devsecops?topic=devsecops-cd-devsecops-cli"}, {"document_id": "ibmcld_06849-16620-18154", "score": 11.5178175, "text": "\n}\n],\n\"issues\": [\n\"https://github.ibm.com/cocoa-test/e2e-compliance-incident-issues-20220331113709516/issues/6\",\n\"https://github.ibm.com/cocoa-test/e2e-compliance-incident-issues-20220331113709516/issues/7\",\n\"https://github.ibm.com/cocoa-test/e2e-compliance-incident-issues-20220331113709516/issues/8\"\n],\n\"tool\": \"owasp-zap-ui\"\n}\nShow more\n\nWhere evidence_collection_subject is the repository_url for a repo scan and the artifactory_url for an image scan.\n\n\n\n\n\n\n\n v1 evidence summary \n\nThe DevSecOps pipeline creates an evidence summary document. This document is based on evidence that is created during each of the continuous integration builds that deploy an image, and the evidence that is created during the deployment itself. The summary is created for the change request that is required to deploy any stage; it is also used by the Security and Compliance Center integration.\n\nThe format and fields of the evidence summary document are specified by using the typescript syntax:\n\ninterface Summary {\nversion: '1.0'; // schema version\ndate: string; // ISO-8601, UTC, ie. YYYY-MM-DDThh:mm:ssZ\ntoolchain_crn: string; // CRN of the toolchain that generated the summary\npipeline_id: string; // ID of the pipeline that generated the summary\npipeline_run_id: string; // ID of the pipeline run that generated the summary\nevidences: Evidence[];\n}\n\n\n\n Example \n\n{\n\"date\": \"23-43-2020 UTC\",\n\"version\": \"1.0\",\n\"pipeline_run_id\": 12345, // this is the id of the CD pipeline that deploys in prod, not all data below may come from this pipeline", "title": "", "source": "https://cloud.ibm.com/docs/devsecops?topic=devsecops-devsecops-evidence"}]}
{"task_id": "c01c8cf11437e6bb3bc93efac26528c2<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10817-1342-3184", "score": 25.309298, "text": "\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage/build/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_10817-7-1802", "score": 24.938204, "text": "\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_04518-1426-3052", "score": 21.08487, "text": "\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https://github.com/Carthage/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https://github.com/Carthage/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_04518-7-1743", "score": 21.042166, "text": "\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https://cocoapods.org) or [Carthage](https://github.com/Carthage/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_07551-14062-16080", "score": 20.94422, "text": "\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https://jsonpath.com/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_02772-4213-5899", "score": 20.73022, "text": "\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-mobile-apps"}, {"document_id": "ibmcld_10852-43319-44485", "score": 18.632025, "text": "\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_09479-6537-8273", "score": 13.088023, "text": "\n* Port max = 3389\n* Source type = Any\n\n\n\n\n\n2. Obtain the connection information you need to connect to the Windows VPC.\n\n\n\n1. Click Virtual server instances.\n2. Click the name of your Windows VPC instance. The instance details are displayed.\n3. Under Encrypted password click Download RDP file. A file that can be used with Windows Remote Desktop will be downloaded.\n\nIf you are using another client to connect to your Windows VPC, you can still use the information contained in the RDP file to get the connection information for the VPC.\n\n\n\n3. Connect to your Windows VPC using a remote desktop client and the RDP file information. Sign in with the User name of .Administrator and the decripted ssh key as the password.\n\n\n\n\n\n\n\n Install NXLog \n\nFollow these steps to install NXLog.\n\nYou will need to run as a Windows Administrator for all command prompt or PowerShell steps.\n\n\n\n1. The [Chocolately package manager](https://chocolatey.org/) is used to install NXLog. Run one of the following if you do not have the package manager already installed.\n\nFrom a Windows command prompt (cmd.exe):\n\npowershell -command \"Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))\"\n\nFrom a PowerShell prompt:\n\nSet-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))\n2. Run the following command in PowerShell to install NXLog Community Edition.", "title": "", "source": "https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-windows_vpc_tutorial"}, {"document_id": "ibmcld_13430-11933-13740", "score": 13.050091, "text": "\n: Known issue: The Swedish telephony (sv-SE_Telephony) and Italian multimedia (it-IT_Multimedia) models are not yet available. They will be made available with version 4.6.5.\n\nDefect fix: You can now change the installed models and voices with the advanced installation options\n: Defect fix: During installation, you can now specify different models or voices with the advanced installation options of the command-line interface. Previously, the service always installed the default models and voices. The limitation continues to apply for Watson Speech services versions 4.6.0, 4.6.2, and 4.6.3. For information about installing models and voices, see Specifying additional installation options in [Installing Watson Speech services](https://www.ibm.com/docs/en/cloud-paks/cp-data/4.6.x?topic=services-installing).\n\nSetting load balancer timeouts\n: Watson Speech services require that you change the load balancer timeout settings for both the server and client to 300 seconds. These settings ensure that long-running speech recognition requests, those with long or difficult audio, have sufficient time to complete. For more information, see Information you need to complete this task in [Installing Watson Speech services](https://www.ibm.com/docs/en/cloud-paks/cp-data/4.6.x?topic=services-installing).\n\nSecurity vulnerabilities addressed\n: The following security vulnerabilities have been fixed:\n\n\n\n* [Security Bulletin: IBM Watson Speech Services Cartridge for IBM Cloud Pak for Data is vulnerable to cross-site scripting in GNOME libxml2 (CVE-2016-3709](https://www.ibm.com/support/pages/node/6967621)\n* [Security Bulletin: IBM Watson Speech Services Cartridge for IBM Cloud Pak for Data is vulnerable to a denial of service in SQlite (CVE-2020-35525)](https://www.ibm.com/support/pages/node/6967623)", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-release-notes-data"}, {"document_id": "ibmcld_05880-1367-2045", "score": 12.755373, "text": "\nIn the dialog box, click Install. Note that it can take a few minutes for the add-on to be installed.\n4. On the Diagnostics and Debug Tool card, click Dashboard.\n5. In the debug tool dashboard, select the istio_control_plane or istio_resources group of tests. Some tests check for potential warnings, errors, or issues, and some tests only gather information that you can reference while you troubleshoot. For more information about the function of each test, click the information icon next to the test's name.\n6. Click Run.\n7. Check the results of each test. If any test fails, click the information icon next to the test's name for information about how to resolve the issue.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-istio_debug_tool"}]}
{"task_id": "c01c8cf11437e6bb3bc93efac26528c2<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10817-1342-3184", "score": 19.696482, "text": "\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage/build/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_04518-1426-3052", "score": 18.884956, "text": "\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https://github.com/Carthage/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https://github.com/Carthage/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_10817-7-1802", "score": 17.964684, "text": "\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_07551-14062-16080", "score": 17.704395, "text": "\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https://jsonpath.com/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_02772-4213-5899", "score": 17.121113, "text": "\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-mobile-apps"}, {"document_id": "ibmcld_04518-7-1743", "score": 16.90811, "text": "\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https://cocoapods.org) or [Carthage](https://github.com/Carthage/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_12332-1034-2510", "score": 11.749103, "text": "\nYour Go SDK should be packaged as a [Go Module](https://blog.golang.org/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https://search.maven.org/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https://www.npmjs.com/) package within the [ibm-cloud](https://www.npmjs.com/org/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https://pypi.python.org/) / [pip](https://pypi.python.org/pypi/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https://swift.org/package-manager/) / [CocoaPods](https://cocoapods.org/) / [Carthage](https://github.com/Carthage/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https://github.com/IBM/ibm-cloud-sdk-common).", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-devtools"}, {"document_id": "ibmcld_10852-43319-44485", "score": 11.12509, "text": "\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_06097-5888-7083", "score": 11.083715, "text": "\nerror \"$(date +\"%b %d %G %H:%M:%S\"): Unable to fetch controller pod.\"\nif [ \"$controllerPodName\" == \"\" ]]; then\necho \"$(date +\"%b %d %G %H:%M:%S\"): VPC Block CSI Driver addon is not enabled\"\nexit 1\nfi\n\necho \"apiVersion: v1\ndata:\nibm-credentials.env: $encodedValue\nkind: Secret\nmetadata:\nname: ibm-cloud-credentials\nnamespace: kube-system\ntype: Opaque\" > ibm-cloud-credentials.yaml\n\ncreate the k8s secret\nkubectl apply -f ibm-cloud-credentials.yaml &> /dev/null\nerror \"$(date +\"%b %d %G %H:%M:%S\"): Error creating ibm-cloud-credentials secret.\"\necho \"$(date +\"%b %d %G %H:%M:%S\"): Created ibm-cloud-credentials secret\"\n\nrestart the controller pod\necho \"$(date +\"%b %d %G %H:%M:%S\"): Restarting $controllerPodName pod\"\nkubectl delete pod $controllerPodName -n kube-system &> /dev/null\nerror \"$(date +\"%b %d %G %H:%M:%S\"): Error restarting $controllerPodName pod in kube-system namespace.\"\n\ncontrollerPodStatus=\nfor i in {1..12}\ndo\nsleep 5\ncontrollerPodStatus=$(kubectl get pods -n kube-system | grep ibm-vpc-block-csi-controller | awk '{print $3}')\nif [ \"$controllerPodStatus\" == \"Running\" ]]; then\necho \"$(date +\"%b %d %G %H:%M:%S\"): VPC Block CSI Driver is now using ibm-cloud-credentials secret\"", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-storage-block-vpc-trusted-profiles"}, {"document_id": "ibmcld_06058-1513-3112", "score": 10.715415, "text": "\nThis process is also referred to as no root squash. An effective way of updating all your worker nodes is to use a daemon set, which runs a specified pod on every worker node in your cluster. In this case, the pod that is controlled by the daemon set updates each of your worker nodes to enable root permission on the volume mount path.\n\nThe deployment is configured to allow the daemon set pod to run in privileged mode, which is necessary to access the host file system. Running a pod in privileged mode does create a security risk, so use this option with caution.\n\nWhile the daemon set is running, new worker nodes that are added to the cluster are automatically updated.\n\nBefore you begin:\n\n\n\n* [Create persistent storage](https://cloud.ibm.com/docs/containers?topic=containers-file_storageadd_file).\n* [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\n\n\nSteps:\n\n\n\n1. Copy the norootsquash daemon set [deployment YAML file](https://github.com/IBM-Cloud/kube-samples/tree/master/daemonset-sample)\n2. Create the norootsquash daemon set deployment.\n\nkubectl apply -f norootsquash.yaml\n3. Get the name of the pod that your storage volume is mounted to. This pod is not the same as the norootsquash pods.\n\nkubectl get pods\n4. Log in to the pod.\n\nkubectl exec -it mypod /bin/bash\n5. Verify that the permissions to the mount path are root.\n\nroot@mypod:/ ls -al /mnt/myvol/\ntotal 8\ndrwxr-xr-x 2 root root 4096 Feb 7 20:49 .\ndrwxr-xr-x 1 root root 4096 Feb 20 18:19 .", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-root"}]}
{"task_id": "c01c8cf11437e6bb3bc93efac26528c2<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07551-15747-17355", "score": 14.318679, "text": "\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https://github.com/IBM/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n/Register iOS devices/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_10817-1342-3184", "score": 14.28213, "text": "\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage/build/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_04518-1426-3052", "score": 14.187986, "text": "\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https://github.com/Carthage/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https://github.com/Carthage/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_10852-44214-45420", "score": 13.249509, "text": "\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_07551-14062-16080", "score": 11.405429, "text": "\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https://jsonpath.com/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_04518-7-1743", "score": 11.014852, "text": "\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https://cocoapods.org) or [Carthage](https://github.com/Carthage/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_12332-1034-2510", "score": 10.2632885, "text": "\nYour Go SDK should be packaged as a [Go Module](https://blog.golang.org/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https://search.maven.org/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https://www.npmjs.com/) package within the [ibm-cloud](https://www.npmjs.com/org/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https://pypi.python.org/) / [pip](https://pypi.python.org/pypi/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https://swift.org/package-manager/) / [CocoaPods](https://cocoapods.org/) / [Carthage](https://github.com/Carthage/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https://github.com/IBM/ibm-cloud-sdk-common).", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-devtools"}, {"document_id": "ibmcld_10852-43319-44485", "score": 8.858393, "text": "\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_05001-3597-5431", "score": 7.218972, "text": "\nSample instructions are provided for using a client application or command line once your CLI client has been configured and is operational.\n\n\n\n rClone example \n\nThe rclone tool is typically used to keep directories synchronized and for migrating data between storage platforms. You can learn more from the documentation on [!using rclone](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-rclone).\n\nrclone purge {remote}:{path} [flags]\n\n\n\n\n\n Minio example \n\nThe open source Minio client allows you to use UNIX-like commands (ls, cp, cat, etc.) with IBM Cloud\u00ae Object Storage. For more information, check out [using Minio](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-minio).\n\nmc rm --recursive --force {instance-alias}/{bucket-name}\n\n\n\n\n\n AWS example \n\nThe official command-line interface for AWS is compatible with the IBM Cloud Object Storage S3 API and you can find out more on how to [use the AWS CLI](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-aws-cli).\n\naws s3 rm s3://{bucket-name} --recursive\n\n\n\n\n\n\n\n Code Example \n\nDeleting an entire directory or removing all the contents of a bucket can be time consuming deleting each object, one at a time. The ability to delete one item at a time can be leveraged to save time and effort by collecting a list of all the items before deletion.\n\nThe topic itself points out the danger of deletion: data will be lost. Of course, when that is the goal, caution should be exercised that only the targeted deletions should occur. Check\u2014and double-check\u2014instances, bucket names, and any prefixes or paths that need to be specified.\n\n\n\n Overview \n\nThe code pattern in this exercise configures a client before creating one for the purpose of gathering a list of items for the purpose of deleting each object.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-deleting-multiple-objects-patterns"}, {"document_id": "ibmcld_05171-4-2124", "score": 7.087163, "text": "\n{:step: data-tutorial-type=\"step\"} {:hide-dashboard: .hide-dashboard} {:apikey: data-credential-placeholder=\"apikey\"}\n\n\n\n Developing a web application \n\nThis tutorial shows you how to build a simple image gallery using IBM Cloud\u00ae Object Storage, bringing together many different concepts and practices key to web development.\n\nFrom beginning to end, building a web application covers a lot of different concepts and is a great way to introduce yourself to the features of IBM Cloud Object Storage. Your application uses IBM Cloud Object Storage for storage in a Node.js application that allows a user to upload and view JPEG image files.\n\n\n\n The Scenario \n\nThe scenario for this tutorial involves many moving parts:\n\n\n\n* A web server to host the web application\n* Use of the command line\n* A storage instance for the images in the gallery\n* A version control system integrated into continuous delivery\n* Client-side application bindings in both scripts and markup\n* Images to upload and display\n\n\n\nAnd if you are looking for all that in one package, this tutorial will provide a complete, start-to-finish, example for you. However, this instruction can only temporarily set aside principles of security and secure code. Web applications actually put into production require proper security, or they won't be suitable for possible visitors.\n\n\n\n\n\n Before you begin \n\nEnsure that you have what you need to start:\n\n\n\n* An account for the IBM Cloud Platform\n* Docker, as part of the IBM Cloud Developer Tools\n* Node.js\n* Git (both desktop and command line)\n\n\n\n\n\n Using the Command Line \n\nLet's start by opening a tool familiar to experienced developers, and a new best friend to those just getting started: the command line. For many, the graphic user interface (GUI) relegated your computer's command-line interface to second-class status. But now, it's time to bring it back (although the GUI isn't going away anytime soon, especially when we need to browse the web to download instructions for the command-line toolset).\n\nOpen a shell and create a directory. Change your own reference directory to the new one you created.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-web-application"}]}
{"task_id": "c01c8cf11437e6bb3bc93efac26528c2<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10852-44214-45420", "score": 25.980938, "text": "\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_10817-1342-3184", "score": 24.708542, "text": "\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage/build/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_04518-7-1743", "score": 22.869898, "text": "\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https://cocoapods.org) or [Carthage](https://github.com/Carthage/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_10817-7-1802", "score": 22.554228, "text": "\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_04518-1426-3052", "score": 22.512163, "text": "\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https://github.com/Carthage/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https://github.com/Carthage/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_07551-15747-17355", "score": 20.7236, "text": "\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https://github.com/IBM/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n/Register iOS devices/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_12332-1034-2510", "score": 19.974876, "text": "\nYour Go SDK should be packaged as a [Go Module](https://blog.golang.org/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https://search.maven.org/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https://www.npmjs.com/) package within the [ibm-cloud](https://www.npmjs.com/org/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https://pypi.python.org/) / [pip](https://pypi.python.org/pypi/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https://swift.org/package-manager/) / [CocoaPods](https://cocoapods.org/) / [Carthage](https://github.com/Carthage/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https://github.com/IBM/ibm-cloud-sdk-common).", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-devtools"}, {"document_id": "ibmcld_10852-43319-44485", "score": 19.21806, "text": "\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_10817-2884-4620", "score": 16.974766, "text": "\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in /Library/Developer/Xcode/DerivedData/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_07551-14062-16080", "score": 16.07073, "text": "\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https://jsonpath.com/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}]}
{"task_id": "c01c8cf11437e6bb3bc93efac26528c2<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10852-44214-45420", "score": 19.22444, "text": "\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_10817-1342-3184", "score": 18.578583, "text": "\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage/build/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_04518-1426-3052", "score": 16.689722, "text": "\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https://github.com/Carthage/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https://github.com/Carthage/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_12332-1034-2510", "score": 16.547852, "text": "\nYour Go SDK should be packaged as a [Go Module](https://blog.golang.org/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https://search.maven.org/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https://www.npmjs.com/) package within the [ibm-cloud](https://www.npmjs.com/org/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https://pypi.python.org/) / [pip](https://pypi.python.org/pypi/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https://swift.org/package-manager/) / [CocoaPods](https://cocoapods.org/) / [Carthage](https://github.com/Carthage/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https://github.com/IBM/ibm-cloud-sdk-common).", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-devtools"}, {"document_id": "ibmcld_07551-15747-17355", "score": 15.206232, "text": "\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https://github.com/IBM/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n/Register iOS devices/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_04518-7-1743", "score": 13.890176, "text": "\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https://cocoapods.org) or [Carthage](https://github.com/Carthage/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_10852-43319-44485", "score": 12.342788, "text": "\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_07551-14062-16080", "score": 12.228251, "text": "\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https://jsonpath.com/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_12897-1586-3529", "score": 12.137474, "text": "\n2. Confirm that a client is trying to modify the latest version of a document.\n\n\n\nYou must specify the previous _rev when you [update a document](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-documentsupdate) or else your request fails and returns a [409 error](https://cloud.ibm.com/apidocs/cloudantlist-of-http-codes).\n\n_rev must not be used to build a version control system because it is an internal value that is used by the server. Therefore, older revisions of a document are transient, and removed regularly.\n\nHowever, you can query a particular revision by using its _rev, but older revisions are regularly deleted by a process called [compaction](https://en.wikipedia.org/wiki/Data_compaction). You can query a particular document revision by using its _rev in order to obtain a history of revisions to your document. However, a consequence of compaction is that you cannot rely on a successful response. If you need a version history of your documents, a solution is to [create a new document](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-documentscreate-document) for each revision.\n\n\n\n\n\n Distributed databases and conflicts \n\nDistributed databases work without a constant connection to the main database on IBM Cloudant, which is itself distributed, so updates based on the same previous version can still be in conflict.\n\nTo find conflicts, add the query parameter [conflicts=true](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-databasesget-changes) when you retrieve a document. The response contains a _conflicts array with all conflicting revisions.\n\nTo find conflicts for multiple documents in a database, write a view.\n\nThe following map function is an example that emits all conflicting revisions for every document that has a conflict.\n\nSee the following example of a map function to find documents with a conflict:\n\nfunction (doc) {\nif (doc._conflicts) {\nemit(null, [doc._rev].concat(doc._conflicts));\n}\n}", "title": "", "source": "https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-document-versioning-and-mvcc"}, {"document_id": "ibmcld_06397-7-2189", "score": 11.890328, "text": "\nDatabase Versioning Policy \n\nWhen you provision a Cloud Databases deployment, you can choose from the versions currently available on IBM Cloud. Find the latest versions from the [catalog pages](https://cloud.ibm.com/catalog?category=databases), the [IBM Cloud Databases CLI](https://cloud.ibm.com/docs/databases-cli-plugin?topic=databases-cli-plugin-cdb-referencedeployables-show), or the [IBM Cloud Databases API](https://cloud.ibm.com/apidocs/cloud-databases-apiget-all-deployable-databases).\n\n\n\n Version Tags \n\nPreferred - The recommended and default database version for all new deployments. It's the most stable, up-to-date version of the database from both a database-level and service-level perspective.\n\nPreview - A preview database version is released for a limited time to try available functions. Often it is the newest available version available from the database project maintainers in preparation for making it the \"Preferred\" version. While deployable, preview versions are not suitable for production, as they are excluded from service-level agreements and support. Also, a preview version isn't guaranteed to become a production-level release. IBM reserves the right to ask a customer to delete a deployment that uses a preview version.\n\nDeprecated - Old versions and versions nearing their end of life dates are marked as \"Deprecated\". Provisions and restores of deployments that run a deprecated version are still available and deployments that are running a deprecated version continue to be supported. However, you are encouraged to upgrade to the new \"Preferred\" version of the database as deprecated versions are eventually removed from IBM Cloud and are no longer provisionable, restorable, or supported.\n\nUntagged - Untagged database versions are fully supported and deployable versions. They are usually slightly older than the current preferred version, but they are still supported by the database project maintainers. They continue to be supported on Cloud Databases deployments until their deprecation is announced.\n\n\n\n\n\n Deprecation of Major Versions \n\nIBM Cloud Databases tries to support a major version of a database for 3 years from its release.", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-enterprisedb?topic=cloud-databases-versioning-policy"}]}
{"task_id": "b4614daadceeecb400f7baf0aa48dcb8<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07191-1691-3739", "score": 15.754233, "text": "\nIf you test the same search term on a small data set, you might find that the filter and query parameters return very similar (if not identical) results. However, there is a difference between the two parameters.\n\n\n\n* Using a filter parameter alone returns search results in no specific order.\n* Using a query parameter alone returns search results in order of relevance.\n\n\n\nIn large data sets, if you need results returned in order of relevance, it is advisable that you combine the filter and query parameters because using them together improves performance. The reason is because the filter parameter runs first and caches results, and then the query parameter ranks them. For an example of using filters and queries together, see [Building combined queries](https://cloud.ibm.com/docs/discovery?topic=discovery-query-conceptsbuilding-combined-queries). Filters can also be used in aggregations.\n\nWhen you write a query that includes both a filter, and an aggregation, query, or natural_language_query parameter; the filter parameters run first, after which any aggregation, query, or natural_language_query parameters run in parallel.\n\nWith a simple query, especially on a small data set, filter and query often return the exact same (or similar) results. If a filter and query call return similar results, and getting a response in order of relevance does not matter, it is better to use filter because filter calls are faster and are cached. Caching means that the next time you make that call, you get a much quicker response, particularly in a big data set.\n\n\n\n\n\n\n\n aggregation \n\nAggregation queries return a count of documents matching a set of data values; for example, top keywords, overall sentiment of entities, and more. For the full list of aggregation options, see the [Aggregations table](https://cloud.ibm.com/docs/discovery?topic=discovery-query-aggregations). These aggregations are written using the [Discovery Query Language](https://cloud.ibm.com/docs/discovery?topic=discovery-query-operators).\n\n\n\n\n\n natural_language_query", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-query-parameters"}, {"document_id": "ibmcld_12845-3742-5554", "score": 15.533005, "text": "\n: An array of selected values that are associated with the custom parameter that you want to interact with. This parameter shows in the UI when one of those values is selected.\n\nparameters.associations.parameters.optionsRefresh\n: When this parameter is set to true, the optionsUrl is called when the associated parameter value is changed and this parameter is visible in the UI.\n\nparameters.optionsUrl\n: The API that is called by the console to get a list of options for dropdown, check box, or radio input type. The response is a JSON structure that contains two fields:\n\noptions\n: An array of JSON that will return parameters.options; for more details see the entry for parameters.options.\n\nvalue\n: The new default value of the parameter. For more details, see the entry for parameters.value.\n\nThe console passes the ace_config query parameter, which contains the current org GUID, space GUID, the current value of all custom parameters, and the current price plan ID. The bearer token is propagated in the header.\n\nparameters.invalidmessage\n: The message that appears when the content of the text box is invalid.\n\nparameters.description\n: The description of the parameter that is displayed to help users with the value of the parameter.\n\nparameters.required\n: A Boolean value that indicates whether the parameter must be entered in the IBM Cloud user interface.\n\nparameters.pattern\n: A regular expression that the value is checked against.\n\nparameters.placeholder\n: A short hint that describes the expected value.\n\nparameters.readonly\n: A Boolean value that indicates whether the value of the parameter is displayed only and cannot be changed by users. The default value is false.\n\nparameters.hidden\n: A Boolean value that indicates whether the key-value pair is hidden from users. The default value is false.", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-service_parameters_def_examples"}, {"document_id": "ibmcld_07095-2569-4026", "score": 15.4793005, "text": "\nUsing the parameters together improves performance because the filter parameter is applied first. It filters the documents and caches the results. The query parameter then ranks the cached results.\n\n\n\n Filter example: Get a document by its ID \n\nQuery body:\n\n{\n\"filter\": \"document_id::b6d8c6e3-1097-421b-9e39-75717d2554aa\"\n}\n\nIf the document exists, the query returns 1 matching result. If it doesn't, the query returns no matching results.\n\n\n\n\n\n Filter example: Find a document ID by its file name \n\nIf you don't know the document_id of a document, but you know the original filename of the document, you can use the filter and return parameters together to discover the document_id.\n\nQuery body:\n\n{\n\"filter\": \"extracted_metadata.filename::100674.txt\",\n\"return\": [ \"document_id\", \"extracted_metadata\" ]\n}\n\nResponse:\n\n{\n\"matching_results\": 1,\n\"results\": [\n{\n\"document_id\": \"b6d8c6e3-1097-421b-9e39-75717d2554aa\",\n\"extracted_metadata\": {\n\"sha1\": \"AD447F7592A17CDCBF0A589C4E6EC2087AF7H35F\",\n\"filename\": \"100674.txt\",\n\"file_type\": \"text\"\n}\n}\n]\n}\n\n\n\n\n\n Filter example: Find documents that mention an entity value \n\nThe query looks for documents that mention the entity Gilroy and finds 4 matching documents.\n\nQuery body:\n\n{\n\"filter\": \"enriched_text.entities.text::Gilroy\"\n}\n\nResponse:\n\n{\n\"matching_results\": 4\n}\n\n\n\n\n\n\n\n Filtering nested values \n\nYou can nest one filter inside another to ensure that the documents that are returned match more than one condition.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-dql-overview"}, {"document_id": "ibmcld_07098-7-2215", "score": 15.268535, "text": "\nQuery parameters \n\nYou can use these parameters when you write queries with the Discovery Query Language. For more information, see the Discovery [API reference](https://cloud.ibm.com/apidocs/discovery-dataquery). For an overview of query concepts, see the [Query overview](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-concepts).\n\nQueries that are written in the Discovery Query Language can include both search and structure parameters.\n\nThe default values for query parameters can differ by project type. For more information about default values, see [Default query settings](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-defaults).\n\n\n\n Search parameters \n\nUse search parameters to search your collection, identify a result set, and analyze the result set.\n\nThe results set is the group of documents that are identified by the combined searches of the search parameters. The results set might be significantly larger than the returned results. If an empty query is submitted, the results set is equal to all the documents in the collection.\n\nDocuments that you do not have permissions to access are not returned in query results.\n\n\n\n\n\n Answer finding \n\nIBM Cloud\n\nThe find_answers parameter is supported in managed deployments only.\n\nBy default, Discovery provides answers by returning the entire [passage](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-parameterspassages) that contains the answer to a natural language query. When the answer-finding feature is enabled, Discovery also provides a \"short answer\" within the passage, and a confidence score to show whether the \"short answer\" answers the question that is explicit or implicit in the user query. Applications that use the answer-finding feature can display the short answer alone or can display the short answer emphasized in the context of the full passage. For most applications, displaying the short answer emphasized within the full passage is preferable, because answers generally make more sense in context.\n\nThe answer finding feature behaves in the following ways:\n\nIn the passage examples that follow, the short answers are shown in bold font.\n\n\n\n* Finds answers.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-parameters"}, {"document_id": "ibmcld_04353-90549-92065", "score": 15.174623, "text": "\nThis query parameter cannot be used in conjunction with the deactivation_date, expiration_date, deactivation_date_min, and deactivation_date_max query parameters. The value must match regular expression /[0-9]{4}-[0-9]{2}-[0-9]{2}/.\n\n--created-at (string)\n: Optional. Return only managed keys whose creation time matches the parameter. The value must match regular expression /[0-9]{4}-[0-9]{2}-[0-9]{2}/.\n\n--created-at-min (string)\n: Optional. Return only managed keys whose creation time is at or after the parameter value. This query parameter cannot be used in conjunction with the created_at query parameter. The value must match regular expression /[0-9]{4}-[0-9]{2}-[0-9]{2}/.\n\n--created-at-max (string)\n: Optional. Return only managed keys whose creation time is at or before the parameter value. This query parameter cannot be used in conjunction with the created_at query parameter. The value must match regular expression /[0-9]{4}-[0-9]{2}-[0-9]{2}/.\n\n--updated-at (string)\n: Optional. Return only managed keys whose update time matches the parameter. The value must match regular expression /[0-9]{4}-[0-9]{2}-[0-9]{2}/.\n\n--updated-at-min (string)\n: Optional. Return only managed keys whose update time is after the parameter value. This query parameter cannot be used in conjunction with the updated_at query parameter. The value must match regular expression /[0-9]{4}-[0-9]{2}-[0-9]{2}/.\n\n--updated-at-max (string)\n: Optional. Return only managed keys whose update time is before the parameter value.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-hpcs-cli-plugin"}, {"document_id": "ibmcld_08425-90779-92295", "score": 15.174623, "text": "\nThis query parameter cannot be used in conjunction with the deactivation_date, expiration_date, deactivation_date_min, and deactivation_date_max query parameters. The value must match regular expression /[0-9]{4}-[0-9]{2}-[0-9]{2}/.\n\n--created-at (string)\n: Optional. Return only managed keys whose creation time matches the parameter. The value must match regular expression /[0-9]{4}-[0-9]{2}-[0-9]{2}/.\n\n--created-at-min (string)\n: Optional. Return only managed keys whose creation time is at or after the parameter value. This query parameter cannot be used in conjunction with the created_at query parameter. The value must match regular expression /[0-9]{4}-[0-9]{2}-[0-9]{2}/.\n\n--created-at-max (string)\n: Optional. Return only managed keys whose creation time is at or before the parameter value. This query parameter cannot be used in conjunction with the created_at query parameter. The value must match regular expression /[0-9]{4}-[0-9]{2}-[0-9]{2}/.\n\n--updated-at (string)\n: Optional. Return only managed keys whose update time matches the parameter. The value must match regular expression /[0-9]{4}-[0-9]{2}-[0-9]{2}/.\n\n--updated-at-min (string)\n: Optional. Return only managed keys whose update time is after the parameter value. This query parameter cannot be used in conjunction with the updated_at query parameter. The value must match regular expression /[0-9]{4}-[0-9]{2}-[0-9]{2}/.\n\n--updated-at-max (string)\n: Optional. Return only managed keys whose update time is before the parameter value.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-cli-plugin-hpcs-cli-plugin"}, {"document_id": "ibmcld_16321-14177-15957", "score": 15.024301, "text": "\nThe WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https://cloud.ibm.com/apidocs/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use. For more information about voice model options, see [Supported languages and voices](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-voiceslanguageVoices).\n\nThe model you specify must be one that is supported by the Text to Speech service instance that is configured for use with the integration.\n\n\n\n\n\n\n\n Transferring a call to a live agent \n\nWhen you configure the phone integration, you can optionally set up backup call center support, which makes it possible for the assistant to transfer a call to a human.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actions"}, {"document_id": "ibmcld_13446-19419-21379", "score": 15.013319, "text": "\nIf you set the redaction parameter to true, the service automatically forces the smart_formatting parameter to be true, and it disables the keywords, keywords_threshold, max_alternatives, and (for the WebSocket interface) interim_results parameters. For more information, see [Numeric redaction](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-formattingnumeric-redaction).\n\n\n\nTable 22. The redaction parameter\n\n Availability and usage Description \n\n Previous-generation models Beta for US English, Japanese, and Korean. \n Next-generation models Beta for US English, Japanese, and Korean. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST /v1/recognize method \n Asynchronous HTTP Query parameter of POST /v1/recognitions method \n\n\n\n\n\n\n\n smart_formatting \n\nAn optional boolean that indicates whether the service converts dates, times, numbers, currency, and similar values into more conventional representations in the final transcript. For US English, the feature also converts certain keyword phrases into punctuation symbols. By default (false), smart formatting is not performed. For more information, see [Smart formatting](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-formattingsmart-formatting).\n\n\n\nTable 23. The smart_formatting parameter\n\n Availability and usage Description \n\n Previous-generation models Beta for US English, Japanese, and Spanish (all dialects). \n Next-generation models Beta for US English, Japanese, and Spanish (all dialects). It also also available for the en-WW_Medical_Telephony model when US English audio is recognized. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST /v1/recognize method \n Asynchronous HTTP Query parameter of POST /v1/recognitions method \n\n\n\n\n\n\n\n speaker_labels \n\nAn optional boolean that indicates whether the service identifies which individuals spoke which words in a multi-participant exchange.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-summary"}, {"document_id": "ibmcld_02569-4530-5596", "score": 14.974009, "text": "\nIt is expected for message values to duplicate information from code, target, and custom extensions to the error model.\n\nImportantly, message values are still meant for developers and for this reason SHOULD NOT be localized or written for use in a user interface. Fields mentioned within a message SHOULD be mentioned by exact field name (e.g., first_name, not \"first name\").\n\nConsider the example above of an error code with value invalid_color. A poor message would be:\n\n\"The color provided for paint was invalid.\"\n\nUnlike the code, a message MAY prescribe a specific solution, thereby adding value. A better message would be:\n\n\"The color for paint must be red or blue.\"\n\nAs demonstrated in the above examples, message values SHOULD use the back-tick character to enclose field names, parameter names, header names, and specific values.\n\n\n\n\n\n\n\n Robustness tradeoffs \n\nThe robustness principle section has been moved to a [new page](https://cloud.ibm.com/docs/api-handbook?topic=api-handbook-robustness), and the previous guidance has been substantially repudiated.", "title": "", "source": "https://cloud.ibm.com/docs/api-handbook?topic=api-handbook-errors"}, {"document_id": "ibmcld_09701-13735-14292", "score": 14.878196, "text": "\nThe value of this parameter must be a multiple of 60000000 microseconds.\n\n\n\n\n\n version (integer) \n\nVersion of an alert.\n\nThe version changes every time you update an alert.\n\nThe version is used for optimistic locking.\n\n\n\n\n\n\n\n Query parameters \n\n\n\n alertId (integer) \n\nID of an alert.\n\n\n\n\n\n from (long) \n\nDefines the start timestamp, in microseconds, that is used when you request information about alerts that are defined.\n\n\n\n\n\n to (long) \n\nDefines the end timestamp, in microseconds, that is used when you request information about alerts that are defined.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-alert_api"}]}
{"task_id": "b4614daadceeecb400f7baf0aa48dcb8<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16321-14177-15957", "score": 19.927404, "text": "\nThe WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https://cloud.ibm.com/apidocs/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use. For more information about voice model options, see [Supported languages and voices](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-voiceslanguageVoices).\n\nThe model you specify must be one that is supported by the Text to Speech service instance that is configured for use with the integration.\n\n\n\n\n\n\n\n Transferring a call to a live agent \n\nWhen you configure the phone integration, you can optionally set up backup call center support, which makes it possible for the assistant to transfer a call to a human.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actions"}, {"document_id": "ibmcld_13455-13739-15986", "score": 19.083519, "text": "\n* By sending a JSON text message with the action parameter set to the value stop:\n\n{action: 'stop'}\n* By sending an empty binary message, one in which the specified blob is empty:\n\nwebsocket.send(blob)\n\n\n\nIf the client fails to signal that the transmission is complete, the connection can time out without the service sending final results. To receive final results between multiple recognition requests, the client must signal the end of transmission for the previous request before it sends a subsequent request. After it returns the final results for the first request, the service returns another {\"state\":\"listening\"} message to the client. This message indicates that the service is ready to receive another request.\n\n\n\n\n\n Send additional requests and modify request parameters \n\nWhile the WebSocket connection remains active, the client can continue to use the connection to send further recognition requests with new audio. By default, the service continues to use the parameters that were sent with the previous start message for all subsequent requests that are sent over the same connection.\n\nTo change the parameters for subsequent requests, the client can send another start message with the new parameters after it receives the final recognition results and a new {\"state\":\"listening\"} message from the service. The client can change any parameters except for those parameters that are specified when the connection is opened (model, language_customization_id, and so on).\n\nThe following example sends a start message with new parameters for subsequent recognition requests that are sent over the connection. The message specifies the same content-type as the previous example, but it directs the service to return confidence measures and timestamps for the words of the transcription.\n\nvar message = {\naction: 'start',\ncontent-type: 'audio/l16;rate=22050',\nword_confidence: true,\ntimestamps: true\n};\nwebsocket.send(JSON.stringify(message));\n\n\n\n\n\n Keep a connection alive \n\nThe service terminates the session and closes the connection if an inactivity or session timeout occurs:\n\n\n\n* An inactivity timeout occurs if audio is being sent by the client but the service detects no speech. The inactivity timeout is 30 seconds by default.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets"}, {"document_id": "ibmcld_03285-13886-15581", "score": 19.010826, "text": "\nOnly changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https://cloud.ibm.com/apidocs/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actions"}, {"document_id": "ibmcld_03285-12413-14528", "score": 18.187536, "text": "\n\"parameter name\": \"parameter value\",\n\"parameter name\": \"parameter value\"\n}\n}\n}\n]\n}\n}\nShow more\n\n\n\nEach command type along with its related parameters are described in the following sections.\n\n\n\n command_info.type : configure \n\nDynamically reconfigures the Text to Speech service by applying a set of configuration parameters, which can be based on the dialog or action flow. For example, you might want to choose a particular voice at a specific point in the conversation.\n\n\n\n parameter description required default \n\n synthesize The Text to Speech service configuration to use when synthesizing audio. The parameters defined by this object are used when connecting to the Text to Speech service for speech synthesis requests. For more information about these parameters, see the [Text to Speech API documentation](https://cloud.ibm.com/apidocs/text-to-speechsynthesize-audio-websockets-). yes Current Text to Speech configuration \n update_strategy Specifies the update strategy to use when setting the speech configuration. Possible values include:<br><br><br><br> * replace: Replaces the configuration for the rest of the session. Any root-level fields in the new configuration completely overwrite the previous configuration.<br> * replace_once: Replaces the configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actions"}, {"document_id": "ibmcld_16321-5729-7915", "score": 18.172989, "text": "\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https://cloud.ibm.com/apidocs/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actions"}, {"document_id": "ibmcld_03285-5746-7932", "score": 18.172989, "text": "\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https://cloud.ibm.com/apidocs/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actions"}, {"document_id": "ibmcld_13446-19419-21379", "score": 18.036966, "text": "\nIf you set the redaction parameter to true, the service automatically forces the smart_formatting parameter to be true, and it disables the keywords, keywords_threshold, max_alternatives, and (for the WebSocket interface) interim_results parameters. For more information, see [Numeric redaction](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-formattingnumeric-redaction).\n\n\n\nTable 22. The redaction parameter\n\n Availability and usage Description \n\n Previous-generation models Beta for US English, Japanese, and Korean. \n Next-generation models Beta for US English, Japanese, and Korean. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST /v1/recognize method \n Asynchronous HTTP Query parameter of POST /v1/recognitions method \n\n\n\n\n\n\n\n smart_formatting \n\nAn optional boolean that indicates whether the service converts dates, times, numbers, currency, and similar values into more conventional representations in the final transcript. For US English, the feature also converts certain keyword phrases into punctuation symbols. By default (false), smart formatting is not performed. For more information, see [Smart formatting](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-formattingsmart-formatting).\n\n\n\nTable 23. The smart_formatting parameter\n\n Availability and usage Description \n\n Previous-generation models Beta for US English, Japanese, and Spanish (all dialects). \n Next-generation models Beta for US English, Japanese, and Spanish (all dialects). It also also available for the en-WW_Medical_Telephony model when US English audio is recognized. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST /v1/recognize method \n Asynchronous HTTP Query parameter of POST /v1/recognitions method \n\n\n\n\n\n\n\n speaker_labels \n\nAn optional boolean that indicates whether the service identifies which individuals spoke which words in a multi-participant exchange.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-summary"}, {"document_id": "ibmcld_13790-13547-14551", "score": 17.943487, "text": "\nThe following examples show error responses. They include a JSON text message and a formatted message from the client's onClose() callback method. The formatted messages begin with the boolean true because the connection is closed. They also include the WebSocket error code that caused the closure.\n\n\n\n* This example shows error messages for an invalid argument for the accept parameter:\n\n{\n\"error\": \"Unsupported mimetype. Supported mimetypes are: ['application/json', 'audio/flac', ...]\"\n}\n(True, 1011, u'see the previous message for the error details.')\n* This example shows error messages for a missing text parameter:\n\n{\n\"error\": \"Required parameter \"text\" is missing.\"\n}\n(True, 1011, u'see the previous message for the error details.')\n\n\n\nThe following example shows a warning response, in this case for an unknown parameter named invalid-parameter. It does not include the second message because the connection is not closed by the warning.\n\n{\n\"warnings\": \"Unknown arguments: invalid-parameter.\"\n}", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingWebSocket"}, {"document_id": "ibmcld_13446-4441-6470", "score": 17.6877, "text": "\nTable 5. The base_model_version parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket Query parameter of /v1/recognize connection request \n Synchronous HTTP Query parameter of POST /v1/recognize method \n Asynchronous HTTP Query parameter of POST /v1/recognitions method \n\n\n\n\n\n\n\n character_insertion_bias \n\nAn optional float between -1.0 and 1.0 that indicates whether the service is biased to recognize shorter (negative values) or longer (positive values) strings of characters when developing transcription hypotheses. By default, the service uses a default bias of 0.0. The value that you specify represents a change from a model's default. For more information, see [Character insertion bias](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-parsinginsertion-bias).\n\n\n\nTable 6. The character_insertion_bias parameter\n\n Availability and usage Description \n\n Previous-generation models Not available. \n Next-generation models Beta for all models. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST /v1/recognize method \n Asynchronous HTTP Query parameter of POST /v1/recognitions method \n\n\n\n\n\n\n\n Content-Type \n\nAn optional audio format (MIME type) that specifies the format of the audio data that you pass to the service. The service can automatically detect the format of most audio, so the parameter is optional for most formats. It is required for the audio/alaw, audio/basic, audio/l16, and audio/mulaw formats. For more information, see [Specifying an audio format](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-audio-formatsaudio-formats-specifying).\n\n\n\nTable 7. The Content-Type parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket content-type parameter of JSON start message", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-summary"}, {"document_id": "ibmcld_13361-1589-2935", "score": 17.6055, "text": "\n* For the [WebSocket interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets), you first specify the customization ID with the language_customization_id parameter of the /v1/recognize method. You use this method to establish a WebSocket connection with the service.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}/v1/recognize'\n+ '?access_token=' + access_token\n+ '&language_customization_id={customization_id}';\nvar websocket = new WebSocket(wsURI);\n\nYou then specify the name of the grammar with the grammar_name parameter in the JSON start message for the active connection. Passing this value with the start message allows you to change the grammar dynamically for each request that you send over the connection.\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio/l16;rate=22050',\ngrammar_name: '{grammar_name}'\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\n}\n* For the [synchronous HTTP interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-http), pass both parameters with the POST /v1/recognize method.\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: audio/flac\" --data-binary @audio-file.flac \"{url}/v1/recognize?language_customization_id={customization_id}&grammar_name={grammar_name}\"\n\nIBM Cloud Pak for Data", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-grammarUse"}]}
{"task_id": "b4614daadceeecb400f7baf0aa48dcb8<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13790-7-1700", "score": 21.24687, "text": "\nThe WebSocket interface \n\nTo synthesize text to speech with the WebSocket interface of the IBM Watson\u00ae Text to Speech service, you first establish a connection with the service by calling its /v1/synthesize method. You then send the text to be synthesized to the service as a JSON text message over the connection. The service automatically closes the WebSocket connection when it finishes processing the request.\n\nThe synthesize request and response cycle includes the following steps:\n\n\n\n1. [Open a connection](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingWebSocketWSopen).\n2. [Send input text](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingWebSocketWSsend).\n3. [Receive a response](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingWebSocketWSreceive).\n\n\n\nThe WebSocket interface accepts identical input and produces identical results as the GET and POST /v1/synthesize methods of the HTTP interface. In addition, the WebSocket interface also supports use of the SSML <mark> element to identify the location of user-specified markers in the audio. It can also return timing information for all strings of the input text. (The <mark> element and word timings are available only with the WebSocket interface.)\n\n\n\n* For more information about obtaining word timings, see [Generating word timings](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https://cloud.ibm.com/apidocs/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingWebSocket"}, {"document_id": "ibmcld_13790-1284-2889", "score": 21.243721, "text": "\n* For more information about obtaining word timings, see [Generating word timings](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https://cloud.ibm.com/apidocs/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https://tools.ietf.org/html/rfc6455).\n\n\n\n Open a connection \n\nYou call the /v1/synthesize method over the WebSocket Secure (WSS) protocol to open a connection to the service. The method is available at the following endpoint:\n\nwss://api.{location}.text-to-speech.watson.cloud.ibm.com/instances/{instance_id}/v1/synthesize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of the service instance.\n\nThe examples in the documentation abbreviate wss://api.{location}.text-to-speech.watson.cloud.ibm.com/instances/{instance_id} to {ws_url}. So all WebSocket examples call the method as {ws_url}/v1/synthesize.\n\nA WebSocket client calls the /v1/synthesize method with the following query parameters to establish an authenticated connection with the service:\n\naccess_token (required string)\n: Pass a valid access token to authenticate with the service.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingWebSocket"}, {"document_id": "ibmcld_13297-4312-5935", "score": 21.089848, "text": "\nTo use the WebSocket interface, you first use the /v1/recognize method to establish a connection with the service. You specify parameters such as the language model and any custom models that are to be used for requests that are sent over the connection. You then register event listeners to handle responses from the service. To make a request, you send a JSON text message that includes the audio format and any additional parameters. You pass the audio as a binary message (blob), and then send a text message to signal the end of the audio.\n\nThe following example provides JavaScript code that establishes a connection and sends the text and binary messages for a recognition request. The basic example does not include the code to define all of the necessary event handlers for the connection.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}/v1/recognize'\n+ '?access_token=' + access_token;\nvar websocket = new WebSocket(wsURI);\n\nwebsocket.onopen = function(evt) { onOpen(evt) };\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio/flac'\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\nwebsocket.send(JSON.stringify({action: 'stop'}));\n}\nShow more\n\n\n\n\n\n Using the synchronous HTTP interface \n\n[The synchronous HTTP interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-http) provides the simplest way to make a recognition request. You use the POST /v1/recognize method to make a request to the service. You pass the audio and all parameters with the single request. The following curl example shows a basic HTTP recognition request:\n\nIBM Cloud", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-basic-request"}, {"document_id": "ibmcld_13455-7-1568", "score": 20.86423, "text": "\nThe WebSocket interface \n\nThe WebSocket interface of the IBM Watson\u00ae Speech to Text service is the most natural way for a client to interact with the service. To use the WebSocket interface for speech recognition, you first use the /v1/recognize method to establish a persistent connection with the service. You then send text and binary messages over the connection to initiate and manage recognition requests.\n\nBecause of their advantages, WebSockets are the preferred mechanism for speech recognition. For more information, see [Advantages of the WebSocket interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-service-featuresfeatures-websocket-advantages). For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https://cloud.ibm.com/apidocs/speech-to-text).\n\n\n\n Managing a WebSocket connection \n\nThe WebSocket recognition request and response cycle has the following steps:\n\n\n\n1. [Open a connection](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-open)\n2. [Initiate a recognition request](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-start)\n3. [Send audio and receive recognition results](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-audio)\n4. [End a recognition request](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-more)\n6.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets"}, {"document_id": "ibmcld_07578-506456-508701", "score": 20.85975, "text": "\nFor client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n* How to view usage metrics for App Configuration?\n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https://cloud.ibm.com/billing/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https://cloud.ibm.com/observe) section of the IBM Cloud console.\n* How to predict App Configuration cost?\n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-506398-508643", "score": 20.85975, "text": "\nFor client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n* How to view usage metrics for App Configuration?\n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https://cloud.ibm.com/billing/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https://cloud.ibm.com/observe) section of the IBM Cloud console.\n* How to predict App Configuration cost?\n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_13361-1589-2935", "score": 20.780638, "text": "\n* For the [WebSocket interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets), you first specify the customization ID with the language_customization_id parameter of the /v1/recognize method. You use this method to establish a WebSocket connection with the service.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}/v1/recognize'\n+ '?access_token=' + access_token\n+ '&language_customization_id={customization_id}';\nvar websocket = new WebSocket(wsURI);\n\nYou then specify the name of the grammar with the grammar_name parameter in the JSON start message for the active connection. Passing this value with the start message allows you to change the grammar dynamically for each request that you send over the connection.\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio/l16;rate=22050',\ngrammar_name: '{grammar_name}'\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\n}\n* For the [synchronous HTTP interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-http), pass both parameters with the POST /v1/recognize method.\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: audio/flac\" --data-binary @audio-file.flac \"{url}/v1/recognize?language_customization_id={customization_id}&grammar_name={grammar_name}\"\n\nIBM Cloud Pak for Data", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-grammarUse"}, {"document_id": "ibmcld_13455-26115-26611", "score": 20.664572, "text": "\nIf the socket closes with an error, the client receives an informative message of the form {\"error\":\"{message}\"} before the socket closes. Use the onerror event handler to respond appropriately. For more information about WebSocket return codes, see [IETF RFC 6455](https://tools.ietf.org/html/rfc6455).\n\nThe WebSocket implementations of the SDKs can return different or additional response codes. For more information, see the [API & SDK reference](https://cloud.ibm.com/apidocs/speech-to-text).", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets"}, {"document_id": "ibmcld_16321-14177-15957", "score": 20.41906, "text": "\nThe WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https://cloud.ibm.com/apidocs/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use. For more information about voice model options, see [Supported languages and voices](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-voiceslanguageVoices).\n\nThe model you specify must be one that is supported by the Text to Speech service instance that is configured for use with the integration.\n\n\n\n\n\n\n\n Transferring a call to a live agent \n\nWhen you configure the phone integration, you can optionally set up backup call center support, which makes it possible for the assistant to transfer a call to a human.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actions"}, {"document_id": "ibmcld_13455-1311-2796", "score": 19.88905, "text": "\n4. [End a recognition request](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-more)\n6. [Keep a connection alive](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-keep)\n7. [Close a connection](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-close)\n\n\n\nWhen the client sends data to the service, it must pass all JSON messages as text messages and all audio data as binary messages.\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https://tools.ietf.org/html/rfc6455).\n\n\n\n Open a connection \n\nThe Speech to Text service uses the WebSocket Secure (WSS) protocol to make the /v1/recognize method available at the following endpoint:\n\nwss://api.{location}.speech-to-text.watson.cloud.ibm.com/instances/{instance_id}/v1/recognize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of your service instance.\n\nThe examples in the documentation abbreviate wss://api.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets"}]}
{"task_id": "b4614daadceeecb400f7baf0aa48dcb8<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13800-4975-5531", "score": 15.875889, "text": "\n\"customization_id\": \"64f4807f-a5f1-5867-924f-7bba1a84fe97\",\n\"owner\": \"297cfd08-330a-22ba-93ce-1a73f454dd98\",\n\"created\": \"2017-09-16T17:12:31.743Z\",\n\"name\": \"Customization test\",\n\"language\": \"en-US\",\n\"description\": \"Customization test\",\n\"last_modified\": \"2017-09-16T17:12:31.743Z\"\n}\n}\nShow more\n\nTo see the custom words and prompts that the model includes, use the GET /v1/customizations/{customization_id} method. For more information, see [Querying a custom model](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-customModelscuModelsQuery).", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-voices-list"}, {"document_id": "ibmcld_02753-7-2147", "score": 15.236737, "text": "\nCustomizing tokens \n\nWith App ID, tokens are used to identify users and secure your resources. You can choose to customize the information that is injected in to the tokens by the service. By injecting the information into your tokens, it's available to your application at run time without you having to configure extra network calls. For more information about tokens and how they're used in App ID, see [Understanding tokens](https://cloud.ibm.com/docs/appid?topic=appid-tokens).\n\nBy customizing your token configuration, you can ensure that your security and user experience needs are met. However, should a token ever become compromised, a malicious user might have more information or time that can be used to affect your application. Be sure that you understand the security implications of the customizations that you want to make before you make them.\n\n\n\n Understanding custom claims mapping \n\nA claim is a statement that an entity makes about itself or on behalf of someone else. For example, if you signed into an application by using an identity provider, the provider would send the application a group of claims or statements about you to the app so that it can group with information that it already knows about you. This way, when you sign in, the app is set up with your information, in the way that you configured it.\n\n\n\n What types of claims can I define? \n\nThe claims that are provided by App ID fall into several categories that are differentiated by their level of customization.\n\nNormalized claims\n: In each identity token, there is a set of claims that is recognized by App ID as normalized. When available, the claims are mapped directly from your identity provider to the token by default. The claims can't be explicitly omitted but they can be overwritten in your token by custom claims. The claims include name, email, picture, and locale.\n\nRestricted claims\n: Restricted claims are those that have limited customization possibilities and cannot be overwritten by custom mappings. For an access token, scope is the only restricted claim. Although it cannot be overwritten, it can be extended with your own scope.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-customizing-tokens"}, {"document_id": "ibmcld_13652-8279-9663", "score": 15.134219, "text": "\n\"customization_id\": \"63f5807f-a4f2-5766-914e-7abb1a84fe97\",\n\"owner\": \"297cfd08-330a-22ba-93ce-1a73f454dd98\",\n\"created\": \"2016-07-15T18:12:31.743Z\",\n\"name\": \"Test Two\",\n\"language\": \"en-US\",\n\"description\": \"Second customization test\",\n\"last_modified\": \"2016-07-15T18:23:50.912Z\"\n}\n]\n}\nShow more\n\nThe created and last_modified times for the first model are the same because it has yet to be updated. The times for the second model are different, indicating that it has been changed since its initial creation. The information does not include the custom entries defined for the models.\n\n\n\n\n\n Updating a custom model \n\nTo update information about a custom model, use the POST /v1/customizations/{customization_id} method. You specify the updates as a JSON object. In addition to modifying its name and description, you can also use this method to add or update word/translation pairs in the model. You cannot change a model's language once it is created.\n\nThe following example updates the name and description of a custom model. An empty JSON array is sent with the words parameter to indicate that the model's entries are to remain unchanged.\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application/json\" --data \"{\"name\":\"Test Update\", \"description\":\"Customization test update\", \"words\":[]}\" \"{url}/v1/customizations/{customization_id}\"\n\nIBM Cloud Pak for Data", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-customModels"}, {"document_id": "ibmcld_13396-1754-3852", "score": 14.517383, "text": "\n* customization_id identifies the custom model's Globally Unique Identifier (GUID). The GUID is used to identify the model in methods of the interface.\n* created is the date and time in Coordinated Universal Time (UTC) at which the custom model was created.\n* updated is the date and time in Coordinated Universal Time (UTC) at which the custom model was last modified.\n* language is the language of the custom model. The value matches the language identifier from the name of the base model. For example, en-US for a US English language model.\n* dialect is the dialect of the language for the custom model, which does not necessarily match the language of the custom model for previous-generation Spanish models. For more information, see the description of the dialect field in [Create a custom language model](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-languageCreatecreateModel-language).\n* owner identifies the credentials of the service instance that owns the custom model.\n* name is the name of the custom model.\n* description shows the description of the custom model, if one was provided at its creation.\n* base_model indicates the name of the language model for which the custom model was created.\n* versions provides a list of the available versions of the custom model. Each element of the array indicates a version of the base model with which the custom model can be used. Multiple versions exist only if the custom model is upgraded to a new version of its base model. Otherwise, only a single version is shown. For more information, see [Listing version information for a custom model](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-custom-upgrade-usecustom-upgrade-use-listing).\n\n\n\nThe method also returns a status field that indicates the state of the custom model:\n\n\n\n* pending indicates that the model was created. It is waiting either for valid training data (corpora, words, or grammars) to be added or for the service to finish analyzing data that was added.\n* ready indicates that the model contains valid data and is ready to be trained.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-manageLanguageModels"}, {"document_id": "ibmcld_13365-4946-6541", "score": 14.249075, "text": "\nThe customer ID is associated with the allowlisted callback URL or with the data that is sent with the individual recognition request.\n* With requests to add corpora, custom words, or grammars to custom language models:\n\n\n\n* POST /v1/customizations/{customization_id}/corpora/{corpus_name}\n* POST /v1/customizations/{customization_id}/words\n* PUT /v1/customizations/{customization_id}/words/{word_name}\n* POST /v1/customizations/{customization_id}/grammars/{grammar_name}\n\n\n\nThe customer ID is associated with the corpora, custom words, or grammars that are added or updated by the request.\n* With requests to add audio resources to custom acoustic models:\n\n\n\n* POST /v1/acoustic_customizations/{customization_id}/audio/{audio_name}\n\n\n\nThe customer ID is associated with the audio resource that is added or updated by the request.\n\n\n\n\n\n\n\n Specify a customer ID example \n\nThe following example associates the customer ID my_customer_ID with the data passed with a POST /v1/recognize request:\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"X-Watson-Metadata: customer_id=my_customer_ID\" --header \"Content-Type: audio/wav\" --data-binary @audio.wav \"{url}/v1/recognize\"\n\nIBM Cloud Pak for Data\n\ncurl -X POST --header \"Authorization: Bearer {token}\" --header \"X-Watson-Metadata: customer_id=my_customer_ID\" --header \"Content-Type: audio/wav\" --data-binary @audio.wav \"{url}/v1/recognize\"\n\n\n\n\n\n\n\n Deleting customer data \n\nTo delete all data that is associated with a customer ID, use the DELETE /v1/user_data method. You pass the string customer_id={id} as a query parameter with the request.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-information-security"}, {"document_id": "ibmcld_13386-1713-3820", "score": 14.247917, "text": "\n* customization_id identifies the custom model's Globally Unique Identifier (GUID). The GUID is used to identify the model in methods of the interface.\n* created is the date and time in Coordinated Universal Time (UTC) at which the custom model was created.\n* updated is the date and time in Coordinated Universal Time (UTC) at which the custom model was last modified.\n* language is the language of the custom model.\n* owner identifies the credentials of the service instance that owns the custom model.\n* name is the name of the custom model.\n* description shows the description of the custom model, if one was provided at its creation.\n* base_model_name indicates the name of the language model for which the custom model was created.\n* versions provides a list of the available versions of the custom model. Each element of the array indicates a version of the base model with which the custom model can be used. Multiple versions exist only if the custom model is upgraded to a new version of its base model. Otherwise, only a single version is shown. For more information, see [Listing version information for a custom model](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-custom-upgrade-usecustom-upgrade-use-listing).\n\n\n\nThe methods also return a status field that indicates the state of the custom model:\n\n\n\n* pending indicates that the model was created. It is waiting either for valid training data (audio resources) to be added or for the service to finish analyzing data that was added.\n* ready indicates that the model contains valid audio data and is ready to be trained. If the model contains a mix of valid and invalid audio resources, training of the model fails unless you set the strict query parameter to false. For more information, see [Training failures](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-acousticfailedTraining-acoustic).\n* training indicates that the model is being trained on audio data.\n* available indicates that the model is trained and ready to use with recognition requests.\n* upgrading indicates that the model is being upgraded.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-manageAcousticModels"}, {"document_id": "ibmcld_13352-2748-4496", "score": 13.596075, "text": "\nYou use the POST /v1/customizations/{customization_id}/grammars/{grammar_name} method to add a grammar file to a custom model.\n\ncustomization_id (required string)\n: Specify the customization ID of the custom model to which the grammar is to be added.\n\ngrammar_name (required string)\n: Specify a name for the grammar. Use a localized name that matches the language of the custom model and reflects the contents of the grammar.\n\n\n\n* Include a maximum of 128 characters in the name.\n* Do not use characters that need to be URL-encoded. For example, do not use spaces, slashes, backslashes, colons, ampersands, double quotes, plus signs, equals signs, questions marks, and so on in the name. (The service does not prevent the use of these characters. But because they must be URL-encoded wherever used, their use is strongly discouraged.)\n* Do not use the name of a grammar or corpus that has already been added to the custom model.\n* Do not use the name user, which is reserved by the service to denote custom words that are added or modified by the user.\n* Do not use the name base_lm or default_lm. Both names are reserved for future use by the service.\n\n\n\nContent-Type (required string)\n: Use the request header to specify the format of the grammar:\n\n\n\n* application/srgs for an ABNF grammar\n* application/srgs+xml for an XML grammar\n\n\n\nPass the grammar text file as the body of the request. The following example adds the grammar file named confirm.abnf to the custom model with the specified ID. The example names the grammar confirm-abnf.\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application/srgs\" --data-binary @confirm.abnf \"{url}/v1/customizations/{customization_id}/grammars/confirm-abnf\"\n\nIBM Cloud Pak for Data", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-grammarAdd"}, {"document_id": "ibmcld_13365-3377-5348", "score": 13.206363, "text": "\nExperimental and beta features should not be used when implementing a solution that requires the labeling and deletion of data.\n\n\n\n Specifying a customer ID \n\nTo associate a customer ID with data, include the X-Watson-Metadata header with the request that passes the information. You pass the string customer_id={id} as the argument of the header.\n\nA customer ID can include any characters except for the ; (semicolon) and = (equals sign). Specify a random or generic string for the customer ID; do not specify a personally identifiable string, such as an email address or Twitter ID. You can specify different customer IDs with different requests. A customer ID that you specify is associated with the instance of the service whose credentials are used with the request; only credentials for that instance of the service can delete data associated with the ID.\n\n\n\n Supported methods \n\nYou can use the X-Watson-Metadata header with the following methods:\n\n\n\n* With WebSocket requests:\n\n\n\n* /v1/recognize\n\n\n\nYou specify the customer ID with the x-watson-metadata query parameter of the request to open the connection. You must URL-encode the argument to the query parameter, for example, customer_id%3dmy_customer_ID. The customer ID is associated with all data that is passed with recognition requests sent over the connection.\n* With synchronous HTTP requests:\n\n\n\n* POST /v1/recognize\n\n\n\nThe customer ID is associated with the data that is sent with the individual request.\n* With asynchronous HTTP requests:\n\n\n\n* POST /v1/register_callback\n* POST /v1/recognitions\n\n\n\nThe customer ID is associated with the allowlisted callback URL or with the data that is sent with the individual recognition request.\n* With requests to add corpora, custom words, or grammars to custom language models:\n\n\n\n* POST /v1/customizations/{customization_id}/corpora/{corpus_name}\n* POST /v1/customizations/{customization_id}/words\n* PUT /v1/customizations/{customization_id}/words/{word_name}", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-information-security"}, {"document_id": "ibmcld_13327-1936-3804", "score": 13.204955, "text": "\nYou can associate a customer ID with data that is added or updated for custom language and custom acoustic models. You associate a customer ID with corpora, custom words, grammars, and audio resources by passing the X-Watson-Metadata header with the following methods. If necessary, you can then delete the data by using the DELETE /v1/user_data method.\n\n\n\n* POST /v1/customizations/{customization_id}/corpora/{corpus_name}\n* POST /v1/customizations/{customization_id}/words\n* PUT /v1/customizations/{customization_id}/words/{word_name}\n* POST /v1/customizations/{customization_id}/grammars/{grammar_name}\n* POST /v1/acoustic_customizations/{customization_id}/audio/{audio_name}\n\n\n\nIn addition, if you delete an instance of the Speech to Text service from the IBM Cloud console, all data associated with that service instance is automatically deleted. This includes all custom language models, corpora, grammars, and words, and all custom acoustic models and audio resources. This data is purged automatically and regardless of whether a customer ID is associated with the data.\n\nFor more information, see [Information security](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-information-security).\n\n\n\n\n\n Request logging and data privacy \n\nIBM Cloud\n\nHow the service handles request logging for calls to the customization interface depends on the request:\n\n\n\n* The service does not log data that is used to build custom models. For example, when working with corpora and words in a custom language model, you do not need to set the X-Watson-Learning-Opt-Out request header. Your training data is never used to improve the service's base models.\n* The service does log data when a custom model is used with a recognition request. You can opt out of request logging at the account level or by setting the X-Watson-Learning-Opt-Out request header to true.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-custom-usage"}, {"document_id": "ibmcld_02797-7-1882", "score": 13.141859, "text": "\nCustomizing your user experience \n\nIn a world with everything at our finger tips, people expect their experiences to be tailored to them. Whether we're having an in-person conversation or shopping online, we want to see only the things that apply to us. By using this step-by-step guide, you can learn how to harness the power of user attributes and really capture your users attention with App ID.\n\n\n\n Scenario \n\nYou're a developer for an online retailer, with a specialization in food. You're tasked with creating a personalized experience for your app users. You decide to focus your efforts on creating targeted advertising based on things that you know about your users. So, when a user signs up for your app, you ask them a few questions with answers that they can choose from. For example, you might ask the following question:\n\nDo you have any dietary preferences?\n\n\n\n* I'm a vegetarian.\n* I'm a pescatarian.\n* I'm dairy-free.\n* I'm gluten-free.\n* I'm low carb.\n\n\n\nYou can then map their answers to [specific attributes](https://cloud.ibm.com/docs/appid?topic=appid-profiles) that you can use to target the advertising that they're shown.\n\nAlthough this tutorial is written for web apps that use Cloud Directory, attributes can be used in a much broader sense. Custom attributes can be anything that you want them to be! If you stay under 100k attributes and you format them as a plain JSON object, you can store all types of information.\n\n\n\n\n\n Before you begin \n\nReady? Let's get started!\n\nBe sure that you have the following prerequisites before you begin:\n\n\n\n* An instance of the App ID service\n* A set of service credentials\n\n\n\n\n\n\n\n Step 1: Configuring your App ID instance \n\nBefore you can start adding attributes for your users, you need to configure your instance of App ID.\n\n\n\n1. In the Identity Providers tab of the service dashboard, enable Cloud Directory.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-tutorial-attributes"}]}
{"task_id": "b4614daadceeecb400f7baf0aa48dcb8<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16288-1733-3996", "score": 20.23629, "text": "\nIt's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call. This 503 response can then be used by the SIP trunking provider to reroute the call to another region. If you want to take advantage of this capability, open a service ticket against the Watson Assistant service instance that requires disaster recovery.\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by going to the Advanced options tab in the phone integration settings, and selecting one or both of the following options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Applying advanced SIP trunk configuration settings \n\nTo configure how your assistant interacts with a SIP trunk from an external provider, go to the SIP trunk tab in the phone integration settings, and update the following options in the SIP trunking integration section:\n\n\n\n* SIP INVITE headers to extract: List the headers that you want your assistant to use.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-config"}, {"document_id": "ibmcld_03160-4262-5873", "score": 17.237732, "text": "\nIf this test did not work as expected, double check your phone number configuration to make sure its attached to your flow.\n\n\n\n\n\n\n\n Creating a Twilio function to handle incoming calls \n\nNow we need to configure the call flow to direct inbound calls to the assistant using a Twilio function. Follow these steps:\n\n\n\n1. In the navigation menu, click the All Products & Services icon.\n2. Click Services.\n3. Click Create Service. Specify a service name and then click Next.\n4. Click Add > Add Function to add a new function to your service. Name the new function /receive-call.\n5. Replace the template in your /receive-call function with the following code:\n\nexports.handler = function(context, event, callback) {\nconst VoiceResponse = require('twilio').twiml.VoiceResponse;\nconst response = new VoiceResponse();\nconst dial = response.dial({\nanswerOnBridge: \"true\",\nreferUrl: \"/refer-handler\"\n});\nconst calledPhoneNumber = event.Called;\ndial.sip(sip:${calledPhoneNumber}@{sip_uri_hostname};secure=true);\nreturn callback(null, response);\n}\n\n\n\n* Replace {sip_uri_hostname} with the hostname portion of your assistant's phone integration SIP URI (everything that comes after sips:).. Note that Twilio does not support SIPS URIs, but does support secure SIP trunking by appending ;secure=true to the SIP URI.\n\n\n\n6. Click Save.\n7. Click Deploy All.\n\n\n\n\n\n\n\n Redirecting to the incoming call handler \n\nIn this section you will use a TwiML Redirect** widget in your Studio Flow editor to call out to the /call-recieve function created in the previous section.\n\n\n\n1. Add a TwiML Redirect widget to your Studio Flow canvas.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone-flex"}, {"document_id": "ibmcld_16287-1442-3506", "score": 15.570257, "text": "\nThe trunk can connect to the public switched telephone network (PSTN) or your company's on-premises private branch exchange (PBX).\n\nWhen a customer makes a phone call using the telephone number connected to your assistant, the phone integration makes it possible for your assistant to answer. The integration converts output from your assistant into voice audio by using the IBM Watson\u00ae Text to Speech service, and the audio is sent to the telephone network through the SIP trunk. When the customer replies, the voice input is converted into text by using the IBM Watson\u00ae Speech to Text service.\n\nThis feature is available only to Plus or Enterprise plan users.\n\nDepending on the architecture of your existing telephony infrastructure, there are multiple ways you might integrate it with Watson Assistant. For more information about common integration patterns, read the blog post [Hey Watson, can I have your number?](https://medium.com/ibm-watson/hey-watson-can-i-have-your-number-7de8fc7621ed) on Medium.\n\n\n\n Set up the integration \n\nYou must have Manager role access to the instance and Viewer role access to the resource group to complete setup. For more information about access levels, see [Managing access](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-access-control).\n\nTo set up the integration:\n\n\n\n1. In the Integrations section on the main page for your assistant under Essential Channels, you will see a tile for Phone.\n2. On the Phone tile, click Add.\n3. On the pop-up window, click Add again.\n4. Choose whether to generate a free phone number for your assistant, integrate with your contact center, or connect to an existing SIP trunk:\n\n\n\n* To generate a free phone number for your assistant, click Generate a free phone number.\n\nGenerating a free phone number is supported only for Watson Assistant instances in the Dallas and Washington DC data centers.\n* To integrate with a [contact center](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone), click Integrate with your contact center.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone"}, {"document_id": "ibmcld_16289-4293-5909", "score": 15.462659, "text": "\n5. Delete the Say/Play widget and continue to the next step.\n6. If this test did not work as expected, double check your phone number configuration to make sure its attached to your flow.\n\n\n\n\n\n\n\n Creating a Twilio function to handle incoming calls \n\nNow we need to configure the call flow to direct inbound calls to the assistant using a Twilio function. Follow these steps:\n\n\n\n1. In the navigation menu, click the All Products & Services icon.\n2. Click Services.\n3. Click Create Service. Specify a service name and then click Next.\n4. Click Add > Add Function to add a new function to your service. Name the new function /receive-call.\n5. Replace the template in your /receive-call function with the following code:\n\nexports.handler = function(context, event, callback) {\nconst VoiceResponse = require('twilio').twiml.VoiceResponse;\nconst response = new VoiceResponse();\nconst dial = response.dial({\nanswerOnBridge: \"true\",\nreferUrl: \"/refer-handler\"\n});\nconst calledPhoneNumber = event.Called;\ndial.sip(sip:${calledPhoneNumber}@{sip_uri_hostname};secure=true);\nreturn callback(null, response);\n}\n\n\n\n* Replace {sip_uri_hostname} with the hostname portion of your assistant's phone integration SIP URI (everything that comes after sips:).. Note that Twilio does not support SIPS URIs, but does support secure SIP trunking by appending ;secure=true to the SIP URI.\n\n\n\n6. Click Save.\n7. Click Deploy All.\n\n\n\n\n\n\n\n Redirecting to the incoming call handler \n\nIn this section you will use a TwiML Redirect** widget in your Studio Flow editor to call out to the /receive-call function created in the previous section.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-flex"}, {"document_id": "ibmcld_03158-17978-19852", "score": 15.406751, "text": "\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Buy a Number.\n* If you already have a number, you can click the plus sign (+) to provision a new phone number in your region.\n\n\n\n8. Assign the number to the SIP trunk you created by going back to the SIP trunk and clicking the number sign (#) icon.\n\n\n\nIf you use a Lite or Trial Twilio account for testing purposes, then be sure to verify the transfer target.\n\nYou cannot enable SIP authentication if you choose Twilio as your SIP trunk provider. Twilio doesn't support SIPS for originating calls.\n\n\n\n\n\n Using other third-party providers \n\nYou can ask for help setting up an account with another SIP trunk provider by opening a support request.\n\nIBM has established relationships with the following SIP trunk providers:\n\n\n\n* [Five9](https://www.five9.com/products/capabilities/contact-center-software)\n* [Genesys](https://www.genesys.com/en-sg/definitions/what-is-a-trunk)\n* [Vonage](https://www.vonage.com/communications-apis/sip-trunking/)\n* [Voximplant](https://voximplant.com/)\n\n\n\nThe SIP trunk provider sets up a SIP trunk for your voice traffic, and manages access from allowed IP addresses. Most of the major SIP trunk providers have existing relationships with IBM. Therefore, the network configuration that is required to support the SIP trunk connection typically can be handled for you with minimal effort.\n\n\n\n1. Create a [IBM Cloud case](https://cloud.ibm.com/unifiedsupport/cases/form).\n2. Click Customer success as the case type.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone"}, {"document_id": "ibmcld_16288-6287-8401", "score": 15.365867, "text": "\nWhen you use the phone integration as the first line of assistance for customers, it's a good idea to have a live agent backup available. You can design your assistant to transfer a call to a human in case the phone connection fails, or if a user asks to speak to someone.\n\nYour company might already have one or more phone numbers that connect to an automatic call dispatcher (ACD) that can queue callers until an appropriate agent is available. If not, choose a call center service to use as your backup.\n\nA conversation cannot be transferred from one integration type to another. For example, if you use the web chat integration with service desk support, you cannot transfer a phone call to the service desk that is set up for the web chat.\n\nYou must provide the call center SIP URI for the call center service you use. You must specify this information in your assistant when you enable a call transfer from a dialog node or action step. For more information, see [Transferring a call to a live agent](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer).\n\n\n\n\n\n Optimize your actions for phone interaction \n\nFor the best customer experience, design your dialog with the capabilities of the phone integration in mind:\n\n\n\n* Do not include HTML elements in your action responses. To add formatting, use Markdown. For more information, see [Formatting responses](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-respondrespond-formatting).\n* You can use a search extension to include search results in actions that the phone integration will read. When search results are returned, the phone integration reads the introductory message (for example, I found this information that might be helpful), and then the body of only the first search result.\n\nThe entire search response (meaning the introductory message plus the body of the first search result) must be less than 5,000 characters long or the response will not be read at all. Be sure to test the search results that are returned and curate the data collection that you use as necessary.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-config"}, {"document_id": "ibmcld_16287-7-2037", "score": 15.322709, "text": "\nIntegrating with phone ![Plus or higher plans only](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/plus.png) \n\nIBM Cloud\n\nAdding the phone integration to your assistant makes your assistant available to customers over the phone.\n\nIf an end user asks to speak to a person, the phone integration can transfer the call to an agent. Supported live agent and contact center integrations:\n\n\n\n* Genesys\n* Twilio Flex\n* NICE CXone\n* Bring your own\n\n\n\nThere are several ways to add the phone integration to your assistant:\n\n\n\n* You can generate a free phone number that is automatically provisioned from IntelePeer. This is available only with new phone integrations. If you have an existing phone integration, you must delete it and create a new one to switch to a free phone number.\n* You can connect to a contact center with live agents. For more information about setting up the integration, see [Integrating with phone and NICE CXone contact center](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone).\n* You can use and connect an existing number by configuring a Session Initiation Protocol (SIP) trunk from a provider such as Genesys, IntelePeer, or Twilio.\n\n\n\nA SIP trunk is equivalent to an analog telephone line, except it uses Voice over Internet Protocol (VoIP) to transmit voice data and can support multiple concurrent calls. The trunk can connect to the public switched telephone network (PSTN) or your company's on-premises private branch exchange (PBX).\n\nWhen a customer makes a phone call using the telephone number connected to your assistant, the phone integration makes it possible for your assistant to answer. The integration converts output from your assistant into voice audio by using the IBM Watson\u00ae Text to Speech service, and the audio is sent to the telephone network through the SIP trunk. When the customer replies, the voice input is converted into text by using the IBM Watson\u00ae Speech to Text service.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone"}, {"document_id": "ibmcld_16288-7-2218", "score": 15.19479, "text": "\nPhone integration configuration \n\nIBM Cloud\n\nAfter you have set up the phone integration for your assistant, you can modify the phone integration settings to customize the call behavior.\n\n\n\n Handling call and transfer failures \n\nYou can configure the phone integration to transfer the caller to a human agent if the phone connection fails for any reason. To transfer the caller to a human agent automatically, go to the Advanced tab in the phone integration settings, and make the following configuration selections:\n\n\n\n* SIP target when a call fails: Add the SIP endpoint for your support agent service. Specify a SIP or telephone URI for a general call queue that can redirect requests to other queues. For more information, see [Configuring backup call center support](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-transfer-service).\n* Call failure message: Add the message you want the assistant to say to a caller before it transfers the call to a human agent.\n\n\n\nIf, after you transfer the call to a human, the connection to a live agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message you want the assistant to say to a caller if transfer to a live agent fails. The message can be up to 150 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after the failure message. This option is enabled by default. If this option is disabled, when a call transfer fails, your assistant can disconnect or process a different action.\n\nIf you choose to leave a call connected despite a transfer failure, Watson Assistant will initiate a new turn to determine the next step. It's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-config"}, {"document_id": "ibmcld_16288-10521-12298", "score": 15.175099, "text": "\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Add a number and then Buy a Number.\n* If you already have a number, you can click Add a number and then Add an Existing Number.\n\n\n\n\n\nIf you use a Lite or Trial Twilio account for testing purposes, then be sure to verify the transfer target. For more information, see the [Twilio documentation](https://support.twilio.com/hc/en-us/articles/223136107-How-does-Twilio-s-Free-Trial-work-).\n\nYou cannot enable SIP authentication if you choose Twilio as your SIP trunk provider. Twilio doesn't support SIPS for originating calls.\n\n\n\n\n\n Using other third-party providers \n\nYou can ask for help setting up an account with another SIP trunk provider by opening a support request.\n\nIBM has established relationships with the following SIP trunk providers:\n\n\n\n* [Five9](https://www.five9.com/products/capabilities/contact-center-software)\n* [Genesys](https://www.genesys.com/en-sg/definitions/what-is-a-trunk)\n* [Vonage](https://www.vonage.com/communications-apis/sip-trunking/)\n* [Voximplant](https://voximplant.com/)\n\n\n\nThe SIP trunk provider sets up a SIP trunk for your voice traffic, and manages access from allowed IP addresses. Most of the major SIP trunk providers have existing relationships with IBM. Therefore, the network configuration that is required to support the SIP trunk connection typically can be handled for you with minimal effort.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-config"}, {"document_id": "ibmcld_03158-23545-25765", "score": 15.01313, "text": "\nThe SIP trunk service sends a SIP INVITE HTTP request to your assistant's phone integration to establish a connection.\n3. The phone integration connects to the speech services that are required to support the interaction.\n4. After the services are ready, the connection is established, and audio is sent over the Real-time Transport Protocol (RTP).\n\nRTP is a network protocol for delivering audio and video over IP networks.\n5. The welcome node of the dialog is processed. The response text is sent to the Text to Speech service to be converted to audio and the audio is sent to the caller.\n6. When the customer says something, the audio is converted to text by the Speech to Text service and is sent to your assistant's dialog skill for evaluation.\n7. The dialog processes the input and calculates the best response. The response text from the dialog node is sent to the Text to Speech service to be converted to audio and the audio is sent back to the caller over the existing connection.\n8. If the caller asks to speak to a person, the assistant can transfer the person to a call center. A SIP REFER request is sent to the SIP trunk provider so it can transfer the call to the call center SIP URI that is specified in the dialog node where the transfer action is configured.\n9. When one of the participants of the call hangs up, a SIP BYE HTTP request is sent to the other participant.\n\n\n\n\n\n\n\n\n\n Phone integration limits \n\nAny speech service charges that are incurred by the phone integration are included as Voice add-on charges in your Watson Assistant service plan usage. The Voice add-on use is charged separately and in addition to your service plan charges.\n\nPlan usage is measured based on the number of monthly active users, where a user is identified by the caller's unique phone number. An MD5 hash is applied to the phone number and the 128-bit hash value is used for billing purposes.\n\nThe number of concurrent calls that your assistant can participate in at one time depends on your plan type.\n\n\n\nPlan details\n\n Plan Concurrent calls \n\n Enterprise 1,000 \n Plus 100 \n Trial 5 \n\n\n\n\n\n\n\n Troubleshooting the phone integration \n\nFind solutions to problems that you might encounter while using the integration.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone"}]}
{"task_id": "b4614daadceeecb400f7baf0aa48dcb8<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16321-7-1807", "score": 15.769431, "text": "\nHandling phone interactions \n\nIf your assistant uses the phone integration, you can use various response types to customize the behavior of the integration or manage the flow of conversations that your assistant has with customers over the telephone.\n\nYou can use response types to perform the following phone-specific actions:\n\n\n\n* [Apply advanced settings to the Speech to Text service](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-speech-advanced)\n* [Apply advanced settings to the Text to Speech service](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-text-advanced)\n* [Transfer a call to a live agent](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer)\n* [Play hold music or a voice recording](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-hold-music)\n* [Enable keypad entry](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-dtmf)\n* [Transfer the conversation to the web chat integration](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer-channel)\n* [End the call](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-hangup)\n* [Send a text message during a phone conversation](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-sms)\n\n\n\nIn some cases, you might want to combine response types to perform multiple actions. For example, you might want to implement two-factor authentication by requesting phone keypad entry and sending a text message from the same action step. For more information, see the following:", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actions"}, {"document_id": "ibmcld_16288-1733-3996", "score": 15.349797, "text": "\nIt's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call. This 503 response can then be used by the SIP trunking provider to reroute the call to another region. If you want to take advantage of this capability, open a service ticket against the Watson Assistant service instance that requires disaster recovery.\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by going to the Advanced options tab in the phone integration settings, and selecting one or both of the following options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Applying advanced SIP trunk configuration settings \n\nTo configure how your assistant interacts with a SIP trunk from an external provider, go to the SIP trunk tab in the phone integration settings, and update the following options in the SIP trunking integration section:\n\n\n\n* SIP INVITE headers to extract: List the headers that you want your assistant to use.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-config"}, {"document_id": "ibmcld_16288-6287-8401", "score": 14.275341, "text": "\nWhen you use the phone integration as the first line of assistance for customers, it's a good idea to have a live agent backup available. You can design your assistant to transfer a call to a human in case the phone connection fails, or if a user asks to speak to someone.\n\nYour company might already have one or more phone numbers that connect to an automatic call dispatcher (ACD) that can queue callers until an appropriate agent is available. If not, choose a call center service to use as your backup.\n\nA conversation cannot be transferred from one integration type to another. For example, if you use the web chat integration with service desk support, you cannot transfer a phone call to the service desk that is set up for the web chat.\n\nYou must provide the call center SIP URI for the call center service you use. You must specify this information in your assistant when you enable a call transfer from a dialog node or action step. For more information, see [Transferring a call to a live agent](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer).\n\n\n\n\n\n Optimize your actions for phone interaction \n\nFor the best customer experience, design your dialog with the capabilities of the phone integration in mind:\n\n\n\n* Do not include HTML elements in your action responses. To add formatting, use Markdown. For more information, see [Formatting responses](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-respondrespond-formatting).\n* You can use a search extension to include search results in actions that the phone integration will read. When search results are returned, the phone integration reads the introductory message (for example, I found this information that might be helpful), and then the body of only the first search result.\n\nThe entire search response (meaning the introductory message plus the body of the first search result) must be less than 5,000 characters long or the response will not be read at all. Be sure to test the search results that are returned and curate the data collection that you use as necessary.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-config"}, {"document_id": "ibmcld_03369-22311-24192", "score": 14.205883, "text": "\nFor more information, see [Handling phone interactions](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-transfer-channel).\n\n\n\n\n\n 3 December 2021 \n\nConfigure webhook timeout\n: From the Pre-message webhook and Post-message webhook configuration pages, you can configure the webhook timeout length from a minimum of 1 second to a maximum of 30 seconds. For more information, see [Webhook overview](https://cloud.ibm.com/docs/assistant?topic=assistant-webhook-overview).\n\n\n\n\n\n 27 November 2021 \n\nNew API version\n: The current API version is now 2021-11-27. This version introduces the following changes:\n\n\n\n* The output.text object is no longer returned in message responses. All responses, including text responses, are returned only in the output.generic array.\n\n\n\n\n\n\n\n 9 November 2021 \n\nNew phone response types\n: New response types are available for controlling the configuration and behavior of the phone integration. These response types replace most of the older vgw actions, which are now deprecated. (The vgw actions will continue to work, so existing skills do not need to be changed.) For more information, see [Handling phone interactions](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actions).\n\nRich response types\n: Your assistant can now send responses that include elements such as audio, video, or embedded iframe content. For more information, see [Rich responses](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-multimedia).\n\n\n\n\n\n 4 November 2021 \n\nActions enhancement: Add variables to links\n: In an actions skill, when including a link in an assistant response, you can now access and use variables. In the URL field for a link, type a dollar sign ($) character to see a list of variables to choose from.\n\n\n\n\n\n 14 October 2021 \n\nvgwHangUp message no longer sent", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_03285-4-1711", "score": 13.933173, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Handling phone interactions \n\nIf your assistant uses the phone integration, you can use various response types to customize the behavior of the integration or manage the flow of conversations that your assistant has with customers over the telephone.\n\nYou can use response types to perform the following phone-specific actions:\n\n\n\n* [Apply advanced settings to the Speech to Text service](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-speech-advanced)\n* [Apply advanced settings to the Text to Speech service](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-text-advanced)\n* [Transfer a call to a human agent](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-transfer)\n* [Play hold music or a voice recording](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-hold-music)\n* [Enable keypad entry](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-dtmf)\n* [Transfer the conversation to the web chat integration](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-transfer-channel)\n* [End the call](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-hangup)\n* [Send a text message during a phone conversation](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-sms)", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actions"}, {"document_id": "ibmcld_03165-4477-6547", "score": 13.849952, "text": "\nFrom the All Products and Services menu, click Phone Numbers.\n9. From the Active Numbers page, click one of your phone numbers. Scroll to the Messaging section, and then find the Webhook field that defines what to do when a message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n10. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n11. Click Save and exit.\n\n\n\nTo watch a video that walks through the setup process, see [Phone and SMS Integration](https://community.ibm.com/community/user/watsonapps/viewdocument/phone-and-sms-integration?CommunityKey=7a3dc5ba-3018-452d-9a43-a49dc6819633&tab=librarydocuments) in the IBM Watson Apps Community.\n\nIf you want your assistant to be able to switch between voice and text during a customer interaction, enable both the phone and text messaging integrations. The integrations do not need to use the same third-party service provider. For more information, see [Integrating with phone](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone).\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your dialog for messaging \n\nFor the best customer experience, design your dialog with the capabilities of the Twilio integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* You can send media files or even documents in your response. These files can be intercepted and processed by a configured premessage webhook.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-sms"}, {"document_id": "ibmcld_03158-13826-15767", "score": 13.509087, "text": "\nFor more information, see [Transfer a call to a human agent](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-transfer).\n\n\n\n\n\n Optimize your dialog for voice \n\nFor the best customer experience, design your dialog with the capabilities of the phone integration in mind:\n\n\n\n* Do not include HTML elements in your dialog text responses. To add formatting, use Markdown. For more information, see [Simple text response](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-simple-text).\n* Use the Connect to human agent response type to initiate a transfer to a human agent. For more information, see [Transferring a call to a human agent](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-transfer).\n* Use the Channel transfer response type to initiate a transfer to the web chat integration. For more information, see [Transferring the caller to the web chat integration](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-transfer-channel).\n* The pause response type is not supported. If you want to add a pause, use the turn_settings.timeout_count context variable (for more information, see [Context variables that are set by your dialog or actions](https://cloud.ibm.com/docs/assistant?topic=assistant-phone-contextphone-context-variables-set-by-dialog)).\n* You can include search skill response types in dialog nodes that the phone integration will read. The introductory message (I searched my knowledge base and so on), and then the body of only the first search result is read.\n\nThe search skill response (meaning the introductory message plus the body of the first search result) must be less than 5,000 characters long or the response will not be read at all. Be sure to test the search results that are returned and curate the data collection that you use as necessary.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone"}, {"document_id": "ibmcld_16294-8240-10414", "score": 13.461312, "text": "\nOnce the phone number has been enabled for SMS, you will see a webhook icon beside the number.\n\nPaste the value that you copied from the Webhook URI field into it.\n15. Click Save.\n16. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n\n\n\n\n\n\n\n\n\n SMS Advanced configuration options \n\nThe Advanced options tab is available after you set up the SMS integration. Click the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your actions for messaging \n\nFor the best customer experience, design your actions with the capabilities of the SMS integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* The SMS integration does not support chat transfers that are initiated with the connect_to_agent response type.\n* Image, Audio, Video response types allow sending a message containing media. A title and description are sent along with the attachment. Note that depending on the carrier and device of the end user these messages may not be successfully received. For a list of the supported content types for Twilio, see [Twilio: Accepted Content Types for Media](https://www.twilio.com/docs/sms/accepted-mime-types).\n\nFor more information on these response types, see [Response types reference](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-response-types-reference).\n\n\n\nIf you want to use the same action for an assistant that you deploy to many different platforms, add custom responses per integration type. You can add a conditioned response that tells the assistant to show the response only when the SMS integration is being used.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-sms"}, {"document_id": "ibmcld_03158-8929-11062", "score": 13.058951, "text": "\nFor more information, see [Configuring backup support](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phonedeploy-phone-transfer-service).\n* Call failure message: Add the message to say to a caller before you transfer them to a human agent.\n\n\n\nIf, after you transfer the caller to a human agent, the connection to the human agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message to stream to callers if the transfer to a human agent fails. The message can be up to 1,024 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after sharing the failure message. This option is enabled by default. If disabled, when a call transfer fails, your assistant can disconnect or process a different dialog node.\n\n\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by selecting one or both of the following configuration options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phonedeploy-phone-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Apply advanced SIP trunk configuration settings \n\n\n\n* SIP INVITE headers to extract: List headers that you want to use in your dialog.\n\nThe SIP request often sends INVITE headers with information about the request that is used by the SIP network.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone"}, {"document_id": "ibmcld_16324-4772-6688", "score": 13.045698, "text": "\nPlan whether you want to connect the assistant to existing content sources by taking an inventory of relevant help content (for example, product information, knowledge articles, FAQs) available to your customers.\n\nYou can give your assistant access to this information by adding a [search integration](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-search-add) to your assistant. The search integration uses IBM Watson\u00ae Discovery to return smart answers to natural language questions.\n\n\n\n\n\n 5. Plan your handoff strategy \n\nFinally, prevent customers from hitting dead ends by [escalating conversations to a human agent](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-human-agent) if the assistant isn't able to resolve a customer's question or problem. As part of your planning, figure out what your escalation strategy is going to be. This strategy will vary depending on the deployment channel you choose.\n\nIf you deploy to your website, you have three options for escalating to a human agent:\n\n\n\n* Inline\n* Email address\n* Phone number\n\n\n\nIf you opt for the inline approach, you can directly escalate to a human agent in your existing contact center tool without forcing the user to leave the web chat widget. This approach also provides the agent with the full context of the conversation. To use either the email address or phone number approach, provide the user with the agent\u2019s email address or phone number. These approaches are simple to set up, but they can be more disconnected experiences for your customers.\n\nIf you deploy by using the phone integration, you can reach a human agent only by transferring the phone call to someone who can help.\n\n\n\n\n\n Start building an assistant \n\nIf you're ready to start building an assistant, see [Editing actions](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-build-actions-overview) for more information.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-plan-assistant"}]}
{"task_id": "b4614daadceeecb400f7baf0aa48dcb8<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02110-4734-6930", "score": 16.716822, "text": "\nA context-based restriction rule that includes multiple network zones can have a maximum of 1000 IP addresses indirectly associated with it. For example, in a rule that includes two network zones, one of the zones could have 800 IP addresses and the other could have a maximum of 200 IP addresses.\n\nIf you want to check the number of rules in your account, see [Viewing the total number of rules per account](https://cloud.ibm.com/docs/account?topic=account-account-limits&interface=clitotal-number-rules-cli). To request an increase in the account limit, see [Requesting a policy and rule shared limit increase](https://cloud.ibm.com/docs/account?topic=account-account-limits&interface=clilimit-increase).\n\n\n\n Eventual consistency \n\nContext-based restrictions follow an [eventually consistent](https://en.wikipedia.org/wiki/Eventual_consistency) pattern that is common to many cloud-native services. As a result, Context-based restrictions remain highly available and performant across multiple global regions. Changes that are made to Context-based restrictions rules and network zones are recorded and propagated worldwide. Access changes might not take effect until the propagation process is complete, usually within a few minutes.\n\n\n\n\n\n\n\n Access policy version limitations \n\nAs of 25 January 2023, IAM supports two versions of the IAM Policy Management API: /v2/policies and /v1/policies. v1/polices allows for string comparisons against attributes in the subject and resources of a policy. v2/polices introduces a new schema that provides backwards functional compatibility while allowing for more complex comparisons and operators.\n\n\n\n String comparisons \n\nThe following table lists the string comparison operators that you can use to build access policies with /v2/policies syntax. For more information about each version, see [Comparing /v1/policies and /v2/policies syntax](https://cloud.ibm.com/docs/account?topic=account-known-issuescompare-syntax).\n\n\n\nTable 3. The string comparison operators available for conditions in access policies.\n\n Operator Description \n\n stringEquals Case-sensitive string comparison. Boolean or number values are converted into a string before comparison.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-known-issues"}, {"document_id": "ibmcld_02110-1686-3682", "score": 15.913269, "text": "\nIf a limit is exceeded, you receive an exception and are not allowed to create any new resources beyond that limit.\n\nIf you have a specific use case that requires an extended limit, you can request an increase. For more information, see [Increasing account limits](https://cloud.ibm.com/docs/account?topic=account-account-limits).\n\n\n\nTable 1. IAM account limits\n\n Resource Max \n\n Access groups per account 500 \n Access groups per user 50 \n Access management tags per account 250 \n API Keys per identity 20 \n Custom roles per account 40 \n Dynamic rules per access group 5 \n Dynamic rules per trusted profile 20 \n Dynamic rules per Identity provider (IdP) 2000 \n IdPs per account 5 \n Policies per account <br><br>[1] 4020 \n Policies per subject within an account 1000 \n Policies with access management tags within an account 25 \n Service IDs per account 2000 \n Trusted profiles per account 2000 \n Users per trial account 100 \n Users per billable account 7500 \n\n\n\nA maximum of 1,000 policies and service to service authorizations within one account is recommended to ensure optimal performance within your account. For more information about limiting the number of policies in your account, see the [Best practices for organizing resources and assigning access](https://cloud.ibm.com/docs/account?topic=account-account_setup).\n\nIf you want to check the number of policies in your account, see [Viewing the total number of policies per account](https://cloud.ibm.com/docs/account?topic=account-account-limits&interface=clitotal-number-policies-cli). To request an increase in the account limit, see [Requesting a policy and rule shared limit increase](https://cloud.ibm.com/docs/account?topic=account-account-limits&interface=clilimit-increase).\n\n\n\n Policy limitations based on attributes \n\nAccess management tags are only available when you create an access policy that is scoped for all IAM-enabled services. In this case, when you enable the access based on tags, no other attributes can be added.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-known-issues"}, {"document_id": "ibmcld_02597-4595-6892", "score": 15.861779, "text": "\nThrough the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.\n\nAs well as controlling which APIs a customer can use, different Plans can be used to implement rate limits. A rate limit can be implemented as a default rate across an entire Plan, or for specific operations of an API within that Plan, exempting them from the Plan rate limit. Different Plans can have differing rate limits, both between operations and for the overall limit. Applying rate limits to Plans makes it easy to offer different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute while a \"Full Plan\" might permit up to 1000 calls per minute.\n\nFinally, different Plans can be used to assign a billing cost. A Plan can be set as a free Plan, or as a Plan with billing. Plans with billing can be used with rate limits to set different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute for a cost of $5 per month, while a \"Full Plan\" might permit up to 1000 calls per minute for a cost of $20 per month.\n\nNote: Applying a rate limit at the Plan level, creates a default rate limit that applies to each operation within the Plan. If you need to set specific rate limits for specific operations, you must set them within the operations themselves and this setting overrides the setting at the Plan level.\n\nIBM API Connect also supports the implementation of multiple versions of Products. You can choose version numbers and use them to aid the development of your Products and Plans.\n\nNote: The version for a Product is distinct from the version of any APIs that are contained in the associated Plans. Plans cannot themselves have their own version, they use the version of their parent Product.", "title": "", "source": "https://cloud.ibm.com/docs/apiconnect?topic=apiconnect-about_apic_overview"}, {"document_id": "ibmcld_16287-7751-9832", "score": 14.774777, "text": "\nHowever, provisioning the new number might take several minutes.\n\n\n\n\n\n Adding more phone numbers \n\nIf you are using existing phone numbers you configured via a SIP trunk provider, you can add multiple numbers to the same phone integration.\n\nIf you generated a free phone number, you cannot add more numbers.\n\nTo add more phone numbers:\n\n\n\n1. In the phone integration settings, go to the Phone number tab.\n2. Use one of the following methods:\n\n\n\n* To add phone numbers one by one, click Add phone number in the table, and enter the phone number along with an optional description. Click the Add button to save the number.\n* To import a set of phone numbers that are stored in a comma-separated values (CSV) file, click the Upload a CSV file icon (![Add phone number][images/phone-integ-import-number.png]), and then find the CSV file that contains the list of phone numbers.\n\nThe phone numbers you upload will replace any existing numbers in the table.\n\n\n\n\n\n\n\n\n\n Setting up live agent escalation \n\nIf you want your assistant to be able to transfer a conversation to a live agent, you can connect your phone integration to a contact center. For more information, see instructions for the supported platform:\n\n\n\n* [Genesys](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-genesys)\n* [Twilio Flex](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-flex)\n\n\n\n\n\n\n\n Phone integration limits \n\nAny speech service charges incurred by the phone integration are included as Voice add-on charges in your Watson Assistant service plan usage. The Voice add-on use is charged separately and in addition to your service plan charges.\n\nPlan usage is measured based on the number of monthly active users, where a user is identified by the caller's unique phone number. An MD5 hash is applied to the phone number and the 128-bit hash value is used for billing purposes.\n\nThe number of concurrent calls that your assistant can participate in at one time depends on your plan type.\n\n\n\nPlan details\n\n Plan Concurrent calls \n\n Enterprise 1,000", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone"}, {"document_id": "ibmcld_16290-6035-7786", "score": 14.668592, "text": "\nSelect Phone, and then choose the phone you created in the Phone management section. Set yourself as available. The phone icon on the left should now be active.\n19. Click + to start a new call. Specify the number you assigned to Watson Assistant and then click Dial. You should now hear your assistant speak.\n\n\n\nIf you encounter any errors, click Performance -> Interactions and view the PCAP file to read the diagnostics.\n\n\n\n\n\n Transferring to a live agent \n\nNow that your Genesys Cloud environment can connect to Watson Assistant, you can set up the ability for your assistant to transfer calls back to your live agents. To do so, follow these steps:\n\n\n\n1. In the Genesys Cloud console, go to DID Numbers -> DID Ranges and create a new range. Specify the following information:\n\n\n\n* In the DID Start and DID End fields, specify a phone number. (Once again, you do not need to use a real phone number; you can just make up an identifier for your Genesys environment, such as 1-888-888-1234.)\n\n\n\n![Genesys create range](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/phone-genesys-create-range.png)\n\n\n\n* In the Service Provider field, type a descriptive name (for example, Watson).\n\n\n\n2. If you have not already set up a queue to enable callers to wait for available agents, follow these steps to create a simple one now:\n\n\n\n1. Click Admin.\n2. Under Contact Center, click Queues.\n3. Create a new queue and give it a descriptive name.\n4. Add yourself as a member.\n5. Click Save.\n\n\n\n3. Create a simple call flow. Your business might already have something more complex for routing.\n\n\n\n1. Click Admin.\n2. Click Architect.\n3. In the Flows: Inbound Call section, click + to create a new flow.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-genesys"}, {"document_id": "ibmcld_02110-3232-5244", "score": 14.614931, "text": "\nTo request an increase in the account limit, see [Requesting a policy and rule shared limit increase](https://cloud.ibm.com/docs/account?topic=account-account-limits&interface=clilimit-increase).\n\n\n\n Policy limitations based on attributes \n\nAccess management tags are only available when you create an access policy that is scoped for all IAM-enabled services. In this case, when you enable the access based on tags, no other attributes can be added. And, when you base your policy on a specific location or resource group, no tag can be added to the access policy.\n\n\n\n\n\n Trusted profile limitations \n\nUsers can't use the Support Center when they log in to IBM Cloud by applying a trusted profile.\n\n\n\n\n\n\n\n Context-based restrictions limits \n\nThe following table lists the maximum limits for context-based restrictions. These limits apply to any user who can create context-based restrictions rules or network zones. For more information, see [What are context-based restrictions?](https://cloud.ibm.com/docs/account?topic=account-context-restrictions-whatis).\n\nIf you have a specific use case that requires an extended limit, you can request an increase. For more information, see [Increasing account limits](https://cloud.ibm.com/docs/account?topic=account-account-limits).\n\n\n\nTable 2. Context-based restrictions limits\n\n Resource Max \n\n Context-based restriction rules per account <br><br>[2] 4020 \n Network zones per account 500 \n IP addresses per network zone 1000 \n IP addresses per rule 1000 \n\n\n\nA context-based restriction rule that includes multiple network zones can have a maximum of 1000 IP addresses indirectly associated with it. For example, in a rule that includes two network zones, one of the zones could have 800 IP addresses and the other could have a maximum of 200 IP addresses.\n\nIf you want to check the number of rules in your account, see [Viewing the total number of rules per account](https://cloud.ibm.com/docs/account?topic=account-account-limits&interface=clitotal-number-rules-cli).", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-known-issues"}, {"document_id": "ibmcld_03166-23681-24372", "score": 14.614377, "text": "\nFor Lite plans, usage is measured by the number of /message calls (API) are sent to the assistant from the web chat integration. For all other plans, usage is measured by the number of monthly active users (MAU) that the web chat interacts with. The maximum number of allowed MAUs differs depending on your Watson Assistant plan type.\n\n\n\nPlan details\n\n Plan Maximum usage \n\n Enterprise Unlimited MAU \n Premium (legacy) Unlimited MAU \n Plus Unlimited MAU \n Trial 5,000 MAU \n Lite 10,000 API (approximately 1,000 MAU) \n\n\n\nFor more information about how the web chat widget tracks MAUs, see [Billing](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-basicsweb-chat-basics-billing).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat"}, {"document_id": "ibmcld_07578-512956-514877", "score": 14.584696, "text": "\nYou might use the same instance of App Configuration for both scenarios for a total cost of just over $1600 per month.\n\n\n\n* What are the capabilities, quotas, and limits for various aspects of the App Configuration plans?\n\n\n\nTable 2. Capabilities, quotas, and limits for various pricing plans\n\n Lite Standard Enterprise \n\n Number of collaborators (team members) No restriction No restriction No restriction \n Max number of instances 1 No restriction No restriction \n Instance life 30 days of inactivity No restriction No restriction \n Base price for instance (monthly) Free Charge (see catalog page) Charge (see catalog page) \n Monthly active entity IDs included with instance 10 1000 10,000 \n Monthly active entity ID overage Overage not allowed overage allowed overage allowed \n Max monthly active entity IDs per instance 10 Unlimited Unlimited \n API calls included with instance 5,000 100,000 1,000,000 \n API call overage price Overage not allowed Overage allowed Overage allowed \n Max monthly API calls per instance 5,000 Unlimited Unlimited \n Environments 1 15 15 \n Collections 1 20 Unlimited \n Properties 10 (properties + flags) 1000 Unlimited \n Property types All All All \n Max property size 10 kB 10 kB 10 kB \n Max storage size (all properties) 0.1 MB 10 MB 10 MB \n Flags 10 (properties + flags) 100 Unlimited \n Attributes Glean from response and custom attributes Glean from response and custom attributes Glean from response and custom attributes \n Segments 3 <br><br> * <br><br><br> Unlimited \n Segment definition rules per segment 3 <br><br> * <br><br><br> 25 \n Max targeting definition rules per instance 3 <br><br> * <br><br><br> 100 \n Targeting definition rules per feature <br><br> * <br><br><br> <br><br> * <br><br><br> 50 \n Delivery mode Websocket (server)pull or get (client) Websocket (server) pull or get(client) Websocket(server)pull or get (client) \n Role-based access Env-level Env-level Env-level", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-512910-514831", "score": 14.584696, "text": "\nYou might use the same instance of App Configuration for both scenarios for a total cost of just over $1600 per month.\n\n\n\n* What are the capabilities, quotas, and limits for various aspects of the App Configuration plans?\n\n\n\nTable 2. Capabilities, quotas, and limits for various pricing plans\n\n Lite Standard Enterprise \n\n Number of collaborators (team members) No restriction No restriction No restriction \n Max number of instances 1 No restriction No restriction \n Instance life 30 days of inactivity No restriction No restriction \n Base price for instance (monthly) Free Charge (see catalog page) Charge (see catalog page) \n Monthly active entity IDs included with instance 10 1000 10,000 \n Monthly active entity ID overage Overage not allowed overage allowed overage allowed \n Max monthly active entity IDs per instance 10 Unlimited Unlimited \n API calls included with instance 5,000 100,000 1,000,000 \n API call overage price Overage not allowed Overage allowed Overage allowed \n Max monthly API calls per instance 5,000 Unlimited Unlimited \n Environments 1 15 15 \n Collections 1 20 Unlimited \n Properties 10 (properties + flags) 1000 Unlimited \n Property types All All All \n Max property size 10 kB 10 kB 10 kB \n Max storage size (all properties) 0.1 MB 10 MB 10 MB \n Flags 10 (properties + flags) 100 Unlimited \n Attributes Glean from response and custom attributes Glean from response and custom attributes Glean from response and custom attributes \n Segments 3 <br><br> * <br><br><br> Unlimited \n Segment definition rules per segment 3 <br><br> * <br><br><br> 25 \n Max targeting definition rules per instance 3 <br><br> * <br><br><br> 100 \n Targeting definition rules per feature <br><br> * <br><br><br> <br><br> * <br><br><br> 50 \n Delivery mode Websocket (server)pull or get (client) Websocket (server) pull or get(client) Websocket(server)pull or get (client) \n Role-based access Env-level Env-level Env-level", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_16274-14264-16070", "score": 14.395911, "text": "\nspeech_to_text Number The maximum latency (in milliseconds) between when silence is detected in the caller's speech and when a final result from the Speech to Text service is received. This value is calculated from all Speech to Text recognition results related to the call. \n\n\n\n\n\n\n\n realtime_transport_network_summary \n\nWhen RTCP is enabled, the realtime_transport_network_summary object provides statistics for the inbound stream in the inbound_stream object and statistics for the outbound stream in the outbound_stream object.\n\nThe following example shows the structure of the realtime_transport_network_summary object:\n\n\"realtime_transport_network_summary\": {\n\"inbound_stream\": {\n\"maximum_jitter\": 5,\n\"average_jitter\": 1,\n\"packets_lost\": 0,\n\"packets_transmitted\": 1000,\n\"canonical_name\": \"user@example.com\",\n\"tool_name\": \"User SIP Phone\"\n},\n\"outbound_stream\": {\n\"maximum_jitter\": 5,\n\"average_jitter\": 1,\n\"packets_lost\": 0,\n\"packets_transmitted\": 2000,\n\"canonical_name\": \"voice.gateway@127.0.0.1\",\n\"tool_name\": \"IBM Voice Gateway/1.0.0.5\"\n}\n}\nShow more\n\n\n\nThe object for each stream contains the following properties:\n\n\n\nProperties of the realtime_transport_network_summary object\n\n Properties Type Description \n\n maximum_jitter Number The maximum jitter during the call. \n average_jitter Number The average jitter, calculated over the duration of the call. \n packets_lost Number An estimate of the number of packets that were lost during the call. \n packets_transmitted Number An estimate of the total number of packets that were transmitted during the call. \n canonical_name String A unique identifier for the sender of the stream, typically in @ format. \n tool_name String The name of the application or tool where the stream originated. For the phone integration, the default is IBM Voice Gateway/.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-cdr-log-reference"}]}
{"task_id": "b4614daadceeecb400f7baf0aa48dcb8<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03312-7276-9469", "score": 18.222569, "text": "\nThe phone integration can also be configured to respond to a SIP INVITE with a SIP 500 (service unavailable) message if an outage is detected during call setup instead of transferring a call to a live agent. A SIP 500 can then be used to redirect the call to another zone, or if many SIP 500s are received, to another region. Using a SIP 500 INVITE error is a better way to signal a failure to an upstream SIP trunking provider because it gives the provider a way to reroute the call. Using only the default transfer target to handle call failures is acceptable for low call volume scenarios but can result in large numbers of calls being directed to a customer contact center when bigger call volumes are handled by Watson Assistant. To enable this 500 error response capability for a specific Watson Assistant instance, you need to make a request to IBM.\n\nYou should plan for both full and partial service outages. A good first step is to plan for a manual failover between regions before enabling automation. This requires a complete replica of Watson Assistant in both regions, including all custom speech model training. When automation is enabled it is best to start with a strategy for detecting and failing over to the passive backup region when a complete regional outage is detected. After this is in place, a strategy can be implemented to deal with partial outages, which should cover the vast majority of failure conditions that can occur with a phone integration deployment.\n\n\n\n\n\n\n\n Web chat \n\n\n\n Monitoring \n\nWeb chat provides an onError listening feature that allows the host page to detect specific types of outage errors, in particular INITIAL_CONFIG, OPEN_CONFIG, and MESSAGE_COMMUNICATION errors.\n\nYou can find the documentation for this feature here:\n\n[https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configuration#onerror-detail](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationonerror-detail)\n\n\n\n\n\n Failover \n\nHandling a failover for web chat is simple assuming you have set up an additional web chat integration in another region. When the failover needs to be manually triggered, make the following changes:", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-failover"}, {"document_id": "ibmcld_03312-5487-7760", "score": 17.89459, "text": "\nIf a failover is automated and a regional backup is enabled, it is always best to try a different zone first and only redirect traffic to the passive backup region if a preconfigured number of failures occur within a short period of time. This prevents an unnecessary failover between regions if only a short outage occurs.\n\nNote that Watson Assistant provides a round-robin fully qualified domain name (FQDN) that includes the IPs for each zone in the region. Many SIP trunking providers automatically retry each IP in the FQDN when failures occur. To support disaster recovery, the service provider may need to configure two separate SIP trunks, one for each region, and only when all the zones in a single region fail should the call be switched to the backup region. It's important to set the SIP INVITE failure timeouts at the SIP trunking provider low enough to avoid long call setup latencies when a failover is occurring.\n\n\n\n\n\n Partial service outage \n\nThe second type of failure is a partial service outage within the region. This is much harder to detect and manage because of the large number of variations in service failures that can occur within a region. In some cases, these may be small issues that affect the performance characteristics of the call but not cause the call to fail.\n\nFor issues like this that ultimately cause a call to fail, there are two ways Watson Assistant can handle the call. The first is to accept the call and then transfer it to a configured default SIP URI. This can be configured in the Watson Assistant phone integration settings and is also used if there is a mid-call failure. The default transfer target SIP URI is defined in the SIP target when a call fails field located on the Advanced tab of the phone integration configuration panel.\n\nThe phone integration can also be configured to respond to a SIP INVITE with a SIP 500 (service unavailable) message if an outage is detected during call setup instead of transferring a call to a live agent. A SIP 500 can then be used to redirect the call to another zone, or if many SIP 500s are received, to another region. Using a SIP 500 INVITE error is a better way to signal a failure to an upstream SIP trunking provider because it gives the provider a way to reroute the call.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-failover"}, {"document_id": "ibmcld_16288-7-2218", "score": 17.727139, "text": "\nPhone integration configuration \n\nIBM Cloud\n\nAfter you have set up the phone integration for your assistant, you can modify the phone integration settings to customize the call behavior.\n\n\n\n Handling call and transfer failures \n\nYou can configure the phone integration to transfer the caller to a human agent if the phone connection fails for any reason. To transfer the caller to a human agent automatically, go to the Advanced tab in the phone integration settings, and make the following configuration selections:\n\n\n\n* SIP target when a call fails: Add the SIP endpoint for your support agent service. Specify a SIP or telephone URI for a general call queue that can redirect requests to other queues. For more information, see [Configuring backup call center support](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-transfer-service).\n* Call failure message: Add the message you want the assistant to say to a caller before it transfers the call to a human agent.\n\n\n\nIf, after you transfer the call to a human, the connection to a live agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message you want the assistant to say to a caller if transfer to a live agent fails. The message can be up to 150 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after the failure message. This option is enabled by default. If this option is disabled, when a call transfer fails, your assistant can disconnect or process a different action.\n\nIf you choose to leave a call connected despite a transfer failure, Watson Assistant will initiate a new turn to determine the next step. It's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-config"}, {"document_id": "ibmcld_03158-8929-11062", "score": 17.674648, "text": "\nFor more information, see [Configuring backup support](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phonedeploy-phone-transfer-service).\n* Call failure message: Add the message to say to a caller before you transfer them to a human agent.\n\n\n\nIf, after you transfer the caller to a human agent, the connection to the human agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message to stream to callers if the transfer to a human agent fails. The message can be up to 1,024 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after sharing the failure message. This option is enabled by default. If disabled, when a call transfer fails, your assistant can disconnect or process a different dialog node.\n\n\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by selecting one or both of the following configuration options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phonedeploy-phone-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Apply advanced SIP trunk configuration settings \n\n\n\n* SIP INVITE headers to extract: List headers that you want to use in your dialog.\n\nThe SIP request often sends INVITE headers with information about the request that is used by the SIP network.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone"}, {"document_id": "ibmcld_16250-5445-7809", "score": 17.586882, "text": "\nTo support disaster recovery, the service provider may need to configure two separate SIP trunks, one for each region, and only when all the zones in a single region fail should the call be switched to the backup region. It's important to set the SIP INVITE failure timeouts at the SIP trunking provider low enough to avoid long call setup latencies when a failover is occurring.\n\n\n\n\n\n Partial service outage \n\nThe second type of failure is a partial service outage within the region. This is much harder to detect and manage because of the large number of variations in service failures that can occur within a region. In some cases, these may be small issues that affect the performance characteristics of the call but not cause the call to fail.\n\nFor issues like this that ultimately cause a call to fail, there are two ways Watson Assistant can handle the call. The first is to accept the call and then transfer it to a configured default SIP URI. This can be configured in the Watson Assistant phone integration settings and is also used if there is a mid-call failure. The default transfer target SIP URI is defined in the SIP target when a call fails field located on the Advanced tab of the phone integration configuration panel.\n\nThe phone integration can also be configured to respond to a SIP INVITE with a SIP 500 (service unavailable) message if an outage is detected during call setup instead of transferring a call to a live agent. A SIP 500 can then be used to redirect the call to another zone, or if many SIP 500s are received, to another region. Using a SIP 500 INVITE error is a better way to signal a failure to an upstream SIP trunking provider because it gives the provider a way to reroute the call. Using only the default transfer target to handle call failures is acceptable for low call volume scenarios but can result in large numbers of calls being directed to a customer contact center when bigger call volumes are handled by Watson Assistant. To enable this 500 error response capability for a specific Watson Assistant instance, you need to make a request to IBM.\n\nYou should plan for both full and partial service outages. A good first step is to plan for a manual failover between regions before enabling automation. This requires a complete replica of Watson Assistant in both regions, including all custom speech model training.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-failover"}, {"document_id": "ibmcld_16250-7169-9454", "score": 17.143845, "text": "\nUsing only the default transfer target to handle call failures is acceptable for low call volume scenarios but can result in large numbers of calls being directed to a customer contact center when bigger call volumes are handled by Watson Assistant. To enable this 500 error response capability for a specific Watson Assistant instance, you need to make a request to IBM.\n\nYou should plan for both full and partial service outages. A good first step is to plan for a manual failover between regions before enabling automation. This requires a complete replica of Watson Assistant in both regions, including all custom speech model training. When automation is enabled it is best to start with a strategy for detecting and failing over to the passive backup region when a complete regional outage is detected. After this is in place, a strategy can be implemented to deal with partial outages, which should cover the vast majority of failure conditions that can occur with a phone integration deployment.\n\n\n\n\n\n\n\n Web chat \n\n\n\n Monitoring \n\nWeb chat provides an onError listening feature that allows the host page to detect specific types of outage errors, in particular INITIAL_CONFIG, OPEN_CONFIG, and MESSAGE_COMMUNICATION errors.\n\nYou can find the documentation for this feature here:\n\n[https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configuration#onerror-detail](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationonerror-detail)\n\n\n\n\n\n Failover \n\nHandling a failover for web chat is simple assuming you have set up an additional web chat integration in another region. When the failover needs to be manually triggered, make the following changes:\n\n\n\n* The embed script that contains your integration ID, region, service instance ID, and subscription ID (if applicable) needs be changed or updated to use the IDs for the new integration and region.\n* If you are using Salesforce or ZenDesk integrations for connecting to human agents, update the configuration within those systems to make sure they can communicate with the correct integration. Follow the instructions on the Live agent tab in the web chat configuration for setting up those systems. This is only needed for obtaining the conversation history for the agent.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-failover"}, {"document_id": "ibmcld_16288-1733-3996", "score": 16.517101, "text": "\nIt's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call. This 503 response can then be used by the SIP trunking provider to reroute the call to another region. If you want to take advantage of this capability, open a service ticket against the Watson Assistant service instance that requires disaster recovery.\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by going to the Advanced options tab in the phone integration settings, and selecting one or both of the following options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Applying advanced SIP trunk configuration settings \n\nTo configure how your assistant interacts with a SIP trunk from an external provider, go to the SIP trunk tab in the phone integration settings, and update the following options in the SIP trunking integration section:\n\n\n\n* SIP INVITE headers to extract: List the headers that you want your assistant to use.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-config"}, {"document_id": "ibmcld_03158-7739-9484", "score": 15.926795, "text": "\n[checkmark icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/phone-checkmark-save.png) to save each number.\n* To import a set of phone numbers that are stored in a comma-separated values (CSV) file, click the Upload a CSV file icon (![Add phone number](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/phone-integ-import-number.png)), and then find the CSV file that contains the list of phone numbers.\n\nThe phone numbers you upload will replace any existing numbers in the table.\n\n\n\n\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the call behavior:\n\n\n\n Handle call and transfer failures \n\nYou can configure the phone integration to transfer the caller to a human agent if the phone connection fails for any reason. To transfer the caller to a human agent automatically, make the following configuration selections:\n\n\n\n* SIP target when a call fails: Add the SIP endpoint for your support agent service. Specify a SIP or telephone URI for a general call queue that can redirect requests to other queues. For more information, see [Configuring backup support](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phonedeploy-phone-transfer-service).\n* Call failure message: Add the message to say to a caller before you transfer them to a human agent.\n\n\n\nIf, after you transfer the caller to a human agent, the connection to the human agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message to stream to callers if the transfer to a human agent fails. The message can be up to 1,024 characters in length.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone"}, {"document_id": "ibmcld_03312-3639-6036", "score": 15.926483, "text": "\nA Watson Assistant phone integration in one region is unaware of a phone integration in a different region. You need to ensure that your assistants are identically configured in both regions. You also need to rely on the upstream SIP trunking provider to detect and manage failing over between regions.\n\n\n\n Monitoring \n\nSIP trunking providers can be configured to actively health-check the Watson Assistant session border controllers (SBCs) by sending periodic SIP OPTIONS messages to each zone within a region. A failure to receive a response from one of the zones being health-checked can be used to either provide notification of a failure to trigger a manual failover, or it can be used to automate removal of the failed zone from the route list.\n\n\n\n\n\n Failover \n\nThe SIP trunking provider plays an important role in detecting and managing a failover, especially if an automatic failover is expected between regions. In most cases, SIP trunking providers should be configured to treat each zone within a region as active/active and two regions where an assistant is configured as active/passive. SIP trunking providers should always be configured to load balance and fail over between zones within a single region. The remainder of this section focuses on handling a failover between regions.\n\n\n\n\n\n Full service outage \n\nPhone integration failures have two types. The first type is a full outage where the session border controllers in all 3 regional zones become unreachable. This is the easier of the two types to detect and handle because the SIP trunking provider is immediately notified via SIP timeouts that the call fails and can be configured to either automatically fail over or the call routing can be manually reconfigured at the SIP trunking provider to direct traffic away from the failed region towards the passive backup region. If a failover is automated and a regional backup is enabled, it is always best to try a different zone first and only redirect traffic to the passive backup region if a preconfigured number of failures occur within a short period of time. This prevents an unnecessary failover between regions if only a short outage occurs.\n\nNote that Watson Assistant provides a round-robin fully qualified domain name (FQDN) that includes the IPs for each zone in the region. Many SIP trunking providers automatically retry each IP in the FQDN when failures occur.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-failover"}, {"document_id": "ibmcld_16321-20604-22275", "score": 15.611371, "text": "\n\"message\": \"Sorry, I could not find an agent.\"\n},\n\"message_to_human_agent\": \"The caller needs help resetting their password\"\n}\n]\n}\nShow more\n\n\n\n\n\n Transferring upon failure \n\nTo configure transfer on failures, go to the Advanced tab in the phone integration settings. The following selections can be configured:\n\n\n\n* Transfer failure message\n* Disconnect call on transfer failure\n\n\n\nFor more information, see [Handling call and transfer failures](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-failure).\n\n\n\n\n\n Passing Watson Assistant Metadata in SIP Signaling \n\nTo support loading the conversational history between the caller and Watson Assistant, the phone integration specifies a value for the User-to-User header as a key that can be used with the web chat integration. If User-to-User is specified in the transfer_headers list, the session history key is sent in the X-Watson-Assistant-Session-History-Key header.\n\nThe value of the SIP header is limited to 1024 bytes.\n\nHow this data is presented in the SIP REFER message also depends on the value of transfer_headers_send_method(as defined in [Generic Service Desk SIP Parameters](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsgeneric-service-desk-sip-parameters)).\n\nThe following example shows the data included as headers:\n\nREFER sip:b@atlanta.example.com SIP/2.0\nVia: SIP/2.0/UDP agenta.atlanta.example.com;branch=z9hG4bK2293940223\nTo: <sip:b@atlanta.example.com>\nFrom: <sip:a@atlanta.example.com>;tag=193402342\nCall-ID: 898234234@agenta.atlanta.example.com\nCSeq: 23 REFER\nMax-Forwards: 7\nRefer-To: sip:user@domain.com", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actions"}]}
{"task_id": "5815bb4a99e2a0d8a986348da4c49083<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_12498-8087-10171", "score": 22.185143, "text": "\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret"}, {"document_id": "ibmcld_12493-7948-9647", "score": 17.637678, "text": "\nUse the following commands to add a static secret, such as a user credential or an arbitrary secret, to your Secrets Manager instance. Allowable values for SECRET_TYPE are: arbitrary,imported_cert, [kv](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-vault-manage-kv-cli), private_cert, public_cert, and username_password.\n\nCreate a secret in the default secret group.\n\nvault write [-format=FORMAT] ibmcloud/SECRET_TYPE/secrets name=NAME [description=\"DESCRIPTION\"] [username=USERNAME] [password=USERNAME] [payload=DATA] [expiration_date=EXPIRATION] [certificate=CERTIFICATE_DATA] [private_key=PRIVATE_KEY_DATA] [intermediate=INTERMEDIATE_CERTIFICATE_DATA] [ca=CA_CONFIGURATION_NAME] [dns=DNS_CONFIGURATION_NAME] [key_algorithm=KEY_ALGORITHM] [labels=LABEL,LABEL]\n\nCreate a secret in a specified secret group.\n\nvault write [-format=FORMAT] ibmcloud/SECRET_TYPE/secrets/groups/SECRET_GROUP_ID name=NAME [description=\"DESCRIPTION\"] [username=USERNAME] [password=USERNAME] [payload=DATA] [expiration_date=EXPIRATION] [certificate=CERTIFICATE_DATA] [private_key=PRIVATE_KEY_DATA] [intermediate=INTERMEDIATE_CERTIFICATE_DATA] [ca=CA_CONFIGURATION_NAME] [dns=DNS_CONFIGURATION_NAME] [key_algorithm=KEY_ALGORITHM] [labels=LABEL,LABEL]\n\n\n\n Prerequisites \n\nYou need the [Writer service role](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam) to create secrets.\n\n\n\n\n\n Command options \n\nname\n: The human-readable alias that you want to assign to the secret. Required.\n\ndescription\n: An extended description to assign to the secret.\n\nexpiration_date\n: The expiration date that you want to assign to the secret. Supported for the arbitrary and username_password secret types.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-vault-cli"}, {"document_id": "ibmcld_07578-1213887-1215935", "score": 17.340887, "text": "\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https://cloud.ibm.com/docs/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1216520-1218568", "score": 17.340887, "text": "\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https://cloud.ibm.com/docs/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_16729-294066-295916", "score": 16.55405, "text": "\nA script and tool will assist you to simulate the transmission of web server log messages from a static file to Event Streams.\n\nObject Storage Event Streams\n\n+3\n\nAnalytics Engine,Data Engine,Key Protect\n\n\n\n* 3 hours\n* 2023-05-05\n\n\n\n[Getting started with Secrets Manager](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-getting-started)Getting started with Secrets Manager\n\nThis tutorial focuses on storing and managing a username and password in IBM Cloud\u00ae Secrets Manager. With Secrets Manager, you can create, lease, and centrally manage secrets that are used in IBM Cloud services or your custom-built applications. Secrets are stored in a dedicated Secrets Manager instance, built on open source HashiCorp Vault.\n\nSecrets Manager\n\n\n\n* 10 minutes\n* 2023-03-01\n\n\n\n[Access a storage bucket by using a dynamic secret](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-tutorial-access-storage-bucket)Access a storage bucket by using a dynamic secret\n\nIn this tutorial, you learn how to use IBM Cloud\u00ae Secrets Manager to create and lease an IAM credential that can be used to access a bucket in Cloud Object Storage.\n\nSecrets Manager Object Storage\n\n\n\n* 1 hour\n* 2023-05-30\n\n\n\n[Secure secrets for apps that run in your Kubernetes cluster](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-tutorial-kubernetes-secrets)Secure secrets for apps that run in your Kubernetes cluster\n\nThis tutorial is for the Classic flavor of Kubernetes Service clusters. External Secrets is also available as an OpenShift operator.\n\nSecrets Manager\n\n\n\n* 45 minutes\n* 2023-06-15\n\n\n\n[Part 2: Create a GitHub issue when your certificates are about to expire](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-tutorial-expiring-secrets-part-2)Part 2: Create a GitHub issue when your certificates are about to expire", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}, {"document_id": "ibmcld_12498-9696-11699", "score": 16.06589, "text": "\n[IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL/TLS certificates](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-automatic-rotation) !", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret"}, {"document_id": "ibmcld_12415-7-1973", "score": 16.04966, "text": "\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https://cloud.ibm.com/docs/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-faqs"}, {"document_id": "ibmcld_16727-1218119-1220168", "score": 15.363392, "text": "\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-1215486-1217535", "score": 15.363392, "text": "\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_12717-7818-8740", "score": 15.116917, "text": "\nCheck whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code CM-3(2)(0), CM-4(0), CM-4(1)(0), CM-7(1)(a), CM-7(b), RA-5(1)(0), RA-5(2)(0), RA-5(3)(0), RA-5(a), RA-5(b), RA-5(c), RA-5(d), SA-10(e), SA-15(a), SA-3(a), SA-3(d), SA-8(0), SI-10(0), SI-2(2)(0), SI-2(a), SI-2(b), SI-2(c), and SI-2(d) Rule was added \n Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts CM-3(2)(0), CM-4(0), CM-4(1)(0), CM-7(1)(a), CM-7(b), RA-5(1)(0), RA-5(2)(0), RA-5(3)(0), RA-5(a), RA-5(b), RA-5(c), RA-5(d), SA-10(e), SA-15(a), SA-3(a), SA-3(d), SA-8(0), SI-10(0), SI-2(2)(0), SI-2(a), SI-2(b), SI-2(c), and SI-2(d) Rule was added \n Check whether Secrets Manager arbitrary secrets are rotated at least every # days IA-5(g) Rule was added \n Check whether Secrets Manager user credentials are rotated at least every # days IA-5(g) Rule was added", "title": "", "source": "https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-fs-change-log"}]}
{"task_id": "5815bb4a99e2a0d8a986348da4c49083<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_14389-3006-4736", "score": 15.769883, "text": "\n* Better - This offer is built on the benefits of the Good option, with the addition of BIG-IP DNS\u2122, BIG-IP Advanced Firewall Manager\u2122 (AFM), and BIG-IP Application Acceleration Manager\u2122 (AAM) modules. It delivers global traffic management services, application performance optimization, and advanced network firewall and Distributed Denial of Service (DDoS) mitigation capabilities.\n* Best - In addition to the Good and Better offers, BIG-IP Application Security Manager\u2122 (ASM) provides:\n\n\n\n* Comprehensive application protection against L7 DDoS\n* Open Web Application Security Project (OWASP) top 10 threats\n* Common application vulnerabilities\n\n\n\n\n\nBIG-IP Access Policy Manager\u2122 (APM) offers users secure, simplified access to applications located anywhere within a multicloud environment, incorporating features such as SSO (Single Sign-On) and MFA (Multifactor Authentication).\n\nYou cannot change the license model after service installation. To change the license model, you must delete the existing service and reinstall the service by choosing a different license model.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [F5 BIG-IP overview](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-f5_considerations)\n* [Managing F5 BIG-IP](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-managing_f5)\n* [Ordering services for vCenter Server instances](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vc_addingservices)\n* [Contacting IBM\u00ae Support](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-trbl_support)\n* [FAQ](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-faq-vmwaresolutions)\n* [F5 Deployment Guides](https://www.f5.com/services/resources/deployment-guides)", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-f5_ordering"}, {"document_id": "ibmcld_07854-0-2195", "score": 15.16579, "text": "\n\n\n\n\n\n\n  SA-12 - Supply Chain Protection \n\n\n\n  Control requirements \n\nSA-12 - 0\n:   The organization protects against supply chain threats to the information system, system component, or information system service by employing [IBM Assignment: IBM-defined personnel security requirements, approved HW/SW vendor list/ process, and secure SDLC procedures] as part of a comprehensive, defense-in-breadth information security strategy.\n\n\n\n\n\n  NIST supplemental guidance \n\nInformation systems (including system components that compose those systems) need to be protected throughout the system development life cycle (i.e., during design, development, manufacturing, packaging, assembly, distribution, system integration, operations, maintenance, and retirement). Protection of organizational information systems is accomplished through threat awareness, by the identification, management, and reduction of vulnerabilities at each phase of the life cycle and the use of complementary, mutually reinforcing strategies to respond to risk. Organizations consider implementing a standardized process to address supply chain risk with respect to information systems and system components, and to educate the acquisition workforce on threats, risk, and required security controls. Organizations use the acquisition/procurement processes to require supply chain entities to implement necessary security safeguards to: (i) reduce the likelihood of unauthorized modifications at each stage in the supply chain; and (ii) protect information systems and information system components, prior to taking delivery of such systems/components. This control also applies to information system services. Security safeguards include, for example: (i) security controls for development systems, development facilities, and external connections to development systems; (ii) vetting development personnel; and (iii) use of tamper-evident packaging during shipping/warehousing. Methods for reviewing and protecting development plans, evidence, and documentation are commensurate with the security category or classification level of the information system. Contracts may specify documentation protection requirements.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-sa-12"}, {"document_id": "ibmcld_07949-17036-19108", "score": 14.12254, "text": "\nBy monitoring for risks, you can identify security vulnerabilities and quickly work to mitigate the impact and fix the issue. By using Security and Compliance Center along with [external integrations](https://cloud.ibm.com/security-compliance/integrations) (such as, OpenShift Compliance Operator (OSCO), Tanium, NeuVector, and so on), you can build a robust approach for monitoring for security and compliance issues.\n\n\n\n\n\n\n\n Integration \n\n\n\n IBM Event Streams for IBM Cloud (optional) \n\n[Event Streams](https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-about) is a high-throughput message bus built with Apache Kafka. It is optimized for event ingestion into IBM Cloud and event stream distribution between your services and applications.\n\nYou can use Event Streams to complete the following tasks:\n\n\n\n* Offload work to back-end worker applications.\n* Connect event streams to streaming analytics to realize powerful insights.\n* Publish event data to multiple applications to react in real time.\n\n\n\nEvent Streams offers a fully managed Apache Kafka service, ensuring durability and high availability for our clients. By using Event Streams, you have support around the clock from our team of Kafka experts.\n\n\n\n\n\n\n\n Databases \n\n\n\n IBM Cloud Hyper Protect DBaaS for MongoDB (optional) \n\nMoving confidential and mission-critical data to the cloud presents data confidentiality, security, and reliability concerns. [IBM Cloud\u00ae Hyper Protect DBaaS for MongoDB](https://cloud.ibm.com/docs/hyper-protect-dbaas-for-mongodb?topic=hyper-protect-dbaas-for-mongodb-overview) offers highly secure database environments that have technology-enforced protection and high availability.\n\nBuilt on IBM LinuxONE technology, Hyper Protect DBaaS for MongoDB helps you to alleviate data security and compliance concerns with built-in encryption and tamper protection for data at rest and in flight. You can deploy your workloads with sensitive data and build compliant applications without having to be a security expert.\n\n\n\n\n\n IBM Cloud Hyper Protect DBaaS for PostgreSQL (optional)", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-satellite-architecture-about"}, {"document_id": "ibmcld_09492-7377-9593", "score": 14.107659, "text": "\nIBM performs external and internal vulnerability scanning and subsequent remediation in all IBM Maximo Application Suite Dedicated environments on a quarterly basis per IBM IT Security Standards (ITSS). This includes Operating System, Middleware, Application and TCP/IP vulnerability scanning.\n\nVulnerabilities are assigned individual vulnerability ratings and exploitation categories (Critical, High, Medium or Low). These ratings are used to determine an IBM mandated time requirement to remediate and resolve the vulnerability.\n\nVulnerability scanning results and logs are considered IBM Confidential Information and are not disclosed to customers or prospects.\n\nSQL Injection - please see FAQ link below regarding how Maximo protects against SQL injection: [https://www-01.ibm.com/support/docview.wss?uid=swg21419049](https://www-01.ibm.com/support/docview.wss?uid=swg21419049)\n\n\n\n\n\n Security Services \n\nThe IBM Maximo Application Suite Dedicated team provides the following security and system access services. These services are included as part of IBM Maximo Application Suite Dedicated:\n\nSetup of SSL certificates and DNS registration. This is standard by default and allows for secure browser based HTTPS (encrypted) access IBM Maximo Application Suite Dedicated end users.\n\nSetup of IPsec Virtual Private Network (VPN) between client locations and IBM Cloud data center(s). VPN setup is optional, and is used to provide the following:\n\n\n\n* Direct read-only access to IBM on Cloud databases\n* LDAP authentication\n\n\n\nOther uses are not currently available using VPN.\n\nSetup and configuration of SSO including OIDC (default), SAML and LDAP user authentication for IBM Maximo Application Suite applications. SSO configuration is optional but is included as part of the IBM on Cloud subscription.\n\n\n\n\n\n Compliance - IBM Cloud (Infrastructure) \n\nAll IBM Maximo Application Suite Dedicated customer environments are managed to IBM IT Security Standards (ITSS) defined by IBM\u2019s Chief Information Security Officer (CISO). This includes vulnerability scanning and subsequent remediation.\n\nIBM Cloud holds ISO-27001 certification and can provide SOC 1, 2 and 3 reports to customers\n\nIBM Cloud (IaaS) ISO certificates:", "title": "", "source": "https://cloud.ibm.com/docs/mas-ms?topic=mas-ms-Security"}, {"document_id": "ibmcld_09513-6833-9016", "score": 14.072711, "text": "\nIBM performs external and internal vulnerability scanning and subsequent remediation in all IBM Maximo Application Suite SaaS environments on a quarterly basis per IBM IT Security Standards (ITSS). This includes Operating System, Middleware, Application and TCP/IP vulnerability scanning.\n\nVulnerabilities are assigned individual vulnerability ratings and exploitation categories (Critical, High, Medium or Low). These ratings are used to determine an IBM mandated time requirement to remediate and resolve the vulnerability.\n\nVulnerability scanning results and logs are considered IBM Confidential Information and are not disclosed to customers or prospects.\n\nSQL Injection - please see FAQ link below regarding how Maximo protects against SQL injection: [https://www-01.ibm.com/support/docview.wss?uid=swg21419049](https://www-01.ibm.com/support/docview.wss?uid=swg21419049)\n\n\n\n\n\n Security Services \n\nThe IBM Maximo Application Suite SaaS team provides the following security and system access services. These services are included as part of the IBM Maximo Application Suite as a Service:\n\nSetup of SSL certificates and DNS registration. This is standard by default and allows for secure browser based HTTPS (encrypted) access IBM Maximo Application Suite SaaS end users.\n\nSetup of IPsec Virtual Private Network (VPN) between client locations and IBM Cloud data center(s). VPN setup is optional, and is used to provide the following:\n\n\n\n* Direct read-only access to IBM on Cloud databases\n* LDAP authentication\n\n\n\nOther uses are not currently available using VPN.\n\nSetup and configuration of SSO including OIDC (default), SAML and LDAP user authentication for IBM Maximo Application Suite applications. SSO configuration is optional but is included as part of the IBM on Cloud subscription.\n\n\n\n\n\n Compliance - AWS (Infrastructure) \n\nAll IBM Maximo Application Suite SaaS customer environments are managed to IBM IT Security Standards (ITSS) defined by IBM\u2019s Chief Information Security Officer (CISO). This includes vulnerability scanning and subsequent remediation\n\nAWS holds ISO-27001 certification and can provide SOC 1, 2 and 3 reports to customers\n\nAWS (IaaS) ISO information:", "title": "", "source": "https://cloud.ibm.com/docs/mas-saas?topic=mas-saas-Security"}, {"document_id": "ibmcld_15848-0-2092", "score": 13.892901, "text": "\n\n\n\n\n\n\n  Security best practices for z/OS virtual server instances \n\nTo secure your z/OS virtual server instance and identify any security vulnerabilities, you must refer to the following security information and industry standard security reports.\n\nProducts and services in the z/OS stock images are periodically reviewed and updated. IBM continues to follow the standard security guidance and provides differentiating technologies in security and data privacy, focusing on but not limited to the following areas:\n\n\n\n*  Security patch management\n*  Firmware currency\n*  Setup of suggested products and services\n*  Configuration of hardware and software (operating systems, middleware, third-party applications, open source, network cards, and so on)\n*  Integration and monitoring of software, hardware, and end-points\n*  Cybersecurity:\n\n\n\n*  Least access privilege\n*  Separation of duties\n*  Defense-in-depth\n*  Authentication strength\n*  End-to-end encryption\n\n\n\n\n\nFor this release, you need to follow the security best practices for your z/OS virtual server instance:\n\n\n\n*  If you want to apply the latest service for your instance, it is suggested that you wait until the next month\u2019s refresh stock image to provision a new z/OS virtual server instance.\n*  Ensure that you follow the password policy, see [Configuring the password](https://cloud.ibm.com/docs/vpc?topic=vpc-vsi_is_connecting_zosconfigure-password).\n*  For more information about various security topics, see the following references:\n\n\n\n*  [What is zero trust?](https://www.ibm.com/topics/zero-trust)\n*  [NIST Special Publication Security & Privacy Controls for Information Systems & Organizations](https://doi.org/10.6028/NIST.SP.800-53r5)\n*  [IBM X-Force Threat Intelligence Report](https://www.ibm.com/security/data-breach/threat-intelligence/)\n*  [IBM on Enterprise Security](https://www.ibm.com/it-infrastructure/z/capabilities/enterprise-security)\n*  [PCI DSS v4.0](https://www.pcisecuritystandards.org/documents/PCI-DSS-v4_0.pdf)\n*  [CIS Benchmarks for IBM Z](https://workbench.cisecurity.org/files/3877)\n\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-security-best-practices-zos"}, {"document_id": "ibmcld_14336-7-2347", "score": 13.791042, "text": "\nCaveonix RiskForesight introduction \n\nEnterprises that undergo a digital transformation are adopting a hybrid cloud strategy. This strategy includes workloads in both the private cloud and multiple external cloud environments, such as the public cloud or a cloud managed by a service provider. Most enterprises are also faced with the challenge of protecting an ever-increasing attack surface while simultaneously maintaining compliance with industry and regulatory compliance requirements.\n\nTo protect this expanding attack surface, enterprises need continuous visibility into workloads from the start until the end of their lifecycle. Enterprises must maintain a \u201cfull-stack\u201d understanding of the workload vulnerabilities and configuration issues at the infrastructure, platform, and application level in the context of threats and compliance requirements. Enterprises need predictive analytics to \u201cconnect the dots\u201d to give a proactive view of their cyberrisk and compliance risk posture in this vast, new hybrid world.\n\nCaveonix RiskForesight\u2122 provides proactive workload protection from risks due to cyberthreats and regulatory compliance issues. It provides real-time visibility into what is running in an enterprise\u2019s hybrid cloud through native integration into cloud orchestration platforms. Combining such visibility with risk reduction models and enforcement actions that can be automated, RiskForesight quickly develops a prioritized list of actions to mitigate. RiskForesight is a multitenant-aware hybrid cloud workload protection platform that implements a proactive risk management framework. This framework can operate at multiple control planes: network, compute, security, and compliance, while the implementation of the framework at cloud scale is automated.\n\nThe platform is fully integrated into the VMware\u00ae technology stack from vCD, vRA, vCenter to NSX and many public clouds. The RiskForesight platform has three key modules: Detect, Predict, and Act, providing 360-degree visibility into hybrid cloud workloads in real time by natively integrating into hybrid cloud orchestration modules. It is the industry\u2019s first, seamless hybrid cloud protection platform. This platform allows customers to see IT, cyberrisk and compliance risk across the full cybercontrol planes of network, security, compute, and compliance.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-caveonix-intro"}, {"document_id": "ibmcld_11605-7-2426", "score": 13.537534, "text": "\nIBM Security Services for SAP \n\nIBM Cloud\u00ae Security Services for SAP offer a cybersecurity solution that automates the monitoring and protection of SAP applications on IBM Cloud, and keeps workloads compliant and secure from inside and outside threats.\n\nIBM Services for SAP, developed in partnership with IBM Security Software and other business partners, implement and configure the SAP landscape to meet IT environment requirements for continuous workload visibility and protection.\n\nThrough continuous monitoring, IBM Security Services are able to deliver near real-time preventive, detective, and corrective solutions for securing SAP systems and applications with unmatched coverage and protection. This protection includes context-aware insight across SAP NetWeaver ABAP or Javas and SAP HANA platforms, with network security, security management, and associated workflows.\n\nIBM Security Services for SAP offer the following features:\n\n\n\n* Comprehensive understanding of vulnerabilities and potential attack vectors\n* Methods to implement and avoid defects in ABAP code or SAP Transports\n* Identifying configuration vulnerabilities for ABAP, JAVA, and HANA environments\n* Identifying missing or outdated SAP notes and patches\n* Identifying, monitoring and review of highly privileged SAP accounts\n* Enabling continuous monitoring of vulnerabilities with integration to existing SIEM solution\n\n\n\nKey benefits of requesting IBM Security Services for SAP to assist with your IBM Cloud\u00ae for SAP deployments:\n\n\n\n* Consultative engagement methods centered on your business objectives\n* Experienced end-to-end architectural experts that work jointly with the IBM Cloud team\n* Accelerated cloud adoption for successful implementation of SAP workloads on the cloud\n* Prescriptive best practices for solution implementation by using IBM Cloud Services products and features\n* Rapid learning and risk mitigation through access to IBM Cloud experts\n\n\n\nFor more information, see [IBM.com - IBM Security - SAP Security and GRC Strategy Services](https://www.ibm.com/security/services/security-governance/sap-grc-strategy)\n\n\n\n Procedure to request IBM Security Services for SAP \n\nTo begin with IBM Security Services for SAP, use either:\n\n\n\n* Live Chat with IBM Security Sales, by using [IBM.com - IBM Security](https://www.ibm.com/security/services/security-governance/sap-grc-strategy) and click Let's talk in the botttom-left", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-ibm-security-services"}, {"document_id": "ibmcld_16696-7-2390", "score": 13.534447, "text": "\nKey features of IBM Cloud Security and Compliance Center Workload Protection \n\nIBM Cloud\u00ae Security and Compliance Center Workload Protection offers functionality to protect workloads, get deep cloud and container visibility, posture management (compliance, benchmarks, CIEM), vulnerability scanning, forensics, and threat detection and blocking.\n\n\n\n Provides a unified and centralized framework to manage the security and compliance of applications, workloads and infrastructure \n\n\n\n* Provides a unified and centralized framework to manage the security and compliance of applications, workloads and infrastructure and protect workloads and resources that run on IBM Cloud, in other clouds, and on-prem. Presents relevant performance and security data in one location.\n* Is built on open standards for cloud native security and control, including Falco, the open source standard for cloud threat detection, and Open Policy Agent (OPA), the open source standard for policy-as-code.\n* Offers a workload protection platform (WPP) that focuses on management and security controls for workloads.\n* Offers a compliance platform (CP) that focuses on management and compliance controls that are required to meet industry standards and laws.\n* Includes Cloud security posture management (CSPM) to help you secure the infrastructure where workloads are deployed.\n* Includes Kubernetes Security Posture Management (KSPM) to help you secure Kubernetes clusters or Openshift clusters, and the workloads running within it.\n* Offers alerting on violations, and assists with remediation tasks.\n\n\n\n\n\n\n\n Offers host and image scanning, auditing, and runtime vulnerability management capabilities \n\n\n\n* Filters and surfaces vulnerabilities in images, clusters, namespaces, or hosts.\n* Alerts on unscanned images or images when the evaluation status changes with new vulnerabilities.\n* Logs user actions, container activity, and command arguments.\n* Enforces security policies and blocks attacks.\n\n\n\n\n\n\n\n Provides posture management for a distributed environment \n\n\n\n* Schedules customized benchmark tests to run across cloud, hosts, services, or clusters.\n* Controls compliance at cloud, orchestrator, and container level.\n* Tracks and optimizes cloud users permissions and entitlements.\n* Exports results to SIEM, logging clusters, or other tools.\n\n\n\n\n\n\n\n Provides runtime detection and data enrichment", "title": "", "source": "https://cloud.ibm.com/docs/workload-protection?topic=workload-protection-key-features"}, {"document_id": "ibmcld_04227-0-2310", "score": 13.293839, "text": "\n\n\n\n\n\n\n  Web Application Firewall concepts \n\nThe Web Application Firewall (WAF) protects against OSI Layer-7 attacks, which can be some of the most tricky. This document gives some details.\n\n\n\n  What is a Web Application Firewall? \n\nA WAF helps protect web applications by filtering and monitoring HTTP traffic between a web application and the internet. A WAF is an OSI protocol Layer-7 defense in the [OSI model](https://en.wikipedia.org/wiki/OSI_model), and it is not designed to defend against all types of attacks.\n\nDeploying a WAF in front of a web application is like placing a shield between the web application and the internet. A proxy server protects a client machine\u2019s identity by using an intermediary (for outgoing traffic), but a WAF is a type of reverse-proxy that protects the server from exposure by having the client's traffic pass through the WAF before reaching the server (for incoming traffic).\n\n\n\n\n\n  Types of attacks WAF can prevent \n\nA WAF typically protects web applications from attacks such as cross-site forgery, cross-site-scripting (XSS), file inclusion, and SQL injection, among others. A WAF usually is part of a suite of tools, which together can create a holistic defense against a range of attack vectors.\n\n\n\n\n\n  How a WAF works \n\nA WAF operates through a set of rules often called policies. These policies aim to protect against vulnerabilities in the application by filtering out malicious traffic.\n\nThe value of a WAF comes from the speed and ease with which its policy modifications can be implemented, thereby allowing a faster response to varying attack vectors. For example, during a [DDoS attack](https://en.wikipedia.org/wiki/Denial-of-service_attack), rate limiting can be implemented by modifying WAF policies.\n\n\n\n\n\n  Key benefits of a CIS WAF \n\nThe IBM Cloud\u00ae Internet Services WAF is an easy way to set up, manage, and customize security rules to protect your web applications from common web threats. See the following list for key features:\n\n\n\n*  Easy setup - The CIS WAF is part of our overall service, which takes just a few minutes to set up. After you redirect your DNS to us, you can switch on the WAF and set up the rules you need.\n*  Detailed reporting - See greater detail in the reporting, for example, threats blocked by rule/rule group.\n\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-waf-q-and-a"}]}
{"task_id": "5815bb4a99e2a0d8a986348da4c49083<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_12498-8087-10171", "score": 19.75469, "text": "\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret"}, {"document_id": "ibmcld_12493-27359-28981", "score": 18.798956, "text": "\nPrerequisites \n\nYou need the [Writer service role](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam) to rotate secrets.\n\n\n\n\n\n Command options \n\npayload\n: The new data to store for an arbitrary secret. Only text-based payloads are supported. If you need to store a binary file, be sure to base64 encode it before you save it to Secrets Manager. For more information, see [Examples](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-vault-clivault-cli-create-static-secret-examples).\n\npassword\n: The new password to assign to a username_password secret.\n\ncertificate\n: The new certificate data to store for an imported_cert secret. Supported file type is .pem.\n\nprivate_key\n: The new private key data to store for an imported_cert secret. Supported file type is .pem.\n\nintermediate\n: The new intermediate certificate data to store for an imported_cert secret. Supported file type is .pem.\n\n-format\n: Prints the output in the format that you specify. Valid formats are table, json, and yaml. The default is table. You can also set the output format by using the VAULT_FORMAT environment variable.\n\n-force\n: Replaces the password that is stored for a username_password secret with a randomly generated, 32-character password that contains uppercase letters, lowercase letters, digits, and symbols.\n\n\n\n\n\n Examples \n\nManually rotate the secret data that is stored for an arbitrary secret.\n\nvault write -format=json ibmcloud/arbitrary/secrets/fe874c2b-e8fd-bbb6-9f19-e91bbe744735/rotate payload=\"Updated secret data.\"\n\nManually rotate the password that is stored for a username_password secret.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-vault-cli"}, {"document_id": "ibmcld_12467-1716-3849", "score": 18.424591, "text": "\n* When you try to modify or delete a secret while it is locked, Secrets Manager denies the request with an HTTP 412 Precondition Failed response. You see an error message similar to the following example:\n\nThe requested action can't be completed because the secret version is locked.\n\nIf you're working with\n\ndynamic secrets, such as IAM credentials, locking your secrets also means that by default, those secrets can't be read or accessed. For more information, see [Why can't I read a locked IAM credentials secret?](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-locked-iam-credentials)\n* If a locked secret reaches its expiration date, it stays in the Active state and its data remains accessible to your applications. Secrets Manager moves the secret to the Destroyed state and permanently deletes the expired secret data only after all locks on the secret are removed.\n\nSSL/TLS certificates still reach their defined expiration dates and move into a Destroyed state even if they are locked. For more information, see [Why did my locked certificate move to the Destroyed state?](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-locked-certificates)\n* If you try to rotate a secret while its current version is locked and the previous version is unlocked (or if an automatic rotation is scheduled), the request to rotate the secret is allowed. The current secret version becomes the new previous version, retaining its existing locks. A new current version is created without any locks.\n* If you try to rotate a secret while its previous version is locked (or if an automatic rotation is scheduled), your request to rotate the secret is denied. Rotation is allowed only after all locks on the previous secret version are removed.\n\n\n\n\n\n Creating locks in the UI \n\nYou can create up to 1000 locks on a secret by using the Secrets Manager UI. Each lock can be used to represent a single application or service that uses your secret.\n\nA secret is considered locked after you attach one or more locks to it. A lock can be applied only on a secret version that contains active payload, or secret data.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-secret-locks"}, {"document_id": "ibmcld_12498-9696-11699", "score": 18.381575, "text": "\n[IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL/TLS certificates](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-automatic-rotation) !", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret"}, {"document_id": "ibmcld_12428-14731-16279", "score": 18.340775, "text": "\nIf reuse_api_key is false for IAM credentials, manual rotation for the secret isn't supported. For more information, see [Manually rotating secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-manual-rotation).\n\n\n\n\n\n Using an existing service ID in your account \n\nYou might already have a service ID in your account that you want to use to dynamically generate an API key. In this scenario, you can choose to create an IAM credentials secret by bringing your own service ID. For example, the following command creates an IAM credential by using the service_id field.\n\nYou can store metadata that are relevant to the needs of your organization with the custom_metadata and version_custom_metadata request parameters. Values of the version_custom_metadata are returned only for the versions of a secret. The custom metadata of your secret is stored as all other metadata, for up to 50 versions, and you must not include confidential data.\n\nYou can find the ID value of a service ID in the IAM section of the console. Go to Manage > Access (IAM) > Service IDs > name. Click Details to view the ID.\n\ncurl -X POST\n-H \"Authorization: Bearer {iam_token}\" -H \"Accept: application/json\" -H \"Content-Type: application/json\" -d '{\n\"name\": \"example-iam-credentials-secret\",\n\"description\": \"Description of my IAM Credentials secret\",\n\"service_id\":\"iam-ServiceId-c0c7cfa4-b24e-4917-ad74-278f2fee5ba0\",\n\"secret_type\": \"iam_credentials\",\n\"secret_group_id\": \"bfc0a4a9-3d58-4fda-945b-76756af516aa\",\n\"labels\": [\n\"dev\",\n\"us-south\"\n],\n\"ttl\": \"30m\",", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials&interface=ui"}, {"document_id": "ibmcld_12422-14705-16253", "score": 18.340775, "text": "\nIf reuse_api_key is false for IAM credentials, manual rotation for the secret isn't supported. For more information, see [Manually rotating secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-manual-rotation).\n\n\n\n\n\n Using an existing service ID in your account \n\nYou might already have a service ID in your account that you want to use to dynamically generate an API key. In this scenario, you can choose to create an IAM credentials secret by bringing your own service ID. For example, the following command creates an IAM credential by using the service_id field.\n\nYou can store metadata that are relevant to the needs of your organization with the custom_metadata and version_custom_metadata request parameters. Values of the version_custom_metadata are returned only for the versions of a secret. The custom metadata of your secret is stored as all other metadata, for up to 50 versions, and you must not include confidential data.\n\nYou can find the ID value of a service ID in the IAM section of the console. Go to Manage > Access (IAM) > Service IDs > name. Click Details to view the ID.\n\ncurl -X POST\n-H \"Authorization: Bearer {iam_token}\" -H \"Accept: application/json\" -H \"Content-Type: application/json\" -d '{\n\"name\": \"example-iam-credentials-secret\",\n\"description\": \"Description of my IAM Credentials secret\",\n\"service_id\":\"iam-ServiceId-c0c7cfa4-b24e-4917-ad74-278f2fee5ba0\",\n\"secret_type\": \"iam_credentials\",\n\"secret_group_id\": \"bfc0a4a9-3d58-4fda-945b-76756af516aa\",\n\"labels\": [\n\"dev\",\n\"us-south\"\n],\n\"ttl\": \"30m\",", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials"}, {"document_id": "ibmcld_12415-7-1973", "score": 18.108402, "text": "\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https://cloud.ibm.com/docs/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-faqs"}, {"document_id": "ibmcld_12447-1578-3681", "score": 17.602417, "text": "\nIf the IAM credentials secret was created by using an existing service ID in the account, only the API key is regenerated as part of a manual rotation. In contrast, if the secret was created by selecting an access group, both the service ID and API key values are regenerated when they're manually rotated.<br><br>The Reuse IAM credentials until lease expires (reuse_api_key) option for an IAM credentials secret impacts whether it can be rotated manually. If this field is false or set to Off in the UI, manual rotation isn't supported. The API key that is dynamically generated for the secret on each read is already a single-use, ephemeral value. \n [Imported certificates](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificatesimport-certificates) Certificates that were initially imported to a service instance are immediately replaced with the data that you reimport on rotation. \n [Key-value secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-key-value) Key-value secrets are immediately replaced with the data that you provide on rotation. \n [Private certificates](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificatescreate-certificates) Private certificates are immediately replaced with a certificate that is signed by its parent or issuing certificate authority. \n [Public certificates](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificatesorder-certificates) Public certificates move to the Active, Rotation pending status to indicate that a request to rotate a certificate is being processed. Secrets Manager sends the request to the configured certificate authority (CA), for example Let's Encrypt, to validate the ownership of your domains. If the validation completes successfully, a new certificate is issued. \n [User credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-user-credentials) Passwords that are associated with user credentials secrets are immediately replaced with the data that you provide on rotation. \n\n\n\n\n\n\n\n\n\n Creating new secret versions in the UI", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-manual-rotation&interface=ui"}, {"document_id": "ibmcld_12462-22671-23294", "score": 17.535765, "text": "\n\"alt_name1\", \"alt_name2\"\n],\n\"algorithm\": \"sha256WithRSAEncryption\",\n\"key_algorithm\": \"rsaEncryption 2048 bit\",\n\"rotation\": {\n\"enabled\": false,\n\"rotate_keys\":false\n},\n\"custom_metadata\" : {\n\"anyKey\" : \"anyValue\"\n},\n\"version_custom_metadata\" : {\n\"anyKey\" : \"anyValue\"\n},\n\"expiration_date\" : \"2030-01-01T00:00:00Z\",\n}\n]\n\nThe command outputs the ID value of the secret, along with other metadata. For more information about the command options, see [ibmcloud secrets-manager secret-create](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-cli-plugin-secrets-manager-clisecrets-manager-cli-secret-create-command).", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-public-certificates&interface=ui"}, {"document_id": "ibmcld_16727-1218119-1220168", "score": 17.515457, "text": "\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}]}
{"task_id": "5815bb4a99e2a0d8a986348da4c49083<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_12498-8087-10171", "score": 18.752178, "text": "\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret"}, {"document_id": "ibmcld_12415-7-1973", "score": 18.425917, "text": "\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https://cloud.ibm.com/docs/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-faqs"}, {"document_id": "ibmcld_16727-1218119-1220168", "score": 17.312191, "text": "\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-1215486-1217535", "score": 17.312191, "text": "\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_12428-4-1817", "score": 17.302813, "text": "\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Creating IAM credentials \n\nYou can use IBM Cloud\u00ae Secrets Manager to dynamically generate IAM credentials for accessing an IBM Cloud resource that requires IAM authentication.\n\nIAM credentials are\n\ndynamic secretsthat you can use to access an IBM Cloud resource. A set of IAM credentials consists of a service ID and an API key that is generated each time that the protected resource is read or accessed. You can define a time-to-live (TTL) or a lease duration for your IAM credential at its creation so that you shorten the amount of time that the secret exists.\n\nTo learn more about the types of secrets that you can manage in Secrets Manager, see [What is a secret?](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret)\n\n\n\n Before you begin \n\nBefore you get started, be sure that you have the required level of access. To create or add secrets, you need the [Writer service role or higher](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam).\n\nIAM credentials require an extra configuration step before you can start to create or manage them in the service. For more information, see [Configuring the IAM credentials engine](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-configure-iam-engine).\n\nAn account administrator (or any entity with the required level of access) can externally alter IAM Credentials that are created and managed by Secrets Manager. If such a service ID or API key is deleted outside of Secrets Manager, the service might behave unexpectedly. For example, you might be unable to create, or rotate credentials.\n\n\n\n\n\n Creating IAM credentials in the UI \n\nTo create IAM credentials by using the Secrets Manager UI, complete the following steps.\n\n\n\n1. In the console, click the Menu icon !", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials&interface=ui"}, {"document_id": "ibmcld_12422-4-1817", "score": 17.302813, "text": "\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Creating IAM credentials \n\nYou can use IBM Cloud\u00ae Secrets Manager to dynamically generate IAM credentials for accessing an IBM Cloud resource that requires IAM authentication.\n\nIAM credentials are\n\ndynamic secretsthat you can use to access an IBM Cloud resource. A set of IAM credentials consists of a service ID and an API key that is generated each time that the protected resource is read or accessed. You can define a time-to-live (TTL) or a lease duration for your IAM credential at its creation so that you shorten the amount of time that the secret exists.\n\nTo learn more about the types of secrets that you can manage in Secrets Manager, see [What is a secret?](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret)\n\n\n\n Before you begin \n\nBefore you get started, be sure that you have the required level of access. To create or add secrets, you need the [Writer service role or higher](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam).\n\nIAM credentials require an extra configuration step before you can start to create or manage them in the service. For more information, see [Configuring the IAM credentials engine](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-configure-iam-engine).\n\nAn account administrator (or any entity with the required level of access) can externally alter IAM Credentials that are created and managed by Secrets Manager. If such a service ID or API key is deleted outside of Secrets Manager, the service might behave unexpectedly. For example, you might be unable to create, or rotate credentials.\n\n\n\n\n\n Creating IAM credentials in the UI \n\nTo create IAM credentials by using the Secrets Manager UI, complete the following steps.\n\n\n\n1. In the console, click the Menu icon !", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials"}, {"document_id": "ibmcld_12498-9696-11699", "score": 17.09635, "text": "\n[IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL/TLS certificates](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-automatic-rotation) !", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret"}, {"document_id": "ibmcld_12493-7948-9647", "score": 17.071737, "text": "\nUse the following commands to add a static secret, such as a user credential or an arbitrary secret, to your Secrets Manager instance. Allowable values for SECRET_TYPE are: arbitrary,imported_cert, [kv](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-vault-manage-kv-cli), private_cert, public_cert, and username_password.\n\nCreate a secret in the default secret group.\n\nvault write [-format=FORMAT] ibmcloud/SECRET_TYPE/secrets name=NAME [description=\"DESCRIPTION\"] [username=USERNAME] [password=USERNAME] [payload=DATA] [expiration_date=EXPIRATION] [certificate=CERTIFICATE_DATA] [private_key=PRIVATE_KEY_DATA] [intermediate=INTERMEDIATE_CERTIFICATE_DATA] [ca=CA_CONFIGURATION_NAME] [dns=DNS_CONFIGURATION_NAME] [key_algorithm=KEY_ALGORITHM] [labels=LABEL,LABEL]\n\nCreate a secret in a specified secret group.\n\nvault write [-format=FORMAT] ibmcloud/SECRET_TYPE/secrets/groups/SECRET_GROUP_ID name=NAME [description=\"DESCRIPTION\"] [username=USERNAME] [password=USERNAME] [payload=DATA] [expiration_date=EXPIRATION] [certificate=CERTIFICATE_DATA] [private_key=PRIVATE_KEY_DATA] [intermediate=INTERMEDIATE_CERTIFICATE_DATA] [ca=CA_CONFIGURATION_NAME] [dns=DNS_CONFIGURATION_NAME] [key_algorithm=KEY_ALGORITHM] [labels=LABEL,LABEL]\n\n\n\n Prerequisites \n\nYou need the [Writer service role](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam) to create secrets.\n\n\n\n\n\n Command options \n\nname\n: The human-readable alias that you want to assign to the secret. Required.\n\ndescription\n: An extended description to assign to the secret.\n\nexpiration_date\n: The expiration date that you want to assign to the secret. Supported for the arbitrary and username_password secret types.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-vault-cli"}, {"document_id": "ibmcld_12479-7-1826", "score": 16.742048, "text": "\nAccess a storage bucket by using a dynamic secret \n\nIn this tutorial, you learn how to use IBM Cloud\u00ae Secrets Manager to create and lease an IAM credential that can be used to access a bucket in Cloud Object Storage.\n\nAs an enterprise developer, you might be looking for ways to improve the security of your application secrets. When it comes to managing API keys, you want the ability to create your credentials dynamically so that they exist only when you need them to. You also want to lease an API key to someone else on your team and ensure that it is automatically revoked after a time duration that you specify.\n\nWith Secrets Manager, you can create a\n\ndynamic secretthat you can use to access a protected resource, such as deployment logs that you store in a Cloud Object Storage bucket. For example, consider the following scenario.\n\nZoom\n\n![The diagram shows the basic flow between the Secrets Manager and Cloud Object Storage services.](https://cloud.ibm.com/docs-content/v1/content/991f60ddbe3ab0a9aa69481a07a0a73b359fa329/secrets-manager/images/iam-credential-flow.svg)\n\nFigure 1. IAM credential flow\n\n\n\n1. As an admin user, you want to create a dynamic secret that your team can use to access a Cloud Object Storage bucket in your account. You send a request to create IAM credentials in Secrets Manager.\n2. Secrets Manager creates the secret and validates it against your defined IAM access policies.\n3. Later, a developer wants to access the contents of your storage bucket. The developer sends a request to retrieve the value of your IAM credential.\n4. Secrets Manager validates the request and generates a single-use API key that the developer can use to authenticate to Cloud Object Storage. After the API key reaches the end of its lease, the API key is revoked automatically.\n\n\n\n\n\n Before you begin", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-tutorial-access-storage-bucket"}, {"document_id": "ibmcld_07578-1213887-1215935", "score": 16.526022, "text": "\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https://cloud.ibm.com/docs/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}]}
{"task_id": "5815bb4a99e2a0d8a986348da4c49083<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_12417-2921-4069", "score": 19.78232, "text": "\n6. Click Add.\n\nYou did it! The username and password are now stored in your dedicated, single-tenant instance of Secrets Manager.\n\n\n\n\n\n\n\n Step 3: Manage its lifecycle \n\nAfter you add a secret to your instance, you can establish a regular cadence for managing its lifecycle. For example, you might need to adhere to an internal requirement or regulatory control in your business for rotating secrets every 30 days.\n\n\n\n1. In the Secrets table, click the Actions menu ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/991f60ddbe3ab0a9aa69481a07a0a73b359fa329/icons/actions-icon-vertical.svg) to open a list of options for your secret.\n\n\n\n1. To view and edit details about the secret, click Edit details.\n2. To rotate the secret, click Rotate.\n3. If you no longer need the secret, click Delete.\n\n\n\n\n\n\n\n\n\n Next steps \n\nNow you can add more secrets and design a secrets management strategy to control who has access to them.\n\n\n\n* To find out more about organizing secrets, check out [Best practices for organizing secrets and assigning access](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-getting-started"}, {"document_id": "ibmcld_12384-3080-4916", "score": 19.37589, "text": "\n[User credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-user-credentials) The existing password value is replaced with a randomly generated 32-character password that contains uppercase letters, lowercase letters, digits, and symbols. The username value does not change. \n [IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials) The Service ID's API key value is replaced with a new API key. The previous API key remains available for the remaining time in the defined TTL. \n\n\n\n\n\n\n\n\n\n Scheduling automatic rotation in the UI \n\nYou can schedule the automatic rotation of secrets by using the Secrets Manager UI.\n\n\n\n Setting an automatic rotation policy for user credentials \n\nIf you prefer to schedule your passwords to be automatically rotated at regular intervals, you can enable automatic rotation for your user credentials at their creation. You can also enable auto rotation by editing the details of an existing secret.\n\nIf you need more control over the rotation frequency of a secret, you can use the Secrets Manager API to set a custom interval by using day or month units of time. For more information, see the [API reference](https://cloud.ibm.com/apidocs/secrets-manager/secrets-manager-v2put-policy).\n\n\n\n1. If you're [adding a secret](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-user-credentialsuser-credentials-ui), enable the rotation option.\n2. If you're editing an existing secret, enable automatic rotation by updating its details.\n\n\n\n1. In the Secrets table, view a list of your existing secrets.\n2. In the row for the secret that you want to edit, click the Actions menu ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/991f60ddbe3ab0a9aa69481a07a0a73b359fa329/icons/actions-icon-vertical.svg)> Edit details.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-automatic-rotation"}, {"document_id": "ibmcld_12447-3178-4817", "score": 18.986359, "text": "\nSecrets Manager sends the request to the configured certificate authority (CA), for example Let's Encrypt, to validate the ownership of your domains. If the validation completes successfully, a new certificate is issued. \n [User credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-user-credentials) Passwords that are associated with user credentials secrets are immediately replaced with the data that you provide on rotation. \n\n\n\n\n\n\n\n\n\n Creating new secret versions in the UI \n\nYou can manually rotate your secrets and certificates by using the Secrets Manager UI.\n\n\n\n Rotating arbitrary secrets \n\nYou can use the Secrets Manager UI to manually rotate your arbitrary secrets.\n\n\n\n1. In the console, click the Menu icon ![Menu icon](https://cloud.ibm.com/docs-content/v1/content/991f60ddbe3ab0a9aa69481a07a0a73b359fa329/icons/icon_hamburger.svg)> Resource List.\n2. From the list of services, select your instance of Secrets Manager.\n3. In the Secrets Manager UI, go to the Secrets list.\n4. In the row for the secret that you want to rotate, click the Actions menu ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/991f60ddbe3ab0a9aa69481a07a0a73b359fa329/icons/actions-icon-vertical.svg)> Rotate.\n5. Select a new file or enter a new secret value.\n6. Optional: Add metadata to your secret or to a specific version of your secret.\n\n\n\n1. Upload a file or enter the metadata and the version metadata in JSON format.\n\n\n\n7. To rotate the secret immediately, click Rotate.\n8. Optional: Check the version history to view the latest updates.\n\nIn the row of the secret that you rotated, click the Actions menu !", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-manual-rotation&interface=ui"}, {"document_id": "ibmcld_12348-1227-2514", "score": 18.689802, "text": "\n(https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret)[![carousel thumbnail](https://cloud.ibm.com/docs-content/v1/content/secrets-manager//images/secure-manage-secrets-video-thumbnail.png)<br><br>Securely managing your cloud secrets with Secrets Manager](https://www.youtube.com/watch?v=rOp7aGyavnk)\n\n Latest updates \n\n[View more](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-release-notes)17 April 2023 | Now available: new API and CLI versions\n\nThe new API, SDK, Terraform, and CLI versions offer more options to manage your Secrets Manager instance. The Secrets Manager API v1 has been deprecated in favor of v2.\n\n3 March 2023 | Now available: Terraform support\n\nSecrets Manager now supports Terraform.\n\n11 December 2022 | Support for context-based restrictions (CBR)\n\nManage user and service access to your Secrets Manager resources by using context-based restrictions.\n\n14 November 2022 | Manually configure your own DNS provider\n\nYour DNS provider isn't integrated with the service? You can now manually configure it by using the UI.\n\n18 October 2022 | Add custom metadata to your secret versions and auto-rotate IAM credentials\n\nDo you need more space to log details about your secret versions? Add relevant information as metadata.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager"}, {"document_id": "ibmcld_12491-1364-3085", "score": 18.652699, "text": "\nFrom the list of services, select your instance of Secrets Manager.\n3. In the Secrets table, click Add.\n4. From the list of secret types, select the User credentials tile.\n5. Click Next.\n6. Add a name and description to easily identify your secret.\n7. Select the\n\nsecret groupthat you want to assign to the secret.\n\nDon't have a secret group? In the Secret group field, you can click Create to provide a name and a description for a new group. Your secret is added to the new group automatically. For more information about secret groups, check out [Organizing your secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-secret-groups).\n8. Optional: Add labels to help you to search for similar secrets in your instance.\n9. Optional: Add metadata to your secret or to a specific version of your secret.\n\n\n\n1. Upload a file or enter the metadata and the version metadata in JSON format.\n\n\n\n10. Click Next.\n11. Enter the username and password that you want to associate with the secret.\n12. Optional: Enable expiration and rotation options to control the lifespan of the secret.\n\n\n\n1. To set an expiration date for the secret, switch the expiration toggle to Yes.\n2. To rotate your secret at a 30, 60, or 90-day interval, switch the Automatic secret rotation toggle to Yes.\n\n\n\n13. Click Next.\n14. Review the details of your secret.\n15. Click Add.\n\n\n\n\n\n\n\n Adding user credentials from the CLI \n\nTo store a username and password by using the Secrets Manager CLI plug-in, run the [ibmcloud secrets-manager secret-create](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-cli-plugin-secrets-manager-clisecrets-manager-cli-secret-create-command) command.\n\nibmcloud secrets-manager secret-create", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-user-credentials"}, {"document_id": "ibmcld_12491-3915-5501", "score": 18.586702, "text": "\nAdding user credentials with the API \n\nYou can store a username and password programmatically by calling the Secrets Manager API.\n\nThe following example shows a query that you can use to create a username and password secret. When you call the API, replace the ID variables and IAM token with the values that are specific to your Secrets Manager instance.\n\nYou can store metadata that are relevant to the needs of your organization with the custom_metadata and version_custom_metadata request parameters. Values of the version_custom_metadata are returned only for the versions of a secret. The custom metadata of your secret is stored as all other metadata, for up to 50 versions, and you must not include confidential data.\n\ncurl -X POST\n-H \"Authorization: Bearer {IAM_token}\" -H \"Accept: application/json\" -H \"Content-Type: application/json\" -d '{\n\"name\": \"example-username-password-secret\",\n\"description\": \"Description of my user credentials secret\",\n\"secret_type\": \"username_password\",\n\"secret_group_id\": \"bfc0a4a9-3d58-4fda-945b-76756af516aa\",\n\"labels\": [\n\"dev\",\n\"us-south\"\n],\n\"username\": \"example-username\",\n\"password\": \"example-password\",\n\"rotation\": {\n\"auto_rotate\": true,\n\"interval\": 10,\n\"unit\": \"day\"\n},\n\"custom_metadata\": {\n\"metadata_custom_key\": \"metadata_custom_value\"\n},\n\"version_custom_metadata\": {\n\"custom_version_key\": \"custom_version_value\"\n}\n}'\n\"https://{instance_ID}.{region}.secrets-manager.appdomain.cloud/api/v2/secrets\"\n\n\n\n\n\n Adding user credentials with Terraform \n\nYou can store a username and password programmatically by using Terraform for Secrets Manager.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-user-credentials"}, {"document_id": "ibmcld_12467-3399-5495", "score": 18.585566, "text": "\nRotation is allowed only after all locks on the previous secret version are removed.\n\n\n\n\n\n Creating locks in the UI \n\nYou can create up to 1000 locks on a secret by using the Secrets Manager UI. Each lock can be used to represent a single application or service that uses your secret.\n\nA secret is considered locked after you attach one or more locks to it. A lock can be applied only on a secret version that contains active payload, or secret data.\n\nTo help you to create a new lock and remove older locks in a single operation, you can also specify an optional mode at lock creation.\n\n\n\nTable 1. Optional lock modes and their descriptions\n\n Mode Description \n\n Remove previous locks Removes any other locks that match the name that you specify. If any matching locks are found in the previous version of the secret, those locks are deleted when your new lock is created.<br><br>For example, suppose that the previous version of your secret contains a lock lock-x. Creating a lock on the current version of your secret and enabling the Delete matching locks option results in removing lock-x from the previous version. \n Remve previous locks and delete previous version data Same as the previous option, but also permanently deletes the data of the previous secret version if it doesn't have any locks that are associated with it.<br><br>Suppose that the previous version of your secret contains a lock lock-z. Creating a lock on the current version of your secret with both the Delete matching locks and Delete previous version data options results in removing lock-z from the previous version. Additionally, because the previous version doesn't have any other locks that are attached to it, the secret data that is associated with the previous version is also deleted. \n\n\n\n\n\n Creating a lock on the current secret version \n\nYou can lock the current version of a secret by using the Secrets Manager UI. A successful request attaches a new lock to the current version of your selected secret, or replaces a lock of the same name if it already exists.\n\n\n\n1. In the console, click the Menu icon !", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-secret-locks"}, {"document_id": "ibmcld_12384-4-1975", "score": 18.384802, "text": "\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Automatically rotating secrets \n\nYou can schedule automatic rotation for secrets by using IBM Cloud\u00ae Secrets Manager.\n\nWhen you rotate a secret in your service instance, you create a new version of its value. By scheduling automatic rotation of your secrets at regular intervals, you can reduce the likelihood of compromise and ensure that your credentials never expire.\n\nAutomatic rotation is available only for secrets that are generated by Secrets Manager. If the secret was imported initially, you must provide new secret data to rotate it. For more information, see [Manually rotating secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-manual-rotation).\n\n\n\n Before you begin \n\nBefore you get started, be sure that you have the required level of access. To rotate secrets, you need the [Writer service role or higher](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam).\n\n\n\n Supported secret types \n\nAutomatic rotation is supported for [private certificates](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificatescreate-certificates), [public certificates](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificatesorder-certificates), [user credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-user-credentials) and [IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials). Depending on the type of secret, automatic rotation takes place immediately on the date and time that you set, or it might need to complete a few extra steps before a new version of the secret can be created.\n\n\n\nTable 1. Describes how Secrets Manager evaluates manual rotation by secret type\n\n Type Rotation description \n\n [Private certificates](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificatescreate-certificates) The existing certificate value is replaced with new certificate content.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-automatic-rotation"}, {"document_id": "ibmcld_12492-76358-77657", "score": 18.370419, "text": "\n\"secret_id\": \"184408d6-8264-5ff3-c308-6922ed04ad88\",\n\"versions\": [\n{\n\"alias\": \"current\",\n\"id\": \"f2b68dbb-c291-87df-6026-7611c324c823\",\n\"locks\":\n\"lock-for-app-1\"\n],\n\"payload_available\": true\n}\n]\n},\n\"wrap_info\": null,\n\"warnings\": null,\n\"auth\": null\n}\n\n\n\n\n\n\n\n\n\n Policies \n\n\n\n Set secret policies \n\nCreates or updates an [automatic rotation policy](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-automatic-rotation) for a secret. Supported secret types include: username_password\n\n\n\nTable 9. Set secret policy request parameters\n\n Request parameters Description \n\n interval The length of the secret rotation time interval. \n unit The units for the secret rotation time interval. Allowable values are: day, month \n\n\n\n\n\n Example request \n\nSet a rotation policy on an username_password secret in the default secret group.\n\ncurl -X PUT \"https://{instance_id}.{region}.secrets-manager.appdomain.cloud/v1/ibmcloud/arbitrary/secrets/{secret_id}/policies\" -H 'X-Vault-Token: {Vault-Token}' -H 'Content-Type: application/json' --data-raw '{\n\"policies\": [\n{\n\"rotation\": {\n\"interval\": 10,\n\"unit\": \"day\"\n},\n\"type\": \"application/vnd.ibm.secrets-manager.secret.policy+json\"\n}\n]\n}'\n\nSet a rotation policy on a username_password secret in an existing secret group.\n\ncurl -X PUT \"https://{instance_id}.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-vault-api"}, {"document_id": "ibmcld_12492-51531-52986", "score": 18.349564, "text": "\nTo set an automatic rotation policy for a secret, see [Set secret policies](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-vault-apivault-set-secret-policies).\n\n\n\nTable 8. Rotate secret request parameters\n\n Request parameters Description \n\n payload The new secret data to assign to an arbitrary or a kv secret. \n password The new password to assign to a username_password secret. \n certificate The new certificate to assign to an imported_cert secret. \n private_key The new private key to assign to an imported_cert secret. \n intermediate The new intermediate certificate data to assign to an import_cert secret. \n\n\n\n\n\n Example requests \n\nRotate an arbitrary secret in the default secret group.\n\ncurl -X POST \"https://{instance_id}.{region}.secrets-manager.appdomain.cloud/v1/ibmcloud/arbitrary/secrets/{secret_id}/rotate\" -H 'Accept: application/json' -H 'X-Vault-Token: {Vault-Token}' -d '{\n\"payload\": \"new-secret-data\"\n}'\n\nRotate an arbitrary secret in an existing secret group.\n\ncurl -X POST \"https://{instance_id}.{region}.secrets-manager.appdomain.cloud/v1/ibmcloud/arbitrary/secrets/groups/{group_id}/{secret_id}/rotate\" -H 'Accept: application/json' -H 'X-Vault-Token: {Vault-Token}' -d '{\n\"payload\": \"new-secret-data\"\n}'\n\nRotate a kv secret in the default secret group. [Learn more](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-vault-manage-kv&interface=apioverview-kv).\n\ncurl -X POST 'https://{instance_id}.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-vault-api"}]}
{"task_id": "5815bb4a99e2a0d8a986348da4c49083<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00060-3531-4494", "score": 23.813492, "text": "\n\"name\": \"serverless-instance\",\n\"region_id\": \"us-south\",\n\"account_id\": \"d628eae2ccxxxx3bb0c9dxxxx\",\n\"reseller_channel_id\": \"\",\n\"resource_plan_id\": \"8afxxxx-xxxx-xxxx-xxxx-946d843xxxx\",\n\"resource_group_id\": \"65828fxxxx594594816exxx\",\n\"resource_group_crn\": \"crn:v1:staging:public:resource-controller::a/d628eae2ccxxxx3bb0c9dxxxx::resource-group:65828fxxxx594594816exxx\",\n\"target_crn\": \"crn:v1:staging:public:globalcatalog::::deployment:8afxxxx-xxxx-xxxx-xxxx-946d843xxxx%3Aus-south\",\n\"parameters\": {\n\"default_config\": {\n\"spark.driver.cores\": \"1\",\n\"spark.driver.memory\": \"512m\",\n\"spark.executor.cores\": \"1\",\n\"spark.executor.instances\": \"1\"\n},\n\"default_runtime\": {\n\"additional_packages\": \"parquet-modular-encryption\"],\n\"spark_version\": \"3.0.0\"\n},\n\"instance_home\": {\n\"endpoint\": \"s3.direct.us-south.cloud-object-storage.appdomain.cloud\",\n\"guid\": \"902xxxx-xxxx-xxxx-xxxx-4127da8xxxx\",\n\"hmac_access_key\": \"xxxxxxxxx\",\n\"hmac_secret_key\": \"xxxxxxxx\",\n\"provider\": \"ibm-cos\",", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-retrieve-instance-details"}, {"document_id": "ibmcld_00052-7-2119", "score": 23.194155, "text": "\nManaging serverless instances using the IBM Cloud console \n\nYou can manage your severless instance by:\n\n\n\n* Changing configuration settings, for example, to include library add-ons or to configure instance home after you created the instance.\n* Monitoring the status of submitted applications and kernels created in the instance.\n\n\n\n\n\n Console configuration tab \n\nYou can view and edit the current configuration settings for your IBM Analytics Engine serverless instance from the IBM Cloud\u00ae Resource list.\n\n\n\n1. Access the [IBM Cloud\u00ae Resource list](https://test.cloud.ibm.com/resources).\n2. Click Services and software, find your IBM Analytics Engine serverless instance and click the instance to see the details.\n3. Click Manage > Configuration to view:\n\n\n\n* The runtime. Currently, you can only select the Default Spark runtime which includes the geospatial, data skipping and Parquet encryption packages.\n* The instance home volume to add an instance home or change the access credentials of an existing instance home\n\n\n\n* You can set instance home after you created your IBM Analytics Engine serverless instance. Instance home must be associated with an IBM Cloud Object Storage instance. You can choose an instance:\n\n\n\n* In your account by selecting it from the list\n* From another account. For this instance, you need to enter:\n\n\n\n* The GUID of the IBM Cloud Object Storage instance\n* The endpoint\n* The region\n* The HMAC access and secret key\n\n\n\n\n\n* You can change the access credentials of an existing instance home volume. For this instance, you need to enter:\n\n\n\n* The new HMAC access and secret key\n\n\n\n\n\nFor details on how to access Object Storage, see [Using IBM Object Storage as the instance home volume](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-cos-serverless).\n* The default Spark configuration options to override configuration settings.\n\nFor a list of the default Spark configurations set for serverless instances, see [Default Spark configurations](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-conceptsdefault-spark-config).", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-manage-serverless-console"}, {"document_id": "ibmcld_00055-8836-9818", "score": 23.149483, "text": "\ncurl -X GET https://api.us-south.ae.cloud.ibm.com/v3/analytics_engines/{instance_id} -H \"Authorization: Bearer $token\"\n\nSample response:\n\n{\n\"id\": \"dc0e-eab2-4t9e-9441-56620949\",\n\"state\": \"created\",\n\"state_change_time\": \"2021-04-21T04:24:01Z\",\n\"default_runtime\": {\n\"spark_version\": \"3.1\",\n\"instance_home\": {\n\"provider\": \"ibm-cos\",\n\"type\": \"objectstore\",\n\"region\": \"us-south\",\n\"endpoint\": \"https://s3.direct.us-south.cloud-object-storage.appdomain.cloud\",\n\"bucket\": \"ae-bucket-do-not-delete-dc0e-eab2-4t-9441-566209499546\",\n\"hmac_access_key\": \"eHg=\",\n\"hmac_secret_key\": \"4d76\"\n},\n\"default_config\": {\n\"spark.driver.memory\": \"4g\",\n\"spark.driver.cores\": 1\n}\n}\n}\nShow more\n2. Check the value of the \"state\" attribute. It must be active before you can start running applications in the instance.\n\n\n\n\n\n\n\n Learn more \n\nWhen provisioning serverless instances, follow the recommended [Best practices](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-best-practices-serverless).", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless"}, {"document_id": "ibmcld_00064-7-2200", "score": 23.129223, "text": "\nArchitecture and concepts in serverless instances \n\nThis topic shows you the architecture of IBM Analytics Engine serverless instances and describes some key concepts and definitions.\n\n\n\n Instance architecture \n\nThe IBM Analytics Engine service is managed by using IBM Cloud\u00ae Identity and Access Management (IAM). As an IBM Cloud account owner, you are assigned the account administrator role.\n\nWith an IBM Cloud account, you can provision and manage your serverless Analytics Engine instance by using the:\n\n\n\n* IBM Cloud console\n* CLI\n* REST API\n\n\n\nThe Analytics Engine microservices in the control plane, accessed through an API gateway handle instance creation, capacity provisioning, customization and runtime management while your Spark applications run in isolated namespaces in the data plane. Each Spark application that you submit runs in its own Spark cluster, which is a combination of Spark master and executor nodes. See [Isolation and network access](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-security-model-serverlessisolation-network-access).\n\nEach Analytics Engine instance is associated with an IBM Cloud Object Storage instance for instance related data that is accessible by all applications that run in the instance. Currently, all Spark events are stored in this instance as well. Spark application logs are aggregated to a Log Analysis log server.\n\nZoom\n\n![Shows the IBM Analytics Engine serverless instance architecture.](https://cloud.ibm.com/docs-content/v1/content/cd4be197c8921ed12923aa899ac93a8ab643c158/AnalyticsEngine/images/AE-serverless-architecture.svg)\n\nFigure 1. Architecture flow diagram of IBM Analytics Engine\n\n\n\n\n\n Key concepts \n\nWith IBM Analytics Engine serverless instances, you can spin up Apache Spark clusters as needed and customize the Spark runtime and default Spark configuration options.\n\nThe following sections describe key concepts when provisioning serverless instances.\n\n\n\n IBM Analytics Engine service instance \n\nAn IBM Cloud\u00ae service is cloud extension that provides ready-for-use functionality, such as database, messaging, and web software for running code, or application management or monitoring capabilities.", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts"}, {"document_id": "ibmcld_00060-7-1693", "score": 22.999216, "text": "\nRetrieving details of a serverless instance \n\nYou can retrieve information, like the instance ID (or GUID) and the provisioning state of an IBM Analytics Engine serverless instance from the instance details. You need the instance ID to use the Spark application REST API and the Livy batch APIs.\n\nYou can retrieve the details by:\n\n\n\n* [Using the IBM Cloud CLI](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-retrieve-instance-detailsretrieve-guid-cli)\n* [Using the IBM Cloud REST API](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-retrieve-instance-detailsretrieve-guid-api)\n\n\n\n\n\n Accessing instance details by using the IBM Cloud CLI \n\nTo get the details of an instance:\n\n\n\n1. List all of the created serverless instances:\n\n$ ibmcloud resource service-instances --service-name ibmanalyticsengine\n\nThis call retrieves the instances of type service_instance in all resource groups in all locations for your account.\n\nExample response:\n\nName Location State Type Resource Group ID\nserverless-instance us-south active service_instance 65xxxxxxxxxxxxxxxa3fd\n2. Enter the following command with the server instance name of your instance to view the instance details:\n\n$ ibmcloud resource service-instance \"Analytics Engine-xyz\"\n\nThis retrieves your instance from the resource groups under your account.\n\nExample response:\n\nName: Analytics Engine-xyz\nID:\ncrn:v1:staging:public:ibmanalyticsengine:us-south:a/XXXXX:XXXXX::\nGUID: XXXXX\nLocation: us-south\nService Name: ibmanalyticsengine\nService Plan Name: standard-serverless-spark\nResource Group Name: Default\nState: active\nType: service_instance\nSub Type:\nCreated at: 2021-01-06T07:49:12Z\nCreated by: XXXXX", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-retrieve-instance-details"}, {"document_id": "ibmcld_00007-1713-3490", "score": 22.961, "text": "\nSee [Serverless instance architecture and concepts](https://cloud.ibm.com/docs/analyticsengine?-serverless-architecture-concepts).\n2. [Provision a serverless instance](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless)\n\n\n\n\n\n\n\n Run applications \n\nTo run Spark applications in a serverless IBM Analytics Engine instance:\n\n\n\n1. Optionally, give users access to the provisioned instance to enable collaboration. See [Managing user access to share instances](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n2. Optionally, customize the instance to fit the requirements of your applications. See [Customizing the instance](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-cust-instance).\n3. Submit your Spark application by using the Spark application REST API. See [Running Spark batch applications](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-spark-batch-serverless).\n4. Submit your Spark application by using the Livy batch API. See [Running Spark batch applications using the Livy API](https://cloud.ibm.com/docs/analyticsengine?topic=AnalyticsEngine-livy-api-serverless).\n\n\n\n\n\n\n\n End-to-end scenario using the Analytics Engine serverless CLI \n\nTo help you get started quickly and simply with provisioning an Analytics Engine instance and submitting Spark applications, you can use the Analytics Engine serverless CLI.\n\nFor an end-to-end scenario of the steps you need to take, from creating the services that are required, to submitting and managing your Spark applications by using the Analytics Engine CLI, see [Create service instances and submit applications using the CLI](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-using-cli).", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine"}, {"document_id": "ibmcld_00020-7-2287", "score": 22.950176, "text": "\nBest practices \n\nUse the following set of recommended guidelines when provisioning and managing your serverless instances and when running Spark applications.\n\n\n\nTable 1. Best practices when using serverless instances including detailed descriptions and reference links\n\n Best Practice Description Reference Link \n\n Use separate IBM Analytics Engine service instances for your development and production environments. This is a general best practice. By creating separate IBM Analytics Engine instances for different environments, you can test any configuration and code changes before applying them on the production instance. NA \n Upgrade to the latest Spark version As open source Spark versions are released, they are made available in IBM Analytics Engine after a time interval required for internal testing. Watch out for the announcement of a new Spark versions in the Release Notes section and upgrade the runtime of your instance to move your applications to latest Spark runtime. Older runtimes are be deprecated and eventually removed as newer versions are released. Make sure you test your applications on the new runtime before making changes on the production instances. <br><br> * [Release notes for IBM Analytics Engine serverless instances](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-iae-serverless-relnotes)<br><br><br> \n Grant role-based access You should grant role-based access to all users on the IBM Analytics Engine instances based on their requirements. For example, only your automation team should have permissions to submit applications because it has access to secrets and your DevOps team should only be able to see the list of all applications and their states. <br><br> * [Granting permissions to users](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless)<br><br><br> \n Choose the right IBM Cloud Object Storage configuration <br><br> * Disaster Recovery (DR) Resiliency: You should use the IBM Cloud Object Storage Cross Regional resiliency option that backs up your data across several different cities in a region. In contrast, the Regional resiliency option back ups data in a single data center.<br> * Encryption: IBM Cloud Object Storage comes with default built-in encryption.", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-best-practices-serverless"}, {"document_id": "ibmcld_00055-7-1864", "score": 22.689651, "text": "\nProvisioning an IBM Analytics Engine serverless instance \n\nYou can create a serverless IBM Analytics Engine service instance:\n\n\n\n* [Using the IBM Cloud console](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverlessconsole-provisioning)\n* [Using the IBM Cloud command-line interface](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverlesscli-provisioning)\n* [Using the Resource Controller REST API](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverlessrest-api-provisioning)\n\n\n\nNote that you are not able to define certain limitation and quota settings while provisioning a serverless instance. These values are predefined. See [Limits and quotas for Analytics Engine instances](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-limits) for a list of these settings and their values.\n\nYou must have access to either the IBM Cloud\u00ae us-south (Dallas) or the eu-de (Frankurt) region.\n\n\n\n Creating a service instance from the IBM Cloud console \n\nYou can create an instance using the IBM Cloud console. To understand the concepts behind provisioning settings in the UI, see [Architecture and concepts in serverless instances](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts).\n\nTo create an IBM Analytics Engine instance:\n\n\n\n1. Log into the [IBM Cloud\u00ae console](https://cloud.ibm.com/catalog).\n2. Click Sevices and select the category Analytics.\n3. Search for Analytics Engine and then click on the tile to open the service instance creation page.\n4. Choose the location in which you want the service instance to be deployed. Currently, us-south and eu-de are the only supported regions.\n5. Select a plan. Currently, Standard Serverless for Apache Spark is the only supported serverless plan.\n6.", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless"}, {"document_id": "ibmcld_13159-4121-5777", "score": 22.66115, "text": "\nLeave Container image selected and use icr.io/solution-tutorials/tutorial-serverless-api-webapp:latest as Image reference. It uses an already existing container image.\n4. Go to and expand the section Runtime settings. Increase the Min number of instances to 1 and reduce Max number of instances to 2. The minimum of one makes the app more responsive during the initial tests. You could reduce it later to zero again.\n5. Under Instance resources, select 0.25 vCPU / 0.5 GB for CPU and memory. Not much of resources is needed for this type of app.\n6. Click Create to deploy the new backend app for the guestbook.\n7. Create a service binding to the database.\n\n\n\n1. Click Service bindings tab.\n2. Click Create.\n3. Click IBM Cloud service instance and choose your database from the drop down.\n4. Click Add.\n\n\n\n8. Wait for the provioning to report as green and ready. Click on Test application, then on Application URL. The backend app should load and return a page saying healthy. Remember or copy the application URL because it is needed for the next part.\n\n\n\nInstead of using the pre-built container image, you could build the image on your own. This can be done either outside of or [with the help of Code Engine](https://cloud.ibm.com/docs/codeengine?topic=codeengine-plan-build). If not using the pre-built container image and if [using a private container registry additional steps might be needed](https://cloud.ibm.com/docs/codeengine?topic=codeengine-deploy-app-private). You can find the source at [https://github.com/IBM-Cloud/serverless-guestbook/tree/ce](https://github.com/IBM-Cloud/serverless-guestbook/tree/ce)\n\n\n\n\n\n\n\n Step 3: Deploy the web app", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-serverless-webapp"}, {"document_id": "ibmcld_00055-4234-5526", "score": 22.513464, "text": "\nSee [Architecture and concepts in serverless instances](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts) for a description of the provisioning parameters in the payload.\n\nNote that both Spark 3.1 and Spark 3.3 are supported. If you don't specify a default Spark runtime version when you create a service instance, Spark 3.1 is taken by default.\n\n{\n\"default_runtime\": {\n\"spark_version\": \"3.1\"\n},\n\"instance_home\": {\n\"region\": \"us-south\",\n\"endpoint\": \"https://s3.direct.us-south.cloud-object-storage.appdomain.cloud\",\n\"hmac_access_key\": \"<your-hmac-access-key\",\n\"hmac_secret_key\": \"<your-hmac-secret-key\"\n},\n\"default_config\": {\n\"key1\": \"value1\",\n\"key2\": \"value2\"\n}\n}\n\nThe IBM Cloud\u00ae response to the create instance command:\n\nCreating service instance MyServiceInstance in resource group Default of account <your account name> as <your user name>...\nOK\nService instance MyServiceInstance was created.\n\nName: MyServiceInstance\nID: crn:v1:staging:public:ibmanalyticsengine:us-south:a/d628eae2cc7e4373bb0c9d2229f2ece5:1e32e-afd9-483a-b1-724ba5cf4::\nGUID: 1e32e-afd9-483a-b1-724ba5cf4\nLocation: us-south\nState: provisioning\nType: service_instance\nSub Type:\nService Endpoints: public\nAllow Cleanup: false\nLocked: false\nCreated at: 2021-11-29T07:20:40Z", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless"}]}
{"task_id": "5815bb4a99e2a0d8a986348da4c49083<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00083-7-1689", "score": 13.75582, "text": "\nStandard Spark examples \n\nYou can use the following code samples to learn how to use Spark in different situations.\n\nTo understand how to access Object Storage, see [Understanding the Object Storage credentials](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-cos-credentials-in-iae-serverless).\n\n\n\n Reading a CSV file from Object Storage using already stated credentials \n\nThe following code samples show you how to create a Python script that reads data from a CSV file to a Python DataFrame. Both the Python script and the CSV file are located in Object Storage.\n\nYou can use the same IBM Cloud Object Storage credentials that you specified at the time you submitted the Spark application or that were set as a default configuration when you created the IBM Analytics Engine service instance to read from Object Storage within the application.\n\nExample of the application called read-employees.py. Insert the Object Storage bucket name and service name. The service name is any name given to your Object Storage instance:\n\nfrom pyspark.sql import SparkSession\n\ndef init_spark():\nspark = SparkSession.builder.appName(\"read-write-cos-test\").getOrCreate()\nsc = spark.sparkContext\nreturn spark,sc\n\ndef read_employees(spark,sc):\nprint(\"Hello 1\" , spark )\nemployeesDF = spark.read.option(\"header\",True).csv(\"cos://cosbucketname.cosservicename/employees.csv\")\nprint(\"Hello 2\" , employeesDF)\nemployeesDF.createOrReplaceTempView(\"empTable\")\nseniors = spark.sql(\"SELECT empTable.NAME FROM empTable WHERE empTable.BAND >= 6\")\nprint(\"Hello 3\", seniors)\nseniors.show()\n\ndef main():\nspark,sc = init_spark()\nread_employees(spark,sc)\n\nif __name__ == '__main__':\nmain()\nShow more", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-spark-batch-examples"}, {"document_id": "ibmcld_13481-1627-2985", "score": 12.368733, "text": "\nDisplay your tables and run an SQL statement:\n\nspark.sql('show tables').show(truncate=False)\n\n replace yourTable with a valid table. Do not use the sample tables as you do not have access to the data!\nspark.sql('select * from yourTable').show()\n\n\n\n\n\n Usage with IBM Analytics Engine \n\nThe Hive metastore client is also already included in IBM\u00ae Analytics Engine. It also includes the convenience library to configure the connection to the Hive metastore. The following example shows a Spark batch job for a show tables example in Python:\n\nimport sys\nfrom dataengine import SparkSessionWithDataengine\n\nif __name__ == '__main__':\ncrn = sys.argv[1]\napikey = sys.argv[2]\n\nprint(\" Start SparkSessionWithDataengine example\")\nsession_builder = SparkSessionWithDataengine.enableDataengine(crn, apikey, \"public\")\n\nprint(\" Setup IBM Cloud Object Storage access\")\nspark = session_builder.appName(\"AnalyticEngine DataEngine integration\") \n.config(\"fs.cos.impl\", \"com.ibm.stocator.fs.ObjectStoreFileSystem\") \n.config(\"fs.stocator.scheme.list\", \"cos\") \n.config(\"fs.stocator.cos.impl\", \"com.ibm.stocator.fs.cos.COSAPIClient\") \n.getOrCreate()\n\nprint(\" Got a spark session, listing all tables\")\nspark.sql('show tables').show()\n\nspark.stop()\nShow more\n\nPrepare a JSON file to start that program, as in the following example (listTablesExample.json):\n\n{\n\"application_details\": {", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastore"}, {"document_id": "ibmcld_16661-2743-3994", "score": 12.203765, "text": "\nspark = SparkSession.builder .appName(\"lh-hms-cloud\") .config(\"spark.hadoop.fs.s3a.bucket.lakehouse-bucket.endpoint\" ,\"s3.direct.us-south.cloud-object-storage.appdomain.cloud\") .config(\"spark.hadoop.fs.s3a.bucket.lakehouse-bucket.access.key\" ,\"<access-key-for-source-bucket>\") .config(\"spark.hadoop.fs.s3a.bucket.lakehouse-bucket.secret.key\" ,\"<secret-key-for-source-bucket>\") .config(\"spark.hadoop.fs.s3a.bucket.source-bucket.endpoint\" ,\"s3.direct.us-south.cloud-object-storage.appdomain.cloud\") .config(\"spark.hadoop.fs.s3a.bucket.source-bucket.access.key\" ,\"<access-key-for-lakehous-bucket>\") .config(\"spark.hadoop.fs.s3a.bucket.source-bucket.secret.key\" ,\"<secret-key-for-lakehouse-bucket>\") .enableHiveSupport() .getOrCreate()\n\nreturn spark\n\ndef main():\ntry:\nspark = init_spark()\n Create a database in lakehouse catalog\nspark.sql(\"create database if not exists lakehouse.demodb LOCATION 's3a://lakehouse-bucket/'\")\n list the database under lakehouse catalog\nspark.sql(\"show databases from lakehouse\").show()\n\n demonstration: Create a basic Iceberg table, insert some data and then query table\nspark.sql(\"create table if not exists lakehouse.demodb.testTable(id INTEGER, name VARCHAR(10), age INTEGER, salary DECIMAL(10, 2)) using iceberg\").show()", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-run_samp_file"}, {"document_id": "ibmcld_13118-24929-26231", "score": 12.202605, "text": "\n$service'.secret.key\": \"'$secret_access_key'\"\n}'\n\nAgain verify the results in the platform log.\n\nThe final step is to submit the spark application that accesses the data in the same bucket. Create a file, solution.py, with the following contents and upload it to the bucket. Notice the COS_PARQUET environment variable that will be initialized in the next step.\n\nsolution.py:\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import SQLContext\nimport os\nimport sys\n\ndef main():\n COS_PARQUET in format: cos://<bucket>.<service>/landing_folder/topic=<topic>/jobid=<jobid>/\n like cos://ABC-log-analysis.solution/logs-stream-landing/topic=webserver/jobid=48914a16-1d33-4d3e-93e3-7efb855b662e/\nprint(\"solution v1.0\")\nif \"COS_PARQUET\" not in os.environ:\nprint(\"COS_PARQUET must be in environment\")\nreturn 1\ncos_parquet = os.environ[\"COS_PARQUET\"]\nprint(f\"cos_parquet: {cos_parquet}\")\n\nspark = SparkSession.builder.appName(\"solution\").getOrCreate()\nsc = spark.sparkContext\nsqlContext = SQLContext(sc)\n\ndf = spark.read.parquet(cos_parquet)\nsqlContext.registerDataFrameAsTable(df, \"Table\")\ndf_query = sqlContext.sql(\"SELECT * FROM Table LIMIT 10\")\ndf_query.show(10)\nreturn 0\n\nif __name__ == '__main__':\nsys.exit(main())\nShow more\n\nNow submit the spark application that accesses the data in the same bucket.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-big-data-log-analytics"}, {"document_id": "ibmcld_13481-7-1988", "score": 12.099622, "text": "\nConnecting Apache Spark with Data Engine \n\nIBM Cloud\u00ae Data Engine catalog provides an interface that is compatible with Apache Hive metastore. This unified metadata repository enables any Big Data engine, such as Apache Spark, to use Data Engine as metastore. The same definition for tables and views can be created once and used from any connected engine. Each instance of Data Engine exports its catalog as a database called default.\n\n\n\n Catalog usage within Data Engine \n\nThe Catalog can be used in Data Engine in read and write mode. Seamless access is configured without any configuration steps needed.\n\n\n\n\n\n Connecting Apache Spark with Data Engine \n\nWhen you use the Hive metastore compatible interface, access is limited to read only operations. Thus, existing tables and views can be used, but not modified.\n\nDepending from where you want to connect to your catalog, the steps may vary.\n\n\n\n Usage within Watson Studio Notebooks \n\nWatson Studio has the compatible Hive metastore client already included. It also includes a convenience library to configure the connection to the Hive metastore. Set the required variables (CRN and apikey) and call the helper function to connect to the Hive metastore:\n\n change the CRN and the APIkey according to your instance\ncrn='yourDataengineCRN'\napikey='yourAPIkey'\n\nfrom dataengine import SparkSessionWithDataengine\n\n call the helper function to create a session builder equipped with the correct config\nsession_builder = SparkSessionWithDataengine.enableDataengine(crn, apikey, \"public\")\nspark = session_builder.appName(\"Spark DataEngine integration test\").getOrCreate()\n\nDisplay your tables and run an SQL statement:\n\nspark.sql('show tables').show(truncate=False)\n\n replace yourTable with a valid table. Do not use the sample tables as you do not have access to the data!\nspark.sql('select * from yourTable').show()\n\n\n\n\n\n Usage with IBM Analytics Engine \n\nThe Hive metastore client is also already included in IBM\u00ae Analytics Engine.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastore"}, {"document_id": "ibmcld_00029-6261-7679", "score": 11.892066, "text": "\n\"spark.hadoop.fs.cos.ALIAS NAME.endpoint\": \"CHANGEME\",\n\"spark.hadoop.fs.cos.ALIAS NAME.access.key\": \"CHANGEME\",\n\"spark.hadoop.fs.cos.ALIAS NAME.secret.key\": \"CHANGEME\"\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0},\n\u00a0 \"application\": \"cos://mybucket.ALIAS NAME/create_table_data_engine.py\",\n\u00a0 \"arguments\": [\"<CHANGEME-CRN-DATA-ENGINE-INSTANCE>\",\"<APIKEY-WITH-ACCESS-TO-DATA-ENGINE-INSTANCE>\"]\n\u00a0\u00a0\u00a0\u00a0}\n}\n\nParameter values:\n\nALIAS NAME: specify the data engine endpoint for your region. For more information on the currently supported data engine endpoints, see [Data engine endpoints](https://cloud.ibm.com/docs/sql-query?topic=sql-query-overviewendpoints).\n\nMake sure that you select the standard aliases.\n{: important}\nShow more\n\n\n\n\n\n\n\n Reading data from table by passing full list of Data Engine parameters \n\nYou can read the data from the metastore table using the SQL querry.\n\nRead the data from the table by using the Spark SQL in the following application called select_query_data_engine.py:\n\nfrom pyspark.sql import SparkSession\nimport time\n\ndef init_spark():\nspark = SparkSession.builder.appName(\"dataengine-table-select-test\").getOrCreate()\nsc = spark.sparkContext\nreturn spark,sc\n\ndef select_query_data_engine(spark,sc):\ntablesDF=spark.sql(\"SHOW TABLES\")\ntablesDF.show()\nstatesDF=spark.sql(\"SELECT * from COUNTRIESCAPITALS\");\nstatesDF.show()\n\ndef main():\nspark,sc = init_spark()\nselect_query_data_engine(spark,sc)\n\nif __name__ == '__main__':\nmain()", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"}, {"document_id": "ibmcld_00096-10596-12360", "score": 11.860267, "text": "\n\"state\": \"active\",\n\"state_change_time\": \"\"\n}\n\nOnly submit your Spark application when the state of the Analytics Engine service is active.\n\n\n\n\n\n\n\n Step 3: Upload and submit a Spark application \n\nUpload an application file to Cloud Object Storage and submit a Spark application.\n\nThis tutorial shows you how to add the Spark application to the Cloud Object Storage instance bucket that is used as instance home by the Analytics Engine instance. If you want to separate the instance related files from the files you use to run your applications, for example the applications files themselves, data files, and any results of your analysis, you can use a different bucket in the same Cloud Object Storage instance or use a different Cloud Object Storage instance.\n\n\n\n1. Upload the Spark application file:\n\nAction\n: Enter:\n\nibmcloud cos upload --bucket BUCKET_NAME --key KEY --file PATH [--concurrency VALUE] [--max-upload-parts PARTS] [--part-size SIZE] [--leave-parts-on-errors] [--cache-control CACHING_DIRECTIVES] [--content-disposition DIRECTIVES] [--content-encoding CONTENT_ENCODING] [--content-language LANGUAGE] [--content-length SIZE] [--content-md5 MD5] [--content-type MIME] [--metadata STRUCTURE] [--region REGION] [--output FORMAT] [--json]\n\nParameter values:\n\n\n\n* BUCKET_NAME: Name of bucket used when bucket was created\n* KEY: Application file name\n* PATH: file name and path to the Spark application file\n\n\n\nExample\n: Enter:\n\nibmcloud cos upload --bucket test-cos-storage-bucket --key test-math.py --file test-math.py\n\nSample application file\n: Sample of test-math.py:\n\nfrom pyspark.sql import SparkSession\nimport time\nimport random\nimport cmath\n\ndef init_spark():\nspark = SparkSession.builder.appName(\"test-math\").getOrCreate()\nsc = spark.sparkContext", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-using-cli"}, {"document_id": "ibmcld_00054-3422-4901", "score": 11.753818, "text": "\n\"spark.hadoop.javax.jdo.option.ConnectionURL\": \"jdbc:postgresql://<CHANGEME>.databases.appdomain.CHANGEME/ibmclouddb?sslmode=verify-ca&sslrootcert=/home/spark/shared/user-libs/certificate_library_set/custom/postgres.cert&socketTimeout=30\",\n\"ae.spark.librarysets\":\"certificate_library_set\"\n5. Set up the Hive metastore schema in the Databases for PostgreSQL instance because there are no tables in the public schema of Databases for PostgreSQL database when you create the instance. This step executes the Hive schema related DDL so that metastore data can be stored in them. After running the following Spark application called postgres-create-schema.py, you will see the Hive metadata tables created against the \"public\" schema of the instance.\n\nfrom pyspark.sql import SparkSession\nimport time\ndef init_spark():\n\u00a0 spark = SparkSession.builder.appName(\"postgres-create-schema\").getOrCreate()\n\u00a0 sc = spark.sparkContext\n\u00a0 return spark,sc\ndef create_schema(spark,sc):\n\u00a0 tablesDF=spark.sql(\"SHOW TABLES\")\n\u00a0 tablesDF.show()\n\u00a0 time.sleep(30)\ndef main():\n\u00a0 spark,sc = init_spark()\n\u00a0 create_schema(spark,sc)\nif __name__ == '__main__':\n\u00a0 main()\n6. Now run the following script called postgres-parquet-table-create.py to create a Parquet table with metadata from IBM Cloud Object Storage in the Databases for PostgreSQL database.\n\nfrom pyspark.sql import SparkSession\nimport time\ndef init_spark():\n\u00a0 spark = SparkSession.builder.appName(\"postgres-create-parquet-table-test\").getOrCreate()", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-postgresql-external-metastore"}, {"document_id": "ibmcld_00086-7-1903", "score": 11.720366, "text": "\nSpark user interface \n\nThe Spark user interface (Spark UI) helps you to keep track of various aspects of a running Spark application.\n\nThe list below includes a few examples:\n\n\n\n* current running stage\n* number of tasks in a stage\n* reason for a longer running stage\n* strangler task in a stage\n* whether the executors in the application are used optimally\n* inspect into memory and disk consumption of the driver and executors\n\n\n\nFor details, see the [Spark-UI documentation](https://spark.apache.org/docs/latest/monitoring.htmlweb-interfaces).\n\nIBM Analytics Engine displays the Spark UI only for the Spark applications that are currently running. You cannot access Spark UI for a completed application.\n\nUse the Spark history server to inspect the run of a completed Spark application. To access the Spark history server, see the [Access Spark history server](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-spark-history-serverless).\n\n\n\n Accessing the Spark UI \n\nThe Spark UI endpoint of a running Spark application is accessible from the service details page of the IBM Analytics Engine instance.\n\nThe following image shows you an example of the Application tab with the link to the Spark UI of a running application.\n\nZoom\n\n![Shows the ink to Spark-ui of a running application](https://cloud.ibm.com/docs-content/v1/content/cd4be197c8921ed12923aa899ac93a8ab643c158/AnalyticsEngine/images/spark_ui.png)\n\nFigure 1. Application tab of IBM Analytics Engine service details page\n\nThe Spark UI endpoint of the running Spark application can also be obtained by invoking the following IBM Analytics Engine REST API endpoints or corresponding SDK methods:\n\n\n\n* [Retrieve the details of a given Spark application](https://cloud.ibm.com/apidocs/ibm-analytics-engine-v3get-application)\n* [List Spark applications](https://cloud.ibm.com/apidocs/ibm-analytics-engine-v3list-applications)", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-spark-user-interface"}, {"document_id": "ibmcld_00071-13290-14873", "score": 11.431918, "text": "\n[EnvironmentVariableName]\" configuration (application_details > env) also. They will, however, be accessible only to the tasks running on the executor and not the driver.\n\nExample of pyspark application that accesses the environment variables that are passed using the \"os.getenv\" call.\n\nfrom pyspark.sql.types import IntegerType\nimport os\n\ndef init_spark():\nspark = SparkSession.builder.appName(\"spark-env-test\").getOrCreate()\nsc = spark.sparkContext\nreturn spark,sc\n\ndef returnExecutorEnv(x):\n Attempt to access environment variable from a task running on executor\nreturn os.getenv(\"TESTENV1\")\n\ndef main():\nspark,sc = init_spark()\n\n dummy dataframe\ndf=spark.createDataFrame([(\"1\",\"one\")])\ndf.show()\ndf.rdd.map(lambda x: (x[0],returnExecutorEnv(x[0]))).toDF().show()\n Attempt to access environment variable on driver\nprint (os.getenv(\"TESTENV1\"))\nspark.stop()\n\nif __name__ == '__main__':\nmain()\nShow more\n\n\n\n\n\n Run a Spark application with non-default language version \n\nThe Spark runtime support Spark application written in the following languages:\n\n\n\n* Scala\n* Python\n* R\n\n\n\nA Spark runtime version comes with default runtime language version. IBM extend support for new language versions and remove the existing language version to keep the runtime free from any security vulnerabilities. The system also provides settling time to transition your workloads when ever there is a new language versions. You can test your workload with a language version by passing an environment variable that points to the language version of the application.\n\nExample:\n\n\"application_details\": {", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-spark-app-rest-api"}]}
{"task_id": "5815bb4a99e2a0d8a986348da4c49083<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13481-6212-7871", "score": 23.35947, "text": "\nDownload the [Hive-compatible client](https://us.sql-query.cloud.ibm.com/download/catalog/hive-metastore-standalone-client-3.1.2-sqlquery-1.0.13.jar) and place it in a directory of your Apache Spark cluster that is not on the classpath. This step is necessary, as the client is loaded into an isolated classloader to avoid version conflicts. Note that in the examples the files are placed in /tmp/dataengine, when you use a different folder, adjust the example accordingly.\n\nThe client differs from the Hive version 3.1.2 release by more enhancements that add support for TLS and authentication through IBM Cloud\u00ae Identity and Access Management. For user, specify the CRN and for password a valid API key with access to your Data Engine. Find the endpoint to use in the following table.\n\n\n\nTable 1. Region endpoints\n\n Region Endpoint \n\n us-south thrift://catalog.us.dataengine.cloud.ibm.com:9083 \n eu-de thrift://catalog.eu-de.dataengine.cloud.ibm.com:9083 \n\n\n\n\n\n\n\n Convenience libraries to configure Spark \n\nWhile the Data Engine catalog is compatible with the Hive metastore and can be used as any other external Hive metastore server, an SDK is provided to minimize the steps that are needed to configure Apache Spark. The SDK simplifies connecting to the Hive metastore and IBM Cloud Object Storage buckets referenced by tables or views.\n\nIn case of using Python download both, the Scala and the Python SDK, and place them in a folder that is in the classpath of your Apache Spark cluster. When using Scala, the Scala SDK is enough.\n\n\n\n* [spark-dataengine-scala](https://us.sql-query.cloud.ibm.com/download/catalog/dataengine-spark-integration-1.4.51.jar)", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastore"}, {"document_id": "ibmcld_13481-5443-6857", "score": 21.332464, "text": "\n.config(\"spark.hive.metastore.uris\", \"thrift://catalog.<region>.sql-query.cloud.ibm.com:9083\") \n.config(\"spark.hive.metastore.use.SSL\", \"true\") \n.config(\"spark.hive.metastore.truststore.password\", \"changeit\") \n.config(\"spark.hive.metastore.client.auth.mode\", \"PLAIN\") \n.config(\"spark.hive.metastore.client.plain.username\", '<YourDataengineCRN>') \n.config(\"spark.hive.metastore.client.plain.password\", '<YourAPIkey>') \n.config(\"spark.hive.execution.engine\", \"spark\") \n.config(\"spark.hive.stats.autogather\", \"false\") \n.config(\"spark.sql.warehouse.dir\", \"file:///tmp\") \n only spark is allowed as the default catalog\n.config(\"metastore.catalog.default\", \"spark\") \n.enableHiveSupport() \n.getOrCreate()\nShow more\n\n\n\n\n\n Apache Hive metastore version 3.1.2 compatible client \n\nDownload the [Hive-compatible client](https://us.sql-query.cloud.ibm.com/download/catalog/hive-metastore-standalone-client-3.1.2-sqlquery-1.0.13.jar) and place it in a directory of your Apache Spark cluster that is not on the classpath. This step is necessary, as the client is loaded into an isolated classloader to avoid version conflicts. Note that in the examples the files are placed in /tmp/dataengine, when you use a different folder, adjust the example accordingly.\n\nThe client differs from the Hive version 3.1.2 release by more enhancements that add support for TLS and authentication through IBM Cloud\u00ae Identity and Access Management.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastore"}, {"document_id": "ibmcld_00029-8568-9861", "score": 20.376017, "text": "\n\"spark.hive.metastore.client.auth.mode\":\"PLAIN\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.use.SSL\":\"true\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.stats.autogather\":\"false\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.username\":\"<CHANGEME-CRN-DATA-ENGINE-INSTANCE>\",\n for spark 3.3\n\"spark.hive.metastore.truststore.path\":\"/opt/ibm/jdk/lib/security/cacerts\",\n for spark 3.1, spark 3.2\n\"spark.hive.metastore.truststore.path\":\"file:///opt/ibm/jdk/jre/lib/security/cacerts\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.catalogImplementation\":\"hive\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.hive.metastore.jars\":\"/opt/ibm/connectors/data-engine/hms-client/\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.hive.metastore.version\":\"3.0\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.warehouse.dir\":\"file:///tmp\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.catalogImplementation\":\"hive\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hadoop.metastore.catalog.default\":\"spark\"\n},\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"application\": \"cos://mybucket.ALIAS NAME/select_query_data_engine.py\"\n\u00a0\u00a0\u00a0 }\n}\nShow more\n\nParameter values:\n\n\n\n* ALIAS NAME: specify the data engine endpoint for your region. For more information on the currently supported data engine endpoints, see [Data engine endpoints](https://cloud.ibm.com/docs/sql-query?topic=sql-query-overviewendpoints).\n* THRIFT URL: specify the region-specific thrift URL. For example, thrift://catalog.us.dataengine.cloud.ibm.com:9083.", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"}, {"document_id": "ibmcld_16635-0-1693", "score": 20.04842, "text": "\n\n\n\n\n\n\n  HMS Overview \n\n\n\n  Hive Metastore \n\nHive Metastore (HMS) is a service that stores metadata related to Presto and other services in a backend Relational Database Management System (RDBMS) or Hadoop Distributed File System (HDFS).\n\nWhen you create a new table, information related to the schema such as column names, data types etc is stored in the metastore relational database. A metastore enables the user to see the data files in the HDFS object storage as if they are stored in tables with HMS.\n\nMetastore acts as a bridge between the schema of the table and the data files stored in object storages. HMS holds the definitions, schema, and other metadata for each table and maps the data files and directories to the table representation which is viewed by the user. Therefore, HMS is used as a storage location for the schema and tables. HMS is a metastore server that connects to the object storage to store data and keeps its related metadata on PostgreSQL.\n\nAny database with a JDBC driver can be used as a metastore. Presto makes requests through thrift protocol to HMS. The Presto instance reads and writes data to HMS. HMS supports 5 backend databases as follows. In IBM\u00ae watsonx.data, PostgreSQL database is used.\n\n\n\n*  Derby\n*  MySQL\n*  MS SQL Server\n*  Oracle\n*  PostgreSQL\n\n\n\nCurrently HMS in watsonx.data supports Iceberg table format.\n\nFollowing three modes of deployment are supported for HMS. In watsonx.data the remote mode is used.\n\n\n\n*  Embedded Metastore - Derby with singe session.\n*  Local Metastore - MySQl with multiple session accessible locally.\n*  Remote Metastore - metastore runs on its own separate JVM and accessible via thrift network APIs.\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-hms_overview"}, {"document_id": "ibmcld_16636-0-1664", "score": 19.592596, "text": "\n\n\n\n\n\n\n  Integrating Presto with Apache Hudi using a Hudi connector \n\nYou can integrate Presto with Apache Hudi by using the Hudi connector. You can query Hudi tables that are synced to Hive metastore (HMS) using Presto's SQL interface. This combination offers the benefits of fast and interactive analytics on large-scale, high-velocity data stored in Hudi. Hudi connector uses the metastore to track partition locations. It uses underlying Hudi file system and input formats to list data files.\n\n\n\n  Configuring a catalog in Presto \n\nCreate a hudi.properties file inside /opt/presto/etc/catalog directory in the presto container.\n\n hudi.properties\nconnector.name=hudi\n\n HMS thrift URI\nhive.metastore.uri=thrift://<hostname>:<port>\n\n properties to enable connection to object-storage bucket\nhive.s3.ssl.enabled=true\nhive.s3.path-style-access=true\nhive.s3.endpoint=<Bucket API Endpoint>\nhive.s3.aws-access-key=<INSERT YOUR ACCESS KEY>\nhive.s3.aws-secret-key=<INSERT YOUR SECRET KEY>\n\n properties to enable TLS connection to HMS\nhive.metastore.thrift.client.tls.enabled=true\nhive.metastore.authentication.type=PLAIN\nhive.metastore.thrift.client.tls.truststore.path=<Truststore Path>\nhive.metastore.thrift.client.tls.truststore.password=<Truststore Password>\nhive.metastore.thrift.client.tls.keystore.path=<Keystore Path>\nhive.metastore.thrift.client.tls.keystore.password=<Keystore Password>\nShow more\n\n\n\n\n\n  Limitations \n\n\n\n1.  Connector does not support DDL or DML SQL statements. Presto can query data using the Hudi connector, but cannot directly perform write operations.\n2.  Data modifications must be done through Hudi-specific tools and workflows.\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-hudi-conn"}, {"document_id": "ibmcld_13481-4684-5710", "score": 19.397278, "text": "\n.config(\"fs.cos.impl\", \"com.ibm.stocator.fs.ObjectStoreFileSystem\") \n.config(\"fs.stocator.scheme.list\", \"cos\") \n.config(\"fs.stocator.cos.impl\", \"com.ibm.stocator.fs.cos.COSAPIClient\") \n.config(\"fs.stocator.cos.scheme\", \"cos\") \n register the required Cloud Object Storage path used in our application, add endpoints for all buckets\n.config(\"spark.hadoop.fs.cos.us-geo.endpoint\", \"https://s3.us.cloud-object-storage.appdomain.cloud\") \n.config(\"spark.hadoop.fs.cos.us-geo.iam.endpoint\", \"https://iam.cloud.ibm.com/identity/token\") \n.config(\"spark.hadoop.fs.cos.us-geo.iam.api.key\", '<YourAPIkey>') \n.config(\"spark.sql.hive.metastore.version\", \"3.0\") \n directory where the Hive client has been placed\n.config(\"spark.sql.hive.metastore.jars\", \"/tmp/dataengine/\") \n.config(\"spark.hive.metastore.uris\", \"thrift://catalog.<region>.sql-query.cloud.ibm.com:9083\") \n.config(\"spark.hive.metastore.use.SSL\", \"true\") \n.config(\"spark.hive.metastore.truststore.password\", \"changeit\") \n.config(\"spark.hive.metastore.client.auth.mode\", \"PLAIN\")", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastore"}, {"document_id": "ibmcld_00029-7-2023", "score": 19.087288, "text": "\nUsing IBM Cloud Data Engine as external metastore \n\nIBM Cloud Data Engine is IBM Cloud's central service for data lakes. It provides stream ingestion, data preparation, ETL, and data query from IBM Cloud Object Storage and Kafka. It also manages tables and views in a catalog that is compatible with Hive metastore and other big data engines and services can connect to it. See [Overview of IBM Cloud Data Engine](https://cloud.ibm.com/docs/sql-query?topic=sql-query-overview).\n\nEach instance of IBM Cloud Data Engine includes a database catalog that you can use to register and manage table definitions for your data on IBM Cloud Object Storage. Catalog syntax is compatible with Hive metastore syntax. You can use IBM Cloud Data Engine to externalize metadata outside the IBM Analytics Engine Spark cluster.\n\n\n\n Pre-requisites \n\nThe following are the pre-requisites:\n\n\n\n* Creating IBM Cloud Data Engine instance\n* Storing data in Cloud Object Storage\n* Creating schema\n\n\n\n\n\n Creating IBM Cloud Data Engine instance \n\n{: metastore-prerequisite_line1}\n\nCreate an IBM Cloud Data Engine instance by using the Standard plan.\u00a0See [Data Engine](http://cloud.ibm.com/catalog/services/data-engine-previously-sql-query).\n\nAfter you have provisioned the Data Engine instance:\n1. Make a note of the CRN of the instance.\n1. Create an account-level API key or service ID level API key with access to the instance.\n1. This service ID should be granted access to both the Data Engine instance as well as the IBM Cloud Object Storage bucket.\n\nYou can then configure your IBM Analytics Engine instance to use the default metastore configuration either at instance level or at application level as needed.\n\nIBM Cloud Data Engine supports creating instances for different endpoints(location). Within an instance, different IBM Cloud Object Storage buckets are created to store data. The data buckets can be created for different end points(region). The endpoints for the data engine instance(thrift) and the data bucket are different.", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"}, {"document_id": "ibmcld_13481-3545-4909", "score": 19.006802, "text": "\ncurl -X POST https://api.us-south.ae.cloud.ibm.com/v3/analytics_engines/<GUID of Analytic Engine>/spark_applications --header \"Authorization: Bearer $TOKEN\" -H \"content-type: application/json\" -d @listTablesExample.json\n\n\n\n\n\n Apache Spark Data Engine integration \n\nFor self-hosted Apache Spark installations use the following instructions.\n\n\n\n1. Ensure that [Stocator](https://github.com/CODAIT/stocator) is installed according to the instructions provided.\n2. Download the Hive-compatible client with the provided [instructions](https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastorehive_compatible_client).\n3. Either download the [provided convenience libraries](https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastoreconvenience_libraries) or, in case you don't want to use them, set the following settings in SparkContext yourself:\n\nspark = SparkSession.builder.appName('Python-App') \n.config(\"spark.sql.pyspark.jvmStacktrace.enabled\", True) \n.config(\"spark.hive.metastore.truststore.path\", \"file:///opt/ibm/jdk/jre/lib/security/cacerts\") \n to access IBM Cloud Object Storage ensure that stocator is available\n.config(\"fs.cos.impl\", \"com.ibm.stocator.fs.ObjectStoreFileSystem\") \n.config(\"fs.stocator.scheme.list\", \"cos\") \n.config(\"fs.stocator.cos.impl\", \"com.ibm.stocator.fs.cos.COSAPIClient\") \n.config(\"fs.stocator.cos.scheme\", \"cos\")", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastore"}, {"document_id": "ibmcld_16641-2355-3755", "score": 18.872358, "text": "\nspark.sql.catalog.lakehouse.uri = <hms-thrift-endpoint-from-watsonx.data> for example (thrift://81823aaf-8a88-4bee-a0a1-6e76a42dc833.cfjag3sf0s5o87astjo0.databases.appdomain.cloud:32683)\nspark.hive.metastore.client.auth.mode = PLAIN\nspark.hive.metastore.client.plain.username = <hms-user-from-watsonx.data> (for example, ibmlhapikey)\nspark.hive.metastore.client.plain.password = <hms-password-from-watsonx.data>\nspark.hive.metastore.use.SSL = true\nspark.hive.metastore.truststore.type = JKS\nspark.hive.metastore.truststore.path = file:///opt/ibm/jdk/lib/security/cacerts\nspark.hive.metastore.truststore.password = changeit\nShow more\n\n\n\nParameter value:\n\n\n\n* Hms-thrift-endpoint-from-watsonx.Data: Specify the credentials for watsonx.data.\n* Hms-user-from-watsonx.Data: The watsonx.data username.\n* Hms-password-from-watsonx.Data: The watsonx.data password.\n\n\n\n\n\n\n\n Configuring Analytics Engine instance by using Analytics Engine API \n\nTo configure your IBM Analytics Engine instance from the Analytics Engine API, complete the following steps:\n\n\n\n1. Generate an IAM token to connect to the IBM Analytics Engine API. For more information about how to generate an IAM token, see [IAM token](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverlessendpoints-cli).\n2. Run the following API command to invoke the Analytics Engine API by using the generated IAM token.", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-lh-config-ae"}, {"document_id": "ibmcld_16641-6629-7897", "score": 18.859568, "text": "\n\"spark.sql.catalog.lakehouse.type\": \"hive\",\n\"spark.sql.catalog.lakehouse.uri\": \"<hms-thrift-endpoint-from-watsonx.data> for example (thrift://81823aaf-8a88-4bee-a0a1-6e76a42dc833.cfjag3sf0s5o87astjo0.databases.appdomain.cloud:32683) \",\n\"spark.hive.metastore.client.auth.mode\": \"PLAIN\",\n\"spark.hive.metastore.client.plain.username\": \"<hms-user-from-watsonx.data> (for example, ibmlhapikey)\",\n\"spark.hive.metastore.client.plain.password\": \"<hms-password-from-watsonx.data>\",\n\"spark.hive.metastore.use.SSL\": \"true\",\n\"spark.hive.metastore.truststore.type\": \"JKS\",\n\"spark.hive.metastore.truststore.path\": \"file:///opt/ibm/jdk/lib/security/cacerts\",\n\"spark.hive.metastore.truststore.password\": \"changeit\"\n}\nShow more\n* INSTANCE_ID: The Analytics Engine instance ID. For more information about how to retrieve an instance ID, see [Obtaining the service endpoints](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverlessendpoints-cli)\n* Hms-thrift-endpoint-from-watsonx.Data: Specify the credentials for watsonx.data. For more information on getting the HMS credentials, see [Getting (Hive metastore) HMS Credentials](https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-hms).\n* Hms-user-from-watsonx.Data: The watsonx.data username.", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-lh-config-ae"}]}
{"task_id": "20c2cbd18c16c12c9c2bbead6aef1a21<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04105-1672-3877", "score": 22.453156, "text": "\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04105-3403-5572", "score": 19.888796, "text": "\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04105-7-2225", "score": 14.373378, "text": "\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04146-2946-5057", "score": 12.592393, "text": "\nAvailable Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet. It is rare to see values above 60, so tune your firewall rules to challenge those above 10, and to block those above 50. \n\n\n\n\n\n\n\n\n\n Functions \n\nThe firewall rules language has a number of functions to convert fields.\n\nThese are not currently supported in the CIS UI Visual Expression Builder.\n\n\n\nTable 3. Firewall rules functions\n\n Function name Argument types Return type Usage example Notes \n\n lower String String lower(http.host) == \"www.example.com\" Converts a string field to lowercase. Only uppercase ASCII bytes are being converted, every other bytes are left as-is. \n upper String String upper(http.host) == \"www.example.com\" Converts a string field to uppercase. Only lowercase ASCII bytes are being converted, every other bytes are left as-is. \n\n\n\n\n\n\n\n Expressions \n\nAn expression returns true or false based on a match against incoming traffic. For example:\n\nhttp.host eq \"www.example.com\" and ip.src in 92.182.212.0/24\n\nIn this example, two single expressions comprise a compound expression. Think of each single expression as a condition. Each condition is evaluated individually before applying and logic to determine the final result of the compound expression.\n\nLooking at the first single expression, you can see that it contains:\n\n\n\n* a field - http.host\n* a comparison operator - eq\n* a value - \"www.example.com\"\n\n\n\nNot all conditions have the same structure. Additional examples using different structures are discussed in the next section.\n\n\n\n Comparison operators \n\nThe following comparison operators are available for use in expressions:\n\n\n\nTable 4. Comparison operators for expressions\n\n English C-like Description \n\n eq == Equal \n ne != Not equal", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-fields-and-expressions"}, {"document_id": "ibmcld_04105-5067-6335", "score": 12.006054, "text": "\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04170-7-2189", "score": 11.501283, "text": "\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https://research.google/pubs/pub45581/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with /cdn-cgi/challenge-platform/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under /cdn-cgi/challenge-platform/ is allowed.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections"}, {"document_id": "ibmcld_16364-213826-215727", "score": 10.973666, "text": "\nFor details, see [Defining entities](https://cloud.ibm.com/docs/assistant?topic=assistant-entities) and search for Enabling system entities.\n* You can now view a history of conversations with users on the Improve page. You can use this to understand your bot's behavior. For details, see [Improving your skill](https://cloud.ibm.com/docs/assistant?topic=assistant-logs).\n* You can now import entities from a comma-separated value (CSV) file, which helps with when you have a large number of entities. For details, see [Defining entities](https://cloud.ibm.com/docs/assistant?topic=assistant-entities) and search for Importing entities.\n\n\n\n\n\n\n\n 20 September 2016 \n\nNew version 2016-09-20\n: To take advantage of the changes in a new version, change the value of the version parameter to the new date. If you're not ready to update to this version, don't change your version date.\n\n\n\n* version 2016-09-20: dialog_stack changed from an array of strings to an array of JSON objects.\n\n\n\n\n\n\n\n 29 August 2016 \n\nUpdates\n: This release includes the following updates:\n\n\n\n* You can move dialog nodes from one branch to another, as siblings or peers. For details, see [Moving a dialog node](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-tasksdialog-tasks-move-node).\n* You can expand the JSON editor window.\n* You can view chat logs of your bot's conversations to help you understand it's behavior. You can filter by intents, entities, date, and time. For details, see [Improving your skill](https://cloud.ibm.com/docs/assistant?topic=assistant-logs).\n\n\n\n\n\n\n\n 11 July 2016 \n\nGeneral Availability\n: This General Availability release enables you to work with entities and dialogs to create a fully functioning bot.\n\n\n\n\n\n 18 May 2016 \n\nExperimental release\n: This Experimental release of the Watson Assistant introduces the user interface and enables you to work with workspaces, intents, and examples.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_04175-0-1274", "score": 10.0356045, "text": "\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-machine-learning-models"}, {"document_id": "ibmcld_16358-8609-10224", "score": 9.972249, "text": "\n[Shows the chat bot preview in a fake web page](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/tut-neural-user-trained.png)\n\nFigure 6. Creating a user-trained model\n5. Click Apply changes and reprocess.\n\nAfter some processing occurs, a representation of the document is displayed in the Smart Document Understanding tool. The tool shows you a view of the original document along with a representation of the document, where the text is replaced by blocks. The blocks represent field types.\n\nInitially, the blocks are labeled as text because all of the document content is considered to be standard text by default, and is indexed in the text field.\n\nWe want to label all first- and second-level headings as subtitles instead of text.\n6. From the thumbnails view, click the thumbnail for the first full-text page from the document to open the first page with real content.\n\nZoom\n\n![Shows the Smart Document Understanding tool](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/tut-neural-sdu-tool.png)\n\nFigure 7. The Smart Document Understanding tool\n7. To annotate the document, click the subtitle label from the Field labels list. Then, click each block in the representation of the PDF page that represents a heading to change its label from text to subtitle.\n\nZoom\n\n![Shows labeled subtitles in the SDU tool](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/tut-neural-sdu-subtitle.png)\n\nFigure 8. Applying the subtitle label", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-tutorial-neuralseek"}, {"document_id": "ibmcld_16364-205949-207992", "score": 9.91585, "text": "\nThe navigation menu options are available from the side of the main page instead of the top. In the page header, breadcrumb links display that show you where you are. You can now switch between service instances from the Workspaces page. To get there quickly, click Back to workspaces from the navigation menu. If you have multiple service instances, the name of the current instance is displayed. You can click the Change link beside it to choose another instance.\n* When you create a dialog, two nodes are now added to it for you: 1) a Welcome node at the start the dialog tree that contains the greeting to display to the user and 2) an Anything else node at the end of the tree that catches any user inquiries that are not recognized by other nodes in the dialog and responds to them. See [Creating a dialog](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-build) for more details.\n* When you are testing a dialog in the \"Try it out\" pane, you can now find and resubmit a recent test utterance by pressing the Up key to cycle through your previous inputs.\n* Experimental Korean language support for 5 system entities (@sys-date, @sys-time, @sys-currency, @sys-number, @sys-percentage) is now available. There are known issues for some of the numeric entities, and limited support for informal language input.\n* An Overview page is available from the Improve tab. The page provides a summary of interactions with your bot. You can view the amount of traffic for a given time period, as well as the intents and entities that were recognized most often in user conversations. For additional information, see [Using the Overview page](https://cloud.ibm.com/docs/assistant?topic=assistant-logs-overview).\n\n\n\n\n\n\n\n 27 April 2017 \n\nSystem entities\n: The following system entities are now available as beta features in English only:\n\n\n\n* sys-location: Recognizes references to locations, such as towns, cities, and countries, in user utterances.\n* sys-person: Recognizes references to people's names, first and last, in user utterances.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}]}
{"task_id": "20c2cbd18c16c12c9c2bbead6aef1a21<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04170-7-2189", "score": 22.56624, "text": "\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https://research.google/pubs/pub45581/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with /cdn-cgi/challenge-platform/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under /cdn-cgi/challenge-platform/ is allowed.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections"}, {"document_id": "ibmcld_04105-5067-6335", "score": 18.949375, "text": "\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04334-39121-41053", "score": 17.546139, "text": "\nValid values for group are all, domain, reliability, performance, security. This option is mutually exclusive with -f, --feature.\n\n-f, --feature\n: Feature of domain settings to check. This option is mutually exclusive with g, --group. Valid values are as follow:\n\n\n\n* always_use_https: Redirect all requests with scheme http to https. This applies to all http requests to the domain.\n* automatic_https_rewrites: Help fix mixed content by changing http to https for all resources or links on your web site that can be served with HTTPS.\n* brotli: When the client requesting an asset supports the brotli compression algorithm, CIS will serve a brotli compressed version of the asset.\n* browser_check: Evaluate HTTP headers from your visitors browser for threats. If a threat is found a block page will be delivered.\n* challenge_ttl: Specify how long a visitor with a bad IP reputation is allowed access to your website after completing a challenge.\n* ciphers: A whitelist of ciphers for TLS termination in the BoringSSL format. This command only lists ciphers specifically whitelisted by customers. If no ciphers are whitelisted, the list is empty and the default ciphers are used. See [TLS Options](/docs/cis? topic=cis-cis-tls-options#cipher-suites) for the list of default ciphers.\n* cname_flattening: Follow a CNAME to where it points and return that IP address instead of the CNAME record. By default, only flatten the CNAME at the root of your domain.\n* email_obfuscation: Encrypt email addresses on your web page from bots while keeping them visible to humans.\n* opportunistic_onion: Allow legitimate users of Tor Browser to access your websites.\n* hotlink_protection: Protect your images from off-site linking.\n* http2: Accelerate your website with HTTP/2.\n* http3: Accelerate your website with HTTP/3.\n* image_load_optimization: Improve load time for pages that include images on mobile devices with slow network connections.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_04334-43529-45385", "score": 17.3181, "text": "\nUpdate a feature for the domain.\n\nibmcloud cis domain-settings-update DNS_DOMAIN_ID (-f, --feature FEATURE) (-v, --value VALUE) [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required. -f, --feature value\n: Feature of domain settings to update. Required. Valid values:\n\n\n\n* always_use_https: Redirect all requests with scheme http to https. This applies to all http requests to the domain.\n* automatic_https_rewrites: Help fix mixed content by changing http to https for all resources or links on your web site that can be served with HTTPS.\n* brotli: When the client requesting an asset supports the brotli compression algorithm, CIS will serve a brotli compressed version of the asset.\n* browser_check: Evaluate HTTP headers from your visitors browser for threats. If a threat is found a block page will be delivered.\n* challenge_ttl: Specify how long a visitor with a bad IP reputation is allowed access to your website after completing a challenge.\n* ciphers: A whitelist of ciphers for TLS termination. These ciphers must be in the BoringSSL format.\n* cname_flattening: Follow a CNAME to where it points and return that IP address instead of the CNAME record. By default, only flatten the CNAME at the root of your domain.\n* email_obfuscation: Encrypt email addresses on your web page from bots while keeping them visible to humans.\n* opportunistic_onion: Allow legitimate users of Tor Browser to access your websites.\n* hotlink_protection: Protect your images from off-site linking.\n* http2: Accelerate your website with HTTP/2.\n* http3: Accelerate your website with HTTP/3.\n* image_load_optimization: Improve load time for pages that include images on mobile devices with slow network connections.\n* image_size_optimization: Improve image load time by optimizing images hosted on your domain.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_04105-3403-5572", "score": 17.314138, "text": "\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04175-0-1274", "score": 16.69935, "text": "\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-machine-learning-models"}, {"document_id": "ibmcld_04113-1734-4014", "score": 16.603727, "text": "\nIBM CIS usually accelerates API traffic by removing connection overhead. However, the default security stance can interfere with many API calls. It is recommended that you take a few actions to prevent interference with your API traffic after proxying is active.\n\n\n\n* Turn security features off selectively, using the Page Rules features.\n\n\n\n* Create a Page Rule with the URL pattern of your API, such as api.example.com\n* Add the following rule behaviors:\n\n\n\n* Select Security Level to Essentially off\n* Select TLS to Off\n* Select Browser Integrity Check to Off\n\n\n\n* Select Provision Resource\n\n\n\n* Alternatively, you can turn off Web Application Firewall globally from the Security page.\n\n\n\n\n\n What does the Browser Integrity Check do? \n\nThe browser integrity check looks for HTTP headers that are commonly abused by spammers. It denies traffic with those headers access to your page. It also blocks visitors that do not have a user agent, or who add a non-standard user agent (this tactic is commonly used by abuse bots, crawlers, or APIs).\n\n\n\n\n\n\n\n Best practice 4: Configure your security settings as strictly as possible \n\nCIS provides some options for encrypting your traffic. As a reverse proxy the TLS connection is terminated at Cloudflare and a new TLS connection is opened to your origin servers. For your termination with CIS, you can upload a custom certificate from your account, you can use a wildcard certificate provisioned for you by CIS, or both.\n\n\n\n Upload a custom certificate \n\nYou can upload your public and private key when you create an Enterprise domain. If you upload your own certificate, you gain immediate compatibility with encrypted traffic, and you maintain control over your certificate (for example, an Extended Validation (EV) certificate). Remember that you'll be responsible for managing your certificate if you upload a custom certificate. For example, IBM CIS won't track the certificate expiration dates.\n\n\n\n\n\n Alternatively, use a certificate provisioned by CIS \n\nIBM CIS has partnered with several Certificate Authorities (CAs) to provide domain wildcard certificates for our customers, by default. Manual verification could be required for setting up these certificates, and your support team can help you perform these additional steps.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-best-practices-for-cis-setup"}, {"document_id": "ibmcld_04107-9120-10897", "score": 16.323868, "text": "\nCIS WAF contains rulesets to mitigate non-volumetric attacks, including cross-site forgery, cross-site-scripting (XSS), file inclusion, and SQL injection. For additional information about WAF, see [Web Application Firewall concepts](https://cloud.ibm.com/docs/cis?topic=cis-waf-q-and-awhat-types-of-attacks-can-waf-prevent).\n\n\n\n\n\n Cost protection \n\nCIS does not meter or bill for traffic that is blocked as part of DDoS mitigation, firewall, or rate limiting. Only requests that are passed through the CIS network to the origin destination incur charges or usage.\n\nCIS also helps keep egress bandwidth charges from your origin under control by only passing along good requests that the origin needs to respond to. All CIS plans offer unlimited and unmetered mitigation of DDoS attacks. You are never charged for attack traffic. There\u2019s no penalty for spikes due to attack traffic, so there's no chargeback by the customer.\n\n\n\n\n\n\n\n Reliability features \n\nZoom\n\n![reliability graphic](https://cloud.ibm.com/docs-content/v1/content/cb1eb27836421578019401fa7556779109430b29/cis/images/reliability-graphic.png)\n\nFigure 2. Reliability features\n\n\n\n Global load balancing features \n\nThe global load balancing service distributes your traffic across multiple servers with a combination of origin pools, health checks, and a load balancer. Global load balancing has the following features:\n\n\n\n* Proxy and non-proxy options for load balancing\n* Origin pools and health checks\n\n\n\n\n\n Global anycast network \n\nThe available health check regions are based on the [Cloudflare Global Anycast Network](https://www.cloudflare.com/network/).\n\n\n\n\n\n\n\n DNS features \n\nDNS within CIS has the following features:\n\n\n\n* DNS management - Manage your DNS records, control proxying, and enable DNS security.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-ibm-cloud-internet-services-cis"}, {"document_id": "ibmcld_04107-7548-9466", "score": 16.276876, "text": "\nThese attacks consist of a flood of traffic at ISO Layer 3 (the network layer), such as ICMP floods, or at Layer 4 (the transport layer), such as TCP SYN floods or reflected UDP floods. These attacks send malicious ISO Layer-7 requests (the application layer), such as GET floods. \n Automatically blocked at CIS edge CIS handles these attacks with Defense mode, WAF, and security-level settings. \n\n\n\n\n\n\n\n On-demand anti-DDoS \n\nIBM Cloud Internet Services ingests traffic by returning a CIS IP address on the DNS lookup for a domain, instead of the actual record for the origin server\u2019s IP address. This allows CIS to ingest, single-pass inspect, and re-encrypt data before sending it to the origin server destination. CIS can also act in DNS-only mode, returning the actual DNS record without obfuscating the IP, which disables DDoS and the other functions of CIS. To enable CIS protections, switch the \"proxy\" slider next to each DNS record to on; to disable protections, switch to off.\n\n\n\n\n\n Unlimited DDoS mitigation \n\nDDoS mitigation is typically an expensive service that can grow in cost when under attack. Unlimited DDoS mitigation is included with CIS at no additional cost.\n\n\n\n\n\n Mitigate Layer 7 attacks (configuration) \n\nThough DDoS is enabled by default in CIS, you can further configure Layer 7 security by:\n\n\n\n* Configuring WAF ruleset sensitivity and response behavior\n* Adding rate limiting\n* Adding firewall rules\n\n\n\nUse these features to customize Layer 7 mitigation of both volumetric and non-volumetric attacks.\n\n\n\n\n\n Mitigate non volumetric attacks \n\nCIS WAF contains rulesets to mitigate non-volumetric attacks, including cross-site forgery, cross-site-scripting (XSS), file inclusion, and SQL injection. For additional information about WAF, see [Web Application Firewall concepts](https://cloud.ibm.com/docs/cis?topic=cis-waf-q-and-awhat-types-of-attacks-can-waf-prevent).\n\n\n\n\n\n Cost protection", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-ibm-cloud-internet-services-cis"}, {"document_id": "ibmcld_04334-40577-42576", "score": 16.18592, "text": "\n* email_obfuscation: Encrypt email addresses on your web page from bots while keeping them visible to humans.\n* opportunistic_onion: Allow legitimate users of Tor Browser to access your websites.\n* hotlink_protection: Protect your images from off-site linking.\n* http2: Accelerate your website with HTTP/2.\n* http3: Accelerate your website with HTTP/3.\n* image_load_optimization: Improve load time for pages that include images on mobile devices with slow network connections.\n* image_size_optimization: Improve image load time by optimizing images hosted on your domain.\n* ip_geolocation: Include the country code of the visitor location with all requests to your website.\n* ipv6: Enable IPv6 support and gateway.\n* max_upload: The amount of data visitors can upload to your website in a single request.\n* min_tls_version: Only allow HTTPS connections from visitors that support the selected TLS protocol version or newer.\n* minify: Reduce the file size of source code on your website.\n* mobile_redirect: Redirect visitors that are using mobile devices to a mobile-optimized website.\n* opportunistic_encryption: Opportunistic Encryption allows browsers to benefit from the improved performance of HTTP/2 by letting them know that your site is available over an encrypted connection.\n* origin_error_page_pass_thru: When Origin Error Page is set to On, CIS will proxy the 502 and 504 error pages directly from the origin. (Enterprise plan only)\n* prefetch_preload: CIS will prefetch any URLs included in the prefetch HTTP header (Enterprise plan only).\n* pseudo_ipv4: Adds an IPv4 header to requests when a client is using IPv6, but the server only supports IPv4.\n* response_buffering: Enable or disable buffering of responses from the origin server (Enterprise plan only).\n* script_load_optimization: Improve the paint time for pages that include JavaScript.\n* security_header: Enforce web security policy for your website.\n* security_level: Choose the appropriate security profile for your website.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}]}
{"task_id": "20c2cbd18c16c12c9c2bbead6aef1a21<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04105-5067-6335", "score": 22.400301, "text": "\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04105-3403-5572", "score": 21.941723, "text": "\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04170-7-2189", "score": 21.69438, "text": "\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https://research.google/pubs/pub45581/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with /cdn-cgi/challenge-platform/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under /cdn-cgi/challenge-platform/ is allowed.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections"}, {"document_id": "ibmcld_04170-1738-2974", "score": 20.241522, "text": "\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under /cdn-cgi/challenge-platform/ is allowed. Your CSP should allow scripts that are served from your origin domain (script-src self).\n* If your CSP uses a nonce for script tags, CIS adds these nonces to the scripts it injects by parsing your CSP response header.\n* If your CSP does not use nonce for script tags and JavaScript Detection is enabled, you might see a console error such as\n\nRefused to execute inline script because it violates the following Content Security Policy directive: \"script-src 'self'\". Either the 'unsafe-inline' keyword, a hash ('sha256-b123b8a70+4jEj+d6gWI9U6IilUJIrlnRJbRR/uQl2Jc='), or a nonce ('nonce-...') is required to enable inline execution.\n* It is not recommended to use unsafe-inline. Instead, it is recommend that you use CSP nonces in script tags which are parsed and supported in the CDN.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections"}, {"document_id": "ibmcld_04179-7-1888", "score": 19.063437, "text": "\nManaging CIS for optimal security \n\nThe IBM Cloud\u00ae Internet Services (CIS) security settings include safe defaults designed to avoid false positives and negative influence on your traffic. However, these safe default settings do not provide the best security posture for every customer. Take the following steps to be sure that your CIS account is configured in a safe and secure way.\n\nRecommendations and best practices:\n\n\n\n* Secure your origin IP addresses by proxying and increasing obfuscation\n* Configure your security level selectively\n* Activate your Web Application Firewall (WAF) safely\n\n\n\n\n\n Best practice 1: Secure your origin IP addresses \n\nWhen a subdomain is proxied using CIS, all traffic is protected because we actively respond with IP addresses specific to CIS (for example, all of your clients connect to CIS proxies first, and your origin IP addresses are obscured).\n\n\n\n Use CIS proxies for all DNS records for HTTP(S) traffic from your origin \n\nTo improve the security of your origin IP address, you should proxy all HTTP(S) traffic.\n\nSee the difference yourself - Query a non-proxied and a proxied record:\n\ndig nonproxied.theburritobot.com +short\n1.2.3.4 (The origin IP address)\n\n$ dig proxied.theburritobot.com +short\n104.16.22.6 , 104.16.23.6 (CIS IP addresses)\n\n\n\n\n\n Obscure non-proxied origin records with non-standard names \n\nAny records that cannot be proxied through CIS, and that still use your origin IP, such as FTP, can be secured by creating additional obfuscation. In particular, if you require a record for your origin that cannot be proxied by CIS, use a non-standard name. For example, instead of ftp.example.com use [random word or-random characters].example.com. This obfuscation makes dictionary scans of your DNS records less likely to expose your origin IP addresses.\n\n\n\n\n\n Use separate IP ranges for HTTP and non-HTTP traffic if possible", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-manage-your-ibm-cis-for-optimal-security"}, {"document_id": "ibmcld_04177-7-2309", "score": 18.880276, "text": "\nManaging your CIS deployment \n\nYou'll begin by using the Overview screen as your working base of operations. It shows all of the current parameters for your deployment.\n\nOnce you've set up your DNS and configured it, you are ready to go!\n\n\n\n Using the Overview screen \n\nUsing the Overview screen, you can see the status of all your selections. Each setting links to the section of the user interface where the setting is configured. To modify any selection, you can navigate by clicking the link for the setting. For example, to change the load balancer configuration or add a new load balancer, click the Load Balancer field.\n\nOn the Overview screen, you might see that your domain name configuration is in Pending status, or in Active status. Pending status indicates that your domain is not fully set up, yet. You have to update your DNS provider or registrar with the name servers that are provided as part of the setup process.\n\nEnterprise only: The Service Details section of the Overview also allows you to add additional domains to your instance of CIS, and to switch between multiple domains.\n\n\n\n\n\n Changing the Service mode \n\nIn the Service Mode section of the Overview page is a list menu to select one of two modes:\n\n\n\n* Defense Mode helps protect against existing or predicted DNS attacks. This mode prevents all traffic from reaching your origin servers through your domain.\n* Pause Service disables all security and performance benefits to your domain. DNS functions still resolve for your website, but traffic is sent directly to configured origins.\n\n\n\n\n\n Setting up Service mode \n\n\n\n1. Select the mode you want from the list menu.\n2. Click Activate mode.\n3. Confirm or cancel the selection in the confirmation pop-up.\n\n\n\nA notification appears on all pages to show that either Pause Service or Defense Mode is active. To return to normal operation, click Deactivate mode in the notification banner.\n\n\n\n\n\n\n\n Configuring and managing your DNS \n\nGo to the Reliability section, click the DNS tab and add a record. Type in the information about your DNS record and then click Add record to implement your changes.\n\nAfter creating your records, consider turning on the Proxy setting. Most of the features of CIS require that the internet traffic to your site flow through CIS infrastructure.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-manage-your-cis-deployment"}, {"document_id": "ibmcld_04164-7-1670", "score": 18.018389, "text": "\nHelpful tools for managing your CIS deployment \n\nSome public-domain Unix system administration tools can help you manage your IBM Cloud\u00ae Internet Services (CIS) deployment.\n\n\n\n Sysadmin tools \n\n\n\n* whois (domain identification tool)\n* dig (DNS tool)\n* cURL (HTTP and HTTPS tool)\n* netcat (IP and port tool)\n* traceroute (network tool)\n\n\n\n\n\n\n\n Commercial tools for external and remote testing \n\n\n\n* GTMetrix (HTTP)\n* Web page test (HTTP)\n* WhatsMyDNS (DNS tool)\n* G Suite Toolbox (DNS and HTTP)\n\n\n\n\n\n\n\n Tools for looking at logs and history \n\nHTTP Archive files (HAR files)\n\n\n\n Using whois \n\nwhois is a UNIX system command line tool you can use to look up registrar information for a given domain name or IP address. For example, the domain\u2019s given authoritative servers or the owner of a particular IP address.\n\nExamples:\n\nwhois example.com\n\nwhois 8.8.8.8\n\n\n\n\n\n Using dig \n\ndig is a Unix command line tool that can perform DNS queries and check DNS records for a specific domain. It is similar to nslookup.\n\nThe schema of this command is dig <record_type> <domainname> <options>\n\nFor example:\n\n\n\n* dig example.com\n* dig my.example.com\n* dig example.com +trace\n* dig NS example.com\n* dig example.com @ns.example.com\n\n\n\n\n\n\n\n Using cURL \n\ncURL is a Unix command line tool that lets you transmit data using the URL syntax. It\u2019s commonly used to make HTTP requests or compare server responses.\n\nThe schema for this command is: curl -option1 -option2 http://example.com/url\n\nFor example:\n\n\n\n* curl -svo /dev/null http://www.example.com\n* curl -svo /dev/null -A \u201cUSER_AGENT_STRING\u201d http://www.example.com\n* curl -svo /dev/null -H \u201chost: www.example.com\u201d http://ORIGIN_IP", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-helpful-tools-for-managing-your-cis-deployment"}, {"document_id": "ibmcld_04175-0-1274", "score": 17.634619, "text": "\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-machine-learning-models"}, {"document_id": "ibmcld_04177-1842-4099", "score": 17.43005, "text": "\nTo return to normal operation, click Deactivate mode in the notification banner.\n\n\n\n\n\n\n\n Configuring and managing your DNS \n\nGo to the Reliability section, click the DNS tab and add a record. Type in the information about your DNS record and then click Add record to implement your changes.\n\nAfter creating your records, consider turning on the Proxy setting. Most of the features of CIS require that the internet traffic to your site flow through CIS infrastructure. In other words, it only applies to proxied records and load balancers. To really reap the benefit of CIS, make sure that your DNS records and load balancers have the proxy setting enabled.\n\n\n\n\n\n Setting up and manage your caching \n\nNext, you can set up caching. You have the option of three types of caching, available from the caching screen list menu.\n\n\n\n* No query string: Only delivers resources from cache when there is no query string.\n* Query string independent: Delivers the same resource to everyone independent of the query string. The Ignore Query String setting applies only to static file extensions. This setting removes the query string when generating the cache key, so that a request for style.css?something is normalized to style.css when serving from the cache.\n* Query string dependent: Delivers a different resource each time the query string changes.\n\n\n\n\n\n\n\n Purge cache \n\nYou can purge your cache to prepare for updates at any time by entering the URL into the purge cache field. You can purge a single file or multiple files (up to 30 at a time).\n\n\n\n\n\n Browser expiration \n\nYou can use the list menu to select the time of browser expiration that you require; for example, 8 hours, or 1 day.\n\nEnterprise only: You can also instruct CIS not to override browser cache control by setting this to Respect Existing Headers.\n\n\n\n\n\n Using Development mode \n\nDevelopment mode is intended for use when major updates or new file uploads are required, or any time you do not want the end users to work from the cache at all, but to retrieve files directly from the origin servers. To begin using Development Mode, toggle the switch to Enabled position. To stop using Development Mode, toggle the switch to Disabled position. Development mode expires automatically after 3 hours.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-manage-your-cis-deployment"}, {"document_id": "ibmcld_04105-7-2225", "score": 17.189045, "text": "\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}]}
{"task_id": "20c2cbd18c16c12c9c2bbead6aef1a21<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04175-0-1274", "score": 22.228493, "text": "\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-machine-learning-models"}, {"document_id": "ibmcld_16256-4941-7340", "score": 19.088247, "text": "\nThis version is then labeled as Previous after you upgrade. In addition, each new release will support running models that were trained on the version prior to that so that upgrading won't impact your runtime. For example, if you upgrade from IBM Cloud Pak for Data 4.6 to 4.7, and were using Latest (01-Jun-2022) that version becomes listed as Previous (01 June 2022) and remains your selected version.\n\n\n\n Automatic retraining after upgrading \n\nAfter your Watson Assistant for IBM Cloud Pak for Data upgrade is complete, Watson Assistant performs automatic retraining for any assistant models that were trained using a version that is no longer supported. In this case, Watson Assistant automatically retrains your assistant to the Latest version. This automatic retraining is required to assure your ability to run your trained models in your next upgrade.\n\n\n\n\n\n Best practices \n\nIt's recommended to use the Latest version in your production deployment of Watson Assistant for IBM Cloud Pak for Data. This is the default for newly-created assistants. During an upgrade, your settings don't automatically switch existing assistants to use the latest version. If prior to your upgrade you had selected Latest, your settings continue to use that version, now labeled as Previous. After you upgrade, it's recommended you choose Latest and run basic regression tests.\n\nIBM performs robust testing on a variety of data sets to minimize impacts on existing assistants. But given the nature of machine learning models and the nuance and subtlety of natural languages processing, you may find some discrepancies from version to version. If you find a major issue through your tests, you have the ability to switch your settings and use Previous to return to the prior behavior. In this event, we recommend you contact IBM and provide details of your test so that that IBM can support you in the steps to resolve the problem.\n\nIt's also recommended that you try the Beta version in one of your test systems after you upgrade. This gives you early visibility to changes that are likely to be delivered in a future version, and will reduce the probability of negative impacts to your production systems. IBM values both positive and negative feedback from customers who use Beta. You will have the opportunity to shape how the algorithms function before the version is promoted to Latest in a future version.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-algorithm-version"}, {"document_id": "ibmcld_16495-7-2129", "score": 18.94377, "text": "\nMaking machine learning model improvements \n\nAfter you determine areas in which the model is having trouble, take steps to improve its performance.\n\n\n\n Creating model versions \n\nAfter you create a machine learning model, you can take a snapshot to keep a backup version of the current resources in case you want to restore the resources in a future iteration.\n\n\n\n About this task \n\nThe F1 score provides an indication of the quality of the model. If the model performance results are good, you might want to store a version of the component before changing any of the resources. If changes that you make result in poorer quality, you can revert to a version that you stored. When you revert to an older version, all annotation tasks are archived because they are no longer valid.\n\nYou can have a maximum of 10 versions of a workspace. If you reach that limit, delete older versions or versions that you no longer need before creating a new version.\n\nWhen you create a new version, the following resources are captured:\n\n\n\n* Type system\n* Corpus\n* Ground truth\n* Machine learning model\n* Machine learning model evaluation results\n\n\n\nThe following resources are excluded:\n\n\n\n* Annotation tasks, because they are temporal by design, used only for determining ground truth\n* Dictionaries, because dictionaries can be large, and various types of dictionaries are managed in different ways\n\n\n\n\n\n\n\n Procedure \n\nTo create and restore machine learning model versions:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Performance. Performance statistics about the current version, labeled version 1.0, are displayed.\n3. To take a snapshot of the current version, click Machine Learning Model > Versions, and then click Take Snapshot. The resources in version 1.0 are frozen, and a new version, labeled 1.1, becomes the current version. For each new version that you create, the minor version number is incremented, for example, 1.0 becomes 1.1 and then becomes 1.2.\n4. Revise the workspace resources as needed, re-train, and re-evaluate the model.\n5.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-improve-ml"}, {"document_id": "ibmcld_16437-7-2129", "score": 18.94377, "text": "\nMaking machine learning model improvements \n\nAfter you determine areas in which the model is having trouble, take steps to improve its performance.\n\n\n\n Creating model versions \n\nAfter you create a machine learning model, you can take a snapshot to keep a backup version of the current resources in case you want to restore the resources in a future iteration.\n\n\n\n About this task \n\nThe F1 score provides an indication of the quality of the model. If the model performance results are good, you might want to store a version of the component before changing any of the resources. If changes that you make result in poorer quality, you can revert to a version that you stored. When you revert to an older version, all annotation tasks are archived because they are no longer valid.\n\nYou can have a maximum of 10 versions of a workspace. If you reach that limit, delete older versions or versions that you no longer need before creating a new version.\n\nWhen you create a new version, the following resources are captured:\n\n\n\n* Type system\n* Corpus\n* Ground truth\n* Machine learning model\n* Machine learning model evaluation results\n\n\n\nThe following resources are excluded:\n\n\n\n* Annotation tasks, because they are temporal by design, used only for determining ground truth\n* Dictionaries, because dictionaries can be large, and various types of dictionaries are managed in different ways\n\n\n\n\n\n\n\n Procedure \n\nTo create and restore machine learning model versions:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Performance. Performance statistics about the current version, labeled version 1.0, are displayed.\n3. To take a snapshot of the current version, click Machine Learning Model > Versions, and then click Take Snapshot. The resources in version 1.0 are frozen, and a new version, labeled 1.1, becomes the current version. For each new version that you create, the minor version number is incremented, for example, 1.0 becomes 1.1 and then becomes 1.2.\n4. Revise the workspace resources as needed, re-train, and re-evaluate the model.\n5.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-improve-ml"}, {"document_id": "ibmcld_16495-3299-5420", "score": 18.843632, "text": "\nYou might need to make modifications while you train a model, based on the performance statistics. But, generally, you want the type system to be as close to final as possible before you begin large-scale annotation tasks. If you change the type system after human annotators began their work, they must revisit the documents that they annotated. They must assess the applicability of the type system changes.\n\n\n\n About this task \n\nThis process propagates the current type system, ground truth editor keyboard shortcuts, and color settings to all document sets in a task.\n\n\n\n\n\n Procedure \n\nTo modify the type system without losing the work that was done by human annotators:\n\n\n\n1. Change the type system. For example, you can add or remove entity types or relation types.\n2. Decide whether you want to propagate the changes to existing human annotation tasks.\n3. Open the Machine Learning Model > Annotations page and click the Annotation Tasks tab. Open each task that you want to update and click Apply Type System Updates.\n\nIf you removed entity types or relation types from the type system, all occurrences of those types are highlighted in gray in the documents. These invalid types are ignored by the machine learning model. They do not prevent you from submitting and approving document sets.\n4. Provide details to the human annotators about what changed in the type system.\n5. Ask human annotators to update their documents to reflect the changes in the type system. For example, if you added new entity types or relation types, they must review their documents and annotate them appropriately.\n\n> Note: If the task contains completed documents, human annotators cannot alter those documents to assess type system changes until they are back in an editable state. To become editable, ask human annotators to submit the document sets so that you can reject them.\n\n\n\nRelated concepts:\n\n[Type systems](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-typesystemwks_typesystem)\n\n\n\n\n\n\n\n Document set management \n\nUse the right sets of data to test and train the model at the right time.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-improve-ml"}, {"document_id": "ibmcld_16437-3299-5354", "score": 18.73566, "text": "\nYou might need to make modifications while you train a model, based on the performance statistics. But, generally, you want the type system to be as close to final as possible before you begin large-scale annotation tasks. If you change the type system after human annotators began their work, they must revisit the documents that they annotated. They must assess the applicability of the type system changes.\n\n\n\n About this task \n\nThis process propagates the current type system, ground truth editor keyboard shortcuts, and color settings to all document sets in a task.\n\n\n\n\n\n Procedure \n\nTo modify the type system without losing the work that was done by human annotators:\n\n\n\n1. Change the type system. For example, you can add or remove entity types or relation types.\n2. Decide whether you want to propagate the changes to existing human annotation tasks.\n3. Open the Machine Learning Model > Annotations page and click the Annotation Tasks tab. Open each task that you want to update and click Apply Type System Updates.\n\nIf you removed entity types or relation types from the type system, all occurrences of those types are highlighted in gray in the documents. These invalid types are ignored by the machine learning model. They do not prevent you from submitting and approving document sets.\n4. Provide details to the human annotators about what changed in the type system.\n5. Ask human annotators to update their documents to reflect the changes in the type system. For example, if you added new entity types or relation types, they must review their documents and annotate them appropriately.\n\n> Note: If the task contains completed documents, human annotators cannot alter those documents to assess type system changes until they are back in an editable state. To become editable, ask human annotators to submit the document sets so that you can reject them.\n\n\n\nRelated concepts:\n\n[Type systems](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-typesystemwks_typesystem)\n\n\n\n\n\n\n\n Document set management", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-improve-ml"}, {"document_id": "ibmcld_16563-20012-20766", "score": 18.402117, "text": "\nFor example, you might want to take a snapshot before you retrain the model. If the statistics are poorer the next time you train it, you can promote the older version and delete the version that returned poorer results.\n\n\n\n\n\n\n\n Results \n\nYou created a machine learning model, trained it, and evaluated how well it performed when annotating test data and blind data. By exploring the performance metrics, you can identify ways to improve the accuracy of the machine learning model.\n\n\n\n\n\n\n\n Tutorial summary \n\nYou created a machine learning model.\n\n\n\n Lessons learned \n\nBy completing this tutorial, you learned about the following concepts:\n\n\n\n* Document sets\n* Machine learning models\n* Human annotation tasks\n* Inter-annotator agreement and adjudication", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"}, {"document_id": "ibmcld_03369-153104-155424", "score": 18.319256, "text": "\nNote that the Watson Assistant service learning models may have been updated as part of this enhancement, and when you retrain your model any changes will be applied.\n\n\n\n\n\n 3 October 2017 \n\nPattern-defined entities (Beta)\n: You can now define specific patterns for an entity, using regular expressions. This can help you identify entities that follow a defined pattern, for example SKU or part numbers, phone numbers, or email addresses. See [Pattern-defined entities](https://cloud.ibm.com/docs/assistant?topic=assistant-entitiesentities-patterns) for additional details.\n\n\n\n* You can add either synonyms or patterns for a single entity value; you cannot add both.\n* For each entity value, there can be a maximum of up to 5 patterns.\n* Each pattern (regular expression) is limited to 128 characters.\n* Importing or exporting via a CSV file does not currently support patterns.\n* The REST API does not support direct access to patterns, but you can retrieve or modify patterns using the /values endpoint.\n\n\n\nFuzzy matching filtered by dictionary (English only)\n: An improved version of fuzzy matching for entities is now available, for English. This improvement prevents the capturing of some common, valid English words as fuzzy matches for a given entity. For example, fuzzy matching will not match the entity value like to hike or bike, which are valid English words, but will continue to match examples such as lkie or oike.\n\n\n\n\n\n 27 September 2017 \n\nCondition builder updates\n: The control that is displayed to help you define a condition in a dialog node has been updated. Enhancements include support for listing available context variable names after you enter the $ to begin adding a context variable.\n\n\n\n\n\n 31 August 2017 \n\nImprove section rollback\n: The median conversation time metric, and corresponding filters, are being temporarily removed from the Overview page of the Improve section. This removal will prevent the calculation of certain metrics from causing the median conversation time metric, and the conversations over time graph, to display inaccurate information. IBM regrets removing functionality from the tool, but is committed to ensuring that we are communicating accurate information to users.\n\nDialog node names\n: You can now assign any name to a dialog node; it does not need to be unique.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_03110-6742-7759", "score": 17.981562, "text": "\nBut given the nature of machine learning models and the nuance and subtlety of natural languages processing, you may find some discrepancies from version to version. If you find a major issue through your tests, you have the ability to switch your settings and use Previous to return to the prior behavior. In this event, we recommend you contact IBM and provide details of your test so that that IBM can support you in the steps to resolve the problem.\n\nIt's also recommended that you try the Beta version in one of your test systems after you upgrade. This gives you early visibility to changes that are likely to be delivered in a future version, and will reduce the probability of negative impacts to your production systems. IBM values both positive and negative feedback from customers who use Beta. You will have the opportunity to shape how the algorithms function before the version is promoted to Latest in a future version. If you choose Beta, your assistant always trains on the most current beta version.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-algorithm-version"}, {"document_id": "ibmcld_16436-12448-14593", "score": 17.902914, "text": "\nThrough training and refinement of example input data, the model can deliver accurate, repeatable results when it analyzes new data.\n* machine learning annotator\n\nSee [machine learning model](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-glossarygloss_M).\n* machine learning model\n\nA component that identifies entities and entity relationships according to a statistical model that is based on ground truth. The model applies past experience, such as training data, to determine or predict the correct outcome of future experiences based on characteristics of the data. These past experiences are captured in the form of a model by calculating feature scores for each candidate answer or evidence and combining that with known outcomes. Sometimes referred to as machine learning annotator.\n* mention\n\nA span of text that you consider relevant in your domain data. For example, in a type system about automotive vehicles, occurrences of terms like \"airbag\", \"Ford Explorer\", and \"child restraint system\" might be relevant mentions.\n\n\n\n\n\n\n\n N \n\n\n\n* named entity\n\nA concept in a domain that falls in to a well-defined category, such as names of organizations, locations, authors, or diseases.\n* natural language processing\n\nA field of artificial intelligence and linguistics that studies the problems inherent in the processing and manipulation of natural language, with an aim to increase the ability of computers to understand human languages.\n\n\n\n\n\n\n\n O \n\n\n\n* ontology\n\nAn explicit formal specification of the representation of the objects, concepts, and other entities that can exist in some area of interest and the relationships among them.\n\n\n\n\n\n\n\n P \n\n\n\n* part of speech (POS)\n\nIn a dictionary, individual lexical items are assigned part of speech (POS) tags. For example, the word 'fly' can be identified as a verb or a noun.\n* performance\n\nThe measurement of a Watson system in terms of accuracy, precision, and recall, for example, when answering questions, discovering relationships, or annotating text.\n* pre-annotation\n\nThe process of annotating a set of documents prior to human annotation.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-glossary"}]}
{"task_id": "20c2cbd18c16c12c9c2bbead6aef1a21<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16563-7-2056", "score": 19.622866, "text": "\nCreating a machine learning model \n\nThis tutorial helps you understand the process for building a machine learning model that you can deploy and use with other Watson services.\n\n\n\n Learning objectives \n\nAfter you complete the lessons in this tutorial, you will know how to perform the following tasks:\n\n\n\n* Create document sets\n* Pre-annotate documents\n* Create tasks for human annotators\n* Analyze inter-annotator agreement and adjudicate conflicts in annotated documents\n* Create machine learning models\n\n\n\nThis tutorial takes approximately 60 minutes to finish. If you explore other concepts that are related to this tutorial, it might take longer to complete.\n\n\n\n\n\n Before you begin \n\n\n\n* You're using a supported browser. See [Browser requirements](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-system-requirements).\n* You successfully completed [Getting started with Knowledge Studio](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutintro), which covers creating a workspace, creating a type system, and adding a dictionary.\n* You must have at least one user ID in either the Admin or Project Manager role.\n\nIf possible, use multiple user IDs for the machine learning model tasks in this tutorial (one Admin or Project Manager user ID, and at least two Human Annotator user IDs). Using multiple user IDs provides the most realistic simulation of an actual IBM Watson\u00ae Knowledge Studio workspace, where a project manager must coordinate and adjudicate annotation that is performed by multiple human annotators. However, if you have access to only a single user ID, you can still simulate most parts of the process.\n\nFor more information about user roles, see [User roles in Knowledge Studio](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-roles).\n\n\n\n\n\n\n\n Results \n\nAfter completing this tutorial, you will have a custom machine learning model that you can use with other Watson services.\n\n\n\n\n\n Lesson 1: Adding documents for annotation", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"}, {"document_id": "ibmcld_16464-7-2089", "score": 19.230507, "text": "\nCreating a machine learning model \n\nThis tutorial helps you understand the process for building a machine learning model that you can deploy and use with other Watson services.\n\n\n\n Learning objectives \n\nAfter you complete the lessons in this tutorial, you will know how to perform the following tasks:\n\n\n\n* Create document sets\n* Pre-annotate documents\n* Create tasks for human annotators\n* Analyze inter-annotator agreement and adjudicate conflicts in annotated documents\n* Create machine learning models\n\n\n\nThis tutorial takes approximately 60 minutes to finish. If you explore other concepts that are related to this tutorial, it might take longer to complete.\n\n\n\n\n\n Before you begin \n\n\n\n* You're using a supported browser. See [Browser requirements](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-system-requirements).\n* You successfully completed [Getting started with Knowledge Studio](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutintro), which covers creating a workspace, creating a type system, and adding a dictionary.\n* You must have at least one user ID in either the Admin or Project Manager role.\n\n> Note: If possible, use multiple user IDs for the machine learning model tasks in this tutorial (one Admin or Project Manager user ID, and at least two Human Annotator user IDs). Using multiple user IDs provides the most realistic simulation of an actual IBM Watson\u2122 Knowledge Studio workspace, where a project manager must coordinate and adjudicate annotation that is performed by multiple human annotators. However, if you have access to only a single user ID, you can still simulate most parts of the process.\n\nFor information about user roles, see [User roles in Knowledge Studio](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-roles).\n\n\n\n\n\n\n\n Results \n\nAfter completing this tutorial, you will have a custom machine learning model that you can use with other Watson services.\n\n\n\n\n\n Lesson 1: Adding documents for annotation", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}, {"document_id": "ibmcld_16524-7-2263", "score": 19.016043, "text": "\nTraining the machine learning model \n\nIn IBM Watson\u00ae Knowledge Studio , the creation of the machine learning model involves training the machine learning model and evaluating how well the model performed when annotating test data and blind data.\n\n\n\n Creating a machine learning model \n\nWhen you create a machine learning model, you select the document sets that you want to use to train the model and specify the percentage of documents that are to be used as training data, test data, and blind data.\n\n\n\n About this task \n\nBy exploring the performance metrics, you can identify ways to improve the model's accuracy.\n\n> Restriction: Only three machine learning models can be trained at a time per Knowledge Studio instance. If your instance contains multiple workspaces and the number of machine learning models that are being trained in other workspaces totals 3 already, then your request to train the machine learning model in your workspace will be queued until the other training processes are done.\n\n\n\n\n\n Procedure \n\nTo create a machine learning model:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Select Machine Learning Model > Performance.\n3. Verify that all of the document sets have been approved and that all annotation conflicts have been resolved through adjudication. Only documents that have become ground truth through adjudication or approval can be used to train the model.\n4. Click Train and evaluate.\n5. Optional: To specify how you want to allocate documents from your document sets to be used by the system-level training, test, or blind sets, click Edit settings.\n\nSee [Document set management](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-improve-mlwks_mamanagedata) for help determining which ratios to apply.\n6. Click Train to train the model, or click Train & Evaluate to train the model, evaluate annotations added by the machine learning model, and analyze the performance statistics.\n\n> Important: Training a machine learning model can take several minutes or several hours, depending on the number of human annotations that exist and the total number of words across all documents.\n7. Select the document sets that you want to use for training the model.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-train-ml"}, {"document_id": "ibmcld_16464-20282-21209", "score": 18.869282, "text": "\n10. Click Versions. On the Versions page, you can take a snapshot of the model and the resources that were used to create it (except for dictionaries and annotation tasks). For example, you might want to take a snapshot before you retrain the model. If the statistics are poorer the next time you train it, you can promote the older version and delete the version that returned poorer results.\n\n\n\n\n\n\n\n Results \n\nYou created a machine learning model, trained it, and evaluated how well it performed when annotating test data and blind data. By exploring the performance metrics, you can identify ways to improve the accuracy of the machine learning model.\n\n\n\n\n\n\n\n Tutorial summary \n\nYou created a machine learning model.\n\n\n\n Lessons learned \n\nBy completing this tutorial, you learned about the following concepts:\n\n\n\n* Document sets\n* Machine learning models\n* Human annotation tasks\n* Inter-annotator agreement and adjudication", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}, {"document_id": "ibmcld_16563-16867-19031", "score": 18.840416, "text": "\nLesson 7: Creating a machine learning model \n\nIn this lesson, you will learn how to create a machine learning model in Knowledge Studio.\n\n\n\n About this task \n\nWhen you create a machine learning model, you select the document sets that you want to use to train it. You also specify the percentage of documents that are to be used as training data, test data, and blind data. Only documents that became ground truth through approval or adjudication can be used to train the machine learning model.\n\nFor more information about the machine learning model, see [Training the machine learning model](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-train-ml) and [Analyzing machine learning model performance](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-evaluate-ml).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator.\n2. Click Machine Learning Model > Performance > Train and evaluate.\n3. Select All, and then click Train & Evaluate.\n\nTraining might take more than ten minutes, or even hours, depending on the number of human annotations and the number of words in all the documents.\n4. After the machine learning model is trained, you can export it from the Version page, or you can view detailed information about its performance by clicking the Detailed Statistics links that are located above each of the graphs on the Performance page.\n5. To view the Training / Test / Blind Sets page, click the Train and evaluate button.\n6. To see the documents that human annotators worked on, click View Ground Truth.\n7. To see the annotations that the trained machine learning model created on that same set of documents, click View Decoding Results.\n8. To view details about the precision, recall, and F1 scores for the machine learning model, click the Performance page.\n9. Click the Detailed Statistics links above each of the graphs. On these Statistics pages, you can view the scores for mentions, relations, and coreference chains by using the radio buttons.\n\nYou can analyze performance by viewing a summary of statistics for entity types, relation types, and coreference chains.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"}, {"document_id": "ibmcld_13129-1604-3452", "score": 18.766401, "text": "\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. The admin uploads a CSV file from a local machine.\n2. The uploaded CSV file is stored in IBM Cloud Object Storage service as a dataset.\n3. The dataset is then used to build and deploy a machine learning model. The deployed model is exposed as an API (scoring-endpoint).\n4. The user makes an API call to predict the outcome with the test data.\n5. The deployed machine learning model is monitored for quality, accuracy and other key parameters with the test data.\n\n\n\n\n\n\n\n Step 1: Import data to a project \n\nA project is how you organize your resources to achieve a particular goal. Your project resources can include data, collaborators, and analytic tools like Jupyter notebooks and machine learning models.\n\nYou can create a project to add data and open a data asset in the data refiner for cleansing and shaping your data.\n\n\n\n Create a project \n\n\n\n1. If you do not have an existing Object Storage service, go to the [IBM Cloud\u00ae catalog](https://cloud.ibm.com/catalog) and create an instance of [Object Storage](https://cloud.ibm.com/objectstorage/create).\n2. From the [catalog](https://cloud.ibm.com/catalog), create [Watson Studio](https://cloud.ibm.com/catalog/services/data-science-experience?taxonomyNavigation=app-services)\n\n\n\n1. Select a region\n2. Select a Lite pricing plan\n3. Change the Service name to watson-studio-tutorial\n4. Select a resource group and click Create\n\n\n\n3. Click on the Launch in IBM Cloud Pak for Data button.\n4. Create a project by clicking on New project under the Projects tile and then in the subsequent page click Create an empty project.\n5. Provide iris_project as the project name and Leave the Restrict who can be a collaborator checkbox unchecked as there's no confidential data.\n6. Under Storage, choose an existing Object Storage service.\n7. Click Create.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-create-deploy-retrain-machine-learning-model"}, {"document_id": "ibmcld_16451-7-2278", "score": 18.759348, "text": "\nTraining the machine learning model \n\nIn IBM Watson\u2122 Knowledge Studio for IBM Cloud Pak for Data, the creation of the machine learning model involves training the machine learning model and evaluating how well the model performed when annotating test data and blind data.\n\n\n\n Creating a machine learning model \n\nWhen you create a machine learning model, you select the document sets that you want to use to train the model and specify the percentage of documents that are to be used as training data, test data, and blind data.\n\n\n\n About this task \n\nBy exploring the performance metrics, you can identify ways to improve the model's accuracy.\n\nOnly three machine learning models can be trained at a time per Knowledge Studio instance. If your instance contains multiple workspaces and the number of machine learning models that are being trained in other workspaces totals 3 already, then your request to train the machine learning model in your workspace will be queued until the other training processes are done.\n\n\n\n\n\n Procedure \n\nTo create a machine learning model:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Select Machine Learning Model > Performance.\n3. Verify that all of the document sets have been approved and that all annotation conflicts have been resolved through adjudication. Only documents that have become ground truth through adjudication or approval can be used to train the model.\n4. Click Train and evaluate.\n5. Optional: To specify how you want to allocate documents from your document sets to be used by the system-level training, test, or blind sets, click Edit settings.\n\nFor more information about which ratios to apply, see [Document set management](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-improve-mlwks_mamanagedata).\n6. Click Train to train the model, or click Train & Evaluate to train the model, evaluate annotations added by the machine learning model, and analyze the performance statistics.\n\nTraining a machine learning model can take several minutes or several hours, depending on the number of human annotations that exist and the total number of words across all documents.\n7. Select the document sets that you want to use for training the model.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-train-ml"}, {"document_id": "ibmcld_16563-20012-20766", "score": 18.622862, "text": "\nFor example, you might want to take a snapshot before you retrain the model. If the statistics are poorer the next time you train it, you can promote the older version and delete the version that returned poorer results.\n\n\n\n\n\n\n\n Results \n\nYou created a machine learning model, trained it, and evaluated how well it performed when annotating test data and blind data. By exploring the performance metrics, you can identify ways to improve the accuracy of the machine learning model.\n\n\n\n\n\n\n\n Tutorial summary \n\nYou created a machine learning model.\n\n\n\n Lessons learned \n\nBy completing this tutorial, you learned about the following concepts:\n\n\n\n* Document sets\n* Machine learning models\n* Human annotation tasks\n* Inter-annotator agreement and adjudication", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"}, {"document_id": "ibmcld_07028-1792-3496", "score": 18.552588, "text": "\nTo add a Machine Learning model, complete the following steps:\n\n\n\n1. Create the model and export it from the tool you use to create it.\n\nFor more information, see the following documentation:\n\n\n\n* Knowledge Studio for IBM Cloud Pak\u00ae for Data\n\n\n\n* [Creating a rule-based model](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-rule-annotator)\n* [Creating a machine learning model](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-ml_annotator)\n\n\n\n* Knowledge Studio for IBM Cloud\n\n\n\n* [Creating a rule-based model](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-rule-annotator)\n* [Creating a machine learning model](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-ml_annotator)\n\n\n\n* [Watson Explorer Content Analytics Studio](https://www.ibm.com/docs/en/watson-explorer/12.0.x?topic=analytics-content-studio-advanced-text)\n\nYou must export the model from Watson Explorer Content Analytics Studio as a UIMA PEAR file. For more information, see: [Creating Custom PEAR Files for use with Lexical Analysis Streams](https://www.ibm.com/docs/en/watson-explorer/12.0.x?topic=las-creating-custom-pear-files-use-lexical-analysis-streams).\n* [Discovery entity extractor](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-entity-extractorentity-extractor-export)\n\n\n\n2. From the Teach domain concepts section of the Improvement tools panel, and then click Import machine learning models.\n3. Specify a name for the model, and then choose the language that was used to define the model.\n4. Click Upload to browse for the file that you exported earlier.\n5.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-domain-ml"}, {"document_id": "ibmcld_13129-7-1929", "score": 18.443787, "text": "\nBuild, deploy, test and monitor a predictive machine learning model \n\nThis tutorial may incur costs. Use the [Cost Estimator](https://cloud.ibm.com/estimator/review) to generate a cost estimate based on your projected usage.\n\nThis tutorial walks you through the process of building a predictive machine learning model, deploying the generated model as an API to be used in your applications and testing the model all of this happening in an integrated and unified self-service experience on IBM Cloud. You will then monitor the deployed model with IBM Watson OpenScale.\n\nIn this tutorial, the Iris flower data set is used for creating a machine learning model to classify species of flowers.\n\nIn the terminology of machine learning, classification is considered an instance of supervised learning, i.e. learning where a training set of correctly identified observations is available.\n\nWatson Studio provides you with the environment and tools to solve your business problems by collaboratively working with data. You can choose the tools you need to analyze and visualize data, to cleanse and shape data, to ingest streaming data, or to create and train machine learning models.\n\n\n\n Objectives \n\n\n\n* Import data to a project.\n* Build a machine learning model.\n* Deploy the model and try out the API.\n* Test a machine learning model.\n* Monitor the deployed model\n* Retrain your model.\n\n\n\nZoom\n\n![Architecture Diagram](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution22-build-machine-learning-model/architecture_diagram.png)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. The admin uploads a CSV file from a local machine.\n2. The uploaded CSV file is stored in IBM Cloud Object Storage service as a dataset.\n3. The dataset is then used to build and deploy a machine learning model. The deployed model is exposed as an API (scoring-endpoint).\n4.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-create-deploy-retrain-machine-learning-model"}]}
{"task_id": "20c2cbd18c16c12c9c2bbead6aef1a21<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04170-7-2189", "score": 19.219557, "text": "\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https://research.google/pubs/pub45581/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with /cdn-cgi/challenge-platform/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under /cdn-cgi/challenge-platform/ is allowed.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections"}, {"document_id": "ibmcld_04105-3403-5572", "score": 18.325104, "text": "\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04334-40577-42576", "score": 17.352196, "text": "\n* email_obfuscation: Encrypt email addresses on your web page from bots while keeping them visible to humans.\n* opportunistic_onion: Allow legitimate users of Tor Browser to access your websites.\n* hotlink_protection: Protect your images from off-site linking.\n* http2: Accelerate your website with HTTP/2.\n* http3: Accelerate your website with HTTP/3.\n* image_load_optimization: Improve load time for pages that include images on mobile devices with slow network connections.\n* image_size_optimization: Improve image load time by optimizing images hosted on your domain.\n* ip_geolocation: Include the country code of the visitor location with all requests to your website.\n* ipv6: Enable IPv6 support and gateway.\n* max_upload: The amount of data visitors can upload to your website in a single request.\n* min_tls_version: Only allow HTTPS connections from visitors that support the selected TLS protocol version or newer.\n* minify: Reduce the file size of source code on your website.\n* mobile_redirect: Redirect visitors that are using mobile devices to a mobile-optimized website.\n* opportunistic_encryption: Opportunistic Encryption allows browsers to benefit from the improved performance of HTTP/2 by letting them know that your site is available over an encrypted connection.\n* origin_error_page_pass_thru: When Origin Error Page is set to On, CIS will proxy the 502 and 504 error pages directly from the origin. (Enterprise plan only)\n* prefetch_preload: CIS will prefetch any URLs included in the prefetch HTTP header (Enterprise plan only).\n* pseudo_ipv4: Adds an IPv4 header to requests when a client is using IPv6, but the server only supports IPv4.\n* response_buffering: Enable or disable buffering of responses from the origin server (Enterprise plan only).\n* script_load_optimization: Improve the paint time for pages that include JavaScript.\n* security_header: Enforce web security policy for your website.\n* security_level: Choose the appropriate security profile for your website.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_04105-5067-6335", "score": 16.845877, "text": "\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04179-1360-3455", "score": 16.577463, "text": "\nAny records that cannot be proxied through CIS, and that still use your origin IP, such as FTP, can be secured by creating additional obfuscation. In particular, if you require a record for your origin that cannot be proxied by CIS, use a non-standard name. For example, instead of ftp.example.com use [random word or-random characters].example.com. This obfuscation makes dictionary scans of your DNS records less likely to expose your origin IP addresses.\n\n\n\n\n\n Use separate IP ranges for HTTP and non-HTTP traffic if possible \n\nSome customers use separate IP ranges for HTTP and non-HTTP traffic, thereby allowing them to proxy all records pointing to their HTTP IP range, and to obscure all non-HTTP traffic with a different IP subnet.\n\n\n\n\n\n\n\n Best practice 2: Configure your security level selectively \n\nYour Security Level establishes the sensitivity of our IP Reputation Database. To prevent negative interactions or false positives, configure your Security Level by domain to heighten security where necessary, and to decrease it where appropriate.\n\n\n\n Increase the security level for sensitive areas to 'High' \n\nYou can increase this setting from the Advanced Security page for your domain or by adding a Page Rule for administration pages or login pages, to reduce brute-force attempts:\n\n\n\n1. Create a Page Rule with the URL pattern of your API (for example, www.example.com/wp-login).\n2. Identify the Security Level setting.\n3. Mark the setting as High.\n4. Select Provision Resource.\n\n\n\n\n\n\n\n Decrease the security level for non-sensitive paths or APIs to reduce false positives \n\nThis setting can be decreased for general pages and API traffic:\n\n\n\n1. Create a Page Rule with the URL pattern of your API (for example, www.example.com/api/).\n2. Identify the Security Level setting.\n3. Turn Security Level to Low or Essentially off.\n4. Select Provision Resource.\n\n\n\n\n\n\n\n What do security level settings mean? \n\nOur security level settings are aligned with threat scores that certain IP addresses acquire from malicious behavior on our network. A threat score above 10 is considered high.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-manage-your-ibm-cis-for-optimal-security"}, {"document_id": "ibmcld_04193-4202-4977", "score": 16.544867, "text": "\nTo learn how to set up your account for connecting to a private network, see [Enabling VRF and service endpoints](https://cloud.ibm.com/docs/account?topic=account-vrf-service-endpoint).\n\n\n\n\n\n\n\n Step 3. Create a CIS resource on the private network \n\nTest your private network connection by using the [CIS CLI plug-in](https://cloud.ibm.com/docs/cis-cli-plugin?topic=cis-cli-plugin-cis-cli).\n\n\n\n1. Log into a CIS private endpoint instance.\n\nibmcloud login -a private.cloud.ibm.com\n\n\n\n\n\n\n\n\n\n Using the API \n\nUse the service endpoint's FQDN api.private.cis.cloud.ibm.com in the URL to access the service. For example:\n\ncurl https://api.private.cis.cloud.ibm.com/v1/:crn/zones -H 'content-type: application/json' -H 'accept: application/json' -H 'x-auth-user-token: Bearer xxxxxx'", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-service-endpoints"}, {"document_id": "ibmcld_12457-7573-9487", "score": 16.345863, "text": "\nSelect Resources based on selected attributes.\n5. In the Service instance field, select your CIS instance.\n6. In the Roles and actions section, select the Manager role. If you want to grant the service ID the ability to access the CIS instance from the Resource list in the IBM Cloud console, you can also assign the Viewer platform role.\n7. Click Review > Add > Assign to complete the access assignment.\n\n\n\n5. Complete the steps to [add a DNS configuration](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-add-dns-provider) to your Secrets Manager instance.\n\n\n\n\n\n\n\n\n\n Granting service access to classic infrastructure \n\nIf you manage domains by using classic infrastructure, you must grant service access to its DNS service so that Secrets Manager can validate the ownership of your domains. You need your classic infrastructure account credentials before you can grant access.\n\nTo obtain your classic infrastructure username and API key, you can use the Access (IAM) section of the console.\n\nYou can view and access your classic infrastructure credentials from the Access (IAM) section of the console only if you are a classic infrastructure user. If you do not have classic infrastructure access, the VPN username and classic infrastructure API key fields do not display on the page. For more information, see [Managing classic infrastructure access](https://cloud.ibm.com/docs/account?topic=account-mngclassicinfra).\n\nZoom\n\n![The figure shows a simplified IAM dashboard with numbered steps for viewing your classic infrastructure username and API key. The steps are described in the following text.](https://cloud.ibm.com/docs-content/v1/content/991f60ddbe3ab0a9aa69481a07a0a73b359fa329/secrets-manager/images/classic-infra-creds.svg)\n\nFigure 2. Viewing your classic infrastructure username and API key\n\n\n\n1. In the console, go to Manage > Access (IAM) > Users, then select the user's name.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-prepare-order-certificates&interface=ui"}, {"document_id": "ibmcld_01391-16119-17644", "score": 16.290379, "text": "\nFor a secured connection with HTTPS, you can either obtain a certificate from [Let's Encrypt](https://letsencrypt.org/) as described in the following [IBM Cloud\u00ae blog](https://www.ibm.com/cloud/blog/secure-apps-on-ibm-cloud-with-wildcard-certificates) or through [IBM Cloud Secrets Manager](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-public-certificates&interface=ui).\n\n\n\n\n\n Increase performance and protect from Denial of Service attacks \n\nA distributed denial of service ([DDoS](https://en.wikipedia.org/wiki/Denial-of-service_attack)) attack is a malicious attempt to disrupt normal traffic of a server, service, or network by overwhelming the target or its surrounding infrastructure with a flood of internet traffic. CIS is equipped to protect your domain from DDoS.\n\n\n\n1. In the CIS dashboard, select Reliability > Global Load Balancer.\n2. Locate the GLB you created in the Load Balancers table.\n3. Enable the Security and Performance features in the Proxy column:\n\nZoom\n\n![CIS Proxy Toggle ON](https://cloud.ibm.com/docs-content/v1/content/cbb80bf851fb762a838129cba09d5674f8bfffda/Registry/includes/solution-tutorials/includes/solution-tutorials/images/solution32-multi-region-k8s-cis/cis-proxy.png)\n\nCIS Proxy Toggle ON\n\n\n\nYour GLB is now protected. An immediate benefit is that the origin IP addresses of your clusters will be hidden from the clients. If CIS detects a threat for an upcoming request, the user may see a screen like this one before being redirected to your application:\n\nZoom\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-multi-region-k8s-cis"}, {"document_id": "ibmcld_13148-17032-19148", "score": 16.26543, "text": "\nOther services like Data Engine need to access buckets to perform data analysis. And yet another category of services need access to subscribe to change notifications to trigger the execution of actions.\n* [Event Notifications](https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-getting-started): To push out information about events to subscribers, service instances need to access an Event Notifications instance.\n* [Secrets Manager](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-getting-started): This service stores and provides to other services IAM API keys, SSL/TLS certificates, and other secrets. Hence, the dependent (source) services need to access Secrets Manager.\n* [Cloud Internet Services (CIS)](https://cloud.ibm.com/docs/cis?topic=cis-getting-started): It manages domain names and other network data and, therefore, can be used for, e.g., certificate validation.\n\n\n\nNote that the above list is not complete.\n\n\n\n\n\n\n\n\n\n Summary \n\nAccessing resources in different accounts, even sharing resources is common practice. There are several use cases where users benefit from resource sharing. They were discussed in the overview. A combination of user identity and password or an API key to access a resource often serves as authentication. Access can be scoped to a set of privileges, e.g., only allowing read access or some other restricted actions. Sometimes, these type of credentials can be created and managed by the accessing resource like an application or compute environment (\"service binding\"). An even tighter integration which does not require credentials is the concept of IBM Cloud service-to-service authorization. The accessing resource (source) and the accessed resource (target) are identified by their properties (authentication) and an access role is assigned (authorization). Such a relationship can be even established across account boundaries. This allows for a simple to configure, but yet secure cross-account resource sharing.\n\n\n\nSummary of sharing and reuse capabilities across services\n\n Service Capability \n\n Security and Observability", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-resource-sharing"}, {"document_id": "ibmcld_04107-4464-6614", "score": 16.23822, "text": "\n* Specific URLs - For example, you can allow IP 1.2.3.4 access to directory example.com/foo/ and allow IP 5.6.7.8 access to directory example.com/bar/, but not allow the reverse.\n\n\n\nThis capability is useful when you need more granularity in your access rules because, with IP rules, you can either apply the block to all subdomains of the current domain, or all domains on your account. You cannot specify URIs.\n\n\n\n\n\n\n\n Firewall rules \n\nCreate rules that examine incoming HTTP traffic against a set of filters to block, challenge, log, or allow matching requests.\n\nIn general, firewall rules are designed for properties that are exposed in OSI Layer-7 (HTTP), such as request headers and body content characteristics. Therefore, firewall rules apply to HTTP/HTTPS [Range](https://cloud.ibm.com/docs/cis?topic=cis-cis-range) apps.\n\n\n\n\n\n Events \n\nView events that are triggered by an active web application firewall rule. For each event, you can change the triggered action based on the requesting IP address, or the requesting region as a whole.\n\n\n\n\n\n Range \n\nExtend the power of CIS DDoS, TLS, and IP firewall to your web servers and your TCP-based services by using Range applications, keeping them online and secure.\n\n\n\n\n\n Advanced security \n\nAdvanced security settings include the following features, which you can change, enable, or disable.\n\n\n\n* Browser integrity check - The browser integrity check looks for HTTP headers that are commonly abused by spammers. It denies traffic with those headers access to your page. It also blocks or challenges visitors that do not have a user agent, or who add a nonstandard user agent. This tactic is commonly used by abuse bots, crawlers, or APIs.\n* Challenge passage - Controls how long a visitor that passed a challenge (or JavaScript challenge) gains access to your site before they are challenged again. This challenge is based on the visitor's IP, and therefore does not apply to challenges presented by WAF rules because they are based on an action that the user performs on your site.\n* Security level - Sets the security level of your website to determine which visitors receive a challenge page.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-ibm-cloud-internet-services-cis"}]}
{"task_id": "20c2cbd18c16c12c9c2bbead6aef1a21<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_12498-7-2091", "score": 16.79545, "text": "\nWhat is a secret? \n\nA secret is a piece of sensitive information. For example, an API key, password, or any type of credential that you might use to access a confidential system.\n\nBy using secrets, you're able to authenticate to protected resources as you build your applications. For example, when you try to access an external service API, you're asked to provide a unique credential. After you supply your credential, the external service can understand who you are and whether you're authorized to interact with it.\n\nTo learn more about the general characteristics of a secret, check out the following video.\n\n\n\n* Video transcript\n\nHow are you making sure that your secrets are securely stored so that you can avoid data breaches and chaos in your DevOps workflows?\n\nHi, I'm Alex Greer with the IBM Cloud team, and before I get started make sure to like and subscribe now.\n\nWhat is a secret?\n\nA secret is a digital credential that is going to allow entities to communicate and perform actions on a service. This discrete piece of information keeps that access point secure. So let's look at how this paradigm exists.\n\nLet's start with an entity here that needs to access some sort of service. We'll leave it little ambiguous for now, but some sort of service. To properly communicate with the service and be able to take the action that it needs to get its job done, this entity is going to need to communicate to the service two things: One, who it is, so that service can understand what or who is interacting with it. Two, it's going to have to know the set of permissions that it should grant in the context of its service. With these, the service can now properly allow that entity to interact with them. How we enable this interaction is with something we call a \"secret.\"\n\nNow, with this dynamic established, let's move into an example with users. For users, we'll say that this user here is our entity, and we'll say our service here \u2013 let's say that it's a developer, and they happen to need read or write access. They're interacting with the development repo to do that.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret"}, {"document_id": "ibmcld_07982-7-2122", "score": 16.423466, "text": "\nHandling and securing secrets \n\nA secret is any piece of data that is sensitive within the context of an application or service. Secrets must be securely protected through their entire lifecycle.\n\nSecrets include all of the following but are not limited to:\n\n\n\n* Passwords of any type (database logins, OS accounts, functional IDs, and so on)\n* API keys\n* Long-lived authentication tokens (OAuth2, GitHub, IAM, and so on)\n* SSH keys\n* Encryption keys\n* Other private keys (PKI/TLS certificates, HMAC keys, signing keys, and so on)\n\n\n\nApplication providers should ensure:\n\n\n\n* Secrets are generated and stored in the environment (for example, dev, test, and production) where your service is deployed.\n* Secrets never leave their environments (for example, dev, test, and production) and should be secured by using access control measures. Service design should minimize the number of machines and people with access to secrets by using both authorization and network restrictions based on the principle of least privilege.\n* Secrets are rotated in according with the requirements of the IBM Cloud Framework for Financial Services with minimal or no downtime.\n* Secrets are never stored in source code, configuration files, or documentation.\n\n\n\nThe following table lists the different solutions that you can use to protect your application secrets.\n\n\n\nTable 1. Secrets management and data protection scenarios\n\n Scenario What to use \n\n You need to create, lease, and manage API keys, credentials, database configurations, and other secrets for your services and applications. Use [IBM Cloud Secrets Manager](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-getting-started). \n You need to generate, renew, and manage TLS/SSL certificates for your deployments. Use [IBM Cloud Secrets Manager](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-getting-started). \n You need to create and manage encryption keys. Use [Hyper Protect Crypto Services](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-overview) to manage encryption keys in a single-tenant service with dedicated hardware.", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-shared-secrets"}, {"document_id": "ibmcld_12415-7-1973", "score": 13.790731, "text": "\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https://cloud.ibm.com/docs/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-faqs"}, {"document_id": "ibmcld_12348-1227-2514", "score": 13.788377, "text": "\n(https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret)[![carousel thumbnail](https://cloud.ibm.com/docs-content/v1/content/secrets-manager//images/secure-manage-secrets-video-thumbnail.png)<br><br>Securely managing your cloud secrets with Secrets Manager](https://www.youtube.com/watch?v=rOp7aGyavnk)\n\n Latest updates \n\n[View more](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-release-notes)17 April 2023 | Now available: new API and CLI versions\n\nThe new API, SDK, Terraform, and CLI versions offer more options to manage your Secrets Manager instance. The Secrets Manager API v1 has been deprecated in favor of v2.\n\n3 March 2023 | Now available: Terraform support\n\nSecrets Manager now supports Terraform.\n\n11 December 2022 | Support for context-based restrictions (CBR)\n\nManage user and service access to your Secrets Manager resources by using context-based restrictions.\n\n14 November 2022 | Manually configure your own DNS provider\n\nYour DNS provider isn't integrated with the service? You can now manually configure it by using the UI.\n\n18 October 2022 | Add custom metadata to your secret versions and auto-rotate IAM credentials\n\nDo you need more space to log details about your secret versions? Add relevant information as metadata.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager"}, {"document_id": "ibmcld_12960-7-1811", "score": 13.728886, "text": "\nConfiguring Secrets Manager \n\nIBM Cloud\u00ae Secrets Manager helps you to securely store and apply secrets for apps across IBM Cloud services.\n\nA secret is anything that provides access to sensitive information, such as an [API key](https://cloud.ibm.com/docs/account?topic=account-manapikey). You can use the Secrets Manager tool integration to access secrets, wherever they are required in the toolchain workflow.\n\nBefore you configure a Secrets Manager tool integration, make sure that you [provision an instance of the Secrets Manager service](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-create-instancecreate-instance-ui).\n\nYou can configure the Secrets Manager tool integration to identify secrets by name or by [Cloud Resource Name (CRN)](https://cloud.ibm.com/docs/account?topic=account-crn).\n\n\n\n Identifying secrets by name \n\nWhen you configure the Secrets Manager tool integration to identify secrets by name, your toolchain can access the following secret types:\n\n\n\n* Identity and Access Management (IAM) credentials secrets.\n* Arbitrary secrets that are stored in the Secrets Manager.\n\n\n\nFor more information about IAM credentials secrets, and Arbitrary secrets in Secrets Manager, see [Working with secrets of different types](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\nConfigure Secrets Manager to securely manage secrets that are part of your toolchain:\n\n\n\n1. If you are configuring this tool integration as you are creating the toolchain, in the Configurable Integrations section, click Secrets Manager. If Secrets Manager is defined as an optional tool integration, it is located under More Tools.\n2. If you have a toolchain and are adding this tool integration to it, from the IBM Cloud console, click the menu icon !", "title": "", "source": "https://cloud.ibm.com/docs/services/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager"}, {"document_id": "ibmcld_00894-7-1811", "score": 13.728886, "text": "\nConfiguring Secrets Manager \n\nIBM Cloud\u00ae Secrets Manager helps you to securely store and apply secrets for apps across IBM Cloud services.\n\nA secret is anything that provides access to sensitive information, such as an [API key](https://cloud.ibm.com/docs/account?topic=account-manapikey). You can use the Secrets Manager tool integration to access secrets, wherever they are required in the toolchain workflow.\n\nBefore you configure a Secrets Manager tool integration, make sure that you [provision an instance of the Secrets Manager service](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-create-instancecreate-instance-ui).\n\nYou can configure the Secrets Manager tool integration to identify secrets by name or by [Cloud Resource Name (CRN)](https://cloud.ibm.com/docs/account?topic=account-crn).\n\n\n\n Identifying secrets by name \n\nWhen you configure the Secrets Manager tool integration to identify secrets by name, your toolchain can access the following secret types:\n\n\n\n* Identity and Access Management (IAM) credentials secrets.\n* Arbitrary secrets that are stored in the Secrets Manager.\n\n\n\nFor more information about IAM credentials secrets, and Arbitrary secrets in Secrets Manager, see [Working with secrets of different types](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\nConfigure Secrets Manager to securely manage secrets that are part of your toolchain:\n\n\n\n1. If you are configuring this tool integration as you are creating the toolchain, in the Configurable Integrations section, click Secrets Manager. If Secrets Manager is defined as an optional tool integration, it is located under More Tools.\n2. If you have a toolchain and are adding this tool integration to it, from the IBM Cloud console, click the menu icon !", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager"}, {"document_id": "ibmcld_12353-1100-2351", "score": 13.136263, "text": "\n(https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret)[![carousel thumbnail](https://cloud.ibm.com/docs-content/v1/content/secrets-manager-cli-plugin//images/secure-manage-secrets-video-thumbnail.png)<br><br>Securely managing your cloud secrets with Secrets Manager](https://www.youtube.com/watch?v=rOp7aGyavnk)\n\n Latest updates \n\n[View more](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-release-notes)20 September 2021 | Now available: Order domain-validated TLS certificates from Let's Encrypt\n\nYou can now use Secrets Manager to order Let's Encrypt certificates that you can deploy to your apps and services. Check the full release notes for details.\n\n30 August 2021 | Now available: Certificate Manager to Secrets Manager migration scripts\n\nLooking to migrate your certificates from Certificate Manager into Secrets Manager? Take advantage of migration scripts to start your transition.\n\n20 June 2021 | Now available: Import your existing TLS certificates\n\nYou can now use Secrets Manager to import and manage certificates for your apps and service. This release also adds support for connecting to Secrets Manager from a Virtual Private Cloud (VPC) network. Check the full release notes for details.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager-cli-plugin"}, {"document_id": "ibmcld_12498-18607-20398", "score": 13.080673, "text": "\n[Checkmark icon](https://cloud.ibm.com/docs-content/v1/content/991f60ddbe3ab0a9aa69481a07a0a73b359fa329/icons/checkmark-icon.svg) \n\n\n\n\n\n\n\n\n\n What's in a secret? \n\nSecrets that you store with the service consist of metadata attributes and a secret value. While the metadata attributes help you to identify a secret, the secret value is the data that protected services need to authenticate and authorize you or your application.\n\nCheck out the following image to see how a secret is structured.\n\nZoom\n\n![This image shows the components of a secret. The information in the image is detailed in the surrounding content.](https://cloud.ibm.com/docs-content/v1/content/991f60ddbe3ab0a9aa69481a07a0a73b359fa329/secrets-manager//images/example-secret.svg)\n\nFigure 1. JSON representation of Secrets Manager secret\n\n\n\n1. The name, id, and description, and other common fields hold identifying information about a secret. These fields store the general attributes of your secret that you can use to understand its purpose and history.\n2. For most secret types, the secret_data object contains the actual value of your secret.\n\nWhen you use the Secrets Manager API to retrieve the value of a secret, the fields that you see in the secret_data object differ depending on the type of secret that you are inspecting. For example, the following truncated example shows how secret data is represented for an arbitrary secret.\n\n{\n\"name\": \"my-arbitrary-secret\",\n\"secret_type\": \"arbitrary\",\n...\n\"secret_data\": {\n\"payload\": \"The quick brown fox jumped over the lazy dog.\"\n}\n}\n\nIf you're working with IAM credentials, the secret data is listed alongside the other common fields that describe your secret. For example, the following truncated example shows how secret data is represented for an IAM credential.\n\n{", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret"}, {"document_id": "ibmcld_12498-1639-3565", "score": 13.00742, "text": "\nWith these, the service can now properly allow that entity to interact with them. How we enable this interaction is with something we call a \"secret.\"\n\nNow, with this dynamic established, let's move into an example with users. For users, we'll say that this user here is our entity, and we'll say our service here \u2013 let's say that it's a developer, and they happen to need read or write access. They're interacting with the development repo to do that. To gain that access again, coming back to the need, we have authorization and permission. How it's going to communicate, specifically in this circumstance, is by giving it user credentials. Now, that user can interact with the development repo in the way that they need to get their job done.\n\nNow, looking at a cloud native application story, we have many microservices that must talk to each other. So, let's look at that. Let's call it service \"A,\" that needs to interact with a database called \"DB\" and grab a piece of specific information that it needs to get its job done. What it needs, in the form of the secret here, is what we call \"DB configs.\" Again, this DB config is going to allow it to have the correct communication with the service by saying, this is who I am and this is what I came here to accomplish.\n\nBut now that we have our user credentials in our DB configs as examples of secrets, we realize the vulnerability that can be created here if these credentials were to fall into the wrong hands. And this is why it's so important to establish a centralized place to manage all these things as we build out more applications and microservices. As we have more of these, the problem becomes more complex. If it falls into the wrong hands, how is protected? How do we block it from getting to that point? How was that data isolated?\n\nWhen we look at the damage that this can cause, we're looking in the millions of dollars, for example, for a data breach.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret"}, {"document_id": "ibmcld_07578-1213887-1215935", "score": 12.891156, "text": "\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https://cloud.ibm.com/docs/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}]}
{"task_id": "20c2cbd18c16c12c9c2bbead6aef1a21<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09060-6596-8123", "score": 12.18907, "text": "\nTo protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional.The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date. If the expirationDate attribute is omitted, the key does not expire. \n key_type Optional.A boolean value that determines whether the key material can leave the service. When you set the extractable attribute to true, the service creates a standard key that you can store in your apps or services. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service.\n\nA successful POST api/v2/keys response returns the ID value for your key, along with other metadata. The ID is a unique identifier that is assigned to your key and is used for subsequent calls to the Key Protect API.\n\nOptional: Verify that the key was created by running the following call to get the keys in your Key Protect service instance.\n\n$ curl -X GET \"https://<regon>.kms.cloud.ibm.com/api/v2/keys\" -H \"accept: application/vnd.ibm.collection+json\" -H \"authorization: Bearer <IAM_token>\" -H \"bluemix-instance: <instance_ID>\"\n\n\n\n\n\n What's next \n\n\n\n* To find out more about programmatically managing your keys, [check out the Key Protect API reference doc](https://cloud.ibm.com/apidocs/key-protect).", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-create-standard-keys"}, {"document_id": "ibmcld_09513-12728-14481", "score": 12.111803, "text": "\nThis is applicable to EU-US and Swiss-US customers: [https://www.ibm.com/privacy/details/us/en/privacy_shield.html](https://www.ibm.com/privacy/details/us/en/privacy_shield.html)\n\nData Responsibility at IBM [https://www.ibm.com/blogs/policy/dataresponsibility-at-ibm/](https://www.ibm.com/blogs/policy/dataresponsibility-at-ibm/) If a government wants access to data held by IBM on behalf of a SaaS client, IBM would expect that government to deal directly with that client\n\nData Processing Addendum (GDPR)\n\n[https://www.ibm.com/support/customer/csol/terms/?id=Z126-7870&lc=en#detail-document](https://www.ibm.com/support/customer/csol/terms/?id=Z126-7870&lc=endetail-document)\n\n\n\n\n\n Data Privacy and Subject Rights \n\nIBM Privacy Statement IBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https://www.ibm.com/privacy/us/en/](https://www.ibm.com/privacy/us/en/)\n\nRight to Lodge a Complaint In the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https://www.ibm.com/scripts/contact/contact/us/en/privacy/](https://www.ibm.com/scripts/contact/contact/us/en/privacy/)\n\n\n\n\n\n NIST \n\nIBM Maximo Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n Data Leakage Prevention / Data Loss Prevention (DLP) \n\nIBM Cloud Delivery Services does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only.", "title": "", "source": "https://cloud.ibm.com/docs/mas-saas?topic=mas-saas-Security"}, {"document_id": "ibmcld_09109-6121-7923", "score": 11.42207, "text": "\n<br> <br>Important: To protect your privacy, do not store your personal data as metadata for your key. <br> <br>Each alias must be alphanumeric, case sensitive, and cannot contain spaces or special characters other than - or _. The alias cannot be a UUID and must not be a Key Protect reserved name: allowed_ip, key, keys, metadata, policy, policies. registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. \n key_description Optional.An extended description of your key. To protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional.The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date. If the expirationDate attribute is omitted, the key does not expire. \n key_material Required.The base64-encoded key material, such as a symmetric key, that you want to manage in the service. For more information, check out [Base64 encoding your key material](https://cloud.ibm.com/docs/key-protect?topic=key-protect-import-standard-keyshow-to-encode-standard-key-material). <br> <br>Ensure that the key material meets the following requirements: <br>A standard key can be up to 7,500 bytes in size. The key must be base64-encoded. \n key_type A boolean value that determines whether the key material can leave the service. <br> <br>When you set the extractable attribute to true, the service designates the key as a standard key that you can store in your apps or services. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-import-standard-keys"}, {"document_id": "ibmcld_09175-3817-5689", "score": 11.391652, "text": "\nKey Protect meets controls for global, industry, and regional compliance standards, including GDPR, HIPAA, and ISO 27001/27017/27018, and others.\n\nFor a complete listing of IBM Cloud compliance certifications, see [Compliance on the IBM Cloud](https://ibm.com/cloud/compliance).\n\n\n\n EU support \n\nKey Protect has extra controls in place to protect your Key Protect resources in the European Union (EU).\n\nIf you use Key Protect resources in the Frankfurt, Germany region to process personal data for European citizens, you can enable the EU Supported setting for your IBM Cloud account. To find out more, see [Enabling the EU Supported setting](https://cloud.ibm.com/docs/account?topic=account-eu-hipaa-supportedbill_eusupported) and [Requesting support for resources in the European Union](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatareusupported).\n\n\n\n\n\n General Data Protection Regulation (GDPR) \n\nThe GDPR seeks to create a harmonized data protection law framework across the EU. The regulation aims to give citizens back the control of their personal data, and impose strict rules on any entity that hosts and processes that data.\n\nIBM is committed to providing clients and IBM Business Partners with innovative data privacy, security, and governance solutions to assist them in their journey to GDPR readiness.\n\nTo ensure GDPR compliance for your Key Protect resources, [enable the EU supported setting](https://cloud.ibm.com/docs/account?topic=account-eu-hipaa-supportedbill_eusupported) for your IBM Cloud account. You can learn more about how Key Protect processes and protects personal data by reviewing the following addendums.\n\n\n\n* [IBM Key Protect for IBM Cloud Data Sheet Addendum (DSA)](https://www.ibm.com/software/reports/compatibility/clarity-reports/report/html/softwareReqsForProduct?deliverableId=180A0EC0658B11E5A8DABB56563AC132)", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-security-and-compliance"}, {"document_id": "ibmcld_02776-2010-4574", "score": 11.282586, "text": "\n* Technically Identifiable Personal Information (such as device IDs, usage-based identifiers, static IP address, and so on. - when linked to an individual)\n* Healthcare Information (data related to physical or mental health of an individual, or which otherwise reveals information about his or her health status)\n\n\n\n\n\n\n\n Usage Data \n\nWhen engaging in the Permitted Uses of the Service, Developer may collect certain information automatically, including, but not limited to the following (collectively \"Usage Data\"):\n\n\n\n* The types of devices being used for testing or development\n* IP addresses\n* Operating systems\n* The types of Internet browsers used\n* Unique device identifiers and other diagnostic data\n\n\n\n\n\n\n\n\n\n Use Of Data \n\nDeveloper uses the collected data for various purposes:\n\n\n\n* To perform development and testing of applications\n* To provide analysis or valuable information to improve development and testing\n* To monitor usage in development and testing\n* To detect, prevent, and address technical issues\n\n\n\n\n\n\n\n Transfer Of Data \n\nInformation, including Personal Data, may be transferred to \u2014 and maintained on \u2014 computers located outside of Developer\u2019s state, province, country or other governmental jurisdiction where the data protection laws may differ than those from Developer\u2019s jurisdiction.\n\nDeveloper will take all steps reasonably necessary to ensure that Personal Data is treated securely and in accordance with this Privacy Policy and applicable law. Developer will also ensure no transfer of Personal Data will take place to an organization or a country, unless there are adequate authorizations and controls in place including obtaining consent where necessary and ensuring the security of Personal Data.\n\n\n\n\n\n Disclosure Of Data \n\n\n\n Legal Requirements \n\nDeveloper may disclose Personal Data in the good faith belief that such action is necessary:\n\n\n\n* To comply with a legal obligation\n* To protect and defend the rights or property of Developer\n* To prevent or investigate possible wrongdoing in connection with development and testing activities\n* To protect the safety of Personal Data\n* To protect against legal liability\n\n\n\n\n\n\n\n\n\n Security Of Data \n\nDeveloper will strive to use appropriate means to protect all Personal Data used in performing the Permitted Uses of the Service.\n\n\n\n\n\n Service Providers \n\nDeveloper may employ third-party companies and individuals (\"Service Providers\") to facilitate Permitted Uses of the Service, including to perform development and testing, or to analyze development and testing activities.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-privacy-policy"}, {"document_id": "ibmcld_08515-6389-8309", "score": 11.207913, "text": "\nTo protect your privacy, do not store your personal data as metadata for your key. \n key_description An extended description of your key. To protect your privacy, do not store your personal data as metadata for your key. \n YYYY-MM-DD<br><br>HH:MM:SS.SS The date and time that the key expires in the system, in RFC 3339 format. If the expirationDate attribute is omitted, the key does not expire. \n key_material The base64 encoded key material, such as an existing key-wrapping key, that you want to store and manage in the service. For more information, see [Base64 encoding your key material](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-import-root-keysencode-key-material-root-key). Ensure that the key material meets the following requirements:<br><br><br><br> * The key must be 16, 24, or 32 bytes long, corresponding to 128, 192, or 256 bits.<br> * The key must be base64-encoded.<br><br><br> \n key_type A boolean value that determines whether the key material can leave the service. When you set the extractable attribute to false, the service designates the key as a root key that you can use for wrap or unwrap operations. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service. For more examples of PII, see section 2.2 of the [NIST Special Publication 800-122](https://www.nist.gov/publications/guide-protecting-confidentiality-personally-identifiable-information-pii).\n\nA successful POST api/v2/keys response returns the ID value for your key, along with other metadata. The ID is a unique identifier that is assigned to your key and is used for subsequent calls to the Hyper Protect Crypto Services key management service API.\n3. Optional: Verify that the key was added by running the following call to browse the keys in your Hyper Protect Crypto Services service instance.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-import-root-keys"}, {"document_id": "ibmcld_02776-3988-5695", "score": 11.074557, "text": "\n* To prevent or investigate possible wrongdoing in connection with development and testing activities\n* To protect the safety of Personal Data\n* To protect against legal liability\n\n\n\n\n\n\n\n\n\n Security Of Data \n\nDeveloper will strive to use appropriate means to protect all Personal Data used in performing the Permitted Uses of the Service.\n\n\n\n\n\n Service Providers \n\nDeveloper may employ third-party companies and individuals (\"Service Providers\") to facilitate Permitted Uses of the Service, including to perform development and testing, or to analyze development and testing activities.\n\nThese Service Providers have access to Personal Data only to perform these tasks on Developer\u2019s behalf and are obligated not to disclose or use it for any other purpose.\n\n\n\n\n\n Children's Privacy \n\nThe Permitted Use of the Service does not address anyone under the age of 18 (\"Children\").\n\nDeveloper does not knowingly collect Personal Data from anyone under the age of 18. If Developer becomes aware of the collection or processing of Personal Data from Children without verification of parental consent, Developer will take steps to remove that information from the default settings of App ID.\n\n\n\n\n\n Changes To This Privacy Policy \n\nThis Privacy Policy may be updated from time to time and any changes will be reflected by posting the new Privacy Policy on this page. Before the change becomes effective and updated, notification is made via prominent notice on our Service.\n\nThis Privacy Policy should be reviewed periodically for any changes. Changes to this Privacy Policy are effective when they are posted on this page.\n\n\n\n\n\n Contact Us \n\nFor any questions about this Privacy Policy, please contact the Developer.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-privacy-policy"}, {"document_id": "ibmcld_08433-6344-8271", "score": 11.072902, "text": "\nOne or more unique, human-readable aliases assigned to your key.<br><br>Important: To protect your privacy, do not store your personal data as metadata for your key.<br><br>Each alias must be alphanumeric, case-sensitive, and cannot contain spaces or special characters other than dashes (-) or underscores (_). The alias cannot be a version 4 UUID and must not be a Hyper Protect Crypto Services reserved name: allowed_ip, key, keys, metadata, policy, policies, registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. Alias size can be 2 - 90 characters (inclusive). \n key_description Optional: An extended description of your key.<br><br>Important: To protect your privacy, do not store your personal data as metadata for your key. \n YYYY-MM-DD<br><br>HH:MM:SS.SS Optional: The date and time that the key expires in the system, in RFC 3339 format. If the expirationDate attribute is omitted, the key does not expire. \n key_type A boolean value that determines whether the key material can leave the service.<br><br>When you set the extractable attribute to true, the service creates a standard key that you can store in your apps or services. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service. For more examples of PII, see section 2.2 of the [NIST Special Publication 800-122](https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-122.pdf).\n\nA successful POST /v2/keys response returns the ID value for your key, along with other metadata. The ID is a unique identifier that is assigned to your key and is used for subsequent calls to the Hyper Protect Crypto Services key management service API.\n3. Optional: Verify that the key was created by running the following call to get the keys in your Hyper Protect Crypto Services service instance.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-create-standard-keys"}, {"document_id": "ibmcld_02776-7-2525", "score": 11.046967, "text": "\nPrivacy policy: Default Facebook and Google settings \n\nEffective: August 2019 Client, hereinafter referred to as \"Developer\", performs development and testing of applications by using the default configuration of IBM Cloud\u00ae App ID (\"App ID\" or \"Service\") for Facebook or Google. Developer uses the default settings of App ID only for evaluation and testing purposes, and to determine whether to incorporate App ID into the applications being developed by Developer (\"Permitted Uses\"). Developer will not use the default settings of App ID for any uses or purposes other than the previously stated Permitted Uses.\n\nDeveloper will implement a Privacy Policy, separate from this document, upon transition of applications from development to production.\n\nThis document informs of: the policies regarding the collection, use, disclosure, or any other operations carried out (\"Processing\") on personally identifiable information that can be used to contact or identify a person (\"Personal Data\"); and Developer\u2019s responsibilities when engaging in the Permitted Uses of the Service, and the choices associated with the Processing of Personal Data.\n\nDeveloper will Process Personal Data while engaging in the Permitted Uses of the Service. By using the Service, Developer confirms that it is Processing Personal Data in accordance with this policy and applicable laws.\n\n\n\n Information Collection And Use \n\nDeveloper collects several different types of information for the Permitted Uses. The following types of data are collected and are described as follows: Personal Data, Usage Data, and Tracking and Cookies Data.\n\n\n\n Personal Data \n\nWhile engaging in the Permitted Uses of the Service, Developer may collect certain personally identifiable information that can be used to contact or identify a person (\"Personal Data\"). Personally identifiable information may include, but is not limited to:\n\n\n\n* Cookies and Usage Data\n* Basic Personal Information (such as name, address, phone number, email, and so on.)\n* Technically Identifiable Personal Information (such as device IDs, usage-based identifiers, static IP address, and so on. - when linked to an individual)\n* Healthcare Information (data related to physical or mental health of an individual, or which otherwise reveals information about his or her health status)\n\n\n\n\n\n\n\n Usage Data \n\nWhen engaging in the Permitted Uses of the Service, Developer may collect certain information automatically, including, but not limited to the following (collectively \"Usage Data\"):", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-privacy-policy"}, {"document_id": "ibmcld_16423-6502-8727", "score": 10.85237, "text": "\nIf you want to build a model that is optimized for your data, but do not want to upload the data as-is to Knowledge Studio for privacy reasons, you can strip the documents of any personally identifiable information (PII) first, and then use those anonymized documents to train the model. Do not redact the information or replace it wholesale with variables. For best results, replace the real information with fake information of the same type.\n\nFor example, if the PII that you want to protect is client names, then instead of redacting each name or replacing each name with a variable, such as USER_NAME, replace each name with a fake name that uses a variety of typical name syntax styles, such as Jane Doe, Mr. Smith, Dietrich, or Dr. Jones, PhD. Consider writing a script that concatenates a variety of first and last names, and titles and last names, and adds last names alone to create fake names that can be inserted into the document to replace instances of real user names. The goal is to simulate as closely as possible real values in the source documents. If the same text (USER_NAME) is used in the documents or text is redacted, you will basically be training the model to expect all names to have that same value or be redacted. When the model is used at runtime on new documents, and encounters never-seen-before names in all their variability, you want it to be able to recognize them as names.\n\n\n\n\n\n\n\n Adding documents to a workspace \n\nTo train a model, you must add documents that are representative of your domain content to your workspace.\n\n\n\n About this training task \n\nAs a best practice, start with a relatively small collection of documents. Use these documents to train human annotators (if your workspace involves human annotation) and to refine the annotation guidelines. Small documents can help human annotators identify coreference chains throughout the document. As annotation accuracy improves, you can add more documents to the corpus to provide greater depth to the training effort.\n\n\n\n\n\n Procedure \n\nTo add documents to a workspace:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select the Assets> Documents > Documentation sets tab.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotation"}]}
{"task_id": "747a810abfd6da4a9c37cdb74feec95e<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02998-8791-9815", "score": 21.927397, "text": "\nYou created a simple conversation with two intents and a dialog to recognize them.\n\n\n\n\n\n\n\n Next steps \n\nThis tutorial is built around a simple example. For a real application, you need to define some more interesting intents, some entities, and a more complex dialog that uses them both. When you have a polished version of the assistant, you can make API calls to it from your client application.\n\n\n\n* Complete follow-on tutorials that build more advanced dialogs:\n\n\n\n* Add standard nodes with the [Building a complex dialog](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-tutorial) tutorial.\n* Learn about slots with the [Adding a node with slots](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-tutorial-slots) tutorial.\n\n\n\n* Check out more [sample apps](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-sample-apps) to get ideas.\n\n\n\nWhen you're ready to deploy your assistant, see [Deploying](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-custom-app).", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-getting-started"}, {"document_id": "ibmcld_03329-9694-10633", "score": 19.217833, "text": "\nFor a real application, you need to define some more interesting intents, some entities, and a more complex dialog that uses them both. When you have a polished version of the assistant, you can integrate it with web sites or channels, such as Slack, that your customers already use. As traffic increases between the assistant and your customers, you can use the tools that are provided in the Analytics page to analyze real conversations, and identify areas for improvement.\n\n\n\n* Complete follow-on tutorials that build more advanced dialogs:\n\n\n\n* Add more dialog nodes to design complex conversational exchanges. See [Building a complex dialog](https://cloud.ibm.com/docs/assistant?topic=assistant-tutorial).\n* Learn techniques for getting customers to share information that the assistant needs before it can provide a useful response. See [Adding a node with slots](https://cloud.ibm.com/docs/assistant?topic=assistant-tutorial-slots).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-gs-dialog"}, {"document_id": "ibmcld_05171-3109-4618", "score": 17.156572, "text": "\nGo ahead and create a Docker account online at [Docker hub](https://hub.docker.com), run the Docker app, and sign in.\n\n\n\n\n\n Installing Node.js \n\nThe app that you build uses [Node.JS](https://nodejs.org/) as the server-side engine to run the JavaScript code for this web application. To use the Node Package Manager (npm) to manage your app's dependencies, you must install Node locally. Also, a local installation of Node simplifies testing, speeding up development.\n\nBefore you start, you might consider a version manager, like Node Version Manager, or nvm, to install Node. A version manager reduces the complexity of managing different versions of Node.js.\n\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash\n\n...or wget (just one is necessary, but not both; use whichever is available on your system):\n\nwget -qO- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash\n\nOr, for Windows, you can use [nvm for Windows](https://github.com/coreybutler/nvm-windows) with installers and source code at the link.\n\nUsing nvm, install Node.\n\nnvm install v6.17.1\n\nWhichever approach you use after you install Node.js and npm (included with Node) on your computer, congratulate yourself on a job well started!\n\n\n\n\n\n Installing Git \n\nYou're probably already familiar with Git, as it's the most widely used source code versioning system. We use Git later when we create a Continuous Deployment (CD) Toolchain in the IBM Cloud Platform for continuous delivery and deployment.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-web-application"}, {"document_id": "ibmcld_05171-26574-28535", "score": 17.138037, "text": "\nViewing the source code of the completed application in your preferred editor might be helpful as you follow the next steps. This is the version of your webapplication that is committed and deployed to IBM Cloud Platform when you complete this tutorial.\n\n\n\n Designing the app \n\nThese are the two main tasks that a user should be able to do with the simple image gallery web application:\n\n- Upload images from a web browser to the Object Storage bucket.\n- View the images in the Object Storage bucket in a web browser.\n\nThe next steps focus on how to accomplish these two demonstration functions rather than building a fully developed, production-grade app. Deploying this tutorial and leaving it exposed and running means that anyone who finds the app can perform the same actions: upload files to your IBM Cloud Object Storage bucket and view any JPEG images already there in their browser.\n\n\n\n\n\n Developing the app \n\nIn the package.json file, inside the scripts object, you see how \"start\" is defined. This file is what IBM Cloud Platform uses to tell node to run app.js each time the app starts. Also, use it when testing the app locally. Look at the main application file, which is called app.js. This is the code that we have told Node.js to process first when you start your app with the npm start command (or nodemon).\n\n{\n\"scripts\": {\n\"start\": \"node app.js\"\n}\n}\n\nOur app.js file uses node to load modules that are needed to get started. The Express framework creates the app as a singleton simply called app. The example ends (leaving out most of the code for now) telling the app to listen on the port that is assigned and an environment property, or 3000 by default. When successfully starting at the start, it prints a message with the server URL to the console.\n\nvar express = require('express');\nvar cfenv = require('cfenv');\nvar bodyParser = require('body-parser');\nvar app = express();\n//...\n\n// start server on the specified port and binding host", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-web-application"}, {"document_id": "ibmcld_05171-4-2124", "score": 17.12512, "text": "\n{:step: data-tutorial-type=\"step\"} {:hide-dashboard: .hide-dashboard} {:apikey: data-credential-placeholder=\"apikey\"}\n\n\n\n Developing a web application \n\nThis tutorial shows you how to build a simple image gallery using IBM Cloud\u00ae Object Storage, bringing together many different concepts and practices key to web development.\n\nFrom beginning to end, building a web application covers a lot of different concepts and is a great way to introduce yourself to the features of IBM Cloud Object Storage. Your application uses IBM Cloud Object Storage for storage in a Node.js application that allows a user to upload and view JPEG image files.\n\n\n\n The Scenario \n\nThe scenario for this tutorial involves many moving parts:\n\n\n\n* A web server to host the web application\n* Use of the command line\n* A storage instance for the images in the gallery\n* A version control system integrated into continuous delivery\n* Client-side application bindings in both scripts and markup\n* Images to upload and display\n\n\n\nAnd if you are looking for all that in one package, this tutorial will provide a complete, start-to-finish, example for you. However, this instruction can only temporarily set aside principles of security and secure code. Web applications actually put into production require proper security, or they won't be suitable for possible visitors.\n\n\n\n\n\n Before you begin \n\nEnsure that you have what you need to start:\n\n\n\n* An account for the IBM Cloud Platform\n* Docker, as part of the IBM Cloud Developer Tools\n* Node.js\n* Git (both desktop and command line)\n\n\n\n\n\n Using the Command Line \n\nLet's start by opening a tool familiar to experienced developers, and a new best friend to those just getting started: the command line. For many, the graphic user interface (GUI) relegated your computer's command-line interface to second-class status. But now, it's time to bring it back (although the GUI isn't going away anytime soon, especially when we need to browse the web to download instructions for the command-line toolset).\n\nOpen a shell and create a directory. Change your own reference directory to the new one you created.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-web-application"}, {"document_id": "ibmcld_13144-10995-12568", "score": 17.062395, "text": "\nClick on the URL under Routes to visit your application. Enter any string for username and password, for instance test:test because the app is running in demonstration mode.\n\n\n\nThe Node.js app has been deployed to Red Hat OpenShift Container Platform. To recap:\n\n\n\n* The \"Example Health\" Node.js application was deployed directly from GitHub into your cluster.\n* The application was examined in the Red Hat OpenShift on IBM Cloud console.\n* A Build Configuration was created - a new commit can be both built and deployed by clicking Start Build in the Builds section of the application details.\n\n\n\n\n\n\n\n\n\n Step 3: Logging and monitoring \n\nIn this section, you will explore the out-of-the-box logging and monitoring capabilities that are offered in Red Hat OpenShift on IBM Cloud.\n\n\n\n Simulate Load on the Application \n\nCreate a script to simulate load.\n\n\n\n1. Make sure you're connected to the project where you deployed your app.\n\noc project example-health\n2. Retrieve the public route to access your application:\n\noc get routes\n\nOutput looks similar to this, note your value for Host:\n\nNAME HOST/PORT PATH SERVICES PORT TERMINATION WILDCARD\npatient-health-frontend patient-health-frontend-example-health.roks07-872b77d77f69503584da5a379a38af9c-0000.eu-de.containers.appdomain.cloud patient-health-frontend 8080-tcp None\n3. Define a variable with the host:\n\nHOST=$(oc get routes -o json | jq -r '.items[0].spec.host')\n4. Verify access to the application. It outputs patient information:\n\ncurl -s -L http://$HOST/info\n\nOutput should look like:\n\n$ curl -s -L http://$HOST/info", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-openshift-microservices"}, {"document_id": "ibmcld_03916-7-1838", "score": 16.949823, "text": "\nDeveloping applications \n\nAfter you install smart contracts (chaincode) and deploy your peer and ordering nodes, you are ready to develop client applications to transact with other members of your IBM Blockchain Platform network. Applications invoke the business logic contained in smart contracts to create, transfer, and update assets on the blockchain ledger. Use this page to learn how to use client applications to interact with networks from the IBM\u00ae Blockchain Platform console.\n\nTarget audience: This topic is designed for application developers who are interested in developing client apps for an IBM Blockchain Platform network, in Node.js, Go, or Java.\n\n\n\n Using the v2.4 Fabric Gateway peer service \n\nIBM Blockchain Platform v2.5.4 adds support for the v2.4 Hyperledger Fabric Gateway peer service, which introduces an updated model for developing applications. The v2.4 gateway peer model relocates node connection and transaction processing requirements from the client application to the v2.4 peer nodes. The [v2.4 Fabric Gateway](https://hyperledger-fabric.readthedocs.io/en/release-2.4/gateway.html) method therefore enables developers to focus on business solutions, without having to code gateway connection or transaction processing logic in client applications, as is required for earlier releases.\n\n\n\n Supported app development methods in Fabric v2.4 \n\nTo develop new applications for IBM Blockchain Platform v2.5.4, using the latest v2.4 Hyperledger Fabric Gateway peer service and API are recommended, as documented in [Running a Fabric Application](https://hyperledger-fabric.readthedocs.io/en/release-2.4/write_first_app.html). However, for existing applications developed for IBM Blockchain Platform v2.5.2 and earlier, no migration is required\u2014 your existing applications will continue to run on v2.5.4.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-app"}, {"document_id": "ibmcld_02952-7-2097", "score": 16.642784, "text": "\nConnecting customers with support \n\nNo matter where you deploy your assistant, give your customers a way to get additional support when they need it.\n\nBuild your dialog to recognize when customers need help that cannot be provided by the assistant. Add logic that can connect your customers to whatever type of professional support you offer. Your solutions might include:\n\n\n\n* A toll-free phone number to a call center that is manned by human agents\n* An online support ticket form that customers fill out and submit\n* A service desk solution that is configured to work with your custom client application. The built-in Zendesk and Salesforce integrations aren\u2019t supported.\n\n\n\nDesign your dialog to recognize customer requests for help and address them. Add an intent that understands the customer request, and then add a dialog branch that handles the request.\n\nYou might add an intent and use it in a dialog node like these example intents:\n\n\n\nAlternative support request intent examples\n\n Intent name Intent user example 1 Intent user example 2 Response from dialog node that conditions on intent \n\n call_support How do I reach support? What's your toll-free number? Call 1-800-555-0123 to reach a call center agent at any time. \n support_ticket How do I get help? Who can help me with an issue I'm having? Go to [Support Center](https://example.com/support) and open a support ticket. \n\n\n\n\n\n Adding chat transfer support \n\nDesign your dialog so that it can transfer customers to human agents. Consider adding support for initiating a transfer in the following scenarios:\n\n\n\n* Any time a user asks to speak to a person.\n\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-support"}, {"document_id": "ibmcld_05171-1587-3575", "score": 16.632078, "text": "\nLet's start by opening a tool familiar to experienced developers, and a new best friend to those just getting started: the command line. For many, the graphic user interface (GUI) relegated your computer's command-line interface to second-class status. But now, it's time to bring it back (although the GUI isn't going away anytime soon, especially when we need to browse the web to download instructions for the command-line toolset).\n\nOpen a shell and create a directory. Change your own reference directory to the new one you created. When created, your application has its own subdirectory with the starter code and configuration needed to get up and running.\n\nLeave the command line and return to your browser so you can follow the instructions to install the [IBM Cloud Platform developer tools](https://cloud.ibm.com/docs/cli?topic=cli-install-devtools-manually) at the link. The Developer Tools offer an extensible and repeatable approach to building and deploying cloud applications.\n\n\n\n\n\n Installing Docker \n\nUsing containers, like Docker, speeds up development and eases testing and supports automated deployment. A container is a lightweight structure that doesn't need an operating system, just your code and configuration for everything from dependencies to settings.\n\n[Docker](https://www.docker.com) is installed as part of the Developer Tools, and we need it. Its work takes place mostly in the background within routines that scaffold your new app. Docker must be running for the build commands to work. Go ahead and create a Docker account online at [Docker hub](https://hub.docker.com), run the Docker app, and sign in.\n\n\n\n\n\n Installing Node.js \n\nThe app that you build uses [Node.JS](https://nodejs.org/) as the server-side engine to run the JavaScript code for this web application. To use the Node Package Manager (npm) to manage your app's dependencies, you must install Node locally. Also, a local installation of Node simplifies testing, speeding up development.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-web-application"}, {"document_id": "ibmcld_05171-9378-10995", "score": 16.552586, "text": "\nSpeech to Text Node.js App - React app using the Watson Speech to\nText service to transform voice audio into written text.\n\n6. Text to Speech Node.js App - React app using the Watson Text to\nSpeech service to transform text into audio.\n\n7. Visual Recognition Node.js App - React app using the Watson\nVisual Recognition service to analyze images for scenes, objects, text,\nand other subjects.\n\n-------------------------\n0. Return to the previous selection\n\n===============================================================================\n? Enter selection number:> 3\n\nThe hardest option for developers everywhere is still required: naming your app. Follow the example and type webapplication, then press enter.\n\n? Enter a name for your application> webapplication\n\nLater, you can add as many services, like data stores or compute functions, as needed or wanted through the web console. However, type 'n' for no when asked if you want to add services now. Also, if you haven't already set a resource group, you may be prompted at this time. You may skip this by typing 'n' at this prompt.\n\nUsing the resource group Default (default) of your account\n\n? Do you want to select a service to add to this application? [Y/n]> n\n\nOne way to manage a containerized application is with orchestration software, like Kubernetes, which is a de facto standard in development. But for this tutorial, we can let the Cloud Foundry service manage a single Docker container that holds the code, libraries, and configuration needed by your app.\n\nType '4' and press enter to use 'IBM DevOps' for integrating CD within your project lifecycle.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-web-application"}]}
{"task_id": "747a810abfd6da4a9c37cdb74feec95e<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10510-17837-19983", "score": 16.734138, "text": "\nWorker nodes carry the deployments and services that make up your app. When you host workloads in the public cloud, you want to ensure that your app is protected from being accessed, changed, or monitored by an unauthorized user or software.\n\n\n\n Who owns the worker node and am I responsible to secure it? \n\nThe ownership of a worker node depends on the type of cluster that you create and the infrastructure provider that you choose.\n\n\n\n* Classic clusters: Worker nodes are provisioned in to your IBM Cloud account. The worker nodes are dedicated to you and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and IBM Cloud Kubernetes Service components apply the latest security updates and patches.\n* VPC clusters: Worker nodes are provisioned in to an IBM Cloud account that is owned by IBM to enable monitoring of malicious activities and apply security updates. You can't access your worker nodes by using the VPC dashboard. However, you can manage your worker nodes by using the IBM Cloud Kubernetes Service console, CLI, or API. The virtual machines that make up your worker nodes are dedicated to you and you are responsible to request timely updates so that your worker node OS and IBM Cloud Kubernetes Service components apply the latest security updates and patches.\n\n\n\nFor more information, see [Your responsibilities by using Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-responsibilities_iks).\n\nUse the ibmcloud oc worker update[command](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clics_worker_update) regularly (such as monthly) to deploy updates and security patches to the operating system and to update the Red Hat OpenShift version that your worker nodes run. When updates are available, you are notified when you view information about the master and worker nodes in the IBM Cloud console or CLI, such as with the ibmcloud oc clusters ls or ibmcloud oc workers ls --cluster <cluster_name> commands. Worker node updates are provided by IBM as a full worker node image that includes the latest security patches.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-security"}, {"document_id": "ibmcld_10463-8360-9835", "score": 16.346226, "text": "\nkube-dal10-cr18e61e63c6e94b658596ca93d087eed9-w3 169.xx.xxx.xxx 10.176.48.78 u3c.2x4.encrypted normal Ready dal10 1.26_1513\n3. Copy the public IP of the worker node and the node port into your text cheat sheet to use in later lessons.\n4. Verify that you can access the public IP address the worker node through the node port. Note: Because worker nodes in VPC clusters don't have a public IP address, you can access an app through a NodePort only if you are connected to your private VPC network, such as through a VPN connection. Then, you can use the worker node's private IP address and NodePort: <worker_private_IP>:<NodePort>.\n\ncurl --connect-timeout 10 <worker_IP>:<NodePort>\n\nThe following example output confirms that the request to your app came through the private IP address 10.1.1.1 for the worker node and the 31024 node port. The webserver-855556f688-xd849 app pod received the curl request:\n\nHostname: webserver-855556f688-xd849\nPod Information:\n-no pod information available-\nServer values:\nserver_version=nginx: 1.13.3 - lua: 10008\nRequest Information:\nclient_address=1.1.1.1\nmethod=GET\nreal path=/\nquery=\nrequest_version=1.1\nrequest_scheme=http\nrequest_uri=http://10.1.1.1:8080/\nRequest Headers:\naccept=/\nhost=10.1.1.1:31024\nuser-agent=curl/7.60.0\nRequest Body:\n-no body in request-\n\n\n\n\n\nAt this point, your app is exposed from multiple IP addresses and ports. Most of these IPs are internal to the cluster and can be accessed only over the private network.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-policy_tutorial"}, {"document_id": "ibmcld_10444-5383-7233", "score": 16.288952, "text": "\nFor more information, see [worker node resource reserves](https://cloud.ibm.com/docs/openshift?topic=openshift-planning_worker_nodesresource_limit_node).\n\nWant to be sure that you always have enough worker nodes to cover your workload? Try out [the cluster autoscaler](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-scaling-classic-vpc).\n\n\n\n\n\n Why do my worker nodes have the master role? \n\nWhen you run oc get nodes or oc describe node <worker_node>, you might see that the worker nodes have master,worker roles. In OpenShift Container Platform clusters, operators use the master role as a nodeSelector so that OCP can deploy default components that are controlled by operators, such as the internal registry, in your cluster. No master node processes, such as the API server or Kubernetes scheduler, run on your worker nodes. For more information about master and worker node components, see [Red Hat OpenShift architecture](https://cloud.ibm.com/docs/openshift?topic=openshift-service-architectureservice-architecture-4).\n\n\n\n\n\n How can I check the operating system that my worker nodes run? \n\nWhen you create a worker pool, you choose the flavor, which describes the operating system along with the compute resources of the worker nodes. Supported operating systems are RHEL 7.\n\nYou can also log in to your cluster to check the operating system of the worker nodes.\n\n\n\n1. [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n2. List your worker nodes.\n\noc get nodes\n3. Describe your worker node and check for the operating system label that IBM applies, or the OS Image and Operating System fields in the System Info section.\n\noc describe node <node>\n\nExample output\n\nNAME: 10.xxx.xx.xxx\nRoles: <none>", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-planning_worker_nodes"}, {"document_id": "ibmcld_05558-22392-24219", "score": 16.138578, "text": "\nAdd stand-alone worker nodes to the cluster. For bare metal flavors, specify dedicated.\n\nibmcloud ks worker add --cluster <cluster_name_or_ID> --workers <number_of_worker_nodes> --public-vlan <public_VLAN_ID> --private-vlan <private_VLAN_ID> --flavor <flavor> --hardware <shared_or_dedicated>\n5. Verify that the worker nodes are created.\n\nibmcloud ks worker ls --cluster <cluster_name_or_ID>\n\n\n\n\n\n\n\n Installing SGX drivers and platform software on SGX-capable worker nodes \n\nIntel Software Guard Extensions (SGX) is a technology that can protect data-in-use through hardware-based server security. With Intel SGX, you can protect select code and data from disclosure or modification. Through the use of trusted execution environments (TEE), known as enclaves, you can encrypt the pieces of your app memory that contain sensitive data while the data or code is being used. To use Intel SGX, you must install the SGX drivers and platform software on SGX-capable worker nodes. Then, design your app to run in an SGX environment.\n\nZoom\n\n![An example SGX application.](https://cloud.ibm.com/docs-content/v1/content/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7/containers/images/cc-iks.png)\n\nFigure. Example SGX application set up\n\nWhen you develop a confidential computing application, you must design it in a way that you can segment the information that needs to be encrypted. At runtime, the segmented information is kept confidential through attestation. When a request for information from the segmented code or app data is received, the enclave verifies that the request comes from the part of the application that exists outside of the enclave within the same application before sharing any information. Through the attestation process, information is kept confidential and data leakage is prevented.\n\n\n\n Installing with a script", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-add_workers"}, {"document_id": "ibmcld_10527-23624-25627", "score": 16.128107, "text": "\n: When you run oc get nodes, you might notice that the ROLES of your worker nodes are marked as both master,worker. These nodes are worker nodes in IBM Cloud, and don't include the master components that are managed by IBM. Instead, these nodes are marked as master because they run OpenShift Container Platform components that are required to set up and manage default resources within the cluster, such as the OperatorHub and internal registry.\n\nCluster networking\n: Your worker nodes are created in a VPC subnet in the zone that you specify. Communication between the master and worker nodes is over the private network. If you create a cluster with the public and private cloud service endpoints enabled, authenticated external users can communicate with the master over the public network, such as to run oc commands. If you create a cluster with only the private cloud service endpoints enabled, authenticated external users can communicate with the master over the private network only. You can set up your cluster to communicate with resources in on-premises networks, other VPCs, or classic infrastructure by setting up a VPC VPN, IBM Cloud Direct Link, or IBM Cloud Transit Gateway on the private network.\n\nApp networking\n: Virtual Private Cloud load balancers are automatically created in your VPC outside the cluster for any networking services that you create in your cluster. For example, a VPC load balancer exposes the router services in your cluster by default. Or, you can create a Kubernetes LoadBalancer service for your apps, and a VPC load balancer is automatically generated. VPC load balancers are multizone and route requests for your app through the private node ports that are automatically opened on your worker nodes. If the public and private cloud service endpoints are enabled, the routers and VPC load balancers are created as public by default. If only the private cloud service endpoint is enabled, the routers and VPC load balancers are created as private by default.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-service-architecture"}, {"document_id": "ibmcld_06079-10297-12436", "score": 16.116531, "text": "\nWorker node With IBM Cloud Kubernetes Service, the virtual machines that your cluster manages are instances that are called worker nodes. These worker nodes virtual machines and all the worker node components are dedicated to you only and are not shared with other IBM customers. However, the underlying hardware is shared with other IBM customers. For more information, see [Virtual machines](https://cloud.ibm.com/docs/containers?topic=containers-planning_worker_nodesvm). You manage the worker nodes through the automation tools that are provided by IBM Cloud Kubernetes Service, such as the API, CLI, or console. Unlike classic clusters, you don't see VPC compute worker nodes in your infrastructure portal or separate infrastructure bill, but instead manage all maintenance and billing activity for the worker nodes from IBM Cloud Kubernetes Service. Worker nodes include the same [components](https://cloud.ibm.com/docs/containers?topic=containers-service-archworker-components) as described in the Classic architecture. Community Kubernetes worker nodes run on Ubuntu 18.04 x86_64, 16.04 x86_64 (deprecated). \n Cluster networking Your worker nodes are created in a VPC subnet in the zone that you specify. By default, the public and private cloud service endpoints for your cluster are enabled. Communication between the master and worker nodes is over the private network. Authenticated external users can communicate with the master over the public network, such as to run kubectl commands. You can optionally set up your cluster to communicate with on-prem services by setting up a VPC VPN on the private network. \n App networking You can create a Kubernetes LoadBalancer service for your apps in the cluster, which automatically provisions a VPC load balancer in your VPC outside the cluster. The load balancer is multizonal and routes requests for your app through the private NodePorts that are automatically opened on your worker nodes. For more information, see [Exposing apps with VPC load balancers](https://cloud.ibm.com/docs/containers?topic=containers-vpc-lbaas). Calico is used as the cluster networking policy fabric.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-service-arch"}, {"document_id": "ibmcld_05964-11806-13757", "score": 15.953368, "text": "\nIf you replace multiple worker nodes at the same time, they are deleted and replaced concurrently, not one by one. Make sure that you have enough capacity in your cluster to reschedule your workloads before you replace worker nodes. \n\n\n\n\n\n\n\n Networking \n\nKeep in mind that the [service](https://cloud.ibm.com/docs/containers?topic=containers-limitationstech_limits) limitations also apply.\n\n\n\nVPC cluster networking limitations\n\n Category Description \n\n App URL length DNS resolution is managed by the cluster's [virtual private endpoint (VPE)](https://cloud.ibm.com/docs/containers?topic=containers-vpc-subnetsvpc_basics_vpe), which can resolve URLs up to 130 characters. If you expose apps in your cluster with URLs, such as the Ingress subdomain, ensure that the URLs are 130 characters or fewer. \n Istio managed add-on See [Istio add-on limitations](https://cloud.ibm.com/docs/containers?topic=containers-istio-aboutistio_limitations). \n Network speeds [VPC profile network speeds](https://cloud.ibm.com/docs/vpc?topic=vpc-profiles) refer to the speeds of the worker node interfaces. The maximum speed available to your worker nodes is 25Gbps. Because IP in IP encapsulation is required for traffic between pods that are on different subnets, data transfer speeds between pods on different subnets might be slower, about half the compute profile network speed. Overall network speeds for apps that you deploy to your cluster depend on the worker node size and application's architecture. \n NodePort You can access an app through a NodePort only if you are connected to your private VPC network, such as through a VPN connection. To access an app from the internet, you must use a VPC load balancer or Ingress service instead. \n Pod network VPC access control lists (ACLs) filter incoming and outgoing traffic for your cluster at the subnet level, and security groups filter incoming and outgoing traffic for your cluster at the worker nodes level.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-limitations"}, {"document_id": "ibmcld_10264-2929-4693", "score": 15.952289, "text": "\nInstead, use the [worker replace --update CLI](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clicli_worker_replace) or [API operation](https://containers.cloud.ibm.com/global/swagger-global-api//beta/replaceWorker) to replace worker nodes that are outdated or in a troubled state. \n Cluster networking Unlike classic infrastructure, the worker nodes of your VPC cluster are attached to VPC subnets and assigned private IP addresses. The worker nodes are not connected to the public network, which instead is accessed through a public gateway, floating IP, or VPN gateway. For more information, see [Overview of VPC networking in Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc-subnetsvpc_basics). \n Apps and container platform You can choose to create [community Kubernetes or Red Hat OpenShift clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-faqscontainer_platforms) to manage your containerized apps. Your app build processes don't differ because of the infrastructure provider, but how you expose the app does. For more information, see [Choosing an app exposure service](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_network_planning). \n App networking All pods that are deployed to a worker node are assigned a private IP address in the 172.30.0.0/16 range and are routed between worker nodes on the worker node private IP address of the private VPC subnet. To expose the app on the public network, you can create a Kubernetes LoadBalancer service, which provisions a VPC load balancer and public hostname address for your worker nodes. For more information, see [Exposing apps with VPC load balancers](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc-lbaas).", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providers"}, {"document_id": "ibmcld_06030-8682-10315", "score": 15.781117, "text": "\nVerify that you can access the public IP address the worker node through the node port. Note: Because worker nodes in VPC clusters don't have a public IP address, you can access an app through a NodePort only if you are connected to your private VPC network, such as through a VPN connection. Then, you can use the worker node's private IP address and NodePort: <worker_private_IP>:<NodePort>.\n\ncurl --connect-timeout 10 <worker_IP>:<NodePort>\n\nThe following example output confirms that the request to your app came through the private IP address 10.1.1.1 for the worker node and the 31024 node port. The webserver-855556f688-xd849 app pod received the curl request:\n\nHostname: webserver-855556f688-xd849\nPod Information:\n-no pod information available-\nServer values:\nserver_version=nginx: 1.13.3 - lua: 10008\nRequest Information:\nclient_address=1.1.1.1\nmethod=GET\nreal path=/\nquery=\nrequest_version=1.1\nrequest_scheme=http\nrequest_uri=http://10.1.1.1:8080/\nRequest Headers:\naccept=/\nhost=10.1.1.1:31024\nuser-agent=curl/7.60.0\nRequest Body:\n-no body in request-\n\n\n\n\n\nAt this point, your app is exposed from multiple IP addresses and ports. Most of these IPs are internal to the cluster and can be accessed only over the private network. Only the public node port and public NLB port are exposed to the public internet.\n\nNext, you can start creating and applying Calico policies to block public traffic.\n\n\n\n\n\n Step 2: Block all incoming traffic to all node ports \n\nTo secure the PR firm's cluster, you must block public access to both the NLB service and node ports that are exposing your app. Start by blocking access to node ports.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-policy_tutorial"}, {"document_id": "ibmcld_10505-8460-10320", "score": 15.759734, "text": "\nWorker nodes <br><br> * Provide worker node patch operating system (OS), version, and security updates.<br> * Fulfill automation requests to update and recover worker nodes.<br><br><br> <br><br> * Use the API, CLI, or console tools to [apply](https://cloud.ibm.com/docs/containers?topic=containers-updateupdate) the provided worker node updates that include operating system patches; or to request that worker nodes are rebooted, reloaded, or replaced.<br><br><br> \n Cluster version <br><br> * Provide a suite of tools to automate cluster management, such as the Red Hat OpenShift on IBM Cloud [API](https://containers.cloud.ibm.com/global/swagger-global-api//), [CLI plug-in](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli), and [console](https://cloud.ibm.com/kubernetes/clusters).<br> * Automatically apply Red Hat OpenShift master patch OS, version, and security updates.<br> * Make major and minor updates for master nodes available for you to apply.<br> * Provide worker node major, minor, and patch OS, version, and security updates.<br> * Fulfill automation requests to update cluster master and worker nodes.<br><br><br> <br><br> * Use the API, CLI, or console tools to [apply](https://cloud.ibm.com/docs/containers?topic=containers-updateupdate) the provided major and minor Red Hat OpenShift master updates and major, minor, and patch worker node updates.<br><br><br> \n\n\n\n\n\n\n\n Identity and access management \n\nYou and IBM share responsibilities for controlling access to your Red Hat OpenShift on IBM Cloud instances. For IBM Cloud\u00ae Identity and Access Management responsibilities, consult that product's documentation. You are responsible for identity and access management to your application data.\n\n\n\nTable 4. Responsibilities for identity and access management\n\n Resource IBM responsibilities Your responsibilities", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-satellite-responsibilities"}]}
{"task_id": "747a810abfd6da4a9c37cdb74feec95e<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_06007-7-1994", "score": 18.288212, "text": "\nUnderstanding network basics of VPC clusters \n\nWhen you create your cluster, you must choose a networking setup so that certain cluster components can communicate with each other and with networks or services outside of the cluster.\n\n\n\n* [Worker-to-worker communication](https://cloud.ibm.com/docs/containers?topic=containers-plan_vpc_basicsvpc-worker-worker): All worker nodes must be able to communicate with each other on the private network through VPC subnets.\n* [Worker-to-master and user-to-master communication](https://cloud.ibm.com/docs/containers?topic=containers-plan_vpc_basicsvpc-workeruser-master): Your worker nodes and your authorized cluster users can communicate with the Kubernetes master securely over virtual private endpoints or cloud service endpoints.\n* [Worker communication to other services or networks](https://cloud.ibm.com/docs/containers?topic=containers-plan_vpc_basicsvpc-worker-services-onprem): Allow your worker nodes to securely communicate with other IBM Cloud services, such as IBM Cloud\u00ae Container Registry, to on-premises networks, to other VPCs, or to classic infrastructure resources.\n* [External communication to apps that run on worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-plan_vpc_basicsvpc-external-workers): Allow public or private requests into the cluster as well as requests out of the cluster to a public endpoint.\n\n\n\n\n\n Worker-to-worker communication using VPC subnets \n\nBefore you create a VPC cluster for the first time, you must [create a VPC subnet](https://cloud.ibm.com/vpc/provision/network) in each zone where you want to deploy worker nodes. A VPC subnet is a specified private IP address range (CIDR block) and configures a group of worker nodes and pods as if they are attached to the same physical wire.\n\nWhen you create a cluster, you specify an existing VPC subnet for each zone. Each worker node that you add in a cluster is deployed with a private IP address from the VPC subnet in that zone.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-plan_vpc_basics"}, {"document_id": "ibmcld_10442-7-1871", "score": 18.271662, "text": "\nUnderstanding network basics of VPC clusters \n\nWhen you create your cluster, you must choose a networking setup so that certain cluster components can communicate with each other and with networks or services outside of the cluster.\n\n\n\n* [Worker-to-worker communication](https://cloud.ibm.com/docs/openshift?topic=openshift-plan_vpc_basicsvpc-worker-worker): All worker nodes must be able to communicate with each other on the private network through VPC subnets.\n* [Worker-to-master and user-to-master communication](https://cloud.ibm.com/docs/openshift?topic=openshift-plan_vpc_basicsvpc-workeruser-master): Your worker nodes and your authorized cluster users can communicate with the Kubernetes master securely over virtual private endpoints or cloud service endpoints.\n* [Worker communication to other services or networks](https://cloud.ibm.com/docs/openshift?topic=openshift-plan_vpc_basicsvpc-worker-services-onprem): Allow your worker nodes to securely communicate with other IBM Cloud services, such as IBM Cloud\u00ae Container Registry, to on-premises networks, to other VPCs, or to classic infrastructure resources.\n* [External communication to apps that run on worker nodes](https://cloud.ibm.com/docs/openshift?topic=openshift-plan_vpc_basicsvpc-external-workers): Allow public or private requests into the cluster as well as requests out of the cluster to a public endpoint.\n\n\n\n\n\n Worker-to-worker communication using VPC subnets \n\nBefore you create a VPC cluster for the first time, you must [create a VPC subnet](https://cloud.ibm.com/vpc/provision/network) in each zone where you want to deploy worker nodes. A VPC subnet is a specified private IP address range (CIDR block) and configures a group of worker nodes and pods as if they are attached to the same physical wire.\n\nWhen you create a cluster, you specify an existing VPC subnet for each zone.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-plan_vpc_basics"}, {"document_id": "ibmcld_10137-2664-4619", "score": 18.126797, "text": "\n: v2 API: Same as v1; see [Using an API key to log in to clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-access_clusteraccess_api_key).\n\nSupported APIs by infrastructure type\n: v1 API: classic\n: v2 API: vpc and classic\n\n\n\n* The vpc provider is designed to support multiple VPC subproviders. The supported VPC subprovider is vpc-gen2, which corresponds to a VPC cluster for Generation 2 compute resources.\n* Provider-specific requests have a path parameter in the URL, such as v2/vpc/createCluster. Some APIs are only available to a particular provider, such as GET vlan for classic or GET vpcs for VPC.\n* Provider-neutral requests can include a provider-specific body parameter that you specify, usually in JSON, such as {\"provider\": \"vpc\"}, if you want to return responses for only the specified provider.\n\n\n\nGET responses\n: v1 API: The GET method for a collection of resources (such as GET v1/clusters) returns the same details for each resource in the list as a GET method for an individual resource (such as GET v1/clusters/{idOrName}).\n: v2 API: To return responses faster, the v2 GET method for a collection of resources (such as GET v2/clusters) returns only a subset of information that is detailed in a GET method for an individual resource (such as GET v2/clusters/{idOrName}). Some list responses include a providers property to identify whether the returned item applies to classic or VPC infrastructure. For example, the GET zones list returns some results such as mon01 that are available only in the classic infrastructure provider, while other results such as us-south-01 are available only in the VPC infrastructure provider.\n\nCluster, worker node, and worker-pool responses\n: v1 API: Responses include only information that is specific to the classic infrastructure provider, such as the VLANs in GET cluster and worker responses.\n: v2 API: The information that is returned varies depending on the infrastructure provider.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_api_install"}, {"document_id": "ibmcld_05858-1723-3537", "score": 17.853579, "text": "\nFor more information, see [Intel Hyper-Threading Technology](https://cloud.ibm.com/docs/vpc?topic=vpc-profilesvpc-intel-hyper-threading). \n Security Clusters on shared hardware run in an isolated environment in the public cloud. Clusters on dedicated hosts do not run in a shared environment, instead only your clusters are present on your hosts. Network access control lists protect the subnets that provide the floating IPs for your worker nodes. For more information, see the [VPC documentation](https://cloud.ibm.com/docs/vpc?topic=vpc-about-vpc). \n High availability The master includes three replicas for high availability. Further, if you create your cluster in a multizone metro, the master replicas are spread across zones and you can also spread your worker pools across zones. For more information, see [High availability for IBM Cloud Kubernetes Service](https://cloud.ibm.com/docs/containers?topic=containers-ha). \n Reservations Reservations aren't available for VPC. \n Cluster administration VPC clusters can't be reloaded or updated. Instead, use the [worker replace --update CLI](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clicli_worker_replace) or [API operation](https://containers.cloud.ibm.com/global/swagger-global-api//beta/replaceWorker) to replace worker nodes that are outdated or in a troubled state. \n Cluster networking Unlike classic infrastructure, the worker nodes of your VPC cluster are attached to VPC subnets and assigned private IP addresses. The worker nodes are not connected to the public network, which instead is accessed through a public gateway, floating IP, or VPN gateway. For more information, see [Overview of VPC networking in IBM Cloud Kubernetes Service](https://cloud.ibm.com/docs/containers?topic=containers-vpc-subnetsvpc_basics).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-infrastructure_providers"}, {"document_id": "ibmcld_06007-1457-3349", "score": 17.745842, "text": "\nBefore you create a VPC cluster for the first time, you must [create a VPC subnet](https://cloud.ibm.com/vpc/provision/network) in each zone where you want to deploy worker nodes. A VPC subnet is a specified private IP address range (CIDR block) and configures a group of worker nodes and pods as if they are attached to the same physical wire.\n\nWhen you create a cluster, you specify an existing VPC subnet for each zone. Each worker node that you add in a cluster is deployed with a private IP address from the VPC subnet in that zone. After the worker node is provisioned, the worker node IP address persists after a reboot operation, but the worker node IP address changes after replace and update operations.\n\nSubnets provide a channel for connectivity among the worker nodes within the cluster. Additionally, any system that is connected to any of the private subnets in the same VPC can communicate with workers. For example, all subnets in one VPC can communicate through private layer 3 routing with a built-in VPC router. If you have multiple clusters that must communicate with each other, you can create the clusters in the same VPC. However, if your clusters don't need to communicate, you can achieve better network segmentation by creating the clusters in separate VPCs. You can also create [access control lists (ACLs)](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc-acls) for your VPC subnets to mediate traffic on the private network. ACLs consist of inbound and outbound rules that define which ingress and egress is permitted for each VPC subnet.\n\nIf your worker nodes must access a public endpoint outside of the cluster, you can enable a public gateway on the VPC subnet that the worker nodes are deployed to. A public gateway can be attached to or detached from a subnet at any time.\n\nThe default IP address range for VPC subnets is 10.0.0.0 \u2013 10.255.255.255.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-plan_vpc_basics"}, {"document_id": "ibmcld_10442-1449-3496", "score": 17.63109, "text": "\nBefore you create a VPC cluster for the first time, you must [create a VPC subnet](https://cloud.ibm.com/vpc/provision/network) in each zone where you want to deploy worker nodes. A VPC subnet is a specified private IP address range (CIDR block) and configures a group of worker nodes and pods as if they are attached to the same physical wire.\n\nWhen you create a cluster, you specify an existing VPC subnet for each zone. Each worker node that you add in a cluster is deployed with a private IP address from the VPC subnet in that zone. After the worker node is provisioned, the worker node IP address persists after a reboot operation, but the worker node IP address changes after replace and update operations.\n\nSubnets provide a channel for connectivity among the worker nodes within the cluster. Additionally, any system that is connected to any of the private subnets in the same VPC can communicate with workers. For example, all subnets in one VPC can communicate through private layer 3 routing with a built-in VPC router. If you have multiple clusters that must communicate with each other, you can create the clusters in the same VPC. However, if your clusters don't need to communicate, you can achieve better network segmentation by creating the clusters in separate VPCs. You can also create [access control lists (ACLs)](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc-acls) for your VPC subnets to mediate traffic on the private network. ACLs consist of inbound and outbound rules that define which ingress and egress is permitted for each VPC subnet.\n\nWhen you create a VPC cluster and enable both the public and private cloud service endpoints during cluster creation, the public cloud service endpoint is used by default for access to components such as the Red Hat OpenShift web console for your cluster. In order for console pods to establish a secure, public connection over the internet through the public service endpoint, you must enable a public gateway on each VPC subnet that your worker nodes are deployed to.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-plan_vpc_basics"}, {"document_id": "ibmcld_05858-3083-5003", "score": 17.566696, "text": "\nCluster networking Unlike classic infrastructure, the worker nodes of your VPC cluster are attached to VPC subnets and assigned private IP addresses. The worker nodes are not connected to the public network, which instead is accessed through a public gateway, floating IP, or VPN gateway. For more information, see [Overview of VPC networking in IBM Cloud Kubernetes Service](https://cloud.ibm.com/docs/containers?topic=containers-vpc-subnetsvpc_basics). \n Apps and container platform You can choose to create [community Kubernetes or Red Hat OpenShift clusters](https://cloud.ibm.com/docs/containers?topic=containers-faqscontainer_platforms) to manage your containerized apps. Your app build processes don't differ because of the infrastructure provider, but how you expose the app does. For more information, see [Choosing an app exposure service](https://cloud.ibm.com/docs/containers?topic=containers-cs_network_planning). \n App networking All pods that are deployed to a worker node are assigned a private IP address in the 172.30.0.0/16 range and are routed between worker nodes on the worker node private IP address of the private VPC subnet. To expose the app on the public network, you can create a Kubernetes LoadBalancer service, which provisions a VPC load balancer and public hostname address for your worker nodes. For more information, see [Exposing apps with VPC load balancers](https://cloud.ibm.com/docs/containers?topic=containers-vpc-lbaas). \n Storage For persistent storage, use [block](https://cloud.ibm.com/docs/containers?topic=containers-vpc-block). For the number of volumes that can be attached per worker node, see [Volume attachment limits](https://cloud.ibm.com/docs/vpc?topic=vpc-attaching-block-storagevol-attach-limits). The storage class limits the volume size to 20TB and IOPS capacity to 20,000. For non-persistent storage, secondary storage on the local worker node is not available.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-infrastructure_providers"}, {"document_id": "ibmcld_06294-7-1823", "score": 17.546585, "text": "\nCreating a cluster in your Virtual Private Cloud (VPC) \n\nCreate an IBM Cloud\u00ae Kubernetes Service cluster in your Virtual Private Cloud (VPC).\n\nWith IBM Cloud Kubernetes Service clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https://cloud.ibm.com/docs/vpc?topic=vpc-about-vpc). VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of IBM Cloud Kubernetes Service [infrastructure providers](https://cloud.ibm.com/docs/containers?topic=containers-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality. You can create only standard clusters for VPC.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create an IBM Cloud Kubernetes Service cluster in a Virtual Private Cloud (VPC). Then, you deploy an app and expose the app publicly by using a load balancer.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in IBM Cloud Kubernetes Service in VPC for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.\n\nPermissions\n: If you are the account owner, you already have the required permissions to create a cluster and can continue to the next step. Otherwise, ask the account owner to [set up the API key and assign you the minimum user permissions in IBM Cloud IAM](https://cloud.ibm.com/docs/openshift?topic=openshift-access_referencecluster_create_permissions).\n\nCommand-line tools\n: For quick access to your resources from the command line, try the [IBM Cloud Shell](https://cloud.ibm.com/shell). Otherwise, set up your local command-line environment by completing the following steps.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-vpc_ks_tutorial"}, {"document_id": "ibmcld_16098-7-1823", "score": 17.546585, "text": "\nCreating a cluster in your Virtual Private Cloud (VPC) \n\nCreate an IBM Cloud\u00ae Kubernetes Service cluster in your Virtual Private Cloud (VPC).\n\nWith IBM Cloud Kubernetes Service clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https://cloud.ibm.com/docs/vpc?topic=vpc-about-vpc). VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of IBM Cloud Kubernetes Service [infrastructure providers](https://cloud.ibm.com/docs/containers?topic=containers-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality. You can create only standard clusters for VPC.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create an IBM Cloud Kubernetes Service cluster in a Virtual Private Cloud (VPC). Then, you deploy an app and expose the app publicly by using a load balancer.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in IBM Cloud Kubernetes Service in VPC for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.\n\nPermissions\n: If you are the account owner, you already have the required permissions to create a cluster and can continue to the next step. Otherwise, ask the account owner to [set up the API key and assign you the minimum user permissions in IBM Cloud IAM](https://cloud.ibm.com/docs/openshift?topic=openshift-access_referencecluster_create_permissions).\n\nCommand-line tools\n: For quick access to your resources from the command line, try the [IBM Cloud Shell](https://cloud.ibm.com/shell). Otherwise, set up your local command-line environment by completing the following steps.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc_ks_tutorial"}, {"document_id": "ibmcld_06294-3784-5599", "score": 17.497072, "text": "\nCreate a VPC called myvpc and note the ID in the output. VPCs provide an isolated environment for your workloads to run within the public cloud. You can use the same VPC for multiple clusters, such as if you plan to have different clusters host separate microservices that need to communicate with each other. If you want to separate your clusters, such as for different departments, you can create a VPC for each cluster.\n\nibmcloud is vpc-create myvpc\n2. Create a subnet for your VPC, and note its ID. Consider the following information when you create the VPC subnet:\n\n\n\n* Zones: You must have one VPC subnet for each zone in your cluster. The available zones depend on the metro location that you created the VPC in. To list available zones in the region, run ibmcloud is zones.\n* IP addresses: VPC subnets provide private IP addresses for your worker nodes and load balancer services in your cluster, so make sure to [create a subnet with enough IP addresses](https://cloud.ibm.com/docs/containers?topic=containers-vpc-subnetsvpc_basics_subnets), such as 256. You can't change the number of IP addresses that a VPC subnet has later.\n* Public gateways: You don't need to attach a public gateway to complete this tutorial. Instead, you can keep your worker nodes isolated from public access by using VPC load balancers to expose workloads securely. You might attach a public gateway if your worker nodes need to access a public URL. For more information, see [Planning your cluster network setup](https://cloud.ibm.com/docs/containers?topic=containers-plan_clusters).\n\n\n\nibmcloud is subnet-create mysubnet1 <vpc_ID> --zone us-south-1 --ipv4-address-count 256\n\n\n\n3. Create a cluster in your VPC in the same zone as the subnet. By default, your cluster is created with a public and a private cloud service endpoint.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-vpc_ks_tutorial"}]}
{"task_id": "747a810abfd6da4a9c37cdb74feec95e<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09655-7-1917", "score": 17.708378, "text": "\nCreate a cluster \n\nThis section steps through the build tasks needed to create the Windows Server Failover Cluster (WSFC) and the availability group.\n\nThis guide assumes that you:\n\n\n\n* Have at least two servers running Windows 2019 and SQL Server 2019 to cluster.\n* Have a bastion host with external Internet access.\n* Have deployed active directory.\n\n\n\n\n\n Install the Failover Clustering feature \n\n\n\n1. RDP to the first SQL server using a user from the SQL Admins group account and open a PowerShell session.\n2. Add the SQL Admins group to the local Remote Management Users group so users in this group, can execute remote commands.\n3. Allow inbound TCP port 5022 into the server as this port is used for availability group traffic. Install the Failover Clustering feature and then restart the server:\n\n$domainnb = \"<NB_Domain>\"\n$group = $domainnb + \"SQLAdmins\"\nAdd-LocalGroupMember -Group \"Remote Management Users\" -Member $group\nNew-NetFirewallRule -DisplayName 'SQL-AG-Inbound' -Profile Domain -Direction Inbound -Action Allow -Protocol TCP -LocalPort 5022\nInstall-WindowsFeature \u2013Name Failover-Clustering \u2013IncludeManagementTools\nRestart-Computer -Force\n4. Repeat for the second SQL server.\n\n\n\n\n\n\n\n Create a WSFC and enable SQL Always On \n\n\n\n1. RDP to the first SQL server using a user from the SQL Admins group account and open a PowerShell session.\n2. Run a cluster validation test. Ignore any \"one pair of network interfaces\" warnings, as this is normal for this deployment.\n3. If there are no errors them create a WSFC cluster with a name of wsfc01 which includes the two SQL servers <hostname1> and <hostname2>. The -ManagementPointNetworkType Distributed option uses the node IP address of the virtual server which means that secondary IP addressing on the interface is not required. This option creates a Distributed Network Name (DNN), which routes traffic to the appropriate clustered resource.\n4.", "title": "", "source": "https://cloud.ibm.com/docs/microsoft?topic=microsoft-mssql-cluster"}, {"document_id": "ibmcld_10354-7-1644", "score": 17.701952, "text": "\nLearning path for administrators \n\nFollowing a curated learning path through Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae to create a cluster, manage the cluster's resources and lifecycle, and use the powerful tools of Red Hat OpenShift on IBM Cloud to secure, manage, and monitor your cluster workloads.\n\n\n\n Plan your environment \n\nStart by designing a cluster for maximum availability and capacity for your workloads.\n\n\n\n1. Environment strategy:\n\n\n\n1. Define your [Kubernetes strategy](https://cloud.ibm.com/docs/openshift?topic=openshift-strategy) for the cluster, such as deciding how many clusters to create for your environments.\n2. Plan your [security strategy](https://cloud.ibm.com/docs/openshift?topic=openshift-securitynetwork_segmentation), such as ensuring network segmentation and workload isolation.\n\n\n\n2. Cluster setup: After you plan your environment, plan the setup for a specific cluster.\n\n\n\n1. Choose a [supported infrastructure provider](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providers).\n2. Plan your [cluster network setup](https://cloud.ibm.com/docs/openshift?topic=openshift-plan_clusters).\n3. Plan your cluster for [high availability](https://cloud.ibm.com/docs/openshift?topic=openshift-ha_clusters).\n4. Plan your [worker node setup](https://cloud.ibm.com/docs/openshift?topic=openshift-planning_worker_nodes).\n\n\n\n\n\nLooking for serverless? Try [Code Engine](https://cloud.ibm.com/docs/codeengine?topic=codeengine-getting-started).\n\n\n\n\n\n Create a cluster \n\nCreate a cluster with infrastructure, network, and availability setups that are customized to your use case and cloud environment.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-learning-path-admin"}, {"document_id": "ibmcld_10096-5554-7309", "score": 16.925537, "text": "\nLooking for a fast way to create a cluster from the UI? Try out [Automating cluster creation with IBM Cloud Schematics templates](https://cloud.ibm.com/docs/openshift?topic=openshift-templates).\n\n\n\n\n\n Deciding on your cluster setup \n\nAfter you set up your account to create clusters, decide on the setup for your cluster. You must make these decisions every time that you create a cluster. Review the following decision tree image for more information, such as comparisons of Kubernetes and Red Hat OpenShift, and VPC and classic infrastructure.\n\n\n\n\n\n Next steps \n\nWhen the cluster is up and running, you can check out the following cluster administration tasks:\n\n\n\n* If you created the cluster in a multizone capable zone, [spread worker nodes by adding a zone to your cluster](https://cloud.ibm.com/docs/openshift?topic=openshift-add_workers).\n* [Deploy an app in your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-deploy_appapp_cli)\n* [Set up your own private registry in IBM Cloud to store and share Docker images with other users.](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-started)\n* [Set up the cluster autoscaler](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-scaling-classic-vpc) to automatically add or remove worker nodes from your worker pools based on your workload resource requests.\n* Control who can create pods in your cluster with [pod security policies](https://cloud.ibm.com/docs/containers?topic=containers-psp).\n\n\n\nThen, you can check out the following network configuration steps for your cluster setup:\n\n\n\n* Classic clusters:\n\n\n\n* Isolate networking workloads to edge worker nodes [in classic clusters without a gateway](https://cloud.ibm.com/docs/openshift?topic=openshift-edge).", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-clusters"}, {"document_id": "ibmcld_13131-4462-6154", "score": 16.832201, "text": "\n* For Kubernetes on Classic infrastructure see reference documentation [Creating classic cluster](https://cloud.ibm.com/docs/containers?topic=containers-cluster-create-classic&interface=ui).\n* Choose a resource group.\n* Uncheck all zones except one.\n* Scale down to 1 Worker nodes per zone.\n* Choose the smallest Worker Pool flavor.\n* Enter a Cluster name.\n* Click Create.\n\n\n\n\n\n\n\n Step 1: Deploy a dynamic web application to be accelerated \n\nLet's consider a simple dynamic web application for collaboration for a team geographically distributed. With this application, team members can create and manage team's to-do items together.\n\nThis [sample application](https://github.com/IBM-Cloud/cdn-with-cda-todolist) is based on [Beego](https://github.com/beego/beego), a RESTful HTTP framework for the rapid development of Go applications including APIs, web apps and backend services.\n\n\n\n Build the application \n\n\n\n1. Clone the application\n\ngit clone https://github.com/IBM-Cloud/cdn-with-cda-todolist.git\n2. Change to the application directory\n\ncd cdn-with-cda-todolist\n3. Identify the cluster. ibmcloud ks cluster ls will return cluster names.\n\nibmcloud ks cluster ls\n\nSet the variable accordingly:\n\nMYCLUSTER=<cluster_name>\n4. Identify the Container Registry and set a namespace. ibmcloud cr info will return the name of the container registry.\n\nibmcloud cr info\n\nSet the variable accordingly:\n\nMYCONTAINERREGISTRY=<us.icr.io_like_value_returned_from_ibmcloud_cr_info>\n\nSet the variable to a name you want to used as a new namespace:\n\nMYNAMESPACE=<my_container_registry_namespace>\n5. Create a namespace to store the container image. Feel free to skip this step and use an existing namespace.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-dynamic-content-cdn"}, {"document_id": "ibmcld_05960-7-1650", "score": 16.72408, "text": "\nLearning path for administrators \n\nFollowing a curated learning path through IBM Cloud\u00ae Kubernetes Service to create a cluster, manage the cluster's resources and lifecycle, and use the powerful tools of IBM Cloud Kubernetes Service to secure, manage, and monitor your cluster workloads.\n\n\n\n Plan your environment \n\nStart by designing a cluster for maximum availability and capacity for your workloads.\n\n\n\n1. Environment strategy:\n\n\n\n1. Define your [Kubernetes strategy](https://cloud.ibm.com/docs/containers?topic=containers-strategy) for the cluster, such as deciding how many clusters to create for your environments.\n2. Plan your [security strategy](https://cloud.ibm.com/docs/containers?topic=containers-securitynetwork_segmentation), such as ensuring network segmentation and workload isolation.\n\n\n\n2. Cluster setup: After you plan your environment, plan the setup for a specific cluster.\n\n\n\n1. Choose a [supported infrastructure provider](https://cloud.ibm.com/docs/containers?topic=containers-infrastructure_providers).\n2. Plan your [cluster network setup](https://cloud.ibm.com/docs/containers?topic=containers-plan_clusters).\n3. Plan your cluster for [high availability](https://cloud.ibm.com/docs/containers?topic=containers-ha_clusters).\n4. Plan your [worker node setup](https://cloud.ibm.com/docs/containers?topic=containers-planning_worker_nodes).\n\n\n\n\n\nLooking for serverless? Try [Code Engine](https://cloud.ibm.com/docs/codeengine?topic=codeengine-getting-started).\n\n\n\n\n\n Create a cluster \n\nCreate a cluster with infrastructure, network, and availability setups that are customized to your use case and cloud environment.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-learning-path-admin"}, {"document_id": "ibmcld_05819-1301-3152", "score": 16.513676, "text": "\nGive your cluster a unique name, such as mycluster-free.\n4. Select a resource group to create the cluster in, such as default.\n5. In the Summary pane, review the order summary and then click Create. A worker pool is created that contains one worker node in the default resource group.\n\n\n\nThe worker node can take a few minutes to provision, but you can see the progress in the Worker nodes tab. When the status reaches Ready, you can start working with your cluster by [deploying your first app](https://cloud.ibm.com/docs/containers?topic=containers-getting-starteddeploy-app)!\n\n\n\n\n\n Creating a VPC cluster in the IBM Cloud console \n\nCreate a standard VPC cluster by using the IBM Cloud console. For more detailed information about your cluster customization options, see [Creating a standard VPC cluster](https://cloud.ibm.com/docs/containers?topic=containers-cluster-create-vpc-gen2&interface=ui).\n\nVPC clusters can be created as standard clusters only, and as such incur costs. Be sure to review the order summary at the end of this tutorial to review the costs for your cluster. To keep your costs to a minimum, set up your cluster as a single zone cluster with one worker node only.\n\n\n\n1. Create a Virtual Private Cloud (VPC) on generation 2 compute.\n\n\n\n1. Navigate to the [VPC create console](https://cloud.ibm.com/vpc/provision/vpc).\n2. Give the VPC a name and select a resource group to deploy the VPC into.\n3. Give the VPC subnet a name and select the location where you want to create the cluster.\n4. Attach a public gateway to your subnet so that you can access public endpoints from your cluster. This public gateway is used later on to access container images from Docker Hub.\n5. Click Create virtual private cloud.\n\n\n\n2. From the [IBM Cloud Kubernetes Service dashboard](https://cloud.ibm.com/kubernetes/clusters), click Create cluster.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-getting-started"}, {"document_id": "ibmcld_13115-3024-4814", "score": 16.46858, "text": "\nA minimal cluster with one (1) zone, one (1) worker node and the smallest available size (Flavor) is sufficient for this tutorial. The name mycluster will be used in this tutorial.\n\nOpen the [Kubernetes clusters](https://cloud.ibm.com/kubernetes/clusters) and click Create cluster. See the documentation referenced below for more details based on the cluster type. Summary:\n\n\n\n* Click Standard tier cluster\n* For Kubernetes on VPC infrastructure see reference documentation[Creating VPC clusters](https://cloud.ibm.com/docs/containers?topic=containers-cluster-create-vpc-gen2&interface=ui).\n\n\n\n* Click Create VPC:\n\n\n\n* Enter a name for the VPC.\n* Chose the same resource group as the cluster.\n* Click Create.\n\n\n\n* Attach a Public Gateway to each of the subnets that you create:\n\n\n\n* Navigate to the [Virtual private clouds](https://cloud.ibm.com/vpc-ext/network/vpcs).\n* Click the previously created VPC used for the cluster.\n* Scroll down to subnets section and click a subnet.\n* In the Public Gateway section, click Detached to change the state to Attached.\n* Click the browser back button to return to the VPC details page.\n* Repeat the previous three steps to attach a public gateway to each subnet.\n\n\n\n\n\n* For Kubernetes on Classic infrastructure see reference documentation [Creating classic cluster](https://cloud.ibm.com/docs/containers?topic=containers-cluster-create-classic&interface=ui).\n* Choose a resource group.\n* Uncheck all zones except one.\n* Scale down to 1 Worker nodes per zone.\n* Choose the smallest Worker Pool flavor.\n* Enter a Cluster name.\n* Click Create.\n\n\n\n\n\n\n\n Step 2: Deploy and configure a Kubernetes app to forward logs \n\nThe ready-to-run [code for the logging app is located in this GitHub repository](https://github.com/IBM-Cloud/application-log-analysis).", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-application-log-analysis"}, {"document_id": "ibmcld_10568-21131-23284", "score": 16.458029, "text": "\nInstead of making more clusters, you can add worker pools for different flavors of computing resources available for the app and service components that you want to use. When you develop the app, the resources it uses are in the same zone, or otherwise closely connected in a multizone, so that you can make assumptions about latency, bandwidth, or correlated failures. However, it becomes even more important for you to organize your cluster by using namespaces, resource quotas, and labels.\n\n\n\n\n\n How can I set up my resources within the cluster? \n\n\n\n Consider your worker node capacity \n\nTo get the most out of your worker node's performance, consider the following: - Keep up your core strength: Each machine has a certain number of cores. Depending on your app's workload, set a limit for the number of pods per core, such as 10. - Avoid node overload: Similarly, just because a node can contain more than 100 pods doesn't mean that you want it to. Depending on your app's workload, set a limit for the number of pods per node, such as 40. - Don't tap out your cluster bandwidth**: Keep in mind that network bandwidth on scaling virtual machines is around 1000 Mbps. If you need hundreds of worker nodes in a cluster, split it up into multiple clusters with fewer nodes, or order bare metal nodes. - Sorting out your services: Plan out how many services that you need for your workload before you deploy. Networking and port forwarding rules are put into Iptables. If you anticipate a larger number of services, such as more than 5,000 services, split up the cluster into multiple clusters.\n\n\n\n\n\n Provision different types of machines for a mix of computing resources \n\nEveryone likes choices, right? With Red Hat OpenShift on IBM Cloud, you have [a mix of flavors](https://cloud.ibm.com/docs/openshift?topic=openshift-planning_worker_nodesplanning_worker_nodes) that you can deploy: from bare metal for intensive workloads to virtual machines for rapid scaling. Use labels or namespaces to organize deployments to your machines. When you create a deployment, limit it so that your app's pod deploys only on machines with the best mix of resources.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-strategy"}, {"document_id": "ibmcld_05628-4-2149", "score": 16.296066, "text": "\n* UI\n* CLI\n* Terraform\n\n\n\n\n\n\n\n Creating classic clusters \n\nClassic infrastructure\n\nUse the IBM Cloud CLI or the IBM Cloud console to create a fully customizable standard cluster with your choice of hardware isolation and access to features like multiple worker nodes for a highly available environment.\n\nRed Hat OpenShift on IBM Cloud clusters are created with a public only or both a public and private service endpoint. Public service endpoints can't be disabled, and therefore, you can't convert a public Red Hat OpenShift cluster to a private one. If you want your cluster to remain private, see [Planning your cluster network setup](https://cloud.ibm.com/docs/containers?topic=containers-plan_vpc_basicsvpc-pgw).\n\n\n\n Creating a classic cluster in the console \n\nCreate your single zone or multizone classic Kubernetes cluster by using the IBM Cloud console. Follow the console instructions to make the following cluster configurations. To begin creating your cluster, navigate to the [Kubernetes clusters console](https://cloud.ibm.com/kubernetes/clusters) and click Create cluster.\n\nLocation details\n: When you create a cluster, its resources remain in the location that you deploy the cluster to.\n: \n\n* Resource group: A cluster can be created in only one resource group, and after the cluster is created, you can't change its resource group. To create clusters in a resource group other than the default, you must have at least the [Viewer role](https://cloud.ibm.com/docs/containers?topic=containers-userschecking-perms) for the resource group.\n\n\n\n: \n\n* Geography: Select an area to create the cluster in, such as North America. The geography helps filter the Availability and Metro values that you can select in the console.\n\n\n\n: \n\n* Availability: A cluster can be created with a Single zone or Multizone configuration. A multizone cluster provides high availability, with the Kubernetes master deployed in a multizone-capable zone and three replicas of the master spread across different zones.\n\n\n\n* For multizone clusters, choose a Metro location. For the best performance, select the metro location that is physically closest to you.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cluster-create-classic&interface=ui"}, {"document_id": "ibmcld_10096-7-1787", "score": 16.164017, "text": "\nPreparing to create clusters \n\nCreate a cluster in Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae.\n\nAfter [getting started](https://cloud.ibm.com/docs/containers?topic=containers-getting-started), you might want to create a cluster that is customized to your use case and different public and private cloud environments. Consider the following steps to create the correct cluster each time.\n\n\n\n1. [Prepare your account to create clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-clusterscluster_prepare). This step includes creating a billable account, setting up an API key with infrastructure permissions, making sure that you have Administrator access in IBM Cloud IAM, planning resource groups, and setting up account networking.\n2. [Decide on your cluster setup](https://cloud.ibm.com/docs/openshift?topic=openshift-clustersprepare_cluster_level). This step includes planning cluster network and HA setup, estimating costs, and if applicable, allowing network traffic through a firewall.\n3. Create your [VPC Gen2](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-vpc-gen2) or [classic](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-classic) cluster by following the steps in the IBM Cloud console or CLI.\n\n\n\n\n\n Preparing to create clusters at the account level \n\nPrepare your IBM Cloud account for IBM Cloud Kubernetes Service. After the account administrator makes these preparations, you might not need to change them each time that you create a cluster. However, each time that you create a cluster, you still want to verify that the current account-level state is what you need it to be.\n\n\n\n1. [Create or upgrade your account to a billable account (IBM Cloud Pay-As-You-Go or Subscription)](https://cloud.ibm.com/registration).\n2.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-clusters"}]}
{"task_id": "747a810abfd6da4a9c37cdb74feec95e<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_12581-17606-19704", "score": 20.228891, "text": "\nIf you are validating a deployable architecture that references modules from the catalog, make sure that the modules were onboarded to the catalog.\n\n\n\n1. From the Validate version page, enter the name of your Schematics service, select a resource group, select a Schematics region, and click Next.\n\nIn the Tags field, you can enter a name of a specific tag to attach to your template. This tag is put on the IBM Cloud Schematics workspace. Tags provide a way to organize, track usage costs, and manage access to the resources in your account.\n2. From the input variables section, review your parameter values, and click Next.\n3. In the Validation version section, select I have read and agree to the following license agreements.\n4. Click Validate.\n\nTo monitor the progress of the validation process, click View logs.\n\n\n\n\n\n\n\n Validating a test deployment by using the CLI \n\nTo validate a version of your deployable architecture into an existing product, run the [ibmcloud catalog offering version validate](https://cloud.ibm.com/docs/cli?topic=cli-manage-catalogs-pluginvalidate-offering) command:\n\nibmcloud catalog offering version validate --vl <VERSION_LOCATOR>\n\n\n\n\n\n Reviewing cost by using the CLI \n\nReview the cost of your deployable architecture by using the console. To view the steps, see [Reviewing or defining cost by using the console](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-onboard-custom&interface=uicustom-cost-ui).\n\n\n\n\n\n Reviewing or defining cost by using the console \n\nYou can review the estimated starting cost of your product. If you included the resource metadata in your source repository, the information is parsed during validation and pulled into a starting cost per hour (USD) summary table. The table is displayed in the catalog for customers to compare across variations of a deployable architecture or to get a general idea of what a base configuration of your deployable architecture might cost.\n\nThe summary table lists the resources that your product uses and their estimated costs. Starting cost is an estimate based on available data.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-onboard-custom"}, {"document_id": "ibmcld_12104-9776-11234", "score": 18.430944, "text": "\nSoftware deployments with Schematics\n\n\n\n1. Choose a template: The [IBM software solutions catalog](https://cloud.ibm.com/catalogsoftware) offers a wide variety of infrastructure and software templates that you can choose from. These templates help to quickly install software, such as IBM Cloud Paks, IBM\u00ae WebSphere Application Server for IBM Cloud\u00ae, or Kibana and Grafana into the target service of your choice.\n2. Configure your workspace and target: When you choose one of the provided templates, you must select the target where you want to install the template. Depending on the template that you choose, the target can be an IBM Cloud Kubernetes Service cluster, a Red Hat OpenShift on IBM Cloud cluster, or a classic or Virtual Servers for VPC. Because Schematics is used to install the software, you must configure the workspace that is automatically created for you.\n3. Run the template: When you run the template, Schematics uses the built-in Terraform, Ansible, Helm, OpenShift Operator, or Cloud Pak capabilities to install your software or spin up infrastructure resources. You can use your workspace to monitor the progress of your template execution.\n\n\n\n\n\n\n\n Next steps \n\n\n\n* Explore blueprint samples by using Schematics [tutorials](https://cloud.ibm.com/docs/schematics?topic=schematics-provisioning-terraform-template).\n* Click [here](https://cloud.ibm.com/docs/schematics?topic=schematics-how-it-works) to revisit the Schematics use cases.", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-how-it-works"}, {"document_id": "ibmcld_11998-4-1884", "score": 18.076698, "text": "\nSchematics Blueprints is a [beta feature](https://cloud.ibm.com/docs/schematics?topic=schematics-bp-beta-limitations) that are available for evaluation and testing purposes. It is not intended for production usage. Refer to the list of [limitations](https://cloud.ibm.com/docs/schematics?topic=schematics-bp-beta-limitationssc-bp-beta-limitation) for the beta release.\n\n\n\n Reuse and customization \n\nIBM Cloud\u00ae Schematics Blueprints utilizes the analogy of building a house from a blueprint drawing. Where a blueprint defines the architecture, layout, major building blocks and customizations to be applied.\n\nThis building analogy also applies to reuse across environments. A builder may build an entire street of houses from the same blueprint drawing. Each house customized by its choice of color, lighting and styling, but all built to the same design.\n\nBlueprint template reuse supports a number of use cases:\n\n\n\n* Sharing an approved architecture across teams within a business\n* Deploying instances across multiple regions to create a highly resilient application deployment\n* Software delivery pipelines, dev, stage, prod\n\n\n\n\n\n Reuse across environments \n\nA blueprint template (house design) is reusable across environments, using a separately maintained [input configuration](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-termsbpi1) to define the customizations for the target environment and usage. The figure illustrates this with deploying dev, stage and prod environments.\n\nZoom\n\n![Environments deployed from reusable blueprint template](https://cloud.ibm.com/docs-content/v1/content/ba89e173287b28d1453d2a327d8a1f74ae2f1662/schematics//images/new/bp-reuse.svg)\n\nEnvironments deployed from reusable blueprint template\n\nA common reusable template defines the architecture, with separate input files for the dev, stage and prod for define the customizations.", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-blueprint-reuse"}, {"document_id": "ibmcld_16727-623510-625767", "score": 17.867376, "text": "\nIBM Cloud Schematics provides powerful tools to automate your cloud infrastructure provisioning and management process, the configuration and operation of your cloud resources, and the deployment of your app workloads.\n\nTo do so, Schematics uses open source projects, such as Terraform, Ansible, Red Hat OpenShift, Operators, and Helm, and delivers these capabilities to you as a managed service. Rather than installing each open source project on your system, and learn the API or CLI. You can declare the tasks that you want to run in IBM Cloud and watch Schematics run these tasks for you.\n\nFor more information about how Schematics Works, see [About IBM Cloud Schematics](https://cloud.ibm.com/docs/schematics?topic=schematics-learn-about-schematics).\n* What is Infrastructure as Code?\n\nInfrastructure as Code (IaC) helps you codify your cloud environment so that you can automate the provisioning and management of your resources in the cloud. Rather than manually provisioning and configuring infrastructure resources or by using scripts to adjust your cloud environment, you use a high-level scripting language to specify your resource and its configuration. Then, you use tools like Terraform to provision the resource in the cloud by using its API. Your infrastructure code is treated the same way as your app code so that you can apply DevOps core practices such as version control, testing, and continuous monitoring.\n* What am I charged for when I use Schematics?\n\nIBM Cloud Schematics Workspaces are provided to you at no cost. However, when you decide to apply your Terraform template in IBM Cloud by clicking Apply plan from the workspace details page or running the ibmcloud schematics apply command, you are charged for the IBM Cloud resources that are described in your Terraform template. Review available service plans and pricing information for each resource that you are about to create. Some services come with a limit per IBM Cloud account. If you are about to reach the service limit for your account, the resource is not provisioned until you increase the service quota, or remove existing services first.\n\nThe Schematics ibmcloud terraform command usage displays warning and deprecation message as Alias Terraform are deprecated.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-623552-625809", "score": 17.867376, "text": "\nIBM Cloud Schematics provides powerful tools to automate your cloud infrastructure provisioning and management process, the configuration and operation of your cloud resources, and the deployment of your app workloads.\n\nTo do so, Schematics uses open source projects, such as Terraform, Ansible, Red Hat OpenShift, Operators, and Helm, and delivers these capabilities to you as a managed service. Rather than installing each open source project on your system, and learn the API or CLI. You can declare the tasks that you want to run in IBM Cloud and watch Schematics run these tasks for you.\n\nFor more information about how Schematics Works, see [About IBM Cloud Schematics](https://cloud.ibm.com/docs/schematics?topic=schematics-learn-about-schematics).\n* What is Infrastructure as Code?\n\nInfrastructure as Code (IaC) helps you codify your cloud environment so that you can automate the provisioning and management of your resources in the cloud. Rather than manually provisioning and configuring infrastructure resources or by using scripts to adjust your cloud environment, you use a high-level scripting language to specify your resource and its configuration. Then, you use tools like Terraform to provision the resource in the cloud by using its API. Your infrastructure code is treated the same way as your app code so that you can apply DevOps core practices such as version control, testing, and continuous monitoring.\n* What am I charged for when I use Schematics?\n\nIBM Cloud Schematics Workspaces are provided to you at no cost. However, when you decide to apply your Terraform template in IBM Cloud by clicking Apply plan from the workspace details page or running the ibmcloud schematics apply command, you are charged for the IBM Cloud resources that are described in your Terraform template. Review available service plans and pricing information for each resource that you are about to create. Some services come with a limit per IBM Cloud account. If you are about to reach the service limit for your account, the resource is not provisioned until you increase the service quota, or remove existing services first.\n\nThe Schematics ibmcloud terraform command usage displays warning and deprecation message as Alias Terraform are deprecated.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_12052-2939-4666", "score": 17.723341, "text": "\nTemplates are [reusable across multiple environments](https://cloud.ibm.com/docs/schematics?topic=schematics-define-blueprintsdefine-templates-input), with the customizable input values maintained separately from the template as [inputs](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-termsbpi1). In cookie cutter fashion, several environments can be created from the same blueprint template. Each environment has its own [blueprint configuration](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-termsbpb3) and inputs. This separation of template from its runtime configuration allows a single template to be reused many times to deploy a range of environments such as dev, stage, and production with multiple target regions. Each environment being customized with its own input values. See the section [Understanding blueprint templates and configuration](https://cloud.ibm.com/docs/schematics?topic=schematics-blueprint-templates) for more details.\n\nFor examples of blueprint templates and inputs, see the [IBM Cloud Schematics repository](https://github.com/orgs/Cloud-Schematics/repositories?q=blueprint). Creation and editing of blueprints can be performed in [VSCode with the YAML language extension](https://cloud.ibm.com/docs/schematics?topic=schematics-edit-blueprints). Refer to the sections [understanding blueprint templates and configurations](https://cloud.ibm.com/docs/schematics?topic=schematics-blueprint-templates) and [blueprint template reference](https://cloud.ibm.com/docs/schematics?topic=schematics-bp-template-schema-yaml) for guidance to the blueprint syntax when creating or modifying a template.\n\nChange in blueprint environments is explicitly managed through version control.", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-define-blueprints"}, {"document_id": "ibmcld_12095-7-2147", "score": 17.510506, "text": "\nGeneral \n\nAnswers to common questions about the IBM Cloud Schematics are classified into following section.\n\n\n\n What is IBM Cloud Schematics and how does it work? \n\nIBM Cloud Schematics provides powerful tools to automate your cloud infrastructure provisioning and management process, the configuration and operation of your cloud resources, and the deployment of your app workloads.\n\nTo do so, Schematics uses open source projects, such as Terraform, Ansible, Red Hat OpenShift, Operators, and Helm, and delivers these capabilities to you as a managed service. Rather than installing each open source project on your system, and learn the API or CLI. You can declare the tasks that you want to run in IBM Cloud and watch Schematics run these tasks for you.\n\nFor more information about how Schematics Works, see [About IBM Cloud Schematics](https://cloud.ibm.com/docs/schematics?topic=schematics-learn-about-schematics).\n\n\n\n\n\n What is Infrastructure as Code? \n\nInfrastructure as Code (IaC) helps you codify your cloud environment so that you can automate the provisioning and management of your resources in the cloud. Rather than manually provisioning and configuring infrastructure resources or by using scripts to adjust your cloud environment, you use a high-level scripting language to specify your resource and its configuration. Then, you use tools like Terraform to provision the resource in the cloud by using its API. Your infrastructure code is treated the same way as your app code so that you can apply DevOps core practices such as version control, testing, and continuous monitoring.\n\n\n\n\n\n What am I charged for when I use Schematics? \n\nIBM Cloud Schematics Workspaces are provided to you at no cost. However, when you decide to apply your Terraform template in IBM Cloud by clicking Apply plan from the workspace details page or running the ibmcloud schematics apply command, you are charged for the IBM Cloud resources that are described in your Terraform template. Review available service plans and pricing information for each resource that you are about to create. Some services come with a limit per IBM Cloud account.", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-general-faq"}, {"document_id": "ibmcld_12100-1957-2542", "score": 17.508612, "text": "\n[Large-scale environments](https://cloud.ibm.com/docs-content/v1/content/ba89e173287b28d1453d2a327d8a1f74ae2f1662/schematics/images/gs_scale.svg) <br>Deploy large-scale environments Deploy and manage large-scale environments with [Schematics Blueprints](https://cloud.ibm.com/docs/schematics?topic=schematics-get-started-blueprints). Manage the lifecycle of large and complex application infrastructures, created from reusable Terraform based automation modules. Reuse version templates and modules. [Link](https://cloud.ibm.com/docs/schematics?topic=schematics-get-started-blueprints)", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-getting-started"}, {"document_id": "ibmcld_12104-8356-10191", "score": 17.382786, "text": "\nBrowse the [IBM software solutions catalog](https://cloud.ibm.com/catalogsoftware) and choose among a wide range of software and infrastructure templates that you can use to set up cloud resources, and to install IBM and Third party software in your IBM Cloud Kubernetes Service cluster, Red Hat OpenShift on IBM Cloud cluster, or a classic or Virtual Servers for VPC.\n\nSoftware templates are installed by using the built-in Terraform, Ansible, Helm, Red Hat OpenShift on IBM Cloud Operator, and Cloud Pak capabilities in Schematics. When you choose to install one of the provided templates, you create a Schematics Workspaces and choose the target service or host where you want run the installation. You can review which of the integrated technologies in Schematics is used to install your template.\n\nYou can also create your own software and infrastructure templates and import them in to your own private catalog in IBM Cloud. For more information, see [Adding products to a private catalog](https://cloud.ibm.com/docs/account?topic=account-create-private-catalog)\n\nTo get started with software deployment in Schematics, see the [Getting started tutorial](https://cloud.ibm.com/docs/schematics?topic=schematics-get-started-software).\n\nZoom\n\n![Software deployments with Schematics](https://cloud.ibm.com/docs-content/v1/content/ba89e173287b28d1453d2a327d8a1f74ae2f1662/schematics/images/software_flow.png)\n\nFigure 3. Software deployments with Schematics\n\n\n\n1. Choose a template: The [IBM software solutions catalog](https://cloud.ibm.com/catalogsoftware) offers a wide variety of infrastructure and software templates that you can choose from. These templates help to quickly install software, such as IBM Cloud Paks, IBM\u00ae WebSphere Application Server for IBM Cloud\u00ae, or Kibana and Grafana into the target service of your choice.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-how-it-works"}, {"document_id": "ibmcld_12002-4-1944", "score": 17.329552, "text": "\nSchematics Blueprints is a [beta feature](https://cloud.ibm.com/docs/schematics?topic=schematics-bp-beta-limitations) that are available for evaluation and testing purposes. It is not intended for production usage. Refer to the list of [limitations](https://cloud.ibm.com/docs/schematics?topic=schematics-bp-beta-limitationssc-bp-beta-limitation) for the beta release.\n\n\n\n Understanding blueprint templates and configuration \n\nIBM Cloud\u00ae Schematics Blueprints utilizes the analogy of building a house from a blueprint drawing. Where a blueprint defines the architecture, layout and the major building blocks.\n\n\n\n Blueprint configuration \n\nCloud environments are deployed from a blueprint configuration, specifying a blueprint template and customizable input values that define parameters like its region or compute capacity. [Templates](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-termsbpb2) determine the infrastructure architecture, specifying the modules (building blocks) to deploy the cloud resources of an environment. The section [using Terraform modules with blueprint templates](https://cloud.ibm.com/docs/schematics?topic=schematics-blueprint-terraform) illustrates how public modules can be combined with user developed modules to create custom solutions.\n\nWell designed templates are reusable across multiple environments, with the customizable input values maintained separately from the template as [inputs](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-termsbpi1). In cookie cutter fashion, several environments can be created from the same blueprint template. Each environment has its own [blueprint configuration](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-termsbpb3) and inputs. This separation of template from its deploy time configuration is illustrated in the figure. Here a template is reused many times to deploy a range of environments such as dev, stage, and production.", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-blueprint-templates&interface=ui"}]}
{"task_id": "747a810abfd6da4a9c37cdb74feec95e<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04031-1609-3779", "score": 22.292051, "text": "\nFor IBM Blockchain Platform cost estimation purposes, 1 VPC = 1 CPU = 1 vCPU = 1 Core. The term \"VPC\" is also used to refer to a type of infrastructure on IBM Cloud and is unrelated to this topic.\n\nFor a total cost estimate, remember that your blockchain network consists of an Kubernetes cluster on IBM Cloud that contains IBM Blockchain Platform components and uses storage of your choice. Your Kubernetes cluster on IBM Cloud and the storage that you choose incur separate charges. You will not be charged for the cluster that the Operational Tooling instance, also known as the console, is running on. See the [Architecture reference](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-overviewibp-console-overview-architecture) topic for an illustration. More details on how to calculate charges are described below.\n\n\n\n Benefits of the new pricing model \n\n\n\n* No membership fees: Freedom from membership fees means that you can invest directly in your blockchain components.\n* Estimation clarity: A simple hourly pricing model makes cost estimation clear and easy by using the cost estimator tool that is available in the IBM Cloud dashboard.\n* No minimum fee required: Pay for only what you use, no minimum VPC hourly package is required, which makes it very inexpensive to get started.\n* Scalability of compute: You have the option to scale your compute up during peak usage periods or down to a minute fraction of capacity for when the compute is not needed to minimize expense.\n\n\n\nIn summary, these features remove the complexity of accounting for membership limitations or purchasing compute ahead of your needs.\n\n\n\n\n\n Find out how to preview the platform free for 30 days \n\nYou can preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster.\n\nLimitations of the free preview\n\n\n\n* Performance will be limited by throughput, storage, and functionality. Read more about the [limitations of free clusters](https://cloud.ibm.com/docs/containers?topic=containers-cs_ovcluster_types).\n* IBM Cloud will delete your Kubernetes cluster after 30 days.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-saas-pricing"}, {"document_id": "ibmcld_11408-13151-14243", "score": 19.298866, "text": "\nThe following table shows the charges based on the number of connections (includes all types of connection such as DL, VPC, etc.) that you create:\n\n\n\nTable 14. TGW charges based on number of connections\n\n Number of connections Charges \n\n 1 - 4 No charges \n 5 - 20 $9.405 \n 21 - 50 $7.315 \n 51+ $4.7025 \n\n\n\nThe Transit Gateway charges indicated in the tables above are subjected to change. To calculate your pricing, use the [IBM cost estimator](https://cloud.ibm.com/estimator) in IBM Cloud console.\n\n\n\n\n\n End of billing \n\nThe monthly billing cycle ends when you delete the LPAR. If you scale your infrastructure up and down in response to workload requirements, your billing follows the timing of the LPAR provision change. If you stop the LPAR, the billing process is not stopped. You must delete the LPAR to stop the billing cycle.\n\nYou are still charged if the VM is in a suspended state. When your VM is inactive, you can use Dynamic Logical Partitioning (DLPAR) to resize it to a minimal state. You can drastically decrease the price per hour by reducing the VM's core count and memory.", "title": "", "source": "https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-pricing-virtual-server"}, {"document_id": "ibmcld_10116-16035-17814", "score": 18.822586, "text": "\nPricing for VPC infrastructure varies based on regional location and sustained usage.\n\nThis information applies to VPC worker nodes only.\n\nRegional uplift charges\n: When you create a cluster on VPC infrastructure, the worker nodes might incur an uplift charge that varies by the [multizone location](https://cloud.ibm.com/docs/openshift?topic=openshift-regions-and-zoneszones-vpc) that you create the cluster in. The uplift charge is a percentage (%) of the hourly rate (r), and is added to the hourly rate of the worker node. The total hourly rate cost for a worker node can be calculated as r + (r \u00d7 %). In the [Red Hat OpenShift cluster creation console](https://cloud.ibm.com/kubernetes/catalog/create?platformType=openshift), this uplift is reflected in the pricing calculator as you configure your cluster details. The following table describes the pricing uplift by region.\n: For a table that describes the pricing uplift by region, see [Regional pricing for VPC](https://cloud.ibm.com/vpc-ext/provision/vs).\n\nSustained usage discounts\n: For virtual server instances that are billed at an hourly rate, discounted prices depend on how long the instance runs during the billing month. For more information, expand the Sustained usage discounts on IBM Cloud Virtual Servers for VPC section on the [Pricing for VPC](https://cloud.ibm.com/vpc-ext/provision/vs) page.\n\n\n\n\n\n\n\n Estimating costs \n\nSee [Estimating your costs](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as tiered pricing for increased hourly usage. For more information, see [Understanding costs for your clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-costscosts-for-clusters).\n\n\n\n\n\n Managing costs", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-costs"}, {"document_id": "ibmcld_05666-8826-10757", "score": 18.23596, "text": "\nReview each product documentation and use the IBM Cloud console to [estimate costs](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-costcost).\n\n\n\n\n\n Operators and other third-party integrations \n\nOperators and other [third-party integrations](https://cloud.ibm.com/docs/containers?topic=containers-supported_integrations) are a convenient way to add services to your cluster from community, third-party, your own, or other providers. Keep in mind that you are responsible for additional charges and how these services operate in your cluster, from deployment and maintenance to integration with your apps. If you have issues with an operator or third-party integration, work with the appropriate provider to troubleshoot the issue.\n\n\n\n\n\n VPC worker nodes \n\nPricing for VPC infrastructure varies based on regional location and sustained usage.\n\nThis information applies to VPC worker nodes only.\n\nRegional uplift charges\n: When you create a cluster on VPC infrastructure, the worker nodes might incur an uplift charge that varies by the [multizone location](https://cloud.ibm.com/docs/containers?topic=containers-regions-and-zoneszones-vpc) that you create the cluster in. The uplift charge is a percentage (%) of the hourly rate (r), and is added to the hourly rate of the worker node. The total hourly rate cost for a worker node can be calculated as r + (r \u00d7 %). In the [Kubernetes cluster creation console](https://cloud.ibm.com/kubernetes/catalog/create), this uplift is reflected in the pricing calculator as you configure your cluster details. The following table describes the pricing uplift by region.\n: For a table that describes the pricing uplift by region, see [Regional pricing for VPC](https://cloud.ibm.com/vpc-ext/provision/vs).\n\nSustained usage discounts\n: For virtual server instances that are billed at an hourly rate, discounted prices depend on how long the instance runs during the billing month.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-costs"}, {"document_id": "ibmcld_05666-3176-5101", "score": 18.177547, "text": "\n* 291 - 540 hours\n* 541+ hours\n\n\n\n\n\nPhysical machines, or bare metal, (not available for VPC clusters) yield high-performance benefits for workloads such as data, GPU, and AI. Additionally, all the hardware resources are dedicated to your workloads, so you don't have \"noisy neighbors\". Keep in mind these factors that impact your bare metal costs.\n\n\n\n* Monthly billing only: All bare metals are charged monthly.\n* Longer ordering process: After you order or cancel a bare metal server, the process is completed manually in your IBM Cloud infrastructure account. Therefore, it can take more than one business day to complete.\n\nVPC Generation 2 only: Prices vary by region where the underlying worker node infrastructure resides, and you can get sustained usage discounts. For more information, see [What are the regional uplift charges and sustained usage discounts for VPC worker nodes?](https://cloud.ibm.com/docs/containers?topic=containers-costscharges_vpc_gen2).\n\n\n\nFor more information about worker node specifications, see [Available hardware for worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-planning_worker_nodesplanning_worker_nodes).\n\n\n\n\n\n Public bandwidth \n\nBandwidth refers to the public data transfer of inbound and outbound network traffic, both to and from IBM Cloud resources in data centers around the globe.\n\nClassic clusters: Public bandwidth is charged per GB. You can review your current bandwidth summary by logging into the [IBM Cloud console](https://cloud.ibm.com/), from the menu ![Menu icon](https://cloud.ibm.com/docs-content/v1/content/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7/icons/icon_hamburger.svg) selecting Classic Infrastructure, and then selecting the Network > Bandwidth > Summary page.\n\nReview the following factors that impact public bandwidth charges:\n\n\n\n* Location: As with worker nodes, charges vary depending on the zone that your resources are deployed in.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-costs"}, {"document_id": "ibmcld_15960-7-2327", "score": 17.861208, "text": "\nSuspend billing for VPC \n\nWhen you stop a virtual server instance by using the IBM Cloud console, CLI, or API, you don't accrue costs for certain compute resources. Billing stops automatically when you stop the instance. The suspend billing feature helps you reduce cost and prevents you from having to re-create an instance when you need its resources again.\n\nIn situations where you want to scale your infrastructure up and down in response to workload needs, you can stop an instance (and stop billing) as a faster alternative to creating and deleting instances.\n\n\n\n Billing details \n\nIt's important to understand what costs stop accruing and what costs persist when your virtual server instance is powered off.\n\nReview the following table for details on how suspended billing impacts various resource charges.\n\n\n\nTable 7. Resource billing details\n\n Resource Billing stopped Billing persists \n\n vCPU X \n RAM X \n Operating system licenses X \n Floating IPs, Load balancers, or other attached networking offerings X \n Storage X \n\n\n\nUsage times are calculated per second, for both the in use time and suspended time of your virtual server instance. Even if you never initiate the suspend billing feature by powering off your instance, the billing is calculated per second of the instance's lifecycle. No minimum usage requirement exists for an instance.\n\n\n\n Suspend billing and sustained usage discounts \n\nFor sustained usage discounts, a suspended image picks up from where it was on the discount tier. In other words, a usage discount applies only to the time the image is in use, not to the time the image was suspended.\n\n\n\n\n\n Billing invoice \n\nWhen you suspend billing on a virtual server, you see a few changes in your billing invoice. The relevant charges now appear as usage-based details. For example, you might see the following additions that reflect hours available, hours that instances were used, and total number of hours charged:\n\nComputing instance usage...\nRAM usage...\nOperating system usage...\n\n\n\n\n\n\n\n Resource details \n\n\n\n Storage \n\nWhen you suspend billing on a virtual server instance, the associated storage persists, but you can't access data while the virtual server instance is powered off. When you resume billing on the instance, you can then access your data, and normal billing begins again.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-suspend-billing"}, {"document_id": "ibmcld_10116-10237-12114", "score": 17.67616, "text": "\n[Menu icon](https://cloud.ibm.com/docs-content/v1/content/bce0f0917a9eea684d1b4b704ac6343a1f65f446/icons/icon_hamburger.svg) selecting Classic Infrastructure, and then selecting the Network > Bandwidth > Summary page.\n\nReview the following factors that impact public bandwidth charges:\n\n\n\n* Location: As with worker nodes, charges vary depending on the zone that your resources are deployed in.\n* Pay-As-You-Go for VM: Because VMs are billed at an hourly rate, your VM worker node machines have a Pay-As-You-Go allocation of outbound networking based on GB usage.\n* Included bandwidth and tiered packages for BM: Bare metal worker nodes might come with a certain allocation of outbound networking per month that varies by geography: 20 TB for North America and Europe, or 5 TB for Asia Pacific and South America. After you exceed your included bandwidth, you are charged according to a tiered usage scheme for your geography. If you exceed a tier allotment, you might also be charged a standard data transfer fee. For more information, see [Bandwidth packages](https://www.ibm.com/cloud/bandwidth).\n\n\n\nVPC clusters: For more information about how internet data transfer works in your Virtual Private Cloud, see [Pricing for VPC](https://cloud.ibm.com/vpc-ext/provision/vs).\n\n\n\n\n\n Subnet IP addresses \n\nSubnets for Red Hat OpenShift on IBM Cloud clusters vary by infrastructure provider.\n\nClassic clusters: When you create a standard cluster, a portable public subnet with 8 public IP addresses is ordered and charged to your account monthly. For pricing information, see the [Subnets and IPs](https://cloud.ibm.com/docs/subnets) documentation or estimate your costs in the [classic subnets console)](https://cloud.ibm.com/classic/network/subnet/provision). If you already have available portable public subnets in your infrastructure account, you can use these subnets instead.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-costs"}, {"document_id": "ibmcld_11408-11687-13539", "score": 17.66908, "text": "\nData volumes of 235 GB\n\nBoot volumes of 200 GB\n\nDeployed VMs of 160 GB\n\n\n\nTable 10. Account billable for storage use case\n\n Name Size State/Description \n\n data-volume-1 20 GB Available \n data-volume-2 25 GB In-use (attached to vm-1) \n data-volume-3 100 GB In-use (attached to vm-1) \n data-volume-4 30 GB Available \n data-volume-5 60 GB In-use (attached to vm-2) \n\n\n\nTotal billable storage = 595 GB\n\n\n\n* Data volumes: 235 GB\n* Image volumes: 200 GB\n* Deployed VMs: 160 GB\n\n\n\n\n\n\n\n\n\n Pricing for VPN connection \n\nWhen you use a VPN connection, you are billed monthly.\n\nIBM charges with the base price hourly per connection. The base price varies per geography. So if you use one vpn connection that is active for a month, the monthly bill would be $base price X 24 hours X 30 days.\n\n\n\n\n\n Pricing for Power Edge Router \n\nAs a Power Systems Virtual Server user, you are charged based on the Transit Gateway connections that you use:\n\n\n\n* New Transit Gateway that you create in a PER workspace.\n* Existing Transit Gateways that add Power Systems Virtual Server workspace to their existing connection.\n\n\n\nHere are some more PER charges based on the following Transit Gateway specifics:\n\n\n\n* Routing option\n* Number of connections\n\n\n\nThe following table shows the charges based on the routing option that you select:\n\n\n\nTable 13. TGW charges based on routing\n\n Routing type Charges \n\n Local routing data transfer No charges \n Global routing data transfer $0.009405 GB \n\n\n\nThe following table shows the charges based on the number of connections (includes all types of connection such as DL, VPC, etc.) that you create:\n\n\n\nTable 14. TGW charges based on number of connections\n\n Number of connections Charges \n\n 1 - 4 No charges \n 5 - 20 $9.405 \n 21 - 50 $7.315 \n 51+ $4.7025 \n\n\n\nThe Transit Gateway charges indicated in the tables above are subjected to change.", "title": "", "source": "https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-pricing-virtual-server"}, {"document_id": "ibmcld_05666-4707-6582", "score": 17.454422, "text": "\n[Menu icon](https://cloud.ibm.com/docs-content/v1/content/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7/icons/icon_hamburger.svg) selecting Classic Infrastructure, and then selecting the Network > Bandwidth > Summary page.\n\nReview the following factors that impact public bandwidth charges:\n\n\n\n* Location: As with worker nodes, charges vary depending on the zone that your resources are deployed in.\n* Pay-As-You-Go for VM: Because VMs are billed at an hourly rate, your VM worker node machines have a Pay-As-You-Go allocation of outbound networking based on GB usage.\n* Included bandwidth and tiered packages for BM: Bare metal worker nodes might come with a certain allocation of outbound networking per month that varies by geography: 20 TB for North America and Europe, or 5 TB for Asia Pacific and South America. After you exceed your included bandwidth, you are charged according to a tiered usage scheme for your geography. If you exceed a tier allotment, you might also be charged a standard data transfer fee. For more information, see [Bandwidth packages](https://www.ibm.com/cloud/bandwidth).\n\n\n\nVPC clusters: For more information about how internet data transfer works in your Virtual Private Cloud, see [Pricing for VPC](https://cloud.ibm.com/vpc-ext/provision/vs).\n\n\n\n\n\n Subnet IP addresses \n\nSubnets for IBM Cloud Kubernetes Service clusters vary by infrastructure provider.\n\nClassic clusters: When you create a standard cluster, a portable public subnet with 8 public IP addresses is ordered and charged to your account monthly. For pricing information, see the [Subnets and IPs](https://cloud.ibm.com/docs/subnets) documentation or estimate your costs in the [classic subnets console)](https://cloud.ibm.com/classic/network/subnet/provision). If you already have available portable public subnets in your infrastructure account, you can use these subnets instead.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-costs"}, {"document_id": "ibmcld_16727-871736-873537", "score": 16.826939, "text": "\nFor more information, see [About restoring from a backup snapshot](https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore).\n* Am I charged for usage?\n\nYes. Cost for backups is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The backup exists on the account until it reaches its retention period, or when you delete it manually, or when you reach the end of a billing cycle, whichever comes first.\n\nPricing of subsequent backups can also increase or decrease when you [increase source volume capacity](https://cloud.ibm.com/docs/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https://cloud.ibm.com/docs/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile for the source volume. For example, expanding volume capacity increases costs. However, changing an IOPS profile from a 5-IOPS/GB tier to a 3-IOPS/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for backups is also set by region of the source volume. For more information, see [Pricing](https://www.ibm.com/cloud/vpc/pricing).\n\n\n\n Can I use data backups for disaster recovery? \n\nUsing the [backup service](https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. You can also create copies of your backup snapshot in other regions. However, the backup service does not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}]}
{"task_id": "747a810abfd6da4a9c37cdb74feec95e<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16727-883439-885357", "score": 20.64388, "text": "\nBilling for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https://www.ibm.com/cloud/vpc/pricing).\n* Are there limits on the number of volumes I can create?\n\n Are there limits on the number of volumes I can create? \n\nYou can create up to 300 total Block Storage for VPC volumes (data and boot) per account in a region. To increase this [quota](https://cloud.ibm.com/docs/vpc?topic=vpc-quotasblock-storage-quotas), open a [support case](https://cloud.ibm.com/docs/vpc?topic=vpc-getting-help) and specify the zone where you need more volumes.\n* After a data volume is created with a specific capacity, can the capacity later be increased?\n\n After a data volume is created with a specific capacity, can the capacity later be increased? \n\nYou can increase the capacity of data volumes that are attached to a virtual server instance. You can indicate capacity in GB increments up to 16,000 GB capacity, depending on your volume profile. For more information, see [Increasing Block Storage for VPC volume capacity](https://cloud.ibm.com/docs/vpc?topic=vpc-expanding-block-storage-volumes).\n* Can I increase capacity of a boot volume?\n\n Can I increase capacity of a boot volume? \n\nBoot volume capacity can be increased during instance provisioning or later, by directly modifying the boot volume. This feature applies to instances that are created from stock or custom images. You can also specify a larger boot volume capacity when you create an instance template. The boot volume can't be unattached from an instance (that is, stored as stand-alone data volume). For more information, see [Increasing boot volume capacity](https://cloud.ibm.com/docs/vpc?topic=vpc-resize-boot-volumes).", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-883562-885480", "score": 20.64388, "text": "\nBilling for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https://www.ibm.com/cloud/vpc/pricing).\n* Are there limits on the number of volumes I can create?\n\n Are there limits on the number of volumes I can create? \n\nYou can create up to 300 total Block Storage for VPC volumes (data and boot) per account in a region. To increase this [quota](https://cloud.ibm.com/docs/vpc?topic=vpc-quotasblock-storage-quotas), open a [support case](https://cloud.ibm.com/docs/vpc?topic=vpc-getting-help) and specify the zone where you need more volumes.\n* After a data volume is created with a specific capacity, can the capacity later be increased?\n\n After a data volume is created with a specific capacity, can the capacity later be increased? \n\nYou can increase the capacity of data volumes that are attached to a virtual server instance. You can indicate capacity in GB increments up to 16,000 GB capacity, depending on your volume profile. For more information, see [Increasing Block Storage for VPC volume capacity](https://cloud.ibm.com/docs/vpc?topic=vpc-expanding-block-storage-volumes).\n* Can I increase capacity of a boot volume?\n\n Can I increase capacity of a boot volume? \n\nBoot volume capacity can be increased during instance provisioning or later, by directly modifying the boot volume. This feature applies to instances that are created from stock or custom images. You can also specify a larger boot volume capacity when you create an instance template. The boot volume can't be unattached from an instance (that is, stored as stand-alone data volume). For more information, see [Increasing boot volume capacity](https://cloud.ibm.com/docs/vpc?topic=vpc-resize-boot-volumes).", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_04031-1609-3779", "score": 20.18544, "text": "\nFor IBM Blockchain Platform cost estimation purposes, 1 VPC = 1 CPU = 1 vCPU = 1 Core. The term \"VPC\" is also used to refer to a type of infrastructure on IBM Cloud and is unrelated to this topic.\n\nFor a total cost estimate, remember that your blockchain network consists of an Kubernetes cluster on IBM Cloud that contains IBM Blockchain Platform components and uses storage of your choice. Your Kubernetes cluster on IBM Cloud and the storage that you choose incur separate charges. You will not be charged for the cluster that the Operational Tooling instance, also known as the console, is running on. See the [Architecture reference](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-overviewibp-console-overview-architecture) topic for an illustration. More details on how to calculate charges are described below.\n\n\n\n Benefits of the new pricing model \n\n\n\n* No membership fees: Freedom from membership fees means that you can invest directly in your blockchain components.\n* Estimation clarity: A simple hourly pricing model makes cost estimation clear and easy by using the cost estimator tool that is available in the IBM Cloud dashboard.\n* No minimum fee required: Pay for only what you use, no minimum VPC hourly package is required, which makes it very inexpensive to get started.\n* Scalability of compute: You have the option to scale your compute up during peak usage periods or down to a minute fraction of capacity for when the compute is not needed to minimize expense.\n\n\n\nIn summary, these features remove the complexity of accounting for membership limitations or purchasing compute ahead of your needs.\n\n\n\n\n\n Find out how to preview the platform free for 30 days \n\nYou can preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster.\n\nLimitations of the free preview\n\n\n\n* Performance will be limited by throughput, storage, and functionality. Read more about the [limitations of free clusters](https://cloud.ibm.com/docs/containers?topic=containers-cs_ovcluster_types).\n* IBM Cloud will delete your Kubernetes cluster after 30 days.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-saas-pricing"}, {"document_id": "ibmcld_15770-2447-4326", "score": 19.78464, "text": "\n[GPU](https://cloud.ibm.com/docs/vpc?topic=vpc-profilesgpu) GPU enabled profiles provide on-demand access to NVIDIA V100 and A100 GPUs to accelerate AI, high-performance computing, data science, and graphics workloads. \n [Storage Optimized](https://cloud.ibm.com/docs/vpc?topic=vpc-profilesstorageopt) Storage Optimized profiles offer temporary SSD instance storagedisks at a ratio of 1 vCPU to 300 GB instance storage with a lower price point per GB. These profiles are designed for storage-dense workloads and offer virtio interface type for attached disks. \n\n\n\nProfiles with instance storage and profiles with 64 or more vCPUs are deployed exclusively on the Intel\u00ae's second-generation quad processor Xeon\u00ae Platinum 8260 Cascade Lake with 96 cores that are running at a base speed of 2.4 GHz and an all-core turbo frequency of 3.1 GHz or Intel\u00ae's quad processor Xeon\u00ae Gold 6248 Cascade Lake with 80 cores that are running at a base speed of 2.5 GHz and an all-core turbo frequency of 3.1 GHz.\n\nProfiles with AMD manufactured processors are available in the Toronto region.\n\n\n\n Balanced \n\nBalanced profiles provide a mix of performance and scalability for more common workloads with a ratio of 4 GiB of memory for every 1 vCPU of compute. The Balanced profile family includes profiles with and without [instance storage](https://cloud.ibm.com/docs/vpc?topic=vpc-instance-storage). The following table shows all Balanced profiles available for Intel\u00ae x86-64, and AMD x86-64 processors.\n\nBalanced profiles with the bx2d prefix are available in the US South (Dallas), US East (Washington DC), Canada (Toronto), United Kingdom (London), EU Germany (Frankfurt), Japan (Tokyo), Japan (Osaka), and Australia (Sydney) regions.\n\nIntel x86-64\n\nAMD x86-64\n\n\n\nTable 3. Balance profiles options for Intel x86-64 instances\nBalanced profiles options for Intel x86-64 virtual server instances.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-profiles"}, {"document_id": "ibmcld_15111-1536-3423", "score": 19.516293, "text": "\nThe volume exists on the account until you delete the volume or you reach the end of a billing cycle, whichever comes first.\n\nPricing is also affected when you [expand volume capacity](https://cloud.ibm.com/docs/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https://cloud.ibm.com/docs/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile. For example, expanding volume capacity increases costs, and changing an IOPS profile from a 5-IOPS/GB tier to a 3-IOPS/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https://www.ibm.com/cloud/vpc/pricing).\n\n\n\n\n\n Are there limits on the number of volumes I can create? \n\nYou can create up to 300 total Block Storage for VPC volumes (data and boot) per account in a region. To increase this [quota](https://cloud.ibm.com/docs/vpc?topic=vpc-quotasblock-storage-quotas), open a [support case](https://cloud.ibm.com/docs/vpc?topic=vpc-getting-help) and specify the zone where you need more volumes.\n\n\n\n\n\n After a data volume is created with a specific capacity, can the capacity later be increased? \n\nYou can increase the capacity of data volumes that are attached to a virtual server instance. You can indicate capacity in GB increments up to 16,000 GB capacity, depending on your volume profile. For more information, see [Increasing Block Storage for VPC volume capacity](https://cloud.ibm.com/docs/vpc?topic=vpc-expanding-block-storage-volumes).\n\n\n\n\n\n Can I increase capacity of a boot volume? \n\nBoot volume capacity can be increased during instance provisioning or later, by directly modifying the boot volume.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-vpc-faq"}, {"document_id": "ibmcld_15786-2512-4417", "score": 19.202385, "text": "\n[GPU](https://cloud.ibm.com/docs/vpc?topic=vpc-profiles&interface=uigpu) GPU enabled profiles provide on-demand access to NVIDIA V100 and A100 GPUs to accelerate AI, high-performance computing, data science, and graphics workloads. \n [Storage Optimized](https://cloud.ibm.com/docs/vpc?topic=vpc-profiles&interface=uistorageopt) Storage Optimized profiles offer temporary SSD instance storagedisks at a ratio of 1 vCPU to 300 GB instance storage with a lower price point per GB. These profiles are designed for storage-dense workloads and offer virtio interface type for attached disks. \n\n\n\nProfiles with instance storage and profiles with 64 or more vCPUs are deployed exclusively on the Intel\u00ae's second-generation quad processor Xeon\u00ae Platinum 8260 Cascade Lake with 96 cores that are running at a base speed of 2.4 GHz and an all-core turbo frequency of 3.1 GHz or Intel\u00ae's quad processor Xeon\u00ae Gold 6248 Cascade Lake with 80 cores that are running at a base speed of 2.5 GHz and an all-core turbo frequency of 3.1 GHz.\n\nProfiles with AMD manufactured processors are available in the Toronto region.\n\n\n\n Balanced \n\nBalanced profiles provide a mix of performance and scalability for more common workloads with a ratio of 4 GiB of memory for every 1 vCPU of compute. The Balanced profile family includes profiles with and without [instance storage](https://cloud.ibm.com/docs/vpc?topic=vpc-instance-storage). The following table shows all Balanced profiles available for Intel\u00ae x86-64, and AMD x86-64 processors.\n\nBalanced profiles with the bx2d prefix are available in the US South (Dallas), US East (Washington DC), Canada (Toronto), United Kingdom (London), EU Germany (Frankfurt), Japan (Tokyo), Japan (Osaka), and Australia (Sydney) regions.\n\nIntel x86-64\n\nAMD x86-64\n\n\n\nTable 3. Balance profiles options for Intel x86-64 instances\nBalanced profiles options for Intel x86-64 virtual server instances.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-profiles&interface=ui"}, {"document_id": "ibmcld_15956-7-2137", "score": 19.16338, "text": "\nVPC storage service overview \n\nThe IBM Cloud\u00ae Virtual Private Cloud (VPC) provides block storage, file storage, and snapshots solutions to meet your cloud storage needs. Instance storage provides dedicated drives that are directly attached to your virtual server instances. In addition, with the VPC Backup service, you can create scheduled backups of your block storage volumes.\n\n\n\n Block Storage for VPC \n\nIBM\u00ae Cloud Block Storage for Virtual Private Cloud provides hypervisor-mounted, high-performance data storage for your virtual server instances that you can provision within a VPC. The VPC infrastructure provides rapid scaling across zones and extra performance and security.\n\nBy using this service, you can:\n\n\n\n* Create block storage data volumes from the UI, CLI, and API.\n* When you create the volume, specify an IOPS profile that best meets your storage requirements. You can choose a standard IOPS profile with 3, 5, or 10 IOPS per GB performance. Volume capacity can be up to 16 TB and 48,000 IOPS.\n* Create a volume by using a custom profile. Choose IOPS performance from 100 IOPS to 48,000 IOPS, based on volume size up to 16 TB.\n* Attach a data volume to a virtual server instance.\n* Choose customer-managed encryption for your block storage boot or data volume, and secure your data with your own encryption keys.\n* View a list of volumes and select a volume to see its details.\n* Manage volumes: Rename or delete volumes, transfer volumes to a different instance, detach or reattach a volume, assign access to a volume, and access performance metrics.\n* Expand volume capacity to meet your needs.\n* Adjust IOPS up or down, for greater performance or when you want to reduce costs.\n* Adjust the volume bandwidth ratio for volumes that are attached to a virtual server instance.\n\n\n\nFor more information about this service, see [About Block Storage for VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-about).\n\n\n\n\n\n File Storage for VPC \n\nFile Storage for VPC is a zonal file storage offering that provides NFS-based file storage services. You create file shares in an availability zone within a region.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-storage-overview"}, {"document_id": "ibmcld_10116-13064-14929", "score": 19.00242, "text": "\n* VPC clusters: A Load Balancer for VPC is automatically created in your VPC for your cluster. For cost information, see [Pricing for Load Balancer for VPC](https://cloud.ibm.com/vpc-ext/provision/vs).\n\n\n\n\n\n\n\n Default storage for images \n\nTo store images in the internal registry, Red Hat OpenShift on IBM Cloud creates a storage instance that varies by infrastructure provider.\n\n\n\n* Classic clusters: A classic IBM Cloud File Storage for Classic volume is automatically created for you. Your file storage volume is provisioned with an ibmc-file-gold storage class of 100 GB capacity at 10 IOPS/GB, and billed at an hourly rate. If you need more image storage capacity, you can [update the volume size](https://cloud.ibm.com/docs/openshift?topic=openshift-registryopenshift_internal_registry), which modifies the cost.\n* VPC clusters: A bucket in an existing IBM Cloud Object Storage instance is created for you. For more information, see [Billing and pricing in the Object Storage documentation](https://www.ibm.com/cloud/object-storage).\n\n\n\n\n\n\n\n Storage for apps \n\nWhen you provision storage, you can choose the storage type and storage class that is correct for your use case. Charges vary depending on the type of storage, the location, and the specs of the storage instance. Some storage solutions, such as file and block storage offer hourly and monthly rates that you can choose from.\n\nTo choose the correct storage solution, see [Planning highly available persistent storage](https://cloud.ibm.com/docs/openshift?topic=openshift-storage-plan). For more information, see:\n\n\n\n* [File Storage for Classic](https://www.ibm.com/products/file-storage)\n* [Block Storage for Classic](https://www.ibm.com/products/block-storage)\n* [File Storage for VPC](https://www.ibm.com/products/file-storage)\n* [Block Storage for VPC](https://www.ibm.com/products/block-storage)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-costs"}, {"document_id": "ibmcld_07578-882118-884014", "score": 18.886007, "text": "\nYou can also [create stand-alone volumes](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-block-storagecreate-standalone-vol) and later attach them to your instances.\n* How many instances can share a provisioned Block Storage for VPC volume?\n\n How many instances can share a provisioned Block Storage for VPC volume? \n\nA Block Storage for VPC volume can be attached to only one instance at a time. Instances cannot share a volume.\n* How many Block Storage for VPC secondary data volumes can be attached to an instance?\n\n How many Block Storage for VPC secondary data volumes can be attached to an instance? \n\nYou can create 12 Block Storage for VPC data volumes per instance, plus the boot volume.\n* How am I charged for usage?\n\n How am I charged for usage? \n\nCost for Block Storage for VPC is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The volume exists on the account until you delete the volume or you reach the end of a billing cycle, whichever comes first.\n\nPricing is also affected when you [expand volume capacity](https://cloud.ibm.com/docs/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https://cloud.ibm.com/docs/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile. For example, expanding volume capacity increases costs, and changing an IOPS profile from a 5-IOPS/GB tier to a 3-IOPS/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https://www.ibm.com/cloud/vpc/pricing).\n* Are there limits on the number of volumes I can create?\n\n Are there limits on the number of volumes I can create?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-881995-883891", "score": 18.886007, "text": "\nYou can also [create stand-alone volumes](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-block-storagecreate-standalone-vol) and later attach them to your instances.\n* How many instances can share a provisioned Block Storage for VPC volume?\n\n How many instances can share a provisioned Block Storage for VPC volume? \n\nA Block Storage for VPC volume can be attached to only one instance at a time. Instances cannot share a volume.\n* How many Block Storage for VPC secondary data volumes can be attached to an instance?\n\n How many Block Storage for VPC secondary data volumes can be attached to an instance? \n\nYou can create 12 Block Storage for VPC data volumes per instance, plus the boot volume.\n* How am I charged for usage?\n\n How am I charged for usage? \n\nCost for Block Storage for VPC is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The volume exists on the account until you delete the volume or you reach the end of a billing cycle, whichever comes first.\n\nPricing is also affected when you [expand volume capacity](https://cloud.ibm.com/docs/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https://cloud.ibm.com/docs/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile. For example, expanding volume capacity increases costs, and changing an IOPS profile from a 5-IOPS/GB tier to a 3-IOPS/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https://www.ibm.com/cloud/vpc/pricing).\n* Are there limits on the number of volumes I can create?\n\n Are there limits on the number of volumes I can create?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}]}
{"task_id": "4175fcce99c56af0e02be5b8990fc16a<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_15111-10169-12034", "score": 21.212671, "text": "\nBy using the [backup service](https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https://www.ibm.com/cloud/disaster-recovery).\n\n\n\n\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot. For more information, see [Restoring a volume from a snapshot](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-restore).\n\nFor best performance, you can enable snapshots for fast restore. By using the fast restore feature, you can create a volume from a snapshot that is fully provisioned when the volume is created. For more information, see [Snapshots fast restore](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore).\n\n\n\n\n\n Can I add tags to a volume? \n\nYes, you can add user tags and access management tags to your volumes. User tags are used by the backup service to automatically create backup snapshots of the volume. Access management tags help organize access to your Block Storage for VPC volumes. For more information, see [Tags for Block Storage for VPC volumes](https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-about&interface=uistorage-about-tags).\n\n\n\n\n\n\n\n Performance questions", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-vpc-faq"}, {"document_id": "ibmcld_15020-3827-5719", "score": 21.118904, "text": "\nBehind the scenes, the [Snapshot for VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-about) service is used to create a point-in-time copy of your data. When the first backup snapshot is taken, the entire contents of the volume are copied and retained in IBM Cloud\u00ae Object Storage. Subsequent backups of the same volume capture the changes that occurred since the previous backup. You can take up to [750 backups of a volume](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots_vpc_considerations).\n\nYou can [restore](https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about&interface=uibackup-service-restore-concepts) data from a backup snapshot to a new, fully provisioned volume. If the backup is of a boot volume, you can use it to provision a new instance. However, when you provision an instance by restoring a boot volume from a bootable backup snapshot, you can expect degraded performance in the beginning. During the restoration process, the data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC, and thus the provisioned IOPS cannot be fully realized until that process finishes.\n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. The [cross-regional copy](https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about&interface=uibackup-service-crc) can be used in disaster recovery scenarios when you need to turn on your virtual server instance and data volumes in a different region. The remote copy can be created automatically as part of a backup plan, or manually later.\n\nWith the fast restore feature, you can cache snapshots in a specified zone of your choosing. This way, volumes can be restored from snapshots nearly immediately and the new volumes operate with full IOPS instantly. The fast restore feature can achieve a", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about&interface=ui"}, {"document_id": "ibmcld_15007-3814-5680", "score": 21.00397, "text": "\nBehind the scenes, the [Snapshot for VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-about) service is used to create a point-in-time copy of your data. When the first backup snapshot is taken, the entire contents of the volume are copied and retained in IBM Cloud\u00ae Object Storage. Subsequent backups of the same volume capture the changes that occurred since the previous backup. You can take up to [750 backups of a volume](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots_vpc_considerations).\n\nYou can [restore](https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-aboutbackup-service-restore-concepts) data from a backup snapshot to a new, fully provisioned volume. If the backup is of a boot volume, you can use it to provision a new instance. However, when you provision an instance by restoring a boot volume from a bootable backup snapshot, you can expect degraded performance in the beginning. During the restoration process, the data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC, and thus the provisioned IOPS cannot be fully realized until that process finishes.\n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. The [cross-regional copy](https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-aboutbackup-service-crc) can be used in disaster recovery scenarios when you need to turn on your virtual server instance and data volumes in a different region. The remote copy can be created automatically as part of a backup plan, or manually later.\n\nWith the fast restore feature, you can cache snapshots in a specified zone of your choosing. This way, volumes can be restored from snapshots nearly immediately and the new volumes operate with full IOPS instantly. The fast restore feature can achieve a", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about"}, {"document_id": "ibmcld_15034-5426-7253", "score": 20.846972, "text": "\nWhen you use fast restore, the data is pulled from a cached backup snapshot in another zone of your VPC. For more information, see [About restoring from a backup snapshot](https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Am I charged for usage? \n\nYes. Cost for backups is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The backup exists on the account until it reaches its retention period, or when you delete it manually, or when you reach the end of a billing cycle, whichever comes first.\n\nPricing of subsequent backups can also increase or decrease when you [increase source volume capacity](https://cloud.ibm.com/docs/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https://cloud.ibm.com/docs/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile for the source volume. For example, expanding volume capacity increases costs. However, changing an IOPS profile from a 5-IOPS/GB tier to a 3-IOPS/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for backups is also set by region of the source volume. For more information, see [Pricing](https://www.ibm.com/cloud/vpc/pricing).\n\n\n\n Can I use data backups for disaster recovery? \n\nUsing the [backup service](https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. You can also create copies of your backup snapshot in other regions. However, the backup service does not provide continual backup with automatic failover.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-vpc-faq"}, {"document_id": "ibmcld_15007-13930-15825", "score": 20.816347, "text": "\nRestoring from a bootable snapshot is slower than using a regular boot volume.\n\nWhile the creation of the backup requires the volumes to be attached to a running virtual server instance, you can also restore a data volume from a snapshot of an unattached volume. Backups, like snapshots, have a lifecycle that is independent from the source Block Storage for VPC volume.\n\nThe restored volume has the same capacity and IOPS tier profile as the original volume. For more information, see [Restoring a volume from a backup snapshot](https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Restoring a volume by using fast restore \n\nWhen you restore a volume by using fast restore, a fully hydrated volume is created.\n\nYou can create a [backup policy plan](https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan&interface=uibackup-plan-ui) with fast restore zones, and add or remove zones later as needed. The fast restore feature caches one or more copies of a backup snapshot to the zones that you selected. Later, you can use these backup clones to create volumes in any zone within the same region.\n\nFor more information, see [Restoring a volume from a backup snapshot](https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Cross-regional backup copies \n\nNew\n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. You can use and manage the cross-regional snapshot in the target region independently from the parent volume or the original snapshot.\n\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy.\n\nOnly one copy of the backup snapshot can exist in each region.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about"}, {"document_id": "ibmcld_15020-13969-15864", "score": 20.816347, "text": "\nRestoring from a bootable snapshot is slower than using a regular boot volume.\n\nWhile the creation of the backup requires the volumes to be attached to a running virtual server instance, you can also restore a data volume from a snapshot of an unattached volume. Backups, like snapshots, have a lifecycle that is independent from the source Block Storage for VPC volume.\n\nThe restored volume has the same capacity and IOPS tier profile as the original volume. For more information, see [Restoring a volume from a backup snapshot](https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Restoring a volume by using fast restore \n\nWhen you restore a volume by using fast restore, a fully hydrated volume is created.\n\nYou can create a [backup policy plan](https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan&interface=uibackup-plan-ui) with fast restore zones, and add or remove zones later as needed. The fast restore feature caches one or more copies of a backup snapshot to the zones that you selected. Later, you can use these backup clones to create volumes in any zone within the same region.\n\nFor more information, see [Restoring a volume from a backup snapshot](https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Cross-regional backup copies \n\nNew\n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. You can use and manage the cross-regional snapshot in the target region independently from the parent volume or the original snapshot.\n\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy.\n\nOnly one copy of the backup snapshot can exist in each region.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about&interface=ui"}, {"document_id": "ibmcld_14951-45918-47663", "score": 20.761194, "text": "\nThe volume's data is fully restored later, when you attach it to an instance. Volume performance is initially degraded until the volume data is fully restored. For more information, see [Restoring an unattached data volume from a snapshot with the API](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-restore&interface=apisnapshots-vpc-restore-unattached-api).\n\nCross-zone member support for network load balancers. You can now [create a load balancer pool](https://cloud.ibm.com/apidocs/vpc/latestcreate-load-balancer-pool) with members across any zone in the region. You can also use the [create pool member](https://cloud.ibm.com/apidocs/vpc/latestcreate-load-balancer-pool-member) and [replace pool member](https://cloud.ibm.com/apidocs/vpc/latestreplace-load-balancer-pool-members) methods to update an existing pool with members across any zone in the region. The zone of the network load balancer is still identified by the subnet that you specify when you create a load balancer.\n\nNetwork load balancers with route_mode enabled do not support cross zone members.\n\n\n\n\n\n\n\n 21 June 2022 \n\n\n\n For all version dates \n\nBackup for VPC. You can now create backup policies to schedule automatic backups of your block storage volumes. Backups are made when a user tag in a block storage volume matches a user tag defined in a backup policy. Backups are created by a schedule defined in a [backup plan](https://cloud.ibm.com/apidocs/vpc-betacreate-backup-policy-plan). Each plan also has a deletion policy for managing backups created by the plan, which you can customize by specifying the deletion_trigger sub-property. At the scheduled interval, a backup snapshot is created of that volume. You can have up to four backup plans per policy.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-api-change-log"}, {"document_id": "ibmcld_15034-6870-7844", "score": 20.747847, "text": "\nUsing the [backup service](https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. You can also create copies of your backup snapshot in other regions. However, the backup service does not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https://www.ibm.com/cloud/disaster-recovery).\n\n\n\n\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. Only one copy of the backup snapshot can exist in each region. You can't create a copy of the backup snapshot in the source (local) region.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-vpc-faq"}, {"document_id": "ibmcld_15883-3044-4932", "score": 20.739868, "text": "\nYou can also restore a fully provisioned volume by using the [fast restore feature](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-about&interface=apisnapshots-fast-restore) after initial provisioning.\n\nSnapshots have a lifecycle that is independent from the source Block Storage for VPC volume. You can delete the original volume and the snapshot persists. However, do not detach the volume from the instance during snapshot creation. You need to wait until the snapshot is stable before you detach, otherwise you can't reattach the volume to an instance. Snapshots are crash-consistent. If the virtual server stops for any reason, the snapshot data is safe on the disk.\n\nCost for snapshots is calculated based on GB capacity that is stored per month, unless the duration is less than one month. Because the snapshot is based on the capacity that was provisioned for the original volume, the snapshot capacity does not vary.\n\nWith IBM Cloud\u00ae Identity and Access Management, you can set up resource groups in your account to provide user-access to your snapshots. Your IAM role determines whether you can create and manage snapshots. For more information, see [IAM roles for creating and managing snapshots](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-managesnapshots-vpc-iam).\n\nBefore you take a snapshot, make sure that all cached data is present on disk, especially when you're taking snapshots of instances with Windows and Linux\u00ae operating systems. For example, on Linux operating systems, run the sync command to force an immediate write of all cached data to disk.\n\nFor customers with special access, data isolation is provided to store snapshots that you created from your dedicated hosts. With data isolation's extra security, your data is encrypted at rest with a unique key and access to your data is protected by a private firewall.\n\n\n\n\n\n How snapshots work", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-about&interface=api"}, {"document_id": "ibmcld_15896-3043-4930", "score": 20.69116, "text": "\nYou can also restore a fully provisioned volume by using the [fast restore feature](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots-fast-restore) after initial provisioning.\n\nSnapshots have a lifecycle that is independent from the source Block Storage for VPC volume. You can delete the original volume and the snapshot persists. However, do not detach the volume from the instance during snapshot creation. You need to wait until the snapshot is stable before you detach, otherwise you can't reattach the volume to an instance. Snapshots are crash-consistent. If the virtual server stops for any reason, the snapshot data is safe on the disk.\n\nCost for snapshots is calculated based on GB capacity that is stored per month, unless the duration is less than one month. Because the snapshot is based on the capacity that was provisioned for the original volume, the snapshot capacity does not vary.\n\nWith IBM Cloud\u00ae Identity and Access Management, you can set up resource groups in your account to provide user-access to your snapshots. Your IAM role determines whether you can create and manage snapshots. For more information, see [IAM roles for creating and managing snapshots](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-managesnapshots-vpc-iam).\n\nBefore you take a snapshot, make sure that all cached data is present on disk, especially when you're taking snapshots of instances with Windows and Linux\u00ae operating systems. For example, on Linux operating systems, run the sync command to force an immediate write of all cached data to disk.\n\nFor customers with special access, data isolation is provided to store snapshots that you created from your dedicated hosts. With data isolation's extra security, your data is encrypted at rest with a unique key and access to your data is protected by a private firewall.\n\n\n\n\n\n How snapshots work", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-about&interface=ui"}]}
{"task_id": "4175fcce99c56af0e02be5b8990fc16a<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_15164-28701-29788", "score": 17.368965, "text": "\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.\n\ncurl -X POST \"$vpc_api_endpoint/v1/backup_policies/8758bd18-344b-486a-b606-5b8cb8cdd044/plans?version=2023-05-09&generation=2\"\n-H \"Authorization: $iam_token\"\n-d '{\n\"active\": true,\n\"attach_user_tags\": [\n\"hourly-backups\"\n],\n\"copy_user_tags\": true,\n\"cron_spec\": \"0 /2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 20,\n\"delete_over_count\": 20\n},\n\"remote_region_policies\": {\n\"delete_over_count\": 5,\n\"encryption_key\": [\n{\n\"CRN\": \"crn:v1:bluemix:public:kms:us-south:a/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd617\"\n}\n],\n\"region\": [\n{\n\"name\":\"us-east\"\n}\n]\n},\n\"name\": \"my-hourly-plan-2\"\n}'", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan&interface=ui"}, {"document_id": "ibmcld_15160-28636-29723", "score": 17.368965, "text": "\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.\n\ncurl -X POST \"$vpc_api_endpoint/v1/backup_policies/8758bd18-344b-486a-b606-5b8cb8cdd044/plans?version=2023-05-09&generation=2\"\n-H \"Authorization: $iam_token\"\n-d '{\n\"active\": true,\n\"attach_user_tags\": [\n\"hourly-backups\"\n],\n\"copy_user_tags\": true,\n\"cron_spec\": \"0 /2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 20,\n\"delete_over_count\": 20\n},\n\"remote_region_policies\": {\n\"delete_over_count\": 5,\n\"encryption_key\": [\n{\n\"CRN\": \"crn:v1:bluemix:public:kms:us-south:a/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd617\"\n}\n],\n\"region\": [\n{\n\"name\":\"us-east\"\n}\n]\n},\n\"name\": \"my-hourly-plan-2\"\n}'", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan"}, {"document_id": "ibmcld_15163-28736-29823", "score": 17.368965, "text": "\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.\n\ncurl -X POST \"$vpc_api_endpoint/v1/backup_policies/8758bd18-344b-486a-b606-5b8cb8cdd044/plans?version=2023-05-09&generation=2\"\n-H \"Authorization: $iam_token\"\n-d '{\n\"active\": true,\n\"attach_user_tags\": [\n\"hourly-backups\"\n],\n\"copy_user_tags\": true,\n\"cron_spec\": \"0 /2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 20,\n\"delete_over_count\": 20\n},\n\"remote_region_policies\": {\n\"delete_over_count\": 5,\n\"encryption_key\": [\n{\n\"CRN\": \"crn:v1:bluemix:public:kms:us-south:a/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd617\"\n}\n],\n\"region\": [\n{\n\"name\":\"us-east\"\n}\n]\n},\n\"name\": \"my-hourly-plan-2\"\n}'", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan&interface=terraform"}, {"document_id": "ibmcld_15162-28726-29813", "score": 17.368965, "text": "\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.\n\ncurl -X POST \"$vpc_api_endpoint/v1/backup_policies/8758bd18-344b-486a-b606-5b8cb8cdd044/plans?version=2023-05-09&generation=2\"\n-H \"Authorization: $iam_token\"\n-d '{\n\"active\": true,\n\"attach_user_tags\": [\n\"hourly-backups\"\n],\n\"copy_user_tags\": true,\n\"cron_spec\": \"0 /2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 20,\n\"delete_over_count\": 20\n},\n\"remote_region_policies\": {\n\"delete_over_count\": 5,\n\"encryption_key\": [\n{\n\"CRN\": \"crn:v1:bluemix:public:kms:us-south:a/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd617\"\n}\n],\n\"region\": [\n{\n\"name\":\"us-east\"\n}\n]\n},\n\"name\": \"my-hourly-plan-2\"\n}'", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan&interface=cli"}, {"document_id": "ibmcld_15161-28756-29853", "score": 17.32313, "text": "\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.\n\ncurl -X POST \"$vpc_api_endpoint/v1/backup_policies/8758bd18-344b-486a-b606-5b8cb8cdd044/plans?version=2023-05-09&generation=2\"\n-H \"Authorization: $iam_token\"\n-d '{\n\"active\": true,\n\"attach_user_tags\": [\n\"hourly-backups\"\n],\n\"copy_user_tags\": true,\n\"cron_spec\": \"0 /2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 20,\n\"delete_over_count\": 20\n},\n\"remote_region_policies\": {\n\"delete_over_count\": 5,\n\"encryption_key\": [\n{\n\"CRN\": \"crn:v1:bluemix:public:kms:us-south:a/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd617\"\n}\n],\n\"region\": [\n{\n\"name\":\"us-east\"\n}\n]\n},\n\"name\": \"my-hourly-plan-2\"\n}'\nShow more", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan&interface=api"}, {"document_id": "ibmcld_01261-7-1890", "score": 16.408623, "text": "\nSecuring your data in File Storage for Classic \n\nIBM Cloud\u00ae takes the need for security seriously, and understands the importance of being able to encrypt data to keep it safe. With provider-managed encryption, IBM Cloud\u00ae File Storage for Classic that is provisioned with either Endurance or Performance options, is secured by default at no additional cost and no impact on performance.\n\nThe provider-managed encryption-at-rest feature uses the following industry standard protocols:\n\n\n\n* Industry-Standard AES-256 encryption.\n* Keys are managed in-house with industry standard Key Management Interoperability Protocol (KMIP).\n* Storage is validated for US Federal Information Processing Standard (FIPS) Publication 140-2, Federal Information Security Management Act (FISMA), Health Insurance Portability and Accountability Act (HIPAA). Storage is also validated for Payment Card Industry (PCI), Basel II, California Security Breach Information Act (SB 1386), and EU General Data Protection Regulation (GDPR) compliance.\n\n\n\n\n\n Securing your snapshots or replicated storage \n\nAll snapshots and replicas of encrypted file storage are also encrypted by default. This feature can\u2019t be turned off on a volume basis. All cluster-to-cluster traffic is encrypted with TLS.\n\n\n\n\n\n Provisioning storage with encryption \n\nThe provider-managed encryption-at-rest feature is available in all [data centers](https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-selectDC). All storage that is ordered in these data centers is automatically provisioned with encryption for data-at-rest.\n\nWhen you order File Storage for Classic, select a data center that is marked with an asterisk (). You can see a lock icon to the right of the Volume Name field that indicates that the volume is encrypted. See Figure 1.\n\nZoom\n\n![Figure 1. Example of the lock icon that indicates that the volume is encrypted.]", "title": "", "source": "https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-mng-data"}, {"document_id": "ibmcld_16035-7-2023", "score": 16.052677, "text": "\nAbout data encryption for VPC \n\nIBM Cloud\u00ae takes security seriously and understands the importance of encrypting data to keep it safe. Block Storage for VPC volumes, snapshots, and File Storage for VPC file shares are automatically encrypted by using IBM-managed encryption. You can also choose to manage your own encryption for volumes, file shares, and custom images by using customer-managed encryption.\n\n\n\n IBM-managed encryption \n\nBy default, VPC volumes and file shares are encrypted at rest with IBM-managed encryption. The service comes with no additional cost.\n\nIBM-managed encryption uses the following industry standard protocols:\n\n\n\n* AES-256 encryption.\n* Keys are managed in-house with Key Management Interoperability Protocol (KMIP).\n* The self-encrypting drives in the Storage architecture are validated for Federal Information Processing Standard (FIPS) Publication 140-2 Level 2.\n* Storage architecture is validated for Federal Information Security Management Act (FISMA), and the Health Insurance Portability and Accountability Act (HIPAA)\n* Storage architecture is also validated for Payment Card Industry (PCI), Basel II, California Security Breach Information Act (SB 1386), and EU Data Protection Directive 95/46/EC compliance.\n\n\n\n\n\n\n\n Customer-managed encryption \n\nFor end-to-end encryption in the IBM Cloud, you can use customer-managed encryption. Your data is protected while at rest, and also in transit from the storage to the hypervisor and host. You are responsible for encrypting your data outside the VPC.\n\nWith customer-managed encryption, you can bring your own customer root key (CRK) to the cloud or have a [key management service](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-aboutkms-for-byok) (KMS) generate a key for you. Root keys are used to encrypt volume, file share, and custom image passphrases with [envelope encryption](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-aboutvpc-envelope-encryption-byok), a process that wraps a key with another key.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-about"}, {"document_id": "ibmcld_15164-27999-29143", "score": 16.038712, "text": "\n\"href\": \"https://us-south.iaas.cloud.ibm.com/v1/regions/us-south/zones/us-south-2\"\n}\n]\n},\n\"copy_user_tags\": false,\n\"created_at\": \"2022-12-09T15:16:37Z\",\n\"cron_spec\": \"0 /2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 5\n},\n\"href\": \"https://us-south.iaas.cloud.ibm.com/v1/backup_policies/8758bd18-344b-486a-b606-5b8cb8cdd044/plans/6e251cfe-6f7b-4638-a6ba-00e9c327b178\",\n\"id\": \"6e251cfe-6f7b-4638-a6ba-00e9c327b178\",\n\"lifecycle_state\": \"stable\",\n\"name\": \"my-hourly-plan-1\",\n\"resource_type\": \"backup_policy_plan\"\n}\n\n\n\n\n\n Creating a backup plan with cross-regional copy option with the API \n\nNew\n\nWhen you create a backup plan, you can choose to create a copy of the backup snapshot in a different region.\n\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan&interface=ui"}, {"document_id": "ibmcld_15162-28024-29168", "score": 16.038712, "text": "\n\"href\": \"https://us-south.iaas.cloud.ibm.com/v1/regions/us-south/zones/us-south-2\"\n}\n]\n},\n\"copy_user_tags\": false,\n\"created_at\": \"2022-12-09T15:16:37Z\",\n\"cron_spec\": \"0 /2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 5\n},\n\"href\": \"https://us-south.iaas.cloud.ibm.com/v1/backup_policies/8758bd18-344b-486a-b606-5b8cb8cdd044/plans/6e251cfe-6f7b-4638-a6ba-00e9c327b178\",\n\"id\": \"6e251cfe-6f7b-4638-a6ba-00e9c327b178\",\n\"lifecycle_state\": \"stable\",\n\"name\": \"my-hourly-plan-1\",\n\"resource_type\": \"backup_policy_plan\"\n}\n\n\n\n\n\n Creating a backup plan with cross-regional copy option with the API \n\nNew\n\nWhen you create a backup plan, you can choose to create a copy of the backup snapshot in a different region.\n\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan&interface=cli"}, {"document_id": "ibmcld_15160-27934-29078", "score": 16.038712, "text": "\n\"href\": \"https://us-south.iaas.cloud.ibm.com/v1/regions/us-south/zones/us-south-2\"\n}\n]\n},\n\"copy_user_tags\": false,\n\"created_at\": \"2022-12-09T15:16:37Z\",\n\"cron_spec\": \"0 /2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 5\n},\n\"href\": \"https://us-south.iaas.cloud.ibm.com/v1/backup_policies/8758bd18-344b-486a-b606-5b8cb8cdd044/plans/6e251cfe-6f7b-4638-a6ba-00e9c327b178\",\n\"id\": \"6e251cfe-6f7b-4638-a6ba-00e9c327b178\",\n\"lifecycle_state\": \"stable\",\n\"name\": \"my-hourly-plan-1\",\n\"resource_type\": \"backup_policy_plan\"\n}\n\n\n\n\n\n Creating a backup plan with cross-regional copy option with the API \n\nNew\n\nWhen you create a backup plan, you can choose to create a copy of the backup snapshot in a different region.\n\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan"}]}
{"task_id": "4175fcce99c56af0e02be5b8990fc16a<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_08669-6042-7847", "score": 19.253992, "text": "\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events. IBM is responsible for the recovery of Hyper Protect Crypto Services components in case of disaster. You are responsible for the recovery of the workloads that run Hyper Protect Crypto Services and your application data.\n\n\n\nTable 5. Responsibilities for disaster recovery\n\n Task IBM responsibilities Your responsibilities \n\n Instance backups Continuously perform in-region and cross-region backups of key resources and perform continuous testing of backups. Back up your master key; validate the backups and restore data when needed. \n Disaster recovery When an in-region disaster occurs, automatically recover and restart service components. When a regional disaster that affects all available zones occurs, ensure that all data except the master key is replicated to another region. IBM will also make additional crypto units available in a different region and manage routing requests to the new crypto units. When a regional disaster that affects all available zones occurs, load your master key to the new crypto units that IBM provisions in a different region for restoring data. You can also enable and initialize failover crypto units before a disaster occurs, which reduces the downtime. \n Availability Provide high availability capabilities, such as IBM-owned infrastructure in multizone regions, to meet local access and low latency requirements for each supported region. Use the list of [available regions](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-regions) to plan for and create new instances of the service.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-shared-responsibilities"}, {"document_id": "ibmcld_08511-7-2392", "score": 18.592354, "text": "\nHigh availability and disaster recovery \n\nIBM Cloud\u00ae Hyper Protect Crypto Services is a highly available, regional service with automatic features that help keep your applications secure and operational.\n\nLearn more about availability and disaster recovery strategies of Hyper Protect Crypto Services.\n\n\n\n Locations, tenancy, and availability \n\nYou can create Hyper Protect Crypto Services resources in one of the supported [IBM Cloud regions](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-regions), which represent the geographic area where your Hyper Protect Crypto Services requests are handled and processed. Each IBM Cloud region contains [multiple availability zones](https://www.ibm.com/cloud/data-centers/) to meet local access, low latency, and security requirements for the region.\n\nAs you plan your encryption at rest strategy with IBM Cloud, keep in mind that provisioning Hyper Protect Crypto Services in a region that is nearest to you is more likely to result in faster, more reliable connections when you interact with the Hyper Protect Crypto Services APIs. Choose a specific region if the users, apps, or services that depend on a Hyper Protect Crypto Services resource are geographically concentrated. Users and services who are far away from the region might experience higher latency.\n\nYour encryption keys are confined to the region that you created them in. Hyper Protect Crypto Services does not copy or export encryption keys to other regions.\n\n\n\n\n\n In-region data redundancy and failover \n\nMultiple\n\ncrypto unitsin a service instance are automatically synchronized and load balanced across multiple availability zones. If one available zone that contains your provisioned service instance cannot be accessed, Hyper Protect Crypto Services has automatic in-region data failover in place. The service follows IBM Cloud requirements for planning and recovering from disaster events. For more information, see [Disaster recovery](https://cloud.ibm.com/docs/overview?topic=overview-zero-downtimedisaster-recovery).\n\n\n\n\n\n Cross-region disaster recovery \n\nIBM also performs cross-region backup for your key resources. Your data is automatically backed up in another supported region daily. Depending on where you create your instance and your requirements for recovery time, you can restore your data in case of a regional disaster with the following options:", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-ha-dr"}, {"document_id": "ibmcld_09515-7-2313", "score": 18.560268, "text": "\nBackups and Disaster Recovery \n\n\n\n Application Backups \n\nData used by applications within the Maximo Application Suite portfolio are backed up according to the following:\n\nAll backups are encrypted. Communication between applications, backup scripts the storage layer and DB services are perfromed via secure transport and accessed only via private endpoints that are offered by the service. Production backups are performed once a day. Backups are stored in a separate AWS data center location.\n\n\n\n\n\n System Configuration Backups \n\nMaximo Application Suite utilizes different components to deliver the applications to clients. Each of these services are backed up using the appropriate backup tool for that component. In general, all component backups:\n\n\n\n* are encrypted\n* are taken daily\n* are stored in a separate data center\n* are saved for 30 days\n\n\n\n\n\n\n\n Database Backup Retention \n\nDatabase backups will be retained for the standard duration of 14 days for Production environments and 7 days for Non-Production environments. In scenarios where the customer would like to retain a backup for longer than the standard duration outlined, the IBM SRE team will perform a database backup and save it to the COS bucket. It will then be the responsibility of the customer to download and maintain these backups. If a restore using one of these downloaded backups is required, the customer will need to upload the backup back to the COS bucket and open a case specifying which backup to use and for which environment they would like the restore.\n\n\n\n\n\n Restore \n\nRestore requests must be submitted via case (ticket) through the IBM Support Community Portal. The expected turn around time will depend on the severity and the size of the restore required. Generally expect 1 - 3 days for a restore to happen. Database restore can only be done to one of the previous daily backups (cannot restore to point in time).\n\n\n\n\n\n Disaster Recovery \n\nIn the event of a DR issue with the Maximo Application Suite SaaS offering for a specific customer, IBM's focus will be in the following order:\n\n\n\n1. Recover the existing infrastructure in place\n2. Recover within the same AWS data center to a new infrastructure\n3. Recover to a secondary AWS data center\n\n\n\nIn the event a disaster is declared, the base parameters are:", "title": "", "source": "https://cloud.ibm.com/docs/mas-saas?topic=mas-saas-backups-and-disaster-recovery"}, {"document_id": "ibmcld_07502-5502-7788", "score": 18.422998, "text": "\nThe disaster recovery kit is an off-site and protected repository that includes hardware, software, and system secure configurations, one-time keys, and the disaster recovery plan. Use this disaster recovery kit during an incident response to restore services.\n\n\n\n Infrastructure as code \n\nInfrastructure as code ensures that good backup practices are implemented in a uniform way across the organization. Include implementation of backups as part of deployable architectures. Keep backup configuration close to provisioning code so that it is easier to ensure that backups are adjusted as information system changes occur. Create and configure backup accounts as code.\n\n\n\n\n\n Backup accounts \n\nEach BU account group should include a separate backup account and an additional backup account should be used for the centralized accounts. These backup accounts provide an extra layer of protection for the confidentiality and integrity of the backed up data. If credentials to a source account are compromised, it should not be possible to use that access to tamper with backups.\n\nSupporting this effort, authorization to backup data in the backup account should use service-to-service or service to trusted profile authorization where possible. Otherwise, use secure storage of credentials with least privilege access.\n\nIf you are using Cloud Object Storage for backup, at minimum, use separate buckets for backing up different workload accounts. Also, use separate backup credentials for each bucket where service to service policies are not possible. Use Cloud Object Storage versioning or [immutable buckets](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable) for maximum security.\n\nServices that provide built in backup facilities might have limitations regarding backup accounts.\n\n\n\n\n\n Service-specific considerations \n\n\n\n IBM Cloud Databases \n\n[IBM Cloud Databases](https://cloud.ibm.com/docs/cloud-databases?topic=cloud-databases-about) provide automatic daily backups that are stored in the same account and geography. Backups are typically stored in [cross-regional storage](https://cloud.ibm.com/docs/cloud-databases?topic=cloud-databases-dashboard-backups&interface=uibackup-locations) and should therefore be immune to a single region outage.", "title": "", "source": "https://cloud.ibm.com/docs/enterprise-account-architecture?topic=enterprise-account-architecture-bcdr"}, {"document_id": "ibmcld_09494-7-2307", "score": 18.392616, "text": "\nBackups and Disaster Recovery \n\n\n\n Application Backups \n\nData used by applications within the Maximo Application Suite portfolio are backed up according to the following:\n\nAll backups are encrypted. Communication between applications, backup scripts the storage layer and DB services are perfromed via secure transport and accessed only via private endpoints that are offered by the service. Production backups are performed once a day. Backups are stored in a separate IBM Cloud data center location.\n\n\n\n\n\n System Configuration Backups \n\nMaximo Application Suite utilizes different components to deliver the applications to clients. Each of these services are backed up using the appropriate backup tool for that component. In general, all component backups:\n\n\n\n* are encrypted\n* are taken daily\n* are stored in a separate data center\n* are saved for 30 days\n\n\n\n\n\n\n\n Database Backup Retention \n\nDatabase backups will be retained for the standard duration of 14 days for Production environments and 7 days for Non-Production environments. In scenarios where the customer would like to retain a backup for longer than the standard duration outlined, the IBM SRE team will perform a database backup and save it to the COS bucket. It will then be the responsibility of the customer to download and maintain these backups. If a restore using one of these downloaded backups is required, the customer will need to upload the backup back to the COS bucket and open a case specifying which backup to use and for which environment they would like the restore.\n\n\n\n\n\n Restore \n\nRestore requests must be submitted via case (ticket) through the IBM Support Community Portal. The expected turn around time will depend on the severity and the size of the restore required. Generally for non-production systems, expect 1 - 3 days for a restore to happen. Database restore can only be done to one of the previous daily backups (cannot restore to point in time).\n\n\n\n\n\n Disaster Recovery \n\nIn the event of a DR issue with the Maximo Application Suite Dedicated Service offering for a specific customer, IBM's focus will be in the following order:\n\n\n\n1. Recover the existing infrastructure in place\n2. Recover within the same IBM Cloud data center to a new infrastructure\n3. Recover to a secondary IBM Cloud data center", "title": "", "source": "https://cloud.ibm.com/docs/mas-ms?topic=mas-ms-backups-and-disaster-recovery"}, {"document_id": "ibmcld_08511-1920-3732", "score": 18.22595, "text": "\nFor more information, see [Disaster recovery](https://cloud.ibm.com/docs/overview?topic=overview-zero-downtimedisaster-recovery).\n\n\n\n\n\n Cross-region disaster recovery \n\nIBM also performs cross-region backup for your key resources. Your data is automatically backed up in another supported region daily. Depending on where you create your instance and your requirements for recovery time, you can restore your data in case of a regional disaster with the following options:\n\n\n\n* If you create your instance in Dallas (us-south) or Washington DC (us-east) and you enable failover crypto units, the failover crypto units back up the operational crypto units and keystores in another region. When a regional disaster occurs, your data is restored automatically with the failover crypto units to reduce the downtime and data loss. For more information about how to use failover crypto units to restore data, see [Restoring your data by using failover crypto units](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-restore-datarestore-data-failover-crypto-units).\n* If you don't enable failover crypto units, you can use the default daily backup to restore your data. In this case, you need to open a support ticket so that IBM can create a new service instance in another supported region to restore your data from the backup. Then, you need to manually load your master key to the new instance again to make it work. In this process, you're the only person who owns the master key. IBM administrators or any third-party users can't access your data or keys in the backup or the restored service instance. For more information about the recovery process, see [Restoring your data by opening an IBM support ticket](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-restore-datarestore-data-open-support-ticket).", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-ha-dr"}, {"document_id": "ibmcld_14774-27023-28718", "score": 18.209103, "text": "\nIf a local restore is needed, the VMware datastore encryption storage policy is used to reencrypt the VM by using an encryption key from the protected region HPCS instance through the KMIP for VMware service.\n5. Veeam network encryption is used for file and backup copy jobs to the recovery region.\n6. VM backup files are encrypted on disk in the recovery region Veeam Repository with Veeam encryption.\n7. If a restore is needed in the recovery region, the Veeam datastore encryption storage policy is used to reencrypt the VM by using an encryption key from the recovery region HPCS instance through the KMIP for VMware service.\n\n\n\nFor more information about Veeam encryption, see [Encryption standards](https://helpcenter.veeam.com/docs/backup/vsphere/encryption_standards.html?ver=100).\n\nIn the IBM Cloud for VMware\u00ae Regulated Workloads dual region design for SaaS Consumer key management, then the same encryption keys are required in the recovery region as used in the protected region. Currently, HPCS does not support the same encryption keys in two regions. If a failure of the first HPCS instance occurs, keys can be restored to another HPCS instance in another region.\n\nFor more information, see:\n\n\n\n* [HPCS cross-region disaster recovery](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-ha-drcross-region-disaster-recovery)\n* [Restoring your data from another region](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-restore-data)\n\n\n\n\n\n\n\n Related links \n\n\n\n* [Caveonix integration](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vrw-caveonix)\n* [Veeam on IBM Cloud overview](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-veeamvm_overview)", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vrw-dualregion-design"}, {"document_id": "ibmcld_08622-1505-3356", "score": 17.8271, "text": "\nTo use failover crypto units to restore data in a regional disaster, make sure that you initialize and configure all the failover crypto units the same as the operational crypto units before the disaster happens. For more information about initialization approaches, see [Introducing service instance initialization approaches](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-initialize-instance-mode).\n\n\n\n\n\n Restoring your data by opening an IBM support ticket \n\nIf you don't enable failover crypto units or you are using Hyper Protect Crypto Services with Unified Key Orchestrator, you need to open an IBM support ticket to restore your data. IBM can then provision a new service instance for you in another region by using the same instance ID, and restore all the key resources from the backup. And then, you need to load your\n\nmaster keyto the new service instance in the new region.\n\nIn the process, you're the only person who owns the master key. IBM administrators or any third-party users cannot access your data or keys in the backup or the restored service instance.\n\nTo restore a backup to an existing service instance, follow these steps:\n\n\n\n1. In the IBM Cloud console, click the Help icon ![Help icon](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/icons/help.svg) > Support center from the IBM Cloud console menu barto enter the Support Center. Click View all in the Recent support cases panel and click Create new case. Or, you can directly go to the [Manage cases page](https://cloud.ibm.com/unifiedsupport/cases) and click Create new case.\n2. On the Create a case page displayed, select the offering Hyper Protect Crypto Services, and then specify the following values:\n\n\n\nTable 1. Describes the fields required for creating a case\n\n Field name Action \n\n Subject Enter Disaster recovery.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-restore-data"}, {"document_id": "ibmcld_08742-4656-6567", "score": 17.755058, "text": "\nRecovery crypto units can also be used as backup crypto units that save a copy of the master key value used by the operational crypto units. If the master key is lost or destroyed, you can [recover the master key from a recovery crypto unit](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-recover-master-key-recovery-crypto-unit) by using signed TKE administrative commands.\n\nIf smart cards are used to load the master key, the recovery crypto units are not applicable and can be ignored. The backup of the master key relies on the backup of the smart cards in that case.\n* Failover crypto unit\n\nFailover crypto units back up the operational crypto units and keystores in another region, and are initialized to provide quick failover in case of disaster. Failover crypto units [charge extra fees](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-faq-pricing) and this option is now available only in regions of us-south and us-east, which means if you create your instance in either of the two regions, the failover crypto units are located in the other region. For more information about using failover crypto units in a regional disaster, see [Restoring your data by using failover crypto units](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-restore-datarestore-data-failover-crypto-units).\n\n\n\n\n\n\n\n Administrators \n\nAdministrators can be added to the target crypto units for issuing commands to the crypto units. You can add up to eight administrators to one crypto unit to increase security. Each administrator owns one private [signature key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-understand-conceptssignature-key-concept) for identity authentication.\n\n\n\n\n\n Signature keys \n\nAn administrator must sign any commands that are issued to the crypto unit with a signature key. The signature keys that are created in Hyper Protect Crypto Services are P521 Elliptic Curve (EC) keys.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-understand-concepts"}, {"document_id": "ibmcld_14533-1761-4064", "score": 17.730688, "text": "\nThe encryption key is not stored and is unavailable to IBM. After the VMware Cloud Director Data Center is deleted, all backups are deleted, and cannot be recovered.\n\n\n\n\n\n High availability and disaster recovery \n\nThe VMware Shared management service is initially only offered in the IBM Cloud NA South and Europe regions. Recovering from potential disasters that affect an entire location requires planning and preparation.\n\n\n\n* You are responsible for understanding your configuration, customization, and usage of the service.\n* You are responsible for enabling your VMs or virtual applications (vApps) to participate in the provided backup service.\n* You are responsible for being ready to restore all instances of your VMs or vApps used in the service in the restored location or new location.\n\n\n\n\n\n High availability \n\nVMware Shared supports high availability of the VMware Cloud Director service itself. The service achieves high availability automatically and transparently by using the Multizone region (MZR) feature that is provided by IBM Cloud.\n\nHowever, you cannot configure workloads that are running VMs and vApps in a high availability manner across multiple IBM Cloud data center sites. VMware Shared currently allows workloads to operate in only one IBM Cloud data center site.\n\nUse VMware Shared with vCenter Server to achieve high availability. You can deploy vCenter Server in multiple IBM Cloud data center regions.\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery can become an issue if an IBM Cloud location experiences a significant failure that includes the potential loss of data. Because MZRs are not available across locations, you must wait for IBM to bring a location back online if it becomes unavailable. If underlying data services are compromised by the failure, you must also wait for IBM to restore those data services.\n\nIf a catastrophic failure occurs, IBM might not be able to recover data from database backups. In this case, you need to restore your data to return your service instance to its most recent state. You can restore the data to the same or to a different location, including a vCenter Server instance.\n\nYour disaster recovery plan includes knowing, preserving, and being prepared to restore all data that is maintained on IBM Cloud.\n\n\n\n\n\n\n\n Related links", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-shared_data"}]}
{"task_id": "4175fcce99c56af0e02be5b8990fc16a<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_15810-70646-72492", "score": 21.713463, "text": "\nApplication Load Balancer (ALB) for VPC\n: Application load balancers now support HTTP/HTTPS compression, which you use to compress data that is transmitted to your users. For more information, see [Compression (HTTP/HTTPS only)](https://cloud.ibm.com/docs/vpc?topic=vpc-advanced-traffic-managementcompression).\n\nHigh Availability (HA) Virtual Network Function (VNF) support\n: Support for a highly available, highly resilient virtual network functions can be achieved by using the \"routing mode\" feature of the IBM Cloud Network Load Balancer (NLB) for VPC. For more information, see [About virtual network functions over VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-about-vnf) and [About HA VNF deployments](https://cloud.ibm.com/docs/vpc?topic=vpc-about-vnf-ha).\n\nUpdates to Getting started with IBM Cloud VPC button\n: The \"Getting started with IBM Cloud VPC\" button now includes access to tours that are specific to what you are doing on the IBM console. If a tour is not available, the button takes you to the VPC List view.\n\n\n\n\n\n 06 January 2022 \n\nUI update when you create a virtual server\n: When you create a virtual server, the UI is updated to include a link in the Operating system section that opens a panel that contains information about the image lifecycle.\n\n\n\n\n\n\n\n December 2021 \n\n\n\n 16 December 2021 \n\nFile Storage for VPC (LA)\n: IBM Cloud\u00ae File Storage for VPC is now available for customers with special approval to preview this service in the Washington, Dallas, Frankfurt, London, Sydney, and Tokyo regions.\n: For more information about this service, see [About File Storage for VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-file-storage-vpc-about).\n\n\n\n\n\n 09 December 2021 \n\nSecurity updates\n: The following stock images were refreshed with the most recent fixes and security updates.\n\n\n\n* Debian version 10\n* CentOS version 7", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-release-notes"}, {"document_id": "ibmcld_15843-1841-4092", "score": 21.64141, "text": "\nAfter you reviewed the [overview](https://cloud.ibm.com/docs/vpc?topic=vpc-responsibilities-vpcoverview-by-resource), see what tasks you and IBM share responsibility for when you use IBM Cloud VPC.\n\n\n\n Incident and operations management \n\nIncident and operations management includes tasks such as monitoring, event management, high availability, problem determination, recovery, and full state backup and recovery.\n\n\n\nTable 2. Responsibilities for incidents and operations\n\n Task IBM Responsibilities Your Responsibilities \n\n Infrastructure IBM deploys a fully managed, highly available, secured, IBM-owned infrastructure. The Customer uses the provided API, CLI, or UI console to provision compute and storage, and to adjust networking configurations to meet the needs of their workload. To automate the provisioning and management of VPC service instances, you can use automation tools, such as IBM Cloud Schematics or Terraform. \n Availability IBM fulfills requests for VPC infrastructure, such as VPCs, subnets, virtual server instances, block storage volumes, security groups, access control lists, floating IP addresses, public gateways, and SSH keys across multiple availability zones (AZs) and multi-zone regions (MZRs). The Customer designs and deploys their workload in a way that achieves high availability by using our provided tools, such as multiple availability zones. At a high level, you are responsible for deploying workloads in different zones of the region, by using at least two load balancers that are located in different zones, and either by using DNS records to point to the load balancers or ensuring that your application can handle the list of IP addresses that it can connect to. For more information, see [Deploy isolated workloads across multiple locations and zones](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vpc-multi-region). \n Bring your own CIDR IBM provides the ability to bring your own CIDR block to a subnet. The Customer ensures the CIDR blocks that they specify for their VPC do not conflict with CIDR blocks that are used by any other network that they plan to connect to their VPC. \n Monitoring IBM provides built-in virtual server instance monitoring and IBM Cloud Monitoring.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-responsibilities-vpc"}, {"document_id": "ibmcld_14916-7-2291", "score": 21.390285, "text": "\nOverview \n\nUse IBM Cloud\u00ae Virtual Private Cloud to create your own space in IBM Cloud\u00ae. A virtual private cloud (VPC) is a secure, isolated virtual network that combines the security of a private cloud with the availability and scalability of IBM's public cloud.\n\n\n\n Logical isolation \n\nVPC gives your applications logical isolation from other networks, while providing scalability and security. To make this logical isolation possible, the VPC is divided into subnets that use a range of private IP addresses. You can create subnets in suggested prefix ranges, or bring your own public IP address range (BYOIP) to your IBM Cloud account. By default, all resources within the same VPC can communicate with each other over the private network, regardless of their subnet.\n\n\n\n\n\n Quick instance provisioning with high network performance \n\nYou can quickly provision scalable compute resources in your VPC by creating virtual server instances with the core and RAM configuration that's best for your workload. You can select from the supported stock images or custom images that were imported from IBM Cloud Object Storage. All images are cloud-init enabled. You can connect to your instance without using a password by adding SSH keys.\n\nYou can create instances with up to 80 Gbps network bandwidth per instance. Each instance can be multi-homed, that is, you can create multiple network interfaces per instance.\n\n\n\n\n\n Multi-architecture images \n\nYou can choose to create virtual server instances with different operating systems on x86_64 or s390x processor architecture. For more information, see [Images](https://cloud.ibm.com/docs/vpc?topic=vpc-about-images).\n\n\n\n\n\n Storage capabilities \n\nWhen you create an instance, a 100 GB block storage volume is automatically attached as a primary boot volume. To add secondary data volumes to your instance, create block storage volumes.\n\n\n\n\n\n External connectivity \n\nSeveral options are available for enabling your instances to communicate with the public internet:\n\n\n\n* To enable all instances in a subnet to send outgoing traffic, attach a public gateway to the subnet.\n* To enable communication to and from a particular instance, independent of whether the subnet is attached to a public gateway, associate the instance with a floating IP.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-about-vpc"}, {"document_id": "ibmcld_14905-7-2029", "score": 21.371841, "text": "\nAbout networking \n\nIBM Cloud\u00ae Virtual Private Cloud (VPC) is a virtual network that is linked to your customer account. It gives you cloud security, with the ability to scale dynamically, by providing fine-grained control over your virtual infrastructure and your network traffic segmentation.\n\n\n\n Overview \n\nEach VPC is deployed to a single region. Within that region, the VPC can span multiple zones.\n\nSubnets in your VPC can connect to the public internet through an optional public gateway. You can assign floating IP addresses to any virtual server instance to enable it to be reachable from the internet, independent of whether its subnet is attached to a public gateway.\n\nSubnets within the VPC offer private connectivity; they can talk to each other over a private link through the implicit router. Setting up routes is not necessary. Figure 1 shows how you can subdivide a virtual private cloud with subnets and each subnet can reach the public internet.\n\nZoom\n\n![Figure showing how a VPC can be subdivided with subnets](https://cloud.ibm.com/docs-content/v1/content/f02b9c9adcbb7328d95a45e105cec371d50f15eb/vpc/images/vpc-experience-simple.svg)\n\nFigure 1. IBM VPC connectivity and security\n\n\n\n\n\n Terminology \n\nTo work with your VPC, review the basic concepts of region and zone as they apply to your deployment.\n\n\n\n Regions \n\nA region is an abstraction that is related to the geographic area in which a VPC is deployed. Each region contains multiple zones, which represent independent fault domains. A VPC can span multiple zones within its assigned region.\n\n\n\n\n\n Zones \n\nA zone is an abstraction that refers to the physical data center that hosts the compute, network, and storage resources, plus the related cooling and power, which provides services and applications. Zones are isolated from each other to create no shared single point of failure, improved fault tolerance, and reduced latency. Each zone is assigned a default address prefix, which specifies the address range in which subnets can be created.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-about-networking-for-vpc"}, {"document_id": "ibmcld_11569-7-2213", "score": 21.293581, "text": "\nAutomating SAP workload deployment on IBM Cloud\u00ae Virtual Private Cloud (VPC) with Terraform and Ansible \n\nYou can use Terraform to automate IBM Cloud VPC provisioning. The VPC provisioned includes virtual server instances with high network performance. The VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including virtual servers. After the VPC is provisioned, the scripts use the Ansible Playbook to install the SAP system.\n\n\n\n IBM Cloud\u00ae VPC introduction \n\nA VPC is a public cloud offering that an enterprise uses to establish its own private cloud-like computing environment on shared [public cloud](https://www.ibm.com/cloud/public) infrastructure. VPCs give an enterprise the ability to define and control a virtual network that is logically isolated from all other public cloud tenants, creating a private, secure place on the public cloud.\n\nImagine that a cloud provider\u2019s infrastructure is a residential apartment building and multiple families live inside. Being a public cloud tenant is akin to sharing an apartment with a few roommates. In contrast, having a VPC is like having your own private condominium; no one else has the key, and no one can enter the space without your permission.\n\nA VPC\u2019s logical isolation is implemented by using virtual network functions and security features that give an enterprise customer granular control over which IP addresses or applications can access particular resources. It is analogous to the \u201cfriends-only\u201d or \u201cpublic/private\u201d controls on social media accounts used to restrict who can or can\u2019t see your otherwise public posts.\n\nWith IBM Cloud VPC, you can use the UI, CLI, and API to manually provision virtual server instances for VPC with high network performance. VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including virtual servers for VPC. Use the following information to understand a simple use case for planning, creating, and configuring resources for your VPC, and learn about more VPC overviews and VPC tutorials. For more information about VPC, see [Getting started with Virtual Private Cloud (VPC)](https://cloud.ibm.com/docs/vpc?topic=vpc-getting-started).", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-components-terraform-3tier-nw-db2-terraform"}, {"document_id": "ibmcld_11570-7-2212", "score": 21.243725, "text": "\nAutomating SAP workload deployment on IBM Cloud\u00ae Virtual Private Cloud (VPC) with Terraform and Ansible \n\nYou can use Terraform to automate IBM Cloud VPC provisioning. The VPC provisioned includes virtual server instances with high network performance. The VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including Virtual Servers. After the VPC is provisioned, the scripts use the Ansible Playbook to install the SAP system\n\n\n\n IBM Cloud\u00ae VPC introduction \n\nA VPC is a public cloud offering that an enterprise uses to establish its own private cloud-like computing environment on shared [public cloud](https://www.ibm.com/cloud/public) infrastructure. VPCs give an enterprise the ability to define and control a virtual network that is logically isolated from all other public cloud tenants, creating a private, secure place on the public cloud.\n\nImagine that a cloud provider\u2019s infrastructure is a residential apartment building and multiple families live inside. Being a public cloud tenant is akin to sharing an apartment with a few roommates. In contrast, having a VPC is like having your own private condominium; no one else has the key, and no one can enter the space without your permission.\n\nA VPC\u2019s logical isolation is implemented by using virtual network functions and security features that give an enterprise customer granular control over which IP addresses or applications can access particular resources. It is analogous to the \u201cfriends-only\u201d or \u201cpublic/private\u201d controls on social media accounts used to restrict who can or can\u2019t see your otherwise public posts.\n\nWith IBM Cloud VPC, you can use the UI, CLI, and API to manually provision virtual server instances for VPC with high network performance. VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including Virtual Servers for VPC. Use the following information to understand a simple use case for planning, creating, and configuring resources for your VPC, and learn about more VPC overviews and VPC tutorials. For more information about VPC, see [Getting started with Virtual Private Cloud (VPC)](https://cloud.ibm.com/docs/vpc?topic=vpc-getting-started).", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-components-terraform-nw-db2-terraform"}, {"document_id": "ibmcld_14870-7-1912", "score": 21.143946, "text": "\nDeployment Journey Overview \n\nIBM Cloud\u00ae Virtual Private Cloud(VPC) allows you to establish your own virtual private cloud by defining a virtual network that is logically isolated from all other public cloud tenants. The underlying software defined networking (SDN) and virtual network functions allows you to quickly establish the network constructs and on-prem connectivity needed to run your workload. The information contained within this document is meant to serve as a technical guide for beginning with a new IBM Cloud Account and leading towards a fully configured VPC network environment.\n\nWelcome to the Deployment Journey for VPC on IBM Cloud! Use the sidebar on the left to navigate between the journey points.\n\n\n\n Journey Map \n\n![Architecture](https://cloud.ibm.com/docs-content/v1/content/d50364af907081c3c38f99c11f35dd9cab4b2510/vpc-journey/images/overview/journey-map.png)\n\n\n\n\n\n Assumptions \n\nThis deployment guide will be assuming the following points. Please note that while your circumstance may not be exactly identical, you will still benefit from the overall journey steps and concepts covered in this guide.\n\n\n\n* You are already familar with the concepts introduced in the \"Tour IBM Cloud\" videos available on the [Getting Started with IBM Cloud](https://cloud.ibm.com/cloud/get-started) page.\n* Access groups will need to be defined so only certain users have the ability to create and manage the VPC network settings (i.e. CIDR ranges, Subnet ACL rules, etc.,).\n* You have a networking background and familar with concepts such as IP Addressing, subnets, routing, etc.,\n* Focus will be on establishing the underlying network connectivity to support VPC based workloads.\n\n\n\n* Note: A separate deployment guide will cover the compute resources which runs within the VPC like IBM Kubernetes Services (IKS), Red Hat OpenShift, IBM Code Engine, and VPC Virtual Server Instances (VSIs).", "title": "", "source": "https://cloud.ibm.com/docs/vpc-journey?topic=vpc-journey-vpc-overview"}, {"document_id": "ibmcld_11606-7-2176", "score": 21.139359, "text": "\nIntroduction to IBM Cloud VPC and Additional Application Server (AAS) to HANA and AnyDB \n\nYou can use Terraform to automate IBM Cloud\u00ae VPC provisioning. The VPC provisioned includes virtual server instances with high network performance. The VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including Virtual Servers. After the VPC is provisioned, the scripts use the Ansible Playbook to install the SAP system. IBM Cloud VPC infrastructure consists of SAP certified hardware that uses Intel Xeon CPUs and additional Intel technologies.\n\n\n\n IBM Cloud VPC introduction \n\nA VPC is a public cloud offering that an enterprise uses to establish its own private cloud-like computing environment on shared [public cloud](https://www.ibm.com/cloud/public) infrastructure. VPCs give an enterprise the ability to define and control a virtual network that is logically isolated from all other public cloud tenants, creating a private, secure place on the public cloud.\n\nImagine that a cloud provider\u2019s infrastructure is a residential apartment building and multiple families live inside. Being a public cloud tenant is akin to sharing an apartment with a few roommates. In contrast, having a VPC is like having your own private condominium; no one else has the key, and no one can enter the space without your permission.\n\nA VPC\u2019s logical isolation is implemented by using virtual network functions and security features that give an enterprise customer granular control over which IP addresses or applications can access particular resources. It is analogous to the \u201cfriends-only\u201d or \u201cpublic/private\u201d controls on social media accounts used to restrict who can or can\u2019t see your otherwise public posts.\n\nWith IBM Cloud VPC, you can use the UI, CLI, and API to manually provision virtual server instances for VPC with high network performance. VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including Virtual Servers for VPC. Use the following information to understand a simple use case for planning, creating, and configuring resources for your VPC, and learn about more VPC overviews and VPC tutorials.", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-intro-automate-aas-hana-anydb-terraform-ansible"}, {"document_id": "ibmcld_11554-7-2222", "score": 21.055367, "text": "\nOverview for automating SAP workload HA deployment on IBM Cloud\u00ae Virtual Private Cloud (VPC) with Terraform and Ansible \n\nYou can use Terraform to automate IBM Cloud VPC provisioning. The VPC provisioned includes virtual server instances with high network performance. The VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including virtual servers. After the VPC is provisioned, the scripts use the Ansible Playbook to install the SAP system.\n\n\n\n IBM Cloud\u00ae VPC introduction \n\nA VPC is a public cloud offering that an enterprise uses to establish its own private cloud-like computing environment on shared [public cloud](https://www.ibm.com/cloud) infrastructure. VPCs give an enterprise the ability to define and control a virtual network that is logically isolated from all other public cloud tenants, creating a private, secure place on the public cloud.\n\nImagine that a cloud provider\u2019s infrastructure is a residential apartment building and multiple families live inside. Being a public cloud tenant is akin to sharing an apartment with a few roommates. In contrast, having a VPC is like having your own private condominium; no one else has the key, and no one can enter the space without your permission.\n\nA VPC\u2019s logical isolation is implemented by using virtual network functions and security features that give an enterprise customer granular control over which IP addresses or applications can access particular resources. It is analogous to the \u201cfriends-only\u201d or \u201cpublic/private\u201d controls on social media accounts used to restrict who can or can\u2019t see your otherwise public posts.\n\nWith IBM Cloud VPC, you can use the UI, CLI, and API to manually provision virtual server instances for VPC with high network performance. VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including Virtual Servers for VPC. Use the following information to understand a simple use case for planning, creating, and configuring resources for your VPC, and learn about more VPC overviews and VPC tutorials. For more information about VPC, see [Getting started with Virtual Private Cloud (VPC)](https://cloud.ibm.com/docs/vpc?topic=vpc-getting-started).", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-automate-sap-ha-deployment-overview"}, {"document_id": "ibmcld_15810-20628-22588", "score": 21.045635, "text": "\nFor more information, see [Network interface configuration for instance profiles](https://cloud.ibm.com/docs/vpc?topic=vpc-api-change-log&interface=cli28-march-2023-all-version-dates).\n\n\n\n\n\n 23 March 2023 \n\nNew network latency dashboard\n: Provides visibility into network latency between all regions to help you plan the optimal selection for your cloud deployment and plan for scenarios, such as data residency and performance. This dashboard provides the average network round-trip latency (round-trip time or RTT) for all pairs of regions in IBM Cloud over a 30-day period.\n\nYou can view and monitor performance in the following IBM Cloud regions: Dallas, Toronto, Washington DC, Frankfurt, London, Osaka, Sydney, Tokyo, and S\u00e3o Paulo.\n\nTo view performance metrics, see the [Network latency dashboard](https://cloud.ibm.com/docs/vpc?topic=vpc-network-latency-dashboard).\n\n\n\n\n\n 21 March 2023 \n\nInstance provision by volume\n: You can now reuse an existing boot volume to provision a virtual server instance. The specified volume must be unattached, be in the same zone as the instance profile, and must have an operating system with the same architecture as the instance profile. By default, a boot volume that is created as part of provisioning a virtual server instance is deleted when the instance is deleted. You can control this behavior when you create or updating an instance. For more information, see [Creating virtual server instances](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-virtual-servers&interface=ui), and [Managing virtual server instances](https://cloud.ibm.com/docs/vpc?topic=vpc-managing-virtual-server-instances&interface=ui).\n\nDesignating VPC route priority\n: When multiple VPC routes exist for a destination, you can now control the priority of these routes (from 0 to 4). New and existing routes that are created without a priority value, are automatically set to the default priority (2). Smaller values have higher priority.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-release-notes"}]}
{"task_id": "4175fcce99c56af0e02be5b8990fc16a<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04734-4788-6538", "score": 15.588157, "text": "\n[External link icon](https://cloud.ibm.com/docs-content/v1/content/8aa0853d34cf2349f1d2db8e5c61e6422a580169/icons/launch-glyph.svg)](https://www.ibm.com/blogs/cloud-computing/2016/08/10/practical-guide-paas/).\n\nWith the SaaS model, your provider maintains the systems through the actual application. The application is cloud-aware, and users can use different end points, depending on the software provider, to use the software. The cloud provider is responsible for all infrastructure and application management, which includes software updates, hardware repairs, and network settings. This model is often used in pay-as-you-go software licensing models. For more information, see [SaaS applications for business and IT](https://www.ibm.com/cloud/saas)![External link icon](https://cloud.ibm.com/docs-content/v1/content/8aa0853d34cf2349f1d2db8e5c61e6422a580169/icons/launch-glyph.svg).\n\n\n\n\n\n Cloud types \n\nThere are three different types of clouds available: public, private, and hybrid. A public cloud includes a shared set of resources that are provisioned to allow access to a company's resources. It is hosted in a multi-tenant environment on a virtual server, and it can be accessed from anywhere.\n\nA private cloud includes resources that are provisioned to allow access to a company's resources. It is hosted on dedicated hardware, such as a bare metal server, and either onsite at the company's office (or across offices) or by a cloud provider. A private cloud can be accessed from anywhere.\n\nA hybrid cloud includes resources that combine the aspects of both public and private clouds. It is hosted both onsite at a company's office (or across offices) and by a cloud provider. A hybrid cloud can be accessed from anywhere.\n\n\n\n\n\n Next steps", "title": "", "source": "https://cloud.ibm.com/docs/cloud-infrastructure?topic=cloud-infrastructure-getting-started-tutorial"}, {"document_id": "ibmcld_11098-1510-3924", "score": 13.007174, "text": "\nAnd, in some ways it is extremely modular in that the replacement unit is usually an entire server. But there is one major difference between the redundancy that is provided in a mainframe and the redundancy that is provided in the cloud \u2013 in the cloud the redundancy must be managed by the user. This means that to design a system to run with high availability on the cloud the system designer needs to be familiar with various high availability issues, as well as the design issues associated with the system that they are trying to build.\n\nThere are decades of academic and practical writings on high availability, and much of the work requires a good understanding of probability mathematics. However, much like with the formula, many of the principles become obvious when properly explained. Redundancy, which can be complicated in some cases, such as the various levels of RAID disk subsystems, is simply a way of dealing with a widely known principle of system design: \u201cAvoid single points of failure.\u201d Admittedly, while the phrase is simple and obvious, implementation can be tricky.\n\nRather than go into the complexities of such implementations, we cover a high-level overview of the areas that need to be addressed by anyone looking to build or run a highly available cloud system.\n\nBeyond the general principles of redundancy, fast repair, and single points of failure (SPOFs), probably the most important thing to understand is that improving availability requires spending effort on avoiding likely causes of outages, rather than trying to harden the system against all possible outages.\n\nAn example can help to make this clear. In astronomy, it is understood that our solar system will effectively end when the Sun goes nova. This will obviously cause all the computing systems on Earth to fail. Hence it is not something worth spending time and money on avoiding. Perhaps that particular example seems too extreme. So as a much simpler, business-oriented example, consider a city-wide fire, such as the one that burned down much of Chicago in the late 1800s. Fires on that scale are unusual, but not unique. As a business, should you spend time and money making sure that your computer systems could survive such a fire? The answer depends on various factors, but if for instance, your entire customer base is in Chicago, worrying about events that will wipe out the whole city is likely not useful.", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-ha-considerations"}, {"document_id": "ibmcld_10725-7-1914", "score": 12.75314, "text": "\nHow Cloud Functions works \n\nIBM Cloud\u00ae Functions service is an event-driven compute platform, also referred to as Serverless computing, or as Function as a Service (FaaS), that runs code in response to events or direct invocations.\n\n\n\n Cloud Functions terminology \n\nLearn the basic concepts of the technology behind Cloud Functions. Then, test your knowledge and [!take a quiz](https://quizzes.12dekrh4l1b4.us-south.codeengine.appdomain.cloud/functions/terms_quiz/quiz.php)\n\n\n\nTable 1. Cloud Functions Terms\n\n Term Description \n\n Namespace [Namespaces](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-namespaces) contain Cloud Functions entities, such as actions and triggers, and belong to a resource group. You can let users access your Cloud Functions entities by granting them access to the namespace. \n Action An [action](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-actions) is a piece of code that performs one specific task. An action can be written in the language of your choice, such as small snippets of JavaScript or Swift code or custom binary code embedded in a Docker container. You provide your action to Cloud Functions either as source code or a Docker image. An action performs work when it is directly invoked by using the Cloud Functions API, CLI, or iOS SDK. An action can also automatically respond to events from IBM Cloud services and third-party services by using a trigger. \n Sequence A set of actions can be chained together into a [sequence](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sequences) without having to write any code. A sequence is a chain of actions, invoked in order, where the output of one action is passed as input to the next action. By creating a sequence, you can combine existing actions together for quick and easy reuse. A sequence can then be invoked just like an action, through a REST API or automatically in response to events.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-about"}, {"document_id": "ibmcld_13074-17975-20043", "score": 12.729238, "text": "\nParses elements (sentences, lists, tables) in governing documents to classify important types and categories For more information, see [Element classification](https://cloud.ibm.com/docs/discovery?topic=discovery-element-classification).\n\n[Smart Document Understanding](https://cloud.ibm.com/docs/discovery?topic=discovery-sdu) is unavailable if this enrichment is used.\n\n\n\n Enrichment pricing \n\nEnrichment pricing information is available on [IBM Cloud](https://cloud.ibm.com/catalog/services/discovery).\n\n\n\n\n\n Enrichment language support \n\nFor information about enrichment language support, see [Discovery language support](https://cloud.ibm.com/docs/discovery?topic=discovery-language-support).\n\n\n\n\n\n\n\n Understanding the difference between Entities, Concepts, and Keywords \n\nAt first glance, Entity extraction, Concept tagging and Keyword extraction appear to be similar enrichments. We'll use the text from the enrichment examples to show the differences between them.\n\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\"\n\nSince the Entity Extraction enrichment extracts persons, places, and organizations in the input text, Entity extraction returns the following entity types:\n\n\"type\": \"City\"\n\"text\": \"Atlanta\"\n\n\"type\": \"Company\"\n\"text\": \"Acme\"\n\n\"type\": \"StateOrCounty\"\n\"text\": \"Georgia\"\n\nSince the Concept tagging enrichment understands how concepts relate, it can identify concepts that are not directly referenced in the text. For example, if an article mentions CERN and the Higgs boson, it identifies Large Hadron Collider as a concept even if that term is not mentioned explicitly. Since our example document text is only one sentence, there are no related concepts, so Concept tagging returns the following concepts:\n\n\"text\": \"Acme Corporation\"\n\"text\": \"factory\"\n\nSince the Keyword extraction enrichment identifies content typically used when indexing data, generating tag clouds, or searching, Keyword extraction returns the following keywords:\n\n\"text\": \"Acme Corporation\"\n\"text\": \"new factory\"", "title": "", "source": "https://cloud.ibm.com/docs/services/discovery?topic=discovery-configservice"}, {"document_id": "ibmcld_10916-50482-52193", "score": 12.440898, "text": "\nA region that is spread across data centers in multiple zones to increase fault tolerance. See also [zone](https://cloud.ibm.com/docs/overview?topic=overview-glossaryx2070723).\n\n\n\n\n\n MZR \n\nSee [multizone region](https://cloud.ibm.com/docs/overview?topic=overview-glossaryx9774820).\n\n\n\n\n\n\n\n N \n\n\n\n named entity \n\nA concept in a domain that falls in to a well defined category, such as names of organizations, locations, authors, or diseases.\n\n\n\n\n\n namespace \n\nA collection of repositories that store images in a registry. A namespace is associated with an IBM Cloud account, which can include multiple namespaces. See also [image](https://cloud.ibm.com/docs/overview?topic=overview-glossaryx2024928), [private image repository](https://cloud.ibm.com/docs/overview?topic=overview-glossaryx8439215).\n\n\n\n\n\n NAT \n\nSee [network address translation](https://cloud.ibm.com/docs/overview?topic=overview-glossaryx2031199).\n\n\n\n\n\n natural language processing (NLP) \n\nA field of artificial intelligence and linguistics that studies the problems inherent in the processing and manipulation of natural language, with an aim to increase the ability of computers to understand human languages.\n\n\n\n\n\n network address translation (NAT) \n\nAn addressing method that is used to enable one IP address to communicate with several other IP addresses, such as those on a private subnet, by means of a lookup table. Network address translation has two main types: 1-to-1 and many-to-1.\n\n\n\n\n\n Network File System (NFS) \n\nA protocol that allows a computer to access files over a network as if they were on its local disks.\n\n\n\n\n\n NFS \n\nSee [Network File System](https://cloud.ibm.com/docs/overview?topic=overview-glossaryx2031282).\n\n\n\n\n\n NLP", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-glossary"}, {"document_id": "ibmcld_06457-8298-9523", "score": 12.43441, "text": "\nCloud Type ibm_ctype The cloud type is a value of public, dedicated, or local. \n Location ibm_location The location of the monitored resource - this might be a region, data center, or global. \n Resource ibm_resource The resource being measured by the service - typically an identifying name or GUID. \n Resource Type ibm_resource_type The type of the resource being measured by the service. \n Scope ibm_scope The scope is the account, organization, or space GUID associated with this metric. \n\n\n\n\n\n\n\n More Attributes \n\nThe following attributes are available for segmenting one or more attributes as described in the reference. See the individual metrics for segmentation options.\n\n\n\nTable 15. Additional Attributes metadata\n\n Attribute Attribute Name Attribute Description \n\n Service instance ibm_service_instance The service instance segment identifies the instance that the metric is associated with. \n Service instance name ibm_service_instance_name The service instance name provides the user-provided name of the service instance, which isn't necessarily a unique value depending on the name that is provided by the user. \n Resource group ibm_resource_group_name The resource group where the service instance was created.", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-etcd?topic=databases-for-etcd-monitoring"}, {"document_id": "ibmcld_04734-6091-6676", "score": 12.192807, "text": "\nIt is hosted on dedicated hardware, such as a bare metal server, and either onsite at the company's office (or across offices) or by a cloud provider. A private cloud can be accessed from anywhere.\n\nA hybrid cloud includes resources that combine the aspects of both public and private clouds. It is hosted both onsite at a company's office (or across offices) and by a cloud provider. A hybrid cloud can be accessed from anywhere.\n\n\n\n\n\n Next steps \n\nTo continue, see [Planning your infrastructure](https://cloud.ibm.com/docs/cloud-infrastructure?topic=cloud-infrastructure-planning-2).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-infrastructure?topic=cloud-infrastructure-getting-started-tutorial"}, {"document_id": "ibmcld_10916-13226-15484", "score": 11.824405, "text": "\nSee also [host](https://cloud.ibm.com/docs/overview?topic=overview-glossaryx2002243).\n\n\n\n\n\n\n\n client secret \n\nA piece of information that is used with an application key to verify the identity of an application. An API can be configured to require that client applications supply their application secret with their application key. The application secret functions effectively as a password known only to the application. The application secret is passed by the client using an HTTP query parameter.\n\n\n\n\n\n cloud computing \n\nA computing platform where users can have access to applications or computing resources, as services, from anywhere through their connected devices. A simplified user interface or application programming interface (API), or both, makes the infrastructure supporting such services transparent to users.\n\n\n\n\n\n cloud portability \n\nThe ability to move applications and services across public or private cloud computing environments, or from different cloud providers.\n\n\n\n\n\n cloud provider \n\nAn organization that provides cloud computing resources.\n\n\n\n\n\n cloud resource name (CRN) \n\nA globally unique identifier for a specific cloud resource. The value is segmented hierarchically by version, instance, type, location, and scope, separated by colons.\n\n\n\n\n\n command-line interface (CLI) \n\nA computer interface in which the input and output are text based.\n\n\n\n\n\n community \n\nA collection of consumer organizations. It is used as a grouping construct when publishing APIs. Communities are used to restrict the visibility and accessibility of APIs.\n\n\n\n\n\n component \n\nIn source control management, a grouping of related artifacts in a stream or repository workspace. A component can contain any number of folders and files.\n\n\n\n\n\n compute \n\nInfrastructure or resources that serve as the basis for building apps in the cloud.\n\n\n\n\n\n config rule \n\nSee [configuration rule](https://cloud.ibm.com/docs/overview?topic=overview-glossaryx3084914).\n\n\n\n\n\n configuration rule (config rule) \n\nA JSON document that defines the configuration of resources and validates the compliance based on security requirements when a resource is created or modified.\n\n\n\n\n\n confusion matrix \n\nA table that provides a detailed numeric breakdown of annotated document sets.", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-glossary"}, {"document_id": "ibmcld_03525-9312-10382", "score": 11.798451, "text": "\nCloud Type ibm_ctype The cloud type is public, dedicated, or local. \n Location ibm_location The location of the monitored resource, which can be a region, data center, or global. \n Resource ibm_resource The resource that is measured by the service, which is typically an identifying name or GUID. \n Resource Type ibm_resource_type The type of the resource that is measured by the service. \n Scope ibm_scope The scope is the account, organization, or space GUID associated with the metric. \n Service name ibm_service_name The name of the service that is generating this metric. \n\n\n\n\n\n\n\n More attributes \n\nThe following attributes are available for one or more attributes described in the previous tables. See the individual metrics for options.\n\n\n\nTable 4. Other atributes\n\n Attribute Attribute Name Attribute Description \n\n target type ibm_atracker_target_type The target type destination of the event. Valid values are: cloud_object_storage, logdna, or event_streams. \n reason ibm_atracker_reason_code The reason for the failure of an event delivery to its destination.", "title": "", "source": "https://cloud.ibm.com/docs/atracker?topic=atracker-monitoring_metrics"}, {"document_id": "ibmcld_11109-12200-14354", "score": 11.639642, "text": "\nThe components on cloud are passive in the sense that they do not perform active production workload, but they are receiving updates from the on premises components that are performing all of the productive workload.\n\nOn the HA+DR side, you see a typical 3-site deploy, where two sites are performing productive workload (active-active couples), while the third site has passive components that just receive the updates from the two productive sites.\n\nIn both cases, you see an \u201con-demand\u201d environment that is dynamically created and used solely to run DR test.\n\nYou should limit the continuous availability class to only those workloads really needing this service level.\n\nTo achieve a continuous availability level is expensive and might be limited by constraints such as the distance and network bandwidth between primary and secondary sites.\n\n\n\n\n\n Advanced recovery class \n\nFor [advanced recovery class](https://cloud.ibm.com/docs/overview?topic=overview-understanding-drplan-objectives), a continuous data replication solution maintains a live copy of source disks over a different cloud site or zone. This can be achieved mainly in three ways:\n\nNative Cloud function\n: Cloud offers disk replication functions to native duplicates data among cloud zones or sites.\n\nDRaaS products\n: In cloud marketplace, there are products and tools available that can be acquired and implemented on cloud resources (compute, storage, network) to provide a user-controllable disk replication in support of a DR as a service solution. Most of these products replicate data with a software solution that is an agent installed in the source VM or Hypervisor that intercepts the updates and sends them to a correspondent receiving software-based replicator at the DR location.\n\nSoftware Defined Storage (SDS)\n: Instead of using native storage functions of the cloud, SDS products from the marketplace use cloud resources (compute, storage, network) to provide a user-controllable disk subsystem, including data replication functions.\n\nOS disks might not be duplicated with an SDS solution as you might have limitations in having a VM to boot from an SDS replicated disk.", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-networking-aspects"}]}
{"task_id": "4175fcce99c56af0e02be5b8990fc16a<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13243-7-1952", "score": 22.23745, "text": "\nUse a VPC/VPN gateway for secure and private on-premises access to cloud resources \n\nThis tutorial will incur costs. Use the [Cost Estimator](https://cloud.ibm.com/estimator/review) to generate a cost estimate based on your projected usage.\n\nIBM offers a number of ways to securely extend an on-premises computer network with resources in the IBM Cloud. This allows you to benefit from the elasticity of provisioning cloud resources when you need them and removing them when no longer required. Moreover, you can easily and securely connect your on-premises capabilities to the IBM Cloud services.\n\nThis tutorial provides the automation to create resources that demonstrate Virtual Private Network (VPN) connectivity between on-premises servers and cloud resources like IBM Cloud\u00ae Virtual Private Cloud Virtual Service Instances (VSIs) and IBM Cloud data services. DNS resolution to cloud resources is also configured. The popular [strongSwan](https://www.strongswan.org/) VPN Gateway is used to represent the on-premises VPN gateway.\n\n\n\n Objectives \n\n\n\n* Access a virtual private cloud (VPC) environment from an on-premises data center\n* Securely reach cloud services using private endpoint gateways\n* Use DNS on-premises to access cloud resources over VPN\n\n\n\nThe following diagram shows the resources created by this tutorial\n\nZoom\n\n![Architecture](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution46-vpc-vpn/vpc-site2site-vpn-tutorial.png)\n\nFigure 1. Architecture diagram of the tutorial\n\nA terraform configuration will create the following resources:\n\n\n\n1. The infrastructure (VPC, Subnets, Security Groups with rules, Network ACL and VSIs).\n2. The Object Storage and Databases for PostgreSQL private endpoint gateways to data services.\n3. The strongSwan open source IPsec gateway software is used on-premises to establish the VPN connection with the cloud environment.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vpc-site2site-vpn"}, {"document_id": "ibmcld_00558-4443-6604", "score": 21.92516, "text": "\nThe Standard plan includes 20 GB of data storage. If you store more than 20 GB, you're charged a defined cost per GB per hour.\n\nRefer to the IBM Cloud Pricing Calculator in the dashboard for pricing at different capacities and currencies, and the [pricing](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-pricingpricing) information for examples to estimate costs.\n\n\n\n\n\n Dedicated Hardware plan \n\nAn IBM Cloudant Dedicated Hardware plan instance is a bare metal IBM Cloudant environment that is provisioned for the sole use of your IBM Cloudant Standard plan instances. The IBM Cloudant Dedicated Hardware plan offers the following options:\n\n\n\n* An IBM Cloudant Dedicated Hardware plan environment that can be provisioned in any [IBM\u00ae global data center](https://www.ibm.com/cloud/data-centers/).\n* This plan is necessary for HIPAA compliance and must be selected at provisioning time.\n* Users can choose to bring-your-own-key (BYOK) with customer-managed encryption keys with IBM Key Protect for all environments provisioned 1 January 2020 or later. IBM Cloudant runs on encrypted disks, but to BYOK, the Dedicated Hardware plan is required. BYOK encryption details must be chosen at provisioning time, and the feature isn't available for already-provisioned Dedicated Hardware plan environments.\n* All Standard plan instances that are deployed on Dedicated Hardware plan environments include both private (internal) endpoints and public endpoints in locations that support Cloud Service Endpoints (CSE). Using private endpoints allows customers to connect to an IBM Cloudant instance through the internal IBM Cloud\u00ae network to avoid upstream application traffic from going over the public network and incurring bandwidth charges. For more information, see [Cloud Service Endpoint documentation](https://cloud.ibm.com/docs/account?topic=account-service-endpoints-overview) for details about enabling Cloud Service Endpoints for your IBM Cloud\u00ae account.\n* Users of an IBM Cloudant Dedicated Hardware plan environment can employ IP allowlisting by contacting support. IP allowlisting configuration applies to all instances that are running on the environment.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-public"}, {"document_id": "ibmcld_12904-4506-6667", "score": 21.92516, "text": "\nThe Standard plan includes 20 GB of data storage. If you store more than 20 GB, you're charged a defined cost per GB per hour.\n\nRefer to the IBM Cloud Pricing Calculator in the dashboard for pricing at different capacities and currencies, and the [pricing](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-pricingpricing) information for examples to estimate costs.\n\n\n\n\n\n Dedicated Hardware plan \n\nAn IBM Cloudant Dedicated Hardware plan instance is a bare metal IBM Cloudant environment that is provisioned for the sole use of your IBM Cloudant Standard plan instances. The IBM Cloudant Dedicated Hardware plan offers the following options:\n\n\n\n* An IBM Cloudant Dedicated Hardware plan environment that can be provisioned in any [IBM\u00ae global data center](https://www.ibm.com/cloud/data-centers/).\n* This plan is necessary for HIPAA compliance and must be selected at provisioning time.\n* Users can choose to bring-your-own-key (BYOK) with customer-managed encryption keys with IBM Key Protect for all environments provisioned 1 January 2020 or later. IBM Cloudant runs on encrypted disks, but to BYOK, the Dedicated Hardware plan is required. BYOK encryption details must be chosen at provisioning time, and the feature isn't available for already-provisioned Dedicated Hardware plan environments.\n* All Standard plan instances that are deployed on Dedicated Hardware plan environments include both private (internal) endpoints and public endpoints in locations that support Cloud Service Endpoints (CSE). Using private endpoints allows customers to connect to an IBM Cloudant instance through the internal IBM Cloud\u00ae network to avoid upstream application traffic from going over the public network and incurring bandwidth charges. For more information, see [Cloud Service Endpoint documentation](https://cloud.ibm.com/docs/account?topic=account-service-endpoints-overview) for details about enabling Cloud Service Endpoints for your IBM Cloud\u00ae account.\n* Users of an IBM Cloudant Dedicated Hardware plan environment can employ IP allowlisting by contacting support. IP allowlisting configuration applies to all instances that are running on the environment.", "title": "", "source": "https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-ibm-cloud-public"}, {"document_id": "ibmcld_13235-7-2014", "score": 21.801788, "text": "\nPublic frontend and private backend in a Virtual Private Cloud \n\nThis tutorial may incur costs. Use the [Cost Estimator](https://cloud.ibm.com/estimator/review) to generate a cost estimate based on your projected usage.\n\nThis tutorial walks you through creating your own IBM Cloud\u00ae Virtual Private Cloud (VPC) with multiple subnets and a virtual server instance (VSI) in each subnet. A VPC is your own, private cloud on shared cloud infrastructure with logical isolation from other virtual networks.\n\nA subnet is an IP address range. It is bound to a single zone and cannot span multiple zones or regions. For the purposes of VPC, the important characteristic of a subnet is the fact that subnets can be isolated from one another, as well as being interconnected in the usual way. Subnet isolation can be accomplished by Security Groups that act as firewalls to control inbound and outbound traffic for one or more virtual server instances.\n\nA good practice is to have a subnet used for resources that must be exposed to the outside world. Resources with restricted access that should never be directly accessed from the outside world are placed within a different subnet. Instances on such a subnet could be your backend database or some secret store that you do not want to be publicly accessible. You will define Security Groups to allow or deny traffic to the VSIs.\n\nIn short, using VPC you can:\n\n\n\n* create a software-defined network (SDN),\n* isolate workloads,\n* have fine control of inbound and outbound traffic.\n\n\n\n\n\n Objectives \n\n\n\n* Understand the infrastructure objects available for virtual private clouds\n* Learn how to create a virtual private cloud, subnets and server instances\n* Know how to apply security groups to secure access to the servers\n\n\n\nZoom\n\n![Architecture](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution40-vpc-public-app-private-backend/Architecture.svg)\n\nFigure 1. Architecture diagram of the tutorial", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vpc-public-app-private-backend"}, {"document_id": "ibmcld_13238-7-1949", "score": 21.763233, "text": "\nSecurely access remote instances with a bastion host \n\nThis tutorial may incur costs. Use the [Cost Estimator](https://cloud.ibm.com/estimator/review) to generate a cost estimate based on your projected usage.\n\nThis tutorial walks you through the deployment of a bastion host to securely access remote instances within a Virtual Private Cloud (VPC). A bastion host is an instance that is provisioned with a public IP address and can be accessed via SSH. Once set up, the bastion host acts as a jump server, allowing secure connection to instances provisioned without a public IP address.\n\nTo reduce exposure of servers within the VPC, you will create and use a bastion host. Administrative tasks on the individual servers are going to be performed using SSH, proxied through the bastion. Access to the servers and regular internet access from the servers, e.g., for software installation, will only be allowed with a special maintenance security group attached to those servers.\n\n\n\n Objectives \n\n\n\n* Learn how to set up a bastion host and security groups with rules\n* Securely manage servers via the bastion host\n\n\n\nZoom\n\n![Architecture](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution47-vpc-secure-management-bastion-server/ArchitectureDiagram.png)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. After setting up the required infrastructure (subnets, security groups with rules, virtual server instances) on the cloud, the admin (DevOps) connects (SSH) to the bastion host using the private SSH key.\n2. The admin assigns a maintenance security group with proper outbound rules.\n3. The admin connects (SSH) securely to the instance's private IP address via the bastion host to install or update any required software eg., a web server\n4. The internet user makes an HTTP/HTTPS request to the web server.\n\n\n\n\n\n\n\n Before you begin \n\n\n\n* Check for user permissions.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vpc-secure-management-bastion-server"}, {"document_id": "ibmcld_16080-7-1779", "score": 21.745287, "text": "\nPublic frontend and private backend in a Virtual Private Cloud \n\nThis tutorial may incur costs. Use the [Cost Estimator](https://cloud.ibm.com/estimator/review) to generate a cost estimate based on your projected usage.\n\nThis tutorial walks you through creating your own IBM Cloud\u00ae Virtual Private Cloud (VPC) with multiple subnets and a virtual server instance (VSI) in each subnet. A VPC is your own, private cloud on shared cloud infrastructure with logical isolation from other virtual networks.\n\nA subnet is an IP address range. It is bound to a single zone and cannot span multiple zones or regions. For the purposes of VPC, the important characteristic of a subnet is the fact that subnets can be isolated from one another, as well as being interconnected in the usual way. Subnet isolation can be accomplished by Security Groups that act as firewalls to control inbound and outbound traffic for one or more virtual server instances.\n\nA good practice is to have a subnet used for resources that must be exposed to the outside world. Resources with restricted access that should never be directly accessed from the outside world are placed within a different subnet. Instances on such a subnet could be your backend database or some secret store that you do not want to be publicly accessible. You will define Security Groups to allow or deny traffic to the VSIs.\n\nIn short, using VPC you can:\n\n\n\n* create a software-defined network (SDN),\n* isolate workloads,\n* have fine control of inbound and outbound traffic.\n\n\n\n\n\n Objectives \n\n\n\n* Understand the infrastructure objects available for virtual private clouds\n* Learn how to create a virtual private cloud, subnets and server instances\n* Know how to apply security groups to secure access to the servers\n\n\n\nZoom\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-public-app-private-backend"}, {"document_id": "ibmcld_16095-7-1863", "score": 21.588905, "text": "\nUse a VPC/VPN gateway for secure and private on-premises access to cloud resources \n\nThis tutorial will incur costs. Use the [Cost Estimator](https://cloud.ibm.com/estimator/review) to generate a cost estimate based on your projected usage.\n\nIBM offers a number of ways to securely extend an on-premises computer network with resources in the IBM Cloud. This allows you to benefit from the elasticity of provisioning cloud resources when you need them and removing them when no longer required. Moreover, you can easily and securely connect your on-premises capabilities to the IBM Cloud services.\n\nThis tutorial provides the automation to create resources that demonstrate Virtual Private Network (VPN) connectivity between on-premises servers and cloud resources like IBM Cloud\u00ae Virtual Private Cloud Virtual Service Instances (VSIs) and IBM Cloud data services. DNS resolution to cloud resources is also configured. The popular [strongSwan](https://www.strongswan.org/) VPN Gateway is used to represent the on-premises VPN gateway.\n\n\n\n Objectives \n\n\n\n* Access a virtual private cloud (VPC) environment from an on-premises data center\n* Securely reach cloud services using private endpoint gateways\n* Use DNS on-premises to access cloud resources over VPN\n\n\n\nThe following diagram shows the resources created by this tutorial\n\nZoom\n\n![Architecture](https://cloud.ibm.com/docs-content/v1/content/f02b9c9adcbb7328d95a45e105cec371d50f15eb/vpc/includes/solution-tutorials/includes/solution-tutorials/images/solution46-vpc-vpn/vpc-site2site-vpn-tutorial.png)\n\nFigure 1. Architecture diagram of the tutorial\n\nA terraform configuration will create the following resources:\n\n\n\n1. The infrastructure (VPC, Subnets, Security Groups with rules, Network ACL and VSIs).\n2. The Object Storage and Databases for PostgreSQL private endpoint gateways to data services.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-site2site-vpn"}, {"document_id": "ibmcld_16094-7-1956", "score": 21.526678, "text": "\nSecurely access remote instances with a bastion host \n\nThis tutorial may incur costs. Use the [Cost Estimator](https://cloud.ibm.com/estimator/review) to generate a cost estimate based on your projected usage.\n\nThis tutorial walks you through the deployment of a bastion host to securely access remote instances within a Virtual Private Cloud (VPC). A bastion host is an instance that is provisioned with a public IP address and can be accessed via SSH. Once set up, the bastion host acts as a jump server, allowing secure connection to instances provisioned without a public IP address.\n\nTo reduce exposure of servers within the VPC, you will create and use a bastion host. Administrative tasks on the individual servers are going to be performed using SSH, proxied through the bastion. Access to the servers and regular internet access from the servers, e.g., for software installation, will only be allowed with a special maintenance security group attached to those servers.\n\n\n\n Objectives \n\n\n\n* Learn how to set up a bastion host and security groups with rules\n* Securely manage servers via the bastion host\n\n\n\nZoom\n\n![Architecture](https://cloud.ibm.com/docs-content/v1/content/f02b9c9adcbb7328d95a45e105cec371d50f15eb/vpc/includes/solution-tutorials/includes/solution-tutorials/images/solution47-vpc-secure-management-bastion-server/ArchitectureDiagram.png)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. After setting up the required infrastructure (subnets, security groups with rules, virtual server instances) on the cloud, the admin (DevOps) connects (SSH) to the bastion host using the private SSH key.\n2. The admin assigns a maintenance security group with proper outbound rules.\n3. The admin connects (SSH) securely to the instance's private IP address via the bastion host to install or update any required software eg., a web server\n4. The internet user makes an HTTP/HTTPS request to the web server.\n\n\n\n\n\n\n\n Before you begin", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-secure-management-bastion-server"}, {"document_id": "ibmcld_13244-7-1999", "score": 20.948725, "text": "\nTeam based privacy using IAM, VPC, Transit Gateway and DNS \n\nThis tutorial may incur costs. Use the [Cost Estimator](https://cloud.ibm.com/estimator/review) to generate a cost estimate based on your projected usage.\n\nMicroservices are popular because they allow an enterprise to organize their development teams around the services they deliver. This tutorial walks you through the steps of creating infrastructure for a IBM Cloud\u00ae Virtual Private Cloud (VPC) based microservice architecture. In this architecture, VPCs are connected to each other using the IBM Cloud\u00ae Transit Gateway. A set of shared microservices is accessed through host names registered in the IBM Cloud\u00ae DNS Services. Each VPC is managed by a separate team isolated by IBM Cloud\u00ae Identity and Access Management. Optionally a IBM Cloud\u00ae Load Balancer can be used to scale out the shared microservice.\n\n\n\n Objectives \n\n\n\n* Learn how to isolate infrastructure using IAM and Resource groups\n* Create the VPCs and associated resources such as subnets, network ACLs, security groups, instances.\n* Address microservices by DNS name resolution using DNS Services.\n* Connect VPCs via Transit Gateway.\n* Transparently configure a Load Balancer for an application.\n\n\n\n\n\n Abstract Architecture: \n\nZoom\n\n![Architecture](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution59-vpc-tg-dns-iam/simple.png)\n\nFigure 1. Architecture diagram of the tutorial\n\nIn the diagram above the end user is accessing the applications. The applications are leveraging shared microservices. The company has separate DevOps teams that own application1, application2 and shared. A networking team focuses on connectivity and network security. The DevOps teams manage Virtual Service Instances, VSIs, used to implement the services they create and support.\n\n\n\n\n\n Concrete Architecture \n\nThe following architecture implements the isolation and connectivity requirements set by the company.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vpc-tg-dns-iam"}, {"document_id": "ibmcld_08172-7-1957", "score": 20.649057, "text": "\nTeam based privacy using IAM, VPC, Transit Gateway and DNS \n\nThis tutorial may incur costs. Use the [Cost Estimator](https://cloud.ibm.com/estimator/review) to generate a cost estimate based on your projected usage.\n\nMicroservices are popular because they allow an enterprise to organize their development teams around the services they deliver. This tutorial walks you through the steps of creating infrastructure for a IBM Cloud\u00ae Virtual Private Cloud (VPC) based microservice architecture. In this architecture, VPCs are connected to each other using the IBM Cloud\u00ae Transit Gateway. A set of shared microservices is accessed through host names registered in the IBM Cloud\u00ae DNS Services. Each VPC is managed by a separate team isolated by IBM Cloud\u00ae Identity and Access Management. Optionally a IBM Cloud\u00ae Load Balancer can be used to scale out the shared microservice.\n\n\n\n Objectives \n\n\n\n* Learn how to isolate infrastructure using IAM and Resource groups\n* Create the VPCs and associated resources such as subnets, network ACLs, security groups, instances.\n* Address microservices by DNS name resolution using DNS Services.\n* Connect VPCs via Transit Gateway.\n* Transparently configure a Load Balancer for an application.\n\n\n\n\n\n Abstract Architecture: \n\nZoom\n\n![Architecture](https://cloud.ibm.com/docs-content/v1/content/09179fd478349810f8adb559294b68138ac393ca/hardware-firewall-shared/includes/solution-tutorials/includes/solution-tutorials/images/solution59-vpc-tg-dns-iam/simple.png)\n\nFigure 1. Architecture diagram of the tutorial\n\nIn the diagram above the end user is accessing the applications. The applications are leveraging shared microservices. The company has separate DevOps teams that own application1, application2 and shared. A networking team focuses on connectivity and network security. The DevOps teams manage Virtual Service Instances, VSIs, used to implement the services they create and support.\n\n\n\n\n\n Concrete Architecture", "title": "", "source": "https://cloud.ibm.com/docs/hardware-firewall-shared?topic=hardware-firewall-shared-vpc-tg-dns-iam"}]}
{"task_id": "4175fcce99c56af0e02be5b8990fc16a<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_15164-28701-29788", "score": 39.314423, "text": "\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.\n\ncurl -X POST \"$vpc_api_endpoint/v1/backup_policies/8758bd18-344b-486a-b606-5b8cb8cdd044/plans?version=2023-05-09&generation=2\"\n-H \"Authorization: $iam_token\"\n-d '{\n\"active\": true,\n\"attach_user_tags\": [\n\"hourly-backups\"\n],\n\"copy_user_tags\": true,\n\"cron_spec\": \"0 /2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 20,\n\"delete_over_count\": 20\n},\n\"remote_region_policies\": {\n\"delete_over_count\": 5,\n\"encryption_key\": [\n{\n\"CRN\": \"crn:v1:bluemix:public:kms:us-south:a/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd617\"\n}\n],\n\"region\": [\n{\n\"name\":\"us-east\"\n}\n]\n},\n\"name\": \"my-hourly-plan-2\"\n}'", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan&interface=ui"}, {"document_id": "ibmcld_15160-28636-29723", "score": 39.314423, "text": "\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.\n\ncurl -X POST \"$vpc_api_endpoint/v1/backup_policies/8758bd18-344b-486a-b606-5b8cb8cdd044/plans?version=2023-05-09&generation=2\"\n-H \"Authorization: $iam_token\"\n-d '{\n\"active\": true,\n\"attach_user_tags\": [\n\"hourly-backups\"\n],\n\"copy_user_tags\": true,\n\"cron_spec\": \"0 /2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 20,\n\"delete_over_count\": 20\n},\n\"remote_region_policies\": {\n\"delete_over_count\": 5,\n\"encryption_key\": [\n{\n\"CRN\": \"crn:v1:bluemix:public:kms:us-south:a/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd617\"\n}\n],\n\"region\": [\n{\n\"name\":\"us-east\"\n}\n]\n},\n\"name\": \"my-hourly-plan-2\"\n}'", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan"}, {"document_id": "ibmcld_15163-28736-29823", "score": 39.314423, "text": "\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.\n\ncurl -X POST \"$vpc_api_endpoint/v1/backup_policies/8758bd18-344b-486a-b606-5b8cb8cdd044/plans?version=2023-05-09&generation=2\"\n-H \"Authorization: $iam_token\"\n-d '{\n\"active\": true,\n\"attach_user_tags\": [\n\"hourly-backups\"\n],\n\"copy_user_tags\": true,\n\"cron_spec\": \"0 /2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 20,\n\"delete_over_count\": 20\n},\n\"remote_region_policies\": {\n\"delete_over_count\": 5,\n\"encryption_key\": [\n{\n\"CRN\": \"crn:v1:bluemix:public:kms:us-south:a/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd617\"\n}\n],\n\"region\": [\n{\n\"name\":\"us-east\"\n}\n]\n},\n\"name\": \"my-hourly-plan-2\"\n}'", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan&interface=terraform"}, {"document_id": "ibmcld_15162-28726-29813", "score": 39.314423, "text": "\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.\n\ncurl -X POST \"$vpc_api_endpoint/v1/backup_policies/8758bd18-344b-486a-b606-5b8cb8cdd044/plans?version=2023-05-09&generation=2\"\n-H \"Authorization: $iam_token\"\n-d '{\n\"active\": true,\n\"attach_user_tags\": [\n\"hourly-backups\"\n],\n\"copy_user_tags\": true,\n\"cron_spec\": \"0 /2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 20,\n\"delete_over_count\": 20\n},\n\"remote_region_policies\": {\n\"delete_over_count\": 5,\n\"encryption_key\": [\n{\n\"CRN\": \"crn:v1:bluemix:public:kms:us-south:a/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd617\"\n}\n],\n\"region\": [\n{\n\"name\":\"us-east\"\n}\n]\n},\n\"name\": \"my-hourly-plan-2\"\n}'", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan&interface=cli"}, {"document_id": "ibmcld_15161-28756-29853", "score": 39.215748, "text": "\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.\n\ncurl -X POST \"$vpc_api_endpoint/v1/backup_policies/8758bd18-344b-486a-b606-5b8cb8cdd044/plans?version=2023-05-09&generation=2\"\n-H \"Authorization: $iam_token\"\n-d '{\n\"active\": true,\n\"attach_user_tags\": [\n\"hourly-backups\"\n],\n\"copy_user_tags\": true,\n\"cron_spec\": \"0 /2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 20,\n\"delete_over_count\": 20\n},\n\"remote_region_policies\": {\n\"delete_over_count\": 5,\n\"encryption_key\": [\n{\n\"CRN\": \"crn:v1:bluemix:public:kms:us-south:a/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd617\"\n}\n],\n\"region\": [\n{\n\"name\":\"us-east\"\n}\n]\n},\n\"name\": \"my-hourly-plan-2\"\n}'\nShow more", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan&interface=api"}, {"document_id": "ibmcld_15911-11812-13034", "score": 36.977524, "text": "\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you need to specify the customer-managed key that you want to use to encrypt the new copy.\n\nThe following example creates a snapshot in the target region (us-south) by using the CRN of a snapshot from the source region (us-east).\n\nibmcloud is snapshot-create --name my-cli-snapshot-crc --source-snapshot-crn crn:v1:staging:public:is:us-south:a/2d1bace7b46e4815a81e52c6ffeba5cf::snapshot:r134-b9590a48-63a3-445e-b819-3f2c0b82daf8\n\nCreating snapshot my-cli-snapshot-crc under account Test Account as user test.user@ibm.com...\n\nID r142-bd4532c0-e73c-44f9-a017-89e5368c521a\nName my-cli-snapshot-crc\nCRN crn:v1:staging:public:is:us-east:a/2d1bace7b46e4815a81e52c6ffeba5cf::snapshot:r142-bd4532c0-e73c-44f9-a017-89e5368c521a\nStatus pending\nClones Zone Available Created\n\nSource volume ID Name Remote Region\nr134-be21061a-4dc6-4c9f-b17d-421838fde399 -remote-421838fde399 us-south\n\nSnapshot Copies ID Name Remote Region CRN Resource type\n\nBootable true\nEncryption provider_managed\nEncryption key -\nSource Snapshot ID Name Remote Region CRN Resource type", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-create&interface=api"}, {"document_id": "ibmcld_15912-11812-13034", "score": 36.977524, "text": "\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you need to specify the customer-managed key that you want to use to encrypt the new copy.\n\nThe following example creates a snapshot in the target region (us-south) by using the CRN of a snapshot from the source region (us-east).\n\nibmcloud is snapshot-create --name my-cli-snapshot-crc --source-snapshot-crn crn:v1:staging:public:is:us-south:a/2d1bace7b46e4815a81e52c6ffeba5cf::snapshot:r134-b9590a48-63a3-445e-b819-3f2c0b82daf8\n\nCreating snapshot my-cli-snapshot-crc under account Test Account as user test.user@ibm.com...\n\nID r142-bd4532c0-e73c-44f9-a017-89e5368c521a\nName my-cli-snapshot-crc\nCRN crn:v1:staging:public:is:us-east:a/2d1bace7b46e4815a81e52c6ffeba5cf::snapshot:r142-bd4532c0-e73c-44f9-a017-89e5368c521a\nStatus pending\nClones Zone Available Created\n\nSource volume ID Name Remote Region\nr134-be21061a-4dc6-4c9f-b17d-421838fde399 -remote-421838fde399 us-south\n\nSnapshot Copies ID Name Remote Region CRN Resource type\n\nBootable true\nEncryption provider_managed\nEncryption key -\nSource Snapshot ID Name Remote Region CRN Resource type", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-create&interface=cli"}, {"document_id": "ibmcld_15914-11812-13034", "score": 36.977524, "text": "\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you need to specify the customer-managed key that you want to use to encrypt the new copy.\n\nThe following example creates a snapshot in the target region (us-south) by using the CRN of a snapshot from the source region (us-east).\n\nibmcloud is snapshot-create --name my-cli-snapshot-crc --source-snapshot-crn crn:v1:staging:public:is:us-south:a/2d1bace7b46e4815a81e52c6ffeba5cf::snapshot:r134-b9590a48-63a3-445e-b819-3f2c0b82daf8\n\nCreating snapshot my-cli-snapshot-crc under account Test Account as user test.user@ibm.com...\n\nID r142-bd4532c0-e73c-44f9-a017-89e5368c521a\nName my-cli-snapshot-crc\nCRN crn:v1:staging:public:is:us-east:a/2d1bace7b46e4815a81e52c6ffeba5cf::snapshot:r142-bd4532c0-e73c-44f9-a017-89e5368c521a\nStatus pending\nClones Zone Available Created\n\nSource volume ID Name Remote Region\nr134-be21061a-4dc6-4c9f-b17d-421838fde399 -remote-421838fde399 us-south\n\nSnapshot Copies ID Name Remote Region CRN Resource type\n\nBootable true\nEncryption provider_managed\nEncryption key -\nSource Snapshot ID Name Remote Region CRN Resource type", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-create&interface=ui"}, {"document_id": "ibmcld_15164-27999-29143", "score": 32.468884, "text": "\n\"href\": \"https://us-south.iaas.cloud.ibm.com/v1/regions/us-south/zones/us-south-2\"\n}\n]\n},\n\"copy_user_tags\": false,\n\"created_at\": \"2022-12-09T15:16:37Z\",\n\"cron_spec\": \"0 /2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 5\n},\n\"href\": \"https://us-south.iaas.cloud.ibm.com/v1/backup_policies/8758bd18-344b-486a-b606-5b8cb8cdd044/plans/6e251cfe-6f7b-4638-a6ba-00e9c327b178\",\n\"id\": \"6e251cfe-6f7b-4638-a6ba-00e9c327b178\",\n\"lifecycle_state\": \"stable\",\n\"name\": \"my-hourly-plan-1\",\n\"resource_type\": \"backup_policy_plan\"\n}\n\n\n\n\n\n Creating a backup plan with cross-regional copy option with the API \n\nNew\n\nWhen you create a backup plan, you can choose to create a copy of the backup snapshot in a different region.\n\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan&interface=ui"}, {"document_id": "ibmcld_15162-28024-29168", "score": 32.468884, "text": "\n\"href\": \"https://us-south.iaas.cloud.ibm.com/v1/regions/us-south/zones/us-south-2\"\n}\n]\n},\n\"copy_user_tags\": false,\n\"created_at\": \"2022-12-09T15:16:37Z\",\n\"cron_spec\": \"0 /2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 5\n},\n\"href\": \"https://us-south.iaas.cloud.ibm.com/v1/backup_policies/8758bd18-344b-486a-b606-5b8cb8cdd044/plans/6e251cfe-6f7b-4638-a6ba-00e9c327b178\",\n\"id\": \"6e251cfe-6f7b-4638-a6ba-00e9c327b178\",\n\"lifecycle_state\": \"stable\",\n\"name\": \"my-hourly-plan-1\",\n\"resource_type\": \"backup_policy_plan\"\n}\n\n\n\n\n\n Creating a backup plan with cross-regional copy option with the API \n\nNew\n\nWhen you create a backup plan, you can choose to create a copy of the backup snapshot in a different region.\n\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan&interface=cli"}]}
{"task_id": "4175fcce99c56af0e02be5b8990fc16a<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_14682-1497-3767", "score": 21.709253, "text": "\n[IBM Cloud for VMware Solutions and Red Hat OpenShift](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/openshift-sddc.svg)\n\nFigure 1. IBM Cloud for VMware Solutions and OpenShift\n\n\n\n Application modernization on IBM Cloud \n\nApplication modernization is a term that describes the process of transitioning existing applications to use new approaches on the cloud. Customers today are seeking innovative, efficient approaches that help them make this transition based on business and application complexity.\n\nBusiness pressures demand faster time to market. Your existing estate includes not only applications, but data, processes, business logic, and user interfaces, all of which need to adapt to keep up with new business demands.\n\nApplication modernization has the following benefits:\n\n\n\n* Improved developer productivity\n* Increased operational efficiency\n* Reduced cost to build new capabilities\n* Expanded capacity delivered in a short time\n\n\n\nIBM understands that 70% of private cloud adoption is driven by the need to modernize application environments. However, most organizations are approaching application modernization in a staged approach, which requires a hybrid and multi cloud landscape, where:\n\n\n\n* Complex and monolithic legacy applications that typically run on mainframes or UNIX systems remain on-premises.\n* x86 environments used for Systems of Record (SoR), applications that are security sensitive, and regulated workloads are placed on a virtualized infrastructure or a private cloud.\n* Applications such as SAP\u00ae or high-performance computing use bare metal resources.\n* Security sensitive and some regulated workloads, which can move to the public cloud are moving to dedicated environments.\n* Systems of engagement (SoE) such as web, mobile, IoT, AI, or Video are moving to public clouds.\n\n\n\nFor example, a common pattern is to have front-end SOE applications that are deployed as containers with databases and legacy middleware that are deployed on VMs on a private cloud.\n\nBecause your IT infrastructure and business needs are unique, you need an approach to modernization that helps accelerate business value delivery, reduces your risks, and preserves your existing investments.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro"}, {"document_id": "ibmcld_11149-1736-3999", "score": 19.701704, "text": "\nWith IBM Cloud Satellite, you can create a hybrid environment that brings the scalability and on-demand flexibility of public cloud services to the applications and data that runs in your secure private cloud.\n* Support for [multicloud](https://www.ibm.com/cloud/learn/multicloud) and hybrid multicloud solutions is also available, which makes it easy for you to work with different vendors. [IBM Cloud Paks](https://www.ibm.com/cloud/paks) are software products for hybrid clouds that enable you to develop apps once and deploy them anywhere.\n* [Virtual Private Cloud (VPC)](https://cloud.ibm.com/docs/vpc?topic=vpc-getting-started) is available as a public cloud service that lets you establish your own private cloud-like computing environment on shared public cloud infrastructure. With VPC, enterprises can define and control a virtual network that is logically isolated from all other public cloud tenants, creating a private, secure place on the public cloud.\n\n\n\nWith our open source technologies, such as Kubernetes, Red Hat OpenShift, and a full range of compute options, including virtual machines, containers, bare metal, and serverless, you have the control and flexibility that's required to support workloads in your hybrid environment. You can deploy cloud-native apps while also ensuring workload portability.\n\nWhether you need to migrate apps to the cloud, modernize your existing apps by using cloud services, ensure data resiliency against regional failure, or use new paradigms and deployment topologies to innovate and build your cloud-native apps, the platform's open architecture is built to accommodate your use case.\n\n\n\n What's built into the platform? \n\nAs the following diagram illustrates, the IBM Cloud platform is composed of multiple components that work together to provide a consistent and dependable cloud experience.\n\n\n\n* A robust console that serves as the front end for creating, viewing, managing your cloud resources\n* An identity and access management component that securely authenticates users for both platform services and controls access to resources consistently across IBM Cloud\n* A catalog that consists of hundreds of supported products\n* A search and tagging mechanism for filtering and identifying your resources", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-whatis-platform"}, {"document_id": "ibmcld_05723-7-2376", "score": 19.635845, "text": "\nGovernment use cases for IBM Cloud \n\nThese use cases highlight how workloads on IBM Cloud\u00ae Kubernetes Service benefit from the public cloud. These workloads are isolated in global regions for data sovereignty, use Watson machine learning instead of net-new code, and connect to on-premises databases.\n\n\n\n Regional government improves collaboration and velocity with community Developers who combine public-private data \n\nAn Open-Government Data Program Executive needs to share public data with the community and private sector, but the data is locked in an on-premises monolithic system.\n\nWith IBM Cloud Kubernetes Service, the Exec delivers the value of combined public-private data. Likewise, the service provides the public cloud platform to refactor and expose microservices from monolithic on-premises apps. Also, the public cloud allows government and the public partnerships to use external cloud services and collaboration-friendly open-source tools.\n\n\n\n Context \n\n\n\n* An \u201copen government\u201d model is the future, but this regional government agency can't make the leap with their on-premises systems.\n* They want to support innovation and foster co-development between private sector, citizens, and public agencies.\n* Disparate groups of Developers from the government and private organizations don\u2019t have a unified open-source platform where they can share APIs and data easily.\n* Government data is locked in on-premises systems with no easy public access.\n\n\n\n\n\n\n\n Solution \n\nAn open-government transformation must be built on a foundation that provides performance, resilience, business continuity, and security. As innovation and co-development move ahead, agencies and citizens depend on software, services, and infrastructure companies to \u201cprotect and serve.\u201d\n\nTo bust bureaucracy and transform government\u2019s relationship with its constituency, they turned to open standards to build a platform for co-creation.\n\n\n\n* OPEN DATA \u2013 data storage where citizens, government agencies, and businesses access, share, and enhance data freely\n* OPEN APIs \u2013 a development platform where APIs are contributed by and reused with all community partners\n* OPEN INNOVATION \u2013 a set of cloud services that allow developers to use plug-in innovation instead of manually coding it\n\n\n\nTo start, the government uses IBM Cloud Object Storage to store its public data in the cloud.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_uc_gov"}, {"document_id": "ibmcld_04734-4788-6538", "score": 19.528963, "text": "\n[External link icon](https://cloud.ibm.com/docs-content/v1/content/8aa0853d34cf2349f1d2db8e5c61e6422a580169/icons/launch-glyph.svg)](https://www.ibm.com/blogs/cloud-computing/2016/08/10/practical-guide-paas/).\n\nWith the SaaS model, your provider maintains the systems through the actual application. The application is cloud-aware, and users can use different end points, depending on the software provider, to use the software. The cloud provider is responsible for all infrastructure and application management, which includes software updates, hardware repairs, and network settings. This model is often used in pay-as-you-go software licensing models. For more information, see [SaaS applications for business and IT](https://www.ibm.com/cloud/saas)![External link icon](https://cloud.ibm.com/docs-content/v1/content/8aa0853d34cf2349f1d2db8e5c61e6422a580169/icons/launch-glyph.svg).\n\n\n\n\n\n Cloud types \n\nThere are three different types of clouds available: public, private, and hybrid. A public cloud includes a shared set of resources that are provisioned to allow access to a company's resources. It is hosted in a multi-tenant environment on a virtual server, and it can be accessed from anywhere.\n\nA private cloud includes resources that are provisioned to allow access to a company's resources. It is hosted on dedicated hardware, such as a bare metal server, and either onsite at the company's office (or across offices) or by a cloud provider. A private cloud can be accessed from anywhere.\n\nA hybrid cloud includes resources that combine the aspects of both public and private clouds. It is hosted both onsite at a company's office (or across offices) and by a cloud provider. A hybrid cloud can be accessed from anywhere.\n\n\n\n\n\n Next steps", "title": "", "source": "https://cloud.ibm.com/docs/cloud-infrastructure?topic=cloud-infrastructure-getting-started-tutorial"}, {"document_id": "ibmcld_04734-6091-6676", "score": 19.293903, "text": "\nIt is hosted on dedicated hardware, such as a bare metal server, and either onsite at the company's office (or across offices) or by a cloud provider. A private cloud can be accessed from anywhere.\n\nA hybrid cloud includes resources that combine the aspects of both public and private clouds. It is hosted both onsite at a company's office (or across offices) and by a cloud provider. A hybrid cloud can be accessed from anywhere.\n\n\n\n\n\n Next steps \n\nTo continue, see [Planning your infrastructure](https://cloud.ibm.com/docs/cloud-infrastructure?topic=cloud-infrastructure-planning-2).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-infrastructure?topic=cloud-infrastructure-getting-started-tutorial"}, {"document_id": "ibmcld_06926-1815-3739", "score": 19.212011, "text": "\nUsing VRF, IBM Cloud tenants are allowed to use remote IP addresses that normally would not be allowed to overlap in the Global table. IBM still reserves the following RFC 1918, link-local addresses, and multicast addresses, which are not routable from this VRF service:\n\n\n\n* 10.0.0.0/14\n* 10.200.0.0/14\n* 10.198.0.0/15\n* 169.254.0.0/16\n* 224.0.0.0/4\n* 166.9.0.0/16 (used by the private endpoint service)\n* Any IP ranges assigned to your VLANs on the IBM platform.\n\n\n\nIBM is moving forward with a next-generation Cloud deployment to enable Virtual Private Cloud (VPC) in our availability zones (AZs). This new VPC capability enables Bring-Your-Own-IP (BYoIP) in the VPC-enabled AZs, which are located in Dallas, Washington DC, London, Frankfurt, Tokyo, and Sydney.\n\nFor example, each tenant on the backbone who uses VRF can have only one customer VRF per Direct Link, which provides connectivity among all the tenant\u2019s servers, regardless of location. However, an IBM Cloud tenant might have more than one Direct Link account that feeds into a single cross-connect router.\n\n\n\n* A tenant\u2019s servers in any VLAN, in any pod, in any data center worldwide can reach all of that tenant\u2019s other servers globally.\n* Every tenant\u2019s customer VRF is connected to the common shared services network to provide private reachability for those servers to use DNS, shared storage, monitoring, patching, and more.\n* The customer VRF is a connectivity service that provides isolation among tenants. Any additional controls that are needed within a tenancy must be provisioned separately by using a gateway, security groups, or host-based controls.\n\n\n\n\n\n\n\n Benefits of moving to VRF \n\nMoving to VRF includes the following primary benefits:\n\n\n\n* Industry-proven and widely accepted multiple isolation separation technologies. Many cloud customers find the Level-3 VPN approach more palatable than ACLs to their auditors and compliance officers.", "title": "", "source": "https://cloud.ibm.com/docs/direct-link?topic=direct-link-overview-of-virtual-routing-and-forwarding-vrf-on-ibm-cloud"}, {"document_id": "ibmcld_14762-7-2008", "score": 19.198118, "text": "\nVirtual Private Cloud overview \n\nThe IBM Cloud\u00ae Virtual Private Cloud is a virtual network that is linked to your customer account. It gives you cloud security, with the ability to scale dynamically, by providing fine-grained control over your virtual infrastructure and your network traffic segmentation.\n\nEach VPC is deployed to a single region. Within that region, the VPC can span multiple zones.\n\nIBM Cloud virtual or IBM Cloud bare metal server presented in your VPC is attached to subnets. Subnets within the VPC offer private connectivity, thus your servers can communicate within and between the subnets by using an implicit router. Subnets in your VPC can connect to the public internet through an optional public gateway, or you can assign floating IP addresses to any network interface of the servers.\n\nThe following diagram shows an overview of IBM Cloud VPC.\n\nZoom\n\n![IBM VPC connectivity and security](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/vpc-ryo-diagrams-overview-virtual.svg)\n\nFigure 1. IBM Cloud VPC connectivity and security\n\nReview the following concepts to understand how IBM Cloud VPC is constructed. The terminology is used throughout this architecture solution.\n\nA region is an abstraction that is related to the geographic area in which a VPC is deployed. Each region contains multiple zones, which represent independent fault domains. A VPC can span multiple zones within its assigned region. A region is also often referred to a multizone region or MZR.\n\nA zone is an abstraction that refers to the physical data center, which hosts the compute, network, storage resources, and the related cooling and power, which provides services and applications. Zones are isolated from each other, so to create no shared single point of failure, improved fault tolerance, and reduced latency. Each zone is assigned a default address prefix, which specifies the range of addresses in which subnets can be created.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vpc-ryo-vpc"}, {"document_id": "ibmcld_14916-7-2291", "score": 19.11716, "text": "\nOverview \n\nUse IBM Cloud\u00ae Virtual Private Cloud to create your own space in IBM Cloud\u00ae. A virtual private cloud (VPC) is a secure, isolated virtual network that combines the security of a private cloud with the availability and scalability of IBM's public cloud.\n\n\n\n Logical isolation \n\nVPC gives your applications logical isolation from other networks, while providing scalability and security. To make this logical isolation possible, the VPC is divided into subnets that use a range of private IP addresses. You can create subnets in suggested prefix ranges, or bring your own public IP address range (BYOIP) to your IBM Cloud account. By default, all resources within the same VPC can communicate with each other over the private network, regardless of their subnet.\n\n\n\n\n\n Quick instance provisioning with high network performance \n\nYou can quickly provision scalable compute resources in your VPC by creating virtual server instances with the core and RAM configuration that's best for your workload. You can select from the supported stock images or custom images that were imported from IBM Cloud Object Storage. All images are cloud-init enabled. You can connect to your instance without using a password by adding SSH keys.\n\nYou can create instances with up to 80 Gbps network bandwidth per instance. Each instance can be multi-homed, that is, you can create multiple network interfaces per instance.\n\n\n\n\n\n Multi-architecture images \n\nYou can choose to create virtual server instances with different operating systems on x86_64 or s390x processor architecture. For more information, see [Images](https://cloud.ibm.com/docs/vpc?topic=vpc-about-images).\n\n\n\n\n\n Storage capabilities \n\nWhen you create an instance, a 100 GB block storage volume is automatically attached as a primary boot volume. To add secondary data volumes to your instance, create block storage volumes.\n\n\n\n\n\n External connectivity \n\nSeveral options are available for enabling your instances to communicate with the public internet:\n\n\n\n* To enable all instances in a subnet to send outgoing traffic, attach a public gateway to the subnet.\n* To enable communication to and from a particular instance, independent of whether the subnet is attached to a public gateway, associate the instance with a floating IP.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-about-vpc"}, {"document_id": "ibmcld_10166-7-2382", "score": 19.113655, "text": "\nGovernment use cases for IBM Cloud \n\nThese use cases highlight how workloads on Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae benefit from the public cloud. These workloads are isolated in global regions for data sovereignty, use Watson machine learning instead of net-new code, and connect to on-premises databases.\n\n\n\n Regional government improves collaboration and velocity with community Developers who combine public-private data \n\nAn Open-Government Data Program Executive needs to share public data with the community and private sector, but the data is locked in an on-premises monolithic system.\n\nWith Red Hat OpenShift on IBM Cloud, the Exec delivers the value of combined public-private data. Likewise, the service provides the public cloud platform to refactor and expose microservices from monolithic on-premises apps. Also, the public cloud allows government and the public partnerships to use external cloud services and collaboration-friendly open-source tools.\n\n\n\n Context \n\n\n\n* An \u201copen government\u201d model is the future, but this regional government agency can't make the leap with their on-premises systems.\n* They want to support innovation and foster co-development between private sector, citizens, and public agencies.\n* Disparate groups of Developers from the government and private organizations don\u2019t have a unified open-source platform where they can share APIs and data easily.\n* Government data is locked in on-premises systems with no easy public access.\n\n\n\n\n\n\n\n Solution \n\nAn open-government transformation must be built on a foundation that provides performance, resilience, business continuity, and security. As innovation and co-development move ahead, agencies and citizens depend on software, services, and infrastructure companies to \u201cprotect and serve.\u201d\n\nTo bust bureaucracy and transform government\u2019s relationship with its constituency, they turned to open standards to build a platform for co-creation.\n\n\n\n* OPEN DATA \u2013 data storage where citizens, government agencies, and businesses access, share, and enhance data freely\n* OPEN APIs \u2013 a development platform where APIs are contributed by and reused with all community partners\n* OPEN INNOVATION \u2013 a set of cloud services that allow developers to use plug-in innovation instead of manually coding it\n\n\n\nTo start, the government uses IBM Cloud Object Storage to store its public data in the cloud.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_gov"}, {"document_id": "ibmcld_09271-7-1763", "score": 18.796566, "text": "\nHosting web applications from a secure private network \n\nThis tutorial describes the use of Classic Infrastructure. Most workloads can be implemented using [IBM Cloud\u00ae Virtual Private Cloud](https://cloud.ibm.com/docs/vpc) resources. Use IBM Cloud VPC to create your own private cloud-like computing environment on shared public cloud infrastructure. A VPC gives an enterprise the ability to define and control a virtual network that is logically isolated from all other public cloud tenants, creating a private, secure place on the public cloud. Specifically, [vpc network load balancer](https://cloud.ibm.com/docs/vpc?topic=vpc-nlb-vs-elb), [virtual server instances](https://cloud.ibm.com/docs/vpc?topic=vpc-vsi_best_practices), [security groups](https://cloud.ibm.com/docs/vpc?topic=vpc-using-security-groups), [network ACLs](https://cloud.ibm.com/docs/vpc?topic=vpc-using-acls) and [public gateways](https://cloud.ibm.com/docs/vpc?topic=vpc-about-networking-for-vpcexternal-connectivity).\n\nThis tutorial may incur costs. Use the [Cost Estimator](https://cloud.ibm.com/estimator/review) to generate a cost estimate based on your projected usage.\n\nHosting web applications is a common deployment pattern for public cloud, where resources can be scaled on demand to meet short term and long term usage demands. Security for the application workloads is a fundamental prerequisite, to complement the resilience and scalability afforded by public cloud.\n\nThis tutorial takes you through the creation of a scalable and secure Internet facing web application hosted in private network secured using a virtual router appliance (VRA), VLANs, NAT and firewalls. The application comprises a load balancer, two web application servers and a MySQL database server.", "title": "", "source": "https://cloud.ibm.com/docs/loadbalancer-service?topic=loadbalancer-service-web-app-private-network"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02597-4595-6892", "score": 18.23969, "text": "\nThrough the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.\n\nAs well as controlling which APIs a customer can use, different Plans can be used to implement rate limits. A rate limit can be implemented as a default rate across an entire Plan, or for specific operations of an API within that Plan, exempting them from the Plan rate limit. Different Plans can have differing rate limits, both between operations and for the overall limit. Applying rate limits to Plans makes it easy to offer different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute while a \"Full Plan\" might permit up to 1000 calls per minute.\n\nFinally, different Plans can be used to assign a billing cost. A Plan can be set as a free Plan, or as a Plan with billing. Plans with billing can be used with rate limits to set different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute for a cost of $5 per month, while a \"Full Plan\" might permit up to 1000 calls per minute for a cost of $20 per month.\n\nNote: Applying a rate limit at the Plan level, creates a default rate limit that applies to each operation within the Plan. If you need to set specific rate limits for specific operations, you must set them within the operations themselves and this setting overrides the setting at the Plan level.\n\nIBM API Connect also supports the implementation of multiple versions of Products. You can choose version numbers and use them to aid the development of your Products and Plans.\n\nNote: The version for a Product is distinct from the version of any APIs that are contained in the associated Plans. Plans cannot themselves have their own version, they use the version of their parent Product.", "title": "", "source": "https://cloud.ibm.com/docs/apiconnect?topic=apiconnect-about_apic_overview"}, {"document_id": "ibmcld_03776-3313-5682", "score": 15.976576, "text": "\nWhen you have a Subscription account, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For example, you might buy a subscription for $12,000 USD a year that comes with a 10% discount. No matter when you incur usage costs within that year, you get fixed billing for the subscription amount, such as $1,000 a month. This account type is a good fit for enterprise organizations with large cloud workloads that want the predictability of fixed billing for their financial planning.\n\nIn addition to the two billable account types, customers that have a Subscription account can sign up for the Enterprise Savings Plan billing model. This billing model is similar to a Subscription account with a few added benefits. The following table details the two billable account types and billing model.\n\n\n\nTable 1. Comparative analysis of account types\n\n Pay-As-You-Go Subscription Enterprise Savings Plan \n\n Monthly billing Timely billing Timely billing \n Invoiced on monthly consumption Invoices independent of usage Invoiced on monthly consumption \n Best suited for developers and companies Best suited for enterprise organizations Best suited for both developers and enterprise organizations \n\n\n\n\n\n Estimating your costs \n\nAfter you select the type of account that fits your organization's needs, it's time to understand how you will be charged for it. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization consumes. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage for the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations.\n\nThe following are the various charging types:\n\n\n\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-overview"}, {"document_id": "ibmcld_04118-531-2235", "score": 15.200384, "text": "\nThe following table compares each offering to help you choose the one that's right for you. Enterprise Tier plans are available with different pricing models.\n\n\n\nTable 1. CIS plan comparison\n\n Standard Next Enterprise Essentials Enterprise Advanced Enterprise Premier Enterprise Usage \n\n Domain 1 1 2 2 Up to 1000, but recommend no more than 20 \n DNS 250 records 3500 records 3500 records 3500 records 3500 records \n Global load balancers <br><br> * 3 pools<br> * 3 origin servers<br> * 5 Health checks<br> * 60s health checks<br> * Geo Routing<br> * Health checks from single region<br> * 60s minimum TTL for non-proxied global load balancers<br><br><br> <br><br> * 20 pools <br> (additional pools available for charge)<br> * 20 origin servers<br> * 100 health checks<br> * 5s health checks<br> * Smart Routing<br> * Health checks from multiple regions<br> * 10s minimum TTL for non-proxied global load balancers<br><br><br> <br><br> * 20 pools <br> (additional pools available for charge)<br> * 20 origin servers<br> * 100 health checks<br> * 5s health checks<br> * Smart Routing<br> * Health checks from multiple regions<br> * 10s minimum TTL for non-proxied global load balancers<br><br><br> <br><br> * 20 pools <br> (additional pools available for charge)<br> * 20 origin servers<br> * 100 health checks<br> * 5s health checks<br> * Smart Routing<br> * Health checks from multiple regions<br> * 10s minimum TTL for non-proxied global load balancers<br><br><br> <br><br> * Up to 100 pools<br> * 100 origin servers<br> * Up to 100 health checks<br> * 5s health checks<br> * Smart Routing<br> * Health checks from multiple regions<br> * 10s minimum TTL for non-proxied global load balancers<br><br><br>", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-cis-plan-comparison"}, {"document_id": "ibmcld_02612-4813-6728", "score": 15.164435, "text": "\nIf you select Custom, use the Type to add field to search for the developer organizations or communities that you want to be able to subscribe to the Plans in the Product.\n9. In the APIs section, specify the APIs that you want to include in the Product.\n\n\n\n1. Click the Add API icon.\n2. Select the APIs that you want to include, then click Apply. The selected APIs are listed.\n\n\n\n10. To make an API available to application developers, you must include it in a Plan. To add one or more Plans to the Product, click the Add Plan icon.\n\n\n\n1. Expand the new Plan that has been created. If you have already added APIs to your Product, these are automatically included.\n2. Rename your Plan in the Title and Name fields, and optionally add a description. Note: A Default Plan is automatically created for you, and you can include your API in this Plan if you do not want to create your own. However, if you decide not to use the Default Plan you must delete it, as a Product cannot be staged if it includes any Plans that do not include APIs.\n\n\n\n11. Verify that the APIs you require are included in the Plan.\n\n\n\n1. Expand the Plan to which you want to add an API.\n2. Under APIs included, ensure that the check boxes of the APIs you require are selected. If there are APIs already selected, and you do not want them included in the Plan you are editing, clear their check boxes.\n\n\n\n12. Optional: Add the billing information for your Plan. To add billing information, you must establish an account with a credit card processing service so your customers can pay with a credit card. Monthly billing Plans are billed on the same date of each month.\n13. Optional: If you want to tailor which operations from an API are included in the Plan, hover the cursor over the API that contains the operation. Click the Show operations icon, and then select or clear the check boxes for the operations you want to include or exclude.\n14.", "title": "", "source": "https://cloud.ibm.com/docs/apiconnect?topic=apiconnect-managing_products"}, {"document_id": "ibmcld_02597-3131-5174", "score": 15.054559, "text": "\nPlans can share APIs, but whether subscription approval is required depends upon the Plan itself. Additionally, you can enforce rate limits through Plans or through operations within a Plan's APIs that override the Plan's rate limit.\n\nPlans can also specify billing costs for customers who use your Products. For example, you can define three different Plans for a single Product. Each Plan can have a different subscription cost and a different rate limit that targets different customers.\n\n\n\n\n\n Products \n\nPlans and APIs are grouped in Products. Through Products, you can manage the availability and visibility of APIs and Plans. Use the API Designer to create, edit, and stage your Product. Use the API Manager to manage the lifecycle of your Product.\n\nThe following diagram demonstrates how Products, Plans, and APIs relate to one another. Note how Plans belong to only one Product, can possess different APIs to other Plans within the same Product, and can share APIs with Plans from any Product. Figure to show the hierarchy of Products, Plans, and APIs. ![Figure to show the hierarchy of Products, Plans, and APIs.](https://cloud.ibm.com/docs-content/v1/content/78bb71851d95d7580503eb9ba10cf3ae31490ade/apiconnect/images/plan_product_hierarchy.png)\n\nYou can create Plans only within Products, and these Products are then published in a Catalog. A lifecycle manager can then control the availability and visibility of APIs and Plans through the API Manager. Through the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.", "title": "", "source": "https://cloud.ibm.com/docs/apiconnect?topic=apiconnect-about_apic_overview"}, {"document_id": "ibmcld_03734-7-2243", "score": 14.652928, "text": "\nEnterprise Savings Plan billing model \n\nThe IBM Cloud\u00ae Enterprise Savings Plan billing model is similar to the billing model for Subscription accounts but with a few added benefits. With this billing model, you commit to spend a certain amount on IBM Cloud and receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount.\n\nThe Commitments and subscriptions page in the console offers a view of any active or upcoming commitments. If you have an active subscription, or had subscriptions in the past, those details are also displayed on this page.\n\n\n\n Before you begin \n\nIf you haven\u2019t created an account, you can register for IBM Cloud by completing the following steps:\n\n\n\n1. Consult with an [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) representative. IBM Cloud Sales will direct you to the [registration page](https://cloud.ibm.com/registration/sales).\n2. Enter the required information. After registration is complete, provide your name, email, and the account ID to the sales representative you are working with.\n3. Your account is activated upon order processing. After the account is activated, you can start leveraging the benefits of our Enterprise Savings Plan billing model.\n\n\n\n\n\n\n\n Signing up for a commitment \n\nTo use the IBM Cloud Enterprise Savings Plan billing model, you must have a Subscription account. After you have the correct account, work with [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) to sign up for this billing model. The sales team creates a commitment quote based on the spending amount for a certain period of time that you want to commit to.\n\nAfter you accept the commitment quote, you receive an additional email to confirm that your payment information is processed and that the commitment is added to your account.\n\n\n\n\n\n Viewing your commitment quote \n\nAfter you contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) and sign up for a commitment, you receive a quote. The commitment quote details your contract period, duration of the commitment, billing frequency, UOM, discount, and commitment terms. The sales team will email you a copy of your quote.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-committed-use"}, {"document_id": "ibmcld_08069-7-2230", "score": 14.4996395, "text": "\nBasic, Advanced, and Premium Support plans \n\nYou can choose a Basic, Advanced, or Premium support plan to customize your IBM Cloud\u00ae support experience for your business needs. The level of support that you select determines the severity that you can assign to support cases and your level of access to the tools available in the Support Center.\n\nIf you have free support, you're provided technical support through [Stack Overflow](https://stackoverflow.com/questions/tagged/ibm-cloud?tab=Newest). Also, with a Lite account and free support, you can open cases that are related to access management, accounts, and billing and usage. If you want to upgrade your support plan, contact a [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) representative.\n\nInitial response Service Level Objectives (SLO) do not apply to any billing, invoice, or sales related inquiry or cases.\n\nThe following table shows the support types available for Pay-As-You-Go accounts, Subscription accounts, and the Enterprise Savings Plan billing model. For more information about accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accounts).\n\n\n\nTable 1. Support plans\n\n Basic Support Advanced Support Premium Support \n\n Description Basic business protection that is included with your IBM Cloud Pay-As-You-Go or Subscription account Prioritized case handling and support experience that is aligned with your business needs for your Pay-As-You-Go account, Subscription account, or Enterprise Savings Plan billing model Client engagement that is aligned with your business outcomes to accelerate time-to-value for your Pay-As-You-Go account, Subscription account, or Enterprise Savings Plan billing model \n Availability 24 x 7 access to the IBM Cloud technical support team through cases <br>Phone and chat are available only for Pay-As-You-Go and Subscription accounts 24 x 7 access to the IBM Cloud technical support team through cases, phone, and chat 24 x 7 access to the IBM Cloud technical support team through cases, phone, and chat \n [Case severity](https://cloud.ibm.com/docs/get-support?topic=get-support-support-case-severity) Not applicable Case severity ranking available Case severity ranking available", "title": "", "source": "https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans"}, {"document_id": "ibmcld_03749-1776-3774", "score": 14.452947, "text": "\n(https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/billing-usage/images/enterprise-billing-usage.svg)\n\nFigure 1.Enterprise billing and usage management\n\n\n\n\n\n Billing options \n\nEnterprises require subscription billing or an account with the [Enterprise Savings Plan billing model](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-committed-use). In subscription billing, you purchase a subscription for an amount of credit to spend during the subscription term, and usage is deducted from the subscription credit at a discounted rate. The Enterprise Savings Plan billing model is similar to subscription billing. You commit to spend a certain amount on IBM Cloud and receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount.\n\nThe account that you use to create the enterprise must be a [Subscription account](https://cloud.ibm.com/docs/account?topic=account-accountssubscription-account) or an account with the [Enterprise Savings Plan billing model](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-committed-use). After the enterprise is created, you can add more accounts to the enterprise. If you add a Lite or trial account, the account is automatically upgraded to a Pay-As-You-Go account.\n\nSome Pay-As-You-Go accounts can't be directly imported into an enterprise, such as many Pay-As-You-Go accounts that are billed in United States dollars (USD). However, you can still import these accounts into your enterprise by converting them to Subscription accounts and then importing them. To convert an account, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule).\n\nEach enterprise supports only a single billing currency. All accounts must use the enterprise billing currency before you add them to the enterprise. Existing accounts that are imported into the enterprise no longer separately manage their billing.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-enterprise&interface=ui"}, {"document_id": "ibmcld_10906-20682-22396", "score": 14.325077, "text": "\nLearn more about [Enterprise Savings Plan](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-committed-use) and [Managing subscriptions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions). \n <br><br> * View invoices and build your own reports<br><br><br> To manage and view your invoices, visit the [Invoices](https://cloud.ibm.com/billing/invoices) page from the billing and usage dashboard in the IBM Cloud console. See [Viewing your invoices](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoices). You can also build your own reports by using the API and SDK that are available.<br><br><br><br> * [Usage Reports API/SDK](https://cloud.ibm.com/apidocs/metering-reporting)<br> * [Enterprise Billing Units API/SDK](https://cloud.ibm.com/apidocs/enterprise-apis/billing-unit).<br> * [Enterprise Usage Reports API/SDK](https://cloud.ibm.com/apidocs/enterprise-apis/resource-usage-reports).<br><br><br> \n\n\n\n\n\n\n\n Connect your network to IBM Cloud \n\nAs the need for global reach and 24/7 operations of web applications increases, the need to host services in multiple cloud data centers increases too. Data centers across multiple locations provide resilience in the case of a geographic failure and bring workloads closer to globally distributed users, which reduces latency and increases perceived performance. The IBM Cloud network enables users to link workloads hosted in secure private networks across data centers and locations. Use the following checklist to review the available options and to connect your existing on-premises environments to IBM Cloud.\n\n\n\nTable 5. Getting started tasks for connecting your network to IBM Cloud\n\n Task Description", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-get-started-checklist"}, {"document_id": "ibmcld_01705-7074-9036", "score": 14.295795, "text": "\nAlso, with a Pay-As-You-Go account, you can order Advanced or Premium support plans to get extra help with your production workloads. Learn more in [Basic, Advanced, and Premium Support plans](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans).\n\nA subset of Pay-As-You-Go accounts are eligible for the new Enterprise Savings Plan billing model. For more information, see [Enterprise Savings Plan billing model](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-committed-use).\n\n\n\n\n\n Subscription account \n\nSubscription accounts offer many of the same benefits as Pay-As-You-Go accounts, including access to the full IBM Cloud catalog and the ability to create multiple resource groups. In addition, Subscription accounts provide discounts for platform services and support and more consistent billing through subscriptions. You can also [set up spending notifications](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-spending) to get notified when your account or a particular service reaches a specific spending threshold that you set.\n\nWhen you purchase a subscription, you commit to a minimum spending amount for a certain period of time and receive a discount on the overall cost. For example, if you commit to spend $1,000 a month for 6 months, you might get a 5% discount. For the duration of the subscription, you get $6,000 of usage but pay only $5,700 for it. The larger the subscription, the better the discount.\n\nLarge organizations and other users with large cloud workloads can benefit from the savings and predictable billing that are provided by subscriptions. IBM Cloud offers multiple types of subscriptions to fit your usage needs.\n\nA subset of subscription accounts are eligible for the new Enterprise Savings Plan billing model. For more information, see [Enterprise Savings Plan billing model](https://cloud.ibm.com/docs/account?topic=account-accountscommitment-model).\n\n\n\n Platform subscriptions", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accounts"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03735-1425-3233", "score": 20.852722, "text": "\nEnter your estimated usage, and click Calculate Cost. You can adjust the estimated usage and recalculate the cost to see how different usage levels affect the overall cost.\n\n\n\nBy default, the estimator shows the pricing and billing currency set for your account. Pricing can vary by region. If you're estimating costs for a different location or currency, you might have to select the appropriate currency on the order summary page for the product or change the currency on your account.\n\n\n\n1. Click Save and select the estimate that you'd like to add the product to, and then add the calculated cost to your estimate by clicking Save.\n2. When you're done adding products to your estimate, review the product details, and click View estimate.\n\n\n\n\n\n\n\n Updating an existing estimate \n\nYou can always update the name and description of an estimate as your needs change. To edit an estimate, complete the following steps:\n\n\n\n1. From the View Estimate page, identify the estimate that you want to edit.\n2. Click the Actions icon ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/action-menu-icon.svg) > Edit.\n3. Enter the updated name and description.\n4. Click Save\n\n\n\n\n\n\n\n Saving and sharing your estimate \n\nWhen you create an estimate, you can save each estimate's unique link to share or revisit directly through your browser. To share an estimate, complete the following steps:\n\n\n\n1. From the View Estimate page, identify the estimate that you want to share.\n2. Click the Actions icon ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/action-menu-icon.svg) > Share.\n3. Click Copy link and share the link with users in your account.\n\n\n\n\n\n\n\n Creating quotes for classic infrastructure services", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cost"}, {"document_id": "ibmcld_12539-0-2074", "score": 20.557598, "text": "\n\n\n\n\n\n\n  Estimating architecture costs in a project \n\nCost estimation is available for deployable architectures in the IBM Cloud catalog. Depending on the deployable architecture, a starting cost is estimated based on the available data. This estimate is meant to be a starting point to help you determine how much your account could be charged for deploying an architecture. This estimated amount is subject to change as the architecture is customized within a project, and it does not include all resources, usage, licenses, fees, discounts, or taxes.\n\n\n\n  Viewing the starting cost for your deployable architecture \n\nDepending on the deployable architecture that you select from the catalog, there is an estimated starting cost.\n\nTo view the estimated starting cost, complete the following steps:\n\n\n\n1.  Go to the catalog details page for the deployable architecture.\n2.  Next, click the Starting at amount for additional details about the cost summary.\n\n\n\nAfter you add the deployable architecture to your project, you can configure the input values. By doing so, you can tailor the architecture to match your needs. Adjusting the configuration input might adjust the estimated cost.\n\n\n\n1.  Go to the Projects page, and select a project.\n2.  Go to Configurations, and select a configuration of the deployable architecture.\n3.  Enter the input values to configure the deployable architecture, and click Save. For more information about configuring and deploying, see [Configuring and deploying a deployable architecture](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-config-project).\n4.  After saving, the validation checks are run and a new cost estimate is computed. This might take a few minutes. After the validation is complete, you can view the estimated cost for the configured architecture on the validation modal in the Cost estimate successful section.\n\n\n\nThis estimated amount is subject to change as the architecture is customized and deployed, and it does not include all resources, usage, licenses, fees, discounts, or taxes.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-cost-estimate-project"}, {"document_id": "ibmcld_03735-7-1918", "score": 20.072443, "text": "\nEstimating your costs \n\nYou can use the cost estimator to estimate the cost of IBM Cloud\u00ae products by customizing plans that fit your business needs. Your account type doesn't affect your estimates. Explore the catalog to find available products to add to an estimate.\n\nEstimates can now be saved to an account. Make sure you're in the account that you want to save the estimate to. If you have existing estimates, they must be converted to a saved estimate that is attached to an account.\n\n\n\n Creating a new estimate \n\n\n\n1. In the IBM Cloud console, go to Cost estimator icon![Cost estimator icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/calculator.svg). From here, you are directed to Estimating your costs page.\n2. Click Create new estimate.\n3. Enter a name and description for the estimate.\n4. Click Create\n5. From here, you are directed to the estimate details page. Click Go to catalog to add products to the estimate.\n6. Select the product that you are interested in.\n\nDepending on the product, an interim informational page might be displayed. For example, if you select Bare Metal Servers, an informational page that describes various features is displayed. Click Continue.\n7. Select your pricing plan and enter other configuration details if needed. Then, click Add to estimate.\n\nSome products might require that you log in to add them to an estimate.\n8. Enter your estimated usage, and click Calculate Cost. You can adjust the estimated usage and recalculate the cost to see how different usage levels affect the overall cost.\n\n\n\nBy default, the estimator shows the pricing and billing currency set for your account. Pricing can vary by region. If you're estimating costs for a different location or currency, you might have to select the appropriate currency on the order summary page for the product or change the currency on your account.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cost"}, {"document_id": "ibmcld_07578-278658-280528", "score": 19.624733, "text": "\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n* Can I view and control my current usage?\n\nSee [View your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.\n\n\n\nSlurm on IBM Cloud\n\n\n\n* What Slurm version is used in cluster nodes deployed with this offering?\n\nCluster nodes that are deployed with this offering include Slurm 19.05.5-1 Advanced Edition.\n* What locations are available for deploying VPC resources?\n\nAvailable regions and zones for deploying VPC resources, and a mapping of those to city locations and data centers can be found in [Locations for resource deployment](https://cloud.ibm.com/docs/overview?topic=overview-locations).\n* What permissions do I need in order to create a cluster using the offering?\n\nInstructions for setting the appropriate permissions for IBM Cloud services that are used by the offering to create a cluster can be found in [Granting user permissions for VPC resources](https://cloud.ibm.com/docs/vpc?topic=vpc-managing-user-permissions-for-vpc-resources), [Managing user access for Schematics](https://cloud.ibm.com/docs/schematics?topic=schematics-access), and [Assigning access to Secrets Manager](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-assign-access).\n* How do I SSH among nodes?\n\nAll of the nodes in the HPC cluster have the same public key that you register at your cluster creation.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-278632-280502", "score": 19.624733, "text": "\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n* Can I view and control my current usage?\n\nSee [View your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.\n\n\n\nSlurm on IBM Cloud\n\n\n\n* What Slurm version is used in cluster nodes deployed with this offering?\n\nCluster nodes that are deployed with this offering include Slurm 19.05.5-1 Advanced Edition.\n* What locations are available for deploying VPC resources?\n\nAvailable regions and zones for deploying VPC resources, and a mapping of those to city locations and data centers can be found in [Locations for resource deployment](https://cloud.ibm.com/docs/overview?topic=overview-locations).\n* What permissions do I need in order to create a cluster using the offering?\n\nInstructions for setting the appropriate permissions for IBM Cloud services that are used by the offering to create a cluster can be found in [Granting user permissions for VPC resources](https://cloud.ibm.com/docs/vpc?topic=vpc-managing-user-permissions-for-vpc-resources), [Managing user access for Schematics](https://cloud.ibm.com/docs/schematics?topic=schematics-access), and [Assigning access to Secrets Manager](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-assign-access).\n* How do I SSH among nodes?\n\nAll of the nodes in the HPC cluster have the same public key that you register at your cluster creation.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_03781-7-1879", "score": 19.445456, "text": "\nScenario: Estimating costs of an example Node app \n\nAssume that you have a Node.js web app with scaling capabilities, and the app uses several services that are provided by IBM Cloud\u00ae. You can learn how the actual cost of your app is calculated in this example.\n\nThe web app uses the following IBM Cloud services and items:\n\n\n\n* Four 256-MB Node.js runtime instances\n* Two Auto-Scaling policies, processor and memory\n* 150 GB per month IBM Cloudant database, 1,000 lookups, 500 writes, and 50 queries\n* 20 GB inbound or outbound network traffic\n\n\n\n\n\n Prices for IBM Cloud resources \n\nTo keep the example simple, assume the prices in the following table don't fluctuate within or between a timeframe, for example, a month. All pricing in this example is in US currency.\n\n\n\nTable 1. Pricing for resources\n\n Service Features Price \n\n SDK for Node.js\u2122 Charges for runtime by GB-hours $0.07 USD/GB-hour \n Auto-Scaling Free service plan for the Auto-Scaling service Free \n IBM Cloudant Standard plan includes 20 GB of free data storage <br>Scale provisioned throughput capacity in increments of: <br>100 lookups per second <br>50 writes per second <br>5 queries per second $1.00 USD/GB of data storage <br>$0.25 USD/Lookup per second <br>$0.50 USD/Write per second <br>$5.00 USD/Query per second \n\n\n\n\n\n\n\n Calculating the app price \n\nThe price of the app can be calculated in the following way:\n\nFour 256-MB Node.js runtime instances\n: IBM Cloud charges for a runtime by GB-hours. The number of GB used per month is 4 x 256 = 1024 MB or 1 GB per month. Assume that there are 24 x 30 = 720 hours in a month, so the application is charged for 1 x 720 = 720 GB-hours.\n\nIBM Cloud offers a free tier of [Cloud Foundry application usage](https://cloud.ibm.com/docs/account?topic=account-accounts) that affects the overall cost for an application that's running, by reducing your costs.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-sample"}, {"document_id": "ibmcld_12576-1732-2808", "score": 19.275326, "text": "\nIn the future, aggregate costs across projects that can be grouped by various criteria will be available. For more information, see [Estimating architecture costs in a project](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-cost-estimate-project).\n\n\n\n\n\n API, SDK, and Terraform \n\nThe projects API, SDK, and Terraform functionalities are beta for this release. Beta products are made solely available for evaluation and testing purposes. There are no warranties, SLAs, or support provided and beta products are not intended for production use.\n\n\n\n\n\n Resource tagging \n\nResources that are created by deploying from a project are automatically given service tags. These tags are only visible by using the command-line interface (CLI) or API and are not currently available in usage reports. You can use the [ibmcloud resource search](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-projects-cli&interface=cliibmcloud-resource-tag-search) command to retrieve the resources created by configurations in a project based on the service tag.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-known-issues"}, {"document_id": "ibmcld_01623-6277-8255", "score": 19.113886, "text": "\nAfter you verify your identity, you set up and provide details for your authentication factor.\n\n\n\n\n\n Step 3: Estimate your costs \n\nComplete the following steps to get an estimate of how much your usage might cost:\n\n\n\n1. Go to the [catalog](https://cloud.ibm.com/catalog), and select Services.\n2. Select a service that you're interested in.\n3. Select a pricing plan, enter other configuration details if needed, and click Add to estimate.\n\nBy default, the estimator shows the pricing and billing currency for your location. Pricing can vary by region. If you're estimating costs for a different location, select the correct region to view accurate pricing.\n4. Add the calculated cost to your estimate by clicking Save.\n5. When you're done adding products to your estimate, click Review estimate to a detailed view of your estimate.\n\nYou can download a CSV, XSLX, or PDF of the estimate by clicking Download.\n\n\n\n\n\n\n\n Step 4: Manage your invoices and payment methods \n\nBefore you start working with resources in your account, familiarize yourself with where you can manage your payment method and access your invoices.\n\n\n\n Managing your payment method \n\n\n\n* To manage your payment method for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Payments.\n* To manage your payment method for an account that's billed in non-USD currency, go to [IBM Billing](https://myibm.ibm.com/billing/).\n\n\n\n\n\n\n\n Accessing your invoices \n\n\n\n* To access an invoice for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices.\n* To access an invoice for an account that's billed in non-USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices. Then, click IBM Invoices.\n\n\n\n\n\n\n\n\n\n Step 5: Set preferences for receiving notifications \n\nComplete the following steps to set your preferences for receiving various types of notifications:\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-account-getting-started"}, {"document_id": "ibmcld_10116-17431-19145", "score": 16.981432, "text": "\nSee [Estimating your costs](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as tiered pricing for increased hourly usage. For more information, see [Understanding costs for your clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-costscosts-for-clusters).\n\n\n\n\n\n Managing costs \n\nThe following steps present a general process to manage costs for your Red Hat OpenShift on IBM Cloud clusters.\n\n\n\n1. Decide on a cloud platform strategy to manage your resources.\n\n\n\n* See [Best practices for billing and usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-best-practices).\n* Organize your billing with [resource groups](https://cloud.ibm.com/docs/account?topic=account-rgs).\n* [Add tags to your clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-add_workerscluster_tags) according to your organizational strategy.\n\n\n\n2. Plan the type of cluster that you need.\n\n\n\n* [Size your cluster to support your workloads](https://cloud.ibm.com/docs/openshift?topic=openshift-strategysizing), including the network bandwidth that your workloads need.\n* [Decide the cluster environment that you want](https://cloud.ibm.com/docs/openshift?topic=openshift-strategykube_env).\n* [Consider the availability that you want for your cluster](https://cloud.ibm.com/docs/openshift?topic=openshift-ha_clusters). For example, a basic high availability setup is one multizone cluster with two worker nodes in each of three zones, for a minimum total of 6 worker nodes.\n\n\n\n3. Check out other IBM Cloud services, add-ons, operators, and other third-party software that you might use that can increase your cost.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-costs"}, {"document_id": "ibmcld_09915-2815-3708", "score": 16.447437, "text": "\nThe first 250,000 NLU items are charged at $0.003 per item\nAdditional NLU items until the 5,000,000th NLU item are charged at $0.001 per item\nEstimated price = (250,000 NLU items \u00d7 $0.003) + (50,000 NLU items \u00d7 $0.001)\nEstimated price = $750 + $50\n\n\n\nTotal cost = $800\n\n\n\n\n\n How do I calculate the Standard Plan price for 15,000 NLU items? \n\n\n\n* Since the first 250,000 NLU items are priced at $0.003/item - your 15,000 NLU items are charged at $0.003 per item (Tier 1). Your estimated price would be $45.\n\n\n\n\n\n\n\n How do I calculate the Standard Plan price for 6,000,000 NLU items? \n\n\n\n* Since you have more than 5,000,000 NLU items, your first 250,000 NLU items are charged at $0.003 per item (Tier 1), your next 4,750,000 NLU items are charged at $0.001 per item (Tier 2), and your remaining 1,000,000 NLU items are charged at $0.0002 per item (Tier 3). Your estimated price would be $5,700.", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-pricing"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03776-3313-5682", "score": 15.252312, "text": "\nWhen you have a Subscription account, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For example, you might buy a subscription for $12,000 USD a year that comes with a 10% discount. No matter when you incur usage costs within that year, you get fixed billing for the subscription amount, such as $1,000 a month. This account type is a good fit for enterprise organizations with large cloud workloads that want the predictability of fixed billing for their financial planning.\n\nIn addition to the two billable account types, customers that have a Subscription account can sign up for the Enterprise Savings Plan billing model. This billing model is similar to a Subscription account with a few added benefits. The following table details the two billable account types and billing model.\n\n\n\nTable 1. Comparative analysis of account types\n\n Pay-As-You-Go Subscription Enterprise Savings Plan \n\n Monthly billing Timely billing Timely billing \n Invoiced on monthly consumption Invoices independent of usage Invoiced on monthly consumption \n Best suited for developers and companies Best suited for enterprise organizations Best suited for both developers and enterprise organizations \n\n\n\n\n\n Estimating your costs \n\nAfter you select the type of account that fits your organization's needs, it's time to understand how you will be charged for it. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization consumes. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage for the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations.\n\nThe following are the various charging types:\n\n\n\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-overview"}, {"document_id": "ibmcld_03798-0-2240", "score": 15.218192, "text": "\n\n\n\n\n\n\n  Understanding my invoice \n\nBillable accounts receive a monthly invoice for the usage charges and other fees that are incurred. At any time, you can view your invoice or expected invoiced charges by going to the [Invoices](https://cloud.ibm.com/billing/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console.\n\nIf your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices. To sign up and view your invoices, you must provide your IBM customer number. If you don't know your customer number, contact IBM Cloud Support by calling 1-866-325-0045 and selecting the third option.\n\nIn this situation, go to [Invoices@IBM](http://ibm.com/invoices) to review your upcoming invoice, past invoices, or details about service charges.\n\n\n\n  Invoicing for different account types \n\nDepending on your account type, your usage is incurred and reflected differently on your invoice. Review the following differences for billing based on your account type:\n\n\n\n*  Subscription: The billed interval is contractual and depends on a negotiated payment for usage credits.\n*  Pay-As-You-Go: An estimation of your charges is found on the [Usage](https://cloud.ibm.com/billing/usage) page. Charges from platform and classic infrastructure services are included if your account uses both types. Infrastructure as a Service (IaaS) charges aren't included.\n\n\n\nThird-party services, such as SendGrid, don't bill for their service through IBM Cloud if you signed up for their service outside of IBM Cloud.\n\nAn IBM Cloud service might provide a free allocation before the start of your billing period. To determine whether your service instance provides a free allocation, go to the [Resources list](https://cloud.ibm.com/resources) in the IBM Cloud console. Click the service name, and then click Plan. Review the feature description for each plan to see whether the service offers free allocations. Free allocations are applied to the account level and not the organization level.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-understand-invoices"}, {"document_id": "ibmcld_03797-4528-6268", "score": 15.001201, "text": "\n[A view of the invoices page in the IBM Cloud console. This view displays new and one-time charges that reflect what you're charged.](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/billing-usage/images/example-invoice-console.png)\n\nFigure 3. New and one-time charges in the console for the month of March.\n\nThe remaining infrastructure charges of $322,806.71 USD from the recurring invoice in the console and the new and one-time charges should add up to the total IaaS final invoice charge of $324,245.93 USD.\n\n\n\n\n\n Granular view of the line item charges \n\nNow that we confirmed that the final invoice totals match the recurring and new and one time charges in the console, let\u2019s find out what the charges on the final invoice represent.\n\nOn the Excel version of your recurring invoice that you downloaded in step 2, click the Detailed Billing tab. The Detailed Billing tab provides a breakdown of all of your infrastructure and platform charges. They represent three major types of usage:\n\n\n\n* In Advance (for example, the month of March) infrastructure monthly usage charges. These are recurring charges that you incur until you cancel the service. The charge is the same every month.\n\n\n\nZoom\n\n![An example of an advanced infrastructure monthly usage charges on the detailed invoice tab from the downloaded Excel invoice.](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/billing-usage/images/advance-billing.png)\n\nFigure 4. In advance infrastructure monthly usage charges.\n\n\n\n* In Arrears (for example, the month of February) infrastructure hourly charges. These are usage-based charges from the previous month. Note the 672 hrs * .066 format of the charges.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"}, {"document_id": "ibmcld_16315-6754-8418", "score": 14.858417, "text": "\n\"card_title\": \"Let\u2019s dispute a charge\",\n\"card_description\": \"Follow along with this guided journey to learn how to find and dispute charges.\",\n\"user_defined_type\": \"IBM_BETA_JOURNEYS_TOUR\",\n\"steps\":\n{\n\"response_type\": \"text\",\n\"text\": \"Charges are listed on the Transactions page. Click your profile photo in the top right corner of your screen, and then click Transactions from the menu.\"\n},\n{\n\"response_type\": \"text\",\n\"text\": \"Here you can view your charges.n Scroll through the Transactions page and review your charges. Each charge contains a merchant name, transaction date, and amount charged.\"\n},\n{\n\"response_type\": \"image\",\n\"source\": \"https://example.com/image.png\",\n\"alt_text\": \"Image showing location of Dispute option\",\n\"description\": \"The option to Dispute is marked in red on the right hand side of each row in the Transactions table. Just click here to file a dispute.\"\n},\n{\n\"response_type\": \"video\",\n\"source\": \"https://vimeo.com/769580398\",\n\"description\": \"Watch this short video to learn what to expect now that you\u2019ve filed a dispute.\"\n}\n]\n}\n}\n]\n}\nShow more\n\n\n\n\n\n Starting a journey without opening the web chat \n\nAlthough journeys are part of the web chat integration, you can make it possible for your customers to start a journey directly from your website without opening the web chat window at all. For example, you might want to include a Show me button on your website that customers can click to launch an interactive tour of the page.\n\nTo start a journey without opening the web chat:\n\n\n\n1. In the action that sends the journey response, edit the JSON that defines the journey. Include \"skip_card\": true to bypass the introductory card.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-journeys"}, {"document_id": "ibmcld_03797-3428-4809", "score": 14.283207, "text": "\n[Download icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/download.svg) to download the invoice directly to your device.\n5. Open the downloaded file, and click Summary tab.\n\n\n\nIn this example, the Platform Services charge matches the total on the PaaS final invoice from Figure 1: $5,566.81 USD. The remaining charges, which total $322,806.71 USD ($328,373.52 - $5566.81 = $322,806.71) represent the remaining infrastructure, nonplatform charges from this recurring invoice.\n\nZoom\n\n![An image of recurring console invoice](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/billing-usage/images/Recurring-invoice.png)\n\nFigure 2.IaaS recurring charges.\n\n\n\n\n\n Identify the new and one-time charges \n\nNext, you need to identify and find the sum of the new and one time charges. Your new and one-time charges are on the [Invoices page](https://cloud.ibm.com/billing/invoices) in the console. There are three new charges on the invoices page during this time period: A charge of $500.52, $767.10, and $171.60.\n\nZoom\n\n![A view of the invoices page in the IBM Cloud console. This view displays new and one-time charges that reflect what you're charged.](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/billing-usage/images/example-invoice-console.png)\n\nFigure 3.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"}, {"document_id": "ibmcld_03729-7-2197", "score": 13.933338, "text": "\nHow you're charged \n\nIBM Cloud\u00ae charges vary depending on the resources that are used by a particular service, runtime, container, or support option. The resources can be the number of API calls, the number of instances, memory, or storage. In addition, tiered pricing is offered in simple, graduated, or block.\n\nIBM Cloud provides detailed [cost estimators](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cost) to help you plan for charges.\n\nAfter you build your resources, you can check the actual cost. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization used. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage of the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations. You can see more information about a specific charge from each resource details page.\n\nDifferent types of charges apply depending on the features of IBM Cloud that you're using. The following table provides a high-level overview:\n\n\n\nTable 1. Charges based on features\n\n Type of Charge Description Resource Type Example \n\n Fixed Fixed-rate pricing is based on an agreed upon monthly charge. If you buy an additional bare metal server, virtual server, or storage resource after the start of the monthly billing period, the cost of the resource for the first month is prorated based on the number of days remaining in the billing period. The prorated cost is billed in a separate invoice. Services For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges"}, {"document_id": "ibmcld_03800-3318-5483", "score": 13.715396, "text": "\nClick View plans to view all the instances of a specific type of resource.\n3. To view a detailed summary of estimated charges for each instance of a specific resource type, click View details. You can also view the detailed monthly usage metrics for the selected instance.\n\n\n\nIf you have a Pay-As-You-Go account that isn't billed in US dollars or a Subscription account, the usage for all services is finalized by the 20th of the following month. If you have a Pay-As-You-Go account that is billed in US dollars, the usage for all services is finalized by the 3rd of the following month.\n\nThe account is billed for the total usage that is incurred across all groups and organizations at the end of each billing cycle. Each billing cycle lasts one month.\n\nYou can filter the usage summary by group and select the time frame for usage. The charges that are shown represent the amount that is billed to the account for that particular month.\n\nIf you select a specific organization from the Filter by group list, you can see the total usage for that organization, including any usage as part of a free tier. The free tier usage is shown as free at the account level, but not at the organizational level. When you view the organizational usage, you see the real usage for that organization, which includes both free and charged usage. All organizational usage is rolled up to the account usage after the free tier is removed.\n\nThe account owner of a billable account can set spending notifications against the total cost of the account, for runtime, services, and for individual services, excluding third-party services. For more information, see [Setting spending notifications](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-spending).\n\n\n\n\n\n\n\n Viewing your usage by using the API \n\nYou can programmatically view your usage by calling the [IBM Cloud Usage Reports API](https://cloud.ibm.com/apidocs/metering-reportingget-account-usage). You can base the query in your API call on an account, org, resource group, or resource instance.\n\nThe following examples show queries that you can use to view account level usage:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage"}, {"document_id": "ibmcld_03771-1594-3365", "score": 13.179979, "text": "\nThe charges on your invoice are consistent with the usage dashboard. On the Invoices page in the console, click View usage to be directed to your usage dashboard. From there, you can select a timeframe and view billing and usage information that aligns directly with the details in your invoice.\n\n\n\n Checking your invoice status \n\nYou can check the status of your invoice on the [Invoices page](https://cloud.ibm.com/billing/invoices):\n\n\n\n* Invoiced: You received the latest invoice from IBM Cloud.\n* Paid: Your payment for the charges on your latest invoice was received.\n* Unpaid: The charges on your latest invoice have not been paid.\n* Pending: Your payment for your latest charges has not been applied due to a payment processing error. In this case, you can contact IBM Cloud Support for more details about the error.\n\n\n\nTurning a resource \"off\" doesn't cancel the resource in your account. You will receive invoices for resources in your account until you cancel them. For more information, see [Cancelling your billing items](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cancel-billing-items).\n\n\n\n\n\n Viewing and downloading your invoice \n\nView and download your invoice from the IBM console by clicking the Download icon ![Download icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/download.svg)> PDF invoice next to each invoice. For some accounts, invoices are available through the [Invoices@IBM](http://ibm.com/invoices) website. See the [Viewing and downloading invoices for all other accounts](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoicesviewing-external-invoices) section for more information.\n\n\n\n\n\n\n\n Viewing and downloading invoices for all other accounts", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoices"}, {"document_id": "ibmcld_03797-5893-7322", "score": 12.977686, "text": "\n(https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/billing-usage/images/advance-billing.png)\n\nFigure 4. In advance infrastructure monthly usage charges.\n\n\n\n* In Arrears (for example, the month of February) infrastructure hourly charges. These are usage-based charges from the previous month. Note the 672 hrs * .066 format of the charges. In arrears, infrastructure hourly charges are always in this format.\n\n\n\nZoom\n\n![An example of an arrears infrastructure hourly charge on the detailed invoice tab from the downloaded Excel invoice.](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/billing-usage/images/arrears-hourly.png)\n\nFigure 5.In Arrears infrastructure hourly charges.\n\n\n\n* In arrears (for example, the month of January) platform service charges. These are usage-based charges from two months prior. They are labeled Platform service in column B and reference the month in which the usage was consumed.\n\n\n\nZoom\n\n![In arrears platform service charges.](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/billing-usage/images/arrears-platform-service-charges.png)\n\nFigure 6. In arrears platform service charges for the month of January.\n\n\n\n\n\n Next steps \n\nTo continue your learning about your billing and usage, see [Managing payments](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusage),", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"}, {"document_id": "ibmcld_11408-13151-14243", "score": 12.919231, "text": "\nThe following table shows the charges based on the number of connections (includes all types of connection such as DL, VPC, etc.) that you create:\n\n\n\nTable 14. TGW charges based on number of connections\n\n Number of connections Charges \n\n 1 - 4 No charges \n 5 - 20 $9.405 \n 21 - 50 $7.315 \n 51+ $4.7025 \n\n\n\nThe Transit Gateway charges indicated in the tables above are subjected to change. To calculate your pricing, use the [IBM cost estimator](https://cloud.ibm.com/estimator) in IBM Cloud console.\n\n\n\n\n\n End of billing \n\nThe monthly billing cycle ends when you delete the LPAR. If you scale your infrastructure up and down in response to workload requirements, your billing follows the timing of the LPAR provision change. If you stop the LPAR, the billing process is not stopped. You must delete the LPAR to stop the billing cycle.\n\nYou are still charged if the VM is in a suspended state. When your VM is inactive, you can use Dynamic Logical Partitioning (DLPAR) to resize it to a minimal state. You can drastically decrease the price per hour by reducing the VM's core count and memory.", "title": "", "source": "https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-pricing-virtual-server"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03776-5228-7163", "score": 24.163486, "text": "\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https://cloud.ibm.com/billing/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https://myibm.ibm.com/billing/).", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-overview"}, {"document_id": "ibmcld_03729-1672-3956", "score": 21.667213, "text": "\nServices For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged. \n Tiered In this pricing model, you get a volumed-based discount according to your actual usage. Tiered pricing is typically used for charge metrics that are expected to have high quantities per month, such as API calls. Services might offer simple, graduated, or block tier pricing plans. Services For API Connect, one of the tiered plans charges $10,000 for the first 25 million monthly API calls and $40.00 USD per 100,000 API calls per month thereafter. \n Reserved Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment. Services Db2 on Cloud has reserved plans. \n\n\n\n\n\n Understanding monthly and hourly tags \n\nOn the usage dashboard, your products and resources can be labeled with Monthly, Hourly, or a combination of both tags to signify how often charges are updated.\n\nThe Monthly tag signifies that resources within your account have a fixed cost. These charge show up immediately after purchase and are prorated in proportion to how many days are left in the month. Any recurring monthly fixed costs are then shown at the first of every month.\n\nThe Hourly tag signifies that resources within your account have variable costs. These resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges"}, {"document_id": "ibmcld_03729-4932-7001", "score": 21.082233, "text": "\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges\n: You select a plan and pay on a flat rate basis. For example, the Bare Metal Servers are charged at a flat-rate.\n\nMetered charges\n: You pay based on your runtime and service consumption. For example, with the Push service, any usage over the free monthly allowance is charged.\n\nReserved charges\n: As the account owner of a Pay As You Go account or a Subscription account, you can reserve a service instance, with a long-term commitment, for a discounted price. For example, you can reserve the standard large Db2 on Cloud offering for 12 months.\n: Some IBM Cloud services offer reserved plans. You can request a reserved plan from the IBM Cloud catalog by clicking the tile of the service. Then, select the service plan that best meets your needs. If a reserved plan is available, click Request, and follow the prompts to send your request. You receive an email that contains the price information of the reserved plan. An IBM Cloud sales representative also contacts you soon to complete the purchase.\n\nTiered charges\n: Similar to metered charges, you pay based on your runtime and service consumption. However, tiered charges add more pricing tiers, often offering discounted charges in tiers with larger consumption. Tiered pricing is offered in simple, graduated, or block.\n\n\n\n Simple tier \n\nIn the simple tier model, the unit price is determined by the tier that the quantity of your usage falls into. The total price is your quantity that is multiplied by the unit price in that tier, for example:\n\n\n\nTable 2. Simple tier pricing table\n\n Quantity of Items Unit Price for All Items", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges"}, {"document_id": "ibmcld_03776-3313-5682", "score": 18.48624, "text": "\nWhen you have a Subscription account, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For example, you might buy a subscription for $12,000 USD a year that comes with a 10% discount. No matter when you incur usage costs within that year, you get fixed billing for the subscription amount, such as $1,000 a month. This account type is a good fit for enterprise organizations with large cloud workloads that want the predictability of fixed billing for their financial planning.\n\nIn addition to the two billable account types, customers that have a Subscription account can sign up for the Enterprise Savings Plan billing model. This billing model is similar to a Subscription account with a few added benefits. The following table details the two billable account types and billing model.\n\n\n\nTable 1. Comparative analysis of account types\n\n Pay-As-You-Go Subscription Enterprise Savings Plan \n\n Monthly billing Timely billing Timely billing \n Invoiced on monthly consumption Invoices independent of usage Invoiced on monthly consumption \n Best suited for developers and companies Best suited for enterprise organizations Best suited for both developers and enterprise organizations \n\n\n\n\n\n Estimating your costs \n\nAfter you select the type of account that fits your organization's needs, it's time to understand how you will be charged for it. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization consumes. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage for the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations.\n\nThe following are the various charging types:\n\n\n\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-overview"}, {"document_id": "ibmcld_03729-7-2197", "score": 16.706627, "text": "\nHow you're charged \n\nIBM Cloud\u00ae charges vary depending on the resources that are used by a particular service, runtime, container, or support option. The resources can be the number of API calls, the number of instances, memory, or storage. In addition, tiered pricing is offered in simple, graduated, or block.\n\nIBM Cloud provides detailed [cost estimators](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cost) to help you plan for charges.\n\nAfter you build your resources, you can check the actual cost. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization used. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage of the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations. You can see more information about a specific charge from each resource details page.\n\nDifferent types of charges apply depending on the features of IBM Cloud that you're using. The following table provides a high-level overview:\n\n\n\nTable 1. Charges based on features\n\n Type of Charge Description Resource Type Example \n\n Fixed Fixed-rate pricing is based on an agreed upon monthly charge. If you buy an additional bare metal server, virtual server, or storage resource after the start of the monthly billing period, the cost of the resource for the first month is prorated based on the number of days remaining in the billing period. The prorated cost is billed in a separate invoice. Services For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges"}, {"document_id": "ibmcld_05666-7-2151", "score": 14.874727, "text": "\nUnderstanding costs for your clusters \n\nWith IBM Cloud\u00ae, you can plan for, estimate, review, and modify your cluster environment to control costs. Just by using a managed service like IBM Cloud\u00ae Kubernetes Service, you are saving many expenses that are associated with managing, updating, and maintaining an infrastructure environment.\n\n\n\n Understanding costs by component \n\nWith IBM Cloud Kubernetes Service clusters, you can use IBM Cloud infrastructure compute, networking, and storage resources with platform services such as Watson AI or Compose Database-as-a-Service. Each resource might entail its own charges that can be [fixed, metered, tiered, or reserved](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-chargescharges) and billed by various incremental rates such as monthly or hourly.\n\nMonthly resources are billed based on the first of the month for usage in the preceding month. If you order a monthly resource in the middle of the month, you are charged a prorated amount for that month. However, if you cancel a resource in the middle of the month, you are still charged the full amount for the monthly resource.\n\n\n\n Worker nodes \n\nClusters can have two main types of worker nodes: virtual or physical (bare metal) machines. Flavor (machine type) availability and pricing varies by the zone that you deploy your cluster to.\n\nWhen do worker nodes begin to incur charges?**\n: Worker nodes begin to incur charges after they complete the provisioning state and continue until you delete the worker nodes and they complete the deleting state. For more information, see [Worker node states](https://cloud.ibm.com/docs/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-costs"}, {"document_id": "ibmcld_12837-8834-10242", "score": 14.268432, "text": "\nBlock tier (up to) The total amount that is charged is established by an up to quantity that doesn't vary within the block If Q is <=Q1, T=T1<br><br>If Q1 < Q <=Q2, T=T2<br><br>If Q2 < Q <=Q3, T=T3 Q1=1000, T1=$0<br><br>Q2=2500, T2=2500<br><br>Q3=10000, T3=$4500<br><br>T=$4500 \n\n\n\nBlock tier pricing is not currently supported. If your product migrated from the resource management console, and you used block tier pricing, it is still honored. However, you can't add any new block tier pricing plans at this time.\n\n\n\n\n\n Metrics for metering models \n\nIf you created your service with Partner Center, you can choose from the following metrics and default metering models:\n\n\n\nTable 9. Partner Center metering model metrics\n\n Type Metric \n\n dailyproration_max Active User \n standard-add API call \n dailyproration_max Authorized User \n standard_add Gigabyte hour \n standard_add Gigabyte month \n monthlyproration Instance \n standard_add Terabyte hour \n standard_add Terabyte month \n dailyproration_max User \n standard_add Virtual Server \n standard_add Virtual Server Hour \n standard_add Virtual Processor Core \n\n\n\nThird-party providers that migrated from the resource management console to Partner Center can manage their metering models with Partner Center. Any information that you added or edited for pricing plans and metering models by using the resource management console can be updated in Partner Center.", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-service-metering-integration"}, {"document_id": "ibmcld_10116-7-2157", "score": 14.185675, "text": "\nUnderstanding costs for your clusters \n\nWith IBM Cloud\u00ae, you can plan for, estimate, review, and modify your cluster environment to control costs. Just by using a managed service like Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae, you are saving many expenses that are associated with managing, updating, and maintaining an infrastructure environment.\n\n\n\n Understanding costs by component \n\nWith Red Hat OpenShift on IBM Cloud clusters, you can use IBM Cloud infrastructure compute, networking, and storage resources with platform services such as Watson AI or Compose Database-as-a-Service. Each resource might entail its own charges that can be [fixed, metered, tiered, or reserved](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-chargescharges) and billed by various incremental rates such as monthly or hourly.\n\nMonthly resources are billed based on the first of the month for usage in the preceding month. If you order a monthly resource in the middle of the month, you are charged a prorated amount for that month. However, if you cancel a resource in the middle of the month, you are still charged the full amount for the monthly resource.\n\n\n\n Worker nodes \n\nClusters can have two main types of worker nodes: virtual or physical (bare metal) machines. Flavor (machine type) availability and pricing varies by the zone that you deploy your cluster to.\n\nWhen do worker nodes begin to incur charges?**\n: Worker nodes begin to incur charges after they complete the provisioning state and continue until you delete the worker nodes and they complete the deleting state. For more information, see [Worker node states](https://cloud.ibm.com/docs/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-costs"}, {"document_id": "ibmcld_05666-1575-3588", "score": 13.725643, "text": "\nFor more information, see [Worker node states](https://cloud.ibm.com/docs/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.\n\n\n\n* Shared versus dedicated: If you share the underlying hardware of the VM, the cost is less than dedicated hardware, but the physical resources are not dedicated to your VM.\n* Hourly billing only: Hourly billing offers more flexibility to order and cancel VMs quickly. You are charged an hourly rate that is metered for only the time that that the worker node is provisioned. The time is not rounded up or down to the nearest hour, but is metered in minutes and charged at the hourly rate. For example, if your worker node is provisioned for 90 minutes, you are charged the hourly rate for 1.5 hours, not 2 hours.\n* Tiered hours per month: The [pricing](https://cloud.ibm.com/kubernetes/catalog/aboutpricing) is billed hourly in [graduated tiered](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-chargesgraduated_tier). As your VM remains ordered for a tier of hours within a billing month, the hourly rate that you are charged lowers. The tiers of hours are as follows:\n\n\n\n* 0 - 150 hours\n* 151 - 290 hours\n* 291 - 540 hours\n* 541+ hours\n\n\n\n\n\nPhysical machines, or bare metal, (not available for VPC clusters) yield high-performance benefits for workloads such as data, GPU, and AI. Additionally, all the hardware resources are dedicated to your workloads, so you don't have \"noisy neighbors\". Keep in mind these factors that impact your bare metal costs.\n\n\n\n* Monthly billing only: All bare metals are charged monthly.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-costs"}, {"document_id": "ibmcld_10116-1581-3594", "score": 13.725643, "text": "\nFor more information, see [Worker node states](https://cloud.ibm.com/docs/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.\n\n\n\n* Shared versus dedicated: If you share the underlying hardware of the VM, the cost is less than dedicated hardware, but the physical resources are not dedicated to your VM.\n* Hourly billing only: Hourly billing offers more flexibility to order and cancel VMs quickly. You are charged an hourly rate that is metered for only the time that that the worker node is provisioned. The time is not rounded up or down to the nearest hour, but is metered in minutes and charged at the hourly rate. For example, if your worker node is provisioned for 90 minutes, you are charged the hourly rate for 1.5 hours, not 2 hours.\n* Tiered hours per month: The [pricing](https://cloud.ibm.com/kubernetes/catalog/aboutpricing) is billed hourly in [graduated tiered](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-chargesgraduated_tier). As your VM remains ordered for a tier of hours within a billing month, the hourly rate that you are charged lowers. The tiers of hours are as follows:\n\n\n\n* 0 - 150 hours\n* 151 - 290 hours\n* 291 - 540 hours\n* 541+ hours\n\n\n\n\n\nPhysical machines, or bare metal, (not available for VPC clusters) yield high-performance benefits for workloads such as data, GPU, and AI. Additionally, all the hardware resources are dedicated to your workloads, so you don't have \"noisy neighbors\". Keep in mind these factors that impact your bare metal costs.\n\n\n\n* Monthly billing only: All bare metals are charged monthly.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-costs"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03797-5893-7322", "score": 35.675373, "text": "\n(https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/billing-usage/images/advance-billing.png)\n\nFigure 4. In advance infrastructure monthly usage charges.\n\n\n\n* In Arrears (for example, the month of February) infrastructure hourly charges. These are usage-based charges from the previous month. Note the 672 hrs * .066 format of the charges. In arrears, infrastructure hourly charges are always in this format.\n\n\n\nZoom\n\n![An example of an arrears infrastructure hourly charge on the detailed invoice tab from the downloaded Excel invoice.](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/billing-usage/images/arrears-hourly.png)\n\nFigure 5.In Arrears infrastructure hourly charges.\n\n\n\n* In arrears (for example, the month of January) platform service charges. These are usage-based charges from two months prior. They are labeled Platform service in column B and reference the month in which the usage was consumed.\n\n\n\nZoom\n\n![In arrears platform service charges.](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/billing-usage/images/arrears-platform-service-charges.png)\n\nFigure 6. In arrears platform service charges for the month of January.\n\n\n\n\n\n Next steps \n\nTo continue your learning about your billing and usage, see [Managing payments](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusage),", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"}, {"document_id": "ibmcld_03797-4528-6268", "score": 33.54523, "text": "\n[A view of the invoices page in the IBM Cloud console. This view displays new and one-time charges that reflect what you're charged.](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/billing-usage/images/example-invoice-console.png)\n\nFigure 3. New and one-time charges in the console for the month of March.\n\nThe remaining infrastructure charges of $322,806.71 USD from the recurring invoice in the console and the new and one-time charges should add up to the total IaaS final invoice charge of $324,245.93 USD.\n\n\n\n\n\n Granular view of the line item charges \n\nNow that we confirmed that the final invoice totals match the recurring and new and one time charges in the console, let\u2019s find out what the charges on the final invoice represent.\n\nOn the Excel version of your recurring invoice that you downloaded in step 2, click the Detailed Billing tab. The Detailed Billing tab provides a breakdown of all of your infrastructure and platform charges. They represent three major types of usage:\n\n\n\n* In Advance (for example, the month of March) infrastructure monthly usage charges. These are recurring charges that you incur until you cancel the service. The charge is the same every month.\n\n\n\nZoom\n\n![An example of an advanced infrastructure monthly usage charges on the detailed invoice tab from the downloaded Excel invoice.](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/billing-usage/images/advance-billing.png)\n\nFigure 4. In advance infrastructure monthly usage charges.\n\n\n\n* In Arrears (for example, the month of February) infrastructure hourly charges. These are usage-based charges from the previous month. Note the 672 hrs * .066 format of the charges.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"}, {"document_id": "ibmcld_03729-1672-3956", "score": 29.784658, "text": "\nServices For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged. \n Tiered In this pricing model, you get a volumed-based discount according to your actual usage. Tiered pricing is typically used for charge metrics that are expected to have high quantities per month, such as API calls. Services might offer simple, graduated, or block tier pricing plans. Services For API Connect, one of the tiered plans charges $10,000 for the first 25 million monthly API calls and $40.00 USD per 100,000 API calls per month thereafter. \n Reserved Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment. Services Db2 on Cloud has reserved plans. \n\n\n\n\n\n Understanding monthly and hourly tags \n\nOn the usage dashboard, your products and resources can be labeled with Monthly, Hourly, or a combination of both tags to signify how often charges are updated.\n\nThe Monthly tag signifies that resources within your account have a fixed cost. These charge show up immediately after purchase and are prorated in proportion to how many days are left in the month. Any recurring monthly fixed costs are then shown at the first of every month.\n\nThe Hourly tag signifies that resources within your account have variable costs. These resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges"}, {"document_id": "ibmcld_07578-474233-476319", "score": 28.55033, "text": "\nHere you can see the total charges and usage for the month by service, plan, or instance. Only the hourly costs that are accrued for the current month and time are available. At the end of the month, you can see the average provisioned throughput capacity for each field: LOOKUPS_PER_MONTH, WRITES_PER_MONTH, and QUERIES_PER_MONTH.\n\n\n\n* Can I change my capacity setting?\n\nYou can change your provisioned throughput capacity and see your current capacity settings in the IBM Cloudant Dashboard. Launch IBM Cloudant Dashboard > Account > Capacity to view and change your provisioned throughput capacity and see the hourly and approximate monthly costs. You can also use the IBM Cloud\u00ae pricing calculator to see estimates in other currencies.\n* How do I know I exceeded the capacity limit that I set?\n\nThe Lite plan includes 1 GB of storage. If you exceed the limit, IBM Cloudant blocks your account from writing new data until you delete enough data to be under the 1-GB limit, or upgrade to a higher plan.\n\nThe first 20 GB of storage comes free with the Standard plan. You can store as much data as you want. Any storage over the 20 GB limit costs $0.0014 per GB per hour, which is approximately $1 per GB per month.\n* Where can I see my usage data?\n\nYou can see your current and historical usage bills in the IBM Cloud Dashboard. Go to Manage > Billing and usage > Usage. Here you can see the total charges and usage for the month by service, plan, or instance. Only the hourly costs that are accrued for the current month and time are available. At the end of the month, you can see the average provisioned throughput capacity for each field: LOOKUPS_PER_MONTH, WRITES_PER_MONTH, and QUERIES_PER_MONTH.\n* Provisioned throughput capacity model FAQ\n\n Provisioned throughput capacity model FAQ \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae calculates your provisioned throughput capacity based on these operation types: Read, Write, and Global Query.\n\n\n\nIBM Cloudant calculates provisioned throughput capacity by totaling the usage for each request class per second, where 1 second is a sliding window.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-474215-476301", "score": 28.55033, "text": "\nHere you can see the total charges and usage for the month by service, plan, or instance. Only the hourly costs that are accrued for the current month and time are available. At the end of the month, you can see the average provisioned throughput capacity for each field: LOOKUPS_PER_MONTH, WRITES_PER_MONTH, and QUERIES_PER_MONTH.\n\n\n\n* Can I change my capacity setting?\n\nYou can change your provisioned throughput capacity and see your current capacity settings in the IBM Cloudant Dashboard. Launch IBM Cloudant Dashboard > Account > Capacity to view and change your provisioned throughput capacity and see the hourly and approximate monthly costs. You can also use the IBM Cloud\u00ae pricing calculator to see estimates in other currencies.\n* How do I know I exceeded the capacity limit that I set?\n\nThe Lite plan includes 1 GB of storage. If you exceed the limit, IBM Cloudant blocks your account from writing new data until you delete enough data to be under the 1-GB limit, or upgrade to a higher plan.\n\nThe first 20 GB of storage comes free with the Standard plan. You can store as much data as you want. Any storage over the 20 GB limit costs $0.0014 per GB per hour, which is approximately $1 per GB per month.\n* Where can I see my usage data?\n\nYou can see your current and historical usage bills in the IBM Cloud Dashboard. Go to Manage > Billing and usage > Usage. Here you can see the total charges and usage for the month by service, plan, or instance. Only the hourly costs that are accrued for the current month and time are available. At the end of the month, you can see the average provisioned throughput capacity for each field: LOOKUPS_PER_MONTH, WRITES_PER_MONTH, and QUERIES_PER_MONTH.\n* Provisioned throughput capacity model FAQ\n\n Provisioned throughput capacity model FAQ \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae calculates your provisioned throughput capacity based on these operation types: Read, Write, and Global Query.\n\n\n\nIBM Cloudant calculates provisioned throughput capacity by totaling the usage for each request class per second, where 1 second is a sliding window.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_03800-1779-3764", "score": 28.15453, "text": "\nViewing usage details from the usage summary widget \n\nIn the usage summary widget on the billing and usage dashboard, you get view of your actual and predicted spending trends.\n\nThe predicted usage for the next month is calculated by finding the trend from the usage of the last three months, including the current month. For example, if it's August, predicted usage is calculated based on usage trends in June, July, and August to find the predicted usage for September.\n\nLet's say the usage is $950.00 USD for June, $1000.00 USD for July, and $1012.50 USD for August. The difference is calculated between the current month and the last month, and last month and the month before that. Then, the two calculations are averaged to find the trend. That trend amount of $1043.75 USD is the predicted next month's usage, with the following calculations:\n\n\n\n* Change between August and July = $1012.50 - $1000.00 = $12.50 USD\n* Change between July and June = $1000.00 - $950.00 = $50.00 USD\n* Average change (trend) = ($12.50 + $50.00) / 2 = $31.25 USD\n\n\n\nAugust usage ($1012.50) + Average change ($31.25) = The predicted usage for next month September ($1043.75 USD)\n\n\n\n\n\n Viewing usage details from the usage page \n\nIn the Services section, you can view a list of your services and the estimated costs that are associated with those services. To view a summary of estimated charges for all instances of a specific resource, complete the following steps:\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage.\n2. Click View plans to view all the instances of a specific type of resource.\n3. To view a detailed summary of estimated charges for each instance of a specific resource type, click View details. You can also view the detailed monthly usage metrics for the selected instance.\n\n\n\nIf you have a Pay-As-You-Go account that isn't billed in US dollars or a Subscription account, the usage for all services is finalized by the 20th of the following month.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage"}, {"document_id": "ibmcld_03729-7-2197", "score": 27.750082, "text": "\nHow you're charged \n\nIBM Cloud\u00ae charges vary depending on the resources that are used by a particular service, runtime, container, or support option. The resources can be the number of API calls, the number of instances, memory, or storage. In addition, tiered pricing is offered in simple, graduated, or block.\n\nIBM Cloud provides detailed [cost estimators](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cost) to help you plan for charges.\n\nAfter you build your resources, you can check the actual cost. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization used. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage of the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations. You can see more information about a specific charge from each resource details page.\n\nDifferent types of charges apply depending on the features of IBM Cloud that you're using. The following table provides a high-level overview:\n\n\n\nTable 1. Charges based on features\n\n Type of Charge Description Resource Type Example \n\n Fixed Fixed-rate pricing is based on an agreed upon monthly charge. If you buy an additional bare metal server, virtual server, or storage resource after the start of the monthly billing period, the cost of the resource for the first month is prorated based on the number of days remaining in the billing period. The prorated cost is billed in a separate invoice. Services For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges"}, {"document_id": "ibmcld_16727-1318553-1320460", "score": 27.563732, "text": "\nThe Standard plan bills for every stored capacity ($/GB/month), Outbound bandwidth ($/GB), class A ($/1,000), class B ($/10,000) and retrieval ($/GB) metrics, where applicable.\n* One Rate plan is suited for active workloads with large amounts of Outbound bandwidth (or varying Outbound bandwidth) as a percent of their Storage capacity (Outbound bandwidth > 20% of Storage capacity). Typical workloads belong to large enterprises and ISVs which may have sub-accounts with multiple divisions/departments or end-users. The plan offers a predictable TCO with an all-inclusive flat monthly charge ($/GB/month) that includes capacity, and built-in allowances for Outbound bandwidth and Operational requests. The built-in allowances for Outbound bandwidth and Operational requests (Class A, Class B) depend on the monthly stored capacity. There is no data retrieval charge.\n\n\n\n* How are the allowance thresholds (for Outbound bandwidth, class A and class B) calculated for the One-Rate plan?\n\nFor each of the One-Rate plan pricing regions(North America, Europe, South America,and Asia Pacific), the total aggregated Storage capacity across all instances (within a region) is used to determine the allowance thresholds.\n\n\n\n* Outbound bandwidth: No charge if Outbound bandwidth \u2264 100% of Storage capacity in GB, then list prices apply ($0.05/GBfor North America and Europe, $0.08/GB for South America and Asia Pacific). For example, for an account with aggregated monthly Storage capacity of 100 GB in North America, there are no Outbound bandwidth charges up to 100 GB of transferred data within that month.\n* Class A: No charge if class A requests \u2264 100 x Storage capacity in GB, then list prices apply ($0.005/1000). For example, for an account with aggregated monthly Storage capacity of 100 GB in North America, there are no Outbound bandwidth charges up to 10,000 class A requests that month in North America.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-1315888-1317795", "score": 27.563732, "text": "\nThe Standard plan bills for every stored capacity ($/GB/month), Outbound bandwidth ($/GB), class A ($/1,000), class B ($/10,000) and retrieval ($/GB) metrics, where applicable.\n* One Rate plan is suited for active workloads with large amounts of Outbound bandwidth (or varying Outbound bandwidth) as a percent of their Storage capacity (Outbound bandwidth > 20% of Storage capacity). Typical workloads belong to large enterprises and ISVs which may have sub-accounts with multiple divisions/departments or end-users. The plan offers a predictable TCO with an all-inclusive flat monthly charge ($/GB/month) that includes capacity, and built-in allowances for Outbound bandwidth and Operational requests. The built-in allowances for Outbound bandwidth and Operational requests (Class A, Class B) depend on the monthly stored capacity. There is no data retrieval charge.\n\n\n\n* How are the allowance thresholds (for Outbound bandwidth, class A and class B) calculated for the One-Rate plan?\n\nFor each of the One-Rate plan pricing regions(North America, Europe, South America,and Asia Pacific), the total aggregated Storage capacity across all instances (within a region) is used to determine the allowance thresholds.\n\n\n\n* Outbound bandwidth: No charge if Outbound bandwidth \u2264 100% of Storage capacity in GB, then list prices apply ($0.05/GBfor North America and Europe, $0.08/GB for South America and Asia Pacific). For example, for an account with aggregated monthly Storage capacity of 100 GB in North America, there are no Outbound bandwidth charges up to 100 GB of transferred data within that month.\n* Class A: No charge if class A requests \u2264 100 x Storage capacity in GB, then list prices apply ($0.005/1000). For example, for an account with aggregated monthly Storage capacity of 100 GB in North America, there are no Outbound bandwidth charges up to 10,000 class A requests that month in North America.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_03776-3313-5682", "score": 27.221024, "text": "\nWhen you have a Subscription account, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For example, you might buy a subscription for $12,000 USD a year that comes with a 10% discount. No matter when you incur usage costs within that year, you get fixed billing for the subscription amount, such as $1,000 a month. This account type is a good fit for enterprise organizations with large cloud workloads that want the predictability of fixed billing for their financial planning.\n\nIn addition to the two billable account types, customers that have a Subscription account can sign up for the Enterprise Savings Plan billing model. This billing model is similar to a Subscription account with a few added benefits. The following table details the two billable account types and billing model.\n\n\n\nTable 1. Comparative analysis of account types\n\n Pay-As-You-Go Subscription Enterprise Savings Plan \n\n Monthly billing Timely billing Timely billing \n Invoiced on monthly consumption Invoices independent of usage Invoiced on monthly consumption \n Best suited for developers and companies Best suited for enterprise organizations Best suited for both developers and enterprise organizations \n\n\n\n\n\n Estimating your costs \n\nAfter you select the type of account that fits your organization's needs, it's time to understand how you will be charged for it. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization consumes. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage for the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations.\n\nThe following are the various charging types:\n\n\n\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-overview"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_08067-0-1736", "score": 16.285818, "text": "\n\n\n\n\n\n\n  Viewing your support costs \n\nIf you have Advanced or Premium support, you can keep track of your monthly support costs from the Support costs page in the IBM Cloud\u00ae console.\n\n\n\n  How you're charged for support \n\nEach [IBM Cloud support plan](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans) has a minimum monthly price for providing support for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost. For details about your purchased support plan, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule).\n\n\n\n\n\n  Viewing support costs \n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https://cloud.ibm.com/docs/account?topic=account-userroles).\n\nIn the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. You can view your support plan and relevant cost details:\n\n\n\n*  If your support costs are billed monthly, you can view your costs for the current month. These costs include the starting price for the plan and any additional costs from your resource usage. After each billing cycle, these charges are added to your monthly invoice.\n*  If you have a support subscription, you can view the remaining credit in your active subscriptions and any overages for the current month. Overage is charged if you run out of credit in your active subscriptions. You can also view upcoming support subscriptions, which are subscriptions that you bought but are not yet valid.\n\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/get-support?topic=get-support-support"}, {"document_id": "ibmcld_07578-1033424-1035350", "score": 14.948624, "text": "\n* How am I charged for support?\n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https://cloud.ibm.com/docs/account?topic=account-userroles).\n* How can I upgrade my support plan?\n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans).\n* Why can't I see my support cases?\n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon ![Help icon](https://cloud.ibm.com/icons/help.svg) > Support center, and click Manage cases. If you're unable to view your cases, try clicking View classic infrastructure cases.\n\nIf you still can't view them, you might not have the required permission. Ask your account owner to add you to the support case access group. For more information, see [SoftLayer account permissions](https://cloud.ibm.com/docs/account?topic=account-migrated_permissions).\n* How do I get support for non-IBM Cloud products?\n\nSome cloud-based IBM products are not offered in IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1033295-1035221", "score": 14.948624, "text": "\n* How am I charged for support?\n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https://cloud.ibm.com/docs/account?topic=account-userroles).\n* How can I upgrade my support plan?\n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans).\n* Why can't I see my support cases?\n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon ![Help icon](https://cloud.ibm.com/icons/help.svg) > Support center, and click Manage cases. If you're unable to view your cases, try clicking View classic infrastructure cases.\n\nIf you still can't view them, you might not have the required permission. Ask your account owner to add you to the support case access group. For more information, see [SoftLayer account permissions](https://cloud.ibm.com/docs/account?topic=account-migrated_permissions).\n* How do I get support for non-IBM Cloud products?\n\nSome cloud-based IBM products are not offered in IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_03787-5002-7004", "score": 13.545941, "text": "\nA subscription is inactive if its term expires or all of its credit is spent.\n\n\n\nYou can use the spending and usage information on the Subscriptions page to evaluate whether your subscriptions suit your usage needs. For example, if you consistently have overages, you might increase your monthly spending commitment to save money on that usage. To buy new subscriptions or change future subscription amounts, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule).\n\n\n\n\n\n Support subscriptions \n\nTo view support subscription usage, in the console, go to Manage > Billing and usage, and select Support costs. You can view the remaining credit in your active support subscriptions and any upcoming subscriptions that aren't yet valid. For more information, see [Viewing your support costs](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-support).\n\n\n\n\n\n\n\n Subscription credit \n\nAfter you buy a subscription for platform or support credit, you add the credit to your account by applying a subscription code. Applying the code ensures that the credit is added to your account and you don't have unexpected overage charges.\n\nFor more information, see [Applying subscription codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code).\n\n\n\n\n\n Expiring subscriptions \n\nYou are notified by email 60, 30, 14, and 1 day before the expiration date of the last subscription on the account. After the subscription expires, your account is converted to a Pay-As-You Go account, which means you pay only for billable services that you use with no contracts or commitments. The discounts that are associated with the subscription account won't apply to the Pay-As-You-Go account. The IBM Sales team is happy to help extend your subscription before you reach its expiration date. If you extend your subscription within 30 days from the expiration date, you won't get charged at the Pay-As-You-Go account rate. After 30 days, you are invoiced as a Pay-As-You-Go account.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions"}, {"document_id": "ibmcld_01705-10258-12247", "score": 13.476997, "text": "\nSupport subscription credit is separate from any platform or service subscription credit in your account and can't be spent on resource usage. For more information, see [How subscription credit is spent](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptionssubscription-basics).\n\n\n\n\n\n Service bundle subscriptions \n\nService bundle subscriptions give you access and credit toward a set of services within a particular domain that are targeted for popular use cases. You can choose from service bundles that span AI, analytics, IBM Blockchain, Internet of Things (IoT), and cloud-native services. If your needs cross multiple domains, you can purchase multiple service bundle subscriptions.\n\nYou can add services bundles to any type of existing account, including Lite accounts. Service bundle subscriptions are subject to the [IBM Cloud Terms of Use](https://cloud.ibm.com/docs/overview/terms-of-use?topic=overview-terms).\n\nService bundle subscriptions aren't available through the IBM Cloud console. To learn more and purchase a service bundle, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule).\n\nAfter you purchase a service bundle subscription, you'll receive an email with a subscription code that you apply to add the bundle to your account. For more information about how to apply subscription codes, see [Subscription credit](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptionssubscription-codes). When your service bundle expires or you use all of the credit, you can continue to use any of the services, with usage charged at the Pay-As-You Go rate.\n\n\n\n\n\n Expiring subscriptions \n\nWhen your subscription is about to expire, you are notified by email 60, 30, 14, and 1 day before the expiration date of the last subscription on the account. After your subscription expires, your account is converted to a Pay-As-You-Go account, which means you pay only for billable services that you use with no contracts or commitments.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accounts"}, {"document_id": "ibmcld_12623-6811-8811", "score": 13.3062525, "text": "\n* A single invoice for all usage within the enterprise, so understanding costs is easier\n* A single place to manage payment methods, so you can update once for all accounts\n\n\n\nLearn more in [Centrally manage billing and usage with enterprises](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-enterprise).\n\n\n\n\n\n Enterprise support \n\nThe level of support that is assigned to an IBM Cloud enterprise defaults to the highest support plan within the enterprise. All child accounts within the enterprise also default to the highest support plan. For more information about the support experience, see [Basic, Advanced, and Premium Support plans](https://cloud.ibm.com/docs/get-support?topic=get-support-support-planssupport_level_enterprise).\n\n\n\n\n\n Resource management \n\nResources and services within an enterprise function the same as in stand-alone accounts. Each account in an enterprise can contain resources in resource groups. Account groups can't contain resources. For more information, see [Managing resources](https://cloud.ibm.com/docs/account?topic=account-manage_resource).\n\nZoom\n\n![A diagram that shows that resources are contained in accounts in the enterprise.](https://cloud.ibm.com/docs-content/v1/content/d4595e5202a9a27767cf034e81b038cdf772e0d5/secure-enterprise/images/enterprise-resources.svg)\n\nFigure 3. Resources in an enterprise\n\nAs with all accounts, resources are tied to the resource group and account in which they're created, so they can't be moved between accounts in the enterprise. However, the enterprise's flexible account structure means you can move resources within the enterprise by moving the accounts that contain them.\n\n\n\n\n\n Top-down usage reporting \n\nFrom the enterprise account, you can view resource usage from all accounts in the enterprise. Starting at the enterprise level, you see estimated usage costs that are broken down by account and account groups. You can navigate down within the enterprise structure to see the costs within each level.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-what-is-enterprise&interface=ui"}, {"document_id": "ibmcld_01705-7074-9036", "score": 12.75527, "text": "\nAlso, with a Pay-As-You-Go account, you can order Advanced or Premium support plans to get extra help with your production workloads. Learn more in [Basic, Advanced, and Premium Support plans](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans).\n\nA subset of Pay-As-You-Go accounts are eligible for the new Enterprise Savings Plan billing model. For more information, see [Enterprise Savings Plan billing model](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-committed-use).\n\n\n\n\n\n Subscription account \n\nSubscription accounts offer many of the same benefits as Pay-As-You-Go accounts, including access to the full IBM Cloud catalog and the ability to create multiple resource groups. In addition, Subscription accounts provide discounts for platform services and support and more consistent billing through subscriptions. You can also [set up spending notifications](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-spending) to get notified when your account or a particular service reaches a specific spending threshold that you set.\n\nWhen you purchase a subscription, you commit to a minimum spending amount for a certain period of time and receive a discount on the overall cost. For example, if you commit to spend $1,000 a month for 6 months, you might get a 5% discount. For the duration of the subscription, you get $6,000 of usage but pay only $5,700 for it. The larger the subscription, the better the discount.\n\nLarge organizations and other users with large cloud workloads can benefit from the savings and predictable billing that are provided by subscriptions. IBM Cloud offers multiple types of subscriptions to fit your usage needs.\n\nA subset of subscription accounts are eligible for the new Enterprise Savings Plan billing model. For more information, see [Enterprise Savings Plan billing model](https://cloud.ibm.com/docs/account?topic=account-accountscommitment-model).\n\n\n\n Platform subscriptions", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accounts"}, {"document_id": "ibmcld_03735-4449-4995", "score": 11.909137, "text": "\nAlso, if you're working with IBM Cloud Sales to set up a Subscription account or the Enterprise Savings Plan billing model, you can still be billed in your local currency.\n\n\n\nTable 1. Supported currencies\n\n ISO 4217 code Currency \n\n AUD Australian dollar \n BRL Brazilian real \n CAD Canadian dollar \n CHF Swiss franc \n DKK Danish krone \n EUR Euro \n GBP Pound sterling \n INR Indian rupee \n JPY Japanese yen \n KRW South Korean won \n NOK Norwegian krone \n NZD New Zealand dollar \n SEK Swedish krona \n USD United States dollar \n ZAR South African rand", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cost"}, {"document_id": "ibmcld_03785-1568-3189", "score": 11.654837, "text": "\nIf you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule).\n\n\n\n\n\n Can I spend more or less than my monthly commitment? \n\nYes, what you spend monthly is up to you! You can spend any amount of the total commitment each month.\n\n\n\n\n\n What happens if I spend my entire subscription amount before my term ends? \n\nYou're required to continue paying your monthly charges until the end of your term. You're charged the non-discounted rate for any usage that goes over your total subscription amount. To avoid overage charges, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) to sign up for a new subscription.\n\n\n\n\n\n Is there a monthly minimum amount required for Subscription accounts? \n\nYes, your subscription must have a combined minimum spending and term commitment of $100.00 USD each month for 12 months.\n\n\n\n\n\n Can I cancel my Subscription account before the end of my term commitment? \n\nA subscription is a contract between you and IBM that commits you to use IBM Cloud for a specific term and spending amount. You can request to cancel your subscription before the end of the term, but whether the subscription can be canceled is at the discretion of IBM. Any remaining credit on your subscription might be forfeited. For more information, contact [Support](https://cloud.ibm.com/unifiedsupport/supportcenter). Make sure that you provide details about why you need to cancel your subscription.\n\nTo close a Pay-As-You-Go account or a Lite account, see [Can I cancel my account?](https://cloud.ibm.com/docs/account?topic=account-accountfaqscancelaccount).", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription-account"}, {"document_id": "ibmcld_03787-1715-3825", "score": 11.540667, "text": "\nThe subscription is divided into two terms that each contain $12,000 of credit, with one term valid from 1 July 2019 through 30 June 2020, and the next term valid from 1 July 2020 through 30 June 2021. You can use the $12,000 credit of the first term at any time during its one-year period, whether it's $6,500 the first month and $500 a month afterward or $1,000 each month. If you spend $13,000 during that time period and don't have any other active subscriptions, the extra $1,000 is billed as overage.\n\nIf you have multiple subscriptions in your account that are valid at the same time, credit is spent from the individual subscription terms according to which one expires the soonest. Adding to the previous example, you might buy a new one-year subscription, 00432100, for $750 a month that starts 1 September 2019. As users in your account use resources, credit is deducted from the first term of your existing subscription, 01234567, because it expires first. When all its credit is spent, credit is then deducted from subscription 00432100 while it's valid.\n\n\n\nTable 1. Subscription credit spending order\n\n Subscription Credit Valid From Valid Until \n\n IBM Cloud Platform - 01234567, term 1 $12,000 1 July 2019 30 June 2020 \n IBM Cloud Platform - 00432100 $9,000 1 September 2019 31 August 2020 \n IBM Cloud Platform - 01234567, term 2 $12,000 1 July 2020 30 June 2021 \n\n\n\nSupport subscriptions that you buy after 24 September 2019 can be spent as described in this section, with credit being available for the entire subscription term. For support subscriptions that were bought before this date, credit is available on a month-to-month basis. When you buy or renew a support subscription, any existing active support subscriptions are converted to the term-based model for the remainder of their term.\n\nFor example, you might have a support subscription for $200 per month with three months remaining. When you buy a new support subscription, the existing subscription is converted to a new one with $600 of credit that can be used anytime within those three months.\n\n\n\n\n\n Viewing subscription usage", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03765-5710-7263", "score": 21.024395, "text": "\nClick Manual Payment and complete the fields in the one-time payment section. One-time payments are reviewed and processed each day. The account balance is updated after the payment is accepted. If a late fee is assessed and you have submitted a one-time payment, contact the [IBM Cloud Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\n\n\n\n\n\n\n Managing your payment method outside of the console \n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https://myibm.ibm.com/billing/) and log in with your IBMid and password. You are also required to enter the temporary passcode that's emailed to you.\n\nTo add a payment method, complete the following steps:\n\n\n\n1. Go to [ibm.com](http://www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your payment information, and click Register. A temporary passcode is emailed to you after the registration process is complete.\n\n\n\nAfter you register a payment method, when you click Manage payment method, you can view the Manage my wallet page to update or delete your payment methods by clicking the Edit icon ![Edit icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/edit-tagging.svg).", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusage"}, {"document_id": "ibmcld_03765-7-1896", "score": 20.982649, "text": "\nManaging payments \n\nDepending on your account type, you can easily manage your payment methods by using the [Payments](https://cloud.ibm.com/billing/payments) page in the IBM Cloud\u00ae console or by going to [IBM\u00ae Billing](https://myibm.ibm.com/billing/).\n\nA valid credit card is required for all Pay-As-You-Go and Subscription accounts. Every month, the credit card is charged with the usage amount that is accumulated during that month. When updates to your payment details are approved, they are applied to your account within 24 hours. The contact that is specified in the billing address section receives an email confirming that the updates are applied.\n\nYou can contact IBM Cloud Support to get help with payment-related issues. From the console menu bar, click the Help icon ![Help icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/help.svg) > Support center, and then click Create a case to get in touch.\n\n\n\n Before you begin \n\nTo manage payments, you need to be assigned the operator role or higher on the billing account management service. See [Assigning access to account management services](https://cloud.ibm.com/docs/account?topic=account-account-services) for more information.\n\n\n\n\n\n Managing payment methods for new US-based Pay-As-You-Go accounts with credit card billing \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, can you add multiple cards to the account, replace your default card with a saved one, or edit the details of a card. You manage your credit card from the [Payments](https://cloud.ibm.com/billing/payments) page in the IBM Cloud console.\n\nComplete the following steps to add a new payment method to the account:\n\n\n\n1. Click Add payment method.\n2. Enter the card details, and click Save. Updates to your card details are reflected immediately.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusage"}, {"document_id": "ibmcld_03776-6753-8705", "score": 19.054766, "text": "\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https://myibm.ibm.com/billing/).\n\nFor more information about how to manage your payments, see [Managing your payment method](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusageprereqs-payments).\n\n\n\n\n\n Tracking your usage \n\nTo view usage data for resources, you must be assigned the correct access. Access can be assigned at the account level or to individual resource groups and Cloud Foundry orgs.\n\n\n\n* To view usage for all resources in the account, you need an access policy with the Administrator role on the Billing account management service.\n* To view usage only for specific IBM Cloud Identity and Access Management (IAM) resources, you need the Viewer role or higher on the resource group.\n* To view usage for only specific Cloud Foundry services, the Billing manager role must be applied at the org level. Billing managers can see the details for only the organizations in which they are assigned the Billing manager role.\n\n\n\nYou can limit the access to view the usage for a specific resource group by assigning the viewer role or higher on all Identity and Access enabled services within that resource group.\n\n\n\n\n\n Managing your invoices \n\nIf you have a Pay-As-You-Go account that's billed in US dollars, you can view your invoice in the IBM Cloud console by going to Manage > Billing and usage, > and clicking Invoices.\n\nIf you own one of the following accounts, you can view your invoice on the [IBM Invoices](http://ibm.com/invoices) website, which is linked from the [Invoices page](https://cloud.ibm.com/billing/invoices) in the console.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-overview"}, {"document_id": "ibmcld_03704-4411-6289", "score": 19.006838, "text": "\nYou might manage your payment method on a separate billing platform, [IBM Billing](https://myibm.ibm.com/billing/). For more information about that process, see [Managing your payment method outside of the console](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https://cloud.ibm.com/unifiedsupport/cases) page in the IBM Cloud console to view the status of your request.\n\n\n\n\n\n Can I delete my credit card? \n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https://cloud.ibm.com/billing/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https://myibm.ibm.com/billing/). For more information, see [Managing your payment method outside of the console](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n\n\n How do I change the invoice currency from US Dollars to my local currency? \n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https://cloud.ibm.com/catalog?contactmodule) for more information.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-billusagefaqs"}, {"document_id": "ibmcld_07578-1045891-1047755", "score": 18.884298, "text": "\nYou might manage your payment method on a separate billing platform, [IBM Billing](https://myibm.ibm.com/billing/). For more information about that process, see [Managing your payment method outside of the console](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https://cloud.ibm.com/unifiedsupport/cases) page in the IBM Cloud console to view the status of your request.\n* Can I delete my credit card?\n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https://cloud.ibm.com/billing/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https://myibm.ibm.com/billing/). For more information, see [Managing your payment method outside of the console](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https://cloud.ibm.com/catalog?contactmodule) for more information.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1045762-1047626", "score": 18.884298, "text": "\nYou might manage your payment method on a separate billing platform, [IBM Billing](https://myibm.ibm.com/billing/). For more information about that process, see [Managing your payment method outside of the console](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https://cloud.ibm.com/unifiedsupport/cases) page in the IBM Cloud console to view the status of your request.\n* Can I delete my credit card?\n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https://cloud.ibm.com/billing/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https://myibm.ibm.com/billing/). For more information, see [Managing your payment method outside of the console](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https://cloud.ibm.com/catalog?contactmodule) for more information.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_03704-3030-4892", "score": 17.786413, "text": "\nIn the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-ts-ccibm)\n\n\n\n\n\n How do I change my payment method? \n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https://cloud.ibm.com/catalog?contactmodule) representative to inquire about payment options.\n\n\n\n\n\n Why didn't my credit card process? \n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https://myibm.ibm.com/billing/). For more information about that process, see [Managing your payment method outside of the console](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-billusagefaqs"}, {"document_id": "ibmcld_03765-1346-3055", "score": 17.291416, "text": "\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, can you add multiple cards to the account, replace your default card with a saved one, or edit the details of a card. You manage your credit card from the [Payments](https://cloud.ibm.com/billing/payments) page in the IBM Cloud console.\n\nComplete the following steps to add a new payment method to the account:\n\n\n\n1. Click Add payment method.\n2. Enter the card details, and click Save. Updates to your card details are reflected immediately.\n\n\n\nYou can\u2019t enter a PO Box as the billing address.\n\nWhen you add a new credit card, it becomes the default credit card. Recurring payments are charged to the default payment method.\n\nComplete the following steps to edit your active payment method:\n\n\n\n1. Click the Actions icon ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/action-menu-icon.svg) > Edit menu.\n2. To edit the billing address, click Edit and update the billing address.\n3. To edit the card details, click Edit and update the card number or expiration date.\n\n\n\nYou can only have one address that's associated with your payment methods. All credit cards in the account will be updated to the same address.\n\nComplete the following steps to set a new default payment method:\n\n\n\n1. Click the Actions icon ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/action-menu-icon.svg) > Set as default.\n2. Confirm that you want to make this payment method the default. The default payment method is charged for recurring payments\n\n\n\n\n\n\n\n Managing payment methods for all other accounts", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusage"}, {"document_id": "ibmcld_03765-4100-6125", "score": 16.891489, "text": "\nGo to the [Payments](https://cloud.ibm.com/billing/payments) page in the IBM Cloud console.\n2. Click Payment method.\n3. In the Add Payment Method section, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\n\n\nSome payment methods aren't accepted as recurring payment methods. You must manually submit the payment each month.\n\n\n\n\n\n India-based customers with accounts that are billed in US Dollars \n\nDue to current banking regulations, recurring credit card transactions might be unsuccessful for India-based customers with accounts that are billed in US Dollars. You can use one of the following methods to make a payment:\n\n\n\n* [Make a one-time payment](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagemakepayment)\n* Request to migrate your account to be billed in India Rupees. To make a request, provide a credit card that is billed in India Rupees on the [Payment Method](https://cloud.ibm.com/billing/payments) page in the IBM Cloud console. Specify that India Rupees are in the Payment Currency section. Additional information might be requested through a Support case during the migration process.\n\n\n\n\n\n\n\n Making a one-time payment \n\nYou can use a credit card to make a one-time payment at any time for any amount, whether it's for the full balance or a partial sum. The details that you enter for the one-time payment aren't recorded for future use, and aren't populated with a default amount.\n\nTo make a one-time payment, in the IBM Cloud console, go to Manage > Billing and usage, and select Payments. Click Manual Payment and complete the fields in the one-time payment section. One-time payments are reviewed and processed each day. The account balance is updated after the payment is accepted. If a late fee is assessed and you have submitted a one-time payment, contact the [IBM Cloud Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\n\n\n\n\n\n\n Managing your payment method outside of the console", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusage"}, {"document_id": "ibmcld_07578-1044428-1046278", "score": 16.85957, "text": "\nGo to the [Payments](https://cloud.ibm.com/billing/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https://cloud.ibm.com/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https://myibm.ibm.com/billing/). For more information about that process, see [Managing your payment method outside of the console](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16727-1068047-1069909", "score": 20.874105, "text": "\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https://www.ibm.com/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https://cloud.ibm.com/account/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https://cloud.ibm.com/registration). For more information, see [Managing subscriptions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule).\n* Can I spend more or less than my monthly commitment?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_16727-1066874-1068548", "score": 19.430582, "text": "\n[Download icon](https://cloud.ibm.com/icons/download.svg) and choose an invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet. In some cases, you are redirected to the [IBM Invoices website](https://www.ibm.com/invoices) where you can download your invoices. From the Invoices page, click the Actions icon ![Actions icon](https://cloud.ibm.com/icons/action-menu-icon.svg) and select the invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet.\n* Is paperless invoicing available?\n\nYes, you can switch to paperless invoices by submitting a request on the [IBM Customer Support site](https://www.ibm.com/support/customer/zz/en/selectcountrylang.html). For more information, see [Requesting paperless invoices](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoicesrequest-paperless-invoices).\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https://www.ibm.com/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-1065299-1067188", "score": 19.282637, "text": "\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https://www.ibm.com/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https://cloud.ibm.com/account/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https://cloud.ibm.com/registration). For more information, see [Managing subscriptions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes!", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_03771-1594-3365", "score": 18.604918, "text": "\nThe charges on your invoice are consistent with the usage dashboard. On the Invoices page in the console, click View usage to be directed to your usage dashboard. From there, you can select a timeframe and view billing and usage information that aligns directly with the details in your invoice.\n\n\n\n Checking your invoice status \n\nYou can check the status of your invoice on the [Invoices page](https://cloud.ibm.com/billing/invoices):\n\n\n\n* Invoiced: You received the latest invoice from IBM Cloud.\n* Paid: Your payment for the charges on your latest invoice was received.\n* Unpaid: The charges on your latest invoice have not been paid.\n* Pending: Your payment for your latest charges has not been applied due to a payment processing error. In this case, you can contact IBM Cloud Support for more details about the error.\n\n\n\nTurning a resource \"off\" doesn't cancel the resource in your account. You will receive invoices for resources in your account until you cancel them. For more information, see [Cancelling your billing items](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cancel-billing-items).\n\n\n\n\n\n Viewing and downloading your invoice \n\nView and download your invoice from the IBM console by clicking the Download icon ![Download icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/download.svg)> PDF invoice next to each invoice. For some accounts, invoices are available through the [Invoices@IBM](http://ibm.com/invoices) website. See the [Viewing and downloading invoices for all other accounts](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoicesviewing-external-invoices) section for more information.\n\n\n\n\n\n\n\n Viewing and downloading invoices for all other accounts", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoices"}, {"document_id": "ibmcld_03771-7-2029", "score": 17.826056, "text": "\nViewing your invoices \n\nTo manage and view your invoices, visit the [Invoices](https://cloud.ibm.com/billing/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console. If your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices.\n\nIn these situations, visit the [Invoices@IBM](http://ibm.com/invoices) website to see your invoices.\n\n\n\n Before you begin \n\nTo view your invoices, you need to be assigned the operator role or higher on the billing account management service. For more information, see [Assigning access to account management services](https://cloud.ibm.com/docs/account?topic=account-account-services).\n\n\n\n\n\n Viewing invoices for new US-based Pay-As-You-Go accounts with credit card billing \n\nNew IBM Cloud Pay-As-You-Go accounts for US customers with credit card billing can now view all classic infrastructure and platform services on one invoice. In the IBM Cloud console, go to Manage > Billing and usage, and select Invoices.\n\nThe new invoice hierarchy highlights the most important details. By showcasing when the usage is measured, you can view each invoice\u2019s billing period in a clarified and comprehensive manner. The adjustments section on your invoice provides details about credits and adjustments from previous billing periods that might be included on an invoice from a different month.\n\nThe charges on your invoice are consistent with the usage dashboard. On the Invoices page in the console, click View usage to be directed to your usage dashboard. From there, you can select a timeframe and view billing and usage information that aligns directly with the details in your invoice.\n\n\n\n Checking your invoice status \n\nYou can check the status of your invoice on the [Invoices page](https://cloud.ibm.com/billing/invoices):", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoices"}, {"document_id": "ibmcld_03764-2220-3440", "score": 17.766714, "text": "\n[Actions icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/action-menu-icon.svg) and select the invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet.\n\n\n\n\n\n Is paperless invoicing available? \n\nYes, you can switch to paperless invoices by submitting a request on the [IBM Customer Support site](https://www.ibm.com/support/customer/zz/en/selectcountrylang.html). For more information, see [Requesting paperless invoices](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoicesrequest-paperless-invoices).\n\n\n\n\n\n What are the adjustments that are shown on my invoice? \n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n\n\n\n\n\n How do I know if my invoice is paid? \n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https://www.ibm.com/invoices), it's paid when the status is Settled.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-invoice-faq"}, {"document_id": "ibmcld_03771-2998-4769", "score": 16.73309, "text": "\nFor some accounts, invoices are available through the [Invoices@IBM](http://ibm.com/invoices) website. See the [Viewing and downloading invoices for all other accounts](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoicesviewing-external-invoices) section for more information.\n\n\n\n\n\n\n\n Viewing and downloading invoices for all other accounts \n\nIf you own one of the following accounts, you can view your invoice on the [Invoices@IBM](http://ibm.com/invoices) website, which is linked from the [Invoices page](https://cloud.ibm.com/billing/invoices) in the IBM console.\n\n\n\n* New and existing Pay-As-You-Go accounts that are based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nTo save a copy of your invoice, click the PDF icon in the Invoice Number column. Then, click the Download icon ![Download icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/download.svg).\n\n\n\n Getting access to Invoices@IBM \n\nIf you are attempting to access the [Invoices@IBM](http://ibm.com/invoices) website for the first time, you can sign up with your IBMid, complete your profile, and provide your IBM customer number to access your account. Your IBM customer number is used for identification purposes during your registration process with the IBM Invoices page and during other interactions with [IBM Support](https://www.ibm.com/support/home/).\n\nTo ensure that access is granted to the correct individuals, you must register using an email address that includes your company's domain, such as ibm.com. Requests using personal, non-company-specific email addresses might not be approved.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoices"}, {"document_id": "ibmcld_07578-1064084-1065746", "score": 16.646486, "text": "\nFor more information, see [Managing migrated SoftLayer account permissions](https://cloud.ibm.com/docs/account?topic=account-migrated_permissions).\n* How can I download my invoice?\n\nTo download your invoice, go to Manage > Billing and usage, and select Invoices. Then, click the Download icon ![Download icon](https://cloud.ibm.com/icons/download.svg) and choose an invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet. In some cases, you are redirected to the [IBM Invoices website](https://www.ibm.com/invoices) where you can download your invoices. From the Invoices page, click the Actions icon ![Actions icon](https://cloud.ibm.com/icons/action-menu-icon.svg) and select the invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet.\n* Is paperless invoicing available?\n\nYes, you can switch to paperless invoices by submitting a request on the [IBM Customer Support site](https://www.ibm.com/support/customer/zz/en/selectcountrylang.html). For more information, see [Requesting paperless invoices](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoicesrequest-paperless-invoices).\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_03764-7-1642", "score": 16.5315, "text": "\nFAQs for invoices \n\nReview the following FAQs to find helpful information about invoices. To find all FAQs for IBM Cloud\u00ae, see our [FAQ library](https://cloud.ibm.com/docs/faqs).\n\n\n\n Where can I access my invoice? \n\nIf you have a billable account, you can access your invoice by clicking Manage > Billing and usage, and selecting Invoices. If you have a Lite account, you don't have an invoice because you're never charged for Lite plan usage.\n\nYou might be redirected to [IBM Invoices website](https://www.ibm.com/invoices). See [How do I view invoices for Pay-As-You-Go or Subscription accounts?](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-ts_cant-view-invoice) and [Viewing your invoices](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoices) for more information.\n\n\n\n\n\n Why does my usage not match my invoice? \n\nYour usage might not match your invoice because the months that are used to compare usage aren't the same, or the total amount of the orgs wasn't selected. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage). If it still doesn't match, get in touch with us by calling 1-866-325-0045 and choosing the third option, or by opening a [support case](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\n\n\n\n\n Why can't I manage my invoices? \n\nYou might not have the correct permissions. Ask your account owner to add you to the View account summary access group. For more information, see [Managing migrated SoftLayer account permissions](https://cloud.ibm.com/docs/account?topic=account-migrated_permissions).", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-invoice-faq"}, {"document_id": "ibmcld_07578-1062822-1064465", "score": 16.492338, "text": "\nIf you have a billable account, you can access your invoice by clicking Manage > Billing and usage, and selecting Invoices. If you have a Lite account, you don't have an invoice because you're never charged for Lite plan usage.\n\nYou might be redirected to [IBM Invoices website](https://www.ibm.com/invoices). See [How do I view invoices for Pay-As-You-Go or Subscription accounts?](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-ts_cant-view-invoice) and [Viewing your invoices](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoices) for more information.\n* Why does my usage not match my invoice?\n\nYour usage might not match your invoice because the months that are used to compare usage aren't the same, or the total amount of the orgs wasn't selected. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage). If it still doesn't match, get in touch with us by calling 1-866-325-0045 and choosing the third option, or by opening a [support case](https://cloud.ibm.com/unifiedsupport/supportcenter).\n* Why can't I manage my invoices?\n\nYou might not have the correct permissions. Ask your account owner to add you to the View account summary access group. For more information, see [Managing migrated SoftLayer account permissions](https://cloud.ibm.com/docs/account?topic=account-migrated_permissions).\n* How can I download my invoice?\n\nTo download your invoice, go to Manage > Billing and usage, and select Invoices. Then, click the Download icon ![Download icon](https://cloud.ibm.com/icons/download.svg) and choose an invoice format.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03710-0-838", "score": 24.99363, "text": "\n\n\n\n\n\n\n  Why can't I apply a subscription code? \n\nTo successfully apply a subscription code, make sure the code is valid and you have the required access.\n\n  What\u2019s happening \n\nWhen you try to apply a subscription code, you see an error that states that the code cannot be applied.\n\n  Why it\u2019s happening \n\nYou might see this error if you don't have the required access in the account or the code expired.\n\n  How to fix it \n\nUse the following options:\n\n\n\n*  Verify that you have access to apply the code. To apply any code, you must have an Editor role or higher on all account management services. To view or change roles, see [Assigning access to account management services](https://cloud.ibm.com/docs/account?topic=account-account-services).\n*  Contact the person who provided the code for help with reissuing an expired code.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cannot-apply-subscription-code"}, {"document_id": "ibmcld_03786-7-2105", "score": 23.859097, "text": "\nApplying subscription codes \n\nAfter you buy a subscription for platform or support credit, you must add the credit to your account by applying a subscription code to an existing account or a new account when you register. Applying the code ensures that the credit is added to your account and you don't have unexpected overage charges.\n\nIf you set up your first subscription through the [Subscriptions page](https://cloud.ibm.com/billing/subscriptions), the credit for this subscription is automatically added to your account - no code required.\n\nAfter IBM Cloud Sales places the order, an email with the subscription code for each subscription and support line item is sent to the appropriate contact.\n\nOnly the account owner, enterprise account owner, or a user with the Editor or Administrator role on the Billing account management service can apply the subscription code. If you don't have access to apply subscription codes, the account owner or administrator can provide access. For more information, see [Assigning access to account management services](https://cloud.ibm.com/docs/account?topic=account-account-services). Applying the subscription code through the IBM Cloud\u00ae console is essential to ensure that your account is migrated appropriately.\n\n\n\n1. Open the email with the subscription code.\n\nIf you bought a subscription and didn't receive your subscription code, [contact us](https://www.ibm.com/cloud?contactmodule) or email Sales at [CloudDigitalSales@us.ibm.com](mailto:CloudDigitalSales@us.ibm.com) to request for it to be sent again.\n2. Click Add subscription to add it to an existing account.\n3. Sign in to the console with your IBMid and password.\n4. From the modal, choose the account you'd like to add the subscription to, select I understand, and then click Add.\n\n\n\nTo manually apply the subscription code to an existing account, complete the following steps:\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings.\n2. Click Apply code.\n\nEach code can be redeemed only one time, and the codes must be redeemed before their expiration date.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code"}, {"document_id": "ibmcld_03786-1684-3421", "score": 22.537994, "text": "\nFrom the modal, choose the account you'd like to add the subscription to, select I understand, and then click Add.\n\n\n\nTo manually apply the subscription code to an existing account, complete the following steps:\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings.\n2. Click Apply code.\n\nEach code can be redeemed only one time, and the codes must be redeemed before their expiration date. Ensure that you add the code to the correct account because the subscription credits can't be removed after the code is applied. After you add the subscription code, you might see that the status of the subscription as IN_PROCESS. Contact IBM Cloud Sales to review the account.\n3. Enter the subscription code, and click Apply.\n\nIf you have separate codes for platform and support credit, apply the platform subscription code first, then apply the support subscription code.\n\n\n\nTo manually apply the subscription code to a new account, complete the following steps:\n\n\n\n1. Go [create an IBM Cloud account](https://cloud.ibm.com/registration), and enter the required information.\n2. Click Register with a code instead of entering your credit card information.\n3. Click Create account.\n\n\n\nIf you don't know your seller, the codes are applied in the wrong order, or you experience issues with applying the codes, [contact IBM Cloud Support](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar).\n\nFor information about other codes and credits that can be applied to different account types, see [Applying feature codes to a Lite account](https://cloud.ibm.com/docs/account?topic=account-codes) or [Applying promo codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code"}, {"document_id": "ibmcld_03785-7-2010", "score": 22.289669, "text": "\nFAQs for subscription accounts \n\nFAQs for subscription accounts include entries about subscription credit, subscription terms, and other subscription-related self-help information.\n\n\n\n How do I add subscription credit to my account? \n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https://cloud.ibm.com/account/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https://cloud.ibm.com/registration). For more information, see [Managing subscriptions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n\n\n\n\n\n What does the IN_PROGRESS status mean when I apply a subscription code? \n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n\n\n\n\n\n Can I pay the total spending commitment up-front or quarterly? \n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule).\n\n\n\n\n\n Can I spend more or less than my monthly commitment? \n\nYes, what you spend monthly is up to you! You can spend any amount of the total commitment each month.\n\n\n\n\n\n What happens if I spend my entire subscription amount before my term ends? \n\nYou're required to continue paying your monthly charges until the end of your term.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription-account"}, {"document_id": "ibmcld_12597-0-804", "score": 21.7227, "text": "\n\n\n\n\n\n\n  Why can't I apply a subscription code to my account in an enterprise? \n\nA subscription code can't be added to the account because of specific access that is required.\n\n  What\u2019s happening \n\nYou can't add a subscription code to your IBM Cloud\u00ae account because you don't have the correct access.\n\n  Why it\u2019s happening \n\nBecause your account is a child account on the enterprise, you can't apply subscription codes. Subscription codes must be applied at the enterprise level.\n\n  How to fix it \n\nContact the owner or the administrator of the enterprise to add the subscription code. When the subscription code is added, it applies to all accounts in the enterprise. For more information, see [Managing subscriptions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-troubleshoot-promo-enterprise"}, {"document_id": "ibmcld_16727-1068047-1069909", "score": 20.653366, "text": "\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https://www.ibm.com/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https://cloud.ibm.com/account/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https://cloud.ibm.com/registration). For more information, see [Managing subscriptions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule).\n* Can I spend more or less than my monthly commitment?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_03787-5002-7004", "score": 20.533564, "text": "\nA subscription is inactive if its term expires or all of its credit is spent.\n\n\n\nYou can use the spending and usage information on the Subscriptions page to evaluate whether your subscriptions suit your usage needs. For example, if you consistently have overages, you might increase your monthly spending commitment to save money on that usage. To buy new subscriptions or change future subscription amounts, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule).\n\n\n\n\n\n Support subscriptions \n\nTo view support subscription usage, in the console, go to Manage > Billing and usage, and select Support costs. You can view the remaining credit in your active support subscriptions and any upcoming subscriptions that aren't yet valid. For more information, see [Viewing your support costs](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-support).\n\n\n\n\n\n\n\n Subscription credit \n\nAfter you buy a subscription for platform or support credit, you add the credit to your account by applying a subscription code. Applying the code ensures that the credit is added to your account and you don't have unexpected overage charges.\n\nFor more information, see [Applying subscription codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code).\n\n\n\n\n\n Expiring subscriptions \n\nYou are notified by email 60, 30, 14, and 1 day before the expiration date of the last subscription on the account. After the subscription expires, your account is converted to a Pay-As-You Go account, which means you pay only for billable services that you use with no contracts or commitments. The discounts that are associated with the subscription account won't apply to the Pay-As-You-Go account. The IBM Sales team is happy to help extend your subscription before you reach its expiration date. If you extend your subscription within 30 days from the expiration date, you won't get charged at the Pay-As-You-Go account rate. After 30 days, you are invoiced as a Pay-As-You-Go account.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions"}, {"document_id": "ibmcld_03732-0-1673", "score": 20.230343, "text": "\n\n\n\n\n\n\n  Applying feature codes \n\nYou can apply feature codes to take advantage of extra IBM Cloud\u00ae resources or capabilities. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops.\n\nAre you looking for details about adding subscription credit to your account? See [Managing subscriptions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions) for more information.\n\nYou must have the Editor role or higher for all account management services to apply a feature code. The extra resources or capabilities that are provided vary depending on the particular code but include one or more of the following items in general:\n\n\n\n*  Increase the memory quota to a number of GB that is specified by the code\n*  Add one organization with a memory quota that is specified by the code\n*  Add an unlimited number of organizations\n*  Upload an extra number of SSL certificates, as specified by the code\n*  Use premium service plans\n*  Convert a Lite account to a trial account, which provides access to more services but only within a limited trial period\n\n\n\nComplete the following steps to apply a feature code to your existing account:\n\nIf you don't have an account yet, you can add your feature code when you [register](https://cloud.ibm.com/registration) for a new account by clicking Register with a code instead of entering your credit card information.\n\n\n\n1.  In the IBM Cloud console, go to Manage > Account, and select Account settings.\n2.  Click Apply code.\n3.  Enter the feature code, which is typically a random alphanumeric value such as a1b2c3def456.\n4.  Click Apply.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-codes"}, {"document_id": "ibmcld_03704-10459-12479", "score": 20.154974, "text": "\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter) and click Create a case.\n\n\n\n\n\n How do I apply a feature code? \n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https://cloud.ibm.com/account/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https://cloud.ibm.com/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code).\n\n\n\n\n\n Why did my account get billed for additional services charges? \n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https://cloud.ibm.com/docs/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-billusagefaqs"}, {"document_id": "ibmcld_07578-1066746-1068772", "score": 19.752771, "text": "\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule).\n* Can I spend more or less than my monthly commitment?\n\nYes, what you spend monthly is up to you! You can spend any amount of the total commitment each month.\n* What happens if I spend my entire subscription amount before my term ends?\n\nYou're required to continue paying your monthly charges until the end of your term. You're charged the non-discounted rate for any usage that goes over your total subscription amount. To avoid overage charges, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) to sign up for a new subscription.\n* Is there a monthly minimum amount required for Subscription accounts?\n\nYes, your subscription must have a combined minimum spending and term commitment of $100.00 USD each month for 12 months.\n* Can I cancel my Subscription account before the end of my term commitment?\n\nA subscription is a contract between you and IBM that commits you to use IBM Cloud for a specific term and spending amount. You can request to cancel your subscription before the end of the term, but whether the subscription can be canceled is at the discretion of IBM. Any remaining credit on your subscription might be forfeited. For more information, contact [Support](https://cloud.ibm.com/unifiedsupport/supportcenter). Make sure that you provide details about why you need to cancel your subscription.\n\nTo close a Pay-As-You-Go account or a Lite account, see [Can I cancel my account?]", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>10", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03709-0-1479", "score": 19.555931, "text": "\n\n\n\n\n\n\n  Why can't I apply a feature code? \n\nTo successfully apply a feature code, make sure the code is valid and that you have the correct account type.\n\n  What\u2019s happening \n\nWhen you try to apply a feature code, you see an error that states that the code cannot be applied.\n\n  Why it\u2019s happening \n\nYou might see this error for any of the following reasons:\n\n\n\n*  Your account doesn't meet the requirements for the feature code.\n*  You don't have the required access in the account.\n*  The code expired.\n\n\n\n  How to fix it \n\nUse the following steps to successfully apply a feature code:\n\n\n\n*  Verify that you have the correct account type. For example, some feature codes for educational promotions are only for Lite accounts. To view your account type, in the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings. For more information, see [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n*  Verify that you have access to apply the code. To apply any code, you must have an Editor role or higher on all account management services. To view or change roles, see [Assigning access to account management services](https://cloud.ibm.com/docs/account?topic=account-account-services).\n*  Contact the person who provided the code for help with reissuing an expired code.\n*  If you are unable to apply a feature code that you received from an educational provider, contact that educational provider for further assistance.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cannot-apply-feature-code"}, {"document_id": "ibmcld_03732-0-1673", "score": 18.161581, "text": "\n\n\n\n\n\n\n  Applying feature codes \n\nYou can apply feature codes to take advantage of extra IBM Cloud\u00ae resources or capabilities. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops.\n\nAre you looking for details about adding subscription credit to your account? See [Managing subscriptions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions) for more information.\n\nYou must have the Editor role or higher for all account management services to apply a feature code. The extra resources or capabilities that are provided vary depending on the particular code but include one or more of the following items in general:\n\n\n\n*  Increase the memory quota to a number of GB that is specified by the code\n*  Add one organization with a memory quota that is specified by the code\n*  Add an unlimited number of organizations\n*  Upload an extra number of SSL certificates, as specified by the code\n*  Use premium service plans\n*  Convert a Lite account to a trial account, which provides access to more services but only within a limited trial period\n\n\n\nComplete the following steps to apply a feature code to your existing account:\n\nIf you don't have an account yet, you can add your feature code when you [register](https://cloud.ibm.com/registration) for a new account by clicking Register with a code instead of entering your credit card information.\n\n\n\n1.  In the IBM Cloud console, go to Manage > Account, and select Account settings.\n2.  Click Apply code.\n3.  Enter the feature code, which is typically a random alphanumeric value such as a1b2c3def456.\n4.  Click Apply.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-codes"}, {"document_id": "ibmcld_03711-0-822", "score": 16.628561, "text": "\n\n\n\n\n\n\n  Why can\u2019t I create a service after I apply a feature code? \n\nYou can recover from issues with creating service after a feature code is applied by following a few easy steps.\n\n  What\u2019s happening \n\nWhen you try to create an instance of a service from the catalog, you're prompted to upgrade with a message such as Upgrade your account to create instances of the offering.\n\n  Why it\u2019s happening \n\nYour account wasn't enabled to create resources of that type after you applied the feature code. The resources or capabilities that are provided vary for each feature code.\n\n  How to fix it \n\nContact the person who gave you the feature code to verify the capabilities that it can enable for your account. For example, contact your educational provider for feature codes that they gave you for use with coursework.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cant-create-service-feature-code"}, {"document_id": "ibmcld_03704-10459-12479", "score": 15.354052, "text": "\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter) and click Create a case.\n\n\n\n\n\n How do I apply a feature code? \n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https://cloud.ibm.com/account/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https://cloud.ibm.com/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code).\n\n\n\n\n\n Why did my account get billed for additional services charges? \n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https://cloud.ibm.com/docs/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-billusagefaqs"}, {"document_id": "ibmcld_07578-1051890-1053900", "score": 14.852148, "text": "\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter) and click Create a case.\n* How do I apply a feature code?\n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https://cloud.ibm.com/account/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https://cloud.ibm.com/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code).\n* Why did my account get billed for additional services charges?\n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https://cloud.ibm.com/docs/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1051761-1053771", "score": 14.852148, "text": "\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter) and click Create a case.\n* How do I apply a feature code?\n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https://cloud.ibm.com/account/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https://cloud.ibm.com/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code).\n* Why did my account get billed for additional services charges?\n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https://cloud.ibm.com/docs/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-1048947-1050776", "score": 14.851178, "text": "\nThe codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops. They're typically random alphanumeric codes, like a1b2c3def456. For more information about feature codes, see [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n* Where can I get a promo code?\n\nPromo codes are provided on a limited basis by IBM Cloud sales to customers with Pay-As-You-Go and Subscription accounts. Promotions provide specific discounts for a set amount of time. For more information, see [Applying promo codes](https://cloud.ibm.com/docs/account?topic=billing-usage-applying-promo-codes).\n* Where can I get a feature code?\n\nFeature codes are provided by IBM Cloud sales and educational providers on a limited basis. Feature codes are meant for select groups and are typically given out at hackathons, conferences, and other events. If you are taking a course through an educational provider and need additional resources to complete the course, contact your educational provider to determine if a feature code is applicable.\n* How do I apply a promo code?\n\nTo apply your promo code, go to the [Promotions](https://cloud.ibm.com/billing/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1048818-1050647", "score": 14.851178, "text": "\nThe codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops. They're typically random alphanumeric codes, like a1b2c3def456. For more information about feature codes, see [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n* Where can I get a promo code?\n\nPromo codes are provided on a limited basis by IBM Cloud sales to customers with Pay-As-You-Go and Subscription accounts. Promotions provide specific discounts for a set amount of time. For more information, see [Applying promo codes](https://cloud.ibm.com/docs/account?topic=billing-usage-applying-promo-codes).\n* Where can I get a feature code?\n\nFeature codes are provided by IBM Cloud sales and educational providers on a limited basis. Feature codes are meant for select groups and are typically given out at hackathons, conferences, and other events. If you are taking a course through an educational provider and need additional resources to complete the course, contact your educational provider to determine if a feature code is applicable.\n* How do I apply a promo code?\n\nTo apply your promo code, go to the [Promotions](https://cloud.ibm.com/billing/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_03704-7496-9340", "score": 14.797458, "text": "\nThe codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops. They're typically random alphanumeric codes, like a1b2c3def456. For more information about feature codes, see [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n\n\n\n\n\n Where can I get a promo code? \n\nPromo codes are provided on a limited basis by IBM Cloud sales to customers with Pay-As-You-Go and Subscription accounts. Promotions provide specific discounts for a set amount of time. For more information, see [Applying promo codes](https://cloud.ibm.com/docs/account?topic=billing-usage-applying-promo-codes).\n\n\n\n\n\n Where can I get a feature code? \n\nFeature codes are provided by IBM Cloud sales and educational providers on a limited basis. Feature codes are meant for select groups and are typically given out at hackathons, conferences, and other events. If you are taking a course through an educational provider and need additional resources to complete the course, contact your educational provider to determine if a feature code is applicable.\n\n\n\n\n\n How do I apply a promo code? \n\nTo apply your promo code, go to the [Promotions](https://cloud.ibm.com/billing/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-billusagefaqs"}, {"document_id": "ibmcld_09087-78546-80790", "score": 14.309728, "text": "\nThis action is not permitted on this resource: Please contact IBM Key Protect or open a service ticket to enable this feature\n\nReason code: FEATURE_RESTRICTED_ERR\n\n\n\n\n\n HTTP status code \n\n403 - Forbidden\n\nThe HTTP 403 Forbidden client error status response code indicates that the server understood the request but refuses to authorize it.\n\nThis status is similar to 401, but in this case, re-authenticating will make no difference. The access is permanently forbidden and tied to the application logic, such as insufficient rights to a resource.\n\n\n\n\n\n Context \n\nYou are attempting to create, update, or use an instance policy with a feature that is not supported.\n\nFor example, instance policy was created for an allowedIp address range, which only supports IPv4 addresses. You then made a request to the instance with an IPv6 address, which returns this error.\n\n\n\n\n\n\n\n 32 - This request requires that the key version... \n\n\n\n Message \n\nThis request requires that the key version is later than current registration key version\n\nReason code: KEY_VERSION_INVALID\n\n\n\n\n\n HTTP status code \n\n422 - Unprocessable Entity\n\nThe HTTP 422 Unprocessable Entity response status code indicates that the server understands the content type of the request entity, and the syntax of the request entity is correct, but it was unable to process the contained instructions.\n\nThe client should not repeat this request without modification.\n\n\n\n\n\n Context \n\nThis error applies to keys used for \"Registrations.\"\n\nWhen a service, such as Cloud Object Storage (COS), tries to replace or restore a key it checks the timestamp of the key.\n\nIf the key timestamp is less than the timestamp of the key used by the registration then this error occurs.\n\nThe key used buy the service must have a timestamp equal to or greater than the registration's key.\n\nRegistrations are associations between root keys and other cloud resources, such as Cloud Object Storage (COS) buckets or Cloud Databases deployments.\n\nFor more information about Registrations, see [viewing associations between root keys and encrypted IBM Cloud resources](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources).\n\n\n\n\n\n\n\n 33 - This root key has been rotated within... \n\n\n\n Message", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-error-messages"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>11", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03713-7-2194", "score": 25.344416, "text": "\nCredit Card error messages \n\nAn issue might occur when you try to update, add, or remove a credit card. Review the following credit card error messages for detailed self-help information.\n\n\n\n Why was my credit card transaction rejected? \n\nProtecting your identity is a priority and IBM Cloud takes credit card verification seriously.\n\n What\u2019s happening \n\nAn issue occurred that caused the transaction to fail. For example, the name and address on file with IBM Cloud doesn't match the information on file with the company that issued your credit card. This error might prompt the following message:\n\n> Error: Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the transaction wasn't successful.\n\n How to fix it \n\nTo ensure that your credit card verification is successful, complete the following steps:\n\n\n\n1. Verify that the name and address for your IBM Cloud account matches the name and address on file with your credit card issuer.\n2. Verify that the country associated with a VAT or tax identification number matches the country in your IBM Cloud account. For example, a VAT ID registered in France can't be associated with an IBM Cloud account that is registered in Finland.\n3. Verify that you are creating a business account and not a personal account if you are specifying a VAT ID or tax identification number.\n4. Review the error message that was displayed. If your transaction was rejected and an email address was not provided, contact your credit card issuer.\n5. Contact us by calling 1-866-325-0045 and selecting the third option.\n\n\n\n\n\n\n\n Why do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03713-1710-3705", "score": 23.472786, "text": "\nWhy do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the update wasn't successful.\n\n How to fix it \n\nGo to the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter) and click Create a case.\n\n\n\n\n\n Why was there a general decline of my credit card? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card inactive or not authorized? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03782-0-720", "score": 22.38745, "text": "\n\n\n\n\n\n\n  Why do I get a section error when I try to provide credit card information? \n\nYou are unable to complete the registration of a new account or to update the credit card information on an existing account because the Credit Card information section can\u2019t be loaded.\n\n  What\u2019s happening \n\nThe following error appears in the Credit Card information section of the form:\n\n> This section can\u2019t be loaded.\n\n  Why it\u2019s happening \n\nA network issue might affect the loading of this section of the form.\n\n  How to fix it \n\nYou can troubleshoot potential network problems by using a private or incognito window, by trying without a VPN or with a different VPN, or by using a browser on a different computer or device.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-section-error"}, {"document_id": "ibmcld_03713-7896-8949", "score": 21.321846, "text": "\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved. Please try another card.\n\n Why it\u2019s happening \n\nYour card information was incorrect.\n\n How to fix it \n\nUse a different credit card to process your transaction.\n\n\n\n\n\n Why was my credit card declined? \n\n What\u2019s happening \n\nAn issue occurred that caused your credit card to decline. This error might prompt the following message:\n\n> Your payment was declined for invoice number\u2026\n\n Why it\u2019s happening \n\nYou have a credit card on file and it was declined.\n\n How to fix it \n\nUpdate your credit card information on the [Payments page](https://cloud.ibm.com/billing/payments). Credit card transactions are automatically retried within 24 hours after you update the information.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03713-6236-8279", "score": 18.891115, "text": "\nFor more information, see [Personal use availability](https://cloud.ibm.com/docs/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> There was an error in the payment process: We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is the transaction already processed? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Transaction already processed.\n\n Why it\u2019s happening \n\nOur payment system has detected multiple similar payments within a short period of time. IBM Cloud is attempting to avoid unintentional duplicate payments.\n\n How to fix it \n\nWait 3-4 hours for the manual payment to be processed and posted to your IBM Cloud} account. Verify your account balance on the [Payments page](https://cloud.ibm.com/billing/payments).\n\n\n\n\n\n Why can't I upgrade my account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your account couldn't be upgraded. Click Upgrade account to try again.\n\n Why it\u2019s happening \n\nIBM Cloud} was unable to process your transaction.\n\n How to fix it \n\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_02273-0-665", "score": 18.460209, "text": "\n\n\n\n\n\n\n  Why can't I submit the form to add my credit card information? \n\nYou can't submit your credit card information to upgrade your Lite account to a billable account.\n\n  What\u2019s happening \n\nThe Upgrade account button is disabled.\n\n  Why it\u2019s happening \n\nThis problem happens when your information isn't entered correctly.\n\n  How to fix it \n\nComplete the following steps:\n\n\n\n1.  Complete all of the required fields to add your credit card and billing information in the IBM Cloud console.\n\nEnsure that you specified a business account and not a personal account type, if you are providing a VAT ID or tax identification number.\n2.  Click Upgrade account.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-ts_addcc"}, {"document_id": "ibmcld_07578-1071351-1073249", "score": 17.857086, "text": "\nSome countries where the local government requires it, taxes are charged directly instead.\n* How do I update my credit card?\n\nIf you have a Pay-As-You-Go account type that is billed in US Dollars, complete the following steps:\n\n\n\n1. Go to the [Payments](https://cloud.ibm.com/billing/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.\n\n\n\nTo switch to a different payment method, select Pay with Other and then click Submit change request. A support case to change your payment method is created for you.\n\nBased on your account type, you might manage your credit card outside of the console. To manage your credit card outside of the console, complete the following steps:\n\n\n\n1. Go to [ibm.com](http://www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https://cloud.ibm.com/icons/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your credit card information, and click Register.\n\n\n\nIf your credit card requires a MasterCard SecureCode that is sent to a mobile phone, you might see an unexpected error message after you submit the code. Refresh the manage my wallet page to verify that your new credit card information is saved.\n* How do I upgrade my account?\n\nTo upgrade your Lite account, go to your [account settings](https://cloud.ibm.com/account/settings). In the Account Upgrade section, click Add credit card to upgrade to a Pay-As-You-Go account, or click Upgrade for a Subscription account.\n\nSee [Upgrading your account](https://cloud.ibm.com/docs/account?topic=account-upgrading-account) for more information.\n* If I upgrade my Lite account, can I continue to use my existing instances?\n\nYes, when you upgrade to a Pay-As-You-Go or Subscription account, you can continue to use the instances that you created with your Lite account.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_01660-2990-4730", "score": 17.61465, "text": "\nGo to the [Payments](https://cloud.ibm.com/billing/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.\n\n\n\nTo switch to a different payment method, select Pay with Other and then click Submit change request. A support case to change your payment method is created for you.\n\nBased on your account type, you might manage your credit card outside of the console. To manage your credit card outside of the console, complete the following steps:\n\n\n\n1. Go to [ibm.com](http://www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your credit card information, and click Register.\n\n\n\nIf your credit card requires a MasterCard SecureCode that is sent to a mobile phone, you might see an unexpected error message after you submit the code. Refresh the manage my wallet page to verify that your new credit card information is saved.\n\n\n\n\n\n How do I upgrade my account? \n\nTo upgrade your Lite account, go to your [account settings](https://cloud.ibm.com/account/settings). In the Account Upgrade section, click Add credit card to upgrade to a Pay-As-You-Go account, or click Upgrade for a Subscription account.\n\nSee [Upgrading your account](https://cloud.ibm.com/docs/account?topic=account-upgrading-account) for more information.\n\n\n\n\n\n If I upgrade my Lite account, can I continue to use my existing instances? \n\nYes, when you upgrade to a Pay-As-You-Go or Subscription account, you can continue to use the instances that you created with your Lite account.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accountfaqs"}, {"document_id": "ibmcld_16727-1072450-1074392", "score": 17.57239, "text": "\nFor more information about issues with credit card authorization, see [Credit Card error messages](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages).\n* How do I get help with issues with creating an account?\n\nIf you are able to log in to an IBM Cloud account, go to the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter) and choose one of the following options.\n\n\n\n* If you have advanced or premium support, click Chat with IBM to talk to an IBM Cloud support representative.\n* Create a support case by clicking Create a case from the Need more help? section.\n\nAfter you open the case, an email notification is sent to you. Follow the instructions for further communication.\n\n\n\nIf you can't log in to an IBM Cloud account, [create an account request](https://watson.service-now.com/x_ibmwc_open_case_app.do!/create).\n* Why is a VAT ID required when I create an account?\n\nA tax identification number, such as a VAT ID, GST number, or TIN, is required to create a new personal use account with an address in specific countries or regions. For information about these requirements or where personal use accounts are not permitted, see [Personal use availability](https://cloud.ibm.com/docs/account?topic=account-account-getting-startedsignup-personalaccts). A tax identification number is also required for company accounts depending on your location. Some countries where the local government requires it, taxes are charged directly instead.\n* How do I update my credit card?\n\nIf you have a Pay-As-You-Go account type that is billed in US Dollars, complete the following steps:\n\n\n\n1. Go to the [Payments](https://cloud.ibm.com/billing/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.\n\n\n\nTo switch to a different payment method, select Pay with Other and then click Submit change request. A support case to change your payment method is created for you.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_02301-1556-3330", "score": 17.545767, "text": "\nFor any billable services that you use beyond any free allowances, you receive a monthly invoice.\n\nIf you're upgrading to reactivate a deactivated account, your account might take a few days to be fully available. If your account continues to be in a pending state, see [Why can't I upgrade my account?](https://cloud.ibm.com/docs/account?topic=account-ts_upgrade_cc) for help.\n\nIf you can't upgrade your account because of an issue with your credit card, see [Troubleshooting credit card error messages](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages) for more information.\n\n\n\n\n\n Promotional credit for upgrading your account \n\nAfter you sign up for a new Pay-As-You-Go account or upgrade your free account, you'll receive a promotional credit to use on any IBM product. To view the list of eligible products, go to the IBM Cloud console and select Catalog > Provider > IBM.\n\nThe credit might take a few hours to appear in your account. Any unused upgrade credit expires after the 30 day period ends. You are invoiced for any usage that exceeds the promotional credit. To view the promotional credit, go to the [Promotions and credits](https://cloud.ibm.com/billing/promotions) page or the [Invoices](https://cloud.ibm.com/billing/invoices) page in the console.\n\nThe following table lists the current upgrade promotional amounts for different currencies:\n\n\n\nTable 1. Promo price for different currencies\n\n Country Currency Converted Promo Amount \n\n United States USD 200.00 \n Australia AUD 279.94 \n Brazil BRL 862.84 \n Canada CAD 260.96 \n Switzerland CHF 190.85 \n China CNY 1,836.38 \n Denmark DKK 1,258.68 \n Euro EUR 168.67 \n UK GBP 151.96 \n Indonesia IDR 3,128,000.00 \n India INR 14,390.14 \n Japan JPY 22,400.62 \n South Korea KRW 232,999.57", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-upgrading-account"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>12", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03713-3269-5168", "score": 36.259827, "text": "\nProblem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card not authorized to place an order? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is IBM Cloud unable to process my order request? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected. Please contact Cloud Trust Enablement at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n Why it\u2019s happening \n\nIBM Cloud\u00ae was unable to process your transaction.\n\n How to fix it \n\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03713-7-2194", "score": 32.625023, "text": "\nCredit Card error messages \n\nAn issue might occur when you try to update, add, or remove a credit card. Review the following credit card error messages for detailed self-help information.\n\n\n\n Why was my credit card transaction rejected? \n\nProtecting your identity is a priority and IBM Cloud takes credit card verification seriously.\n\n What\u2019s happening \n\nAn issue occurred that caused the transaction to fail. For example, the name and address on file with IBM Cloud doesn't match the information on file with the company that issued your credit card. This error might prompt the following message:\n\n> Error: Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the transaction wasn't successful.\n\n How to fix it \n\nTo ensure that your credit card verification is successful, complete the following steps:\n\n\n\n1. Verify that the name and address for your IBM Cloud account matches the name and address on file with your credit card issuer.\n2. Verify that the country associated with a VAT or tax identification number matches the country in your IBM Cloud account. For example, a VAT ID registered in France can't be associated with an IBM Cloud account that is registered in Finland.\n3. Verify that you are creating a business account and not a personal account if you are specifying a VAT ID or tax identification number.\n4. Review the error message that was displayed. If your transaction was rejected and an email address was not provided, contact your credit card issuer.\n5. Contact us by calling 1-866-325-0045 and selecting the third option.\n\n\n\n\n\n\n\n Why do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03713-1710-3705", "score": 30.578365, "text": "\nWhy do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the update wasn't successful.\n\n How to fix it \n\nGo to the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter) and click Create a case.\n\n\n\n\n\n Why was there a general decline of my credit card? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card inactive or not authorized? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03713-4689-6647", "score": 27.495974, "text": "\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nYour credit card number was not recognized by your credit card issuer.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why was my change request rejected because of a VAT ID? \n\n What\u2019s happening \n\nYou tried to complete a change request IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Failed to complete the Change Request process due to the following error: VAT ID is a required field for ...\n\n Why it\u2019s happening \n\nYour VAT ID, CST or other tax identification number cannot be validated.\n\n How to fix it \n\n\n\n1. Verify that tax identification number is valid.\n2. Verify that the tax identification number is associated with the same country as the physical country of residence in your IBM Cloud profile.\n3. Verify whether a VAT ID is required to create an IBM Cloud account in your country of residence. For more information, see [Personal use availability](https://cloud.ibm.com/docs/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03786-7-2105", "score": 23.86459, "text": "\nApplying subscription codes \n\nAfter you buy a subscription for platform or support credit, you must add the credit to your account by applying a subscription code to an existing account or a new account when you register. Applying the code ensures that the credit is added to your account and you don't have unexpected overage charges.\n\nIf you set up your first subscription through the [Subscriptions page](https://cloud.ibm.com/billing/subscriptions), the credit for this subscription is automatically added to your account - no code required.\n\nAfter IBM Cloud Sales places the order, an email with the subscription code for each subscription and support line item is sent to the appropriate contact.\n\nOnly the account owner, enterprise account owner, or a user with the Editor or Administrator role on the Billing account management service can apply the subscription code. If you don't have access to apply subscription codes, the account owner or administrator can provide access. For more information, see [Assigning access to account management services](https://cloud.ibm.com/docs/account?topic=account-account-services). Applying the subscription code through the IBM Cloud\u00ae console is essential to ensure that your account is migrated appropriately.\n\n\n\n1. Open the email with the subscription code.\n\nIf you bought a subscription and didn't receive your subscription code, [contact us](https://www.ibm.com/cloud?contactmodule) or email Sales at [CloudDigitalSales@us.ibm.com](mailto:CloudDigitalSales@us.ibm.com) to request for it to be sent again.\n2. Click Add subscription to add it to an existing account.\n3. Sign in to the console with your IBMid and password.\n4. From the modal, choose the account you'd like to add the subscription to, select I understand, and then click Add.\n\n\n\nTo manually apply the subscription code to an existing account, complete the following steps:\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings.\n2. Click Apply code.\n\nEach code can be redeemed only one time, and the codes must be redeemed before their expiration date.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code"}, {"document_id": "ibmcld_16727-1068047-1069909", "score": 23.542568, "text": "\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https://www.ibm.com/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https://cloud.ibm.com/account/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https://cloud.ibm.com/registration). For more information, see [Managing subscriptions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule).\n* Can I spend more or less than my monthly commitment?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-1069800-1071727", "score": 23.392107, "text": "\nThis credit card hold is reversed within 24 to 72 hours. In many cases, a credit card isn't accepted because your credit card issuer didn't authorize it. For more information about issues with credit card authorization, see [Credit Card error messages](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages).\n* How do I get help with issues with creating an account?\n\nIf you are able to log in to an IBM Cloud account, go to the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter) and choose one of the following options.\n\n\n\n* If you have advanced or premium support, click Chat with IBM to talk to an IBM Cloud support representative.\n* Create a support case by clicking Create a case from the Need more help? section.\n\nAfter you open the case, an email notification is sent to you. Follow the instructions for further communication.\n\n\n\nIf you can't log in to an IBM Cloud account, [create an account request](https://watson.service-now.com/x_ibmwc_open_case_app.do!/create).\n* Why is a VAT ID required when I create an account?\n\nA tax identification number, such as a VAT ID, GST number, or TIN, is required to create a new personal use account with an address in specific countries or regions. For information about these requirements or where personal use accounts are not permitted, see [Personal use availability](https://cloud.ibm.com/docs/account?topic=account-account-getting-startedsignup-personalaccts). A tax identification number is also required for company accounts depending on your location. Some countries where the local government requires it, taxes are charged directly instead.\n* How do I update my credit card?\n\nIf you have a Pay-As-You-Go account type that is billed in US Dollars, complete the following steps:\n\n\n\n1. Go to the [Payments](https://cloud.ibm.com/billing/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_03785-7-2010", "score": 22.765133, "text": "\nFAQs for subscription accounts \n\nFAQs for subscription accounts include entries about subscription credit, subscription terms, and other subscription-related self-help information.\n\n\n\n How do I add subscription credit to my account? \n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https://cloud.ibm.com/account/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https://cloud.ibm.com/registration). For more information, see [Managing subscriptions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n\n\n\n\n\n What does the IN_PROGRESS status mean when I apply a subscription code? \n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n\n\n\n\n\n Can I pay the total spending commitment up-front or quarterly? \n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule).\n\n\n\n\n\n Can I spend more or less than my monthly commitment? \n\nYes, what you spend monthly is up to you! You can spend any amount of the total commitment each month.\n\n\n\n\n\n What happens if I spend my entire subscription amount before my term ends? \n\nYou're required to continue paying your monthly charges until the end of your term.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription-account"}, {"document_id": "ibmcld_07578-1065299-1067188", "score": 22.575562, "text": "\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https://www.ibm.com/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https://cloud.ibm.com/account/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https://cloud.ibm.com/registration). For more information, see [Managing subscriptions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes!", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_03713-6236-8279", "score": 22.19314, "text": "\nFor more information, see [Personal use availability](https://cloud.ibm.com/docs/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> There was an error in the payment process: We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is the transaction already processed? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Transaction already processed.\n\n Why it\u2019s happening \n\nOur payment system has detected multiple similar payments within a short period of time. IBM Cloud is attempting to avoid unintentional duplicate payments.\n\n How to fix it \n\nWait 3-4 hours for the manual payment to be processed and posted to your IBM Cloud} account. Verify your account balance on the [Payments page](https://cloud.ibm.com/billing/payments).\n\n\n\n\n\n Why can't I upgrade my account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your account couldn't be upgraded. Click Upgrade account to try again.\n\n Why it\u2019s happening \n\nIBM Cloud} was unable to process your transaction.\n\n How to fix it \n\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}]}
{"task_id": "1dcbbeb35d4d25ba1ffb787a9f2080e2<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16258-2570-3569", "score": 15.062772, "text": "\n[Conversation filters](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps. A panel opens showing the full back and forth between your customer and the assistant, including step interactions. The panel also provides a summary of how many requests there were, how many were recognized, whether search was initiated, and the duration of the conversation.\n\n![Conversation detail](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-side.png)", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-conversations"}, {"document_id": "ibmcld_16258-1324-3123", "score": 14.4942, "text": "\n[Time period](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-conversations"}, {"document_id": "ibmcld_06953-2615-5096", "score": 13.134225, "text": "\nWhen Emphasize the answer is used (\"find_answers\": true), Discovery rescores and reorders the documents to ensure that documents with the highest-quality answers are returned first.\n\n\n\n\n\n Choosing a project type \n\nIf the Conversational Search project type isn't providing the best answers and you want to understand why, switch to using a Document Retrieval project type.\n\nMost often, the Conversational Search project type is the right choice. You get great results from the start, and when you enable extra features like Emphasize the answer, the answers are clear and concise. However, for advanced use cases, or if you want to be able to troubleshoot issues, a Document Retrieval project type might be a better fit.\n\nTo help you choose the right Discovery project type, review the project type differences that are described in the following table.\n\n\n\nProject type details\n\n Function Conversational Search Document Retrieval \n\n Enrichment support Only the Part of Speech enrichment is applied. The Part of Speech and Entities enrichments are applied. The Entities enrichment is helpful for identifying important information and introduces more ways to filter query results. \n Testing queries from the Improve and customize page in Discovery You see only one of the responses that are returned from the chatbot. You cannot see all of the available responses and cannot analyze individual query results. You can filter query results by enrichment-based facets. You can review details about fields that are indexed in the source documents that are returned for a query. Access to more information makes it easier to troubleshoot unexpected results. \n Search triggers Returns answers from the text field automatically. If answers are stored in another field, you must change the configuration. You can apply a Smart Document Understanding (SDU) model or enrichments to your collections and retrieve useful information from fields other than text when search is triggered from the assistant. \n\n\n\nFor both project types, the best way to test is to trigger search from the Watson Assistant preview. When you configure search support for an assistant, you can fine-tune the experience in ways that aren't available in Discovery.\n\nAnd settings that are available from the Search results tool for a Document Retrieval project type are replaced by configuration settings that you specify in Watson Assistant. For example, the query response title and body are defined in Watson Assistant.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-chat-choose-project"}, {"document_id": "ibmcld_16258-7-1952", "score": 12.564305, "text": "\nReview customer conversations \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nEach timestamp represents a single conversation. The Actions column shows you how many actions, search queries, or unrecognized requests are included in that conversation. The Requests column includes the questions or requests the user entered that initiated an action, started a search query, or weren't recognized.\n\nIf you have activated dialog in your assistant, the Actions column is replaced by a Topics column.\n\n![Conversations page](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations.png)\n\n\n\n Choosing the environment and time period \n\nTo get started, choose the [environment](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-publish-overviewenvironments) and date range you want to analyze. All conversations reflect data based on the environment and the date range you select. When you change the environnment or the date range, the conversations on the page update to reflect the new date range. You can also use Refresh ensure the latest data is shown.\n\n![Time period](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-conversations"}, {"document_id": "ibmcld_16364-201078-203239", "score": 12.378254, "text": "\nSee [Fuzzy matching](https://cloud.ibm.com/docs/assistant?topic=assistant-entitiesentities-fuzzy-matching) for details.\n\n\n\n\n\n 13 June 2017 \n\nUser conversations\n: The Improve panel now includes a User conversations page, which provides a list of user interactions with your chatbot that can be filtered by keyword, intent, entity, or number of days. You can open individual conversations to correct intents, or to add entity values or synonyms.\n\nRegex change\n: The regular expressions that are supported by SpEL functions like find, matches, extract, replaceFirst, replaceAll and split have changed. A group of regular expression constructs are no longer allowed, including look-ahead, look-behind, possessive repetition and backreference constructs. This change was necessary to avoid a security exposure in the original regular expression library.\n\n\n\n\n\n 12 June 2017 \n\nUpdates\n: This release includes the following updates:\n\n\n\n* The maximum number of workspaces that you can create with the Lite plan (formerly named the Free plan) changed from 3 to 5.\n* You can now assign any name to a dialog node; it does not need to be unique. And you can subsequently change the node name without impacting how the node is referenced internally. The name you specify is treated as an alias and the system uses its own internal identifier to reference the node.\n* You can no longer change the language of a workspace after you create it by editing the workspace details. If you need to change the language, you can export the workspace as a JSON file, update the language property, and then import the JSON file as a new workspace.\n\n\n\n\n\n\n\n 6 June 2017 \n\nLearn\n: A new Learn about IBM Watson\u00ae Assistant page is available that provides getting started information and links to service documentation and other useful resources. To open the page, click the icon in the page header.\n\nBulk export and delete\n: You can now simultaneously export a number of intents or entities to a CSV file, so you can then import and reuse them for another Watson Assistant application. You can also simultaneously select a number of entities or intents for deletion in bulk.\n\nUpdates to Korean", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_16343-7-1927", "score": 11.498407, "text": "\nNeuralSeek extension setup \n\n[NeuralSeek](https://neuralseek.com) by [Cerebral Blue](https://cerebralblue.com/) is a combined search and natural-language generation system that is designed to [make conversational AI feel more conversational](https://garrettrowe.medium.com/making-conversational-ai-feel-more-conversational-8748009b3fda). It requires that you load all your content into [IBM Watson\u00ae Discovery](https://cloud.ibm.com/catalog/services/watson-discovery). Then, when a user asks a question, it has Discovery search for multiple relevant documents and then it generates a natural-language answer that uses the contents of those documents. In some cases, the answer might be taken directly from a single document, and in others, the answer can include information from multiple sources that are combined into a single coherent statement. For each query, NeuralSeek returns a single answer and a confidence score. In most cases, it also returns a URL of a document that influenced the answer, which might be one of several documents.\n\nTo set up the extension for NeuralSeek search:\n\n\n\n Set up IBM Watson\u00ae Discovery \n\n\n\n1. You need an instance of [IBM Watson\u00ae Discovery](https://cloud.ibm.com/catalog/services/watson-discovery). Because NeuralSeek can modify your data as needed to make it more effective, make sure it is not an instance with important data that you are using for other purposes.\n2. In Discovery, create a project and load the documents that you want to use.\n\n\n\n\n\n\n\n Get the NeuralSeek OpenAPI specification and API Key \n\n\n\n1. You also need an instance of [NeuralSeek on IBM Cloud](https://cloud.ibm.com/catalog/services/neuralseek).\n2. In NeuralSeek, open the Configure page and enter your information in the Discovery instance details section.\n3. On the Integrate page, and click the OpenAPI file link to download the NeuralSeek.json OpenAPI specification file configured for your instance.\n4.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-search-extension-neuralseek"}, {"document_id": "ibmcld_03285-1272-3273", "score": 11.483954, "text": "\n* [Transfer the conversation to the web chat integration](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-transfer-channel)\n* [End the call](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-hangup)\n* [Send a text message during a phone conversation](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-sms)\n\n\n\nIn some cases, you might want to combine response types to perform multiple actions. For example, you might want to implement two-factor authentication by requesting phone keypad entry and sending a text message from the same dialog node or step. For more information, see [Defining a sequence of phone actions](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-sequence).\n\nFor reference information about phone-specific repsonse types and related context variables, see [Phone context variables](https://cloud.ibm.com/docs/assistant?topic=assistant-phone-context).\n\n\n\n Adding phone-specific responses to your dialog or actions \n\nTo initiate a voice-specific interaction from a dialog node or a step in an action, add a response within the output.generic array using the appropriate response type.\n\nAlthough many response types can be specified using the Watson Assistant user interface, phone-specific response types must currently be added using the JSON editor.\n\nFor more information about using the JSON editor to add responses, see [Defining responses using the JSON editor](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-responses-json).\n\n\n\n\n\n Applying advanced settings to the Speech to Text service \n\nUse the speech_to_text response type to send configuration commands to the Speech to Text service instance used by the phone integration. By sending a speech_to_text response from a dialog node or action step, you can dynamically change the Speech to Text configuration during a conversation.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actions"}, {"document_id": "ibmcld_16251-3354-5410", "score": 11.482519, "text": "\nUse the universal language model when you want to create a conversation in a language where no model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-language-supportadmin-language-support-codes).\n\n\n\n\n\n Integration considerations \n\nKeep these tips in mind for integrations:\n\n\n\n* Phone integration: If you want to deploy an assistant that uses the universal language model, you must connect to custom Speech service language models that can understand the language you're using. For more information about supported language models, see the [Speech to Text](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-modelsmodelsList) and [Text to Speech](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-voiceslanguageVoices) documentation.\n* Search integration: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Supporting global audiences](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-global).\n\n\n\n\n\n\n\n Supported languages \n\nWatson Assistant supports individual features to varying degrees per language.\n\nWatson Assistant has classifier models that are designed specifically to support conversations in the following languages:\n\n\n\nTable 1. Supported languages\n\n Language Language code \n\n Arabic ar \n Chinese (Simplified) zh-cn \n Chinese (Traditional) zh-tw \n Czech cs \n Dutch nl \n English en-us \n French fr \n German de \n Italian it \n Japanese ja \n Korean ko \n Portuguese (Brazilian) pt-br", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-language-support"}, {"document_id": "ibmcld_16364-36153-38148", "score": 11.461617, "text": "\nFrom the Conversations tab of the Analyze page, open the Actions filter and select Greet customer. For more information, see [Filtering conversations](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-conversationsanalytics-conversations-filtering).\n\nFilter actions by name\n: You can now find actions more easily. On the Actions page, you can filter actions by name. Click the search icon, then enter a search string. Your list of actions filters to match what you enter.\n\n\n\n\n\n 12 August 2022 \n\nActions templates\n: When creating actions, you can choose a template that relates to the problem you\u2019re trying to solve. Templates help tailor your actions to include items specific to your business need. The examples in each template can also help you to learn how actions work. Actions templates include features such as intents, entities, condition-based responses, synonyms, response validations, and agent fallback. For more information, see [Building actions from a template](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-actions-templates).\n\nChannel name variable\n: The Channel name integration variable lets you add step conditions using these channels: web chat, phone, SMS, WhatsApp, Slack, or Facebook Messenger. For more information, see [Adding conditions to a step](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-step-conditions).\n\n\n\n\n\n 11 August 2022 \n\nAlgorithm version options available in more languages\n: Algorithm version options are now available in Arabic, Czech, and Dutch. This allows you to choose which Watson Assistant algorithm to apply to your future trainings. For more information, see [Algorithm version and training](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-algorithm-version).\n\n\n\n\n\n 9 August 2022 \n\nNew API methods\n: The v2 API now supports new Environments and Releases methods:\n\n\n\n* Environments: Retrieve information about the environments associated with an assistant.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_03363-6198-7991", "score": 11.370579, "text": "\nThe statistics can cover a longer time period than the period for which logs of conversations are retained.\n\n![Time period control](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/oview-time.png)\n\nYou can choose whether to view data for a single day, a week, a month, or a quarter. In each case, the data points on the graph adjust to an appropriate measurement period. For example, when viewing a graph for a day, the data is presented in hourly values, but when viewing a graph for a week, the data is shown by day. A week always runs from Sunday through Saturday.\n\nYou can create custom time periods also, such as a week that runs from Thursday to the following Wednesday, or a month that begins on any date other than the first.\n\nThe time shown for each conversation is localized to reflect the time zone of your browser. However, API log calls are always shown in UTC time. As a result, if you choose a single day view, for example, the time shown in the visualization might differ from the timestamp specified in the log for the same conversation.\n\n![Time period control](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/oview-time2.png)\n* Intents and Entities filters - Use either of these drop-down filters to show data for a specific intent or entity in your skill.\n\nThe intent and entities filters are populated by the intents and entities in the skill, and not what is in the data source. If you have [selected a data source](https://cloud.ibm.com/docs/assistant?topic=assistant-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs-overview"}]}
{"task_id": "1dcbbeb35d4d25ba1ffb787a9f2080e2<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03042-2711-4616", "score": 20.432858, "text": "\n{: note}\n\n1. conversation_id (v1 only): A property defined in the v1 API that is stored in the context object of a /message API call. This property can be used to identify multiple /message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new /message API call.\nShow more\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle. For example, don't use a person's email address as the user ID. In fact, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https://tools.ietf.org/html/rfc7230section-3.2).\n\nThe built-in integrations derive the user ID in the following ways:\n\n\n\n* For web chat, you can set the value of the user_id property. For more information, see [Adding user identity information](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-userid).\n\n\n\n\n\n Handling anonymous users \n\nIf your custom application or assistant interacts with users who are anonymous, you can generate a randomized universally unique ID to represent each anonymous user. For more information about UUIDs, see [RFC 4122](https://tools.ietf.org/html/rfc4122.html).\n\n\n\n* For web chat, if you do not pass an identifier for the user when the session begins, the web chat creates one for you. It creates a first-party cookie with a generated anonymous ID. The cookie remains active for 45 days. If the same user returns to your site later in the month and chats with your assistant again, the web chat integration recognizes the user.\n\n\n\n\n\n\n\n\n\n Service API versioning", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-services-information"}, {"document_id": "ibmcld_03107-5127-7134", "score": 20.209824, "text": "\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a /message API call. This property can be used to identify multiple /message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new /message API call.\n\n\n\nFor example, if the same person chats with your assistant on three separate occasions over the same billing period, how you represent that user in the API call impacts how the interactions are billed. If you identify the user interaction with a user_id, it counts as one use. If you identify the user interaction with a session_id, then it counts as three uses (because there is a separate session that is created for each interaction).\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle. For example, don't use a person's email address as the user ID. In fact, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https://tools.ietf.org/html/rfc7230section-3.2).\n\nThe built-in integrations derive the user ID in the following ways:\n\n\n\n* For Facebook integrations, the user_id property is set to the sender ID that Facebook provides in its payload.\n* For Slack integrations, the user_id property is a concatenation of the team ID, such as T09LVDR7Y, and the member ID of the user, such has W4F8K9JNF. For example: T09LVDR7YW4F8K9JNF.\n* For web chat, you can set the value of the user_id property.\n\n\n\nBilling is managed per monthly active user per service instance. If a single user interacts with assistants that are hosted by different service instances that belong to the same plan, each interaction is treated as a separate use.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-admin-managing-plan"}, {"document_id": "ibmcld_16259-1485-3642", "score": 16.875463, "text": "\nUnique user is anyone who interacts with your assistant. User ID identifies each user, using a unique label to track the level of service usage. A unique user can have multiple conversations, but a conversation never has more than one unique user.\n\nConversation is a set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back. Conversations can have multiple requests within a single conversation, but a single request doesn't span more than 1 conversation.\n\nRequest is a root-level utterance, such as an initial question or request, that signals the start of a specific flow. A user can initiate multiple requests. Requests are meant to represent the core concepts or topics your users are asking about. A request can have multiple steps within it, for example I want to order a pizza is a request. Delivery/takeout, Small/Medium/Large, Cheese/Pepperoni/Mushrooms/Peppers are all steps within the request of ordering a pizza.\n\n\n\n\n\n Completion and recognition \n\nThe completion and recognition charts provide information about the actions in your assistant.\n\n![Completion and recognition](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-completion-recognition-2.png)\n\n\n\n Completion \n\nCompletion is the measurement of how often users are able to successfully get through all steps of an action.\n\nYour assistant measures when someone reaches the final step of an action. The completion chart provides an overview of all the actions you have built and how many of these are being completed or not.\n\nCompletion is only applicable when a user question or request matched to an action, and the action starts.\n\nOne action can be triggered multiple times, so to better understand individual action performance, click Action completion to understand each action in more detail.\n\n\n\n\n\n Recognition \n\nRecognition is the measurement of how many requests are being recognized by the assistant and routed into starting an action.\n\nThe recognition chart provides you with a view into how many requests are matched to actions.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-overview"}, {"document_id": "ibmcld_03109-5081-6683", "score": 16.741175, "text": "\nThe Intercom user_id property is the id of the author message object in the Conversation Model that is defined by Intercom.\n\n\n\n* To get the ID, open the channel from a web browser. Open the web developer tools to view the console. Look for author.\n\n\n\nThe full customer ID looks like this: customer_id=intercom_5c499e5535ddf5c7fa2d72b3.\n* For Slack, the customer_id is the user_id prepended with slack_. The Slack user_id property is a concatenation of the team ID, such as T09LVDR7Y, and the member ID of the user, such has W4F8K9JNF. For example: T09LVDR7YW4F8K9JNF.\n\n\n\n* To get the team ID, open the channel from a web browser. Open the web developer tools to view the console. Look for [BOOT] Initial team ID.\n* You can copy the member ID from the user's Slack profile.\n* To get the IDs programmatically, use the Slack API. For more information, see [Overview](https://api.slack.com/apis). The full customer ID looks like this: customer_id=slack_T09LVDR7YW4F8K9JNF.\n\n\n\n* For the web chat integration, the service takes the user_id that is passed in and adds it as the customer_id parameter value to the X-Watson-Metadata header with each request.\n\n\n\n\n\n Before you begin \n\nTo be able to delete message data associated with a specific user, you must first associate all messages with a unique customer ID for each user. To specify the customer ID for any messages sent using the /message API, include the X-Watson-Metadata: customer_id property in your header. For example:\n\ncurl -X POST -u \"apikey:3Df... ...Y7Pc9\"\n--header\n'Content-Type: application/json'\n'X-Watson-Metadata: customer_id=abc'\n--data", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-admin-securing"}, {"document_id": "ibmcld_03107-3801-5605", "score": 16.435215, "text": "\nThe user_id property is specified at the root of the request body, as in this example:\n\n{\n\"input\": {\n\"message_type\": \"text\",\n\"text\": \"I want to cancel my order\"\n},\n\"user_id\": \"my_user_id\"\n}\n\nIn some older SDK versions, the user_id property is not supported as a top-level method parameter. As an alternative, you can specify user_id within the nested context.global.system object.\n\nFor more information about the user_id property, see the API reference documentation:\n\n\n\n* [v2 stateless /message](https://cloud.ibm.com/apidocs/assistant-v2/assistant-v2messagestateless)\n* [v2 stateful /message](https://cloud.ibm.com/apidocs/assistant-v2/assistant-v2message)\n\n\n\n\n\n\n\n If the user ID is not specified \n\nIf you are using a custom client application and do not set a user_id value, the service automatically sets it to one of the following values:\n\n\n\n* session_id (v2 API only): A property defined in the v2 API that identifies a single conversation between a user and the assistant. A session ID is provided in /message API calls that are generated by the built-in integrations. The session ends when a user closes the chat window or after the inactivity time limit is reached.\n\nIf you use the stateless v2 message API, you must specify the session_id with each message in an ongoing conversation (in context.global.session_id).\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a /message API call. This property can be used to identify multiple /message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new /message API call.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-admin-managing-plan"}, {"document_id": "ibmcld_16252-3899-5971", "score": 16.41142, "text": "\nFor more information about the user_id property, see the API reference documentation:\n\n\n\n* [v2 stateless /message](https://cloud.ibm.com/apidocs/assistant-v2/assistant-v2messagestateless)\n* [v2 stateful /message](https://cloud.ibm.com/apidocs/assistant-v2/assistant-v2message)\n\n\n\n\n\n\n\n If the user ID is not specified \n\nIf you are using a custom client application and do not set a user_id value, the service automatically sets it to one of the following values:\n\n\n\n* session_id (v2 API only): A property defined in the v2 API that identifies a single conversation between a user and the assistant. A session ID is provided in /message API calls that are generated by the built-in integrations. The session ends when a user closes the chat window or after the inactivity time limit is reached.\n\nIf you use the stateless v2 message API, you must specify the session_id with each message in an ongoing conversation (in context.global.session_id).\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a /message API call. This property can be used to identify multiple /message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new /message API call.\n\n\n\nFor example, if the same person chats with your assistant on three separate occasions over the same billing period, how you represent that user in the API call impacts how the interactions are billed. If you identify the user interaction with a user_id, it counts as one use. If you identify the user interaction with a session_id, then it counts as three uses (because there is a separate session that is created for each interaction).\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-managing-plan"}, {"document_id": "ibmcld_03107-6652-8734", "score": 16.158014, "text": "\n* For Slack integrations, the user_id property is a concatenation of the team ID, such as T09LVDR7Y, and the member ID of the user, such has W4F8K9JNF. For example: T09LVDR7YW4F8K9JNF.\n* For web chat, you can set the value of the user_id property.\n\n\n\nBilling is managed per monthly active user per service instance. If a single user interacts with assistants that are hosted by different service instances that belong to the same plan, each interaction is treated as a separate use. You are billed for the user's interaction with each service instance separately.\n\n\n\n\n\n Test activity charges \n\nTest messages that you send from the Preview button are charged. For the preview, a random user_id is generated and stored in a cookie. The multiple interactions that a single tester has with the assistant embedded in the preview are recognized as coming from a single user and are charged accordingly. If you are doing your own test, running a scripted regression test for example, use a single user_id for all of the calls within your regression test. Other uses are flagged as abuse.\n\n\n\n\n\n Handling anonymous users \n\nIf your custom application or assistant interacts with users who are anonymous, you can generate a randomized universally unique ID to represent each anonymous user. For more information about UUIDs, see [RFC 4122](https://tools.ietf.org/html/rfc4122.html).\n\n\n\n* For web chat, if you do not pass an identifier for the user when the session begins, the web chat creates one for you. It creates a first-party cookie with a generated anonymous ID. The cookie remains active for 45 days. If the same user returns to your site later in the month and chats with your assistant again, the web chat integration recognizes the user. And you are charged only once when the same anonymous user interacts with your assistant multiple times in a single month.\n\n\n\nIf an anonymous user logs in and later is identified as being the same person who submitted a request with a known ID, you are charged twice. Each message with a unique user ID is charged as an independent active user.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-admin-managing-plan"}, {"document_id": "ibmcld_03037-1358-3485", "score": 15.55725, "text": "\n* Conversation: A set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back.\n* Conversation ID: Unique identifier that is added to individual message calls to link related message exchanges together. App developers using the V1 version of the Watson Assistant API add this value to the message calls in a conversation by including the ID in the metadata of the context object.\n* Customer ID: A unique ID that can be used to label customer data such that it can be subsequently deleted if the customer requests the removal of their data.\n* Deployment ID: A unique label that app developers using the V1 version of the Watson Assistant API pass with each user message to help identify the deployment environment that produced the message.\n* Instance: Your deployment of Watson Assistant, accessible with unique credentials. A Watson Assistant instance might contain multiple assistants.\n* Message: A message is a single utterance a user sends to the assistant.\n* Skill ID: The unique identifier of a skill.\n* User: A user is anyone who interacts with your assistant; often these are your customers.\n* User ID: A unique label that is used to track the level of service usage of a specific user.\n* Workspace ID: The unique identifier of a workspace. Although any workspaces that you created before November 9 are shown as skills in the product user interface, a skill and a workspace are not the same thing. A skill is effectively a wrapper for a V1 workspace.\n\n\n\nImportant: The User ID property is not equivalent to the Customer ID property, though both can be passed with the message. The User ID field is used to track levels of usage for billing purposes, whereas the Customer ID field is used to support the labeling and subsequent deletion of messages that are associated with end users. Customer ID is used consistently across all Watson services and is specified in the X-Watson-Metadata header. User ID is used exclusively by the Watson Assistant service and is passed in the context object of each /message API call.\n\n\n\n\n\n Enabling user metrics", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-resources"}, {"document_id": "ibmcld_03037-2895-4808", "score": 15.528555, "text": "\nImportant: The User ID property is not equivalent to the Customer ID property, though both can be passed with the message. The User ID field is used to track levels of usage for billing purposes, whereas the Customer ID field is used to support the labeling and subsequent deletion of messages that are associated with end users. Customer ID is used consistently across all Watson services and is specified in the X-Watson-Metadata header. User ID is used exclusively by the Watson Assistant service and is passed in the context object of each /message API call.\n\n\n\n\n\n Enabling user metrics \n\nUser metrics allow you to see, for example, the number of unique users who have engaged with your assistant, or the average number of conversations per user over a given time interval on the [Overview page](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-overview). User metrics are enabled by using a unique User ID parameter.\n\nTo specify the User ID for a message sent using the /message API, include the user_id property in your global [context](https://cloud.ibm.com/apidocs/assistant-data-v2message), as in this example:\n\n\"context\": {\n\"global\": {\n\"system\": {\n\"user_id\": \"{UserID}\"\n}\n}\n}\n\nIf your application is still using the older [v1 runtime API](https://cloud.ibm.com/apidocs/assistant-data-v1?curl=message), the context format is different:\n\n\"context\" : {\n\"metadata\" : {\n\"user_id\": \"{UserID}\"\n}\n}\n\n\n\n\n\n Associating message data with a user for deletion \n\nThere might come a time when you want to completely remove a set of your user's data from a Watson Assistant instance. When the delete feature is used, then the Overview metrics will no longer reflect those deleted messages; for example, they will have fewer Total Conversations.\n\n\n\n Before you begin \n\nTo delete messages for one or more individuals, you first need to associate a message with a unique Customer ID for each individual.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-resources"}, {"document_id": "ibmcld_16258-2570-3569", "score": 15.243518, "text": "\n[Conversation filters](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps. A panel opens showing the full back and forth between your customer and the assistant, including step interactions. The panel also provides a summary of how many requests there were, how many were recognized, whether search was initiated, and the duration of the conversation.\n\n![Conversation detail](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-side.png)", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-conversations"}]}
{"task_id": "1dcbbeb35d4d25ba1ffb787a9f2080e2<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02774-5358-7120", "score": 17.262388, "text": "\nA user's predefined attributes are empty until their first authentication. Although they're empty, the user is still fully authenticated. You can use their profile ID just as you would someone who has already signed in. For instance, you can modify, search, or delete the profile.\n\n\n\n Before you begin \n\nBefore you get started, you must have the following information:\n\n\n\n* Which identity provider that the user will sign in with.\n* The email of the user that you want to add or their [unique identifier](https://cloud.ibm.com/docs/appid?topic=appid-preregisterpreregister-idp-provide).\n* The [custom attribute](https://cloud.ibm.com/docs/appid?topic=appid-profiles) information that you want to assign.\n\n\n\n\n\n\n\n With the GUI \n\nYou can add a future user and their custom attributes by using the GUI.\n\nThe ability to add future users is disabled for the user name and password configuration of Cloud Directory.\n\n\n\n1. Go to the User Profiles tab of the App ID dashboard.\n2. Click Future users. If you already have future users, you see a table with a list of the user's that you already added. To add another user, click Build a profile. If you don't have any users yet, click Get Started. A screen opens.\n3. Enter your user's email.\n4. Select the identity provider that they sign in with from the Identity Provider drop down.\n5. Add custom attributes by entering the information in a JSON object as shown in the following example.\n\n{\n\"food\": \"Pizza\",\n\"preference\": \"Vegetarian\",\n\"points\": \"37\"\n}\n6. Click Save. The table displays and the user is assigned an identifier.\n\n\n\n\n\n\n\n With the API \n\nYou can add a future user and their custom attributes by using the API.\n\n\n\n1. Log in to IBM Cloud.\n\nibmcloud login\n2. Find your IAM token by running the following command.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-preregister"}, {"document_id": "ibmcld_02797-7-1882", "score": 16.79674, "text": "\nCustomizing your user experience \n\nIn a world with everything at our finger tips, people expect their experiences to be tailored to them. Whether we're having an in-person conversation or shopping online, we want to see only the things that apply to us. By using this step-by-step guide, you can learn how to harness the power of user attributes and really capture your users attention with App ID.\n\n\n\n Scenario \n\nYou're a developer for an online retailer, with a specialization in food. You're tasked with creating a personalized experience for your app users. You decide to focus your efforts on creating targeted advertising based on things that you know about your users. So, when a user signs up for your app, you ask them a few questions with answers that they can choose from. For example, you might ask the following question:\n\nDo you have any dietary preferences?\n\n\n\n* I'm a vegetarian.\n* I'm a pescatarian.\n* I'm dairy-free.\n* I'm gluten-free.\n* I'm low carb.\n\n\n\nYou can then map their answers to [specific attributes](https://cloud.ibm.com/docs/appid?topic=appid-profiles) that you can use to target the advertising that they're shown.\n\nAlthough this tutorial is written for web apps that use Cloud Directory, attributes can be used in a much broader sense. Custom attributes can be anything that you want them to be! If you stay under 100k attributes and you format them as a plain JSON object, you can store all types of information.\n\n\n\n\n\n Before you begin \n\nReady? Let's get started!\n\nBe sure that you have the following prerequisites before you begin:\n\n\n\n* An instance of the App ID service\n* A set of service credentials\n\n\n\n\n\n\n\n Step 1: Configuring your App ID instance \n\nBefore you can start adding attributes for your users, you need to configure your instance of App ID.\n\n\n\n1. In the Identity Providers tab of the service dashboard, enable Cloud Directory.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-tutorial-attributes"}, {"document_id": "ibmcld_02104-7488-9365", "score": 16.741858, "text": "\nFor more information about trusted profiles, see [Creating trusted profiles](https://cloud.ibm.com/docs/account?topic=account-create-trusted-profile).\n\n\n\nIf you have onboarding set to Static and the user selects a trusted profile when they log in the first time, the user is still added to the account.\n5. Then, select the following settings (Optional):\n\n\n\n* Enable for account login?: Enable your IdP references to be used for users to log in to your account. This option is set by default when you first create an IdP reference.\n* Set as the default?: Users can use the default IdP reference URL that you created when you enabled this feature to log in to your account. You can have only one default IdP reference. For all other IdP references that you create, users must use the realm IDs to log in.\n\n\n\n6. Click Create.\n\n\n\nYour IdP reference is now available on the Identity providers list and the realm ID is generated automatically as the value that represents your IAM IdP in IBM Cloud.\n\n\n\n\n\n Logging in with external identity provider credentials \n\nAfter your App ID instance is connected to your IdP, and your App ID instance is integrated with IAM, your users can start logging in to your account. If the IdP reference is set as the default, then you can share the Default IdP URL for your account.\n\nHowever, since you can have only one set as the default, but you can have up to five set up in your account, you might need to get the URL for another IdP reference:\n\n\n\n1. From the Identity provider pages, click the Actions icon ![List of actions icon](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/action-menu-icon.svg) for the row of the IdP reference you need a URL for.\n2. Select View IdP URL.\n3. Copy the IdP URL link to give to users to log in.\n\n\n\n\n\n\n\n Using App ID instances to build dynamic rules in access groups", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-idp-integration"}, {"document_id": "ibmcld_02797-1486-3139", "score": 16.702673, "text": "\nLet's get started!\n\nBe sure that you have the following prerequisites before you begin:\n\n\n\n* An instance of the App ID service\n* A set of service credentials\n\n\n\n\n\n\n\n Step 1: Configuring your App ID instance \n\nBefore you can start adding attributes for your users, you need to configure your instance of App ID.\n\n\n\n1. In the Identity Providers tab of the service dashboard, enable Cloud Directory. Although this tutorial focuses [Cloud Directory](https://cloud.ibm.com/docs/appid?topic=appid-cloud-directory), you might also choose to use any of the other IdP's such as [SAML](https://cloud.ibm.com/docs/appid?topic=appid-enterprise), [Facebook](https://cloud.ibm.com/docs/appid?topic=appid-socialfacebook), [Google](https://cloud.ibm.com/docs/appid?topic=appid-socialgoogle), or a [custom provider](https://cloud.ibm.com/docs/appid?topic=appid-custom-identity).\n2. In the Cloud Directory > Email Verification tab, enable verification and set Allow users to sign-in to your app without first verifying their email address to Yes.\n3. Optionally, in the Profiles tab, set Change custom attributes from the app to Enabled. This action allows users to update their attributes after they answer your initial questionnaire.\n\n\n\nExcellent! Your dashboard is configured and you're ready to start setting attributes.\n\n\n\n\n\n Step 2: Creating user attributes \n\nWhen your users interact with your questionnaire, you can map their answers to specific attributes, then add those attributes to their file.\n\nYour application is responsible for mapping the answers to the specific attributes that you want to add to the profile.\n\n\n\n1. Update the profile with the attribute.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-tutorial-attributes"}, {"document_id": "ibmcld_11474-5244-7072", "score": 16.253782, "text": "\nOpen the App ID instance page from the [resource list](https://cloud.ibm.com/resources) Services and software section.\n2. Go to Manage Authentication \u2192 Cloud Directory \u2192 Users, and click Create User. Enter the user details.\n\n\n\n\n\n\n\n Step 6: Create or modify users' project assignments \n\nIf the IDP administrator will assign users to projects, you can define project values in the user's attributes.\n\n\n\n1. Open the App ID instance page from the [resource list](https://cloud.ibm.com/resources) Services and software section.\n2. Go to Manage Authentication \u2192 Cloud Directory \u2192 Users, and click a user to open it.\n3. Scroll down to Custom Attributes, and click Edit.\n4. Enter a key value pair that can will checked by the dynamic rules of the access groups, then click Save. You can add several values in the same string (for example, {\"project\":\"ml finance\"}); the contains qualifier of the dynamic rule detects a match of a substring. For our example, add:\n\n{\"project\":\"ml\"}\n\nThe value project corresponds to the convention defined in the planning section. ml is the project that the user belongs to.\n\nThis check is done on every login, so changes in the ID provider user attributes will be effective when a user next logs in.\n\n\n\n\n\n\n\n User flow \n\n\n\n1. A user is sent the ID provider URL for the IBM Cloud account.\n\nThe administrator can always go to [Manage \u2192 Access (IAM) \u2192 Identity providers](https://cloud.ibm.com/iam/identity-providers) to look up the ID provider URL.\n2. To work with Qiskit Runtime serive instances, users must create an API key by going to ([Manage \u2192 Access (IAM) \u2192 API keys](https://cloud.ibm.com/iam/apikeys)).\n3. For further information, users can review [Getting started, Step 2](https://cloud.ibm.com/docs/quantum-computing?topic=quantum-computing-get-startedinstall-packages).\n\n\n\n\n\n\n\n Example scenario", "title": "", "source": "https://cloud.ibm.com/docs/quantum-computing?topic=quantum-computing-appid-org"}, {"document_id": "ibmcld_02766-3003-4951", "score": 16.202137, "text": "\nAn identity provider creates and manages information about an entity such as a user, a functional ID, or an application. The provider verifies the identity of the entity by using credentials, such as a password. Then, the IdP sends the identity information back to App ID, which authorizes the user and then grants access to your app.\n\n\n\n1. Navigate to your service dashboard.\n2. In the Identity Providers section of the navigation, select the Manage page.\n3. On the Identity Providers tab, set the providers that you want to use, to On.\n4. Optional: Decide whether to turn off Anonymous users, or leave the default, which is On. When set to On, user attributes are associated with the user from the moment they begin interacting with your app. For more information about the path to becoming an identified user, see [Progressive authentication](https://cloud.ibm.com/docs/appid?topic=appid-anonymousprogressive).\n\n\n\nApp ID provides default credentials to help with your initial setup of Facebook and Google+. You are limited to 20 uses of the credentials per instance, per day. Because they are IBM credentials, they are meant to be used only for development. Before you publish your app, update the configuration to your own credentials.\n\n\n\n\n\n Adding redirect URIs \n\nYour application redirects users to App ID for authentication. After authentication completes, App ID redirects users back to your application. In order for App ID to be able to redirect users back to your app, you need to register the redirect URI. During the sign-in flow, App ID validates the URIs before it allows clients to participate in the authorization workflow, which helps to prevent phishing attacks and grant code leakage. By registering your URI, you're telling App ID that the URI is trusted and it's OK to redirect your users.\n\n\n\n1. Click Authentication Settings to see your URI and token configuration options.\n2. In the Add web redirect URI field, type the URI.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-managing-idp"}, {"document_id": "ibmcld_16378-1689-3407", "score": 15.986687, "text": "\nThis example in this tutorial, which is based on an Express server for Node.js, shows how to start a session with an anonymous user ID and then authenticate the user during the session.\n\n\n\n1. Create a function called getOrSetAnonymousID() that generates a unique anonymous user ID for each customer and stores it in a cookie (or, if the cookie already exists, uses the stored user ID).\n\nUse a cookie that lasts for at least 45 days. If you do not store the user ID for more than 30 days, the same customer might be counted as multiple different users during the same billing period. (This can still happen if the same user deletes the cookie or uses a different browser.)\n\n\n\nfunction getOrSetAnonymousID(request, response) {\nlet anonymousID = request.cookies['ANONYMOUS-USER-ID'];\nif (!anonymousID) {\nanonymousID = anon-${uuid()};\n}\n\nresponse.cookie('ANONYMOUS-USER-ID', anonymousID, {\nexpires: new Date(Date.now() + 1000 * 60 * 60 * 24 * 45), // 45 days.\nhttpOnly: true,\n});\n\nreturn anonymousID;\n}\n\n\n\n1. In the function you use to create a JWT, use the anonymous ID returned from the getOrSetAnonymousID() function as the value of the sub claim. This sets the value of the user ID that will be used to uniquely identify the customer for billing purposes.\n\nIn addition, retrieve any value from the SESSION_INFO cookie, which we will use to store authenticated login information. If a value exists, store it in the user_payload private claim of the JWT. (If the user has not yet authenticated, this cookie does not yet exist.)\n\n\n\nconst jwtContent = {\nsub: anonymousUserID,\nuser_payload: {\nname: 'Anonymous',\ncustom_user_id: anonymousUserID,\n},\n};\n\nif (sessionInfo) {\njwtContent.user_payload.name = sessionInfo.userName;", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-security"}, {"document_id": "ibmcld_02766-1535-3459", "score": 15.900969, "text": "\nBecause App ID is the identity provider, users can take advantage of advanced functionality, such as resetting their password, directly in your app.\n\nWorking with application identity? Check out [Application identity](https://cloud.ibm.com/docs/appid?topic=appid-app).\n\nSeveral identity providers can be configured to be used by App ID. Check out the following table to learn about your options.\n\n\n\nTable 1. Identity provider options\n\n Identity provider Type Description \n\n [Cloud Directory](https://cloud.ibm.com/docs/appid?topic=appid-cloud-directory) Managed registry You can maintain your own user registry in the cloud. When a user signs up for your app, they are added to your directory of users. This option gives your users more freedom to manage their own account within your app. \n [SAML](https://cloud.ibm.com/docs/appid?topic=appid-enterpriseenterprise) Enterprise You can create a single sign-on experience for your users. \n [Facebook](https://cloud.ibm.com/docs/appid?topic=appid-socialfacebook) Social Users can sign in to your app by using their Facebook credentials. \n [Google+](https://cloud.ibm.com/docs/appid?topic=appid-socialgoogle) Social Users can sign in to your app by using their Google credentials. \n [Custom](https://cloud.ibm.com/docs/appid?topic=appid-custom-identitycustom-identity) Custom If none of the provided options fit your specific need, you can configure your own identity flow to work with App ID. \n\n\n\n\n\n Managing providers \n\nAn identity provider creates and manages information about an entity such as a user, a functional ID, or an application. The provider verifies the identity of the entity by using credentials, such as a password. Then, the IdP sends the identity information back to App ID, which authorizes the user and then grants access to your app.\n\n\n\n1. Navigate to your service dashboard.\n2. In the Identity Providers section of the navigation, select the Manage page.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-managing-idp"}, {"document_id": "ibmcld_02734-1732-3794", "score": 15.859888, "text": "\nYou can attach the attributes of only one anonymous profile to the user's identity that is stored in App ID. For example, say that a user browses your application anonymously in two separate browser tabs. The user adds a t-shirt to the shopping cart on the first tab and a pair of shorts to the cart on the second tab. App ID creates two separate anonymous profiles to track the interactions of the user with your application on each tab.\n\nIf the user chooses to sign in from the first tab, then they have access only to the t-shirt they added to their cart before they signed in. In this case, App ID attaches only the attributes of the anonymous profile on the first tab to the user's identity. The service does not merge the anonymous profile that is created on the second tab to the user's identity stored in App ID. But the user can still access the shorts anonymously on the second tab because they are still accessible with the anonymous profile that was created on the second tab. While you develop your app, you can configure how to attach anonymous attributes to identified user profiles.\n\n\n\n What does the progressive authentication flow look like? \n\nIn the following image, you can see the direction of communication that defines the progressive authentication flow between the user, your application, App ID, and the identity provider.\n\nZoom\n\n![The path to becoming an identified user when they start as anonymous](https://cloud.ibm.com/docs-content/v1/content/27ecaa7a29890634603881a8e64789974a29916b/appid/images/auth-anon-user.svg)\n\nFigure 1. Progressive authentication flow of anonymous user\n\n\n\n1. The user interacts with areas of your app that do not require authentication.\n2. Your application notifies App ID that the user wants to interact with your app as an anonymous user.\n3. App ID creates an ad hoc user profile and calls the OAuth login that issues anonymous tokens for the anonymous user.\n4. Using the anonymous tokens from App ID, you can create, read, update, and delete the attributes that are stored in the anonymous user profile.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-anonymous"}, {"document_id": "ibmcld_02774-7-1960", "score": 15.82542, "text": "\nPreregistering future users \n\nWith IBM Cloud\u00ae App ID, you can start building a profile for users that you know are going to need access to your app before their initial sign-in.\n\nTo learn more about the security considerations that might apply when you work with custom attributes, see [Storing and accessing user profiles](https://cloud.ibm.com/docs/appid?topic=appid-profiles).\n\n\n\n Understanding preregistration \n\nThere might be times when you are developing an application that you already know who your app users are going to be. These users are known as \"future users\". You might know ahead of time that certain users need specific permission levels or a specific food preference before they ever start interacting with your app. For example, you work for a development company and you hire a new person to function as a team lead. You might want to assign that user admin access to your app before they start so that when they sign in the first time, they can immediately start working without any further interaction on your part. Say that same person is a vegetarian. By noting it as a custom attribute in their profile, the preference can be pulled for all team lunches without them having to remind you.\n\nBy default, the ability for users to change their own custom attributes through the application is set to off. You can give your users that ability, but before you do be sure that you understand and have considered the [security issues](https://cloud.ibm.com/docs/appid?topic=appid-profilesprofile-set-custom) that can arise.\n\nTo assign custom attributes for future users, you can use either [the GUI](https://cloud.ibm.com/docs/appid?topic=appid-preregisterpreregister-gui) or the [preregistration endpoint](https://cloud.ibm.com/docs/appid?topic=appid-preregisterpreregister-api).\n\n\n\n How are users identified? \n\nYou can identify your users by using one of the following:\n\n\n\n* The email address with which the user signs in to your app.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-preregister"}]}
{"task_id": "1dcbbeb35d4d25ba1ffb787a9f2080e2<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02746-7-1681", "score": 17.142982, "text": "\nDefining password policies \n\nPassword policies, such as strength requirements, help you to enforce more secure applications. By defining advanced policies, you can define the rules that a user must conform to when they set their password or attempt to sign in to your app. For example, you can set the number of times that a user can try to sign in before they are locked out of their account.\n\n\n\n Policy: password strength \n\nA strong password makes it difficult, or even improbable for someone to guess the password in either a manual or automated way. To set requirements for the strength of a user's password, you can use the following steps.\n\nTo set this configuration by using the GUI:\n\n\n\n1. Go to the Cloud Directory > Password policies tab of the App ID dashboard.\n2. In the Define password strength box, click Edit. A screen opens.\n3. Enter a valid regex string in the Password strength box.\n\nExamples:\n\n\n\n* Must be at least 8 characters. (^.{8,}$)\n* Must have one number, one lowercase letter, and one capital letter. (^(?:(?=.d)(?=.[a-z])(?=.[A-Z]).)$)\n* Must have only English letters and numbers. (^[A-Za-z0-9]$)\n* Must have at least one unique character. (^(w)w?(?!1)w+$)\n\n\n\n4. Click Save.\n\n\n\nPassword strength can be set in the Cloud Directory settings page in the App ID dashboard, or by using [the management APIs](https://us-south.appid.cloud.ibm.com/swagger-ui//Management%20API%20-%20Config/mgmt.set_cloud_directory_password_regex).\n\n\n\n Setting a custom error message \n\nIf you set your own password regex policy and a user chooses a password that does not meet your requirements, the default message is The password doesn't meet the strength requirements.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-cd-strength"}, {"document_id": "ibmcld_02746-1213-3197", "score": 13.607404, "text": "\nPassword strength can be set in the Cloud Directory settings page in the App ID dashboard, or by using [the management APIs](https://us-south.appid.cloud.ibm.com/swagger-ui//Management%20API%20-%20Config/mgmt.set_cloud_directory_password_regex).\n\n\n\n Setting a custom error message \n\nIf you set your own password regex policy and a user chooses a password that does not meet your requirements, the default message is The password doesn't meet the strength requirements. You can also choose to set your own message by using the [/management/v4/{tenantId}/config/cloud_directory/password_regex endpoint](https://us-south.appid.cloud.ibm.com/swagger-ui//Management%20API%20-%20Config/mgmt.set_cloud_directory_password_regex).\n\n\n\n\n\n\n\n Advanced password policies \n\nYou can enhance the security of your application by enforcing password constraints.\n\nYou can create an advanced password policy that consists of any combination of the following five features:\n\n\n\n* Lockout after repeated wrong credentials\n* Avoid password reuse\n* Password expiration\n* Minimum period between password changes\n* Ensure that the password does not include user name\n\n\n\nWhen you enable this feature, extra billing for advanced security capabilities is activated. For more information, see [how does App ID calculate pricing](https://cloud.ibm.com/docs/appid?topic=appid-pricing).\n\n\n\n Policy: Avoid Password Reuse \n\nYou might want to prevent your users from choosing a recently used password when they attempt to create a new one. If they try to set their password to one that was recently used, an error is shown in the default Login Widget GUI and the user is prompted to enter another option. This setting allows for you to choose the number of passwords that a user must have before they're able to repeat a previously used password.\n\nTo set this configuration by using the GUI:\n\n\n\n1. Go to the Cloud Directory > Password policies tab of the App ID dashboard.\n2. Toggle Advanced password policy to Enabled.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-cd-strength"}, {"document_id": "ibmcld_07765-0-1628", "score": 13.155418, "text": "\n\n\n\n\n\n\n  IA-5 (4) - Automated Support for Password Strength Determination \n\n\n\n  Control requirements \n\nIA-5 (4) - 0\n:   The organization employs automated tools to determine if password authenticators are sufficiently strong to satisfy [Assignment: organization-defined requirements].\n\n\n\n\n\n  IBM Cloud for Financial Services profile \n\nThe rules related to this control that follow are part of the IBM Cloud for Financial Services v1.2.0 profile in [IBM Cloud\u00ae Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\n\n\n*  Check whether App ID advanced password policies are enabled\n*  IBMid employs automated tools to determine if password authenticators satisfy IBMid password requirements\n*  Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n*  Check whether App ID password strength regex is configured\n*  Check whether IBMid password policy policy contains spaces or any of the following characters: ;:(\"?)<>\n*  Check whether VPN for VPC authentication is configured with a strong pre-shared key with at least # characters\n*  Check whether IBMid password policy requires at least one uppercase letter\n*  Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n\n\n\n\n\n\n\n  NIST supplemental guidance \n\nThis control enhancement focuses on the creation of strong passwords and the characteristics of such passwords (e.g., complexity) prior to use, the enforcement of which is carried out by organizational information systems in IA-5 (1).\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-ia-5.4"}, {"document_id": "ibmcld_02779-11079-12973", "score": 11.099997, "text": "\n: Require users to enter a second form of authentication during sign-in to increase the security of your app. With Cloud Directory, the first factor is the user's password that they would normally use. Then, the service sends the user a one-time code through SMS that the user must enter before they can gain access to your app. For more information, see [Multi-factor authentication](https://cloud.ibm.com/docs/appid?topic=appid-cd-mfa).\n\n\n\n\n\n 11 December 2018 \n\nCloud Directory: Multi-factor authentication - Email\n: Require users to enter a second form of authentication during sign-in to increase the security of your app. With Cloud Directory, the first factor is the user's password that they would normally use. Then, the service sends the user a one-time code through the email that is registered that the user must enter before they can gain access to your app. For more information, see [Multi-factor authentication](https://cloud.ibm.com/docs/appid?topic=appid-cd-mfa).\n\nCloud Directory: Password policies\n: Further enforce app security by specifying rules that users must adhere to when they create the password that they use to sign in. For example, you can set an advanced policy that dictates the number of times a password must change before a user can reuse a previous password. Or, you can prevent users from creating a password that contains their username or email address. For more information, see [Defining password policies](https://cloud.ibm.com/docs/appid?topic=appid-cd-strength).\n\n\n\n\n\n 17 March 2017 \n\nIntroducing App ID\n: IBM Cloud App ID allows you to easily add authentication to web and mobile apps. You no longer have to worry about setting up infrastructure for identity, ensuring geo-availability, and confirming compliance regulations. Instead, you can enhance your apps with advanced security capabilities like multifactor authentication and single sign-on.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-release-notes"}, {"document_id": "ibmcld_02746-7454-8167", "score": 10.937985, "text": "\n\"user_id\" : \"356e065e-49da-45f6-afa3-091a7b464f51\"\n}\n\n\n\n\n\n\n\n Policy: Ensure that the password does not include user name \n\nFor stronger passwords, you might want to prevent users from creating a password that contains their username or the first part of their email address.\n\nTo set this configuration by using the GUI:\n\n\n\n1. Go to the Cloud Directory > Password policies tab of the App ID dashboard.\n2. Toggle Advanced password policy to Enabled.\n3. Toggle Password should not contain user ID to Enabled.\n4. Click Save.\n\n\n\nThis constraint is not case-sensitive. Users are not able to alter the case of some or all the characters to use the personal information. To configure this option, toggle the switch to on.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-cd-strength"}, {"document_id": "ibmcld_02775-4830-5961", "score": 10.699836, "text": "\nFor a complete list of the options and setup information, see [Advanced password management](https://cloud.ibm.com/docs/appid?topic=appid-cd-strengthcd-advanced-password). \n\n\n\nThese features are available only to those instances that are on the graduated tier pricing plan and that were created after 15 March 2018.\n\n\n\n\n\n When am I charged? \n\nYour first 1000 authentication events and 1000 authorized users per service instance are free of charge. You are charged monthly for any additional authentication events and authorized users, as well as any advanced security features that are enabled for each service instance.\n\n\n\n\n\n How do I stop getting charged for App ID? \n\nIf you no longer want to be charged for authentication events and authorized users, you need to ensure that no user can authenticate by using App ID. You must remove the App ID configuration from your app code or confirm that your users are not able to use the configuration to log in to your app. To stop getting charged for advance security features, you must disable them on the Manage Authentication > Authentication Settings page of the service dashboard.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-pricing"}, {"document_id": "ibmcld_02775-3372-5498", "score": 10.284617, "text": "\nYou incur an extra charge when you enable them. For example, if you obtain 10,000 access tokens, then you turn on password policy management and obtain 10,000 more. You would pay for 20,000 authentication events and 10,000 advanced security events. If you disable all the advanced features, your account reverts to the original-cost policy.\n\n\n\nTable 1. Description of the benefits that are gained with advanced authentication events\n\n Feature Benefit \n\n Multi-factor authentication With [MFA for Cloud Directory](https://cloud.ibm.com/docs/appid?topic=appid-cd-mfacd-mfa), you can confirm a user\u2019s identity by requiring them to enter a one time passcode that is sent to their email or SMS after they enter their email and password. \n Runtime authentication activity tracking By integrating Activity Tracker with App ID, you can track different types of authentication events at run time. For example, a password reset request, authentication failures, or a user logout. For more information, see [Viewing runtime events](https://cloud.ibm.com/docs/appid?topic=appid-at-eventsat-monitor-runtime). \n Password policy management As an account owner, you can enforce more secure passwords for Cloud Directory by configuring a set of rules that user passwords must conform to. Examples include, the number of attempted sign-ins before lockout, expiration times, minimum time span between password updates, or the number of times that a password can't be repeated. For a complete list of the options and setup information, see [Advanced password management](https://cloud.ibm.com/docs/appid?topic=appid-cd-strengthcd-advanced-password). \n\n\n\nThese features are available only to those instances that are on the graduated tier pricing plan and that were created after 15 March 2018.\n\n\n\n\n\n When am I charged? \n\nYour first 1000 authentication events and 1000 authorized users per service instance are free of charge. You are charged monthly for any additional authentication events and authorized users, as well as any advanced security features that are enabled for each service instance.\n\n\n\n\n\n How do I stop getting charged for App ID?", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-pricing"}, {"document_id": "ibmcld_07860-2886-4871", "score": 10.211271, "text": "\nSecurity strength requirements associated with such capabilities, functions, and mechanisms include degree of correctness, completeness, resistance to direct attack, and resistance to tampering or bypass. Security assurance requirements include: (i) development processes, procedures, practices, and methodologies; and (ii) evidence from development and assessment activities providing grounds for confidence that the required security functionality has been implemented and the required security strength has been achieved. Security documentation requirements address all phases of the system development life cycle. Security functionality, assurance, and documentation requirements are expressed in terms of security controls and control enhancements that have been selected through the tailoring process. The security control tailoring process includes, for example, the specification of parameter values through the use of assignment and selection statements and the specification of platform dependencies and implementation information. Security documentation provides user and administrator guidance regarding the implementation and operation of security controls. The level of detail required in security documentation is based on the security category or classification level of the information system and the degree to which organizations depend on the stated security capability, functions, or mechanisms to meet overall risk response expectations (as defined in the organizational risk management strategy). Security requirements can also include organizationally mandated configuration settings specifying allowed functions, ports, protocols, and services. Acceptance criteria for information systems, information system components, and information system services are defined in the same manner as such criteria for any organizational acquisition or procurement. The Federal Acquisition Regulation (FAR) Section 7.103 contains information security requirements from FISMA.", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-sa-4"}, {"document_id": "ibmcld_02741-10910-12836", "score": 9.972033, "text": "\nBefore you call the /change_password API to allow a user to reset their password, it is highly recommended to check whether the context has a successful result by using the /forgot_password/confirmation_result endpoint. This operation adds a higher level of security to your back-end reset password process and ensures that a user can modify their password only if the context is still valid.\n\nTo update a user's password after a reset request, supply the following data in the request body:\n\n\n\n* Your tenantID.\n* The user's new password.\n* The Cloud Directory user UUID.\n* Optional: The IP address from which the password reset was performed. If you choose to pass the IP address, then the placeholder %{passwordChangeInfo.ipAddress} is available for the change password email template.\n\n\n\nDepending on your configuration, when a password is changed App ID sends an email to the user that lets them know that a change was made.\n\nTo allow users to change their password while they are signed in to your app, supply the following data in the request body:\n\n\n\n* Your tenantID.\n* The user's new password.\n* The Cloud Directory user UUID.\n\n\n\nYour change password page must prompt the user to enter their current password and their new password.\n\nYour back-end validates the user's current password with the ROP API, and if valid, calls the endpoint with the new password. Depending on your configuration, when a password is changed App ID might send an email to the user letting them know that there was a change.\n\n\n\n\n\n Resend \n\nYou can use the /resend/<templateName> to resend an email when a user does not receive it for some reason.\n\nSupply the following data in the request body:\n\n\n\n* The tenantID.\n* The template name\n* The Cloud Directory user UUID.\n\n\n\n\n\n\n\n Change details \n\nWhen a user is signed in to your app, they can update some of their information. You can use the /Users/<userID> to get and update their information.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-branded"}, {"document_id": "ibmcld_10916-16473-18734", "score": 9.96489, "text": "\nSee also [image](https://cloud.ibm.com/docs/overview?topic=overview-glossaryx2024928), [registry](https://cloud.ibm.com/docs/overview?topic=overview-glossaryx2064940), [layer](https://cloud.ibm.com/docs/overview?topic=overview-glossaryx2028320).\n\n\n\n\n\n context \n\nEnvironmental or conditional information that can be used to define when rules that restrict access to resources should be applied. A context can be a set of properties or attributes like client IP addresses, office hours, time of day, or multi-factor authentication.\n\n\n\n\n\n context-based restriction \n\nAn access management method that defines and enforces access for resources based on the network location of the access request.\n\n\n\n\n\n control \n\nA technical, administrative, or physical safeguard designed to meet a set of defined security and privacy requirements. Controls exist to prevent, detect, or lessen the ability of a threat to exploit a vulnerability.\n\n\n\n\n\n control assessment \n\nThe evaluation of a configuration for compliance with applicable standards.\n\n\n\n\n\n control library \n\nA collection of similar predefined or custom controls.\n\n\n\n\n\n control specification \n\nA statement that defines the specific security and privacy requirements that a control must meet.\n\n\n\n\n\n coreference \n\nA relationship between two words or phrases in which both refer to the same person or thing and one stands as a linguistic antecedent of the other. For example, there is a coreference between the two pronouns in the phrase \"She taught herself\" but not in the phrase \"She taught her\". A coreference links two equivalent entities in the same text.\n\n\n\n\n\n coreference chain \n\nA list of entities that were annotated as coreferences. When a mention is annotated as a coreference, the system creates a coreference chain. The coreference chain provides a way to view all of the mentions in context and verify that all of the occurrences belong together under the same entity type.\n\n\n\n\n\n corpus \n\nA collection of source documents that are used to train a machine learning model.\n\n\n\n\n\n credential \n\nInformation acquired during authentication that describes a user, group associations, or other security-related identity attributes, and that is used to perform services such as authorization, auditing, or delegation.", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-glossary"}]}
{"task_id": "1dcbbeb35d4d25ba1ffb787a9f2080e2<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03363-6198-7991", "score": 17.323986, "text": "\nThe statistics can cover a longer time period than the period for which logs of conversations are retained.\n\n![Time period control](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/oview-time.png)\n\nYou can choose whether to view data for a single day, a week, a month, or a quarter. In each case, the data points on the graph adjust to an appropriate measurement period. For example, when viewing a graph for a day, the data is presented in hourly values, but when viewing a graph for a week, the data is shown by day. A week always runs from Sunday through Saturday.\n\nYou can create custom time periods also, such as a week that runs from Thursday to the following Wednesday, or a month that begins on any date other than the first.\n\nThe time shown for each conversation is localized to reflect the time zone of your browser. However, API log calls are always shown in UTC time. As a result, if you choose a single day view, for example, the time shown in the visualization might differ from the timestamp specified in the log for the same conversation.\n\n![Time period control](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/oview-time2.png)\n* Intents and Entities filters - Use either of these drop-down filters to show data for a specific intent or entity in your skill.\n\nThe intent and entities filters are populated by the intents and entities in the skill, and not what is in the data source. If you have [selected a data source](https://cloud.ibm.com/docs/assistant?topic=assistant-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs-overview"}, {"document_id": "ibmcld_05088-35529-37138", "score": 14.034128, "text": "\nThe new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\ndef add_protection_configuration_to_bucket(bucket_name):\ntry:\nnew_protection_config = {\n\"Status\": \"Retention\",\n\"MinimumRetention\": {\"Days\": 10},\n\"DefaultRetention\": {\"Days\": 100},\n\"MaximumRetention\": {\"Days\": 1000}\n}\n\ncos.put_bucket_protection_configuration(Bucket=bucket_name, ProtectionConfiguration=new_protection_config)\n\nprint(\"Protection added to bucket {0}n\".format(bucket_name))\nexcept ClientError as be:\nprint(\"CLIENT ERROR: {0}n\".format(be))\nexcept Exception as e:\nprint(\"Unable to set bucket protection config: {0}\".format(e))\nShow more\n\n\n\n\n\n Check protection on a bucket \n\ndef get_protection_configuration_on_bucket(bucket_name):\ntry:\nresponse = cos.get_bucket_protection_configuration(Bucket=bucket_name)\nprotection_config = response.get(\"ProtectionConfiguration\")\n\nprint(\"Bucket protection config for {0}n\".format(bucket_name))\nprint(protection_config)\nprint(\"n\")\nexcept ClientError as be:\nprint(\"CLIENT ERROR: {0}n\".format(be))\nexcept Exception as e:\nprint(\"Unable to get bucket protection config: {0}\".format(e))\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-python"}, {"document_id": "ibmcld_03354-4-1897", "score": 13.819448, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Improve your skill \n\nThe Analytics page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nTo open a list of individual messages between customers and the assistant that uses this dialog skill, select User conversations in the navigation bar.\n\nWhen you open the User conversations page, the default view lists inputs that were submitted to the assistant for the last day, with the newest results first. The top intent (#intent) and any recognized entity (@entity) values used in a message, and the message text are available. For intents that are not recognized, the value shown is Irrelevant. If an entity is not recognized, or has not been provided, the value shown is No entities found.\n\n![Logs default page](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/logs_page1.png)\n\nThe User conversations page displays the total number of messages between customers and your assistant. A message is a single utterance that a user sends to the assistant. A conversation typically consists of multiple messages. Therefore, the number of results on the User conversations page is different from the number of conversations that are shown on the Overview page.\n\n\n\n Log limits \n\nThe length of time for which messages are retained depends on your Watson Assistant service plan:\n\nService plan | Chat message retention\n------------------------------------ | ------------------------------------\nEnterprise with Data Isolation | Last 90 days\nEnterprise | Last 30 days\nPremium (legacy) | Last 90 days\nPlus | Last 30 days", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs"}, {"document_id": "ibmcld_09950-6051-7138", "score": 13.813013, "text": "\nUpdating retention time interval (time travel) for tables \n\n\n\n1. Go to Databases.\n2. Select the database and schema in which the table that you want to update is.\n3. Select the table.\n4. From the overflow menu, click Update interval.\n5. Type a retention time interval.\nYou can select between 1 day and up to 99 days, or zero to alter a temporal database to nontemporal. For more information on retention time interval and time travel, see [Netezza Performance Server time travel](https://cloud.ibm.com/docs/netezza?topic=netezza-enablingdisabling_tt).\n6. Click Save.\n\n\n\n\n\n\n\n Dropping tables \n\n\n\n1. Go to Databases.\n2. Select the database and schema in which the table that you want to update is.\n3. Select the table.\n4. From the overflow menu, click Drop.\n5. Confirm your choice by clicking Drop.\n\n\n\n\n\n\n\n Viewing space usage (time travel) \n\n\n\n1. Go to Databases.\n2. Select the database and schema in which the temporal table that you want to analyze is located.\n3. Select the table.\n4. Go to the Time travel tab.\n5. Analyze the data.\nYou can view the information in a list or as a chart.", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-create-tables"}, {"document_id": "ibmcld_05070-25374-27355", "score": 13.760449, "text": "\nThe retention period of an object can only be extended. It cannot be decreased from the currently configured value.\n\nThe retention expansion value is set in one of three ways:\n\n\n\n* additional time from the current value (Additional-Retention-Period or similar method)\n* new extension period in seconds (Extend-Retention-From-Current-Time or similar method)\n* new retention expiry date of the object (New-Retention-Expiration-Date or similar method)\n\n\n\nThe current retention period stored in the object metadata is either increased by the given additional time or replaced with the new value, depending on the parameter that is set in the extendRetention request. In all cases, the extend retention parameter is checked against the current retention period and the extended parameter is only accepted if the updated retention period is greater than the current retention period.\n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nfunction extendRetentionPeriodOnObject(bucketName, objectName, additionalSeconds) {\nconsole.log(Extend the retention period on ${objectName} in bucket ${bucketName} by ${additionalSeconds} seconds.);\nreturn cos.extendObjectRetention({\nBucket: bucketName,\nKey: objectName,\nAdditionalRetentionPeriod: additionalSeconds\n}).promise()\n.then((data) => {\nconsole.log(New retention period on ${objectName} is ${data.RetentionPeriod});\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\n\n\n\n\n\n List legal holds on a protected object \n\nThis operation returns:\n\n\n\n* Object creation date\n* Object retention period in seconds\n* Calculated retention expiration date based on the period and creation date\n* List of legal holds\n* Legal hold identifier", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-node"}, {"document_id": "ibmcld_09955-1464-2581", "score": 13.753394, "text": "\nType a new name for the database.\nIf the name contains special characters, enclose it in double quotation marks. The dot character (\".\") is not supported.\n5. Click Rename.\n\n\n\n\n\n\n\n Updating retention time interval (time travel) for databases \n\n\n\n1. Go to Databases.\n2. Select the database for which you want to update the retention time interval.\n3. From the overflow menu, click Update interval.\n4. Type a retention time interval.\nYou can select between 1 day and up to 99 days, or zero to alter a temporal database to nontemporal. For more information on retention time interval and time travel, see [Netezza Performance Server time travel](https://cloud.ibm.com/docs/netezza?topic=netezza-enablingdisabling_tt).\n5. Click Save.\n\n\n\n\n\n\n\n Viewing privileges for databases \n\n\n\n1. Go to Databases.\n2. Select the database which privileges you want to view.\n3. From the overflow menu, click Show privileges.\nA list of privileges is now displayed.\n\n\n\n\n\n\n\n Dropping databases \n\n\n\n1. Go to Databases.\n2. Select the database that you want to drop.\n3. From the overflow menu, click Drop.\n4. Confirm your choice by clicking Drop.", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-databases"}, {"document_id": "ibmcld_09956-3082-3744", "score": 13.605873, "text": "\nIdentify the table for which you want to view the retention interval.\n\nThe retention interval is displayed in the Retention time interval (days) column.\n\n\n\n\n\n* For a schema:\n\n\n\n\n\n1. Go to Databases.\n2. Select the database in which the schema that you want to view the retention interval is located.\n3. Identify the schema for which you want to view the retention interval.\n\nThe retention interval is displayed in the Retention time interval (days) column.\n\n\n\n\n\n* For a database:\n\n\n\n\n\n1. Go to Databases.\n2. Identify the database for which you want to view the retention interval.\n\nThe retention interval is displayed in the Retention time interval (days) column.", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-dataretentioninterval_tt"}, {"document_id": "ibmcld_05032-3142-5463", "score": 13.494954, "text": "\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention \n\nAllows the user to set the object to be stored indefinitely until a new retention period is applied. This is set at a per object level.\n\n\n\n\n\n Event-based retention \n\nImmutable Object Storage allows users to set indefinite retention on the object if they are unsure of the final duration of the retention period, or want to use event-based retention. Once set to indefinite, user applications can then can change the object retention to a finite value later. For example, a company has a policy of retaining employee records for three years after the employee leaves the company. When an employee joins the company, the records that are associated with that employee can be indefinitely retained. When the employee leaves the company, the indefinite retention is converted to a finite value of three years from the current time, as defined by company policy. The object is then protected for three years after the retention period change. A user or third-party application can change the retention period from indefinite to finite retention that uses an SDK or REST API.\n\n\n\n\n\n Permanent retention \n\nPermanent retention ensures that data can not be deleted, ever, by anyone. Read the documentation carefully and do not use permanent retention unless there is a compelling regulatory or compliance need for permanent data storage.\n\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_04866-3142-5463", "score": 13.494954, "text": "\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention \n\nAllows the user to set the object to be stored indefinitely until a new retention period is applied. This is set at a per object level.\n\n\n\n\n\n Event-based retention \n\nImmutable Object Storage allows users to set indefinite retention on the object if they are unsure of the final duration of the retention period, or want to use event-based retention. Once set to indefinite, user applications can then can change the object retention to a finite value later. For example, a company has a policy of retaining employee records for three years after the employee leaves the company. When an employee joins the company, the records that are associated with that employee can be indefinitely retained. When the employee leaves the company, the indefinite retention is converted to a finite value of three years from the current time, as defined by company policy. The object is then protected for three years after the retention period change. A user or third-party application can change the retention period from indefinite to finite retention that uses an SDK or REST API.\n\n\n\n\n\n Permanent retention \n\nPermanent retention ensures that data can not be deleted, ever, by anyone. Read the documentation carefully and do not use permanent retention unless there is a compelling regulatory or compliance need for permanent data storage.\n\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05044-62456-64487", "score": 13.465668, "text": "\nThe retention period of an object can only be extended. It cannot be decreased from the currently configured value.\n\nThe retention expansion value is set in one of three ways:\n\n\n\n* additional time from the current value (Additional-Retention-Period or similar method)\n* new extension period in seconds (Extend-Retention-From-Current-Time or similar method)\n* new retention expiry date of the object (New-Retention-Expiration-Date or similar method)\n\n\n\nThe current retention period stored in the object metadata is either increased by the given additional time or replaced with the new value, depending on the parameter that is set in the extendRetention request. In all cases, the extend retention parameter is checked against the current retention period and the extended parameter is only accepted if the updated retention period is greater than the current retention period.\n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\npublic static void extendRetentionPeriodOnObject(String bucketName, String objectName, Long additionalSeconds) {\nSystem.out.printf(\"Extend the retention period on %s in bucket %s by %s seconds.n\", objectName, bucketName, additionalSeconds);\n\nExtendObjectRetentionRequest req = new ExtendObjectRetentionRequest(\nbucketName,\nobjectName)\n.withAdditionalRetentionPeriod(additionalSeconds);\n\ncos.extendObjectRetention(req);\n\nSystem.out.printf(\"New retention period on %s is %sn\", objectName, additionalSeconds);\n}\n\n\n\n\n\n List legal holds on a protected object \n\nThis operation returns:\n\n\n\n* Object creation date\n* Object retention period in seconds\n* Calculated retention expiration date based on the period and creation date\n* List of legal holds\n* Legal hold identifier\n* Timestamp when legal hold was applied", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-java"}]}
{"task_id": "1dcbbeb35d4d25ba1ffb787a9f2080e2<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02844-3227-3811", "score": 16.420063, "text": "\nconversation.synonym.delete deletes a synonym that is associated with an entity value. \n conversation.synonym.update edits a synonym that is associated with an entity value. \n conversation.userdata.delete deletes data that was created by a specified customer. \n conversation.value.create creates an entity value. \n conversation.value.delete deletes an entity value. \n conversation.value.update edits an entity value. \n conversation.workspace.create creates a workspace. \n conversation.workspace.delete deletes a workspace. \n conversation.workspace.update makes changes to a workspace.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-audit-events"}, {"document_id": "ibmcld_16280-4696-6712", "score": 14.157733, "text": "\nYou can configure how and where the web chat widget appears, and you can use theming to align it with your branding and website design. If a customer needs help from a person, the web chat integration can transfer the conversation to an agent.\n* [Phone integration](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone): The phone integration enables your assistant to converse with customers on the phone by using the IBM Watson Text to Speech and Speech to Text services. If your customer asks to speak to a person, the phone integration can transfer the call to an agent.\n\n\n\n\n\n\n\n Updating and managing channels \n\nEach channel has specific settings that you can adjust to adapt the end experience for your user. You can edit these settings by selecting the channel in an environment, or in Integrations.\n\nIf you make an update to a channel in the draft environment, the same channel in live environment is not affected in the live environment. Similarly, if you make an update to a channel in the live environment, the same channel in draft environment is not affected. If you select a channel from the Integrations page, you are asked to select which environment you are editing.\n\nFor more information about editing your web chat integration, see [Basic web chat configuration](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-overview).\n\n\n\n\n\n Deleting channels \n\nTo delete a channel, go to the Integrations page and use the overflow menu on the integration:\n\n![GIF of how to delete a channel](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/delete-channel.gif)\n\nIf you deployed your assistant to a channel, then deleting the channel does not remove the assistant from the channel. For example, if you deploy web chat, you paste the JavaScript snippet into the HTML header of your website. Deleting your channel disconnects your content from the customer experience that is shown on your website.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-assistant"}, {"document_id": "ibmcld_02844-1555-3643", "score": 14.146394, "text": "\nconversation.counterexample.update edits a counterexample. \n conversation.data.update does a bulk action, such as importing a CSV file of intents or entities to the skill, or deleting multiple training data items, such as multiple entities or intents. \n conversation.entity.create creates an entity. \n conversation.entity.delete deletes an entity. \n conversation.entity.update edits an entity. \n conversation.example.create adds a user input example to an intent. \n conversation.example.delete deletes a user example from an intent. \n conversation.example.update edits a user example that is associated with an intent. \n conversation.intent.create creates an intent. \n conversation.intent.delete deletes an intent. \n conversation.intent.update edits an intent. \n conversation.log.create corrects an intent that was inaccurately categorized by the skill from the Analytics>User conversations page. \n conversation.node.create creates a dialog node. \n conversation.node.delete deletes a dialog node. \n conversation.node.update edits a dialog node. \n conversation.skill.create creates a skill, either dialog or search. \n conversation.skill.delete deletes a skill. \n conversation.skill.update updates a skill. \n conversation.skill_reference.create adds a specific skill to an assistant. \n conversation.skill_reference.delete removes a specific skill from an assistant. \n conversation.skill_reference.update updates a specific skill that is associated with an assistant. \n conversation.snapshot.create creates a version of a dialog skill. \n conversation.snapshot.delete deletes a version of a dialog skill. \n conversation.synonym.create creates a synonym for an entity value. \n conversation.synonym.delete deletes a synonym that is associated with an entity value. \n conversation.synonym.update edits a synonym that is associated with an entity value. \n conversation.userdata.delete deletes data that was created by a specified customer. \n conversation.value.create creates an entity value. \n conversation.value.delete deletes an entity value. \n conversation.value.update edits an entity value.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-audit-events"}, {"document_id": "ibmcld_03109-8981-10943", "score": 14.111579, "text": "\nOnly data that was added by using the POST /message API endpoint with an associated customer ID can be deleted using this delete method. Data that was added by other methods cannot be deleted based on customer ID. For example, entities and intents that were added from customer conversations, cannot be deleted in this way. Personal Data is not supported for those methods.\n\nIMPORTANT: Specifying a customer_id will delete all messages with that customer_id that were received before the delete request, across your entire Watson Assistant instance, not just within one skill.\n\nAs an example, to delete any message data associated with a user that has the customer ID abc from your Watson Assistant instance, send the following cURL command:\n\ncurl -X DELETE -u \"apikey:3Df... ...Y7Pc9\" \"{url}/v2/user_data?customer_id=abc&version=2020-04-01\"\n\nwhere {url} is the appropriate URL for your instance. For more details, see [Service endpoint](https://cloud.ibm.com/apidocs/assistant/assistant-v2service-endpoint).\n\nAn empty JSON object {} is returned.\n\nFor more information, see the [API reference](https://cloud.ibm.com/apidocs/assistant/assistant-v2deleteuserdata).\n\nNote: Delete requests are processed in batches and may take up to 24 hours to complete.\n\n\n\n\n\n\n\n Web chat usage data \n\nThe Watson Assistant web chat sends limited usage data to the [Amplitude service](https://amplitude.com/). When the web chat widget is being interacted with by a user, we track the features that are being used, and events such as how many times the widget is opened and how many users start conversations. This information does not include Assistant training data or the content of any chat interactions. The information being sent to Amplitude is not Content as defined in the Cloud Service Agreement (CSA); it is Account Usage Information as described in Section 9.d of the CSA and is handled accordingly as described in the [IBM Privacy Statement](https://www.ibm.com/privacy).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-admin-securing"}, {"document_id": "ibmcld_03037-4321-6111", "score": 13.534475, "text": "\nAssociating message data with a user for deletion \n\nThere might come a time when you want to completely remove a set of your user's data from a Watson Assistant instance. When the delete feature is used, then the Overview metrics will no longer reflect those deleted messages; for example, they will have fewer Total Conversations.\n\n\n\n Before you begin \n\nTo delete messages for one or more individuals, you first need to associate a message with a unique Customer ID for each individual. To specify the Customer ID for any message sent using the /message API, include the X-Watson-Metadata: customer_id property in your header. You can pass multiple Customer ID entries with semicolon separated field=value pairs, using customer_id, as in the following example:\n\ncurl -X POST -u \"apikey:3Df... ...Y7Pc9\" --header \"Content-Type: application/json\" \"X-Watson-Metadata: customer_id={first-customer-ID};customer_id={second-customer-ID}\" --data \"{\"input\":{\"text\":\"hello\"}}\" \"{url}/v2/assistants/{assistant_id}/sessions/{session_id}/message?version=2019-02-28\"\n\nwhere {url} is the appropriate URL for your instance. For more details, see [Service endpoint](https://cloud.ibm.com/apidocs/assistant-data-v2service-endpoint) }.\n\nThe customer_id string cannot include the semicolon (;) or equal sign (=) characters. You are responsible for ensuring that each Customer ID parameter is unique across your customers.\n\nTo delete messages using customer_id values, see the [Information security](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-information-securityinformation-security-gdpr-wa) topic.\n\n\n\n\n\n\n\n Jupyter notebooks \n\nIBM created Jupyter notebooks that you can use to analyze the behavior or your assistant. A Jupyter notebook is a web-based environment for interactive computing.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-resources"}, {"document_id": "ibmcld_03109-5081-6683", "score": 12.965771, "text": "\nThe Intercom user_id property is the id of the author message object in the Conversation Model that is defined by Intercom.\n\n\n\n* To get the ID, open the channel from a web browser. Open the web developer tools to view the console. Look for author.\n\n\n\nThe full customer ID looks like this: customer_id=intercom_5c499e5535ddf5c7fa2d72b3.\n* For Slack, the customer_id is the user_id prepended with slack_. The Slack user_id property is a concatenation of the team ID, such as T09LVDR7Y, and the member ID of the user, such has W4F8K9JNF. For example: T09LVDR7YW4F8K9JNF.\n\n\n\n* To get the team ID, open the channel from a web browser. Open the web developer tools to view the console. Look for [BOOT] Initial team ID.\n* You can copy the member ID from the user's Slack profile.\n* To get the IDs programmatically, use the Slack API. For more information, see [Overview](https://api.slack.com/apis). The full customer ID looks like this: customer_id=slack_T09LVDR7YW4F8K9JNF.\n\n\n\n* For the web chat integration, the service takes the user_id that is passed in and adds it as the customer_id parameter value to the X-Watson-Metadata header with each request.\n\n\n\n\n\n Before you begin \n\nTo be able to delete message data associated with a specific user, you must first associate all messages with a unique customer ID for each user. To specify the customer ID for any messages sent using the /message API, include the X-Watson-Metadata: customer_id property in your header. For example:\n\ncurl -X POST -u \"apikey:3Df... ...Y7Pc9\"\n--header\n'Content-Type: application/json'\n'X-Watson-Metadata: customer_id=abc'\n--data", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-admin-securing"}, {"document_id": "ibmcld_16255-9219-11036", "score": 12.670825, "text": "\nAs an example, to delete any message data associated with a user that has the customer ID abc from your Watson Assistant instance, send the following cURL command:\n\ncurl -X DELETE -u \"apikey:3Df... ...Y7Pc9\" \"{url}/v2/user_data?customer_id=abc&version=2020-04-01\"\n\nwhere {url} is the appropriate URL for your instance. For more details, see [Service endpoint](https://cloud.ibm.com/apidocs/assistant/assistant-v2service-endpoint).\n\nAn empty JSON object {} is returned.\n\nFor more information, see the [API reference](https://cloud.ibm.com/apidocs/assistant/assistant-v2deleteuserdata).\n\nNote: Delete requests are processed in batches and may take up to 24 hours to complete.\n\n\n\n\n\n\n\n Web chat usage data \n\nThe Watson Assistant web chat sends limited usage data to the [Amplitude service](https://amplitude.com/). When the web chat widget is being interacted with by a user, we track the features that are being used, and events such as how many times the widget is opened and how many users start conversations. This information does not include Assistant training data or the content of any chat interactions. The information being sent to Amplitude is not Content as defined in the Cloud Service Agreement (CSA); it is Account Usage Information as described in Section 9.d of the CSA and is handled accordingly as described in the [IBM Privacy Statement](https://www.ibm.com/privacy). The purpose of this information gathering is limited to establishing statistics about use and effectiveness of the web chat and making general improvements.\n\n\n\n\n\n Private network endpoints \n\nYou can set up a private network for Watson Assistant instances that are part of a Plus or Enterprise service plan. Using a private network prevents data from being transferred over the public internet, and ensures greater data isolation.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-securing"}, {"document_id": "ibmcld_03117-5698-7668", "score": 12.6123705, "text": "\nAfter a conversation ends, use the v2 [Delete session](https://cloud.ibm.com/apidocs/assistant/assistant-v2deletesession) method to delete the session.\n\n\n\nservice .deleteSession({ assistant_id: assistantId, session_id: sessionId, })\n\n {: codeblock python}\nservice.delete_session(\nassistant_id = assistant_id,\nsession_id = session_id\n)\n\n {: codeblock java}\n\nDeleteSessionOptions deleteSessionOptions = new DeleteSessionOptions.Builder(assistantId, sessionId .build(); service.deleteSession(deleteSessionOptions).execute();\n\nIf you do not explicitly delete the session, it will be automatically deleted after the configured timeout interval. (The timeout duration depends on your plan; for more information, see [Session limits](/docs/assistant?topic=assistant-assistant-settingsassistant-settings-session-limits).)\n\nTo see examples of the v2 APIs in the context of a simple client application, see [Building a client application](/docs/assistant?topic=assistant-api-client).\n\n Handle the v2 response format\n\nYour application might need to be updated to handle the v2 runtime response format, depending on which parts of the response your application needs to access:\n\n- Output for all response types (such as text and option) are still returned in the output.generic object. Application code for handling these responses should work without modification.\n\n- Detected intents and entities are now returned as part of the output object, rather than at the root of the response JSON.\n\n- The conversation context is now organized into two objects:\n\n- The global context contains system-level context data shared by all skills used by the assistant.\n\n- The skill context contains any user-defined context variables used by your dialog skill.\n\nHowever, keep in mind that state data, including conversation context, is now maintained by the assistant, so your application might not need to access the context at all (see [Let the assistant maintain state](api-migration-state)).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-migration"}, {"document_id": "ibmcld_16263-4310-6262", "score": 12.201272, "text": "\nservice.deleteSession(deleteSessionOptions).execute();\n\nservice.delete_session(\nassistant_id = assistant_id,\nsession_id = session_id\n)\n\nservice\n.deleteSession({\nassistant_id: assistantId,\nsession_id: sessionId,\n})\n\nIf you do not explicitly delete the session, it will be automatically deleted after the configured timeout interval. The timeout duration depends on your plan.\n\n\n\nTo see examples of the v2 APIs in the context of a simple client application, see [Building a custom client using the API](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-api-client).\n\n\n\n\n\n Handle the v2 response format \n\nYour application might need to be updated to handle the v2 runtime response format, depending on which parts of the response your application needs to access:\n\n\n\n* Output for all response types (such as text and option) are still returned in the output.generic object. Application code for handling these responses should work without modification.\n* Detected intents and entities are now returned as part of the output object, rather than at the root of the response JSON.\n* The conversation context is now organized into two objects:\n\n\n\n* The global context contains system-level context data that is shared by all skills in the assistant.\n* The skill context contains any user-defined context variables that are used by your dialog skill.\n\n\n\nHowever, keep in mind that state data, including conversation context, is now maintained by the assistant, so your application might not need to access the context at all (see [Let the assistant maintain state](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-api-migrationapi-migration-state)).\n\n\n\nRefer to the v2 [API Reference ](https://cloud.ibm.com/apidocs/assistant/assistant-v2message) for complete documentation of the v2 response format.\n\n\n\n\n\n Let the assistant maintain state \n\nFor most applications, you can now remove any code included for maintaining state.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-api-migration"}, {"document_id": "ibmcld_03037-2895-4808", "score": 11.924021, "text": "\nImportant: The User ID property is not equivalent to the Customer ID property, though both can be passed with the message. The User ID field is used to track levels of usage for billing purposes, whereas the Customer ID field is used to support the labeling and subsequent deletion of messages that are associated with end users. Customer ID is used consistently across all Watson services and is specified in the X-Watson-Metadata header. User ID is used exclusively by the Watson Assistant service and is passed in the context object of each /message API call.\n\n\n\n\n\n Enabling user metrics \n\nUser metrics allow you to see, for example, the number of unique users who have engaged with your assistant, or the average number of conversations per user over a given time interval on the [Overview page](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-overview). User metrics are enabled by using a unique User ID parameter.\n\nTo specify the User ID for a message sent using the /message API, include the user_id property in your global [context](https://cloud.ibm.com/apidocs/assistant-data-v2message), as in this example:\n\n\"context\": {\n\"global\": {\n\"system\": {\n\"user_id\": \"{UserID}\"\n}\n}\n}\n\nIf your application is still using the older [v1 runtime API](https://cloud.ibm.com/apidocs/assistant-data-v1?curl=message), the context format is different:\n\n\"context\" : {\n\"metadata\" : {\n\"user_id\": \"{UserID}\"\n}\n}\n\n\n\n\n\n Associating message data with a user for deletion \n\nThere might come a time when you want to completely remove a set of your user's data from a Watson Assistant instance. When the delete feature is used, then the Overview metrics will no longer reflect those deleted messages; for example, they will have fewer Total Conversations.\n\n\n\n Before you begin \n\nTo delete messages for one or more individuals, you first need to associate a message with a unique Customer ID for each individual.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-resources"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02873-7270-8670", "score": 17.575455, "text": "\nThis standard type of node is useful to capture questions about a certain topic and then in the root response ask a follow-up question that is addressed by the child nodes. For example, it might recognize a user question about discounts and ask a follow-up question about whether the user is a member of any associations with which the company has special discount arrangements. And the child nodes provide different responses based on the user's answer to the question about association membership.\n* The second root node is a node with slots. It also conditions on an intent value. It defines a set of slots, one for each piece of information that you want to collect from the user. Each slot asks a question to elicit the answer from the user. It looks for a specific entity value in the user's reply to the prompt, which it then saves in a slot context variable.\n\nThis type of node is useful for collecting details you might need to perform a transaction on the user's behalf. For example, if the user's intent is to book a flight, the slots can collect the origin and destination location information, travel dates, and so on.\n\n\n\n\n\n\n\n Ready to get started? \n\nFor more information, see [Building a dialog](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overview).\n\nNext topic:[Planning the dialog](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-plan)", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-build"}, {"document_id": "ibmcld_03185-6701-8694", "score": 17.568422, "text": "\n[A sample dialog tree with example content](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/dialog-depiction-full.png)\n\nThe dialog tree in this diagram contains two root dialog nodes. A typical dialog tree would likely have many more nodes, but this depiction provides a glimpse of what a subset of nodes might look like.\n\n\n\n* The first root node conditions on an intent value. It has two child nodes that each condition on an entity value. The second child node defines two responses. The first response is returned to the user if the value of the context variable matches the value specified in the condition. Otherwise, the second response is returned.\n\nThis standard type of node is useful to capture questions about a certain topic and then in the root response ask a follow-up question that is addressed by the child nodes. For example, it might recognize a user question about discounts and ask a follow-up question about whether the user is a member of any associations with which the company has special discount arrangements. And the child nodes provide different responses based on the user's answer to the question about association membership.\n* The second root node is a node with slots. It also conditions on an intent value. It defines a set of slots, one for each piece of information that you want to collect from the user. Each slot asks a question to elicit the answer from the user. It looks for a specific entity value in the user's reply to the prompt, which it then saves in a slot context variable.\n\nThis type of node is useful for collecting details you might need to perform a transaction on the user's behalf. For example, if the user's intent is to book a flight, the slots can collect the origin and destination location information, travel dates, and so on.\n\n\n\n\n\n\n\n Ready to get started? \n\nFor more information, see [Creating a dialog](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overview).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-build"}, {"document_id": "ibmcld_02952-3289-5462", "score": 17.264378, "text": "\nAdd meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.\n\n![Screen capture of the field in the node edit view where you add the node purpose summary.](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/disambig-node-purpose.png)\n\nEvery dialog branch can be processed by the assistant while it chats with a customer, including branches with root nodes in folders.\n4. If a child node in any dialog branch conditions on a request or question that you do not want the assistant to handle, add a Connect to human agent response type to the child node.\n\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point.\n\n\n\nYour dialog is now ready to support transfers from your assistant to a service desk agent.\n\n\n\n\n\n Measuring containment \n\nFrom the Analytics page, you can measure conversation containment. Containment is the rate at which your assistant is able to satisfy a customer's request without human intervention per conversation.\n\nTo measure containment accurately, the metric must be able to identify when a human intervention occurs. The metric primarily uses the Connect to human agent response type as an indicator. If a user conversation log includes a call to a Connect to human agent response type, then the conversation is considered to be not contained.\n\nHowever, not all human interventions are transacted by using a Connect to human agent response type. If you use an alternate method to deliver additional support, you must take additional steps to register the fact that the customer's need was not fulfilled by the assistant. For example, you might direct customers to your call center phone number or to an online support ticket form URL.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-support"}, {"document_id": "ibmcld_02882-18936-21214", "score": 17.186682, "text": "\nYou can return responses with multimedia or interactive elements such as images or clickable buttons to simplify the interaction model of your application and enhance the user experience.\n\nIn addition to the default response type of Text, for which you specify the text to return to the user as a response, the following response types are supported:\n\n\n\n* Connect to human agent: The dialog calls a service that you designate, typically a service that manages human agent support ticket queues, to pass off the conversation to a person. You can optionally include a message that summarizes the user's issue to be provided to the human agent. It is the responsibility of the external service to display a message that is shown to the user that explains that the conversation is being transferred. The dialog does not manage that communication itself. The dialog transfer does not occur when you are testing nodes with this response type in the Try it out pane. You must access a node that uses this response type from a test deployment to see how your users will experience it.\n* Image: Embeds an image into the response. The source image file must be hosted somewhere and have a URL that you can use to reference it. It cannot be a file that is stored in a directory that is not publicly accessible.\n* Option: Adds a list of one or more options. When a user clicks one of the options, an associated user input value is sent to your assistant. How options are rendered can differ depending on where you deploy the dialog. For example, in one integration channel the options might be displayed as clickable buttons, but in another they might be displayed as a dropdown list.\n* Pause: Forces the application to wait for a specified number of milliseconds before continuing with processing. You can choose to show an indicator that the dialog is working on typing a response. Use this response type if you need to perform an action that might take some time. For example, a parent node makes a Cloud Function call and displays the result in a child node. You could use this response type as the response for the parent node to give the programmatic call time to complete, and then jump to the child node to show the result. This response type does not render in the Try it out pane.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overview"}, {"document_id": "ibmcld_02952-1632-3754", "score": 17.024647, "text": "\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.\n\nFor example, an insurance company might want questions about bereavement benefits always to be handled by a person. Or, if a customer wants to close an account, you might want to transfer the conversation to a respresentative who is authorized to offer incentives to keep the customer's business.\n* When the assistant repeatedly fails to understand a customer's request. Instead of asking the customer to retry or rephrase the question over and over, your assistant can offer to transfer the customer to a human agent.\n\n\n\nTo design a dialog that can transfer the conversation, complete the following steps:\n\n\n\n1. Add an intent to your skill that can recognize a user's request to speak to a human.\n\nYou can create your own intent or add the prebuilt intent named General_Connect_to_Agent that is provided with the General content catalog.\n2. Add a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-support"}, {"document_id": "ibmcld_03270-4700-6825", "score": 17.01699, "text": "\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point.\n\n\n\nYour dialog is now ready to support transfers from your assistant to a service desk agent.\n\nFor more information about different service desk solutions, see the following resources:\n\n\n\n* [Adding service desk support to the web chat](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-haa)\n* [Integrating with Intercom](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-intercom)\n\n\n\n\n\n\n\n Measuring containment \n\nFrom the Analytics page, you can measure conversation containment. Containment is the rate at which your assistant is able to satisfy a customer's request without human intervention per conversation.\n\nTo measure containment accurately, the metric must be able to identify when a human intervention occurs. The metric primarily uses the Connect to human agent response type as an indicator. If a user conversation log includes a call to a Connect to human agent response type, then the conversation is considered to be not contained.\n\nHowever, not all human interventions are transacted by using a Connect to human agent response type. If you use an alternate method to deliver additional support, you must take additional steps to register the fact that the customer's need was not fulfilled by the assistant. For example, you might direct customers to your call center phone number or to an online support ticket form URL. If so, you need to flag these types of redirects so the containment metric is able to pick them up.\n\nTo enable the containment metric, complete the following steps:\n\n\n\n1. For any dialog nodes that transfer the chat to a service desk agent, add a Connect to human agent response type.\n\nFor more information, see [Adding a Connect to human agent response type](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n2. For any dialog nodes that redirect customers to alternate forms of customer support, add a context variable named context_connect_to_agent and set it to true.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-support"}, {"document_id": "ibmcld_02914-1593-3315", "score": 16.959866, "text": "\nThe following example shows how the output object is represented in the dialog JSON editor:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"values\":\n{\n\"text\": \"This is my response text.\"\n}\n],\n\"response_type\": \"text\",\n\"selection_policy\": \"sequential\"\n}\n]\n}\n}\n\n\n\nIn the resulting API /message response, the text response is formatted as follows:\n\n{\n\"text\": \"This is my response text.\",\n\"response_type\": \"text\"\n}\n\nThe following output object JSON format is supported for backwards compatibility. With the introduction of rich response types, the output.text structure was augmented with the output.generic structure to facilitate supporting other types of responses in addition to text. Use the new format when you create new nodes to give yourself more flexibility, because you can subsequently change the response type, if needed.\n\n{\n\"output\": {\n\"text\": {\n\"values\": [\n\"This is my response text.\"\n]\n}\n}\n}\n\nThere are response types other than a text response that you can define. See [Responses](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-responses) for more details.\n\nYou can learn more about the /message API call from the [API reference](https://cloud.ibm.com/apidocs/assistant/assistant-v2).\n\n\n\n Retaining information across dialog turns \n\nThe dialog in a dialog skill is stateless, meaning that it does not retain information from one interaction with the user to the next. When you add a dialog skill to an assistant and deploy it, the assistant saves the context from one message call and then re-submits it on the next request throughout the current session. The current session lasts for as long a user interacts with the assistant plus the designated session inactivity time frame.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime-context"}, {"document_id": "ibmcld_03113-1615-3683", "score": 16.951159, "text": "\n* A node cannot point to a previous sibling that is a child of a different parent.\n* Two nodes cannot point to the same previous sibling.\n* A node can specify another node that is to be executed next (the next_step property).\n* A node cannot be its own parent or its own sibling.\n* A node must have a type property that contains one of the following values. If no type property is specified, then the type is standard.\n\n\n\n* event_handler: A handler that is defined for a frame node or an individual slot node.\n\n\n\nFrom the tool, you can define a frame node handler by clicking the Manage handlers link from a node with slots. (The tool user interface does not expose the slot-level event handler, but you can define one through the API.)\n\n\n\n* frame: A node with one or more child nodes of type slot. Any child slot nodes that are required must be filled before the service can exit the frame node.\n\n\n\nThe frame node type is represented as a node with slots in the tool. The node that contains the slots is represented as a node of type=frame. It is the parent node to each slot, which is represented as a child node of type slot.\n\n\n\n* response_condition: A conditional response.\n\n\n\nIn the tool, you can add one or more conditional responses to a node. Each conditional response that you define is represented in the underlying JSON as an individual node of type=response_condition.\n\n\n\n* slot: A child node of a node of type frame.\n\n\n\nThis node type is represented in the tool as being one of multiple slots added to a single node. That single node is represented in the JSON as a parent node of type frame.\n\n\n\n* standard: A typical dialog node. This is the default type.\n\n\n\n* For nodes of type slot that have the same parent node, the sibling order (specified by the previous_sibling property) reflects the order in which the slots will be processed.\n* A node of type slot must have a parent node of type frame.\n* A node of type frame must have at least one child node of type slot.\n* A node of type response_condition must have a parent node of type standard or frame.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-dialog-modify"}, {"document_id": "ibmcld_03113-4-2033", "score": 16.656754, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Modifying a dialog using the API \n\nThe Watson Assistant REST API supports modifying your dialog programmatically, without using the Watson Assistant tool. You can use the /dialog_nodes API to create, delete, or modify dialog nodes.\n\nRemember that the dialog is a tree of interconnected nodes, and that it must conform to certain rules in order to be valid. This means that any change you make to a dialog node might have cascading effects on other nodes, or on the structure of your dialog. Before using the /dialog_nodes API to modify your dialog, make sure you understand how your changes will affect the rest of the dialog. You can make a backup copy of the current dialog by exporting the conversational skill in which it resides. See [Downloading a skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-tasksskill-tasks-download) for details.\n\nA valid dialog always satisfies the following criteria:\n\n\n\n* Each dialog node has a unique ID (the dialog_node property).\n* A child node is aware of its parent node (the parent property). However, a parent node is not aware of its children.\n* A node is aware of its immediate previous sibling, if any (the previous_sibling property). This means that all siblings that share the same parent form a linked list, with each node pointing to the previous node.\n* Only one child of a given parent can be the first sibling (meaning that its previous_sibling is null).\n* A node cannot point to a previous sibling that is a child of a different parent.\n* Two nodes cannot point to the same previous sibling.\n* A node can specify another node that is to be executed next (the next_step property).\n* A node cannot be its own parent or its own sibling.\n* A node must have a type property that contains one of the following values. If no type property is specified, then the type is standard.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-dialog-modify"}, {"document_id": "ibmcld_02900-4643-6783", "score": 16.650013, "text": "\n* a digression that starts elsewhere and enters the node must return to the interrupted dialog flow after the current dialog flow is completed\n\n\n\nTo change the digression behavior for an individual node, complete the following steps:\n\n\n\n1. Click the node to open its edit view.\n2. Click Customize, and then click the Digressions tab.\n\nThe configuration options differ depending on whether the node you are editing is a root node, a child node, a node with children, or a node with slots.\n\n\n\n Digressions away from this node \n\nIf the circumstances listed earlier do not apply, then you can make the following choices:\n\n\n\n* All node types: Choose whether to allow users to digress away from the current node before they reach the end of the current dialog branch.\n* All nodes that have children: Choose whether you want the conversation to come back to the current node after a digression if the current node's response has already been displayed and its child nodes are incidental to the node's goal. Set the Allow return from digressions triggered after this node's response toggle to No to prevent the dialog from returning to the current node and continuing to process its branch.\n\nFor example, if the user asks, Do you sell cupcakes? and the response, We offer cupcakes in a variety of flavors and sizes is displayed before the user changes subjects, you might not want the dialog to return to where it was. Especially, if the child nodes only address possible follow-up questions from the user and can safely be ignored.\n\nHowever, if the node relies on its child nodes to address the question, then you might want to force the conversation to return and continue processing the nodes in the current branch. For example, the initial response might be, We offer cupcakes in all shapes and sizes. Which menu do you want to see: gluten-free, dairy-free, or regular? If the user changes subjects at this point, you might want the dialog to return so the user can pick a menu type and get the information they wanted.\n* Nodes with slots: Choose whether you want to allow users to digress away from the node before all of the slots are filled.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03010-7-2157", "score": 18.068365, "text": "\nDefining intents \n\nIntents are purposes or goals that are expressed in a customer's input, such as answering a question or processing a bill payment. By recognizing the intent expressed in a customer's input, the Watson Assistant service can choose the correct dialog flow for responding to it.\n\n\n\n Intent creation overview \n\n\n\n* Plan the intents for your application.\n\nConsider what your customers might want to do, and what you want your application to be able to handle on their behalf. For example, you might want your application to help your customers make a purchase. If so, you can add a buy_something intent. (The that is added as a prefix to the intent name helps to clearly identify it as an intent.)\n* Teach Watson about your intents.\n\nAfter you decide which business requests that you want your application to handle for your customers, you must teach Watson about them. For each business goal (such as buy_something), you must provide at least 5 examples of utterances that your customers typically use to indicate their goal. For example, I want to make a purchase.\n\nIdeally, find real-world user utterance examples that you can extract from existing business processes. The user examples should be tailored to your specific business. For example, if you are an insurance company, a user example might look more like this, I want to buy a new XYZ insurance plan.\n\nThe examples that you provide are used by your assistant to build a machine learning model that can recognize the same and similar types of utterances and map them to the appropriate intent.\n\n\n\nStart with a few intents, and test them as you iteratively expand the scope of the application.\n\n\n\n\n\n Creating intents \n\n\n\n1. Open your dialog skill. The skill opens to the Intents page.\n2. Select Create intent.\n3. In the Intent name field, type a name for the intent.\n\n\n\n* The intent name can contain letters (in Unicode), numbers, underscores, hyphens, and periods.\n* The name cannot consist of .. or any other string of only periods.\n* Intent names cannot contain spaces and must not exceed 128 characters. The following are examples of intent names:\n\n\n\n* weather_conditions", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents"}, {"document_id": "ibmcld_03334-4-1943", "score": 16.301302, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Creating intents \n\nIntents are purposes or goals that are expressed in a customer's input, such as answering a question or processing a bill payment. By recognizing the intent expressed in a customer's input, the Watson Assistant service can choose the correct dialog flow for responding to it.\n\nTo learn more about creating intents, watch the following 2 1/2-minute video.\n\n\n\n Intent creation overview \n\n\n\n* Plan the intents for your application.\n\nConsider what your customers might want to do, and what you want your application to be able to handle on their behalf. For example, you might want your application to help your customers make a purchase. If so, you can add a buy_something intent. (The that is added as a prefix to the intent name helps to clearly identify it as an intent.)\n* Teach Watson about your intents.\n\nAfter you decide which business requests that you want your application to handle for your customers, you must teach Watson about them. For each business goal (such as buy_something), you must provide at least 5 examples of utterances that your customers typically use to indicate their goal. For example, I want to make a purchase.\n\nIdeally, find real-world user utterance examples that you can extract from existing business processes. The user examples should be tailored to your specific business. For example, if you are an insurance company, a user example might look more like this, I want to buy a new XYZ insurance plan.\n\nThe examples that you provide are used by your assistant to build a machine learning model that can recognize the same and similar types of utterances and map them to the appropriate intent.\n\n\n\nStart with a few intents, and test them as you iteratively expand the scope of the application.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-intents"}, {"document_id": "ibmcld_03373-2953-4766", "score": 15.118542, "text": "\nAfter you identify the list of steps, you can then focus on writing engaging content to turn each interaction into a positive experience for your customer.\n\n![Diagram of a simple exchange between a customer and an actions skill step.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/action-skill-explained.png)\n\n\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https://cloud.ibm.com/docs/assistant?topic=assistant-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. The name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.\n* [Dialog](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-build): A dialog is a branching conversation flow that defines how your application responds when it recognizes the defined intents and entities. You use the dialog editor to create conversations with users, providing responses based on the intents and entities that you recognize in their input.\n\n![Diagram of a basic implementation that uses intent and dialog only.]", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-add"}, {"document_id": "ibmcld_03334-5529-7605", "score": 14.717683, "text": "\n* Both training and test data (for evaluation purposes) should reflect the distribution of intents in real usage. Generally, more frequent intents have relatively more examples, and better response coverage.\n* You can include punctuation in the example text, as long as it appears naturally. If you believe that some users express their intents with examples that include punctuation, and some users will not, include both versions. Generally, the more coverage for various patterns, the better the response.\n\n\n\n\n\n\n\n How entity references are treated \n\nWhen you include an entity mention in a user example, the machine learning model uses the information in different ways in these scenarios:\n\n\n\n* [Referencing entity values and synonyms in intent examples](https://cloud.ibm.com/docs/assistant?topic=assistant-intentsintents-related-entities)\n* [Annotated mentions](https://cloud.ibm.com/docs/assistant?topic=assistant-intentsintents-annotated-mentions)\n* [Directly referencing an entity name in an intent example](https://cloud.ibm.com/docs/assistant?topic=assistant-intentsintents-entity-as-example)\n\n\n\n\n\n Referencing entity values and synonyms in intent examples \n\nIf you have defined, or plan to define, entities that are related to this intent, mention the entity values or synonyms in some of the examples. Doing so helps to establish a relationship between the intent and entities. It is a weak relationship, but it does inform the model.\n\n\n\n\n\n Annotated mentions \n\nAs you define entities, you can annotate mentions of the entity directly from your existing intent user examples. A relationship that you identify in this way between the intent and the entity is not used by the intent classification model. However, when you add the mention to the entity, it is also added to that entity as new value. And when you add the mention to an existing entity value, it is also added to that entity value as new synonym. Intent classification does use these types of dictionary references in intent user examples to establish a weak reference between an intent and an entity.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-intents"}, {"document_id": "ibmcld_03334-15077-16547", "score": 14.253701, "text": "\n* To download all intents, meaning the intents listed on this and any additional pages, do not select any individual intents. Instead, click the Download all intents icon. ![Download all intents icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/download-all.png)\n* To download the intents that are listed on the current page only, select the checkbox in the header. This action selects all of the intents on the current page. Click the Download icon. ![Download icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/download.png)\n* To download one or more specific intents, select the intents that you want to download, and then click the Download icon. ![Download icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/download.png).\n\n\n\n2. Specify the name and location in which to store the CSV file that is generated, and then click Save.\n\n\n\n\n\n\n\n Uploading intents and examples \n\nIf you have a large number of intents and examples, you might find it easier to upload them from a comma-separated value (CSV) file than to define them one by one. Be sure to remove any personal data from the user examples that you include in the file.\n\nAlternatively, you can upload a file with raw user utterances (from call center logs, for example) and let Watson find candidates for user examples from the data.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-intents"}, {"document_id": "ibmcld_07578-2720-4792", "score": 14.25291, "text": "\nAn intent represents the action a user wants to do. An entity represents the object of that action. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-entities). \n Integrations Ways you can deploy your assistant to existing platforms or social media channels. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-integration-add). \n Intent The goal that is expressed in the user input, such as answering a question or processing a bill payment. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-intents). \n Message A single turn within a conversation that includes a single call to the /message API endpoint and its corresponding response. \n Monthly active user (MAU) A single unique user who interacts with an assistant one or many times in a given month. \n Preview Embeds your assistant in a chat window that is displayed on an IBM-branded web page. From the preview, you can test how a conversation flows through any and all skills that are attached to your assistant, from end to end. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-link). \n Response Logic that is defined in the Assistant responds section of a dialog node that determines how the assistant responds to the user. When the node's condition evaluates to true, the response is processed. The response can consist of an answer, a follow-up question, a webhook that sends a programmatic request to an external service, or slots which represent pieces of information that you need the user to provide before the assistant can help. The dialog node response is equivalent to a Then statement in If-Then-Else programming logic. \n Skill Does the work of the assistant. A dialog skill has the training data and dialog that your assistant uses to chat with customers. An actions skill is a new way to build a conversation. Actions offer step-by-step flows for a conversations and are made so that anybody can build them. A search skill is configured to search the appropriate external data sources for answers to customer questions.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-2720-4792", "score": 14.25291, "text": "\nAn intent represents the action a user wants to do. An entity represents the object of that action. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-entities). \n Integrations Ways you can deploy your assistant to existing platforms or social media channels. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-integration-add). \n Intent The goal that is expressed in the user input, such as answering a question or processing a bill payment. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-intents). \n Message A single turn within a conversation that includes a single call to the /message API endpoint and its corresponding response. \n Monthly active user (MAU) A single unique user who interacts with an assistant one or many times in a given month. \n Preview Embeds your assistant in a chat window that is displayed on an IBM-branded web page. From the preview, you can test how a conversation flows through any and all skills that are attached to your assistant, from end to end. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-link). \n Response Logic that is defined in the Assistant responds section of a dialog node that determines how the assistant responds to the user. When the node's condition evaluates to true, the response is processed. The response can consist of an answer, a follow-up question, a webhook that sends a programmatic request to an external service, or slots which represent pieces of information that you need the user to provide before the assistant can help. The dialog node response is equivalent to a Then statement in If-Then-Else programming logic. \n Skill Does the work of the assistant. A dialog skill has the training data and dialog that your assistant uses to chat with customers. An actions skill is a new way to build a conversation. Actions offer step-by-step flows for a conversations and are made so that anybody can build them. A search skill is configured to search the appropriate external data sources for answers to customer questions.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_03403-1720-3144", "score": 14.244613, "text": "\nStep 2: Answer questions about the restaurant \n\nAdd an intent that recognizes when customers ask for details about the restaurant itself. An intent is the purpose or goal expressed in user input. The General_About_You intent that is provided with the General content catalog serves a similar function, but its user examples are designed to focus on queries about the assistant as opposed to the business that is using the assistant to help its customers. So, you will add your own intent.\n\n\n\n Add the about_restaurant intent \n\n\n\n1. From the Intents tab, click Create intent.\n\n![Shows the the Create intent button on the Intents page.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-ass-intent-add.png)\n2. Enter about_restaurant in the Intent name field, and then click Create intent.\n\n![Shows the #about_restaurant intent being added.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-ass-add-intent.png)\n3. Add the following user examples:\n\nTell me about the restaurant\ni want to know about you\nwho are the restaurant owners and what is their philosophy?\nWhat's your story?\nWhere do you source your produce from?\nWho is your head chef and what is the chef's background?\nHow many locations do you have?\ndo you cater or host functions on site?\nDo you deliver?\nAre you open for breakfast?\n4. Click the Close!", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-tutorial"}, {"document_id": "ibmcld_02988-2804-4490", "score": 14.176416, "text": "\nFor example, if you want to check whether the city entity is Dublin (Ohio), you must use @city == 'Dublin (Ohio)' instead of @city:(Dublin (Ohio)).\n\n\n\n\n\n Shorthand syntax for intents \n\nThe following table shows examples of the shorthand syntax that you can use when referring to intents.\n\n\n\nIntents shorthand syntax\n\n Shorthand syntax Full syntax in SpEL \n\n `#help` `intent == 'help'` \n `! #help` `intent != 'help'` \n `NOT #help` `intent != 'help'` \n `#help` or `#i_am_lost` `(intent == 'help' || intent == 'I_am_lost')` \n\n\n\n\n\n\n\n\n\n Built-in global variables \n\nYou can use the expression language to extract property information for the following global variables:\n\n\n\n Global variable Definition \n\n context JSON object part of the processed conversation message. \n entities[ ] List of entities that supports default access to 1st element. \n input JSON object part of the processed conversation message. \n intents[ ] List of intents that supports default access to first element. \n output JSON object part of the processed conversation message. \n\n\n\n\n\n\n\n Accessing entities \n\nThe entities array contains one or more entities that were recognized in user input.\n\nWhile testing your dialog, you can see details of the entities that are recognized in user input by specifying this expression in a dialog node response:\n\n<? entities ?>\n\nFor the user input, Hello now, your assistant recognizes the @sys-date and @sys-time system entities, so the response contains these entity objects:\n\n[\n{\"entity\":\"sys-date\",\"location\":6,9],\"value\":\"2017-08-07\",\n\"confidence\":1,\"metadata\":{\"calendar_type\":\"GREGORIAN\",\n\"timezone\":\"America/New_York\"}},\n{\"entity\":\"sys-time\",\"location\":6,9],\"value\":\"15:01:00\",", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-expression-language"}, {"document_id": "ibmcld_03334-1458-3293", "score": 13.819304, "text": "\nThe user examples should be tailored to your specific business. For example, if you are an insurance company, a user example might look more like this, I want to buy a new XYZ insurance plan.\n\nThe examples that you provide are used by your assistant to build a machine learning model that can recognize the same and similar types of utterances and map them to the appropriate intent.\n\n\n\nStart with a few intents, and test them as you iteratively expand the scope of the application.\n\n![Plus or higher plans only](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/plus.png) If you already have chat transcripts from a call center or customer inquiries that you collected from an online application, put that data to work for you. Share the real customer utterances with Watson and let Watson recommend the best intents and intent user examples for your needs. See [Get help defining intents](https://cloud.ibm.com/docs/assistant?topic=assistant-intent-recommendations) for more details.\n\n\n\n\n\n Creating intents \n\n\n\n1. Open your dialog skill. The skill opens to the Intents page.\n2. Select Create intent.\n3. In the Intent name field, type a name for the intent.\n\n\n\n* The intent name can contain letters (in Unicode), numbers, underscores, hyphens, and periods.\n* The name cannot consist of .. or any other string of only periods.\n* Intent names cannot contain spaces and must not exceed 128 characters. The following are examples of intent names:\n\n\n\n* weather_conditions\n* pay_bill\n* escalate_to_agent\n\n\n\n\n\nA number sign is prepended to the intent name automatically to help identify the term as an intent. You do not need to add it.\n\nKeep the name as short as possible. It's easier to read in the \"Try it out\" pane and conversation logs if you keep the intent name short and concise.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-intents"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03405-3051-4760", "score": 18.117777, "text": "\nClick the System entities tab, and then turn on these entities:\n\n\n\n* @sys-time\n* @sys-date\n* @sys-number\n\n\n\n\n\nYou have successfully enabled the @sys-date, @sys-time, and @sys-number system entities. Now you can use them in your dialog.\n\n\n\n\n\n Step 3: Add a dialog node with slots \n\nA dialog node represents the start of a thread of dialog between your assistant and the user. It contains a condition that must be met for the node to be processed by your assistant. At a minimum, it also contains a response. For example, a node condition might look for the hello intent in user input, and respond with, Hi. How can I help you? This example is the simplest form of a dialog node, one that contains a single condition and a single response. You can define complex dialogs by adding conditional responses to a single node, adding child nodes that prolong the exchange with the user, and much more. (If you want to learn more about complex dialogs, you can complete the [Building a complex dialog](https://cloud.ibm.com/docs/assistant?topic=assistant-tutorial) tutorial.)\n\nThe node that you will add in this step is one that contains slots. Slots provide a structured format through which you can ask for and save multiple pieces of information from a user within a single node. They are most useful when you have a specific task in mind and need key pieces of information from the user before you can perform it. See [Gathering information with slots](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-slots) for more information.\n\nThe node you add will collect the information required to make a reservation at a restaurant.\n\n\n\n1. Click the Dialogs tab to open the dialog tree.\n2. Click the More icon !", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-tutorial-slots"}, {"document_id": "ibmcld_03069-7-2188", "score": 17.698214, "text": "\nTutorial: Building a complex dialog \n\nIn this tutorial, you will use the Watson Assistant service to create a dialog for an assistant that helps users with inquiries about a fictitious restaurant called Truck Stop Gourmand.\n\n\n\n Learning objectives \n\nBy the time you finish the tutorial, you will understand how to:\n\n\n\n* Plan a dialog\n* Define custom intents\n* Add dialog nodes that can handle your intents\n* Add entities to make your responses more specific\n* Add a pattern entity, and use it in the dialog to find patterns in user input\n* Set and reference context variables\n\n\n\n\n\n Duration \n\nThis tutorial will take approximately 2 to 3 hours to complete.\n\n\n\n\n\n Prerequisite \n\nBefore you begin, complete the [Getting Started tutorial](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-getting-started).\n\nYou will use the dialog skill that you created, and add nodes to the simple dialog that you built as part of the getting started exercise.\n\n\n\n\n\n\n\n Step 1: Plan the dialog \n\nYou are building an assistant for a restaurant named Truck Stop Gourmand that has one location and a thriving cake-baking business. You want the simple assistant to answer user questions about the restaurant, its menu, and to cancel customer cake orders. Therefore, you need to create intents that handle inquiries related to the following subjects:\n\n\n\n* Restaurant information\n* Menu details\n* Order cancellations\n\n\n\nYou'll start by creating intents that represent these subjects, and then build a dialog that responds to user questions about them.\n\n\n\n\n\n Step 2: Answer questions about the restaurant \n\nAdd an intent that recognizes when customers ask for details about the restaurant itself. An intent is the purpose or goal expressed in user input. The General_About_You intent that is provided with the General content catalog serves a similar function, but its user examples are designed to focus on queries about the assistant as opposed to the business that is using the assistant to help its customers. So, you will add your own intent.\n\n\n\n Add the about_restaurant intent \n\n\n\n1. From the Intents tab, click Create intent.\n\n![Shows the the Create intent button on the Intents page.]", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-tutorial"}, {"document_id": "ibmcld_03406-34893-35432", "score": 17.630196, "text": "\nIn this tutorial you tested a node with slots and made changes that optimize how it interacts with real users. For more information about this subject, see [Gathering information with slots](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-slots).\n\n\n\n\n\n\n\n Next steps \n\nDeploy your dialog skill by first connecting it to an assistant, and then deploying the assistant. There are several ways you can do this. See [Adding integrations](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-integration-add) for more details.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-tutorial-slots-complex"}, {"document_id": "ibmcld_02952-1632-3754", "score": 17.563475, "text": "\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.\n\nFor example, an insurance company might want questions about bereavement benefits always to be handled by a person. Or, if a customer wants to close an account, you might want to transfer the conversation to a respresentative who is authorized to offer incentives to keep the customer's business.\n* When the assistant repeatedly fails to understand a customer's request. Instead of asking the customer to retry or rephrase the question over and over, your assistant can offer to transfer the customer to a human agent.\n\n\n\nTo design a dialog that can transfer the conversation, complete the following steps:\n\n\n\n1. Add an intent to your skill that can recognize a user's request to speak to a human.\n\nYou can create your own intent or add the prebuilt intent named General_Connect_to_Agent that is provided with the General content catalog.\n2. Add a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-support"}, {"document_id": "ibmcld_03071-3000-4820", "score": 17.557697, "text": "\nYou have successfully enabled the @sys-date, @sys-time, and @sys-number system entities. Now you can use them in your dialog.\n\n\n\n\n\n Step 3: Add a dialog node with slots \n\nA dialog node represents the start of a thread of dialog between your assistant and the user. It contains a condition that must be met for the node to be processed by your assistant. At a minimum, it also contains a response. For example, a node condition might look for the hello intent in user input, and respond with, Hi. How can I help you? This example is the simplest form of a dialog node, one that contains a single condition and a single response. You can define complex dialogs by adding conditional responses to a single node, adding child nodes that prolong the exchange with the user, and much more. (If you want to learn more about complex dialogs, you can complete the [Building a complex dialog](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-tutorial) tutorial.)\n\nThe node that you will add in this step is one that contains slots. Slots provide a structured format through which you can ask for and save multiple pieces of information from a user within a single node. They are most useful when you have a specific task in mind and need key pieces of information from the user before you can perform it. See [Gathering information with slots](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-slots) for more information.\n\nThe node you add will collect the information required to make a reservation at a restaurant.\n\n\n\n1. Click the Dialogs tab to open the dialog tree.\n2. Click the More icon ![More options](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kabob.png) on the #General_Greetings node, and then select Add node below.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-tutorial-slots"}, {"document_id": "ibmcld_02882-7-2075", "score": 17.399235, "text": "\nBuilding a conversational flow \n\nThe dialog defines what your assistant says in response to customers.\n\n\n\n Creating a dialog \n\nTo create a dialog, complete the following steps:\n\n\n\n1. Click the Dialog tab, and then click Create dialog.\n\nWhen you open the dialog editor for the first time, the following nodes are created for you:\n\n\n\n* Welcome: The first node. It contains a greeting that is displayed to your users when they first engage with your assistant. You can edit the greeting.\n\n\n\nThis node is not triggered in dialog flows that are initiated by users. For example, dialogs that are deployed in environments such as messaging channels where customers start the conversation do not process nodes with the welcome special condition.\n\n\n\n* Anything else: The final node. It contains phrases that are used to reply to users when their input is not recognized. You can replace the responses that are provided or add more responses with a similar meaning to add variety to the conversation. You can also choose whether you want your assistant to return each response that is defined in turn or return them in random order.\n\n\n\n2. To add more nodes to the dialog tree, click the More![More icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kabob.png) icon on the Welcome node, and then select Add node below.\n3. In the If assistant recognizes field, enter a condition that, when met, triggers your assistant to process the node.\n\nTo start off, you typically want to add an intent as the condition. For example, if you add open_account here, it means that you want the response that you will specify in this node to be returned to the user if the user input indicates that the user wants to open an account.\n\nAs you begin to define a condition, a box is displayed that shows you your options. You can enter one of the following characters, and then pick a value from the list of options that is displayed.\n\n\n\nCondition builder syntax\n\n Character Lists defined values for these artifact types \n\n `#` intents", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overview"}, {"document_id": "ibmcld_02961-7-1871", "score": 17.195494, "text": "\nDialog building tips \n\nGet tips about ways to address common tasks.\n\n\n\n Adding nodes \n\n\n\n* Add a node name that describes the purpose of the node.\n\nYou currently know what the node does, but months from now you might not. Your future self and any team members will thank you for adding a descriptive node name. And the node name is displayed in the log, which can help you debug a conversation later.\n* To gather the information that is required to perform a task, try using a node with slots instead of a bunch of separate nodes to elicit information from users. See [Gathering information with slots](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-slots).\n* For a complex process flow, tell users about any information they will need to provide at the start of the process.\n* Understand how your assistant travels through the dialog tree and the impact that folders, branches, jump-tos, and digressions have on the route. See [Dialog flow](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-builddialog-build-flow).\n* Do not add jump-tos everywhere. They increase the complexity of the dialog flow, and make it harder to debug the dialog later.\n* To jump to a node in the same branch as the current node, use Skip user input instead of a Jump-to.\n\nThis choice prevents you from having to edit the current node's settings when you remove or reorder the child nodes being jumped to. See [Defining what to do next](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-jump-to).\n* Before you enable digressions away from a node, test the most common user scenarios. And be sure that likely digressed-to nodes are configured to return. See [Digressions](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtimedialog-runtime-digressions).\n\n\n\n\n\n\n\n Adding responses", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-tips"}, {"document_id": "ibmcld_03196-4-2102", "score": 17.063478, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Creating a dialog \n\nThe dialog defines what your assistant says in response to customers.\n\n\n\n Creating a dialog \n\nTo create a dialog, complete the following steps:\n\n\n\n1. From the Skills menu, click Dialog.\n\nThe following nodes are created for you automatically:\n\n\n\n* Welcome: The first node. It contains a greeting that is displayed to your users when they first engage with your assistant. You can edit the greeting.\n\n\n\nThis node is not triggered in dialog flows that are initiated by users. For example, dialogs used in integrations with channels such as Facebook or Slack skip nodes with the welcome special condition.\n\n\n\n* Anything else: The final node. It contains phrases that are used to reply to users when their input is not recognized. You can replace the responses that are provided or add more responses with a similar meaning to add variety to the conversation. You can also choose whether you want your assistant to return each response that is defined in turn or return them in random order.\n\n\n\nFor more information about these built-in nodes, see [Starting and ending the dialog](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-start).\n2. To add more nodes to the dialog tree, click Add node.\n\nYour new node is added after the Welcome node and before the Anything else node.\n3. Add a name to the node.\n\nUse a short, customer-friendly description of what the node does as its name. For example, Open an account, Get policy information, or Get a weather forecast.\n\nThe name can be up to 512 characters in length.\n\nThis node name is shown to customers or service desk personnel to express the purpose of this branch of the dialog, so take some time to add a name that is concise and descriptive.\n4. In the If assistant recognizes field, enter a condition that, when met, triggers your assistant to process the node.\n\nTo start off, you typically want to add an intent as the condition.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overview"}, {"document_id": "ibmcld_02998-8791-9815", "score": 17.028286, "text": "\nYou created a simple conversation with two intents and a dialog to recognize them.\n\n\n\n\n\n\n\n Next steps \n\nThis tutorial is built around a simple example. For a real application, you need to define some more interesting intents, some entities, and a more complex dialog that uses them both. When you have a polished version of the assistant, you can make API calls to it from your client application.\n\n\n\n* Complete follow-on tutorials that build more advanced dialogs:\n\n\n\n* Add standard nodes with the [Building a complex dialog](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-tutorial) tutorial.\n* Learn about slots with the [Adding a node with slots](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-tutorial-slots) tutorial.\n\n\n\n* Check out more [sample apps](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-sample-apps) to get ideas.\n\n\n\nWhen you're ready to deploy your assistant, see [Deploying](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-custom-app).", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-getting-started"}, {"document_id": "ibmcld_03196-1602-3602", "score": 16.756237, "text": "\nFor example, Open an account, Get policy information, or Get a weather forecast.\n\nThe name can be up to 512 characters in length.\n\nThis node name is shown to customers or service desk personnel to express the purpose of this branch of the dialog, so take some time to add a name that is concise and descriptive.\n4. In the If assistant recognizes field, enter a condition that, when met, triggers your assistant to process the node.\n\nTo start off, you typically want to add an intent as the condition. For example, if you add open_account here, it means that you want the response that you will specify in this node to be returned to the user if the user input indicates that the user wants to open an account.\n\nAs you begin to define a condition, a box is displayed that shows you your options. You can enter one of the following characters, and then pick a value from the list of options that is displayed.\n\n\n\nCondition builder syntax\n\n Character Lists defined values for these artifact types \n\n `#` intents \n `@` entities \n `@{entity-name}:` {entity-name} values \n `$` context-variables that you defined or referenced elsewhere in the dialog \n\n\n\nYou can create a new intent, entity, entity value, or context variable by defining a new condition that uses it. If you create an artifact this way, be sure to go back and complete any other steps that are necessary for the artifact to be created completely, such as defining sample utterances for an intent.\n\nTo define a node that triggers based on more than one condition, enter one condition, and then click the plus sign (+) icon next to it. If you want to apply an OR operator to the multiple conditions instead of AND, click the and that is displayed between the fields to change the operator type. AND operations are executed before OR operations, but you can change the order by using parentheses. For example: $isMember:true AND ($memberlevel:silver OR $memberlevel:gold)\n\nThe condition you define must be less than 2,048 characters in length.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overview"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16315-4264-5910", "score": 10.849129, "text": "\nSteps in a journey are shown to the customer one at a time, in the order in which you list them in the steps array.\n\nAs with assistant responses, the response_type property identifies the type of response:\n\ntext\n: A step that shows only text.\n\n{\n\"response_type\": \"text\",\n\"text\": \"This is the text of the response.\"\n}\n\nMarkdown formatting and links are supported in text steps. For more information, see [Markdown formatting](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architectureweb-chat-architecture-markdown).\n\nNote that the structure of a text step in a journey is different from the text response type for assistant responses. Instead of an array of text values, only a single text component is supported.\n\nimage\n: A step that shows an image, along with an optional description.\n\n{\n\"response_type\": \"image\",\n\"source\": \"https://example.com/image.png\",\n\"description\": \"This is the description of the image.\"\n}\n\nThe source property must be the https: URL of a publicly accessible image. The specified image must be in .jpg, .gif, or .png format.\n\nvideo\n: A step that shows a video, along with an optional description.\n\n{\n\"response_type\": \"video\",\n\"source\": \"https://example.com/videos/example-video.mp4\",\n\"description\": \"This is the description of the video.\"\n}\n\nThe URL specified by the source property can be either of the following:\n\n\n\n* The URL of a video file in a standard format such as MPEG or AVI. In the web chat, the linked video will render as an embedded video player.\n\nHLS (.m3u8) and DASH (MPD) streaming videos are not supported.\n* The URL of a video hosted on a supported video hosting service.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-journeys"}, {"document_id": "ibmcld_16352-4521-5970", "score": 9.978177, "text": "\nFor example, you might build a step that executes only if all conditions in group 1 are true or any condition in group 2 is true. (Groups function like parentheses in the boolean conditions of many programming languages.)\n\nAfter you add a group, you can define one or more conditions in the new group. Between groups, choose and or or to indicate whether the conditions in both conditional groups or only one of them must be met for the step to be included in the conversational flow.\n\n\n\n\n\n Operators \n\nAn operator specifies the kind of test you are performing on a value in a condition. The specific operators available in a condition depend on the customer response type of the value, as shown in the following table.\n\n\n\nOperators\n\n Response type Operators \n\n <br><br> * Options<br><br><br> <br><br> * is<br> * is not<br> * is any of<br> * is none of<br><br><br> \n <br><br> * Regex<br><br><br> <br><br> * is<br> * is not<br><br><br> \n <br><br> * Number<br> * Currency<br> * Percent<br><br><br> <br><br> * is defined<br> * is not defined<br> * is equal to (==)<br> * is not equal to (\u2260)<br> * is less than (<)<br> * is less than or equal to (<=)<br> * is greater than (>)<br> * is greater than or equal to (>=)<br><br><br> \n <br><br> * Date<br><br><br> <br><br> * is defined<br> * is not defined<br> * is on (also allows specific day of the week)<br> * is not on<br> * is before<br> * is after<br> * is on or before<br> * is on or after<br><br><br>", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-step-conditions"}, {"document_id": "ibmcld_16353-7-1537", "score": 9.938492, "text": "\nChoosing what to do at the end of a step \n\nBy default, the steps in an action are executed in sequence from first to last. However, you can change this default in order to change what happens next. Used in combination with step conditions, this capability makes it possible for the conversation to follow many different flows depending on the customer's input.\n\nTo specify what happens when a step finishes, click And then.\n\n![Step editor \"And then\" field](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/step-and-then.png)\n\nSelect an option from the drop-down list. The following options are available:\n\n\n\n* [Continue to next step](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-step-what-nextcontinue-to-next-step)\n* [Re-ask previous step(s)](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-step-what-nextre-ask-previous-step)\n* [Go to a subaction](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-step-what-nextgo-to-another-action)\n* [Use an extension](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-step-what-nextuse-extension)\n* [Search for the answer](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-step-what-nextsearch-for-answer)\n* [Connect to agent](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-step-what-nextconnect-to-agent)\n* [End the action](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-step-what-nextend-action)", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-step-what-next"}, {"document_id": "ibmcld_16353-2640-4846", "score": 9.65927, "text": "\nYou can select any step that precedes the step you are editing.\n\nNote that only the selected steps will repeat, regardless of their And then settings. Therefore, if you want to repeat the entire action up to this point, you must select all of the previous steps.\n\nThe current step you are editing is automatically included in the list of steps to be repeated. To avoid an infinite loop, use step conditions to ensure that this step only executes when it is appropriate for previous steps to be repeated. For example, you might have a step that repeats previous steps only if the user answered No to a confirmation question; this way, if the user answers Yes, nothing is repeated and the action continues.\n3. Click Apply.\n\n\n\nAny session variable values that were defined based on choices that the customer made in the repeated steps are cleared and replaced with the new responses.\n\nThere is no option to jump to a later step. Instead of jumping directly to a later step, control the flow through the intervening steps with step conditions or skipping steps.\n\n\n\n\n\n Go to a subaction \n\nAn action that is called from another action is referred to as a subaction. This option switches the conversation flow to another action. If you have an action flow that can be applied across multiple actions, you can use a subaction to build it once and then call it from each action that needs it. For example, as part of an action to place an order, you might call a subaction that enables a new customer to create an account.\n\nTo call a subaction:\n\n\n\n1. In the And then field, select Go to a subaction.\n2. In the Settings window, click the Go to field and select the action that you want to call.\n3. If you do not want to continue with the current action, click End this action after the other action is completed. You might use this option in cases where the customer decides to do something different; in this case, you want the conversation flow to switch to the subaction and not return.\n\nBy default, the assistant returns to the current action after the subaction completes. Any action variables or session variables that are defined in the subaction are accessible from subsequent steps in the calling action.\n4.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-step-what-next"}, {"document_id": "ibmcld_16352-7-1940", "score": 9.4708, "text": "\nAdding conditions to a step \n\nAn action represents a business process that helps customers answer their questions or solve their problems. Such a process must adapt to different specifics, based on information provided by customers or otherwise available at run time. For example, the steps for withdrawing money from a savings account might be slightly different from the steps for withdrawing for a checking account.\n\nA step condition is a boolean test, based on some runtime value; the step executes only if the test evaluates as true. This test can be applied to any variable, such as an action variable containing the customer response from a previous step. By defining step conditions, you can create multiple pathways through an action based on different possible runtime values.\n\nFor more information about variables, see [Using variables to manage conversation information](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-manage-info).\n\nA basic step condition is expressed in the following form:\n\nIf{variable}{operator}{value}\n\nwhere:\n\n\n\n* {variable} is the name of a variable or an expression.\n* {operator} is the type of test to apply to the variable value (for example, is or is not).\n* {value} is the value to compare to the variable.\n\n\n\nFor example, a step condition might read:\n\nIfWithdraw from which account?isChecking\n\nThis condition evaluates as true if the customer's response to the previous Withdraw from which account? step is Checking.\n\nConditions can be grouped together to construct complex tests.\n\nTo add a step condition:\n\n\n\n1. Open the step. Click the condition field at the beginning of the step:\n\nZoom\n\n![Step editor with condition field highlighted](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/step-condition.png)\n\nCondition field\n2. Select with conditions from the drop-down list. The Conditions section expands.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-step-conditions"}, {"document_id": "ibmcld_16353-1180-3143", "score": 9.454674, "text": "\n* [Search for the answer](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-step-what-nextsearch-for-answer)\n* [Connect to agent](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-step-what-nextconnect-to-agent)\n* [End the action](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-step-what-nextend-action)\n\n\n\n\n\n Continue to next step \n\nThis option processes the next step in the steps list. As always, the conditions for the next step are evaluated first to determine whether to show the step's response to the customer. This is the default selection.\n\n\n\n\n\n Re-ask previous step(s) \n\nThis option repeats one or more steps that are listed earlier in the current action. These might be steps that the customer already completed, or steps that were skipped previously based on their step conditions.\n\nYou can use this option to handle situations where the customer has made a mistake and asks to go back to a previous point in the conversation. For example, you might include a confirmation step at the end of a process that asks the user whether the collected information is correct; if the user says no, you can return to the beginning of the process. This option is only available from a step that comes third or later in the steps list.\n\nTo repeat previous steps:\n\n\n\n1. In the And then field, select Re-ask previous step(s).\n2. In the Settings window, click to select any previous steps you want to repeat. You can select any step that precedes the step you are editing.\n\nNote that only the selected steps will repeat, regardless of their And then settings. Therefore, if you want to repeat the entire action up to this point, you must select all of the previous steps.\n\nThe current step you are editing is automatically included in the list of steps to be repeated. To avoid an infinite loop, use step conditions to ensure that this step only executes when it is appropriate for previous steps to be repeated.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-step-what-next"}, {"document_id": "ibmcld_16308-7-1967", "score": 9.322365, "text": "\nWriting expressions \n\nYou can write expressions to specify values that are independent of, or derived from, values that are collected in steps or stored in session variables. You can use an expression to define a step condition or to define the value of a session variable.\n\n\n\n Using an expression in a step condition \n\nYou can use an expression in a step condition if you want to condition a step on the result of a calculation based on information you have gathered during the conversation.\n\nFor example, suppose a customer has $200 in a savings account and wants to transfer $150 from it to a new checking account. The funds transfer fee is $3, and the bank charges a fee when a savings account contains less than $50. You could create a step with a step condition that checks for this situation. The step condition would use an expression like this:\n\n${savings} - (${Step_232} + ${transfer_fee}) < 50\n\nwhere:\n\n\n\n* ${savings} represents a session variable that stores the customer's savings account total.\n* ${Step_232} represents the step that asks for the amount the customer wants to transfer.\n* ${transfer_fee} represents a session variable that specifies the fee for a funds transfer.\n\n\n\nIf the step condition is met, the step warns the user that the requested transfer will bring the savings account balance below the $50 minimum and incur a fee, and ask to confirm before proceeding.\n\nTo use an expression in a step condition, follow these steps:\n\n\n\n1. From the step, click Add condition.\n\nA condition is generated automatically with the most likely choice, which is typically any variables that were set in the previous step.\n2. Click the first segment of the generated condition, and then scroll down and click Expression.\n3. Optional: Click the ![Expand icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/expression-editor-icon.png)Expand icon to open the expression editor window.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-expressions"}, {"document_id": "ibmcld_16338-4145-6019", "score": 9.097892, "text": "\nThe remaining two are actions that were considered because of their confidence score, but weren't used because thee confidence scores were lower.\n\nIf no action scores higher than 20% confidence, you see the built-in action No action matches.\n\n\n\n\n\n Step locator \n\nSometimes you might find an error in the middle of a test conversation, and need to find which step and action is involved. A locator icon next to each assistant response lets you find the associated steps in the editor.\n\nClick the icon, and the editor shows the corresponding step in the background.\n\nZoom\n\n![Step locator](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/review-step-locator.png)\n\nStep locator\n\n\n\n\n\n Follow along \n\nFollow along connects what you are seeing in Preview with what you built in the action. As you interact with your assistant, the debug mode automatically opens each step in the background. That means you can fix an error as soon as you see it, because the editor is already open to the corresponding step.\n\n\n\n\n\n\n\n Variable values in Preview \n\nAs you test your conversation in Preview, you can check that each variable is set correctly. Click Variable values to see the values stored in each variable during the conversation. The Variable values pane has two tabs, one for action variables and one for session variables. If you are using dialog, you can see session variables for both actions and dialog on the Session variables tab.\n\nZoom\n\n![Variable values](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/variable-values-preview.png)\n\nVariable values\n\nTo learn more about variables, see [Managing information during the conversation](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-manage-info).\n\n\n\n\n\n Extension inspector in Preview", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-review"}, {"document_id": "ibmcld_16271-5707-7486", "score": 9.075491, "text": "\nAs expected, the assistant now prompts you to select the account you want to withdraw money from.\n\n\n\n\n\n\n\n Duplicating a step \n\nYou can duplicate a step so you don't have to re-create variable settings and customizations. Duplicating a step is helpful when you need to add a step similar to a previous step, but with minor modifications.\n\nComplete the following steps to duplicate a step:\n\n\n\n1. Click the Duplicate icon on the step that you want to duplicate.\n\nZoom\n\n![Duplicate button on a step](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/action-editor-duplicate-button.png)\n\nDuplicate icon\n\nA step appears immediately following the step that you duplicated. This step is identical to the duplicated step and displays a blue circle in the upper right to indicate that the step is a duplicate.\n\nZoom\n\n![Duplicated step](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/action-preview-duplicate-step.png)\n\nDuplicated step\n2. Edit the information in the new step as necessary.\n\n\n\n\n\n\n\n Adding conditional steps \n\nSuppose our bank charges a fee for withdrawals from checking accounts, and we need to confirm that the customer understands. Our action needs to have slightly different behavior depending on which kind of account the customer selects. We can handle this using step conditions.\n\nWhen a step asks for information from the user, the user's response is stored as an action variable. By referring to the action variables stored by previous steps, you can construct step conditions based on your customer's previous responses.\n\n\n\n1. Click New step.\n2. In the Step 2 is taken field, select with conditions. The Conditions section expands.\n\nZoom\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-build-actions-overview"}, {"document_id": "ibmcld_16304-5865-7272", "score": 8.928002, "text": "\nOr if the customer is selecting a credit card from options that show only the last four digits, you will need to use the full credit card number to access the account details or complete a transaction.\n\nIn this situation, you can write an expression to access the original properties of the selected item:\n\n\n\n1. Create or edit a step that comes after the step in which the customer selects from the dynamic options.\n2. In the Variable values section, write an expression to assign a value to a session variable. (For more information, see [Using an expression to assign a value to a session variable](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-expressionsexpression-variable).)\n3. In the expression editor, type a dollar sign ($) and then select the step in which the customer selected the dynamic option.\n4. Use the property name item to represent the selected item, and dot notation to access its properties. For example, the following expression accesses the id property of the item selected in a previous step:\n\n${step_331}.item.id\n\nYou can use a complex expression to construct a value using multiple properties of the selected item. For example, you might use an expression such as ${step_123}.item.firstname + \" \" + ${step_123}.item.lastname to construct a person's full name. Use the expression to define the value in whatever format you need to complete any required action.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-dynamic-options"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03126-3707-6008", "score": 17.089535, "text": "\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform.\n\n\n\n\n\n What languages does your assistant speak? \n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language).\n\n\n\n\n\n Does your assistant see the glass as half full? \n\nIs your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Choose a personality for your assistant, and then write conversations that reflect that personality. Don't overdo it. Don't sacrifice usability for the sake of keeping your assistant in character. But strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chat bots to identify themselves as chat bots.\n\n\n\n\n\n Who will build your assistant? \n\nAssemble a team with people who understand your customers and their needs, people who know how to interact with customers to reach the best outcomes. These subject matter experts can focus on designing an engaging conversational flow. In fact, the actions skill is designed with this type of expert in mind. The team can simultaneously build a conversational flow by defining discrete actions.\n\nIf you have data scientists or team members with programming skills, you can take advantage of some advanced capabilities that require varying levels of development expertise. This set of users might prefer to build the conversational flow with a dialog skill because there is greater visibility into the individual components that make up the training data.\n\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistants"}, {"document_id": "ibmcld_03126-5596-6966", "score": 16.626665, "text": "\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).\n\n\n\n\n\n Do you have existing content to leverage? \n\nThe answer to many a common question is already documented somewhere in your organization's technical information collateral. If only you could find it!\n\nGive your assistant access to this information by adding a search skill to your assistant. The search skill uses Discovery to return smart answers to natural language questions.\n\n\n\n\n\n Expand your assistant's responsibilities \n\nIf you start small, and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. The built-in metrics of active user conversations help you understand what your customers are asking about and how well your assistant is able to meet their needs.\n\nNothing beats real customer data. It will tell you what areas to tackle next.\n\n\n\n\n\n Ready to start building? \n\nSee [Creating an assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-add) to get started.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistants"}, {"document_id": "ibmcld_02839-1790-3940", "score": 15.02634, "text": "\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n3. Create the skill.\n4. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kebab.png), and then select Language preferences.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-language"}, {"document_id": "ibmcld_03120-4813-6717", "score": 14.723204, "text": "\nFor more information, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions. For a dialog skill, add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Phone integration: If you want to deploy an assistant that uses the universal language model with the phone integration, you must connect to custom Speech service language models that can understand the language you're using. For more information about supported language models, see the [Speech to Text](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-modelsmodelsList) and [Text to Speech](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-voiceslanguageVoices) documentation.\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-basicsweb-chat-basics-global).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}, {"document_id": "ibmcld_02839-7-2335", "score": 14.30505, "text": "\nAdding support for global audiences \n\nYour customers come from all around the globe. You need an assistant that can talk to them in their own language and in a familiar style. Choose the approach that best fits your business needs.\n\n\n\n* Quickest solution: The simplest way to add language support is to author the conversational skill in a single language. You can translate each message that is sent to your assistant from the customer's local language to the skill language. Later you can translate each response from the skill language back to the customer's local language.\n\nThis approach simplifies the process of authoring and maintaining the conversational skill. You can build one skill and use it for all languages. However, the intention and meaning of the customer message can be lost in the translation.\n\nFor more information about webhooks you can use for translation, see [Webhook overview](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-webhook-overview).\n* Most precise solution: If you have the time and resources, the best user experience can be achieved when you build multiple conversational skills, one for each language that you want to support. Watson Assistant has built-in support for all languages. Use one of 13 language-specific models or the universal model, which adapts to any other language you want to support.\n\nWhen you build a skill that is dedicated to a language, a language-specific classifier model is used by the skill. The precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-language"}, {"document_id": "ibmcld_03126-1789-4208", "score": 14.009278, "text": "\nActivate a credit card Your assistant can use a conversational flow to collect information for identity verification, and then call a webhook to submit the request to activate the card on the user's behalf. \n Complete a simple task that involves a complicated application Your assistant can link them to a 2-minute video that illustrates how to complete the task. \n Learn about insurance plan details after the death of a loved one Your assistant can connect the customer directly to a person who can show empathy and patience as the matter is addressed. \n Solve a problem that requires a long and involved procedure to fix Instead of trying to walk the customer through the procedure step by step in conversation, your assistant can link to a help center that documents the full procedure in detail. \n The customer calls support and your assistant answers Let's say the assistant needs a lot of details from the customer before it can help. Instead of trying to prompt the customer for each piece of information and transcribe it properly, your assistant can switch to SMS text messaging. After years of interacting with bad interactive voice response systems, many customers are more likely to yell Agent over and over than to engage in a long exchange. But if you give them a chance to explain something in writing, they tend to do so willingly. \n\n\n\n\n\n\n\n How will customers find your assistant? \n\nDeploy your assistant where customers can find it with ease. For example, you can embed the assistant in your company website or add it to a messaging platform such as Facebook, Slack, or WhatsApp.\n\nWhile the conversational skill is defined in text, customers can talk with your assistant over the phone when you deploy it by using the phone integration.\n\nFor more information about ways to deploy the assistant, see [Adding integrations](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-integration-add).\n\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform.\n\n\n\n\n\n What languages does your assistant speak? \n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language).\n\n\n\n\n\n Does your assistant see the glass as half full?", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistants"}, {"document_id": "ibmcld_03120-3469-5331", "score": 13.956551, "text": "\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}, {"document_id": "ibmcld_02841-1435-2454", "score": 13.811652, "text": "\n[A sample dialog tree with example content](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/dialog-depiction.png) \n\n\n\nThe dialog skill itself is defined in text, but you can integrate it with Watson Speech to Text and Watson Text to Speech services that enable users to interact with your assistant verbally.\n\n![Out-of-the-box training data](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/oob.png) If you want to get started quickly, add prebuilt training data to your dialog skill so your assistant can start helping your customers with the basics.\n\n\n\n\n\n Search skill \n\nA search skill leverages information from existing corporate knowledge bases or other collections of content authored by subject matter experts to address unanticipated or more nuanced customer inquiries.\n\nSee [Creating assistants](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-add) to get started.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistants"}, {"document_id": "ibmcld_03120-1659-3917", "score": 13.616343, "text": "\nThe precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\nFor example, use the web chat integration with your French-speaking assistant to deploy to a French-language page on your website. Deploy your German-speaking assistant to the German page of your website. Maybe you have a support phone number for French customers. You can configure your French-speaking assistant to answer those calls, and configure another phone number that German customers can use.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}, {"document_id": "ibmcld_03120-4-2233", "score": 13.462538, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Adding support for global audiences \n\nYour customers come from all around the globe. You need an assistant that can talk to them in their own language and in a familiar style. Choose the approach that best fits your business needs.\n\n\n\n* Quickest solution: The simplest way to add language support is to author the conversational skill in a single language. You can translate each message that is sent to your assistant from the customer's local language to the skill language. Later you can translate each response from the skill language back to the customer's local language.\n\nThis approach simplifies the process of authoring and maintaining the conversational skill. You can build one skill and use it for all languages. However, the intention and meaning of the customer message can be lost in the translation.\n\nFor more information about webhooks you can use for translation, see [Webhook overview](https://cloud.ibm.com/docs/assistant?topic=assistant-webhook-overview).\n* Most precise solution: If you have the time and resources, the best user experience can be achieved when you build multiple conversational skills, one for each language that you want to support. Watson Assistant has built-in support for all languages. Use one of 13 language-specific models or the universal model, which adapts to any other language you want to support.\n\nWhen you build a skill that is dedicated to a language, a language-specific classifier model is used by the skill. The precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\nFor example, use the web chat integration with your French-speaking assistant to deploy to a French-language page on your website.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02873-7-1949", "score": 21.197357, "text": "\nDialog overview \n\nThe dialog uses the intents that are identified in the user's input, plus context from the application, to interact with the user and ultimately provide a useful response.\n\nThe dialog matches intents (what users say) to responses (what the bot says back). The response might be the answer to a question such as Where can I get some gas? or the execution of a command, such as turning on the radio. The intent and entity might be enough information to identify the correct response, or the dialog might ask the user for more input that is needed to respond correctly. For example, if a user asks, Where can I get some food? you might want to clarify whether they want a restaurant or a grocery store, to dine in or take out, and so on. You can ask for more details in a text response and create one or more child nodes to process the new input.\n\nThe dialog is represented graphically in Watson Assistant as a tree. Create a branch to process each intent that you want your conversation to handle. A branch is composed of multiple nodes.\n\n\n\n Dialog nodes \n\nEach dialog node contains, at a minimum, a condition and a response.\n\n![Shows user input going to a box that contains the statement If: CONDITION, Then: RESPONSE](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/node1-empty.png)\n\n\n\n* Condition: Specifies the information that must be present in the user input for this node in the dialog to be triggered. The information is typically a specific intent. It might also be an entity type, an entity value, or a context variable value. See [Conditions](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-builddialog-overview-conditions) for more information.\n* Response: The utterance that your assistant uses to respond to the user. The response can also be configured to show an image or a list of options, or to trigger programmatic actions.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-build"}, {"document_id": "ibmcld_02952-1632-3754", "score": 20.789133, "text": "\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.\n\nFor example, an insurance company might want questions about bereavement benefits always to be handled by a person. Or, if a customer wants to close an account, you might want to transfer the conversation to a respresentative who is authorized to offer incentives to keep the customer's business.\n* When the assistant repeatedly fails to understand a customer's request. Instead of asking the customer to retry or rephrase the question over and over, your assistant can offer to transfer the customer to a human agent.\n\n\n\nTo design a dialog that can transfer the conversation, complete the following steps:\n\n\n\n1. Add an intent to your skill that can recognize a user's request to speak to a human.\n\nYou can create your own intent or add the prebuilt intent named General_Connect_to_Agent that is provided with the General content catalog.\n2. Add a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-support"}, {"document_id": "ibmcld_02914-6989-8664", "score": 20.365099, "text": "\nAs the dialog asks for and gets information from the user, it can keep track of the information and reference it later in the conversation.\n\nFor example, in one node you might ask users for their name, and in a later node address them by name.\n\n![Shows an introductions node that asks the user for their name, and stores it as a context variable. The next node refers to the user by name by using the $username context variable.](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/set-context-username.png)\n\nIn this example, the system entity @sys-person is used to extract the user's name from the input if the user provides one. In the JSON editor, the username context variable is defined and set to the @sys-person value. In a subsequent node, the $username context variable is included in the response to address the user by name.\n\n\n\n\n\n Defining a context variable \n\nDefine a context variable by adding the variable name to the Variable field and adding a default value for it to the Value field in the node's edit view.\n\n\n\n1. Click to open the dialog node to which you want to add a context variable.\n2. Go to the Assistant responds section and click the menu icon ![overflow menu icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/more-icon.png).\n\nIf you're using multiple conditioned responses, you must click the Customize response icon ![gear icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/customize-response-icon.png) to see the menu that is associated with the response.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime-context"}, {"document_id": "ibmcld_03233-4448-6123", "score": 20.206411, "text": "\nAs the dialog asks for and gets information from the user, it can keep track of the information and reference it later in the conversation.\n\nFor example, in one node you might ask users for their name, and in a later node address them by name.\n\n![Shows an introductions node that asks the user for their name, and stores it as a context variable. The next node refers to the user by name by using the $username context variable.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/set-context-username.png)\n\nIn this example, the system entity @name is used to extract the user's name from the input if the user provides one. In the JSON editor, the username context variable is defined and set to the @name value. In a subsequent node, the $username context variable is included in the response to address the user by name.\n\n\n\n\n\n Defining a context variable \n\nDefine a context variable by adding the variable name to the Variable field and adding a default value for it to the Value field in the node's edit view.\n\n\n\n1. Click to open the dialog node to which you want to add a context variable.\n2. Go to the Assistant responds section and click the menu icon ![overflow menu icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/more-icon.png).\n\nIf you're using multiple conditioned responses, you must click the Customize response icon ![gear icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/customize-response-icon.png) to see the menu that is associated with the response.\n3. Click Open context editor.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-runtime-context"}, {"document_id": "ibmcld_02953-3805-5544", "score": 19.877798, "text": "\n* To find and resubmit a test utterance, you can press the Up key to cycle through your recent inputs.\n* To remove prior test utterances from the chat pane and start over, click the Clear link. Not only are the test utterances and responses removed, but this action also clears the values of any context variables that were set as a result of your interactions with the dialog. Context variable values that you explicitly set or change are not cleared.\n\n\n\n\n\n\n\n What to do next \n\nIf you determine that the wrong intents or entities are being recognized, you might need to modify your intent or entity definitions.\n\nIf the correct intents and entities are being recognized, but the wrong nodes are being triggered in your dialog, make sure your conditions are written properly.\n\nIf you are ready to put the conversation to work helping your users, call the assistant from a client application. See [Building a client application](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-api-client).\n\n\n\n\n\n\n\n Searching your dialog \n\nThe search capability was introduced with the 1.5.0 release.\n\nYou can search the dialog to find one or more dialog nodes that mention a given word or phrase.\n\n\n\n1. From the Dialog page header, click the Search icon ![Search icon in the Intents page header](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/search_icon.png).\n2. Enter a search term or phrase.\n\nThe first time you search, an index is created. You might be asked to wait for the text in your dialog nodes to be indexed and then resubmit your request.\n\n\n\nDialog nodes that contain your search term, with corresponding examples, are shown. Select a result to open it for editing.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-tasks"}, {"document_id": "ibmcld_02873-1543-3356", "score": 19.836899, "text": "\nIt might also be an entity type, an entity value, or a context variable value. See [Conditions](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-builddialog-overview-conditions) for more information.\n* Response: The utterance that your assistant uses to respond to the user. The response can also be configured to show an image or a list of options, or to trigger programmatic actions. See [Responses](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-builddialog-overview-responses) for more information.\n\n\n\nYou can think of the node as having an if/then construction: if this condition is true, then return this response.\n\nFor example, the following node is triggered if the natural language processing function of your assistant determines that the user input contains the cupcake-menu intent. As a result of the node being triggered, your assistant responds with an appropriate answer.\n\n![Shows the user asking about cupcake flavors. the If condition is #cupcake-menu and the Then response is a list of cupcake flavors.](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/node1-simple.png)\n\nA single node with one condition and response can handle simple user requests. But, more often than not, users have more sophisticated questions or want help with more complex tasks. You can add child nodes that ask the user to provide any additional information that your assistant needs.\n\n![Shows that the first node in the dialog asks which type of cupcake the user wants, gluten-free or regular, and has two child nodes that provide a different response depending on the user's answer.](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/node1-children.png)", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-build"}, {"document_id": "ibmcld_03403-31931-33836", "score": 19.829485, "text": "\n[Try it](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/ask_watson.png) icon to open the \"Try it out\" pane.\n2. Click Clear to restart the conversation session.\n3. Enter, Who are you?\n\nYour assistant recognizes the General_About_You intent. Its response ends with the question, What should I call you?\n4. Enter, Jane.\n\nYour assistant saves Jane in the $username variable.\n5. Enter, Hello.\n\nYour assistant recognizes the General_Greetings intent and says, Good day to you, Jane! It uses the conditional response that includes the user's name because the $username context variable contains a value at the time that the greeting node is triggered.\n\n\n\nYou can add a conditional response that conditions on and includes the user's name for any other responses where personalization would add value to the conversation.\n\n\n\n\n\n\n\n Step 6: Test the assistant from your web page integration \n\nNow that you have built a more sophisticated version of the assistant, return to the public web page that you deployed as part of the previous tutorial, and then test the new capabilities you added.\n\n\n\n1. Open the assistant.\n2. Click Preview.\n3. Copy and paste the URL from Share this link into a web browser.\n\nAn IBM-branded page is displayed with your assistant embedded in it as a chat window.\n4. Repeat a few of the test utterances that you submited to the \"Try it out\" pane to see how the assistant behaves in a real integration.\n\nUnlike when you send test utterances to your assistant from the \"Try it out\" pane, standard usage charges apply to API calls that result from utterances that are submited to the chat widget.\n\n\n\n\n\n\n\n Next steps \n\nNow that you have built and tested your dialog skill, you can share it with customers. Deploy your skill by first connecting it to an assistant, and then deploying the assistant. There are several ways you can do this.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-tutorial"}, {"document_id": "ibmcld_03054-27011-29125", "score": 18.762568, "text": "\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition with a search skill response type.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:\n\nintents[0].confidence > 0.5\n\nThis condition is applied to all of the nodes in the folder. The condition tells your assistant to process the nodes in the folder only if your assistant is at least 50% confident that it knows the user's intent.\n3. Move any dialog nodes that you do not want your assistant to process often into the folder.\n\n\n\nAfter changing the dialog, test the assistant to make sure the search skill is triggered as often as you want it to be.\n\nAn alternative approach is to teach the dialog about topics to ignore. To do so, you can add utterances that you want the assistant to send to the search skill immediately as test utterances in the dialog skill's Try it out pane. You can then select the Mark as irrevlant option within the Try it out pane to teach the dialog not to respond to this utterance or others like it.\n\n\n\n\n\n Disabling search \n\nYou can disable the search skill from being triggered.\n\nYou might want to do so temporarily, while you are setting up the integration. Or you might want to only ever trigger a search for specific user queries that you can identify within the dialog, and use a search skill response type to answer.\n\nTo prevent the search skill from being triggered, complete the following steps:\n\n\n\n1. From the Assistants page, click the menu for your assistant, and then choose Settings.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-search-add"}, {"document_id": "ibmcld_03218-17987-20084", "score": 18.715677, "text": "\nFrom the \"Try it out\" pane, enter a test utterance that you think is a good candidate for disambiguation, meaning two or more of your dialog nodes are configured to address utterances like it.2. If the response does not contain a list of dialog node options for you to choose from as expected, first check that you added summary information to the node name (or external node name) field for each of the nodes.3. If disambiguation is still not triggered, it might be that the confidence scores for the nodes are not as close in value as you thought.\n<-- <ul> -->\n\n* To see the confidence scores of the top three intents that were detected in the input, hover over the eye icon in the \"Try it out\" pane.\n* To see the confidence scores of all the intents that are detected in the user input, temporarily add <? intents ?> to the end of the node response for a node that you know will be triggered.\n\nThis SpEL expression shows the intents that were detected in the user input as an array. The array includes the intent name and the level of confidence that your assistant has that the intent reflects the user's intended goal.\n* To see which entities, if any, were detected in the user input, you can temporarily replace the current response with a single text response that contains the SpEL expression, <? entities ?>.\n\nThis SpEL expression shows the entities that were detected in the user input as an array. The array includes the entity name, location of the entity mention within the user input string, the entity mention string, and the level of confidence that your assistant has that the term is a mention of the entity type specified.\n* To see details for all of the artifacts at once, including other properties, such as the value of a given context variable at the time of the call, you can inspect the entire API response. See Viewing API call details]]!\nService returns an array of intents, including Customer_Care_Cancel_Account and eCommerce_Cancel_Product_Order.Service returns an array of intents_ including Customer_Care_Cancel_Account and eCommerce_Cancel_Product_Order_.] ! ! ! !", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-runtime"}, {"document_id": "ibmcld_02882-7-2075", "score": 18.699236, "text": "\nBuilding a conversational flow \n\nThe dialog defines what your assistant says in response to customers.\n\n\n\n Creating a dialog \n\nTo create a dialog, complete the following steps:\n\n\n\n1. Click the Dialog tab, and then click Create dialog.\n\nWhen you open the dialog editor for the first time, the following nodes are created for you:\n\n\n\n* Welcome: The first node. It contains a greeting that is displayed to your users when they first engage with your assistant. You can edit the greeting.\n\n\n\nThis node is not triggered in dialog flows that are initiated by users. For example, dialogs that are deployed in environments such as messaging channels where customers start the conversation do not process nodes with the welcome special condition.\n\n\n\n* Anything else: The final node. It contains phrases that are used to reply to users when their input is not recognized. You can replace the responses that are provided or add more responses with a similar meaning to add variety to the conversation. You can also choose whether you want your assistant to return each response that is defined in turn or return them in random order.\n\n\n\n2. To add more nodes to the dialog tree, click the More![More icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kabob.png) icon on the Welcome node, and then select Add node below.\n3. In the If assistant recognizes field, enter a condition that, when met, triggers your assistant to process the node.\n\nTo start off, you typically want to add an intent as the condition. For example, if you add open_account here, it means that you want the response that you will specify in this node to be returned to the user if the user input indicates that the user wants to open an account.\n\nAs you begin to define a condition, a box is displayed that shows you your options. You can enter one of the following characters, and then pick a value from the list of options that is displayed.\n\n\n\nCondition builder syntax\n\n Character Lists defined values for these artifact types \n\n `#` intents", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overview"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16426-7-2260", "score": 16.313583, "text": "\nUploading resources from another workspace \n\nTo accelerate the creation of a model, you can upload resources like documents (with or without ground truth annotations), a type system, and dictionaries that you downloaded from another workspace.\n\nThe ability to separately download and upload different resources gives you flexibility when designing and creating a model. For example, you might create one workspace to design the type system and perform human annotation, and then create a separate workspace, perhaps in a separate instance of Knowledge Studio with different users, to train the machine learning model. Being able to upload the resources, including the ground truth created by human annotators, makes this scenario possible.\n\nYou cannot download and upload a machine learning model. Instead, you can download all of the artifacts that were used to create the model from one workspace and upload them into a new workspace. From the new workspace, you can run training again to recreate the model. The new model should produce similar results to the original model because they were both trained with the same set of artifacts.\n\nThe files that you download are operating system-independent. The Knowledge Studio instances where you download and upload files do not have to run the same version of Linux.\n\n\n\n Type systems \n\nTo download a type system, open the Assets> Entity Types page and click Download Types. The system creates a file named types-ID.json and prompts you to download the file to your local system. To use this type system in a new workspace, open the Entity Types page and upload the JSON file that you downloaded.\n\n\n\n\n\n Dictionaries \n\nTo download all dictionaries, select the Assets > Dictionaries page, click the Menu icon next to the Create Dictionary button, and select Download Dictionaries. For each dictionary that you download, the system creates a file named dictionary name_timestamp.csv, combines the files into a ZIP file named workspace name_dictionary_timestamp.zip, and prompts you to download the file to your local system.\n\nYou can download an individual dictionary by opening the dictionary and clicking Download. Preview-only dictionaries that you uploaded as a dictionary CSV file cannot be downloaded.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-exportimport"}, {"document_id": "ibmcld_16491-7-2260", "score": 16.313583, "text": "\nUploading resources from another workspace \n\nTo accelerate the creation of a model, you can upload resources like documents (with or without ground truth annotations), a type system, and dictionaries that you downloaded from another workspace.\n\nThe ability to separately download and upload different resources gives you flexibility when designing and creating a model. For example, you might create one workspace to design the type system and perform human annotation, and then create a separate workspace, perhaps in a separate instance of Knowledge Studio with different users, to train the machine learning model. Being able to upload the resources, including the ground truth created by human annotators, makes this scenario possible.\n\nYou cannot download and upload a machine learning model. Instead, you can download all of the artifacts that were used to create the model from one workspace and upload them into a new workspace. From the new workspace, you can run training again to recreate the model. The new model should produce similar results to the original model because they were both trained with the same set of artifacts.\n\nThe files that you download are operating system-independent. The Knowledge Studio instances where you download and upload files do not have to run the same version of Linux.\n\n\n\n Type systems \n\nTo download a type system, open the Assets> Entity Types page and click Download Types. The system creates a file named types-ID.json and prompts you to download the file to your local system. To use this type system in a new workspace, open the Entity Types page and upload the JSON file that you downloaded.\n\n\n\n\n\n Dictionaries \n\nTo download all dictionaries, select the Assets > Dictionaries page, click the Menu icon next to the Create Dictionary button, and select Download Dictionaries. For each dictionary that you download, the system creates a file named dictionary name_timestamp.csv, combines the files into a ZIP file named workspace name_dictionary_timestamp.zip, and prompts you to download the file to your local system.\n\nYou can download an individual dictionary by opening the dictionary and clicking Download. Preview-only dictionaries that you uploaded as a dictionary CSV file cannot be downloaded.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-exportimport"}, {"document_id": "ibmcld_16527-9521-11753", "score": 16.210789, "text": "\nA mention type indicates whether the mention is a name, nominal, or pronoun, and a mention class indicates whether the mention is specific, generic, or negated.\n4. Open the Assets> Relation Types page and specify how two mentions can relate to each other.\n\nOrder between the first and second entities in a relation type is usually relevant. For example, a PERSON entity can be an employee of an ORGANIZATION entity or a geo-political entity (GPE), such as MaryemployedByIBM, but organizations and geo-political entities cannot be employed by a person. When a human annotator clicks an entity in the ground truth editor , the list of available relation types is controlled by what is defined in the type system.\n\nDo not define relation attributes. They are not used by the machine learning model. The model uses only the relation type and order, and ignores the relation attributes.\n5. Use the Edit and Delete icons to modify entity types and their associated relation types, or to delete an entity type or relation type from the type system.\n\nIf you delete an entity that is used in a relation type definition, the relation type definition is also deleted.\n\n\n\n\n\n\n\nRelated tasks:\n\n[Modifying a type system without losing human annotations](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-improve-mlwks_projtypesysmod)\n\n\n\n\n\n\n\n Type system creation guidelines \n\nThe purpose of any type system in Knowledge Studio is to define how spans of text can be annotated. If you choose to create a type system from scratch, follow these guidelines.\n\nFocus on creating an inventory of entity types and relation types that cover the information that is needed by the application in which the type system will be used. Do not cover things that are not needed. Do not split types or make distinctions that are not needed by the application. For example, if the source document contains the sentence Murder on the Orient Express made headlines, then how you define entity types to capture the key information in the sentence differs depending on the type of application that will use the model that you build with the type system.\n\n\n\n* For a literary application, you might create types that capture this information:", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-typesystem"}, {"document_id": "ibmcld_16505-7-1982", "score": 16.036364, "text": "\nMachine learning model creation workflow \n\nCreate a machine learning model that trains a model you can use to identify entities, coreferences, and relationships of interest in new documents.\n\nUnderstand the typical workflow for creating a machine learning model in Knowledge Studio.\n\nAll the steps are performed by the project manager, except for the Annotate documents step, which is performed by the human annotator. Because human annotators are often subject matter experts, they might be consulted during the creation of workspace resources, such as the type system, also.\n\n![The workflow for developing a machine learning model](https://cloud.ibm.com/docs-content/v1/content/50eddb8fd81f33092880335ff107a78ff5cd0f65/watson-knowledge-studio/images/wks-checklist.svg) Figure 1. The workflow for developing a machine learning model\n\n\n\n Steps to create or refine a model \n\n\n\n Step Description \n\n Create a workspace See [Creating a workspace](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-create-project). A workspace contains the resources that are used to create the model, including: <br> <br>- Type system: Upload or create the type system, and define the entity types and relation types that human annotators can apply when annotating text. The model process manager typically works with subject matter experts for your domain to define the type system. See [Establishing a type system](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-typesystem) <br> <br>- Source documents: Create a corpus by uploading sample documents that are representative of your domain content into the workspace. See [Adding documents for annotation](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-documents-for-annotation). Partition the corpus into document sets, specify the percentage of documents that are shared among all document sets, and assign the document sets to human annotators.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-ml_annotator"}, {"document_id": "ibmcld_16442-7-1837", "score": 15.952573, "text": "\nMachine learning model creation workflow \n\nCreate a machine learning model that trains a model you can use to identify entities, coreferences, and relationships of interest in new documents.\n\nUnderstand the typical workflow for creating a machine learning model in Knowledge Studio for IBM Cloud Pak for Data.\n\nAll the steps are performed by the project manager, except for the Annotate documents step, which is performed by the human annotator. Because human annotators are often subject matter experts, they might be consulted during the creation of workspace resources, such as the type system, also.\n\n![The workflow for developing a machine learning model](https://cloud.ibm.com/docs-content/v1/content/148d3bd95f946aa1bb53ea1540475f522e6b61c9/watson-knowledge-studio-data/images/wks-checklist.svg) Figure 1. The workflow for developing a machine learning model\n\n\n\n Step Description \n\n Create a workspace See [Creating a workspace](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-create-project). A workspace contains the resources that are used to create the model, including: <br> <br>- Type system: Upload or create the type system, and define the entity types and relation types that human annotators can apply when annotating text. The model process manager typically works with subject matter experts for your domain to define the type system. See [Establishing a type system](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-typesystem) <br> <br>- Source documents: Create a corpus by uploading sample documents that are representative of your domain content into the workspace. See [Adding documents for annotation](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotation).", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-ml_annotator"}, {"document_id": "ibmcld_16427-2791-4722", "score": 15.793792, "text": "\nYou can upgrade a user ID to a role with greater permissions, but you cannot downgrade a user with an Admin or Project Manager role to the Human Annotator role.\n\n\n\n\n\n\n\n\n\n Lesson 2: Creating a workspace \n\nIn this lesson, you will learn how to create a workspace within Knowledge Studio.\n\n\n\n About this task \n\nA workspace defines all the resources that are required to create a machine learning model, including training documents, the type system, dictionaries, and annotations that are added by human annotators. For more information about workspace creation, see [Creating a workspace](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-create-project).\n\n\n\n\n\n Procedure \n\n\n\n1. {: hide-dashboard} As a Knowledge Studio administrator, from your IBM Cloud [resources](https://cloud.ibm.com/resources) page, click the Knowledge Studio service instance under Services.\n2. Click Launch tool from the Manage page.\n3. Click Create Workspace.\n4. Specify the details for the new workspace:\n\n\n\n* In the Workspace name field, type My workspace.\n* In the Workspace description field, type Watson Knowledge Studio tutorial workspace.\n* In the Language of documents field, use the default value, English. The sample files you will be using for this tutorial are in English.\n\n\n\n5. Click Create.\n\n\n\n\n\n\n\n Results \n\nThe workspace is created and opens automatically.\n\n\n\n\n\n What to do next \n\nYou can now start configuring the workspace resources, such as the type system.\n\n\n\n\n\n\n\n Lesson 3: Creating a type system \n\nIn this lesson, you will learn how to upload and modify a type system within Knowledge Studio. You must create or upload a type system before you begin any annotation tasks.\n\n\n\n About this task \n\nFor more information about type systems, see [Type systems](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-typesystemwks_typesystem).\n\n\n\n\n\n Procedure \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-getting-started"}, {"document_id": "ibmcld_16553-4421-6041", "score": 15.754631, "text": "\nA workspace defines all the resources that are required to create a machine learning model, including training documents, the type system, dictionaries, and annotations that are added by human annotators. For more information about workspace creation, see [Creating a workspace](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-create-project).\n\n\n\n\n\n Procedure \n\n\n\n1. As a Knowledge Studio administrator, from your IBM Cloud [resources](https://cloud.ibm.com/resources) page, click the Knowledge Studio service instance under Services.\n2. Click Launch tool from the Manage page.\n3. Click Create Workspace.\n4. Specify the details for the new workspace:\n\n\n\n* In the Workspace name field, type My workspace.\n* In the Workspace description field, type Watson Knowledge Studio tutorial workspace.\n* In the Language of documents field, use the default value, English. The sample files you will be using for this tutorial are in English.\n\n\n\n5. Click Create.\n\n\n\n\n\n\n\n Results \n\nThe workspace is created and opens automatically.\n\n\n\n\n\n What to do next \n\nYou can now start configuring the workspace resources, such as the type system.\n\n\n\n\n\n\n\n Lesson 3: Creating a type system \n\nIn this lesson, you will learn how to upload and modify a type system within Knowledge Studio. You must create or upload a type system before you begin any annotation tasks.\n\n\n\n About this task \n\nFor more information about type systems, see [Type systems](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-typesystemwks_typesystem).\n\n\n\n\n\n Procedure \n\n\n\n1. Download the [en-klue2-types.json !", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutintro"}, {"document_id": "ibmcld_16410-1604-3872", "score": 15.395758, "text": "\nThe creation of a model is an iterative multiple-step process that involves several stages: knowledge curation, ground truth generation, model development, model evaluation, and runtime deployment.\n\n\n\n End-to-end domain adaptation \n\nThe following diagram summarizes the interactions between these five stages of model development and the typical activities that occur at each stage.\n\n![A summary of the five stages of model development and the activities that occur at each stage.](https://cloud.ibm.com/docs-content/v1/content/148d3bd95f946aa1bb53ea1540475f522e6b61c9/watson-knowledge-studio-data/images/wks_flow.svg) Figure 2. A summary of the five stages of model development and the activities that occur at each stage.\n\n\n\n\n\n Knowledge curation \n\nThis stage, which is external to Knowledge Studio, refers to the process of selecting, collecting, preserving, and maintaining content relevant to a specific domain. Curation adds value to data; it transforms data into trusted information and knowledge.\n\n\n\n\n\n Ground truth generation \n\nThis stage refers to the use of Knowledge Studio tools and best practices to produce a collection of vetted data that can be used to adapt a Watson solution to a particular domain. The accuracy of this vetted data, called ground truth or gold standard documents, is critical because inaccuracies in the ground truth will correlate to inaccuracies in the applications that rely on it.\n\nAn essential part of teaching Watson about a new domain involves providing it with knowledge about entities of interest in your domain content, the relationships between them, and how the entities co-reference each other. Collecting this knowledge includes the following activities:\n\n\n\n* Involving domain subject matter experts to create the following resources, or to identify existing resources that can be re-used or modified for your domain:\n\n\n\n* Annotation guidelines and examples to help human annotators learn how words and passages in your domain content are to be annotated.\n* Type systems that define the domain-specific types (objects) and features (data classifications) that can be discovered in your domain content through text analysis. The type system controls the types of annotations that a human annotator can add to documents.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"}, {"document_id": "ibmcld_16454-9876-11996", "score": 15.273756, "text": "\nFor example, a PERSON entity can be an employee of an ORGANIZATION entity or a geo-political entity (GPE), such as MaryemployedByIBM, but organizations and geo-political entities cannot be employed by a person. When a human annotator clicks an entity in the ground truth editor , the list of available relation types is controlled by what is defined in the type system.\n\nDo not define relation attributes. They are not used by the machine learning model. The model uses only the relation type and order, and ignores the relation attributes.\n5. Use the Edit and Delete icons to modify entity types and their associated relation types, or to delete an entity type or relation type from the type system.\n\nIf you delete an entity that is used in a relation type definition, the relation type definition is also deleted.\n\n\n\n\n\n\n\nRelated tasks:\n\n[Modifying a type system without losing human annotations](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-improve-mlwks_projtypesysmod)\n\n\n\n\n\n\n\n Type system creation guidelines \n\nThe purpose of any type system in Knowledge Studio is to define how spans of text can be annotated. If you choose to create a type system from scratch, follow these guidelines.\n\nFocus on creating an inventory of entity types and relation types that cover the information that is needed by the application in which the type system will be used. Do not cover things that are not needed. Do not split types or make distinctions that are not needed by the application. For example, if the source document contains the sentence Murder on the Orient Express made headlines, then how you define entity types to capture the key information in the sentence differs depending on the type of application that will use the model that you build with the type system.\n\n\n\n* For a literary application, you might create types that capture this information:\n\n[NOVEL] [CRITICAL_RECEPTION]\n\n[Murder on the Orient Express] [made headlines]\n* For a public safety application, you might create these types:\n\n[EVENT_CRIME] [LOCATION]\n\n[Murder] on the [Orient Express] made headlines", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-typesystem"}, {"document_id": "ibmcld_16447-1597-3270", "score": 15.133554, "text": "\nIn large team settings, admins rarely participate in the model development process. \n Project manager Responsible for the overall organization of the workspace that she or he is assigned to. Tasks include creating the type system, managing assets, managing annotation work, evaluating the machine learning model, and deploying models. Users in this role need industry subject-matter expertise because they create the type system, teach the human annotators how to correctly apply the type system, and evaluate the model quality. \n Human annotator Performs the labeling of the entity mentions and relationship mentions in the training documents that he or she is assigned to. The work is assigned to human annotators and monitored by the project manager. Human annotators may not have industry subject-matter expertise, as long as they are taught by the project manager how to correctly apply the type system. \n\n\n\n\n\n\n\n Knowledge Studio role permissions \n\nTo compare the permissions of each role, see the following table. One permission is listed on each row. If a role has that permission, the role column is marked with a check mark (\u2713).\n\n\n\nTable 2. Role permissions\n\n Permission Admin Project manager Human annotator \n\n Manage user access and roles \u2713 \n Manage workspaces \u2713 \n Create the type system and annotation guidelines \u2713 \u2713 \n Upload training documents \u2713 \u2713 \n Manage rules \u2713 \u2713 \n Pre-annotate documents \u2713 \u2713 \n Manage annotation tasks \u2713 \u2713 \n Resolve annotation conflicts with human annotation (adjudication) \u2713 \u2713 \n Train and evaluate machine learning models \u2713 \u2713 \n Export models \u2713 \u2713 \n Annotate document sets directly \u2713 \u2713 \n Perform document annotation in annotation tasks \u2713 \u2713 \u2713", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-roles"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03126-3707-6008", "score": 21.660433, "text": "\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform.\n\n\n\n\n\n What languages does your assistant speak? \n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language).\n\n\n\n\n\n Does your assistant see the glass as half full? \n\nIs your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Choose a personality for your assistant, and then write conversations that reflect that personality. Don't overdo it. Don't sacrifice usability for the sake of keeping your assistant in character. But strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chat bots to identify themselves as chat bots.\n\n\n\n\n\n Who will build your assistant? \n\nAssemble a team with people who understand your customers and their needs, people who know how to interact with customers to reach the best outcomes. These subject matter experts can focus on designing an engaging conversational flow. In fact, the actions skill is designed with this type of expert in mind. The team can simultaneously build a conversational flow by defining discrete actions.\n\nIf you have data scientists or team members with programming skills, you can take advantage of some advanced capabilities that require varying levels of development expertise. This set of users might prefer to build the conversational flow with a dialog skill because there is greater visibility into the individual components that make up the training data.\n\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistants"}, {"document_id": "ibmcld_03043-7-2031", "score": 21.588991, "text": "\nAdding a skill to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nYou can create the following types of skills:\n\n\n\n* Dialog skill: Uses Watson natural language processing and machine learning technologies to understand user questions and requests, and respond to them with answers that are authored by you.\n* Search skill: For a given user query, uses the IBM Watson\u00ae Discovery service to search a data source of your self-service content and return an answer.\n\n\n\nTypically, you create a skill of each type first. Then, as you build a dialog for the dialog skill, you decide when to initiate the search skill. For some questions or requests, a hardcoded or programmatically-derived response (that is defined in the dialog skill) is sufficient. For others, you might want to provide a more robust response by returning a full passage of related information (that is extracted from an external data source by using the search skill).\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. In the tool, the name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-add"}, {"document_id": "ibmcld_03126-5596-6966", "score": 21.176426, "text": "\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).\n\n\n\n\n\n Do you have existing content to leverage? \n\nThe answer to many a common question is already documented somewhere in your organization's technical information collateral. If only you could find it!\n\nGive your assistant access to this information by adding a search skill to your assistant. The search skill uses Discovery to return smart answers to natural language questions.\n\n\n\n\n\n Expand your assistant's responsibilities \n\nIf you start small, and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. The built-in metrics of active user conversations help you understand what your customers are asking about and how well your assistant is able to meet their needs.\n\nNothing beats real customer data. It will tell you what areas to tackle next.\n\n\n\n\n\n Ready to start building? \n\nSee [Creating an assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-add) to get started.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistants"}, {"document_id": "ibmcld_03373-4-1923", "score": 21.075596, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Adding skills to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nConversational skills return responses that are authored by you to answer common questions, while a search skill searches for and returns passages from existing self-service content.\n\nYou can add the following types of skills to your assistant:\n\n\n\n* Conversational skills: Understand and address questions or requests that your customers typically ask about. You provide information about the subjects or tasks that your users need help with, and how they ask about them, and the product dynamically builds a machine learning model that is tailored to understand the same and similar user requests.\n\n\n\n* Actions skill : Offers a simple interface where anyone can build a conversational flow for your assistant to follow. The complex process of training data creation occurs behind the scenes automatically. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-addskill-add-actions-skill)\n* Dialog skill: Offers a set of editors that you use to define both your training data and the conversation. The conversation is represented as a dialog tree. You use the graphical dialog editor to create a script of sorts for your assistant to read from when it interacts with your customers. The dialog keys off the common customer goals that you teach it to recognize, and provides useful responses. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-addskill-add-dialog-skill)\n\n\n\nIf you can't decide which type of conversational skill to create, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).\n* Search skill!", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-add"}, {"document_id": "ibmcld_16364-163116-165172", "score": 20.802393, "text": "\nThis version of the tool was evaluated by beta program participants over the past several months.\n\n\n\n* Skills: What you think of as a workspace is now called a skill. A dialog skill is a container for the natural language processing training data and artifacts that enable your assistant to understand user questions, and respond to them.\n\n\n\nWhere are my workspaces? Any workspaces that you created previously are now listed in your service instance as skills. Click the Skills tab to see them. For more information, see [Adding skills to your assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-add).\n\n\n\n* Assistants: You can now publish your skill in just two steps. Add your skill to an assistant, and then set up one or more integrations with which to deploy your skill. The assistant adds a layer of function to your skill that enables Watson Assistant to orchestrate and manage the flow of information for you. See [Assistants](https://cloud.ibm.com/docs/assistant?topic=assistant-assistants).\n* Built-in integrations: Instead of going to the Deploy tab to deploy your workspace, you add your dialog skill to an assistant, and add integrations to the assistant through which the skill is made available to your users. You do not need to build a custom front-end application and manage the conversation state from one call to the next. However, you can still do so if you want to. See [Adding integrations](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-integration-add) for more information.\n* New major API version: A V2 version of the API is available. This version provides access to methods you can use to interact with an assistant at run time. No more passing context with each API call; the session state is managed for you as part of the assistant layer.\n\n\n\nWhat is presented in the tooling as a dialog skill is effectively a wrapper for a V1 workspace. There are currently no API methods for authoring skills and assistants with the V2 API. However, you can continue to use the V1 API for authoring workspaces.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_16364-98714-100707", "score": 20.630346, "text": "\nFor more information, see [Adding service desk support](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-haa).\n\nAutolearning has been moved and improved\n: Go to the Analytics>Autolearning page to enable the feature and see visualizations that illustrate how autolearning impacts your assistant's performance over time. For more information, see [Empower your skill to learn automatically](https://cloud.ibm.com/docs/assistant?topic=assistant-autolearn).\n\nSearch from actions skill\n: The actions skill now supports triggering a search that uses your associated search skill from within an action step. For more information, see [Deciding what to do next](https://cloud.ibm.com/docs/assistant?topic=assistant-actionsactions-what-next).\n\nSystem entities language support change\n: The new system entities are now used by all skills except Korean-language dialog skills. If you have a Korean skill that uses the older version of the system entities, update it. The legacy version will stop being supported for Korean skills in March 2021. For more information, see [Legacy system entities](https://cloud.ibm.com/docs/assistant?topic=assistant-legacy-system-entities).\n\nDisambiguation selection enhancement\n: When a customer chooses an option from a disambiguation list, the corresponding intent is submitted. With this latest release, a confidence score of 1.0 is assigned to the intent. Previously, the original confidence score of the option was used.\n\nSkill import improvements\n: Importing of large skills from JSON data is now processed in the background. When you import a JSON file to create a skill, the new skill tile appears immediately. However, depending on the size of the skill, it might not be available for several minutes while the import is being processed. During this time, the skill cannot be opened for editing or added to an assistant, and the skill tile shows the text Processing.\n\n\n\n\n\n 23 November 2020 \n\nDeploy your assistant to WhatsApp!", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_03049-3966-5647", "score": 20.268782, "text": "\nYou might need to remove the @sys-person and @sys-location entities from your training data, and any references to them from dialog nodes, for example.\n3. Try again to import the edited skill.\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon ![Skills menu icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/nav-ass-icon.png) to open the Assistants page.\n\nv1.3: Click the Assistants tab.\n2. Click to open the tile for the assistant to which you want to add the skill.\n3. Click Add Dialog Skill.\n4. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nWhen you add a dialog skill from here, you get the development version. If you want to add a specific skill version, add it from the skill's Versions tab instead.\n\n\n\n\n\n\n\n Downloading a dialog skill \n\nYou can download a dialog skill in JSON format. You might want to download a skill if you want to use the same dialog skill in a different instance of the Watson Assistant service, for example. You can download it from one instance and import it to another instance as a new dialog skill.\n\nTo download a dialog skill, complete the following steps:\n\n\n\n1. Find the dialog skill tile on the Skills page or on the configuration page of an assistant that uses the skill.\n2. Click the !", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-dialog-add"}, {"document_id": "ibmcld_03381-4347-6258", "score": 20.155176, "text": "\n2. Try again to upload the edited skill into the original service instance on the plan you want.\n\n\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one dialog skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add an actions or dialog skill.\n3. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nWhen you add a dialog skill from here, you get the development version. If you want to add a specific skill version, add it from the skill's Versions page instead.\n\n\n\n\n\n\n\n Sharing a dialog skill with team members \n\nAfter you create the service instance, you can give other people access to it. Together, you can define the training data and build the dialog.\n\nOnly one person can edit an intent, entity, or a dialog node at a time. If multiple people work on the same item at the same time, then the changes made by the person who saves their changes last are the only changes applied. Changes that are made during the same time frame by someone else and are saved first are not retained. Coordinate the updates that you plan to make with your team members to prevent anyone from losing their work.\n\nTo share a dialog skill with other people, you must give them access to the service instance that hosts the skill. Note that the person you invite will be able to access any skill or assistant in this service instance.\n\n\n\n1. Click the User ![User](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/user-icon2.png) icon in the page header.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-dialog-add"}, {"document_id": "ibmcld_03054-18427-20301", "score": 20.024988, "text": "\nFor details about how to add a search skill response type, see [Adding rich responses](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia-add).\n\nFor more tips about improving results, read the [Improve your natural language query results from Watson Discovery](https://developer.ibm.com/blogs/improving-your-natural-language-query-results-from-watson-discovery/) blog post.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. Open the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon ![Skills menu icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/nav-ass-icon.png) to open the Assistants page.\n\nv1.3: Click the Assistants tab.\n2. Click to open the tile for the assistant to which you want to add the skill.\n3. Click Add Search Skill.\n4. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nAfter you add a search skill to an assistant, it is automatically enabled for the assistant as follows:\n\n\n\n* If the assistant has only a search skill, any user input that is submitted to one of the assistant's integration channels triggers the search skill.\n* If the assistant has both a dialog skill and a search skill, any user input triggers the dialog skill first.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-search-add"}, {"document_id": "ibmcld_03330-3253-5192", "score": 19.875856, "text": "\n* A conversational skill interprets the customer's message further, then directs the flow of the conversation. The skill gathers any information it needs to respond or perform a transaction on the customer's behalf.\n* A search skill leverages existing FAQ or other curated content that you own to find relevant answers to customer questions.\n* If a customer wants more personalized help or wants to discuss a sensitive subject, the assistant can connect the customer with someone from your support team through the web chat integration.\n\n\n\n\n\nFor more information about the architecture, read the [How to Make Chatbot Orchestration Easier](https://medium.com/ibm-watson/how-to-make-chatbot-orchestration-easier-c8ed61620b8d) blog on Medium.com.\n\nTo see how Watson Assistant is helping enterprises cut costs and improve customer satisfaction today, read the [Independent study finds IBM Watson Assistant customers can accrue $23.9 million in benefits](https://www.ibm.com/blogs/watson/2020/03/independent-study-finds-ibm-watson-assistant-customers-accrued-23-9-million-in-benefits/) blog on ibm.com.\n\nThis documentation describes managed instances of Watson Assistant that are offered in IBM Cloud or in Cloud Pak for Data as a Service. If you are interested in on-premises or installed deployments, see [this documentation](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-index).\n\nRead more about these implementation steps by following these links:\n\n\n\n* [Creating an assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-add)\n* [Adding skills to your assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-add)\n* [Deploying your assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-integration-add)\n\n\n\n\n\n\n\n Browser support \n\nThe Watson Assistant application (where you create assistants and skills) requires the same level of browser software as is required by IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-index"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03054-22692-24767", "score": 16.14829, "text": "\n* Search response type: If you add a search skill response type to a dialog node, then your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed.\n\nThis approach is useful if you want to narrow down a user query before you trigger a search. For example, the dialog branch might collect information about the type of device the customer wants to buy. When you know the make and model, you can then send a model keyword in the query that is submitted to the search skill, and get better results.\n* Search skill only: If only a search skill is linked to an assistant, and no dialog skill is linked to the assistant, then a search query is sent to the Discovery service when any user input is received from one of the assistant's integration channels.\n\n\n\n\n\n\n\n Test the search skill \n\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Try it out pane of the search skill.\n\nYou cannot test the full end-to-end user experience from the dialog skill's Try it out pane. The search skill is configured separately and attached to an assistant. The dialog skill has no way of knowing the details of the search, and therefore cannot show search results in its Try it out pane.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, you must test it by using the API.\n\n\n\n1. From the IBM Cloud Pak for Data web client, go to the details page for the provisioned instance.\n2. Copy the URL from the \"Access information\" section of the page. You will specify this value as the {url}.\n3. Copy the bearer token also. You will need to pass the token when you make an API call.\n4. From the dialog builder in the user interface, add a search skill response type to a dialog node.\n5. Make a note of the unique ID of the assistant to which you added the dialog that you edited in the previous step.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-search-add"}, {"document_id": "ibmcld_03043-7-2031", "score": 15.839768, "text": "\nAdding a skill to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nYou can create the following types of skills:\n\n\n\n* Dialog skill: Uses Watson natural language processing and machine learning technologies to understand user questions and requests, and respond to them with answers that are authored by you.\n* Search skill: For a given user query, uses the IBM Watson\u00ae Discovery service to search a data source of your self-service content and return an answer.\n\n\n\nTypically, you create a skill of each type first. Then, as you build a dialog for the dialog skill, you decide when to initiate the search skill. For some questions or requests, a hardcoded or programmatically-derived response (that is defined in the dialog skill) is sufficient. For others, you might want to provide a more robust response by returning a full passage of related information (that is extracted from an external data source by using the search skill).\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. In the tool, the name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-add"}, {"document_id": "ibmcld_03114-12595-14433", "score": 15.8342285, "text": "\nFor each search result, the title, body, and url properties include content returned from the Discovery query. The search skill configuration determines which fields in the Discovery collection are mapped to these fields in the response. Your application can use these fields to display the results to the user (for example, you might use the body text to show an abstract or description of the matching document, and the url value to create a link the user can click to open the document).\n\nIn addition, the header property provides a message to display to the user about the results of the search. In the case of a successful search, header provides introductory text to be displayed before the search results (for example, I found the following information that might be helpful.). Different message text indicates that the search did not return any results, or that the connection to the Discovery service failed. You can customize these messages in the search skill configuration.\n\nFor more information about search skills, see [Creating a search skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-search-add).\n\n\n\n\n\n User-defined \n\nA user-defined response type can contain up to 5000 KB of data to support a type of a response you have implemented in your client. For example, you might define a user-defined response type to display a special color-coded card, or to format data in a table or graphic.\n\nThe user_defined property of the response is an object that can contain any valid JSON data:\n\n{\n\"output\": {\n\"generic\":[\n{\n\"response_type\": \"user_defined\",\n\"user_defined\": {\n\"field_1\": \"String value\",\n\"array_1\":\n1,\n2\n],\n\"object_1\": {\n\"property_1\": \"Another string value\"\n}\n}\n}\n]\n},\n\"user_id\": \"faf4a112-f09f-4a95-a0be-43c496e6ac9a\"\n}\nShow more\n\nYour application can parse and display the data in any way you choose.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-dialog-responses"}, {"document_id": "ibmcld_03054-16734-18944", "score": 15.6145735, "text": "\nSome web page content is dynamically generated and therefore cannot be crawled.\n\n\n\n* Configuring search results for uploaded documents: If you are using a collection of uploaded documents and cannot get the correct search results or the results are not concise enough, consider using Smart Document Understanding when you create the data collection.\n\nThis feature enables you to annotate documents based on text formatting. For example, you can teach Discovery that any text in 28-point bold font is a document title. If you apply this information to the collection when you ingest it, you can later use the title field as the source for the title section of your search result.\n\nYou can also use Smart Document Understanding to split up large documents into segments that are easier to search. For more information, see the the [Configuring your collection with Smart Document Understanding](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-configuring-fields) topic in the Discovery documentation.\n* Improve search results: If you don't like the results you are seeing, review this information for help.\n\n\n\n* Call the search skill from a dialog node, and specify filter details.\n\n\n\nFrom a dialog node search skill response, you can specify a full Discovery query syntax filter to help narrow the results.\n\nFor example, you can define a filter that filters out any documents in the data collection that do not mention an intent in the document title or some other metadata field. Or the filter can filter out documents that do not identify an entity as a known entity in the data collection's metadata or that don't mention the entity anywhere in the full text of the document. For details about how to add a search skill response type, see [Adding rich responses](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia-add).\n\nFor more tips about improving results, read the [Improve your natural language query results from Watson Discovery](https://developer.ibm.com/blogs/improving-your-natural-language-query-results-from-watson-discovery/) blog post.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-search-add"}, {"document_id": "ibmcld_03054-7-2020", "score": 15.563996, "text": "\nCreating a search skill \n\nAn assistant uses a search skill to route complex customer inquiries to IBM Watson\u00ae Discovery for IBM Cloud Pak\u00ae for Data. Discovery treats the user input as a search query. It finds information that is relevant to the query from a configured data source and returns it to the assistant.\n\nAdd a search skill to your assistant to prevent the assistant from having to say things like, I'm sorry. I can't help you with that. Instead, the assistant can query existing company documents or data to see whether any useful information can be found and shared with the customer.\n\n![Shows a search result in the preview link integration](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/search-skill-preview-link.png)\n\nYou must have Discovery for IBM Cloud Pak for Data installed and an instance provisioned before you can complete this procedure to create a search skill. The search skill can connect only to an existing Discovery for IBM Cloud Pak for Data instance.\n\nYour search skill can connect to a single Discovery project. The project can contain multiple collections.\n\nTo learn more about how search skill can benefit your business, [read this blog post](https://medium.com/ibm-watson/adding-search-to-watson-assistant-99e4e81839e5).\n\n\n\n How it works \n\nThe search skill searches for information from one or more data collections that you create by using Discovery for IBM Cloud Pak for Data.\n\nDiscovery for IBM Cloud Pak for Data crawls, converts, and normalizes your unstructured data. The product applies data analysis and cognitive intuition to enrich your data such that you can more easily find and retrieve meaningful information from it later. To read more about Discovery, see the [product documentation](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-about).\n\nTypically, the type of data collection you add to Discovery and access from your assistant contains information that is owned by your company.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-search-add"}, {"document_id": "ibmcld_03054-3104-4808", "score": 15.354916, "text": "\n[Skills menu icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/nav-skills-icon.png).\n\nv1.3: Click the Skills tab. If you don't see the Skills tab, click the breadcrumb link in the page header.\n2. Click Create skill.\n3. Click the Search skill option, and then click Next.\n4. Specify the details for the new skill:\n\n\n\n* Name: A name no more than 100 characters in length. A name is required.\n\nCurrently, you cannot rename your search skill later.\n* Description: An optional description no more than 200 characters in length.\n\n\n\n5. Click Continue.\n6. Choose the Discovery for IBM Cloud Pak for Data instance that you want to extract information from.\n\nIf no instances are available, ask an administrator whether Discovery is deployed in your environment. If so, ask to be given access to the Discovery instance. If not, you cannot create a search skill.\n7. Choose the project that you want to use, by doing one of the following things:\n\n\n\n* Choose an existing project, and then click Configure. Skip to the [Configure the search](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-search-addsearch-skill-add-configure) procedure.\n* If you do not have a project or do not want to use any of the projects that are listed, click Create a new project to add one. Follow the procedure in [Create a data collection](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-search-addsearch-skill-add-create-discovery-collection).\n\n\n\n\n\n\n\n\n\n Create a data collection \n\nWhen the Discovery application opens in a new browser tab or window, the Projects page might be displayed briefly. You do not need to create a project.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-search-add"}, {"document_id": "ibmcld_03010-12555-13929", "score": 15.3443, "text": "\n[Screen capture showing how to move or delete an example](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/move_example.png)\n\n\n\n\n\n\n\n Searching intents \n\nThe search capability was introduced with the 1.5.0 release.\n\nUse the Search feature to find user examples, intent names, and descriptions.\n\n\n\n1. From the Intents page header, click the Search icon ![Search icon in the Intents page header](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/search_icon.png).\n2. Submit a search term or phrase.\n\nThe first time you search for something, you might get a message that says the skill is being indexed. If so, wait a minute, and then resubmit the search term.\n\nIntents that contain your search term are displayed.\n\n![Shows the results from a search for intents](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/intent-search-results.png)\n\n\n\n\n\n\n\n Exporting intents \n\nYou can export a number of intents to a CSV file, so you can then import and reuse them for another Watson Assistant application.\n\n\n\n1. Go to the Intents page.\n\n\n\n* To export all intents, meaning the intents listed on this and any additional pages, do not select any individual intents. Instead, click the Export all intents icon. !", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents"}, {"document_id": "ibmcld_03196-46002-48092", "score": 15.272061, "text": "\nYou can trigger a search of the existing material in real time to get the latest and most up-to-date answer for your customers.\n\nTo use the search skill response type, you must create a search skill and add it to the same assistant that uses this dialog skill. For more information, see [Creating a search skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-search-add).\n\nTo add a Search skill response type, complete the following steps:\n\n\n\n1. From the dialog node where you want to add the response type, click the dropdown menu in the Assistant responds field, and then choose Search skill.\n\nIndicates that you want to search an external data source for a relevant response.\n2. To edit the search query to pass to the Discovery service, click Customize, and then fill in the following fields:\n\n\n\n* Query: Optional. You can specify a specific query in natural language to pass to Discovery. If you do not add a query, then the customer's exact input text is passed as the query.\n\nFor example, you can specify What cities do you fly to?. This query value is passed to Discovery as a search query. Discovery uses natural language understanding to understand the query and to find an answer or relevant information about the subject in the data collection that is configured for the search skill.\n\nYou can include specific information provided by the user by referencing entities that were detected in the user's input as part of the query. For example, Tell me about @product. Or you can reference a context variable, such as Do you have flights to $destination?. Just be sure to design your dialog such that the search is not triggered unless any entities or context variables that you reference in the query have been set to valid values.\n\nThis field is equivalent to the Discovery natural_language_query parameter. For more information, see [Query parameters](https://cloud.ibm.com/docs/discovery?topic=discovery-query-parametersnlq).\n\n\n\n* Filter: Optional. Specify a text string that defines information that must be present in any of the search results that are returned.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overview"}, {"document_id": "ibmcld_03383-8886-10816", "score": 15.242018, "text": "\n* Body: Search result description. Use an abstract, summary, or highlight field from the collection as the search result body.\n\nYou must select something for the body or no search result response is displayed in the Facebook and Slack integrations.\n* URL: This field can be populated with any footer content that you want to include at the end of the search result.\n\nFor example, you might want to include a hypertext link to the original data object in its native data source. Most online data sources provide self-referencing public URLs for objects in the store to support direct access. If you add a URL, it must be valid and reachable. If it is not, the Slack integration will not include the URL in its response and the Facebook integration will not return any response.\n\nThe Facebook and Slack integrations can successfully display the search result response when the URL field is empty.\n\n\n\nYou must use a field for at least one of the search results.\n\nIf no options are available from the drop-down fields, give Discovery more time to finish creating the collection. After waiting, if the collection is not created, then your collection might not contain any documents or might have ingestion errors that you need to address first.\n\n![Shows that the Title, Shortdesc, and url fields are selected and the preview search card is populated with information from those fields](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/search-skill-configure-fields.png)\n\nAs you add field mappings, a preview of the search result is displayed with information from the corresponding fields of your data collection. This preview shows you what gets included in the search result response that is returned to users.\n\nTo get help with configuring the search, see [Troubleshooting](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-search-addskill-search-add-troubleshoot).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-search-add"}, {"document_id": "ibmcld_03196-49298-51137", "score": 15.182997, "text": "\nThe search skill sends a natural language query to Discovery automatically. If you want to use the Discovery query language instead, you can specify it. To do so, open the JSON editor for the node response.\n\nEdit the JSON code snippet to replace natural_language with discovery_query_language. For example:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"query\": \"\",\n\"filter\": \"enriched_text.sentiment.document.label:positive\",\n\"query_type\": \"discovery_query_language\",\n\"response_type\": \"search_skill\"\n}\n]\n}\n}\n\n\n\nTest this response type from the assistant Preview. You cannot test it from the dialog skill's \"Try it out\" pane. For more information about testing dialog and search skills together, see [Testing your assistant from a web page](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-link).\n\n\n\n\n\n Conditional responses \n\nA single dialog node can provide different responses, each one triggered by a different condition. Use this approach to address multiple scenarios in a single node.\n\nThe node still has a main condition, which is the condition for using the node and processing the conditions and responses that it contains.\n\nIn this example, your assistant uses information that it collected earlier about the user's location to tailor its response, and provide information about the store nearest the user. See [Context variables](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-runtime-context) for more information about how to store information collected from the user.\n\n![Shows a node that shows a user ask, Where are you located, and the dialog has three different responses depending on conditions that use info from the $state context variable to specify locations in those states.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/multiple-responses.png)", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overview"}]}
{"task_id": "4c86c8740c3d49e06b7aca9d308119fa<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_05597-10227-11923", "score": 25.26929, "text": "\nIf the cluster master runs two or more versions behind the oldest supported version, you can no longer apply updates and must delete the cluster and create a new one.\n5. Archived: The version is unsupported with no upgrade path. IBM provides no support. IBM reserves the right to shut down the control planes for such clusters.\n\n\n\nIf you wait until your cluster is two or more minor versions behind the oldest supported version, you can't update the cluster. Instead, [create a new cluster](https://cloud.ibm.com/docs/containers?topic=containers-clustersclusters), [deploy your apps](https://cloud.ibm.com/docs/containers?topic=containers-appapp) to the new cluster, and [delete](https://cloud.ibm.com/docs/containers?topic=containers-remove) the unsupported cluster. To avoid this issue, update deprecated clusters to a supported version that is one or two behind the current version, such as 1.21 or 1.22 and then update to the latest version, 1.23. If the worker nodes run a version two or more behind the master, you might see your pods fail by entering a state such as MatchNodeSelector, CrashLoopBackOff, or ContainerCreating until you update the worker nodes to the same version as the master. After you update from a deprecated to a supported version, your cluster can resume normal operations and continue receiving support. You can find out whether your cluster is unsupported by reviewing the State field in the output of the ibmcloud ks cluster ls command or in the [IBM Cloud Kubernetes Service console](https://cloud.ibm.com/kubernetes/clusters).\n\n\n\n\n\n Preparing to update \n\nUpdating a cluster to a new version from the previous version is likely to have an impact on deployed apps.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-changelog"}, {"document_id": "ibmcld_05728-10229-11925", "score": 25.26929, "text": "\nIf the cluster master runs two or more versions behind the oldest supported version, you can no longer apply updates and must delete the cluster and create a new one.\n5. Archived: The version is unsupported with no upgrade path. IBM provides no support. IBM reserves the right to shut down the control planes for such clusters.\n\n\n\nIf you wait until your cluster is two or more minor versions behind the oldest supported version, you can't update the cluster. Instead, [create a new cluster](https://cloud.ibm.com/docs/containers?topic=containers-clustersclusters), [deploy your apps](https://cloud.ibm.com/docs/containers?topic=containers-appapp) to the new cluster, and [delete](https://cloud.ibm.com/docs/containers?topic=containers-remove) the unsupported cluster. To avoid this issue, update deprecated clusters to a supported version that is one or two behind the current version, such as 1.21 or 1.22 and then update to the latest version, 1.23. If the worker nodes run a version two or more behind the master, you might see your pods fail by entering a state such as MatchNodeSelector, CrashLoopBackOff, or ContainerCreating until you update the worker nodes to the same version as the master. After you update from a deprecated to a supported version, your cluster can resume normal operations and continue receiving support. You can find out whether your cluster is unsupported by reviewing the State field in the output of the ibmcloud ks cluster ls command or in the [IBM Cloud Kubernetes Service console](https://cloud.ibm.com/kubernetes/clusters).\n\n\n\n\n\n Preparing to update \n\nUpdating a cluster to a new version from the previous version is likely to have an impact on deployed apps.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_versions"}, {"document_id": "ibmcld_10642-1365-3347", "score": 24.077642, "text": "\nThen, [update the worker nodes](https://cloud.ibm.com/docs/openshift?topic=openshift-updateworker_node) in your cluster.\n\nWorker nodes can run later patch versions than the master, such as patch versions that are specific to worker nodes for security updates.\n\nHow are patch updates applied?\n: By default, patch updates for the master are applied automatically over the course of several days, so a master patch version might show up as available before it is applied to your master. The update automation also skips clusters that are in an unhealthy state or have operations currently in progress. Occasionally, IBM might disable automatic updates for a specific master fix pack, such as a patch that is only needed if a master is updated from one minor version to another. In any of these cases, you can [check the versions change log](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versions) for any potential impact and choose to safely use the ibmcloud oc cluster master update[command](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_cluster_update) yourself without waiting for the update automation to apply.\n\nUnlike the master, you must update your workers for each patch version.\n\nWhat happens during the master update?\n: Your master is highly available with three replica master pods. The master pods have a rolling update, during which only one pod is unavailable at a time. Two instances are up and running so that you can access and change the cluster during the update. Your worker nodes, apps, and resources continue to run.\n\nCan I roll back the update?\n: No, you can't roll back a cluster to a previous version after the update process takes place. Be sure to use a test cluster and follow the instructions to address potential issues before you update your production master.\n\nWhat process can I follow to update the master?\n: The following diagram shows the process that you can take to update your master.\n\nZoom\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-update"}, {"document_id": "ibmcld_05754-3185-5238", "score": 23.649794, "text": "\nYou cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud ks cluster master update[command](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud ks versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https://cloud.ibm.com/docs/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n Understanding the impact of a master outage", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-debug_master"}, {"document_id": "ibmcld_10189-3187-5240", "score": 23.617498, "text": "\nYou cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud oc cluster master update[command](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud oc versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https://cloud.ibm.com/docs/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n Understanding the impact of a master outage", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-debug_master"}, {"document_id": "ibmcld_06209-1393-3390", "score": 23.573595, "text": "\nIf your cluster runs an unsupported Kubernetes version, follow the [version archive instructions](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionsk8s_version_archive). To avoid getting in an unsupported state and operational impact, keep your cluster up-to-date.\n\nCan my worker nodes run a later version than the master?\n: Your worker nodes can't run a later major.minor Kubernetes version than the master. Additionally, your worker nodes can be only up to two versions behind the master version (n-2). First, [update your master](https://cloud.ibm.com/docs/containers?topic=containers-updateupdate_master) to the latest Kubernetes version. Then, [update the worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updateworker_node) in your cluster.\n\nWorker nodes can run later patch versions than the master, such as patch versions that are specific to worker nodes for security updates.\n\nHow are patch updates applied?\n: By default, patch updates for the master are applied automatically over the course of several days, so a master patch version might show up as available before it is applied to your master. The update automation also skips clusters that are in an unhealthy state or have operations currently in progress. Occasionally, IBM might disable automatic updates for a specific master fix pack, such as a patch that is only needed if a master is updated from one minor version to another. In any of these cases, you can [check the versions change log](https://cloud.ibm.com/docs/containers?topic=containers-changelog) for any potential impact and choose to safely use the ibmcloud ks cluster master update[command](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_cluster_update) yourself without waiting for the update automation to apply.\n\nUnlike the master, you must update your workers for each patch version.\n\nWhat happens during the master update?\n: Your master is highly available with three replica master pods.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-update"}, {"document_id": "ibmcld_05653-95381-96778", "score": 23.454533, "text": "\nUpdate your cluster to at least [version 1.20](https://cloud.ibm.com/docs/containers?topic=containers-cs_versions_120) as soon as possible.\n\nMaster fix pack and worker node fix pack update\n: Change log documentation is available for Kubernetes version [1.22.2_1522 and 1.22.2_1523](https://cloud.ibm.com/docs/containers?topic=containers-changelog_1221222_1522_and_1222_1523).\n\n\n\n\n\n 27 September 2021 \n\nMaster fix pack update\n: Change log documentation is available for version [1.21.5_1531](https://cloud.ibm.com/docs/containers?topic=containers-changelog_1211215_1531), [1.20.11_1553](https://cloud.ibm.com/docs/containers?topic=containers-changelog_12012011_1553), [1.19.15_1560](https://cloud.ibm.com/docs/containers?topic=containers-changelog_11911915_1560), [1.18.20_1565](https://cloud.ibm.com/docs/containers?topic=containers-118_changelog11820_1565).\n\nWorker node fix pack update\n: Change log documentation is available for version [1.18.20_1566](https://cloud.ibm.com/docs/containers?topic=containers-118_changelog11820_1566), [1.19.15_1561](https://cloud.ibm.com/docs/containers?topic=containers-changelog_11911915_1561), [12011_1554](https://cloud.ibm.com/docs/containers?topic=containers-changelog_12012011_1554), and [1.21.5_1532](https://cloud.ibm.com/docs/containers?topic=containers-changelog_1211215_1532).\n\n\n\n\n\n 23 September 2021 \n\nReview the release notes for 23 September 2021.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-containers-relnotes"}, {"document_id": "ibmcld_10392-102583-103538", "score": 23.244804, "text": "\nUpdate your cluster to at least [version 4.6](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versions) as soon as possible.\n\nMaster fix pack and worker node fix pack update\n: Change log documentation is available for OpenShift version [4.8.11_1526_openshift and 4.8.12_1527_openshift](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_changelog_48).\n\n\n\n\n\n 27 September 2021 \n\nMaster fix pack update\n: Change log documentation is available for version [4.7.30_1532_openshift](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_changelog_474730_1532),[4.6.44_1556_openshift](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_changelog_464644_1556), [4.5.41_1552_openshift](https://cloud.ibm.com/docs/openshift?topic=openshift-changelog_archive4541_1552), and [3.11.521_1604_openshift](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_changelog_311311521_1604).\n\nWorker node fix pack update", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-relnotes"}, {"document_id": "ibmcld_10394-1469-2994", "score": 23.099926, "text": "\nIf you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.\n\n\n\n\n\n\n\n Step 2: Determine which worker nodes you want to update \n\nMajor\n\nMinor\n\n\n\n1. List your worker nodes by using the oc get nodes command and determining which worker nodes you want to update.\n\noc get nodes\n\nExample output\n\nNAME STATUS ROLES AGE VERSION\n10.241.0.4 Ready master,worker 106s v1.21.6+4b61f94\n10.241.128.4 Ready master,worker 22d v1.21.6+bb8d50a\n10.241.64.4 Ready master,worker 22d v1.21.6+bb8d50a\n\n\n\n\n\n\n\n Step 3: Scale down OpenShift Data Foundation \n\nMajor\n\nMinor\n\n\n\n1. For each worker node that you found in the previous step, find the rook-ceph-mon and rook-ceph-osd deployments.\n\noc get pods -n openshift-storage -o wide | grep -i <node_name>\n2. Scale down the deployments that you found in the previous step.\n\noc scale deployment rook-ceph-mon-c --replicas=0 -n openshift-storage\noc scale deployment rook-ceph-osd-2 --replicas=0 -n openshift-storage\noc scale deployment --selector=app=rook-ceph-crashcollector,node_name=NODE-NAME --replicas=0 -n openshift-storage\n\n\n\n\n\n\n\n Step 4: Cordon and drain the worker node \n\nMajor\n\nMinor\n\n\n\n1. Cordon the node. Cordoning the node prevents any pods from being scheduled on this node.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-storage-update-classic"}, {"document_id": "ibmcld_05526-66361-67875", "score": 23.093723, "text": "\nCluster master HA configuration N/A N/A Updated configuration to improve performance of master update operations. \n Default IBM file storage class N/A N/A Fixed a bug that might cause cluster master operations such as patch updates to clear the default IBM file storage class. \n Gateway-enabled cluster controller N/A 844 New! For classic clusters with a gateway enabled, a DaemonSet is installed to configure settings for routing network traffic to worker nodes. \n IBM Cloud Provider v1.15.3-112 v1.15.4-136 Updated to support the Kubernetes 1.15.4 release. In addition, version 1.0 and 2.0 network load balancers (NLBs) were updated to support classic clusters with a gateway enabled. \n Key Management Service provider 212 221 Improved Kubernetes [key management service provider](https://cloud.ibm.com/docs/containers?topic=containers-encryptionkeyprotect) caching of IBM Cloud IAM tokens. In addition, fixed a problem with Kubernetes secret decryption when the cluster's root key is rotated. \n Kubernetes v1.15.3 v1.15.4 See the [Kubernetes release notes)](https://github.com/kubernetes/kubernetes/releases/tag/v1.15.4). \n Kubernetes Metrics Server v0.3.3 v0.3.4 See the [Kubernetes Metrics Server release notes)](https://github.com/kubernetes-sigs/metrics-server/releases/tag/v0.3.4). \n Load balancer and load balancer monitor for IBM Cloud Provider 148 153 Fixed issues with version 2.0 network load balancers (NLBs) that might cause all network traffic to drop or to be sent only to pods on one worker node.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-115_changelog"}]}
{"task_id": "4c86c8740c3d49e06b7aca9d308119fa<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_05612-7-1934", "score": 24.01913, "text": "\nVersion 1.21 CIS Kubernetes benchmark \n\nKubernetes version 1.21 becomes unsupported on 14 September 2022. Update your cluster to at least [version 1.22](https://cloud.ibm.com/docs/containers?topic=containers-cs_versions_122) as soon as possible.\n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.21. For more information or help understanding the benchmark, see [Using the benchmark](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-121"}, {"document_id": "ibmcld_05618-7-2074", "score": 23.811136, "text": "\nKubernetes version 1.27 CIS Kubernetes Benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.27. For more information or help understanding the benchmark, see [Using the benchmark](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmarkcis-benchmark-use).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive Not Scored 1 Pass IBM \n 1.1.10 Ensure that the Container Network Interface file ownership is set to root:root Not Scored 1 Pass IBM", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-127"}, {"document_id": "ibmcld_05617-7-2046", "score": 23.621243, "text": "\nVersion 1.26 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.26. For more information or help understanding the benchmark, see [Using the benchmark](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive Not Scored 1 Pass IBM \n 1.1.10 Ensure that the Container Network Interface file ownership is set to root:root Not Scored 1 Pass IBM", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-126"}, {"document_id": "ibmcld_05616-7-1945", "score": 23.238974, "text": "\nVersion 1.25 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.25. For more information or help understanding the benchmark, see [Using the benchmark](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-125"}, {"document_id": "ibmcld_05611-7-1955", "score": 23.234146, "text": "\nVersion 1.20 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.20. For more information or help understanding the benchmark, see [Using the benchmark](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-120"}, {"document_id": "ibmcld_05614-7-1955", "score": 23.232182, "text": "\nVersion 1.23 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.23. For more information or help understanding the benchmark, see [Using the benchmark](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-123"}, {"document_id": "ibmcld_05613-7-1955", "score": 23.230106, "text": "\nVersion 1.22 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.22. For more information or help understanding the benchmark, see [Using the benchmark](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-122"}, {"document_id": "ibmcld_05615-7-1945", "score": 23.224121, "text": "\nVersion 1.24 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.24. For more information or help understanding the benchmark, see [Using the benchmark](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-124"}, {"document_id": "ibmcld_05610-7-1993", "score": 22.555609, "text": "\nVersion 1.19 CIS Kubernetes benchmark \n\nKubernetes version 1.19 is unsupported.\n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.19. For more information or help understanding the benchmark, see [Using the benchmark](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-119"}, {"document_id": "ibmcld_05608-3099-5358", "score": 22.200619, "text": "\n* Shared: You and IBM share responsibility for configuring the setting that the benchmark recommends.\n\n\n\n\n\n\n\n\n\n What parts of the benchmark am I responsible for? \n\nBecause IBM Cloud Kubernetes Service is a managed offering, IBM already configures many security settings for you. For example, IBM manages and automatically applies updates to your cluster master. For your worker nodes, IBM provides security and version updates, but you must apply the updates. You are also responsible for your workload applications and data. For more information, see [Your responsibilities while using IBM Cloud Kubernetes Service](https://cloud.ibm.com/docs/containers?topic=containers-responsibilities_iks).\n\n\n\n\n\n What if some part of the service fails to comply with a recommendation? \n\nFirst, check the explanation of the failure for any remediation steps.\n\nThen, determine whether the failure is acceptable according to your security requirements. For example, some recommendations might be more in-depth configuration requirements than your particular processes or standards require. Also, some recommendations are not scored, and don't impact the overall benchmark score.\n\nNext, decide whether the component falls within your responsibility. If so, you might need to change how you configure that component. For example, you might configure pod security policies for all your app deployments. For components that are not directly within your responsibility, assess whether you can use another IBM Cloud service to meet the recommendation.\n\n\n\n\n\n What else can I do to increase the security and compliance of my cluster? \n\nSee [Security for IBM Cloud Kubernetes Service](https://cloud.ibm.com/docs/containers?topic=containers-security).\n\n\n\n\n\n\n\n Running the worker node CIS Kubernetes benchmark \n\nTo review the results of the CIS Kubernetes benchmark for Section 4: Worker node security configuration, you can run the test yourself. Because you own the worker nodes and are partially [responsible](https://cloud.ibm.com/docs/containers?topic=containers-responsibilities_iks) for their compliance, you might make configuration changes that you want to validate on your own.\n\nBefore you begin: [Log in to your account. If applicable, target the appropriate resource group.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark"}]}
{"task_id": "4c86c8740c3d49e06b7aca9d308119fa<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07578-373434-375500", "score": 24.74033, "text": "\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https://cloud.ibm.com/docs/containers?topic=containers-cs_ovbenefits).\n* Can I get a free cluster?\n\nThe free tier option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https://www.ibm.com/account/reg/us-en/signup?formid=MAIL-wcp).\n\nYou can have 1 free cluster at a time in IBM Cloud Kubernetes Service, and each free cluster expires in 30 days. Free clusters are ideal for testing out Kubernetes deployments and getting familiar with the IBM Cloud Kubernetes Service API, CLI, and console tools. After you are done testing your free cluster, you can [copy your configuration files and redeploy them to a standard cluster](https://cloud.ibm.com/docs/containers?topic=containers-update_appcopy_apps_cluster).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-373408-375474", "score": 24.74033, "text": "\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https://cloud.ibm.com/docs/containers?topic=containers-cs_ovbenefits).\n* Can I get a free cluster?\n\nThe free tier option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https://www.ibm.com/account/reg/us-en/signup?formid=MAIL-wcp).\n\nYou can have 1 free cluster at a time in IBM Cloud Kubernetes Service, and each free cluster expires in 30 days. Free clusters are ideal for testing out Kubernetes deployments and getting familiar with the IBM Cloud Kubernetes Service API, CLI, and console tools. After you are done testing your free cluster, you can [copy your configuration files and redeploy them to a standard cluster](https://cloud.ibm.com/docs/containers?topic=containers-update_appcopy_apps_cluster).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_05707-4888-6797", "score": 24.499458, "text": "\nIBM Cloud Kubernetes Service on IBM Cloud Public delivers powerful tools by combining Docker containers, the Kubernetes technology, an intuitive user experience, and built-in security and isolation to automate the deployment, operation, scaling, and monitoring of containerized apps in a cluster of compute hosts For more information, see [IBM Cloud Kubernetes Service technology](https://cloud.ibm.com/docs/containers?topic=containers-service-arch).\n: You can also create your cluster in a Virtual Private Cloud (VPC), which gives you the security of a private cloud environment with isolated networking features along with the dynamic scalability of the public cloud. For more information, see [Overview of Classic and VPC infrastructure providers](https://cloud.ibm.com/docs/containers?topic=containers-infrastructure_providers).\n\nIBM Cloud Private, on-premises\n: IBM Cloud Private is an application platform that can be installed locally on your own machines. You might choose to use Kubernetes in IBM Cloud Private when you need to develop and manage on-premises, containerized apps in your own controlled environment behind a firewall. For more information, see the [IBM Cloud Private product documentation](https://www.ibm.com/docs/en/cloud-private/3.2.x).\n\n\n\n\n\n Comparison of free and standard clusters \n\nReview the following table for a comparison of free and standard clusters.\n\nThe free cluster option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https://www.ibm.com/account/reg/us-en/signup?formid=MAIL-wcp).\n\nFree clusters are automatically deleted after 30 days.\n\nIf you have a free cluster and want to upgrade to a standard cluster, you can [create a standard cluster](https://cloud.ibm.com/docs/containers?topic=containers-clusters).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_ov"}, {"document_id": "ibmcld_05777-1455-3483", "score": 24.103415, "text": "\nYour worker nodes are controlled by a highly available Kubernetes master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https://cloud.ibm.com/docs/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https://cloud.ibm.com/docs/containers?topic=containers-cs_ov).\n\n\n\n\n\n Why should I use IBM Cloud Kubernetes Service? \n\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https://cloud.ibm.com/docs/containers?topic=containers-cs_ovbenefits).\n\n\n\n\n\n Can I get a free cluster? \n\nThe free tier option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https://www.ibm.com/account/reg/us-en/signup?formid=MAIL-wcp).\n\nYou can have 1 free cluster at a time in IBM Cloud Kubernetes Service, and each free cluster expires in 30 days.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-faqs"}, {"document_id": "ibmcld_00808-1356-2847", "score": 23.704113, "text": "\nAnd you must also have a [Kubernetes cluster](https://cloud.ibm.com/kubernetes/clusters) (version 1.15 or higher) with Administrative access to install a private worker.\n\n\n\n* Suggested Kubernetes cluster configurations:\n\n\n\n* IBM Cloud Kubernetes Service version 1.21 or higher to run workloads in isolation on IBM Cloud Public.\n* Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae version 4.9 or later.\n\n\n\n* Network access:\n\n\n\n* Inbound: Not required.\n* Outbound network access uses (TCP:443) where the region matches the delivery pipeline location and is either au-syd (Sydney, Australia), eu-de (Frankfurt, Germany), eu-gb (London, United Kingdom), jp-tok (Tokyo, Japan), jp-osa (Osaka, Japan), us-south (Dallas, US), us-east (Washington DC, US), br-sao (Sao Paulo), or ca-tor (Toronto, CA). For example, for the Frankfurt region specify https://private-worker-service.eu-de.devops.cloud.ibm.com (TCP:443). For network access to the global endpoint for API key validation, use https://iam.cloud.ibm.com (TCP:443).\n\n\n\n* Permissions to pull images from icr.io. Private workers require the tekton-pipelines infrastructure and must be able to pull tekton-releases images from icr.io to complete the private worker installation.\n\nTo pull images from the icr.io container registry, you might need to [define a specific Kubernetes ClusterImagePolicy](https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-faq_pipeline_private_workers&interface=uipipeline_private_worker_image_policy).\n* Optional.", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-install-private-workers&interface=ui"}, {"document_id": "ibmcld_00800-1356-2847", "score": 23.704113, "text": "\nAnd you must also have a [Kubernetes cluster](https://cloud.ibm.com/kubernetes/clusters) (version 1.15 or higher) with Administrative access to install a private worker.\n\n\n\n* Suggested Kubernetes cluster configurations:\n\n\n\n* IBM Cloud Kubernetes Service version 1.21 or higher to run workloads in isolation on IBM Cloud Public.\n* Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae version 4.9 or later.\n\n\n\n* Network access:\n\n\n\n* Inbound: Not required.\n* Outbound network access uses (TCP:443) where the region matches the delivery pipeline location and is either au-syd (Sydney, Australia), eu-de (Frankfurt, Germany), eu-gb (London, United Kingdom), jp-tok (Tokyo, Japan), jp-osa (Osaka, Japan), us-south (Dallas, US), us-east (Washington DC, US), br-sao (Sao Paulo), or ca-tor (Toronto, CA). For example, for the Frankfurt region specify https://private-worker-service.eu-de.devops.cloud.ibm.com (TCP:443). For network access to the global endpoint for API key validation, use https://iam.cloud.ibm.com (TCP:443).\n\n\n\n* Permissions to pull images from icr.io. Private workers require the tekton-pipelines infrastructure and must be able to pull tekton-releases images from icr.io to complete the private worker installation.\n\nTo pull images from the icr.io container registry, you might need to [define a specific Kubernetes ClusterImagePolicy](https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-faq_pipeline_private_workers&interface=uipipeline_private_worker_image_policy).\n* Optional.", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-install-private-workers"}, {"document_id": "ibmcld_00807-1356-2847", "score": 23.704113, "text": "\nAnd you must also have a [Kubernetes cluster](https://cloud.ibm.com/kubernetes/clusters) (version 1.15 or higher) with Administrative access to install a private worker.\n\n\n\n* Suggested Kubernetes cluster configurations:\n\n\n\n* IBM Cloud Kubernetes Service version 1.21 or higher to run workloads in isolation on IBM Cloud Public.\n* Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae version 4.9 or later.\n\n\n\n* Network access:\n\n\n\n* Inbound: Not required.\n* Outbound network access uses (TCP:443) where the region matches the delivery pipeline location and is either au-syd (Sydney, Australia), eu-de (Frankfurt, Germany), eu-gb (London, United Kingdom), jp-tok (Tokyo, Japan), jp-osa (Osaka, Japan), us-south (Dallas, US), us-east (Washington DC, US), br-sao (Sao Paulo), or ca-tor (Toronto, CA). For example, for the Frankfurt region specify https://private-worker-service.eu-de.devops.cloud.ibm.com (TCP:443). For network access to the global endpoint for API key validation, use https://iam.cloud.ibm.com (TCP:443).\n\n\n\n* Permissions to pull images from icr.io. Private workers require the tekton-pipelines infrastructure and must be able to pull tekton-releases images from icr.io to complete the private worker installation.\n\nTo pull images from the icr.io container registry, you might need to [define a specific Kubernetes ClusterImagePolicy](https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-faq_pipeline_private_workers&interface=uipipeline_private_worker_image_policy).\n* Optional.", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-install-private-workers&interface=cli"}, {"document_id": "ibmcld_05724-12280-14738", "score": 23.466934, "text": "\nThese apps are accessible by a public endpoint, which is secured by the API Gateway to the world. Then, researchers and data analysts from everywhere can download data sets and do their own analysis.\n\nDevelopers started by deploying their research-sharing SaaS apps in containers with IBM Cloud Kubernetes Service. They created clusters for a Development environment that allow worldwide Developers to collaboratively deploy app improvements quickly.\n\nSecurity first: The Development Exec chose bare metal to host the research clusters. With bare metal for IBM Cloud Kubernetes Service, the sensitive research workloads now have familiar isolation but within the flexibility of public cloud. Because this nonprofit also has a partnership with pharmaceutical companies, app security is crucial. Competition is fierce, and corporate espionage is possible. From that secure core, Vulnerability Advisor provides scanning.\n\n\n\n* Image vulnerability scanning\n* Policy scanning based on ISO 27k\n\n\n\nSecured research apps lead to increased clinical trial participation.\n\nTo achieve global availability, the Dev, Test, and Production systems are deployed across the globe in several data centers. For HA, they use a combination of clusters in multiple geographic regions as well as multizone clusters. They can easily deploy the research app to Frankfurt clusters to comply with the local European regulation. They also deploy the app within the United States clusters to ensure availability and recovery locally. They also spread the research workload across multizone clusters in Frankfurt to ensure that the European app is available and also balances the workload efficiently. Because researchers are uploading sensitive data with the research-sharing app, the app\u2019s clusters are hosted in regions where stricter regulations apply.\n\nDevelopers focus on domain problems, by using existing tools: Instead of writing unique ML code, ML logic is snapped into apps, by binding IBM Cloud services to clusters. Developers are also freed up from infrastructure management tasks because IBM takes care of Kubernetes and infrastructure upgrades, security, and more.\n\nCompute, storage, and apps run in public cloud with secure access to research data across the globe, as warranted. Compute in clusters is tamper-proof and isolated to bare metal.\n\nTechnical solution:\n\n\n\n* IBM Cloud Kubernetes Service\n* IBM Cloud\u00ae Functions\n* IBM Cloudant\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_uc_health"}, {"document_id": "ibmcld_04186-2976-4733", "score": 23.423447, "text": "\n* own a custom domain so you can configure the DNS for this domain to point to IBM Cloud Internet Services name servers.\n* and [understand the basics of Kubernetes](https://kubernetes.io/docs/tutorials/kubernetes-basics/).\n\n\n\n\n\n\n\n Step 1: Deploy an application to one location \n\nThis tutorial deploys a Kubernetes application to clusters in multiple locations. You will start with one location, Dallas, and then repeat these steps for London.\n\n\n\n Create a Kubernetes cluster \n\nA minimal cluster with one (1) zone, one (1) worker node and the smallest available size (Flavor) is sufficient for this tutorial.\n\nWhen creating the Kubernetes cluster below:\n\n\n\n1. Set Cluster name to my-us-cluster.\n2. Locate in North America and Dallas\n\n\n\nOpen the [Kubernetes clusters](https://cloud.ibm.com/kubernetes/clusters) and click Create cluster. See the documentation referenced below for more details based on the cluster type. Summary:\n\n\n\n* Click Standard tier cluster\n* For Kubernetes on VPC infrastructure see reference documentation [Creating VPC clusters](https://cloud.ibm.com/docs/containers?topic=containers-cluster-create-vpc-gen2&interface=ui).\n\n\n\n* Click Create VPC:\n\n\n\n* Enter a name for the VPC.\n* Chose the same resource group as the cluster.\n* Click Create.\n\n\n\n* Attach a Public Gateway to each of the subnets that you create:\n\n\n\n* Navigate to the [Virtual private clouds](https://cloud.ibm.com/vpc-ext/network/vpcs).\n* Click the previously created VPC used for the cluster.\n* Scroll down to subnets section and click a subnet.\n* In the Public Gateway section, click Detached to change the state to Attached.\n* Click the browser back button to return to the VPC details page.\n* Repeat the previous three steps to attach a public gateway to each subnet.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-multi-region-k8s-cis"}, {"document_id": "ibmcld_01391-2981-4738", "score": 23.423447, "text": "\n* own a custom domain so you can configure the DNS for this domain to point to IBM Cloud Internet Services name servers.\n* and [understand the basics of Kubernetes](https://kubernetes.io/docs/tutorials/kubernetes-basics/).\n\n\n\n\n\n\n\n Step 1: Deploy an application to one location \n\nThis tutorial deploys a Kubernetes application to clusters in multiple locations. You will start with one location, Dallas, and then repeat these steps for London.\n\n\n\n Create a Kubernetes cluster \n\nA minimal cluster with one (1) zone, one (1) worker node and the smallest available size (Flavor) is sufficient for this tutorial.\n\nWhen creating the Kubernetes cluster below:\n\n\n\n1. Set Cluster name to my-us-cluster.\n2. Locate in North America and Dallas\n\n\n\nOpen the [Kubernetes clusters](https://cloud.ibm.com/kubernetes/clusters) and click Create cluster. See the documentation referenced below for more details based on the cluster type. Summary:\n\n\n\n* Click Standard tier cluster\n* For Kubernetes on VPC infrastructure see reference documentation [Creating VPC clusters](https://cloud.ibm.com/docs/containers?topic=containers-cluster-create-vpc-gen2&interface=ui).\n\n\n\n* Click Create VPC:\n\n\n\n* Enter a name for the VPC.\n* Chose the same resource group as the cluster.\n* Click Create.\n\n\n\n* Attach a Public Gateway to each of the subnets that you create:\n\n\n\n* Navigate to the [Virtual private clouds](https://cloud.ibm.com/vpc-ext/network/vpcs).\n* Click the previously created VPC used for the cluster.\n* Scroll down to subnets section and click a subnet.\n* In the Public Gateway section, click Detached to change the state to Attached.\n* Click the browser back button to return to the VPC details page.\n* Repeat the previous three steps to attach a public gateway to each subnet.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-multi-region-k8s-cis"}]}
{"task_id": "4c86c8740c3d49e06b7aca9d308119fa<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07578-373434-375500", "score": 23.431107, "text": "\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https://cloud.ibm.com/docs/containers?topic=containers-cs_ovbenefits).\n* Can I get a free cluster?\n\nThe free tier option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https://www.ibm.com/account/reg/us-en/signup?formid=MAIL-wcp).\n\nYou can have 1 free cluster at a time in IBM Cloud Kubernetes Service, and each free cluster expires in 30 days. Free clusters are ideal for testing out Kubernetes deployments and getting familiar with the IBM Cloud Kubernetes Service API, CLI, and console tools. After you are done testing your free cluster, you can [copy your configuration files and redeploy them to a standard cluster](https://cloud.ibm.com/docs/containers?topic=containers-update_appcopy_apps_cluster).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-373408-375474", "score": 23.431107, "text": "\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https://cloud.ibm.com/docs/containers?topic=containers-cs_ovbenefits).\n* Can I get a free cluster?\n\nThe free tier option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https://www.ibm.com/account/reg/us-en/signup?formid=MAIL-wcp).\n\nYou can have 1 free cluster at a time in IBM Cloud Kubernetes Service, and each free cluster expires in 30 days. Free clusters are ideal for testing out Kubernetes deployments and getting familiar with the IBM Cloud Kubernetes Service API, CLI, and console tools. After you are done testing your free cluster, you can [copy your configuration files and redeploy them to a standard cluster](https://cloud.ibm.com/docs/containers?topic=containers-update_appcopy_apps_cluster).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_16729-100027-101783", "score": 23.168161, "text": "\nIn this tutorial, you will learn about IBM Cloud\u00ae Code Engine by deploying a text analysis with Natural Language Understanding application. You will create a Code Engine project, select the project and deploy Code Engine entities - applications and jobs - to the project. You will learn how to bind IBM Cloud services to your Code Engine entities. You will also understand the auto-scaling capability of Code Engine where instances are scaled up or down (to zero) based on incoming workload.\n\nCode Engine Kubernetes service\n\n+2\n\nObject Storage,Natural Language Understanding\n\n\n\n* 2 hours\n* 2023-05-05\n\n\n\n[Best practices for organizing users, teams, applications](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-users-teams-applications)Best practices for organizing users, teams, applications\n\nThis tutorial gives an overview of the concepts available in IBM Cloud for identity and access management and how they can be implemented to support the multiple development stages of an application.\n\nRed Hat OpenShift on IBM Cloud Log Analysis\n\n+3\n\nMonitoring,Kubernetes service,Cloudant\n\n\n\n* 1 hour\n* 2023-06-14\n\n\n\n[Moving a VM based app to Kubernetes](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vm-to-containers-and-kubernetes)Moving a VM based app to Kubernetes\n\nThis tutorial walks you through the process of moving a VM based app to a Kubernetes cluster by using Kubernetes Service. Kubernetes Service delivers powerful tools by combining container and Kubernetes technologies, an intuitive user experience, and built-in security and isolation to automate the deployment, operation, scaling, and monitoring of containerized apps in a cluster of compute hosts.\n\nKubernetes service\n\n\n\n* 2 hours\n* 2023-06-22", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}, {"document_id": "ibmcld_16728-3750-5611", "score": 22.92031, "text": "\nThis tutorial shows how the IBM Log Analysis service can be used to configure and access logs of a Kubernetes application that is deployed on IBM Cloud. You will deploy a Python application to a cluster provisioned on IBM Cloud Kubernetes Service, configure a logging agent, generate different levels of application logs and access worker logs, pod logs or network logs. Then, you will search, filter and visualize those logs through Log Analysis Web UI.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Apply end to end security to a cloud application](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-cloud-e2e-security)Apply end to end security to a cloud application Solution tutorial\n\nThis tutorial walks you through key security services available in the IBM Cloud\u00ae catalog and how to use them together. An application that provides file sharing will put security concepts into practice.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Architecture Framework](https://cloud.ibm.com/docs/architecture-framework)Architecture Framework Solution guide\n\nThe architecture framework can be used as a guide to provide a consistent approach to architect hybrid, multi-cloud end-to-end solutions based on your requirements.\n\n![solution icon](https://cloud.ibm.com/media/docs/images/homepage/magic-wand.svg) [Best practices for organizing users, teams, applications](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-users-teams-applications)Best practices for organizing users, teams, applications Solution tutorial\n\nThis tutorial gives an overview of the concepts available in IBM Cloud for identity and access management and how they can be implemented to support the multiple development stages of an application.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs?tab=solutions"}, {"document_id": "ibmcld_04810-7-1962", "score": 22.90951, "text": "\nDeployment Journey Overview \n\nIBM Cloud Kubernetes Service(IKS) is a managed offering to create your own Kubernetes cluster of compute hosts to deploy and manage containerized apps on IBM Cloud. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management for your apps. Combined with an intuitive user experience, built-in security and isolation, and advanced tools to secure, manage, and monitor your cluster workloads, you can rapidly deliver highly available and secure containerized apps in the public cloud.\n\nWelcome to the Deployment Journey for Cloud Native on IBM Cloud! Use the sidebar on the left to navigate between the journey points.\n\n\n\n Journey Map \n\n![Architecture](https://cloud.ibm.com/docs-content/v1/content/b7b9235ce6abd45b66931867c388cf107d38e15b/cloud-native-journey/kubernetes-on-vpc/images/overview/journey-map.png)\n\n\n\n\n\n Assumptions \n\nThis deployment guide will be assuming the following points. Please note that while your circumstance may not be exactly identical, you will still benefit from the overall journey steps and concepts covered in this guide.\n\n\n\n* You are already familar with the concepts introduced in the \"Tour IBM Cloud\" videos available on the [Getting Started with IBM Cloud](https://cloud.ibm.com/cloud/get-started) page.\n* Access groups will need to be defined so only certain users have the ability to create and manage the VPC network settings (i.e. CIDR ranges, Subnet ACLs rules, etc.).\n* When you create your cluster, you must choose a VPC networking setup so that certain cluster components can communicate with each other and with networks or services outside of the cluster.\n\n\n\n* Worker-to-worker communication: All worker nodes must be able to communicate with each other on the private network through VPC subnets.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-native-journey?topic=cloud-native-journey-cloud-native-overview"}, {"document_id": "ibmcld_13180-23247-24105", "score": 22.849062, "text": "\n* [Best practices solution guide](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-users-teams-applicationsusers-teams-applications) for organizing users, teams and apps.\n* [Analyze logs and monitor application health](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-application-log-analysisapplication-log-analysis).\n* Set up [continuous integration and delivery pipeline](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-continuous-deployment-to-kubernetescontinuous-deployment-to-kubernetes) for containerized apps that run in Kubernetes.\n* Use [multiple clusters across multiple locations](https://cloud.ibm.com/docs/containers?topic=containers-regions-and-zones) for high availability.\n* Re-platform applications to Kubernetes using [Konveyor Move2Kube](https://move2kube.konveyor.io/).", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vm-to-containers-and-kubernetes"}, {"document_id": "ibmcld_01545-23339-24197", "score": 22.849062, "text": "\n* [Best practices solution guide](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-users-teams-applicationsusers-teams-applications) for organizing users, teams and apps.\n* [Analyze logs and monitor application health](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-application-log-analysisapplication-log-analysis).\n* Set up [continuous integration and delivery pipeline](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-continuous-deployment-to-kubernetescontinuous-deployment-to-kubernetes) for containerized apps that run in Kubernetes.\n* Use [multiple clusters across multiple locations](https://cloud.ibm.com/docs/containers?topic=containers-regions-and-zones) for high availability.\n* Re-platform applications to Kubernetes using [Konveyor Move2Kube](https://move2kube.konveyor.io/).", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-vm-to-containers-and-kubernetes"}, {"document_id": "ibmcld_16729-140447-142378", "score": 22.677387, "text": "\nThis tutorial is part 4 of a 4-part tutorial series where you learn IBM Cloud\u00ae DevSecOps best practices by using a complete reference implementation that is available as a service and powered by IBM Cloud\u00ae Continuous Delivery. In part 4 of this tutorial series, you use the toolchain template for continuous compliance (CC) to ensure that your deployed artifacts and their source repositories are always compliant.\n\nKubernetes service Continuous Delivery\n\n+1\n\nDevSecOps\n\n\n\n* 1 hour\n* 2023-05-22\n\n\n\n[Part 3: Set up a Continuous Deployment (CD) toolchain](https://cloud.ibm.com/docs/devsecops?topic=devsecops-tutorial-cd-toolchain)Part 3: Set up a Continuous Deployment (CD) toolchain\n\nThis tutorial is part 3 of a 4-part tutorial series where you learn IBM Cloud\u00ae DevSecOps best practices by using a complete reference implementation that is available as a service and powered by IBM Cloud\u00ae Continuous Delivery. In part 3 of this tutorial series, you use the toolchain template for continuous deployment (CD) with security and compliance-related best practices in DevSecOps.\n\nKubernetes service Continuous Delivery\n\n+1\n\nDevSecOps\n\n\n\n* 1 hour\n* 2023-05-22\n\n\n\n[Part 2: Set up a Continuous Integration (CI) toolchain](https://cloud.ibm.com/docs/devsecops?topic=devsecops-tutorial-ci-toolchain)Part 2: Set up a Continuous Integration (CI) toolchain\n\nThis tutorial is part 2 of a 4-part tutorial series where you learn IBM Cloud\u00ae DevSecOps best practices by using a complete reference implementation that is available as a service and powered by IBM Cloud\u00ae Continuous Delivery. In part 2 of this tutorial series, you use the toolchain template for continuous integration (CI) with security and compliance-related best practices in DevSecOps. It is preconfigured for continuous deployment with inventory integration, change management with Git Repos and Issue Tracking, evidence collection, and deployment to IBM Cloud Kubernetes Service.", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}, {"document_id": "ibmcld_06885-7-1959", "score": 22.58237, "text": "\nPart 2: Set up a Continuous Integration (CI) toolchain \n\nThis tutorial is part 2 of a 4-part tutorial series where you learn IBM Cloud\u00ae DevSecOps best practices by using a complete reference implementation that is available as a service and powered by IBM Cloud\u00ae Continuous Delivery. In part 2 of this tutorial series, you use the toolchain template for continuous integration (CI) with security and compliance-related best practices in DevSecOps. It is preconfigured for continuous deployment with inventory integration, change management with Git Repos and Issue Tracking, evidence collection, and deployment to IBM Cloud Kubernetes Service.\n\n\n\n Before you begin \n\nBefore you begin part 2 of this tutorial series, ensure that you complete the following prerequisites:\n\n\n\n1. Complete [Part 1: Set up prerequisites](https://cloud.ibm.com/docs/devsecops?topic=devsecops-tutorial-cd-devsecops).\n2. View the [Getting started with DevSecOps in IBM Cloud - Part 1](https://video.ibm.com/embed/recorded/130714354) video.\n3. Start the [IBM Cloud console](https://cloud.ibm.com/). The console is the starting point of this tutorial.\n\n\n\n\n\n\n\n Continuous Integration (CI) toolchain introduction \n\nThe CI toolchain implements the following best practices:\n\n\n\n* Runs a static code scanner on the application repositories to detect secrets in the application source code and vulnerable packages that are used as application dependencies\n* Builds a container image on every Git commit, setting a tag based on build number, timestamp, and commit ID for traceability\n* Tests the Dockerfile before the image is created\n* Stores the built image in a private image registry\n* Automatically configures access permissions for target cluster deployment by using API tokens that can be revoked\n* Scans the container image for security vulnerabilities\n* Adds a Docker signature upon successful completion\n* Inserts the built image tag into the deployment manifest automatically", "title": "", "source": "https://cloud.ibm.com/docs/devsecops?topic=devsecops-tutorial-ci-toolchain"}, {"document_id": "ibmcld_06004-3938-5670", "score": 22.483717, "text": "\nInstead, consider [Istio](https://cloud.ibm.com/docs/containers?topic=containers-istio).\n9. Disposability: Design your app to be disposable, with minimal startup, graceful shutdown, and toleration for abrupt process terminations. Remember, containers, pods, and even worker nodes are meant to be disposable, so plan your app accordingly.\n10. Dev-to-prod parity: Set up a [continuous integration](https://www.ibm.com/garage/method/practices/code/practice_continuous_integration) and [continuous delivery](https://www.ibm.com/garage/method/practices/deliver/practice_continuous_delivery) pipeline for your app, with minimal difference between the app in development and the app in prod.\n11. Logs: Treat logs as event streams: the outer or hosting environment processes and routes log files. Important: In IBM Cloud Kubernetes Service, logs are not turned on by default. To enable, see [Configuring log forwarding](https://cloud.ibm.com/docs/containers?topic=containers-health).\n12. Admin processes: Keep any one-time admin scripts with your app and run them as a [Kubernetes Job object](https://kubernetes.io/docs/concepts/workloads/controllers/job/) to ensure that the admin scripts run with the same environment as the app itself. For orchestration of larger packages that you want to run in your Kubernetes clusters, consider using a package manager such as [Helm](https://helm.sh/).\n\n\n\n\n\n\n\n What about serverless apps? \n\nYou can run serverless apps and jobs through the [IBM Cloud Code Engine](https://cloud.ibm.com/docs/codeengine?topic=codeengine-getting-started) service. Code Engine can also build your images for you. Code Engine is designed so that you don't need to interact with the underlying technology it is built upon.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-plan_deploy"}]}
{"task_id": "4c86c8740c3d49e06b7aca9d308119fa<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_05998-3108-5122", "score": 19.089025, "text": "\nKubernetes resources include services, deployments, and pods. For more information, see [Service architecture](https://cloud.ibm.com/docs/containers?topic=containers-service-arch).\n\nNamespace\n: Kubernetes namespaces are a way to divide your cluster resources into separate areas that you can deploy apps and restrict access to, such as if you want to share the cluster with multiple teams. For example, system resources that are configured for you are kept in separate namespaces like kube-system or ibm-system. If you don't designate a namespace when you create a Kubernetes resource, the resource is automatically created in the default namespace. For more information, see the [Kubernetes documentation](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/).\n\nService\n: A service is a Kubernetes resource that groups a set of pods and provides network connectivity to these pods without exposing the actual private IP address of each pod. You can use a service to make your app available within your cluster or to the public internet. For more information, see the [Kubernetes documentation](https://kubernetes.io/docs/concepts/services-networking/service/).\n\nDeployment\n: A deployment is a Kubernetes resource where you might specify information about other resources or capabilities that are required to run your app, such as services, persistent storage, or annotations. You document a deployment in a configuration YAML file, and then apply it to the cluster. The Kubernetes master configures the resources and deploys containers into pods on the worker nodes with available capacity.\n: Define update strategies for your app, including the number of pods that you want to add during a rolling update and the number of pods that can be unavailable at a time. When you perform a rolling update, the deployment checks whether the update is working and stops the rollout when failures are detected.\n: A deployment is just one type of workload controller that you can use to manage pods.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-overview"}, {"document_id": "ibmcld_10495-3085-5099", "score": 19.089025, "text": "\nKubernetes resources include services, deployments, and pods. For more information, see [Service architecture](https://cloud.ibm.com/docs/containers?topic=containers-service-arch).\n\nNamespace\n: Kubernetes namespaces are a way to divide your cluster resources into separate areas that you can deploy apps and restrict access to, such as if you want to share the cluster with multiple teams. For example, system resources that are configured for you are kept in separate namespaces like kube-system or ibm-system. If you don't designate a namespace when you create a Kubernetes resource, the resource is automatically created in the default namespace. For more information, see the [Kubernetes documentation](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/).\n\nService\n: A service is a Kubernetes resource that groups a set of pods and provides network connectivity to these pods without exposing the actual private IP address of each pod. You can use a service to make your app available within your cluster or to the public internet. For more information, see the [Kubernetes documentation](https://kubernetes.io/docs/concepts/services-networking/service/).\n\nDeployment\n: A deployment is a Kubernetes resource where you might specify information about other resources or capabilities that are required to run your app, such as services, persistent storage, or annotations. You document a deployment in a configuration YAML file, and then apply it to the cluster. The Kubernetes master configures the resources and deploys containers into pods on the worker nodes with available capacity.\n: Define update strategies for your app, including the number of pods that you want to add during a rolling update and the number of pods that can be unavailable at a time. When you perform a rolling update, the deployment checks whether the update is working and stops the rollout when failures are detected.\n: A deployment is just one type of workload controller that you can use to manage pods.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-roks-overview"}, {"document_id": "ibmcld_05777-7-1924", "score": 18.921972, "text": "\nFAQs \n\nReview frequently asked questions (FAQs) for using IBM Cloud\u00ae Kubernetes Service.\n\n\n\n What is Kubernetes? \n\nKubernetes is an open source platform for managing containerized workloads and services across multiple hosts, and offers managements tools for deploying, automating, monitoring, and scaling containerized apps with minimal to no manual intervention. All containers that make up your microservice are grouped into pods, a logical unit to ensure easy management and discovery. These pods run on compute hosts that are managed in a Kubernetes cluster that is portable, extensible, and self-healing in case of failures.\n\nFor more information about Kubernetes, see the [Kubernetes documentation](https://kubernetes.io/docs/home/?path=users&persona=app-developer<=vel=foundational).\n\n\n\n\n\n How does IBM Cloud Kubernetes Service work? \n\nWith IBM Cloud Kubernetes Service, you can create your own Kubernetes cluster to deploy and manage containerized apps on IBM Cloud. Your containerized apps are hosted on IBM Cloud infrastructure compute hosts that are called worker nodes. You can choose to provision your compute hosts as [virtual machines](https://cloud.ibm.com/docs/containers?topic=containers-planning_worker_nodesvm) with shared or dedicated resources, or as [bare metal machines](https://cloud.ibm.com/docs/containers?topic=containers-planning_worker_nodesbm) that can be optimized for GPU and software-defined storage (SDS) usage. Your worker nodes are controlled by a highly available Kubernetes master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https://cloud.ibm.com/docs/containers?topic=containers-service-arch).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-faqs"}, {"document_id": "ibmcld_03824-7-1809", "score": 18.869156, "text": "\nKubernetes \n\nThe IBM Blockchain Platform allows you to provision blockchain components into your Kubernetes cluster. Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.\n\nKubernetes provides a container-centric management environment. It orchestrates computing, networking, and storage infrastructure on behalf of user workloads. This provides much of the simplicity of Platform as a Service (PaaS) with the flexibility of Infrastructure as a Service (IaaS), and enables portability across infrastructure providers.\n\nThe following diagram explains the architecture of Kubernetes. For more explanation about nodes, containers, and pod, see the [Key Kubernetes objects](https://cloud.ibm.com/docs/blockchain/reference?topic=blockchain-k8s-overviewk8s-overview-key-obj) section below.\n\nZoom\n\n![Kubernetes architecture diagram](https://cloud.ibm.com/docs-content/v1/content/c5288bed34c3820e3a5251d820ee91adcd2591a3/blockchain/images/k8s-archi-diagram.svg)\n\nFigure 1. Kubernetes architecture diagram\n\n\n\n Key Kubernetes objects \n\n\n\n* Cluster\n\nA set of machines, called nodes, that run containerized applications managed by Kubernetes. A cluster has several worker nodes and at least one master node.\n* Node\n\nA node is a worker machine in Kubernetes. A node may be a VM or physical machine, depending on the cluster. Each node contains the services necessary to run pods and is managed by the master components. The services on a node include the container runtime, kubelet and kube-proxy. For more information, see the [Kubernetes Node section](https://kubernetes.io/docs/concepts/architecture/nodes/) in the Kubernetes documentation.\n* Container\n\nA lightweight and portable executable image that contains software and all of its dependencies.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain/reference?topic=blockchain-k8s-overview"}, {"document_id": "ibmcld_04085-7-1799", "score": 18.816372, "text": "\nKubernetes \n\nThe IBM Blockchain Platform allows you to provision blockchain components into your Kubernetes cluster. Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.\n\nKubernetes provides a container-centric management environment. It orchestrates computing, networking, and storage infrastructure on behalf of user workloads. This provides much of the simplicity of Platform as a Service (PaaS) with the flexibility of Infrastructure as a Service (IaaS), and enables portability across infrastructure providers.\n\nThe following diagram explains the architecture of Kubernetes. For more explanation about nodes, containers, and pod, see the [Key Kubernetes objects](https://cloud.ibm.com/docs/blockchain?topic=blockchain-k8s-overviewk8s-overview-key-obj) section below.\n\nZoom\n\n![Kubernetes architecture diagram](https://cloud.ibm.com/docs-content/v1/content/c5288bed34c3820e3a5251d820ee91adcd2591a3/blockchain/images/k8s-archi-diagram.svg)\n\nFigure 1. Kubernetes architecture diagram\n\n\n\n Key Kubernetes objects \n\n\n\n* Cluster\n\nA set of machines, called nodes, that run containerized applications managed by Kubernetes. A cluster has several worker nodes and at least one master node.\n* Node\n\nA node is a worker machine in Kubernetes. A node may be a VM or physical machine, depending on the cluster. Each node contains the services necessary to run pods and is managed by the master components. The services on a node include the container runtime, kubelet and kube-proxy. For more information, see the [Kubernetes Node section](https://kubernetes.io/docs/concepts/architecture/nodes/) in the Kubernetes documentation.\n* Container\n\nA lightweight and portable executable image that contains software and all of its dependencies.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-k8s-overview"}, {"document_id": "ibmcld_10495-1595-3474", "score": 18.683027, "text": "\nThe open source project, Kubernetes, combines running a containerized infrastructure with production workloads, open source contributions, and Docker container management tools. The Kubernetes infrastructure provides an isolated and secure app platform for managing containers that is portable, extensible, and self-healing in case of a failover. For more information, see [What is Kubernetes?](https://www.ibm.com/topics/kubernetes).\n\nLearn more about the key concepts of Kubernetes as illustrated in the following image.\n\nZoom\n\n![Example deployment and namespaces](https://cloud.ibm.com/docs-content/v1/content/bce0f0917a9eea684d1b4b704ac6343a1f65f446/openshift/images/k8-namespace.svg)\n\nFigure 2. A description of key concepts for Kubernetes\n\nAccount\n: Your account refers to your IBM Cloud account.\n\nCluster, worker pool, and worker node\n: A Kubernetes cluster consists of a master and one or more compute hosts that are called worker nodes. Worker nodes are organized into worker pools of the same flavor, or profile of CPU, memory, operating system, attached disks, and other properties. The worker nodes correspond to the Kubernetes Node resource, and are managed by a Kubernetes master that centrally controls and monitors all Kubernetes resources in the cluster. So when you deploy the resources for a containerized app, the Kubernetes master decides which worker node to deploy those resources on, accounting for the deployment requirements and available capacity in the cluster. Kubernetes resources include services, deployments, and pods. For more information, see [Service architecture](https://cloud.ibm.com/docs/containers?topic=containers-service-arch).\n\nNamespace\n: Kubernetes namespaces are a way to divide your cluster resources into separate areas that you can deploy apps and restrict access to, such as if you want to share the cluster with multiple teams.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-roks-overview"}, {"document_id": "ibmcld_01545-6013-8003", "score": 18.606403, "text": "\n[Kubernetes](https://kubernetes.io/) is a container orchestrator to manage the lifecycle of containerized apps in a cluster of worker nodes. Your apps might need many other resources to run, such as volumes, networks, and secrets which will help you connect to other cloud services, and secure keys. Kubernetes helps you to add these resources to your app. The key paradigm of Kubernetes is its declarative model. The user provides the desired state and Kubernetes attempts to conform to, and then maintains the described state.\n\nThis [self-paced workshop](https://ibm.github.io/kube101/) can help you to get your first hands-on experience with Kubernetes. Additionally, check out the Kubernetes [concepts](https://kubernetes.io/docs/concepts/) documentation page to learn more about the concepts of Kubernetes.\n\n\n\n\n\n\n\n What IBM's doing for you \n\nBy using Kubernetes clusters with IBM Cloud Kubernetes Service, you get the following benefits:\n\n\n\n* Multiple data centers where you can deploy your clusters.\n* Support for ingress and load balancer networking options.\n* Dynamic persistent volume support.\n* Highly available, IBM-managed Kubernetes masters.\n\n\n\n\n\n\n\n\n\n Sizing clusters \n\nAs you design your cluster architecture, you want to balance costs against availability, reliability, complexity, and recovery. Kubernetes clusters in IBM Cloud Kubernetes Service provide architectural options based on the needs of your apps. With a bit of planning, you can get the most out of your cloud resources without over-architecting or over-spending. Even if you over or underestimate, you can easily scale up or down your cluster, by changing either the number or size of worker nodes.\n\nTo run a production app in the cloud by using Kubernetes, consider the following items:\n\n\n\n1. Do you expect traffic from a specific geographic location? If yes, select the location that is physically closest to you for best performance.\n2. How many replicas of your cluster do you want for higher availability?", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-vm-to-containers-and-kubernetes"}, {"document_id": "ibmcld_13180-5921-7911", "score": 18.606403, "text": "\n[Kubernetes](https://kubernetes.io/) is a container orchestrator to manage the lifecycle of containerized apps in a cluster of worker nodes. Your apps might need many other resources to run, such as volumes, networks, and secrets which will help you connect to other cloud services, and secure keys. Kubernetes helps you to add these resources to your app. The key paradigm of Kubernetes is its declarative model. The user provides the desired state and Kubernetes attempts to conform to, and then maintains the described state.\n\nThis [self-paced workshop](https://ibm.github.io/kube101/) can help you to get your first hands-on experience with Kubernetes. Additionally, check out the Kubernetes [concepts](https://kubernetes.io/docs/concepts/) documentation page to learn more about the concepts of Kubernetes.\n\n\n\n\n\n\n\n What IBM's doing for you \n\nBy using Kubernetes clusters with IBM Cloud Kubernetes Service, you get the following benefits:\n\n\n\n* Multiple data centers where you can deploy your clusters.\n* Support for ingress and load balancer networking options.\n* Dynamic persistent volume support.\n* Highly available, IBM-managed Kubernetes masters.\n\n\n\n\n\n\n\n\n\n Sizing clusters \n\nAs you design your cluster architecture, you want to balance costs against availability, reliability, complexity, and recovery. Kubernetes clusters in IBM Cloud Kubernetes Service provide architectural options based on the needs of your apps. With a bit of planning, you can get the most out of your cloud resources without over-architecting or over-spending. Even if you over or underestimate, you can easily scale up or down your cluster, by changing either the number or size of worker nodes.\n\nTo run a production app in the cloud by using Kubernetes, consider the following items:\n\n\n\n1. Do you expect traffic from a specific geographic location? If yes, select the location that is physically closest to you for best performance.\n2. How many replicas of your cluster do you want for higher availability?", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vm-to-containers-and-kubernetes"}, {"document_id": "ibmcld_05998-1617-3497", "score": 18.536205, "text": "\nThe open source project, Kubernetes, combines running a containerized infrastructure with production workloads, open source contributions, and Docker container management tools. The Kubernetes infrastructure provides an isolated and secure app platform for managing containers that is portable, extensible, and self-healing in case of a failover. For more information, see [What is Kubernetes?](https://www.ibm.com/topics/kubernetes).\n\nLearn more about the key concepts of Kubernetes as illustrated in the following image.\n\nZoom\n\n![Example deployment and namespaces](https://cloud.ibm.com/docs-content/v1/content/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7/containers/images/k8-namespace.svg)\n\nFigure 2. A description of key concepts for Kubernetes\n\nAccount\n: Your account refers to your IBM Cloud account.\n\nCluster, worker pool, and worker node\n: A Kubernetes cluster consists of a master and one or more compute hosts that are called worker nodes. Worker nodes are organized into worker pools of the same flavor, or profile of CPU, memory, operating system, attached disks, and other properties. The worker nodes correspond to the Kubernetes Node resource, and are managed by a Kubernetes master that centrally controls and monitors all Kubernetes resources in the cluster. So when you deploy the resources for a containerized app, the Kubernetes master decides which worker node to deploy those resources on, accounting for the deployment requirements and available capacity in the cluster. Kubernetes resources include services, deployments, and pods. For more information, see [Service architecture](https://cloud.ibm.com/docs/containers?topic=containers-service-arch).\n\nNamespace\n: Kubernetes namespaces are a way to divide your cluster resources into separate areas that you can deploy apps and restrict access to, such as if you want to share the cluster with multiple teams.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-overview"}, {"document_id": "ibmcld_13149-2574-4423", "score": 18.05985, "text": "\nKubernetes Service delivers powerful tools by combining Docker and Kubernetes technologies, an intuitive user experience, and built-in security and isolation to automate the deployment, operation, scaling, and monitoring of containerized apps in a cluster of compute hosts.\n\nA minimal cluster with one (1) zone, one (1) worker node and the smallest available size (Flavor) is sufficient for this tutorial.\n\nOpen the [Kubernetes clusters](https://cloud.ibm.com/kubernetes/clusters) and click Create cluster. See the documentation referenced below for more details based on the cluster type. Summary:\n\n\n\n* Click Standard tier cluster\n* For Kubernetes on VPC infrastructure see reference documentation[Creating VPC clusters](https://cloud.ibm.com/docs/containers?topic=containers-cluster-create-vpc-gen2&interface=ui).\n\n\n\n* Click Create VPC:\n\n\n\n* Enter a name for the VPC.\n* Chose the same resource group as the cluster.\n* Click Create.\n\n\n\n* Attach a Public Gateway to each of the subnets that you create:\n\n\n\n* Navigate to the [Virtual private clouds](https://cloud.ibm.com/vpc-ext/network/vpcs).\n* Click the previously created VPC used for the cluster.\n* Scroll down to subnets section and click a subnet.\n* In the Public Gateway section, click Detached to change the state to Attached.\n* Click the browser back button to return to the VPC details page.\n* Repeat the previous three steps to attach a public gateway to each subnet.\n\n\n\n\n\n* For Kubernetes on Classic infrastructure see reference documentation [Creating classic cluster](https://cloud.ibm.com/docs/containers?topic=containers-cluster-create-classic&interface=ui).\n* Choose a resource group.\n* Uncheck all zones except one.\n* Scale down to 1 Worker nodes per zone.\n* Choose the smallest Worker Pool flavor.\n* Enter a Cluster name.\n* Click Create.\n\n\n\n\n\n\n\n Step 2: Clone a sample application", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-scalable-webapp-kubernetes"}]}
{"task_id": "4c86c8740c3d49e06b7aca9d308119fa<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07578-373434-375500", "score": 23.57252, "text": "\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https://cloud.ibm.com/docs/containers?topic=containers-cs_ovbenefits).\n* Can I get a free cluster?\n\nThe free tier option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https://www.ibm.com/account/reg/us-en/signup?formid=MAIL-wcp).\n\nYou can have 1 free cluster at a time in IBM Cloud Kubernetes Service, and each free cluster expires in 30 days. Free clusters are ideal for testing out Kubernetes deployments and getting familiar with the IBM Cloud Kubernetes Service API, CLI, and console tools. After you are done testing your free cluster, you can [copy your configuration files and redeploy them to a standard cluster](https://cloud.ibm.com/docs/containers?topic=containers-update_appcopy_apps_cluster).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-373408-375474", "score": 23.57252, "text": "\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https://cloud.ibm.com/docs/containers?topic=containers-cs_ovbenefits).\n* Can I get a free cluster?\n\nThe free tier option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https://www.ibm.com/account/reg/us-en/signup?formid=MAIL-wcp).\n\nYou can have 1 free cluster at a time in IBM Cloud Kubernetes Service, and each free cluster expires in 30 days. Free clusters are ideal for testing out Kubernetes deployments and getting familiar with the IBM Cloud Kubernetes Service API, CLI, and console tools. After you are done testing your free cluster, you can [copy your configuration files and redeploy them to a standard cluster](https://cloud.ibm.com/docs/containers?topic=containers-update_appcopy_apps_cluster).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_05722-7-2498", "score": 23.562374, "text": "\nFinancial services use cases for IBM Cloud \n\nThese use cases highlight how workloads on IBM Cloud\u00ae Kubernetes Service can take advantage of high availability, high-performance compute, easy spin-up of clusters for faster development, and AI from IBM Watson\u00ae.\n\n\n\n Mortgage company trims costs and accelerates regulatory compliance \n\nA Risk Management VP for a residential mortgage company processes 70 million records a day, but the on-premises system was slow and also inaccurate. IT expenses soared because hardware quickly went out of date and wasn't utilized fully. While they waited for hardware provisioning, their regulatory compliance slowed.\n\n\n\n Context \n\nTo improve risk analysis, the company looked to IBM Cloud Kubernetes Service and IBM Cloud Analytic services to reduce costs, increase worldwide availability, and ultimately accelerate regulatory compliance. With IBM Cloud Kubernetes Service in multiple regions, their analysis apps can be containerized and deployed across the globe, improving availability and addressing local regulations. Those deployments are accelerated with familiar open source tools, already part of IBM Cloud Kubernetes Service.\n\nThey started by containerizing the analysis apps and putting them in the cloud. In a flash, their hardware headaches went away. They were able to easily design Kubernetes clusters to fit their high-performance CPU, RAM, storage, and security needs. And when their analysis apps change, they can add or shrink compute without huge hardware investments. With the IBM Cloud Kubernetes Service horizontal scaling, their apps scale with the growing number of records, resulting in faster regulatory reports. IBM Cloud Kubernetes Service provides elastic compute resources around the world that are secure and capable.\n\nNow those apps receive high-volume data from a data warehouse on IBM Cloudant. Cloud-based storage in IBM Cloudant ensures higher availability than when it was locked in an on-premises system. Since availability is essential, the apps are deployed across global data centers: for DR and for latency too.\n\nThey also accelerated their risk analysis and compliance. Their predictive and risk analytics functions, such as Monte Carlo calculations, are now constantly updated through iterative agile deployments. Container orchestration is handled by a managed Kubernetes so that operations costs are reduced too. Ultimately risk analysis for mortgages is more responsive to the fast-paced changes in the market.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_uc_finance"}, {"document_id": "ibmcld_05724-7-2333", "score": 23.431002, "text": "\nHealthcare use cases for IBM Cloud \n\nThese use cases highlight how workloads on IBM Cloud\u00ae Kubernetes Service benefit from the public cloud. They have secure compute on isolated bare metal, easy spin-up of clusters for faster development, migration from virtual machines, and data sharing in cloud databases.\n\n\n\n Healthcare provider migrates workloads from inefficient VMs to Ops-friendly containers for reporting and patient systems \n\nAn IT Exec for a healthcare provider has business reporting and patient systems on-premises. Those systems go through slow enhancement cycles, which leads to stagnant patient service levels.\n\nTo improve patient service, the provider looked to IBM Cloud Kubernetes Service and IBM Cloud\u00ae Continuous Delivery to reduce IT expenses and accelerate development, all on a secure platform. The provider\u2019s high-use SaaS systems, which held both patient record systems and business report apps, needed updates frequently. Yet the on-premises environment hindered agile development. The provider also wanted to counteract increasing labor costs and a decreasing budget.\n\nThey started by containerizing their SaaS systems and putting them in the cloud. From that first step, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the SaaS apps, they easily designed Kubernetes clusters to fit their CPU, RAM, and storage needs. Another factor for decreased staff costs is that IBM manages Kubernetes, so the provider can focus on delivering better customer service.\n\nAccelerated development is a key win for the IT Exec. With the move to public cloud, Developers can experiment easily with Node.js SDK, pushing changes to Development and Test systems, scaled out on separate clusters. Those pushes were automated with open toolchains and IBM Cloud\u00ae Continuous Delivery. Updates to the SaaS system no longer languished in slow, error-prone build processes. The Developers can deliver incremental updates to their users, daily or even more frequently. Also, logging and monitoring for the SaaS systems, especially how the patient front-end and back-end reports interact, rapidly integrate into the system. Developers don\u2019t waste time building complex logging systems, just to be able to troubleshoot live systems.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_uc_health"}, {"document_id": "ibmcld_05726-7-2150", "score": 23.232883, "text": "\nRetail use cases for IBM Cloud \n\nThese use cases highlight how workloads on IBM Cloud\u00ae Kubernetes Service can take advantage of analytics for market insights, multi-region deployments across the globe, and inventory management with IBM\u00ae Event Streams for IBM Cloud\u00ae and object storage.\n\n\n\n Brick-and-mortar retailer shares data, by using APIs with global business partners to drive omnichannel sales \n\nA Line-of-Business (LOB) Exec needs to increase sales channels, but the retail system is closed off in an on-premises data center. The competition has global business partners to cross-sell and up sell permutations of their goods: across brick-and-mortar and online sites.\n\nIBM Cloud Kubernetes Service provides a public-cloud ecosystem, where containers enable new business partners and other external players to co-develop apps and data, through APIs. Now that the retail system is on the public cloud, APIs also streamline data sharing and jump-start new app development. App deployments increase when Developers experiment easily, pushing changes to Development and Test systems quickly with toolchains.\n\nIBM Cloud Kubernetes Service and key technologies:\n\n\n\n* [Clusters that fit varied CPU, RAM, storage needs](https://cloud.ibm.com/docs/containers?topic=containers-planning_worker_nodesplanning_worker_nodes)\n* [IBM Cloud\u00ae Object Storage to persist and sync data across apps](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-getting-started-cloud-object-storage)\n* [DevOps native tools, including open toolchains in IBM Cloud\u00ae Continuous Delivery](https://www.ibm.com/cloud/architecture/toolchains/)\n\n\n\n\n\n Context \n\n\n\n* The retailer is faced with strong competitive pressures. First, they need to mask the complexity of crossing into new products and new channels. For example, they need to expand product sophistication. At the same time, it needs to be simpler for their customers to jump across brands.\n* That ability to jump brand means that the retail ecosystem requires connectivity to business partners. Then, the cloud can bring new value from business partners, customers, and other external players.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_uc_retail"}, {"document_id": "ibmcld_06128-7-1993", "score": 22.914305, "text": "\nMoving your environment to IBM Cloud Kubernetes Service \n\nWith IBM Cloud\u00ae Kubernetes Service, you can quickly and securely deploy container workloads for your apps in production. Learn more so that when you plan your cluster strategy, you optimize your setup to make the most of [Kubernetes](https://kubernetes.io/) automated deploying, scaling, and orchestration management capabilities.\n\n\n\n Moving your workloads to the IBM Cloud \n\nYou have lots of reasons to move your workloads to IBM Cloud: reducing total cost of ownership, increasing high availability for your apps in a secure and compliant environment, scaling up and down in respond to your user demand, and many more. IBM Cloud Kubernetes Service combines container technology with open source tools, such as Kubernetes so that you can build a cloud-native app that can migrate across different cloud environments, avoiding vendor lock-in.\n\nBut how do you get to the cloud? What are your options along the way? And how do you manage your workloads after you get there?\n\nUse this page to learn some strategies for your Kubernetes deployments on IBM Cloud Kubernetes Service. And engage with our team on [Slack](https://ibm-cloud-success.slack.com).\n\nNot on slack yet? [!Request an invite](https://cloud.ibm.com/kubernetes/slack)\n\n\n\n What can I move to the IBM Cloud? \n\nWith IBM Cloud, you have flexibility to create Kubernetes clusters in [off-premises, on-premises, or hybrid cloud environments](https://cloud.ibm.com/docs/containers?topic=containers-cs_ovdifferentiation). The following table provides some examples of what types of workloads that users typically move to the various types of clouds. You might also choose a hybrid approach where you have clusters that run in both environments.\n\n\n\nIBM Cloud implementations support your workloads\n\n Workload Kubernetes Service off-prem on-prem \n\n DevOps enablement tools Yes \n Developing and testing apps Yes \n Apps have major shifts in demand and need to scale rapidly Yes", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-strategy"}, {"document_id": "ibmcld_05725-7-1790", "score": 22.870352, "text": "\nOverview of use cases \n\nVarious use cases show the strengths of IBM Cloud Kubernetes Service and IBM Cloud services when used together. These stories highlight several industries as well as types of workloads. Even though each use case is presented through the lens of a particular industry, these workloads are typical across various industries. You see workload themes, such as:\n\n\n\n* AI and machine learning\n* Data and storage\n* DevOps\n* Identity management\n\n\n\nFinancial services\n: Trim IT costs and [accelerate regulatory compliance](https://cloud.ibm.com/docs/containers?topic=containers-cs_uc_financeuc_mortgage)\n: Streamline developer productivity to deploy AI tools to partners [4 times faster](https://cloud.ibm.com/docs/containers?topic=containers-cs_uc_financeuc_payment_tech).\n\nGovernment\n: Secure the exchange of data, [connecting public and private organizations](https://cloud.ibm.com/docs/containers?topic=containers-cs_uc_govuc_port).\n: Improve collaboration velocity with community Developers, [combining public-private data](https://cloud.ibm.com/docs/containers?topic=containers-cs_uc_govuc_data_mashup).\n\nHealthcare\n: Migrate workloads from inefficient VMs to [easily operated containers for patient systems](https://cloud.ibm.com/docs/containers?topic=containers-cs_uc_healthuc_migrate).\n: Securely host sensitive data while you [grow research with partners](https://cloud.ibm.com/docs/containers?topic=containers-cs_uc_healthuc_research).\n\nRetail\n: Share data via APIs with global business partners to [drive omnichannel sales](https://cloud.ibm.com/docs/containers?topic=containers-cs_uc_retailuc_data-share).\n: Optimize inventory expenses with [digital insights to sales behavior](https://cloud.ibm.com/docs/containers?topic=containers-cs_uc_retailuc_grocer).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_uc_intro"}, {"document_id": "ibmcld_05777-7-1924", "score": 22.801174, "text": "\nFAQs \n\nReview frequently asked questions (FAQs) for using IBM Cloud\u00ae Kubernetes Service.\n\n\n\n What is Kubernetes? \n\nKubernetes is an open source platform for managing containerized workloads and services across multiple hosts, and offers managements tools for deploying, automating, monitoring, and scaling containerized apps with minimal to no manual intervention. All containers that make up your microservice are grouped into pods, a logical unit to ensure easy management and discovery. These pods run on compute hosts that are managed in a Kubernetes cluster that is portable, extensible, and self-healing in case of failures.\n\nFor more information about Kubernetes, see the [Kubernetes documentation](https://kubernetes.io/docs/home/?path=users&persona=app-developer<=vel=foundational).\n\n\n\n\n\n How does IBM Cloud Kubernetes Service work? \n\nWith IBM Cloud Kubernetes Service, you can create your own Kubernetes cluster to deploy and manage containerized apps on IBM Cloud. Your containerized apps are hosted on IBM Cloud infrastructure compute hosts that are called worker nodes. You can choose to provision your compute hosts as [virtual machines](https://cloud.ibm.com/docs/containers?topic=containers-planning_worker_nodesvm) with shared or dedicated resources, or as [bare metal machines](https://cloud.ibm.com/docs/containers?topic=containers-planning_worker_nodesbm) that can be optimized for GPU and software-defined storage (SDS) usage. Your worker nodes are controlled by a highly available Kubernetes master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https://cloud.ibm.com/docs/containers?topic=containers-service-arch).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-faqs"}, {"document_id": "ibmcld_05723-3429-5611", "score": 22.780315, "text": "\nThus, they chose IBM Cloud Kubernetes Service because IBM simplifies infrastructure management.\n\n\n\n* Managing Kubernetes master, IaaS, and operational components, such as Ingress and storage\n* Monitoring health and recovery for worker nodes\n* Providing global compute, so Developers don\u2019t have to stand up infrastructure in worldwide regions where they need workloads and data to be located\n\n\n\nMoving compute workloads into the IBM Cloud isn't enough though. The government needs to go through a method transformation as well. By adopting the practices of the IBM Garage Method, the provider can implement an agile and iterative delivery process that supports modern DevOps practices like Continuous Integration and Delivery (CI/CD).\n\nMuch of the CI/CD process itself is automated with IBM Cloud\u00ae Continuous Delivery in the cloud. The provider can define workflow toolchains to prepare container images, check for vulnerabilities, and deploy them to the Kubernetes cluster.\n\nCompute, storage, and API tools run in the public cloud with secure access to and from on-premises data sources.\n\nTechnical solution:\n\n\n\n* IBM Cloud Kubernetes Service\n* IBM Cloud Object Storage and IBM Cloudant\n* IBM\u00ae API Connect\n* IBM Secure Gateway\n* IBM Cloud\u00ae Continuous Delivery\n\n\n\n\n\n Step 1: Store data in the cloud \n\n\n\n* IBM Cloud Object Storage provides historical data storage, accessible to all on the public cloud.\n* Use IBM Cloudant with developer-provided keys to cache data in the cloud.\n* Use IBM Secure Gateway to maintain secure connections to existing on-premises databases.\n\n\n\n\n\n\n\n Step 2: Provide access to data with APIs \n\n\n\n* Use IBM\u00ae API Connect for the API economy platform. APIs allow the public and private sectors to combine data into their apps.\n* Create clusters for public-private apps, which are driven by the APIs.\n* Structure apps into a set of cooperative microservices that run within IBM Cloud Kubernetes Service, which is based on functional areas of apps and their dependencies.\n* Deploy the apps to containers that run in IBM Cloud Kubernetes Service. Built-in HA tools in IBM Cloud Kubernetes Service balance the workloads, including self-healing and load balancing.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_uc_gov"}, {"document_id": "ibmcld_05726-3592-5935", "score": 22.700224, "text": "\n* DEVELOPMENT ENVIRONMENT: Kubernetes clusters for Dev, Test, and Production systems increase collaboration and data sharing among the retailer and its business partners\n\n\n\nFor the retailer to work with global business partners, the inventory APIs required changes to fit each region\u2019s language and market preferences. IBM Cloud Kubernetes Service offers coverage in multiple regions, including North America, Europe, Asia, and Australia, so that the APIs reflected the needs of each country and ensured low latency for API calls.\n\nAnother requirement is that inventory data must be shareable with the business partners and customers of the company. With the inventory APIs, Developers can surface information in apps, such as mobile inventory apps or web e-commerce solutions. The Developers are also busy with building and maintaining the primary e-commerce site. In short, they need to focus on coding instead of managing the infrastructure.\n\nThus, they chose IBM Cloud Kubernetes Service because IBM simplifies infrastructure management.\n\n\n\n* Managing Kubernetes master, IaaS, and operational components, such as Ingress and storage\n* Monitoring health and recovery for worker nodes\n* Providing global compute, so Developers own hardware infrastructure in regions where they need workloads and data to reside\n\n\n\nMoreover logging and monitoring for the API microservices, especially how they pull personalized data out of back-end systems, easily integrates with IBM Cloud Kubernetes Service. Developers don\u2019t waste time building complex logging systems, just to be able to troubleshoot live systems.\n\nIBM\u00ae Event Streams for IBM Cloud\u00ae acts as the just-in-time events platform to bring in the rapidly changing information from the business partners\u2019 inventory systems to IBM Cloud\u00ae Object Storage.\n\nCompute, storage, and event management that run in public cloud with access to retail inventories across the globe, as needed\n\nTechnical solution:\n\n\n\n* IBM Cloud Kubernetes Service\n* IBM\u00ae Event Streams for IBM Cloud\u00ae\n* IBM Cloud\u00ae Object Storage\n* IBM Cloud\u00ae Continuous Delivery\n* IBM Cloud Logging and Monitoring\n* App ID\n\n\n\n\n\n Step 1: Containerize apps by using microservices \n\n\n\n* Structure apps into a set of cooperative microservices that run within IBM Cloud Kubernetes Service based on functional areas of the app and its dependencies.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_uc_retail"}]}
{"task_id": "4c86c8740c3d49e06b7aca9d308119fa<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10354-5992-7531", "score": 22.153772, "text": "\nSecurity strategy: Start by reviewing all [security options](https://cloud.ibm.com/docs/openshift?topic=openshift-security) that are available for your cluster.\n2. Network security:\n\n\n\n* Classic clusters:\n\n\n\n1. To isolate networking workloads, you can restrict network traffic to [edge worker nodes](https://cloud.ibm.com/docs/openshift?topic=openshift-edge).\n2. Set up a firewall by using a [gateway appliance](https://cloud.ibm.com/docs/openshift?topic=openshift-firewallvyatta_firewall) or [Calico network policies](https://cloud.ibm.com/docs/openshift?topic=openshift-network_policies).\n\n\n\n* VPC clusters: Control traffic to and from your cluster with [VPC security groups](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc-network-policy).\n\n\n\n3. Workload security:\n\n\n\n1. [Encrypt sensitive information](https://cloud.ibm.com/docs/openshift?topic=openshift-encryption) in the cluster, such as the master's local disk and secrets.\n2. Set up a [private image registry](https://cloud.ibm.com/docs/openshift?topic=openshift-securityimages_registry) for your developers, such as the one provided by Container Registry, to control access to the registry and the image content that can be pushed.\n3. [Set pod priority](https://cloud.ibm.com/docs/openshift?topic=openshift-pod_priority) to indicate the relative priority of the pods that make up your cluster's workload.\n4. Authorize who can create and update pods by configuring [security context constraints (SCCs)](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_scc).", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-learning-path-admin"}, {"document_id": "ibmcld_06298-32725-34830", "score": 21.723803, "text": "\nThis option provides one of the most secure configurations for the VPN connection because no connections from the remote network back into the cluster are permitted.\n\n\n\n* This setting requires that all data flow over the VPN connection must be outbound regardless of whether the VPN connection is established from the cluster or from the remote network.\n* If you install strongSwan into a single-zone cluster, you must set local.subnet to only one IP address as a /32 subnet. If you install strongSwan in a multizone cluster, you can set local.subnet to the %zoneSubnet variable, and use the local.zoneSubnet to specify an IP address as a /32 subnet for each zone of the cluster.\n\n\n\n4. Optional for version 2.2.0 and later strongSwan Helm charts: Enable the strongSwan service to route incoming requests from the remote network to a service that exists outside of the cluster by using the localNonClusterSubnet setting.\n\n\n\n* The non-cluster service must exist on the same private network or on a private network that is reachable by the worker nodes.\n* The non-cluster worker node can't initiate traffic to the remote network through the VPN connection, but the non-cluster node can be the target of incoming requests from the remote network.\n* You must list the CIDRs of the non-cluster subnets in the local.subnet setting.\n\n\n\n\n\n\n\n\n\n Step 5: Access remote network resources over the VPN connection \n\nDetermine which remote network resources must be accessible by the cluster over the VPN connection.\n\n\n\n1. Add the CIDRs of one or more on-premises private subnets to the remote.subnet setting. Note: If ipsec.keyexchange is set to ikev1, you can specify only one subnet.\n2. Optional for version 2.2.0 and later strongSwan Helm charts: Remap remote network subnets by using the remoteSubnetNAT setting. Network Address Translation (NAT) for subnets provides a workaround for subnet conflicts between the cluster network and on-premises remote network. You can use NAT to remap the remote network's IP subnets to a different private subnet. Remapping happens before the packets are sent over the VPN tunnel.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-vpn"}, {"document_id": "ibmcld_16727-400124-401904", "score": 20.97923, "text": "\nThis setup is called a [multizone cluster](https://cloud.ibm.com/docs/openshift?topic=openshift-ha_clustersmz-clusters) and ensures that your app is accessible, even if a worker node or an entire zone is not available.\n\nTo protect against an entire region failure, create [multiple clusters and spread them across IBM Cloud regions](https://cloud.ibm.com/docs/openshift?topic=openshift-ha_clustersmultiple-clusters-glb). By setting up a network load balancer (NLB) for your clusters, you can achieve cross-region load balancing and cross-region networking for your clusters.\n\nIf you have data that must be available, even if an outage occurs, make sure to store your data on [persistent storage](https://cloud.ibm.com/docs/openshift?topic=openshift-storage-plan).\n\nFor more information about how to achieve high availability for your cluster, see [High availability for Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-haha).\n* What options do I have to secure my cluster?\n\nYou can use built-in security features in Red Hat OpenShift on IBM Cloud to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Red Hat OpenShift API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-securitysecurity).\n* What access policies do I give my cluster users?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-400150-401930", "score": 20.97923, "text": "\nThis setup is called a [multizone cluster](https://cloud.ibm.com/docs/openshift?topic=openshift-ha_clustersmz-clusters) and ensures that your app is accessible, even if a worker node or an entire zone is not available.\n\nTo protect against an entire region failure, create [multiple clusters and spread them across IBM Cloud regions](https://cloud.ibm.com/docs/openshift?topic=openshift-ha_clustersmultiple-clusters-glb). By setting up a network load balancer (NLB) for your clusters, you can achieve cross-region load balancing and cross-region networking for your clusters.\n\nIf you have data that must be available, even if an outage occurs, make sure to store your data on [persistent storage](https://cloud.ibm.com/docs/openshift?topic=openshift-storage-plan).\n\nFor more information about how to achieve high availability for your cluster, see [High availability for Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-haha).\n* What options do I have to secure my cluster?\n\nYou can use built-in security features in Red Hat OpenShift on IBM Cloud to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Red Hat OpenShift API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-securitysecurity).\n* What access policies do I give my cluster users?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_10575-808-2298", "score": 20.9344, "text": "\nTo secure your cluster network or connect to an on-prem data center, you can configure one of the following options:<br><br><br><br> * [strongSwan IPSec VPN Service](https://cloud.ibm.com/docs/openshift?topic=openshift-vpnvpn-setup)<br> * [IBM Cloud\u00ae Direct Link](https://cloud.ibm.com/docs/dl?topic=dl-get-started-with-ibm-cloud-dl)<br> * [Virtual Router Appliance (VRA)](https://cloud.ibm.com/docs/openshift?topic=openshift-vpnvyatta)<br> * [Fortigate Security Appliance (FSA)](https://cloud.ibm.com/docs/vmwaresolutions/services?topic=vmwaresolutions-fsa_considerations)<br><br><br> \n IBM Cloud storage Supported persistent storage solutions, such as IBM Cloud File Storage for Classic, IBM Cloud Block Storage, or IBM Cloud Object Storage are integrated as Kubernetes flex drivers and can be set up by using Helm charts. The storage documentation for each solution includes instructions to install and manage storage. For more information about choosing a persistent storage solution, see [Planning highly available persistent storage](https://cloud.ibm.com/docs/openshift?topic=openshift-storage-plan). \n Cluster autoscaler With the ibm-iks-cluster-autoscaler plug-in, you can scale the worker pools in your cluster automatically to increase or decrease the number of worker nodes in the worker pool based on the sizing requests of your scheduled workloads. For more information, see [Scaling clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-scaling-classic-vpc).", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-supported_integrations"}, {"document_id": "ibmcld_05777-8738-10765", "score": 20.670097, "text": "\nThis setup is called a [multizone cluster](https://cloud.ibm.com/docs/containers?topic=containers-ha_clustersmz-clusters) and ensures that your app is accessible, even if a worker node or an entire zone is not available.\n\nTo protect against an entire region failure, create [multiple clusters and spread them across IBM Cloud regions](https://cloud.ibm.com/docs/containers?topic=containers-ha_clustersmultiple-clusters-glb). By setting up a network load balancer (NLB) for your clusters, you can achieve cross-region load balancing and cross-region networking for your clusters.\n\nIf you have data that must be available, even if an outage occurs, make sure to store your data on [persistent storage](https://cloud.ibm.com/docs/containers?topic=containers-storage-plan).\n\nFor more information about how to achieve high availability for your cluster, see [High availability for IBM Cloud Kubernetes Service](https://cloud.ibm.com/docs/containers?topic=containers-haha).\n\n\n\n\n\n What options do I have to secure my cluster? \n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https://cloud.ibm.com/docs/containers?topic=containers-securitysecurity).\n\n\n\n\n\n What access policies do I give my cluster users? \n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-faqs"}, {"document_id": "ibmcld_10488-11431-12746", "score": 20.439804, "text": "\nCompliance to industry standards varies depending on the infrastructure provider of the cluster, such as classic or VPC.<br> * Monitor, isolate, and recover the cluster master.<br> * Provide highly available replicas of the Kubernetes master API server, etcd, scheduler, and controller manager components to protect against a master outage.<br> * Provide options for cluster network connectivity, such as public and private cloud service endpoints.<br> * Provide options for compute isolation, such as dedicated virtual machines or bare metal.<br> * Integrate Kubernetes role-based access control (RBAC) with IBM Cloud Identity and Access Management (IAM).<br><br><br> <br><br> * Set up and maintain security and regulation compliance for your apps and data. For example, choose how to set up your [cluster network](https://cloud.ibm.com/docs/openshift?topic=openshift-plan_clusters), [protect sensitive information](https://cloud.ibm.com/docs/openshift?topic=openshift-encryption) such as with IBM Key Protect encryption, and configure further [security settings](https://cloud.ibm.com/docs/openshift?topic=openshift-securitysecurity) to meet your workload's security and compliance needs. If applicable, configure your [firewall](https://cloud.ibm.com/docs/openshift?topic=openshift-firewallfirewall).<br><br><br>", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-responsibilities_iks"}, {"document_id": "ibmcld_05960-6212-7932", "score": 20.407598, "text": "\nSecurity strategy: Start by reviewing all [security options](https://cloud.ibm.com/docs/containers?topic=containers-security) that are available for your cluster.\n2. Network security:\n\n\n\n* Classic clusters:\n\n\n\n1. To isolate networking workloads, you can restrict network traffic to [edge worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-edge).\n2. Set up a firewall by using a [gateway appliance](https://cloud.ibm.com/docs/containers?topic=containers-firewallvyatta_firewall) or [Calico network policies](https://cloud.ibm.com/docs/containers?topic=containers-network_policies).\n\n\n\n* VPC clusters: Control traffic to and from your cluster with [VPC security groups](https://cloud.ibm.com/docs/containers?topic=containers-vpc-network-policy).\n\n\n\n3. Workload security:\n\n\n\n1. [Encrypt sensitive information](https://cloud.ibm.com/docs/containers?topic=containers-encryption) in the cluster, such as the master's local disk and secrets.\n2. Set up a [private image registry](https://cloud.ibm.com/docs/containers?topic=containers-securityimages_registry) for your developers, such as the one provided by Container Registry, to control access to the registry and the image content that can be pushed.\n3. [Set pod priority](https://cloud.ibm.com/docs/containers?topic=containers-pod_priority) to indicate the relative priority of the pods that make up your cluster's workload.\n4. Authorize who can create and update pods by configuring [pod security policies (PSPs)](https://cloud.ibm.com/docs/containers?topic=containers-psp).\n\n\n\n\n\n\n\n\n\n Logging and monitoring \n\nSet up logging and monitoring to help you troubleshoot issues and improve the health and performance of your Kubernetes clusters and apps.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-learning-path-admin"}, {"document_id": "ibmcld_06004-35201-37141", "score": 20.382114, "text": "\nYou have different options that depend on your cluster type. For more information, see [Planning networking services](https://cloud.ibm.com/docs/containers?topic=containers-cs_network_planningexternal).\n\n\n\n* Standard cluster: You can expose your app by using a [NodePort, load balancer, or Ingress service](https://cloud.ibm.com/docs/containers?topic=containers-cs_network_planningexternal).\n* Cluster that is made private by using Calico: You can expose your app by using a [NodePort, load balancer, or Ingress service](https://cloud.ibm.com/docs/containers?topic=containers-cs_network_planningprivate_both_vlans). You also must use a Calico preDNAT network policy to block the public node ports.\n* Private VLAN-only standard cluster: You can expose your app by using a [NodePort, load balancer, or Ingress service](https://cloud.ibm.com/docs/containers?topic=containers-cs_network_planningplan_private_vlan). You also must open the port for the service's private IP address in your firewall.\n\n\n\nAs you plan how many Service objects you need in your cluster, keep in mind that Kubernetes uses iptables to handle networking and port forwarding rules. If you run many services in your cluster, such as 5000, performance might be impacted.\n\n\n\n\n\n\n\n Securing apps \n\nAs you plan and develop your app, consider the following options to maintain a secure image, ensure that sensitive information is encrypted, encrypt traffic between app microservices, and control traffic between your app pods and other pods and services in the cluster.\n\nImage security\n: To protect your app, you must protect the image and establish checks to ensure the image's integrity. Review the [image and registry security topic](https://cloud.ibm.com/docs/containers?topic=containers-securityimages_registry) for steps that you can take to ensure secure container images. For example, you might use Vulnerability Advisor to check the security status of container images.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-plan_deploy"}, {"document_id": "ibmcld_07578-380995-382843", "score": 20.324213, "text": "\n* What options do I have to secure my cluster?\n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https://cloud.ibm.com/docs/containers?topic=containers-securitysecurity).\n* What access policies do I give my cluster users?\n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https://cloud.ibm.com/docs/containers?topic=containers-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https://cloud.ibm.com/docs/containers?topic=containers-access_reference) or in the following table's links. For steps to assign policies, see [Granting users access to your cluster through IBM Cloud IAM](https://cloud.ibm.com/docs/containers?topic=containers-userschecking-perms).\n\n\n\nTypes of roles you might assign to meet different use cases.\n\n Use case Example roles and scope", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}]}
{"task_id": "4c86c8740c3d49e06b7aca9d308119fa<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02604-7-2037", "score": 17.713896, "text": "\nUsing the Support Center \n\nNeed help with your API Connect service instance? Visit the IBM Cloud [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter) to file a case.\n\n\n\n1. On the Support Center page, look in the \"Contact support\" section and click Create a case.\n2. On the Create a Case page, look in the \"Services\" list and click API Connect.\n\nIt's important to create your case with the correct service so that IBM Support can track the case and assign the appropriate people to help you. The list of services depends on your IBM Cloud account. If you don't see API Connect in the \"Services\" list, you can locate it as follows:\n\n\n\n* Locate the \"What do you need help with?\" section.\n* Review the text in that section and click the view all services link.\n* In the complete list of services, locate API Connect and click it (services are listed in alphabetic order).\n\n\n\n3. Describe your problem.\n\nUse the fields on the \"Create a Case\" page to explain your problem. The following list describes important information that assists us with resolving issues that you are having in API Connect.\n\nImportant: Do not include your private key in the support request.\n\n\n\n* For all issues, include the following information:\n\n\n\n* Region and customer service instance impacted\n* Component impacted: API Manager, API calls, Portal\n* URL where error is being seen\n* For Dedicated, identify the customer environment\n* For Reserved plan, use a prefix in the Subject field to indicate the version (such as v5, v2018 or v10) and provider-org. For example: [v10 - providerOrg].\n\n\n\n* For API Manager UI-based issues, additionally include:\n\n\n\n* All error codes returned\n* Time (including time zone) that the problem occurred\n\n\n\n* For Portal-based issues, additionally include the user name of person who encountered the problem\n* For issues with invoking APIs, additionally include:\n\n\n\n* Full API URL impacted - the host name should contain apiconnect.ibmcloud.com\n* HTTP method used\n* Frequency and time (with time zone) of the issue", "title": "", "source": "https://cloud.ibm.com/docs/apiconnect?topic=apiconnect-get_help"}, {"document_id": "ibmcld_05818-2659-4377", "score": 17.216814, "text": "\n* See [Getting help](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar) for more details about using the forums.\n\n\n\n\n\n\n\n\n\n Contacting support \n\nBefore you open a support case, gather relevant information about your cluster environment.\n\n\n\n1. Get your cluster details.\n\nibmcloud ks cluster get -c <cluster_name_or_ID>\n2. If your issue involves worker nodes, get the worker node details.\n\n\n\n1. List all worker nodes in the cluster, and note the ID of any worker nodes with an unhealthy State or Status.\n\nibmcloud ks worker ls -c <cluster_name_or_ID>\n2. Get the details of the unhealthy worker node.\n\nibmcloud ks worker get -w <worker_ID> -c <cluster_name_or_ID>\n\n\n\n3. For issues with resources within your cluster such as pods or services, log in to the cluster and use the Kubernetes API to get more information about them.\n\nYou can also use the [IBM Cloud Kubernetes Service Diagnostics and Debug Tool](https://cloud.ibm.com/docs/containers?topic=containers-debug-tool) to gather and export pertinent information to share with IBM Support.\n4. Contact IBM Support by [opening a case](https://cloud.ibm.com/unifiedsupport/cases/form). To learn about opening an IBM support case, or about support levels and case severities, see [Contacting support](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar).\n5. For the Problem type, search for or select Kubernetes Service.\n6. For the Case details, provide a descriptive title and include the details that you previously gathered. From the Resources, you can also select the cluster that the issue is related to.\n\n\n\n\n\n\n\n Requesting access to allowlisted features \n\n\n\n1. [Create a ticket](https://cloud.ibm.com/unifiedsupport/cases/form).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-get-help"}, {"document_id": "ibmcld_08091-5945-8032", "score": 16.966408, "text": "\nFor more information, see [Case severity and initial response times](https://cloud.ibm.com/docs/get-support?topic=get-support-support-case-severity).\n\nYou can change your current support plan at any time by contacting a [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) representative.\n\n\n\n\n\n IBM beta service \n\nIBM releases services or container images that are classified as beta releases. These services are in a trial stage of development and they aren't production-ready. A beta release helps IBM development and marketing teams to assess the value of the service in the market. This assessment enables teams to make updates before the service is released as a GA service or container image.\n\nIf the root cause analysis determines the issue is a defect in the beta service or container image, IBM isn't required to provide a fix. Additionally, the case is assigned the appropriate 3 or 4 severity level.\n\n\n\n\n\n Third-party services \n\nThird-party services are provided by vendors outside of IBM. These services are provided by individual software entities, IBM Business Partners, or independent software vendors (ISV).\n\nSupport for third-party services is provided by the service provider. This includes third-party products that are deployed by using the IBM Cloud Provider Plug-in for Terraform. If the root cause analysis determines that the issue is a defect in a third-party service, IBM isn't required to provide a fix. However, IBM shares analysis with the third-party service provider, if needed, and can work through Marketplace with the third-party service to help solve the issue.\n\n\n\n\n\n Open source or community service \n\nOpen source or community services are provided by open source communities outside of IBM.\n\nIf the root cause analysis determines that the issue is a defect in an open source or community service, IBM isn't required to provide a fix. IBM closes the case and refers you to the community or forum for assistance. You can get community assistance for technical issues through [Stack Overflow](https://stackoverflow.com/questions/tagged/ibm-cloud).", "title": "", "source": "https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar&interface=ui"}, {"document_id": "ibmcld_12814-2351-4052", "score": 16.684061, "text": "\nIf you're experiencing issues with Partner Center, you can create a support case by using the [IBM Cloud Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\nTo create a support case, you must have a Pay-As-You-Go or Subscription account. Also, ensure that you're assigned at least the editor role on the Support Center account management service to create, edit, or view support cases. For more information about actions and roles for account management services, see [Assigning access to account management services](https://cloud.ibm.com/docs/account?topic=account-account-servicesaccount-management-actions-roles) or to assign other users access, see [Assigning user access for working with support cases](https://cloud.ibm.com/docs/get-support?topic=get-support-access).\n\nTo create a support case for Partner Center related issues, complete the following steps:\n\n\n\n1. Click the Help icon ![Help icon](https://cloud.ibm.com/docs-content/v1/content/ff5860bfede49db3197c4bbba7f7123769bdc068/icons/help.svg) > Support center from the console menu bar.\n2. From the Contact support section, click Create a case.\n3. Select All products.\n4. Select Partner Center - Sell as the topic and click Next.\n5. Complete the required fields.\n\nTo maintain security, do not include any personal information, sensitive data, or device or service credentials in case responses. For example, don't include passwords, API keys, secrets, or credit card information.\n6. The following steps are optional:\n\n\n\n* Attach files and resources to provide more details about the issue you're experiencing.\n* If you'd like a user in you account to be updated about the case, add them by using the Contact watchlist.", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-get-pc-support"}, {"document_id": "ibmcld_01595-17454-18582", "score": 16.547796, "text": "\nFor more details on on using these forums, check the [Getting help page here](https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportusing-avatar).\n\nFor information about opening an IBM support ticket, or about support levels and ticket severities, see [Contacting support](https://cloud.ibm.com/docs/get-support?topic=get-support-support-case-severitysupport-case-severity).\n\nPlease provide as much of the following information as possible when submitting a ticket:\n\n\n\n* What OS is the client running on?\n* What version of the client is being used (this can be found using the 'C' command on the client)?\n* If this is a UI issue, paste or attach any associated browser console logs and screenshots\n* Paste or attach any associated requesting application logs and timezone\n* Paste or attach any associated Secure Gateway Client logs and timezone\n* Provide the details of the destination being used (either a screenshot or fill out the fields below):\n\n\n\n* Destination ID\n* Protocol\n* Destination-side Authentication\n* Uploaded certificates (just names and which Box folder or link they were uploaded to)", "title": "", "source": "https://cloud.ibm.com/docs/SecureGateway?topic=SecureGateway-troubleshooting"}, {"document_id": "ibmcld_08068-0-2916", "score": 16.348259, "text": "\n\n\n\n\n\n\n  Case severity and initial response times \n\nHow quickly your support cases are addressed depends on the assigned severity. You assign the severity of the issue when you open the case. With your agreement, the support team adjusts the assigned severity if an incorrect severity level is selected. For more information about Support plans, see [Basic, Advanced, and Premium Support plans](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans).\n\nThe following table lists some common examples of support issues, suggested severity levels, and the initial response time objectives. The initial response time objectives are used to describe IBM goals only, and don't represent a performance guarantee.\n\nInitial response Service Level Objectives (SLO) do not apply to any billing, invoice, or sales-related inquiry or cases.\n\nSeverity Level Definition\n\nInitial Response Time Objectives\n\n\n\nTable 1. Case severity definitions\n\n Severity  Business impact  Details                                                                                                                                                                                                                                                                                                                       \n\n 4         Minimal          An inquiry or non-technical request.                                                                                                                                                                                                                                                                                          \n 3         Some             The product, service, or functions are usable, and the issue doesn't represent a significant impact on operations.                                                                                                                                                                                                            \n 2         Significant      A product, service, business feature, or function of the product or service is severely restricted in its use, or you are in jeopardy of missing business deadlines.                                                                                                                                                          \n 1         Critical         System or Service Down  <br>Business-critical functions are inoperable or a critical interface has failed. This usually applies to a production environment and indicates an inability to access products or services that results in a critical impact on operations. This condition requires an immediate solution.         \n\n\n\nWe work with you 24 hours a day and seven days a week to resolve Severity 1 problems if you have a technical resource available to work during those hours. You must reasonably assist with any problem diagnosis and resolution.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/get-support?topic=get-support-support-case-severity"}, {"document_id": "ibmcld_08091-7-1878", "score": 16.280605, "text": "\nUsing the Support Center \n\nIf you experience problems with IBM Cloud\u00ae, you have several options to get help with determining the cause of the problem and finding a solution. If you're logged in, you can go directly to the [Support center](https://cloud.ibm.com/unifiedsupport/supportcenter) to review your product topics and featured FAQs, open or manage a support case, or search community content. If you can't log in to your account, start a chat by going to the [IBM Cloud Support](https://www.ibm.com/cloud/support) page and clicking Let's talk. Or you can complete the [Create an Account, Login, or Billing Request form](https://watson.service-now.com/x_ibmwc_open_case_app.do!/create).\n\nAs a classic infrastructure user, you might be familiar with support tickets. Tickets are now called cases in IBM Cloud.\n\nThree different types of support plan are offered. For more information, see [Basic, Advanced, and Premium Support plans](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans). You can change your current support plan at any time by contacting a [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) representative.\n\nIBM periodically sends surveys to IBM Cloud customers to get feedback on recent experiences with customer support. The survey focuses on the support quality and the overall experience. IBM management reviews the survey results to improve the support experience.\n\n\n\n Getting support \n\nTo access the Support Center, click the Help icon ![Help icon](https://cloud.ibm.com/docs-content/v1/content/9147bc2ffd9bafd03e4559b378e714fac17a4977/icons/help.svg) > Support center from the IBM Cloud console menu bar.\n\nReview your product topics to get a quick overview of the IBM Cloud documentation that offers common tasks based on what is provisioned on your account. You can search to view topics based on specific products.", "title": "", "source": "https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar&interface=ui"}, {"document_id": "ibmcld_07037-7-2002", "score": 16.13293, "text": "\nGetting help \n\nGet help to solve issues that you encounter when you use the product.\n\nUse these resources to get answers to your questions:\n\n\n\n* Walk through a guided tour to learn about a project type or a feature. Click Guided tours from the page header to see a list of available tours.\n* For answers to frequently asked questions, see the [FAQ](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-faqs).\n* Find answers to common questions or ask questions where experts and other community members can answer. Go to the [Watson Discovery Community forum](https://community.ibm.com/community/user/watsonai/communities/community-home?CommunityKey=80650291-2ff4-4a43-9ff8-5188fdb9552f).\n\n\n\n\n\n IBM Cloud Contacting IBM Cloud Support for managed deployments \n\nManaged deployments are deployments that are hosted on IBM Cloud, including IBM Cloud Pak for Data as a Service deployments.\n\nIf your service plan covers it, you can get help by opening a case from [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\nBe ready to share the following information with IBM Support:\n\n\n\n Account information \n\n\n\n* Account name or customer name.\n* Business impact so IBM Support understands the urgency of the issue and can prioritize it.\n* Case information for any related cases or a parent case.\n* Cloud location where the service instance is hosted (Dallas, Frankfurt, and so on).\n* Your service plan (Plus, Premium and so on).\n\n\n\n\n\n\n\n Problem description \n\n\n\n* What outcome were you expecting and what happened?\n* Message text that is displayed when the error occurs, especially the document ID, if specified.\n* Steps to take to reproduce the issue.\n* Any screen captures that illustrate the problem.\n* When did the problem occur?\n* Instance ID. (The instance ID is part of the URL that is specified in the Credentials section of the service page on IBM Cloud. You can copy the full URL and provide that.)\n* Collect and share the HTTP archive (HAR) file from your browser.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-get-help"}, {"document_id": "ibmcld_08091-4222-6344", "score": 15.911163, "text": "\nEU Support is provided 24 hours a day and 7 days a week by engineers that are located in Europe. Global teams provide support at the discretion of the EU support team. Global teams might be contacted, for example, when issues are not resolved by the Advanced Customer Support (ACS) team in the EU, and more expertise is needed.\n\nYou can specify that you want EU support for your account if the following criteria are true:\n\n\n\n* The EU Supported setting is enabled for your account by the master user or account owner. For more information, see [Enabling the EU Supported setting](https://cloud.ibm.com/docs/account?topic=account-eu-hipaa-supportedbill_eusupported).\n* Your resources are in the appropriate European data center. For more information, see [Data centers](https://cloud.ibm.com/docs/overview?topic=overview-locationsdata-centers).\n* You select the EU supported case level when you open the case.\n\n\n\nIBM Cloud platform services that are hosted in the Frankfurt location must be supported by a team that is physically located in Europe.\n\nEnabling the EU Support setting for your account applies to all future cases that you open for issues on any service or data center that is hosted in the EU region. However, if you add resources outside of an EU data center or Frankfurt location, issues for those resources are not necessarily handled by a support team in Europe. Any cases that are opened before you enable the EU Supported setting aren't affected.\n\n\n\n\n\n IBM generally available service \n\nSupport is provided for problems that are determined to be a defect for services or container images that are generally available (GA) and provided by IBM. The case is addressed based on the severity that you assign. For more information, see [Case severity and initial response times](https://cloud.ibm.com/docs/get-support?topic=get-support-support-case-severity).\n\nYou can change your current support plan at any time by contacting a [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) representative.\n\n\n\n\n\n IBM beta service \n\nIBM releases services or container images that are classified as beta releases.", "title": "", "source": "https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar&interface=ui"}, {"document_id": "ibmcld_11601-7-2113", "score": 15.899833, "text": "\nGetting help and support from IBM Cloud or SAP \n\nIf you experience problems with IBM Cloud, you have several options to get help with determining the cause of the problem and finding a solution.\n\nWhich support option depends on the level of support (and urgency), and whether the problem is with the Offering or running SAP Workloads using the Offering.\n\nOptions include:\n\n\n\n* IBM Cloud Support Case, using the [IBM Cloud Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter)\n* SAP support incident, using the [SAP ONE Support Launchpad](https://launchpad.support.sap.com/)\n* IBM Cloud Docs\n\n\n\nFor previous users of IBM Cloud Classic Infrastructure (formerly Softlayer), please be aware these Support Cases were previously termed Support Tickets.\n\n\n\n IBM Cloud Support \n\nIBM Cloud Support handles any support questions and issues that might arise - available through live web chat, phone, and case-based support.\n\nEach IBM Cloud account automatically comes with customer support at no cost and covers most cases which are placed each day; this is the Basic level of support.\n\nThe types of available and response time of support, depends on the support level of the account. Your support plan also determines the severity level that you can assign to support cases. For more information, see [Basic, Advanced, and Premium Support plans](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans).\n\nYou can change your current support plan at any time by contacting IBM Cloud sales expert.\n\nFor full information about opening an IBM Cloud Support case, or about support levels and ticket severities, see [IBM Cloud Support documentation](https://cloud.ibm.com/docs/get-support).\n\nIf you need support but are unable to log in to your account, start a chat by going to the [IBM Cloud Support](https://www.ibm.com/cloud/support) page and clicking Let's talk.\n\n\n\n New support case with IBM Cloud Support \n\nIf you need to open a support case, collect as much information as possible to help the IBM Cloud Support team to analyze, triage and diagnose your problem as quickly as possible.", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-help-support"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00580-3166-5282", "score": 23.727793, "text": "\nIt is accessed with an HTTP API and can therefore be accessed by any device on the internet that speaks HTTP: application code, web browser, IoT device, or mobile phone. IBM Cloudant is a highly available managed service able to continue to operate with multiple hardware failures.\n\nThat's the end of this part. The next part is called The Document.\n\n\n\n\n\n\n\n The Document video \n\nLearn about IBM Cloudant databases and documents work.\n\n\n\n* The Document video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 2 - The IBM Cloudant Document.\n\nIn the previous section, we saw that IBM Cloudant is a JSON document store. Let's find out what that means in practice and how that compares to other types of database.\n\nMost databases store their data in collections that are called tables, where each unit of data is a row, each with identical, fixed columns. The schema of each table is predefined: a list of columns with their name, date type, value constraints, and relations to other tables carefully defined. Each new record forms a row in a table.\n\nIBM Cloudant is different!\n\nAn IBM Cloudant service includes collections that are called databases (instead of tables) each of which contain any number of documents.\n\nThe example of this slide shows the same data that is expressed in a traditional tabular database and how the same data would be stored in IBM Cloudant as JSON documents.\n\nSo if you come from a relational database background: tables are \"databases\" in IBM Cloudant, and rows are \"documents\".\n\nAn IBM Cloudant document must be a JSON object, starting and ending with curly braces and containing a number of key-value attributes.\n\nJSON objects must be less that 1 megabyte in size and contain any number of strings, numbers, booleans, arrays, and objects. The nesting of objects within objects can continue to any depth.\n\nThe keys that are used can be as brief or verbose as you like.\n\nThe following list includes some simple example documents that show how each data type is used.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-learning-center"}, {"document_id": "ibmcld_00550-7-2005", "score": 23.017904, "text": "\nGrouping related documents together in IBM Cloudant \n\nTraditionally, e-commerce systems are built with relational databases. These databases typically use a number of tables joined to record sales, customer details, purchased products, and delivery tracking information.\n\nRelational databases offer high consistency, which means that application developers can build their applications to a database's strengths. This practice includes joins between collections, enumerations to record the state of an object, and database transactions to guarantee atomic operations.\n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae favors availability over consistency. It's a high-availability, fault-tolerant, distributed database that is eventually consistent. A distributed database means the customer's shopping service is always available and scalable enough to cope with many users who make purchases at the same time. With that in mind, your application can leverage IBM Cloudant's strengths and not treat it like a relational database.\n\nThis discussion outlines some of the factors that are involved in building an e-commerce system that takes advantage of IBM Cloudant's strengths. IBM Cloudant uses concepts that are applicable to many other domains, such as:\n\n\n\n* Using multiple documents to represent the state of a purchase, rather than frequently updating a single document.\n* Storing copies of related objects in order instead of joining to another collection.\n* Creating views to collate documents by order_id to reflect the current state of a purchase.\n\n\n\nFor example, you might create a purchase document that includes details such as the items ordered, customer information, cost, and delivery information.\n\nSee the following example document that describes a purchase:\n\n{\n\"_id\": \"023f7a21dbe8a4177a2816e4ad1ea27e\",\n\"type\": \"purchase\",\n\"order_id\": \"320afa89017426b994162ab004ce3383\",\n\"basket\": [\n{\n\"product_id\": \"A56\",\n\"title\": \"Adele - 25\",\n\"category\": \"Audio CD\",\n\"price\": 8.33,\n\"tax\": 0.2,\n\"quantity\": 2\n},\n{", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-grouping-related-documents-together-in-ibm-cloudant"}, {"document_id": "ibmcld_09557-7-2255", "score": 22.818733, "text": "\nUnderstanding high availability and disaster recovery for Cloud Databases \n\nThis document covers all the IBM Cloud\u00ae Databases, which include Databases for DataStax, Databases for Elasticsearch, Databases for EnterpriseDB, Databases for etcd, Databases for MongoDB, Databases for PostgreSQL, Databases for Redis, Messages for RabbitMQ, and Databases for MySQL.\n\nIBM Cloud\u00ae Databases instances are deployed in either a multi-zone region (MZR) (for example, Dallas, Frankfurt, London, Sydney, Tokyo, and Washington), or a single-campus multizone region (for example, Chennai). Each instance is deployed in a highly available configuration; that is, data is replicated by each database onto one or more servers, making the data highly available during normal operations.\n\n\n\n* In MZRs, database members are distributed across different data centers, or zones.\n* In single-campus multizone regions, database members are distributed across different hosts.\n\n\n\nIf a single-campus multizone region failure in an MZR or a hardware failure in any region occurs, your data is still accessible as it is replicated onto other fully functioning database servers. Such issues are addressed by IBM Cloud\u00ae Specialists in place.\n\nYou can consult your Cloud Databases documentation for more details on how your specific database replicates data among each of its members.\n\nIn addition to the high-availability configuration, for deployments in IBM Cloud Multi-Zone Regions, your data is snapshotted and backed up daily by the IBM Cloud\u00ae Databases platform and stored in [cross-region Cloud Object Storage buckets](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-endpointsendpoints-geo). For most IBM Cloud single-campus multizone regions, your data is backed up locally in [Single-campus multizone region Cloud Object Storage buckets](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-endpointsendpoints-zonee).\n\nIf a complete region failure occurs, the database servers in the region might not be accessible, but the backup data remains available. You can initiate a restore from these backups into an available region from the service management console. Consult your Cloud Databases backups page for more details.", "title": "", "source": "https://cloud.ibm.com/docs/messages-for-rabbitmq?topic=messages-for-rabbitmq-ha-dr"}, {"document_id": "ibmcld_00576-6036-7924", "score": 22.46376, "text": "\nFor more information, see [IBM Cloud Databases for PostgreSQL](https://www.ibm.com/cloud/databases-for-postgresql).\n* Data warehouse for ad hoc querying. For more information, see [IBM\u00ae Db2\u00ae Warehouse on Cloud](https://www.ibm.com/products/db2-warehouse).\n* A queue. For more information, see [IBM MQ](https://www.ibm.com/uk-en/products/mq).\n\n\n\nFor more information, see the [Best and worst practice](https://blog.cloudant.com/2019/11/21/Best-and-Worst-Practices.html) blog.\n\n\n\n\n\n Organizing documents and databases \n\nIBM Cloudant data is organized in a hierarchy of databases and documents. A document is a JSON object with a unique identifier: its _id. A database is a collection of documents with a primary index that allows documents to be retrieved by _id. It also has optional secondary indexes that allow documents to be queried by other attributes in the object.\n\nWhen developers start a project, they sometimes struggle with the following questions:\n\n\n\n* How much data can I put into a single object?\n* Must I store different document types in the same collection or one database per document type?\n\n\n\nIt is important for a document to include all the data about an object that is modeled by your application, for example, a user, an order, or a product. This practice ensures you fetch the entire object from the database in one API call. IBM Cloudant doesn't have the concept of joins like a relational database, so data isn't normalized. However, data can repeat across objects. For example, an order document can include a subset of the product documents that were purchased.\n\nIt's common to store several object types in the same database: a convention is that a type attribute is used to denote the object type. This option is a good one if you need to perform queries that return several object types or if a database needs to be replicated to another location altogether.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloudant-basics"}, {"document_id": "ibmcld_00580-25421-27357", "score": 22.455576, "text": "\nType acurl $URL/_all_dbs to see an array of databases.\n\n\n\nA quick note here on formatting JSON on the command line. We can send the output of our acurl command to another tool, which formats the data nicely on the terminal. The following tools are available for your use:\n\n\n\n* Jq available from the URL on the page, which is more than just a JSON formatter - it allows JSON to be parsed, queried, and manipulated too.\n* python -m json.tool is a simple JSON formatter, if Python is installed on your computer.\n\n\n\nSo acurl $URL/_all_dbs | jq means pipe the output of acurl into jq and what you see is a nicely formatted, colored output.\n\nThe IBM Cloudant API paths are hierarchical with the first level that gives you information about the service, and then each database sits at a level beneath it.\n\nSo acurl $URL/books gives us information about the books database that we created earlier.\n\nYou see information about how many documents it has, how many deleted documents, and how much disk space it's occupying.\n\nDon't forget to pipe the output to jq or Python to get a prettier output.\n\nIf we want to see the documents contained in the database, we can use the _all_docs endpoint.\n\nSo acurl $URL/books/_all_docs means get all the documents from the books database from the IBM Cloudant service at the supplied URL.\n\nThis command's results return a list of _id and _rev values for each document. If you want the document bodies too, then add ?include_docs=true to your API call.\n\nIf we want to fetch a single document back from the database, then documents sit one level beneath the database in the hierarchy of the URL.\n\nSo acurl $URL/books/id means \"get document ID from the database books from the IBM Cloudant service at the supplied URL\".\n\nNotice the hierarchy: service, database, and document.\n\nSo far we only used the GET HTTP method, which is the default one for curl and the one used when you enter a URL into your web browser.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-learning-center"}, {"document_id": "ibmcld_09715-2612-4022", "score": 22.206877, "text": "\n[IBM Cloudant](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-getting-started-with-cloudant) IBM Cloudant is a document-oriented database as a service (DBaaS). It stores data as documents in JSON format. [Platform metrics](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-monitor-ibm-cloud-pm) \n [IBM Cloud Databases for PostgreSQL](https://cloud.ibm.com/docs/databases-for-postgresql?topic=databases-for-postgresql-getting-started) IBM Cloud Databases for PostgreSQL is a managed PostgreSQL service that is hosted in the IBM Cloud and integrated with other IBM Cloud services. [Platform metrics](https://cloud.ibm.com/docs/databases-for-postgresql?topic=databases-for-postgresql-monitoring) \n [IBM Cloud Databases for Redis](https://cloud.ibm.com/docs/databases-for-redis?topic=databases-for-redis-getting-started) IBM Cloud Databases for Redis is a managed service that is hosted in the IBM Cloud and integrated with other IBM Cloud services. [Platform metrics](https://cloud.ibm.com/docs/databases-for-redis?topic=databases-for-redis-monitoring) \n [IBM Cloud Databases for etcd](https://cloud.ibm.com/docs/databases-for-etcd?topic=databases-for-etcd-getting-started) IBM Cloud Databases for etcd is a managed etcd service that is hosted in the IBM Cloud and integrated with other IBM Cloud services. [Platform metrics](https://cloud.ibm.com/docs/databases-for-etcd?topic=databases-for-etcd-monitoring)", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-cloud_services"}, {"document_id": "ibmcld_00612-7-2163", "score": 22.040432, "text": "\nMigration overview \n\nThe [IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae](https://www.ibm.com/cloud/cloudant) database-as-a-service offering is a JSON document store that runs on multi-tenant clusters. The service is available with a choice of geographical locations with predictable costs, scalability, and a service-level agreement (SLA).\n\nYou can migrate to an IBM Cloudant Lite or Standard plan instance on IBM Cloud from one of the following plans:\n\n\n\nTable 1. IBM Cloudant migration paths\n\n Plan Description \n\n IBM Cloudant Enterprise Dedicated, single-tenant clusters \n Apache CouchDB The self-hosted, open source database on which IBM Cloudant is based. \n\n\n\n\n\n Benefits of the IBM Cloudant Lite and Standard plans \n\nWith the Standard plan, you can reserve throughput capacity for your database service, that is, to specify how much throughput your application's database is going to need to handle demand. The Standard plan also charges for the amount of storage you use. Capacity is measured with the following metrics:\n\n\n\nTable 2. Capacity metrics\n\n Metric Description \n\n Reads per second The rate when simple document fetches are performed, for example, retrieving a document by its _id, or querying against a partitioned database that uses a partition key. \n Writes per second The rate when data is written to the database. API calls dealing with document creation, update, or deletion count as \"writes\". \n Global Queries per second The rate when the database is queried by global indices, typically by accessing the _find endpoint, secondary MapReduce, or search indices. \n Storage The amount of disk space occupied by your JSON data, attachments, and secondary indices. \n\n\n\nAs an example, the Lite plan offers 20 reads per second, 10 writes per second, 5 global queries per second, and 1 GB of storage for free. This plan is ideal when you're evaluating the product and during product development. When your application goes into QA or production, switch to the Standard plan to scale the instance. The Standard plan's smallest capacity has 100 reads per second, 50 writes per second, 5 global queries per second, and 20 GB of storage for USD$76.65 per month.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-to-ibm-cloudant-on-ibm-cloud"}, {"document_id": "ibmcld_10165-5520-7943", "score": 21.838224, "text": "\nIBM Cloudant is a modern NoSQL database that is useful for many data-driven use cases: from key-value to complex document-oriented data storage and query. To manage the growing set of regulatory and management report rules, the mortgage company uses IBM Cloudant to store documents that are associated with raw regulatory data the come into the firm. Compute processes on Red Hat OpenShift on IBM Cloud are triggered to compile, process, and publish the data in various reporting formats. Intermediate results common across reports are stored as IBM Cloudant documents so template-driven processes can be used to produce the necessary reports.\n\n\n\n\n\n Results \n\n\n\n* Complex financial simulations are completed in 25% of the time than was previously possible with the existing on-premises systems.\n* Time to deployment improved from the previous 6 - 9 months to 1 - 3 weeks on average. This improvement occurs because Red Hat OpenShift on IBM Cloud allows for a disciplined, controlled process for ramping up app containers and replacing them with newer versions. Reporting bugs can be fixed quickly, addressing issues, such as accuracy.\n* Regulatory reporting costs were reduced with a consistent, scalable set of storage and compute services that Red Hat OpenShift on IBM Cloud and IBM Cloudant bring.\n* Over time, the original apps that were initially moved to the cloud were restructured into cooperative microservices that run on Red Hat OpenShift on IBM Cloud. This action further sped up development and time to deploy and allowed more innovation due to the relative ease of experimentation. They also released innovative apps with newer versions of microservices to take advantage of market and business conditions (that is, so called situational apps and microservices).\n\n\n\n\n\n\n\n\n\n Payment tech company streamlines developer productivity, deploying AI-enabled tools to their partners 4 times faster \n\nA Development Exec has Developers that use on-premises application tools that slow down prototyping while they wait for hardware procurement.\n\nRed Hat OpenShift on IBM Cloud provides spin-up of compute by using open-source standard technology. After the company moved to Red Hat OpenShift on IBM Cloud, Developers have access to DevOps friendly tools, such as portable and easily shared containers.\n\nThen, Developers can experiment easily, pushing changes to Development and Test systems quickly with open toolchains.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_finance"}, {"document_id": "ibmcld_07502-7384-9254", "score": 21.440199, "text": "\n[IBM Cloud Databases](https://cloud.ibm.com/docs/cloud-databases?topic=cloud-databases-about) provide automatic daily backups that are stored in the same account and geography. Backups are typically stored in [cross-regional storage](https://cloud.ibm.com/docs/cloud-databases?topic=cloud-databases-dashboard-backups&interface=uibackup-locations) and should therefore be immune to a single region outage. This facility is reliable and convenient, but does not currently support backup storage in a specified alternate region or account. However, backups can be [restored to another region or account](https://cloud.ibm.com/docs/cloud-databases?topic=cloud-databases-dashboard-backups&interface=ui), so recovery to a passive deployment (cold standby) is supported.\n\nIt is also possible to use database-specific clients (for example pg_dump for PostgreSQL) to backup IBM Cloud Databases to arbitrary storage by using customer automation. If used, these backups should be stored in Cloud Object Storage in an alterative region and in the backup account as described in [Backup accounts](https://cloud.ibm.com/docs/enterprise-account-architecture?topic=enterprise-account-architecture-bcdraccounts).\n\n\n\n\n\n Virtual servers \n\nBoth [volume snapshots](https://cloud.ibm.com/docs/vpc?topic=vpc-backups-vpc-best-practices&interface=ui) and [Veeam](https://cloud.ibm.com/docs/vpc?topic=vpc-about-veeam) are available to backup virtual servers. Veeam is preferred for extensive feature set and its ability to backup application workloads. However, Veeam does require deploying an agent to backup workloads not hosted on VMWare. The Veeam server that is used for backups should be located in a alterative region and in the backup account as described in [Backup accounts](https://cloud.ibm.com/docs/enterprise-account-architecture?topic=enterprise-account-architecture-bcdraccounts).", "title": "", "source": "https://cloud.ibm.com/docs/enterprise-account-architecture?topic=enterprise-account-architecture-bcdr"}, {"document_id": "ibmcld_00580-6386-8382", "score": 21.409138, "text": "\nIt has only a small provisioned capacity and a fixed storage size, but it's fine for testing the IBM Cloudant service.\n\nIBM Cloudant is often referred to as a \"schemaless\" database - but we have to be careful how we define that term.\n\nIt's true to say that you don't need to define your schema (field names, types, constraints, and relationships) ahead of time in an IBM Cloudant database. You can simply write a JSON document of your own design to a database.\n\nDevelopers like this flexibility because they can design their data in their code, turn it into JSON, and write it to the database.\n\nIt's still important to think about the shape of your data, especially in terms of how you are going to query and index it, as we see later.\n\nData design is still required, but strictly speaking that database doesn't need to know about your schema.\n\nLet's say we want to create a database of US presidents. We can simply devise our \"model\" of the data in our app, turn it into JSON, and write it to the database. In this case, we are using a common CouchDB convention: the \"type\" field indicates the data type of the document.\n\nIf at a future date we decide we want to add more data to our \"schema\", we can simply write a new object to the database with no complaints from IBM Cloudant. We could decide to add the \"address\" object only to the following documents:\n\n\n\n* Documents that are created from now on.\n* Only documents that we have addresses for.\n\n\n\nIn other words, documents of the same type can have fields present or missing.\n\nYour database's schema can evolve over time to match your application's needs. You don't (necessarily) need to tell the database about the schema change - write new documents in the new format.\n\nWe can even store multiple document \"types\" in the same database. In this case, people, books, and places reside in the same database. We know which is which because of the \"type\" field (this field is a convention and not something that means anything to IBM Cloudant).", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-learning-center"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13493-1220-3010", "score": 16.216648, "text": "\n* If the format of the input objects is CSV and a delimiter other than the default , (comma) is used, you must specify the delimiter by using the FIELDS TERMINATED BY option of the [STORED AS](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause. All single Unicode characters are allowed as delimiters.\n* By default, it is assumed that CSV input objects have a header line that specifies the names of the input columns. If the objects don't have a header line, you must specify NOHEADER in the [STORED AS](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause.\n* By default, it is assumed that JSON input objects consist of a single JSON record per line. If individual records span multiple lines, you must specify MULTILINE in the [STORED AS](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause.\n* If required, you can use JOIN constructs to join data from several input URIs, even if those URIs point to different instances of Cloud Object Storage.\n* Use the INTO clause of a [query](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referencechapterSQLQueryStatement) to specify the output [URI](https://cloud.ibm.com/docs/sql-query?topic=sql-query-runningunique), that is, the location to which the result is to be written and the wanted result format.\n\n\n\n2. The Target location field displays where the result is stored. An initial bucket in one of your Object Storage instances is automatically created for you when you open the UI. It is then chosen as your default location, if your query does not specify an INTO clause. To ensure the automatic setup of an initial bucket, do the following steps in advance:\n\n\n\n* You must create an Object Storage instance.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-running"}, {"document_id": "ibmcld_07046-4911-6551", "score": 15.943411, "text": "\nDates from metadata date fields, such as extracted_metadata.publicationdate, are stored in the index as dates as long as the date format matches one of the supported date data type formats. You can't see nested fields from the Manage fields page. And when you view a search result as JSON, date field values are displayed as string values because the JSON editor shows the date as a string. However, values from date fields behave like dates. You can use greater than (>) or less than (<) operators with such fields in Discovery Query Language queries, for example.\n\nStructured files\n: Structure files that you import, such as CSV or JSON files, might contain date fields that you want to store as date data types. Discovery can recognize many date formats. However, you might need to add a format to the list. For more information, see Date format settings.\n\n\n\n Date format settings \n\nIf your documents have a root-level field with date information in it, you can set the field to be a Date data type field in the index.\n\nDiscovery recognizes the following date formats automatically:\n\nyyyy-MM-dd'T'HH:mm:ssZ\nyyyy-MM-dd'T'HH:mm:ssXXX\nyyyy-MM-dd'T'HH:mm:ss.SSSZ\nyyyy-MM-dd'T'HH:mm:ss.SSSX\nyyyy-MM-dd\nM/d/yy\nyyyyMMdd\nyyyy/MM/dd\n\nIf you store dates in other formats, you can add the format to the list of supported formats.\n\nTo add more date formats, complete the following steps:\n\n\n\n1. From the Manage fields page for the collection, add a format as a new line in the Date formats field.\n\nSpecify a date format that is supported by the Java [SimpleDateFormat](https://docs.oracle.com/javase/8/docs/api/java/text/SimpleDateFormat.html) class.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-index-overview"}, {"document_id": "ibmcld_07067-29074-30687", "score": 15.282222, "text": "\n* In Discovery v2, the Entities v2 enrichment is used. Entity type names in v2 are specified in headline case, instead of all uppercase letters. If you use a query or aggregation that specifies an entity name, you must change the capitalization. For example, change PERSON to Person.\n* Fields from JSON files that are added to a collection are converted differently during ingestion between v1 and v2. If your application manipulates these results, you might need to make adjustments.\n\nYou can specify the normalizations and conversions objects in the [Update a collection](https://cloud.ibm.com/apidocs/discovery-dataupdatecollection) method of the API to move or merge JSON fields.\n\n\n\nHow JSON source fields are handled\n\n Original JSON field content v1 representation v2 representation Notes \n\n \"field\": null \"field\": null N/A v1 retains the null value. v2 skips the null field altogether. \n \"field\": \"\" \"field\": \"\" N/A v1 retains the empty text value. v2 skips the empty text field altogether. \n \"field\": \"value2\" \"field\": \"value2\" \"field\": \"value2\" No difference. \n \"field\": [] \"field\": [] N/A v1 retains the empty array. v2 skips the field with the empty array altogether. \n \"field\": [ \"value4\" ] \"field\": [ \"value4\" ] \"field\": \"value4\" v1 retains the singleton array. v2 converts the singleton array into the value only; it is not stored as part of an array. \n \"field\": [ 1, 2, 3 ] \"field\": [ 1, 2, 3 ] \"field\": [ 1, 2, 3 ] No difference. \n \"field\": [ \"v6\", \"v7\", \"v8\" ] \"field\": [ \"v6\", \"v7\", \"v8\"] \"field\": [ \"v6\", \"v7\", \"v8\"] No difference. \n\n\n\n\n\n\n\n\n\n\n\n Verifying that your data was migrated successfully", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-migrate-to-v2"}, {"document_id": "ibmcld_00623-7-1781", "score": 15.216602, "text": "\nWorking with IBM Cloudant Query \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Query is a declarative JSON querying syntax for IBM Cloudant databases. You can use a json or text type of index with IBM Cloudant.\n\nIn the following cases, you can specify how the index is created by making it of type json:\n\n\n\n* You know exactly what data you want to look for.\n* You want to keep storage and processing requirements to a minimum.\n\n\n\nBut for maximum flexibility when you search for data, you typically create an index of type text. Indexes of type text have a simple mechanism for automatically indexing all the fields in the documents.\n\nWhile more flexible, text indexes might take longer to create and require more storage resources than json indexes.\n\n\n\n Creating an index \n\nYou can create an index with one of the following types:\n\n\n\n* \"type\": \"json\"\n* \"type\": \"text\"\n\n\n\n\n\n Creating a type=json index \n\nTo create a JSON index in the database $DATABASE, make a POST request to /$DATABASE/_index with a JSON object that describes the index in the request body. The type field of the JSON object must be set to json. A JSON index can be partitioned or global; this option is set by using the partitioned field.\n\nSee the following example that uses HTTP to request an index of type JSON:\n\nPOST /$DATABASE/_index HTTP/1.1\nContent-Type: application/json\n\nSee the following example of a JSON object that creates a partitioned index that is called foo-partitioned-index for the field called foo:\n\n{\n\"index\": {\n\"fields\": [\"foo\"]\n},\n\"name\" : \"foo-partitioned-index\",\n\"type\" : \"json\",\n\"partitioned\": true\n}\n\nSee the following example of a JSON object that creates a global index that is called bar-global-index for the field called bar:\n\n{\n\"index\": {\n\"fields\": [\"bar\"]\n},\n\"name\" : \"bar-global-index\",", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-query"}, {"document_id": "ibmcld_07046-11817-13746", "score": 15.20302, "text": "\nHowever, a different document ID was assigned to it and stored in the parent_document_id field. The assigned document ID is what was returned when you called the List documents method and is what had to be used as the document_id in the endpoint URL for a Delete document method request. When you used the Update document method to assign a new document_id, the original ID continued to be returned in query results. However, the assigned ID had to be used to delete the document. If you have an application that relies on the previous behavior, you can specify a version number earlier than 2023-03-31, such as 2020-08-30, in your API calls.\n\n\n\nNotes about enhancing data:\n\n\n\n* You cannot apply prebuilt or user-trained Smart Document Understanding models to JSON files.\n* When you apply an enrichment to a field from the JSON file, the field data type is converted to an array. The field is converted to an array even if it contains a single value. For example, \"field1\": \"Discovery\" becomes \"field1\": [\"Discovery\"].\n* Only the first 50,000 characters of a custom field from a JSON file are enriched.\n* In project types where the Part of Speech (POS) enrichment is applied automatically, the enrichment is applied to the field that contains the bulk of the file content in the first JSON file that is added to the collection. This field is determined by the following rules:\n\n\n\n* If a field is named text, the POS enrichment is applied to it.\n* The field with the longest string value and highest number of distinct values is chosen.\n* If more than one field meets the previous condition, one of the fields is chosen at random.\n\n\n\n* If you want to apply an enrichment to a nested field, you must create a Content Mining project, and then apply the enrichment to the field. If you want to use a project type other than Content Mining, you can reuse the collection that you created with the Content Mining project type elsewhere.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-index-overview"}, {"document_id": "ibmcld_07103-1597-3698", "score": 15.038335, "text": "\nYou can now define JSON normalizations by using the Collections API\n: The Create a collection and Update a collection methods now support the addition of conversions and normalizations objects that you can specify to apply normalization operations to the documents in the collection. For example, you can define an operation to copy or merge one field to another in the JSON representation of the documents. The conversions object defines normalization operations that occur during ingestion and the normalizations object defines normalization operations that occur after enrichments are applied. For more information, see the [Collections API reference](https://cloud.ibm.com/apidocs/discovery-datalistcollections).\n\n\n\n\n\n 31 March 2023 \n\nUpdate to API version\n: The current API version (v2) is now 2023-03-31. One change was made with this version.\n\nChanged how fields named document_id are handled\n: If you add a JSON file that contains a field named document_id to a collection, the field is ignored. The system assigns a new unique document ID to the document when it is added to the index. To assign a document ID to a document regardless of its file type, use the Update document method from the API.\n\nPreviously, when you uploaded a JSON file with a field named document_id from the product user interface or by using the Add document API method, the document ID from the file was shown as the document_id value in query results. However, a different document ID was assigned to the document, and the assigned ID had to be used for certain other tasks, such as deleting the document. If your application relies on the previous behavior, specify a version number earlier than 2023-03-31, such as 2020-08-30, in your API calls.\n\n\n\n\n\n 2 March 2023 \n\nNow you can specify the types of files to add to a collection\n: When you connect to an external data source, you can limit the types of files to add to the collection from the external data source. For example, you can choose to add only PDF files from a Box data source.\n\n\n\n\n\n 21 Febuary 2023 \n\nOptical character recognition v2 technology is used", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-release-notes"}, {"document_id": "ibmcld_13074-20954-22489", "score": 14.740715, "text": "\n\"{field_name_N}\": {\n\"css_selector\": \"{CSS_selector_expression_N}\",\n\"type\": \"{field_type}\"\n}\n}\n...\n}\n}\n}\nShow more\n\nSpecify values for the new fields as follows:\n\n\n\n* field_name \u2014 The name of the field that you want to add to the JSON output.\n* CSS_selector_expression \u2014 The CSS selector that is to be run against the input HTML to extract the fields. The expression can have one or more matches.\n\nValid CSS selectors are those specified by the [JSoup parser](https://jsoup.org/apidocs/org/jsoup/select/Selector.html) and its [selector syntax](https://jsoup.org/cookbook/extracting-data/selector-syntax). A short list is provided at [Common selectors](https://cloud.ibm.com/docs/discovery?topic=discovery-configservicecommon-selectors).\n* field_type \u2014 Either array or string. If the field type is not specified, it defaults to array. Both the string and array types can be enriched.\n\n\n\nIf a CSS selector matches both a parent node and one or more of its children, the text content of the nodes are duplicated in the JSON output.\n\nField names must meet the restrictions defined in [Field name requirements](https://cloud.ibm.com/docs/discovery?topic=discovery-configreffield_reqs).\n\nThe following JSON passage shows the relevant section of the configuration to which you add CSS selector information.\n\n{\n\"name\": \"Default Configuration\",\n\"description\": \"The configuration used by default when creating a new collection without specifying a configuration_id.\",\n\"conversions\": {\n...\n\"html\": {\n\"exclude_tags_completely\": [\n\"script\",\n\"sup\"\n],", "title": "", "source": "https://cloud.ibm.com/docs/services/discovery?topic=discovery-configservice"}, {"document_id": "ibmcld_07140-11001-12762", "score": 14.635393, "text": "\n* \"{field_name}\" - The name of the field to be created.\n\n\n\nField names defined in your configuration must meet the restrictions defined in [Field Name Requirements](https://cloud.ibm.com/docs/discovery?topic=discovery-configreffield_reqs).\n\n\n\n* \"css_selector\" : stringrequired - a CSS selector expression that defines the area of content to be stored in a field.\n* \"type\" : stringrequired - The type of field to be created, can be string, date For detailed information, see [Using CSS selectors to extract fields](https://cloud.ibm.com/docs/discovery?topic=discovery-configserviceusing-css).\n\n\n\n\n\n\n\n\n\n Segment \n\nThe segment object is a set of configuration options that split ingested documents into one or more segments based on the identified HTML headings (h1, h2).\n\n\"segment\": {\n\"enabled\": true,\n\"selector_tags\": [\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"]\n}\n\n\n\n* \"enabled\": boolean - required - must be set to true to enable document segmentation.\n* \"selector_tags\": array - required - a comma separated array of HMTL h tags on which to split documents.\n\n\n\nAs an overview, when document segmentation is enabled the following cannot be specified:\n\n\n\n* json_normalizations cannot be specified as part of the configuration.\n* normalizations cannot be specified as part of the configuration.\n* The extracted_fields option of the html conversion cannot be specified as part of the configuration.\n\n\n\nFor detailed information, see [Performing segmentation](https://cloud.ibm.com/docs/discovery?topic=discovery-configserviceperforming-segmentation).\n\n\n\n\n\n JSON \n\nYou can perform pre-enrichment normalization of the ingested JSON by defining operation objects in the json_normalizations array.\n\n\"json_normalizations\": [\n{\n\"operation\": \"remove\",\n\"source_field\": \"header\"\n},", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-configref"}, {"document_id": "ibmcld_07046-13262-15106", "score": 14.270542, "text": "\n* The field with the longest string value and highest number of distinct values is chosen.\n* If more than one field meets the previous condition, one of the fields is chosen at random.\n\n\n\n* If you want to apply an enrichment to a nested field, you must create a Content Mining project, and then apply the enrichment to the field. If you want to use a project type other than Content Mining, you can reuse the collection that you created with the Content Mining project type elsewhere. For more information, see [Applying enrichments](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-connector-database-cp4dconnector-database-cp4d-enrich-db).\n\n\n\nYou can specify the normalizations and conversions objects in the [Update a collection](https://cloud.ibm.com/apidocs/discovery-dataupdatecollection) method of the API to move or merge JSON fields.\n\n\n\n\n\n\n\n How passages are derived \n\nDiscovery uses sophisticated algorithms to determine the best passages of text from all of the documents that are returned by a query. Passages are returned per document by default. They are displayed as a section within each document query result and are ordered by passage relevance.\n\nDiscovery uses sentence boundary detection to pick a passage that includes a full sentence. It searches for passages that have an approximate length of 200 characters, then looks at chunks of content that are twice that length to find passages that contain full sentences. Sentence boundary detection works for all supported languages and uses language-specific logic.\n\nFor all project types except Conversational Search, you can change how the passages are displayed in the search results from the Customize display > Search results page. For example, you can configure the number of passages that are shown per document and the maximum character size per passage.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-index-overview"}, {"document_id": "ibmcld_07067-16488-18275", "score": 14.210084, "text": "\nFor example, GET {url}/v1/environments/{environment_id}/collections/{collection_id}/query?q=.\n\nThe API returns the results. The matching_results field specifies the total number of results. The results object returns the matching documents. Each document is returned as a separate JSON object. It returns a maximum of 10 documents by default.\n\n{\n\"matching_results\": 34,\n\"session_token\": \"nnn\",\n\"results\": [\n{\"{result objects}\":\"{maximum of 10 by default}\"}\n]\n}\n2. You can use the count and offset parameters to page through the query results and save all of the documents.\n\nFor example, to get 100 documents at a time, you can set the count to 100 and offset to 0 and submit the query.\n\nGET {url}/v1/environments/{environment_id}/collections/{collection_id}/query?q=&count=100&offset=0\n\nNext, you can again set the count to 100, but this time set the offset to 100 to get the next 100 documents.\n\nGET {url}/v1/environments/{environment_id}/collections/{collection_id}/query?q=&count=100&offset=100\n\nRepeat this process, incrementing the offset by 100 until you retrieve all of the documents.\n3. Prepare the exported documents to be ingested into v2.\n\nEach resulting JSON file that you get from Discovery v1 contains data that is extracted from the original document, such as text, html, and other fields. If custom metadata was associated with the document when it was uploaded to v1, it is also present in the JSON file. In addition, the file contains several fields that were generated by the v1 analysis. Retain only a subset of this data as part of the document that you add to Discovery v2.\n\nThe following tips can help you decide which fields to keep:\n\n\n\n* Include the text field or any other field with textual content that you want to be able to enrich or search in Discovery v2.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-migrate-to-v2"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00556-7-1696", "score": 14.480358, "text": "\nHow to use attachments \n\nAnother way to store data is to use attachments. Attachments are Binary Large OBject ([BLOB](https://en.wikipedia.org/wiki/Binary_large_object)) files that are included within documents.\n\nIt's a good idea to keep attachments small in size and number because attachments can impact performance.\n\nThe BLOB is stored in the _attachments component of the document. The BLOB holds data that includes the following information:\n\n\n\n* The attachment name\n* The type of the attachment\n* The actual content\n\n\n\nExamples of BLOBs would be images and multimedia.\n\nIf you include the attachment as an [inline](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the overall JSON, the attachment content is represented by using BASE64 form.\n\nThe content type corresponds to a [MIME type](https://en.wikipedia.org/wiki/Internet_media_typeList_of_common_media_types). For example, if you want to attach a .jpg image file to a document, you specify the attachment MIME type as image/jpeg.\n\nAttachments aren't permitted on documents in [_replicator](https://cloud.ibm.com/apidocs/cloudantpostreplicate) or [_users](https://cloud.ibm.com/apidocs/cloudantputsecurity) databases.\n\n\n\n Create or update \n\nTo create a new attachment at the same time as creating a new document, include the attachment as an [inline](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the JSON content.\n\nTo create a new attachment on an existing document, or to update an attachment on a document, make a PUT request with the document's most recent _rev to https://$ACCOUNT.cloudant.com/$DATABASE/$DOCUMENT_ID/$ATTACHMENT.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-how-to-use-attachments"}, {"document_id": "ibmcld_06968-15099-17180", "score": 14.223956, "text": "\n[checkmark icon](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/icons/checkmark-icon.svg) \n\n\n\n\n\n* PDF files that are secured with a password or certificate are not supported. Vector objects, including SVG images and vectorized text, are not supported. Only images of the supported image file types that occur in the PDF are rendered.\n* Only single-page image files are supported.\n* Files within compressed archive files (ZIP, GZIP, TAR) are extracted. Discovery ingests the supported file types within the archive; it ignores all other file types. The file names must be encoded in UTF-8. Files with names that include Japanese characters, for example, must be renamed before they are added to the ZIP file.\n* Discovery supports MacOS ZIP files only if they are generated by using a command such as: zip -r my-folder.zip my-folder -x \".DS_Store\". ZIP files that are created by right-clicking a folder and clicking Compress are not supported.\n* PDF files that you upload as part of an archive file are not displayed in the advanced view for a query result that you open from the Improve and customize page. If you want the file to be viewable from the advanced view, reimport the PDF file separately from the archive file.\n\n\n\nWhen you add files to a Document Retrieval for Contracts project type, any file types that support SDU and OCR are processed with a pretrained Smart Document Understanding model and Optical Character Recognition automatically.\n\n\n\n\n\n Document limits \n\nThe number of documents that are allowed per service instance depends on your Discovery plan type.\n\nThe document limit applies to the number of documents in the index. Upload fewer documents at the start if the enrichments that you plan to apply might increase the number of documents later. For example, the following configurations generate more documents:\n\n\n\n* Splitting documents segments one document into multiple documents\n* CSV files that you upload generate one document per line\n* Database data sources that you crawl produce one document per database row", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-collections"}, {"document_id": "ibmcld_16358-3407-5152", "score": 13.925409, "text": "\nSplitting the PDF creates two smaller files that can be enriched faster in Discovery.\n\n\n\n\n\n\n\n Step 2: Create a Document Retrieval project \n\nNow that you have the latest copy of the product documentation, add it to a Discovery project as your data source.\n\nIn Discovery, you will create a Document Retrieval project type. Documents that you add to a project of this type are automatically enriched in the following ways:\n\n\n\n* Entities, such as proper nouns, are identified and tagged.\n* Parts of speech are identified and tagged.\n\n\n\nThis tagged information is used later when a natural language phrase is submitted as a search query to return an accurate response.\n\n\n\n1. Open a new web browser page.\n2. From the Discovery Plus plan service page in IBM Cloud, click Launch Discovery.\n3. From the My Projects page, click New Project.\n4. Name your project Discovery documentation, and then click the Document Retrieval tile.\n\nZoom\n\n![Shows the project type options](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/tut-neural-new-project.png)\n\nFigure 1. Project type options\n5. Click Next.\n\n\n\nYou'll configure the data source for the project in the next step.\n\n\n\n\n\n Step 3: Upload data to the project \n\nAdd the documentation PDFs to your Discovery project.\n\n\n\n1. From the Select data source page, click the Upload data tile, and then click Next.\n\nZoom\n\n![Shows that the Upload data option is chosen from the data sources page](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/tut-neural-data-source.png)\n\nFigure 2. Creating a collection from uploaded data\n2. Name the collection Discovery docs part 1, and then click Next.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-tutorial-neuralseek"}, {"document_id": "ibmcld_00556-10831-12062", "score": 13.626672, "text": "\nThe content must be provided by using [BASE64](https://en.wikipedia.org/wiki/Base64) representation, as shown in the example.\n\nA full list of media types is available in the [media types](https://en.wikipedia.org/wiki/Internet_media_typeList_of_common_media_types) article.\n\nSee the following example JSON document that includes an inline attachment of a jpeg image:\n\n{\n\"_id\":\"document_with_attachment\",\n\"_attachments\":\n{\n\"name_of_attachment\": {\n\"content_type\":\"image/jpeg\",\n\"data\": \"iVBORw0KGgoAA... ...AASUVORK5CYII=\"\n}\n}\n}\n\n\n\n\n\n Performance considerations \n\nWhile document attachments are useful, they do have implications for application performance. In particular, having too many attachments can have an adverse performance impact during replication.\n\nFor example, if your application requires storage for multiple images as attachments or includes large images, you must use an alternative [BLOB](https://en.wikipedia.org/wiki/Binary_large_object) storage mechanism to store the images. You might then use IBM Cloudant to keep the image metadata, such as URLs to the BLOB store.\n\nYou might find it helpful to do performance testing for your specific application to determine which approach works best for your circumstances.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-how-to-use-attachments"}, {"document_id": "ibmcld_16358-7447-9162", "score": 13.335744, "text": "\nBefore we add anything to our new assistant, let's check on the status of our data.\n\n\n\n\n\n Step 5: Prepare your data for retrieval \n\nTo improve the retrievability of the information in your PDF files, you will split the PDF files into many smaller documents. To do so, you will first teach Discovery about the structure of your PDF files, so it understands how subsections are formatted and can split the document by subsection.\n\n\n\n1. Return to the web browser tab where your Discovery project is displayed.\n\nThe Improve and customize page for the last PDF file that you uploaded is displayed.\n2. From the Improvement tools panel, expand Define structure, and then click New fields.\n\nZoom\n\n![Shows the chat bot preview in a fake web page](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/tut-neural-new-fields.png)\n\nFigure 5. Opening the tool for defining fields\n3. Choose the Discovery docs part 1 collection.\n\nThe Identify fields tab is displayed, where you can choose the type of Smart Document Understanding model that you want to use.\n4. Click User-trained models, and then click Submit.\n\nZoom\n\n![Shows the chat bot preview in a fake web page](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/tut-neural-user-trained.png)\n\nFigure 6. Creating a user-trained model\n5. Click Apply changes and reprocess.\n\nAfter some processing occurs, a representation of the document is displayed in the Smart Document Understanding tool. The tool shows you a view of the original document along with a representation of the document, where the text is replaced by blocks. The blocks represent field types.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-tutorial-neuralseek"}, {"document_id": "ibmcld_16423-3286-5408", "score": 13.101558, "text": "\nUpload one CSV file at a time. The first column in the CSV file specifies the file name of the document. The second column in the file contains the document text. For an example of the required format, see the [documents-new.csv](https://watson-developer-cloud.github.io/doc-tutorial-downloads/knowledge-studio/documents-new.csv) file in the tutorial sample files.\n\n\n\n\n\n PDF files \n\nText cannot be extracted from a PDF in some cases, depending on how the PDF was created. Typically, text can't be extracted from embedded fonts that don't map to unicode characters. If you are unsure whether text from a PDF can be extracted, you can try copying the text from the PDF and then pasting it into a text editor. If you do not see the same characters that are visible in the PDF itself, then the text extraction would likely fail.\n\n\n\n\n\n Formatted documents \n\nWhen formatted documents are converted to plain text, it's possible that losing the formatting could result in poor tokenization of words. For example, if a table row in a DOCX file contains cell values that do not end with a period, the values might be converted as one sentence. As another example, if a PDF document contains a very long word that is hyphenated at the end of a line, that word might be converted as two words. In cases like these, the documents might not be suitable for machine learning unless you pre-process the files to fix formatting limitations.\n\n\n\n\n\n Documents from another Watson Knowledge Studio workspace \n\nIf you previously downloaded documents from a Knowledge Studio workspace, you can upload the ZIP file that you downloaded. An option lets you specify whether you want the ground truth annotations to be included in the imported files.\n\nAfter documents are annotated, the annotated documents are stored in JSON format. The markup language in these files, which shows how the original document text was parsed and tokenized, includes elements for all of the annotations that a human annotator added. To improve model accuracy over time, you can upload these files into another workspace, thus preserving all of the existing annotations.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotation"}, {"document_id": "ibmcld_07224-1506-3498", "score": 13.077663, "text": "\nPNG, TIFF, and JPEG images embedded in PDF, Word, PowerPoint, and Excel files are also scanned and the text, if any, is extracted.\n\n\n\n\n\n Using the Smart Document Understanding editor \n\nThe SDU editor is only available for collections that contain supported document types and do not have the Element Classification enrichment applied. If you do not want to use the SDU editor, you can set up your configuration using the API, see the [API reference](https://cloud.ibm.com/apidocs/discovery/).\n\nThe SDU editor functions are only available in the Discovery tooling, they are not available in the API.\n\nNavigating the Smart Document Understanding editor:\n\nIf you did not yet create a Discovery instance and environment, see [Getting started](https://cloud.ibm.com/docs/discovery?topic=discovery-getting-started) for instructions.\n\n\n\n1. On the Manage Data screen, click Upload your own data, and create a new private collection in Discovery.\n2. Drag and drop documents into your collection, or click select documents to upload documents. After the upload is complete, this information displays:\n\n\n\n* The fields identified from your documents.\n* Enrichments applied to your documents. The Entity Extraction, Sentiment Analysis, Category Classification, and Concept Tagging enrichments are automatically applied to the text field by Discovery (unless you are importing documents using a connector). You can add (or remove) additional enrichments to the text (and other) fields.\n* Pre-built queries you can run immediately.\n\n\n\n3. Click Configure data on the upper right. On the Configure data screen, there are three tabs: Identify fields, Manage fields, and Enrich fields.\n\n\n\n* Identify fields contains the SDU editor.\n* Manage fields lists all indexed fields (all fields are indexed by default). Switch off any fields you do not want to index. For example, your PDFs might contain a running header or footer that does not contain useful information, so you can exclude those fields from the index.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-sdu"}, {"document_id": "ibmcld_08937-7-1991", "score": 12.986247, "text": "\nExporting an image to IBM Cloud Object Storage \n\nFrom the Image Templates page, you can export an image template to an [IBM Cloud\u00ae Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-about-cloud-object-storage) account.\n\nThe image export process takes a preexisting, private standard image template, or an encrypted image template and coverts the image into an image file that is stored in a specified location on an IBM Cloud Object Storage account.\n\nIf you imported a VMDK image, you can export that image in VHD or VMDK format. Because of the differences between the image formats, a chance of data loss exists. To protect your data if data loss occurs, the original VHD file is retained.\n\n\n\n Before you begin \n\nFirst, go to the device menu and make sure that you have the correct account permissions to complete the tasks.\n\n\n\n* Go to your console's device menu. For more information, see [Navigating to devices](https://cloud.ibm.com/docs/image-templates?topic=virtual-servers-navigating-devices).\n* Make sure that you have write access to IBM Cloud Object Storage. Only the account owner, or a user with the Manage Users classic infrastructure permission, can adjust the permissions.\n\n\n\nFor more information about permissions, see [Classic infrastructure permissions](https://cloud.ibm.com/docs/account?topic=account-infrapermissioninfrapermission) and [Managing device access](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-managing-device-access).\n\nIf you plan to export this image template to IBM Cloud Object Storage, make sure the image template name does not contain any characters that can be problematic in a web address. For example, ?, =, <, and other special characters might cause unwanted behavior if not URL-encoded.\n\n\n\n\n\n Exporting an image to IBM Cloud Object Storage \n\nUse the following steps to export an image template to IBM Cloud Object Storage.\n\n\n\n1. From the Devices menu, select Manage > Images.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/image-templates?topic=image-templates-exporting-an-image-to-ibm-cloud-object-storage"}, {"document_id": "ibmcld_07224-3070-4970", "score": 12.818713, "text": "\nOn the Configure data screen, there are three tabs: Identify fields, Manage fields, and Enrich fields.\n\n\n\n* Identify fields contains the SDU editor.\n* Manage fields lists all indexed fields (all fields are indexed by default). Switch off any fields you do not want to index. For example, your PDFs might contain a running header or footer that does not contain useful information, so you can exclude those fields from the index. You can also split documents here, based on fields, see [Splitting documents](https://cloud.ibm.com/docs/discovery?topic=discovery-sdusplitting).\n* Enrich fields is identical to the Enrich tab on the original screen. For more information about enrichments, see [Adding enrichments](https://cloud.ibm.com/docs/discovery?topic=discovery-configserviceadding-enrichments). The Upload sample documents option is not available with SDU collections.\n\n\n\nIf you did not upload any documents earlier, return to the Overview screen by clicking the name of your collection in the upper left, or click the ![Manage Data](https://cloud.ibm.com/docs-content/v1/content/ded4adc3ea0bd2a81b113c579f2b1183926da211/discovery//images/icon_yourData.png) icon and choose your collection. Drag and drop documents into your collection, or click browse from computer. After you initially upload your documents, the Upload documents button displays on the upper right.\n4. Open the Identify fields tab. A subset of documents will be available for annotation purposes, between 20 - 50 documents will appear in the dropdown list. The number will depend on several factors, including the number of documents in your collection in the supported file formats.\n\n\n\nYou can use the toolbar at the top to complete the following actions:\n\n\n\n* Choose a document to annotate\n* Navigate the document displayed\n* Adjust the page view (single page view, zoom in, zoom out), clear changes, and export/import models.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-sdu"}, {"document_id": "ibmcld_16358-13647-15380", "score": 12.7227545, "text": "\nNow that subtitles are indexed properly in Discovery, use them as the basis for splitting the PDF files into many smaller documents.\n\n\n\n1. Return to the web browser tab where your Discovery project is displayed.\n2. Open the Manage fields tab for the current collection.\n3. In the Split document on each occurrence of field, choose subtitle, and then click Apply changes and reprocess.\n\nZoom\n\n![Shows the split by field option in Discovery](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/tut-neural-split-doc.png)\n\nFigure 10. Split a document\n4. From the navigation panel, click Manage collections, and then open the other collection.\n5. Go to the Manage fields page, and then choose subtitle in the Split document on each occurrence of field.\n6. Click Apply changes and reprocess.\n\n\n\nThe collections start to be reprocessed. After reindexing is finished, instead of containing one document each, the collections will contain several hundred documents each.\n\nZoom\n\n![Shows the collections with many documents](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/tut-neural-both-collections.png)\n\nFigure 11. The collections with more documents\n\nWhile the index is being rebuilt, let's get our assistant ready.\n\n\n\n\n\n Step 8: Add an extension to your assistant \n\nConnect your assistant to your NeuralSeek service instance.\n\n\n\n1. Reopen the NeuralSeek service from IBM Cloud. You can find the instance in the AI and Machine Learning section of your [resource list](https://cloud.ibm.com/resources).\n2. Click the Integrate tab and follow the instructions to set up the NeuralSeek custom extension for your assistant.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-tutorial-neuralseek"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_06968-16615-18789", "score": 24.214975, "text": "\nThe number of documents that are allowed per service instance depends on your Discovery plan type.\n\nThe document limit applies to the number of documents in the index. Upload fewer documents at the start if the enrichments that you plan to apply might increase the number of documents later. For example, the following configurations generate more documents:\n\n\n\n* Splitting documents segments one document into multiple documents\n* CSV files that you upload generate one document per line\n* Database data sources that you crawl produce one document per database row\n* Each object that is defined in an array in a JSON file results in a separate document\n\n\n\n\n\nNumber of documents per service instance\n\n Plan Documents per service instance \n\n Cloud Pak for Data Unlimited \n Premium Unlimited \n Enterprise Unlimited \n Plus (includes Trial) 500,000 \n\n\n\nThe maximum allowed number can vary slightly depending on the size of the documents. Use these values as a general guideline.\n\n\n\n\n\n File size limits \n\n\n\n Crawled documents \n\nThe maximum size of each file that you can crawl by using a connector differs by deployment type.\n\nIBM Cloud\n\nManaged deployments on IBM Cloud\n\n\n\n* Premium plans only:\n\n\n\n* Box: 50 MB\n* IBM Cloud Object Store: 50 MB\n* Salesforce Files objects: 50 MB\n* All other data sources: 10 MB\n\n\n\n* All other plans: 10 MB\n\n\n\nIBM Cloud Pak for Data\n\nInstalled deployments on IBM Cloud Pak for Data\n\n\n\n* All data sources: 32 MB\n\n\n\n\n\n\n\n Uploaded documents \n\nThe size of each file that you can upload depends on your Discovery plan type. See the *Maximum document size table for details.\n\n\n\nMaximum document size\n\n Plan File size per document \n\n Cloud Pak for Data 50 MB \n Premium 50 MB \n Enterprise 10 MB \n Plus (includes Trial) 10 MB \n\n\n\n\n\n\n\n\n\n Field limits \n\nWhen a document is added to a collection, content from the document is evaluated and added to the appropriate fields in an internal index.\n\nFor structured data, such as uploaded CSV or JSON files, or data from crawled databases, each column or object is stored as a root-level field. For example, if you add a CSV file to collection, each column in the CSV file is stored as a separate field in the index.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-collections"}, {"document_id": "ibmcld_06968-18330-20453", "score": 23.394022, "text": "\nPlus (includes Trial) 10 MB \n\n\n\n\n\n\n\n\n\n Field limits \n\nWhen a document is added to a collection, content from the document is evaluated and added to the appropriate fields in an internal index.\n\nFor structured data, such as uploaded CSV or JSON files, or data from crawled databases, each column or object is stored as a root-level field. For example, if you add a CSV file to collection, each column in the CSV file is stored as a separate field in the index.\n\nA maximum of 1,000 fields can be added to the index.\n\nYou cannot assign the data type, such as Date or String, of a field. The data type is detected automatically and assigned to the field during document ingestion. The assignment is based on the data type that is detected from the first document that is indexed. Ingestion errors can occur in subsequent documents if a different data type is detected for the value in the same field. Therefore, if your documents have a mix of data types in a single field, first ingest the document that has a value with the most flexible data type, such as String, in the field.\n\nWhen you crawl a website or upload an HTML file, the HTML content is added to the collection and indexed in an html field.\n\nThe following table shows the maximum size limit for fields per document.\n\n\n\nMaximum field sizes\n\n Field type Maximum allowed size per document \n\n html field 5 MB \n Sum of all other fields 1 MB \n\n\n\nIf the maximum size of the fields in the document exceeds the allowed limits, they are treated as follows:\n\n\n\n* For a document with an oversized html field, all of the fields in the document are indexed except the html field.\n\nFor IBM Cloud Pak for Data version 4.0 and earlier, the entire document is not indexed.\n* For a document with oversized non-HTML fields, the document is not indexed.\n\n\n\nIf you are uploading a Microsoft Excel file and a message is displayed that indicates that the non-HTML field size limit is exceeded, consider converting the XLS file into a CSV file. When you upload a comma-separated value (CSV) file, each row is indexed as a separate document. As a result, no field size limits are exceeded.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-collections"}, {"document_id": "ibmcld_16727-1272819-1274596", "score": 23.220064, "text": "\nAny volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760 \n 80 GB 20,971,520 \n 100 GB 26,214,400 \n 500 GB 131,072,000 \n 1 TB 268,435,456 \n 4 TB 1,073,741,824 \n 8 TB 2,040,109,451 \n 12 TB 2,040,109,451 \n\n\n\n* I ordered a File Storage for Classic volume in the wrong data center. Is it possible to move or migrate it to another data center?\n\nYou need to order new File Storage for Classic in the right data center, and then cancel the File Storage for Classic device that you ordered in the incorrect location. When the volume is canceled, the request is followed by a 24-hour reclaim wait period. You can still see the volume in the console during those 24 hours. Billing for the volume stops immediately. When the reclaim period expires, the data is destroyed and the volume is removed from the console, too.\n* Measuring IOPS\n\nIOPS is measured based on a load profile of 16-KB blocks with random 50 percent reads and 50 percent writes. Workloads that differ from this profile might experience poor performance. To improve performance, you can try adjusting the host settings or [enabling Jumbo frames](https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-jumboframes).\n* What happens when I use a smaller block size for measuring performance?\n\nMaximum IOPS can be obtained even if you use smaller block sizes. However, the throughput is less in this case. For example, a volume with 6000 IOPS has the following throughput at various block sizes:\n\n\n\n* 16 KB * 6000 IOPS == 93.75 MB/sec", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-1270170-1271947", "score": 23.220064, "text": "\nAny volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760 \n 80 GB 20,971,520 \n 100 GB 26,214,400 \n 500 GB 131,072,000 \n 1 TB 268,435,456 \n 4 TB 1,073,741,824 \n 8 TB 2,040,109,451 \n 12 TB 2,040,109,451 \n\n\n\n* I ordered a File Storage for Classic volume in the wrong data center. Is it possible to move or migrate it to another data center?\n\nYou need to order new File Storage for Classic in the right data center, and then cancel the File Storage for Classic device that you ordered in the incorrect location. When the volume is canceled, the request is followed by a 24-hour reclaim wait period. You can still see the volume in the console during those 24 hours. Billing for the volume stops immediately. When the reclaim period expires, the data is destroyed and the volume is removed from the console, too.\n* Measuring IOPS\n\nIOPS is measured based on a load profile of 16-KB blocks with random 50 percent reads and 50 percent writes. Workloads that differ from this profile might experience poor performance. To improve performance, you can try adjusting the host settings or [enabling Jumbo frames](https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-jumboframes).\n* What happens when I use a smaller block size for measuring performance?\n\nMaximum IOPS can be obtained even if you use smaller block sizes. However, the throughput is less in this case. For example, a volume with 6000 IOPS has the following throughput at various block sizes:\n\n\n\n* 16 KB * 6000 IOPS == 93.75 MB/sec", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_01245-4-1307", "score": 22.419353, "text": "\n* CLI\n* API\n\n\n\n\n\n\n\n Managing storage limits \n\nBy default, you can provision a combined total of 700 Block Storage for Classic and File Storage for Classic volumes globally. By following this process, you can increase the number of volumes you can provision.\n\nFor more information about increasing your storage volume capacity beyond 12 TB, see [expanding File Storage for Classic capacity](https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-expandCapacityincreasecapacityover12TB).\n\nIf you're unsure how many volumes you have, you can confirm the numbers by using multiple methods.\n\n\n\n Confirming your current limit and provisioning count from the CLI \n\n\n\n SLCLI \n\nYou can list the number of your volumes by using the [volume-limits](https://softlayer-python.readthedocs.io/en/latest/cli/file/file-volume-limits) command in slcli (version 5.8.5 or higher).\n\n slcli file volume-limits\n\nThe output looks similar to the following example.\n\n[{'datacenterName': 'global', 'maximumAvailableCount': 700, 'provisioned Count':117}]\n:............:.......................:..................:\n: Datacenter : maximumAvailableCount : ProvisionedCount :\n:............:.......................:..................:\n: global : 700 : 117 :\n:............:.......................:..................:\n\n\n\n\n\n IBM Cloud CLI", "title": "", "source": "https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-managinglimits"}, {"document_id": "ibmcld_07578-1268470-1270517", "score": 22.199572, "text": "\nYou can also access the correct mount point through an API call: SoftLayer_Network_Storage::getNetworkMountAddress().\n* How many volumes can I provision?\n\nBy default, you can provision a combined total of 700 Block and File Storage for Classic volumes. To increase your limit, contact your sales representative. For more information, see [Managing storage limits](https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-managinglimits).\n* How many instances can share the use of a provisioned File Storage for Classic volume?\n\nThe default limit for number of authorizations per file volume is 64. To increase this limit, contact your sales representative.\n* How many File Storage for Classic volumes can be attached to a single host?\n\nThat depends on what the host operating system can handle, it\u2019s not something that IBM Cloud\u00ae limits. Refer to your OS Documentation for limits on the number of file shares that can be mounted.\n* How many files and directories are allowed for specific file volume sizes? What is the maximum number of inodes allowed per volume size?\n\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger. The maximum number of inodes that can be configured on a volume is calculated by taking the total allocated volume size in KB and dividing it by 4. Any volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1271119-1273166", "score": 22.199572, "text": "\nYou can also access the correct mount point through an API call: SoftLayer_Network_Storage::getNetworkMountAddress().\n* How many volumes can I provision?\n\nBy default, you can provision a combined total of 700 Block and File Storage for Classic volumes. To increase your limit, contact your sales representative. For more information, see [Managing storage limits](https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-managinglimits).\n* How many instances can share the use of a provisioned File Storage for Classic volume?\n\nThe default limit for number of authorizations per file volume is 64. To increase this limit, contact your sales representative.\n* How many File Storage for Classic volumes can be attached to a single host?\n\nThat depends on what the host operating system can handle, it\u2019s not something that IBM Cloud\u00ae limits. Refer to your OS Documentation for limits on the number of file shares that can be mounted.\n* How many files and directories are allowed for specific file volume sizes? What is the maximum number of inodes allowed per volume size?\n\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger. The maximum number of inodes that can be configured on a volume is calculated by taking the total allocated volume size in KB and dividing it by 4. Any volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_16483-8083-9756", "score": 21.928333, "text": "\nDictionary file:<br><br><br><br> * CSV file in UTF-8 format<br> * ZIP of dictionaries downloaded from another workspace<br><br><br><br>Term entries file:<br><br><br><br> * CSV file in UTF-8 format<br><br><br> <br><br> * CSV file in UTF-8 format<br> * ZIP of dictionaries to use in another workspace<br><br><br> File size limitations:<br><br><br><br> * 1 MB per CSV term entries file<br> * 16 MB per CSV read-only dictionary file<br> * 15,000 entries per dictionary, except a read-only dictionary<br> * 64 dictionaries per workspace<br><br><br> \n\n\n\n\n\n\n\n Machine learning model \n\nTable 2: Machine learning model\n\n\n\n Task Typical usage Supported input formats Supported output formats Limits and requirements \n\n Document management Upload a small, representative subset of documents Upload documents that contain annotations previously added by a human annotator, a machine learning model, or a UIMA analysis engine You cannot ingest the entire corpus from IBM Watson Explorer for calculating high value documents for annotation. <br><br> * CSV file in UTF-8 format<br> * Text in UTF-8 format<br> * HTML<br> * PDF files (scanned and password-protected files are not supported)<br> * Microsoft Word DOC or DOCX files (password-protected files are not supported)<br> * ZIP file that contains documents downloaded from another workspace<br> * ZIP file that contains documents in UIMA CAS XMI format<br><br><br> ZIP archive file of documents <br><br> * 40,000 characters per document<br> * 10,000 documents per workspace<br> * 1,000 document sets (including annotation sets) per workspace<br> * 5 MB per file and 200 MB per upload (TXT, PDF, DOC, DOCX, and HTML files)<br><br><br>", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-create-project"}, {"document_id": "ibmcld_16420-7872-9592", "score": 21.67219, "text": "\nDictionary file:<br><br><br><br> * CSV file in UTF-8 format<br> * ZIP of dictionaries downloaded from another workspace<br><br><br><br>Term entries file:<br><br><br><br> * CSV file in UTF-8 format<br><br><br> <br><br> * CSV file in UTF-8 format<br> * ZIP of dictionaries to use in another workspace<br><br><br> File size limitations:<br><br><br><br> * 1 MB per CSV term entries file<br> * 16 MB per CSV read-only dictionary file<br> * 15,000 entries per dictionary, except a read-only dictionary<br> * 64 dictionaries per workspace<br><br><br> \n\n\n\n\n\n\n\n Machine learning model \n\nTable 2: Machine learning model\n\n\n\n Task Typical usage Supported input formats Supported output formats Limits and requirements \n\n Document management Upload a small, representative subset of documents Upload documents that contain annotations previously added by a human annotator, a machine learning model, or a UIMA analysis engine You cannot ingest the entire corpus from IBM Watson Explorer for calculating high value documents for annotation. <br><br> * CSV file in UTF-8 format<br> * Text in UTF-8 format<br> * HTML<br> * PDF files (scanned and password-protected files are not supported)<br> * Microsoft Word DOC or DOCX files (password-protected files are not supported)<br> * ZIP file that contains documents downloaded from another workspace<br> * ZIP file that contains documents in UIMA CAS XMI format<br><br><br> ZIP archive file of documents <br><br> * 40,000 characters per document<br> * 10,000 documents per workspace<br> * 1,000 document sets (including annotation sets) per workspace<br> * 5 MB per file and 200 MB per upload (TXT, PDF, DOC, DOCX, and HTML files)<br><br><br> \n Document annotation Manage human annotation.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-creating-a-workspace"}, {"document_id": "ibmcld_01232-3064-5002", "score": 21.56199, "text": "\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger. The maximum number of inodes that can be configured on a volume is calculated by taking the total allocated volume size in KB and dividing it by 4. Any volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760 \n 80 GB 20,971,520 \n 100 GB 26,214,400 \n 500 GB 131,072,000 \n 1 TB 268,435,456 \n 4 TB 1,073,741,824 \n 8 TB 2,040,109,451 \n 12 TB 2,040,109,451 \n\n\n\n\n\n\n\n I ordered a File Storage for Classic volume in the wrong data center. Is it possible to move or migrate it to another data center? \n\nYou need to order new File Storage for Classic in the right data center, and then cancel the File Storage for Classic device that you ordered in the incorrect location. When the volume is canceled, the request is followed by a 24-hour reclaim wait period. You can still see the volume in the console during those 24 hours. Billing for the volume stops immediately. When the reclaim period expires, the data is destroyed and the volume is removed from the console, too.\n\n\n\n\n\n Measuring IOPS \n\nIOPS is measured based on a load profile of 16-KB blocks with random 50 percent reads and 50 percent writes. Workloads that differ from this profile might experience poor performance.", "title": "", "source": "https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-file-storage-faqs"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00556-7-1696", "score": 16.239052, "text": "\nHow to use attachments \n\nAnother way to store data is to use attachments. Attachments are Binary Large OBject ([BLOB](https://en.wikipedia.org/wiki/Binary_large_object)) files that are included within documents.\n\nIt's a good idea to keep attachments small in size and number because attachments can impact performance.\n\nThe BLOB is stored in the _attachments component of the document. The BLOB holds data that includes the following information:\n\n\n\n* The attachment name\n* The type of the attachment\n* The actual content\n\n\n\nExamples of BLOBs would be images and multimedia.\n\nIf you include the attachment as an [inline](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the overall JSON, the attachment content is represented by using BASE64 form.\n\nThe content type corresponds to a [MIME type](https://en.wikipedia.org/wiki/Internet_media_typeList_of_common_media_types). For example, if you want to attach a .jpg image file to a document, you specify the attachment MIME type as image/jpeg.\n\nAttachments aren't permitted on documents in [_replicator](https://cloud.ibm.com/apidocs/cloudantpostreplicate) or [_users](https://cloud.ibm.com/apidocs/cloudantputsecurity) databases.\n\n\n\n Create or update \n\nTo create a new attachment at the same time as creating a new document, include the attachment as an [inline](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the JSON content.\n\nTo create a new attachment on an existing document, or to update an attachment on a document, make a PUT request with the document's most recent _rev to https://$ACCOUNT.cloudant.com/$DATABASE/$DOCUMENT_ID/$ATTACHMENT.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-how-to-use-attachments"}, {"document_id": "ibmcld_00556-1255-2941", "score": 13.972688, "text": "\nTo create a new attachment at the same time as creating a new document, include the attachment as an [inline](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the JSON content.\n\nTo create a new attachment on an existing document, or to update an attachment on a document, make a PUT request with the document's most recent _rev to https://$ACCOUNT.cloudant.com/$DATABASE/$DOCUMENT_ID/$ATTACHMENT. The attachment's [content type](https://en.wikipedia.org/wiki/Internet_media_typeList_of_common_media_types) must be specified by using the Content-Type header. The $ATTACHMENT value is the name by which the attachment is associated with the document.\n\nYou can create more than one attachment for a document by ensuring that the $ATTACHMENT value for each attachment is unique within the document.\n\nSee the following example for creating or updating an attachment by using HTTP:\n\nPUT /$DATABASE/$DOCUMENT_ID/$ATTACHMENT?rev=$REV HTTP/1.1\nContent-Type: $$ATTACHMENT_MIME_TYPE\n\nSee the following example for creating or updating an attachment:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -H \"Authorization: Bearer $API_BEARER_TOKEN\" -X PUT \"$SERVICE_URL/products/small-appliances:100001/product_details.txt\" -H \"Content-Type: text/plain\" --data 'This appliance includes...'\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.DocumentResult;\nimport com.ibm.cloud.cloudant.v1.model.PutAttachmentOptions;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.InputStream;\nimport java.nio.charset.StandardCharsets;\n\nCloudant service = Cloudant.newInstance();\n\nString detailedDescription = \"This appliance includes...\"", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-how-to-use-attachments"}, {"document_id": "ibmcld_00625-3455-5153", "score": 13.084638, "text": "\n\"productid\": \"1000042\",\n\"taxonomy\": [\n\"Home\",\n\"Kitchen\",\n\"Small Appliances\"\n],\n\"type\": \"product\"\n}\nShow more\n\n\n\n Query parameters \n\nYou can add some query parameters to the URL, for example /mydatabase/doc?attachments=true&conflicts=true.\n\nAll parameters are optional.\n\n\n\nTable 1. Query parameters\n\n Name Type Description Default \n\n attachments Boolean Includes attachments bodies in response. False \n att_encoding_info Boolean Includes encoding information in attachment stubs if the particular attachment is compressed. False \n atts_since Array of revision strings Includes attachments only since specified revisions. Doesn't include attachments for specified revisions. [] \n conflicts Boolean Includes information about conflicts in documents. False \n deleted_conflicts Boolean Includes information about deleted conflicted revisions. False \n latest Boolean Forces retrieval of the most recent \"leaf\" revision, no matter what revision was requested. False \n local_seq Boolean Includes last update sequence number for the document. False \n meta Boolean Same as specifying the conflicts, deleted_conflicts, and open_revs query parameters. False \n open_revs Array or all Retrieves documents of specified leaf revisions. Additionally, it accepts the value all to return all leaf revisions. [] \n rev String Retrieves document of specified revision. <br><br> * <br><br><br> \n revs Boolean Includes list of all known document revisions. False \n revs_info Boolean Includes detailed information for all known document revisions. False \n\n\n\n\n\n\n\n Read many \n\nTo fetch more than one document at a time, [query the database](https://cloud.ibm.com/apidocs/cloudantpostalldocs) by using the include_docs option.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-read-a-document"}, {"document_id": "ibmcld_00556-10831-12062", "score": 13.031241, "text": "\nThe content must be provided by using [BASE64](https://en.wikipedia.org/wiki/Base64) representation, as shown in the example.\n\nA full list of media types is available in the [media types](https://en.wikipedia.org/wiki/Internet_media_typeList_of_common_media_types) article.\n\nSee the following example JSON document that includes an inline attachment of a jpeg image:\n\n{\n\"_id\":\"document_with_attachment\",\n\"_attachments\":\n{\n\"name_of_attachment\": {\n\"content_type\":\"image/jpeg\",\n\"data\": \"iVBORw0KGgoAA... ...AASUVORK5CYII=\"\n}\n}\n}\n\n\n\n\n\n Performance considerations \n\nWhile document attachments are useful, they do have implications for application performance. In particular, having too many attachments can have an adverse performance impact during replication.\n\nFor example, if your application requires storage for multiple images as attachments or includes large images, you must use an alternative [BLOB](https://en.wikipedia.org/wiki/Binary_large_object) storage mechanism to store the images. You might then use IBM Cloudant to keep the image metadata, such as URLs to the BLOB store.\n\nYou might find it helpful to do performance testing for your specific application to determine which approach works best for your circumstances.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-how-to-use-attachments"}, {"document_id": "ibmcld_00523-10191-11663", "score": 12.67774, "text": "\n* Attachments aren't backed up by the tools.\n* Backups aren't precisely accurate \"point-in-time\" snapshots. The reason is that the documents in the database are retrieved in batches, but other applications might be updating documents at the same time. Therefore, the data in the database can change between the times when the first and last batches are read.\n* Index definitions held design documents are backed up, but when data is restored the indexes must be rebuilt. This rebuilding might take a considerable amount of time, depending on how much data is restored.\n\n\n\n\n\n\n\n Next steps with your data protection strategies \n\nYou can develop applications that build on basic IBM Cloudant functions and supported tools to enable more complex data protection strategies. Example scenarios are shown in the following list:\n\n\n\n* Restoring single documents from previous states.\n* Storing multiple previous document states to allow for restores from older backups.\n* Migrating older data to cheaper storage, for more cost-effective retention.\n\n\n\nThe backup tools consist of an open source node.js command-line application and library. It's available on [NPM](https://www.npmjs.com/package/@cloudant/couchbackup).\n\nFor ideas and examples that show how to integrate the tools into your data protection strategy, see the [IBM Cloudant backup and recovery guide](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery).", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-disaster-recovery-and-backup"}, {"document_id": "ibmcld_00450-14408-15485", "score": 12.372044, "text": "\n\"retries_per_request\": 20,\n\"http_connections\": 30\n}\n\n\n\n\n\n The effect of large attachments \n\nHaving large numbers of attachments on documents might cause an adverse effect on replication performance.\n\nFor more information about the effect of attachments on replication performance, see [Performance considerations](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-attachmentsperformance-considerations).\n\n\n\n Avoiding the /_replicate endpoint \n\nUse the [_replicator scheduler](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-advanced-replicationthe-replication-scheduler) instead of the /_replicate endpoint.\n\nIf a problem occurs during replication, such as a stall, timeout, or application crash, a replication that is defined within the _replicator database is automatically restarted by the system. However, if you define a replication by sending a request to the /_replicate endpoint, it can't be restarted by the system if a problem occurs because the replication request doesn't persist. Replications that are defined in the _replicator database are easier to monitor.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-advanced-replication"}, {"document_id": "ibmcld_00556-7864-9221", "score": 12.258098, "text": "\nTo delete an attachment, make a DELETE request with the document's most recent _rev to https://$ACCOUNT.cloudant.com/$DATABASE/$DOCUMENT_ID/$ATTACHMENT. If you don't supply the most recent _rev, the response is a [409 error](https://cloud.ibm.com/apidocs/cloudantlist-of-http-codes).\n\nSee the following example of deleting an attachment by using HTTP:\n\nDELETE /$DATABASE/$DOCUMENT_ID/$ATTACHMENT?rev=$REV HTTP/1.1\n\nSee the following example of deleting an attachment:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -H \"Authorization: Bearer $API_BEARER_TOKEN\" -X DELETE \"$SERVICE_URL/products/small-appliances:100001/product_details.txt?rev=4-1a0d1cd6f40472509e9aac646183736a\"\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.DeleteAttachmentOptions;\nimport com.ibm.cloud.cloudant.v1.model.DocumentResult;\n\nCloudant service = Cloudant.newInstance();\n\nDeleteAttachmentOptions attachmentOptions =\nnew DeleteAttachmentOptions.Builder()\n.db(\"products\")\n.docId(\"small-appliances:100001\")\n.attachmentName(\"product_details.txt\")\n.rev(\"4-1a0d1cd6f40472509e9aac646183736a\")\n.build();\n\nDocumentResult response =\nservice.deleteAttachment(attachmentOptions).execute()\n.getResult();\n\nSystem.out.println(response);\n\nfrom ibmcloudant.cloudant_v1 import CloudantV1\n\nservice = CloudantV1.new_instance()\n\nresponse = service.delete_attachment(", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-how-to-use-attachments"}, {"document_id": "ibmcld_00510-7123-9213", "score": 11.867096, "text": "\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1. IBM Cloudant is expensive as a block store.\n2. IBM Cloudant\u2019s internal implementation is not efficient in handling large amounts of binary data.\n\n\n\nSo, slow and expensive.\n\nIBM Cloudant is acceptable for small assets and occasional use. As a rule, if you need to store binary data alongside IBM Cloudant documents, it\u2019s better to use a separate solution more suited for this purpose. You need store only the attachment metadata in the IBM Cloudant document. Yes, that means you need to write some extra code to upload the attachment to a suitable block store of your choice. Verify that it succeeded before you store the token or URL to the attachment in the IBM Cloudant document.\n\nYour databases are smaller, cheaper, faster, and easier to replicate. For more information, see the following websites:\n\n\n\n* IBM Cloudant docs on [attachments](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-how-to-use-attachments)\n* Detaching IBM Cloudant attachments to [Object Storage](https://medium.com/codait/detaching-cloudant-attachments-to-object-storage-with-serverless-functions-99b8c3c77925)\n\n\n\n\n\n\n\n Fewer databases are better than many \n\nIf you can, limit the number of databases per IBM Cloudant account to 500 or fewer. While this particular number is not magic (IBM Cloudant can safely handle more), several use cases exist that are adversely affected by large numbers of databases in an account.\n\nThe replicator scheduler has a limited number of simultaneous replication jobs that it is prepared to run. As the number of databases grows, the replication latency is likely to increase if you try to replicate everything contained in an account.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-data-modeling"}, {"document_id": "ibmcld_00629-40768-42666", "score": 11.243664, "text": "\n* If your documents contain attachments, you might want to consider reducing the batch_size and increasing the worker_processes, to accommodate larger documents in smaller batches.\n* If you have many tiny documents, then you might consider increasing the [worker_process](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-advanced-replicationperformance-related-options) and [http_connections](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-advanced-replicationperformance-related-options) values.\n* If you want to run replication with minimal impact, setting worker_processes and http_connections to 1 might be appropriate.\n* For more information, see [Consumption of Read and Write Operations by Replication](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-publicconsumption-of-read-and-write-operations-by-replication).\n\n\n\nFor further assistance about the best configuration for your use case, go to the [IBM Cloud Support portal](https://www.ibm.com/cloud/support).\n\nReplication performance can be improved by enabling the \"use_bulk_get\": true\" replication option. In that case, the replicator fetches documents from the source in batches rather than individually.\n\n{\n\"_id\": \"rep_doc_id\",\n\"source\": \"https://account1.cloudant.com/db1\",\n\"target\": \"https://account2.cloudant.com/db2\",\n\"use_bulk_get\": true\n}\n\nThe increased replication rate might consume the available read or write rate capacity on the source and target endpoint accounts.\n\n\n\n\n\n Removing conflicting document revisions with replication \n\nOne way to remove conflicted document revisions via replication is by enabling the \"winning_revs_only\": true option. This option only replicates the winning document revisions. That is the revision returned by default by a GET $SERVICE_URL/$DATABASE/$DOCID request. This option is an advanced option, as it discards conflicted document revisions. Use this option with care.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-replication-guide"}, {"document_id": "ibmcld_07000-7-1974", "score": 10.955879, "text": "\nHCL Notes \n\nCrawl an HCL Notes (formerly Lotus Notes) database.\n\nIBM Cloud Pak for Data\n\nThis information applies only to installed deployments.\n\n\n\n What documents are crawled \n\n\n\n* Each document in the HCL Notes database is crawled and added to the collection as a document.\n* If an HCL Notes document has a file attachment, and you choose to process file attachments, only documents that are supported by Discovery are crawled; all others are ignored. For more information, see [Supported file types](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-collectionssupportedfiletypes).\n* If you choose to process attachments, the crawler attempts to crawl and index files that are attached to HCL Notes documents. File types that are supported by Discovery are indexed. For more information, see [Supported file types](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-collectionssupportedfiletypes).\n* Document-level security is supported. When this option is enabled, your users can crawl and query the same content that they can access when they are logged in to HCL Notes. For more information, see [Supporting document-level security](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-collection-typesconfiguredls).\n* When a source is recrawled, new documents are added, updated documents are modified to the current version, and deleted documents are deleted from the collection's index.\n* All Discovery data source connectors are read-only. Regardless of the permissions that are granted to the crawl account, Discovery never writes, updates, or deletes any content in the original data source.\n\n\n\n\n\n\n\n Data source requirements \n\nIn addition to the [data source requirements](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-collection-typesrequirements) for all installed deployments, your HCL Notes data source must meet the following requirements:\n\n\n\n* The data source can crawl HCL Notes 9.0.1 databases.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-connector-notes-cp4d"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00646-7-1813", "score": 21.47418, "text": "\nCreating a web-based To-Do list \n\nCreate a simple web-based to-do list to get familiar with the basic IBM Cloud features.\n\n\n\n Objectives \n\n\n\n1. From this tutorial, you learn how to create a basic website that interfaces with your IBM Cloud database to read and write data.\n\nThe project is a simple to-do list, where you can see a list of notes. You can add and delete notes. Each of your notes has a tag, and you can filter your notes by tag.\n2. To create this to-do list, your application needs to be able to read and write to the database. To read to-dos in \"newest first\" order and to filter by tag, your database needs to have some secondary indexes. Now, we can create all of that.\n\n\n\nYou can complete the tutorial in less than an hour. It doesn't cost you anything over your current IBM Cloudant bill (so it's free if you are on the IBM Cloudant Lite plan).\n\nThe website that you create is served from your local machine, so no other services are required apart from IBM Cloud.\n\nAfter you complete it, you have a basic understanding of how applications can interface with IBM Cloudant through an IBM Cloudant SDK (in this case, NodeJS).\n\n\n\n\n\n Before you begin \n\nYou need the following implements to complete this tutorial:\n\n\n\n1. An IBM Cloudant service instance and some service credentials. You can create the instance and credentials in the IBM Cloudant Dashboard by following the [Getting started with IBM Cloudant](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-getting-started-with-cloudant) tutorial. Be sure to make a note of the APIKey and URL when you create your service credentials.\n2. Ensure you have access to a Mac or Linux\u2122 terminal.\n3. Download [Git](https://git-scm.com/downloads).\n4. Download [Node.js and npm](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm).", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-web-based-todo-list"}, {"document_id": "ibmcld_00522-7-1725", "score": 21.264175, "text": "\nDigging deeper into IBM Cloudant Dashboard \n\nThe IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Dashboard gives new and experienced IBM Cloudant users the opportunity to add, edit, and delete documents. The IBM Cloudant users can refine the indexing and querying options that best suit their application's use-cases.\n\n\n\n Objectives \n\nSet up some basic indexes using the Dashboard to see how each of IBM Cloudant's querying mechanisms works.\n\n\n\n\n\n Before you begin \n\nYou need to create a service instance in IBM Cloudant before you start this tutorial. You can follow the instructions in the [Getting started](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-getting-started-with-cloudant) tutorial to create one.\n\n\n\n\n\n Step 1. The data set \n\n\n\n1. Create a database called books.\n2. Create some sample data that represents a book in a library as shown in the following example:\n\n{\n\"_id\": \"BXP9G5ZQY9Q4EA13\",\n\"author\": \"Dickens\",\n\"title\": \"David Copperfield\",\n\"year\": 1840,\n\"pages\": 723,\n\"publisher\": \"Penguin\",\n\"url\": \"https://www.somurl.com/dc\"\n}\n3. Continue to add some documents that match the pattern in the previous step by using the IBM Cloudant Dashboard.\n\nThe documents store simple key/value pairs that hold metadata about each book: its author and its publisher. In this example, we address the following three use-cases:\n\n\n\n1. A query facility that allows a user to find a book by a known publisher and year.\n2. A general-purpose search engine that allows a user to find books by a combination of one or more of the following descriptors: author, title, year, and publisher.\n3. A report that details the number of books that are published by year.\n\n\n\n\n\n\n\n\n\n Step 2. Querying books by publisher and year - IBM Cloudant Query", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-dig-deeper-dashboard"}, {"document_id": "ibmcld_11142-7-1829", "score": 20.972843, "text": "\nTry out IBM Cloud, for free \n\nLooking to try out IBM Cloud\u00ae? Create an account and start building proof of concepts (POCs) with the many components available in IBM Cloud. You can try Lite and Free service plans to explore IBM Cloud at no cost while learning how to work in the cloud, use Watson, and more. This quick start guide is intended to help you get up and running on IBM Cloud without having to think about costs until you're ready.\n\n\n\n Before you begin \n\nGo to the [IBM Cloud console](https://cloud.ibm.com) and create an account. You're asked to enter your credit card information to secure your account and verify your identity. There are no costs that are associated with signing up, and you can try out IBM Cloud for free. You pay only for billable services that you choose to use, with no long-term contracts or commitments.\n\nYou're set up with a [Pay-As-You-Go account](https://cloud.ibm.com/docs/account?topic=account-accountspaygo), and you can access the full IBM Cloud catalog, including all Lite and Free plans. You receive a $200 credit to help get you started. You can use the $200 credit on IBM Cloud products that are used in the first 30 days.\n\n\n\n\n\n Step 1: Explore the catalog \n\nExplore the catalog for services that are free to use by filtering for Lite and Free pricing plans. You can work on your projects worry free, without the risk of generating a bill.\n\n\n\n1. Go to the [catalog](https://cloud.ibm.com/catalog).\n2. Select the Lite and Free pricing plan options.\n\n\n\n\n\n\n\n Step 2: Create an instance \n\nCreate an instance of product that includes a free Lite plan or a Free tier pricing plan.\n\n\n\n1. Select the tile from the catalog after reviewing the filtered list of products.\n2. Enter any required information to create the instance.\n3. Click Create.\n\n\n\n\n\n\n\n Step 3: Check out the tutorials", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-tutorial-try-for-free"}, {"document_id": "ibmcld_00646-3898-5632", "score": 20.459093, "text": "\nFor example, when your webpage is first loaded, it calls the GET /todolist endpoint. The GET /todolist endpoint uses the postFind method to query the database for all documents (by using the index created after the todo database), and then orders the notes by timestamp, and returns them to the front end for display.\n\nFiltering by tag uses the same postFind method, but by using the second index, you create and delete notes by using the postDocument and deleteDocument methods.\n\n\n\n\n\n\n\n Summary \n\nIBM Cloudant allows rapid development of web applications, as its HTTP API is modeled by the [Node.js SDK](https://www.npmjs.com/package/@ibm-cloud/cloudant) and is easy to integrate with your own code. You create an IBM Cloudant database and add JSON documents that model your own data. Remember to create secondary indexes to help service your query access patterns so that query performance remains quick as your data volume grows.\n\nIf you don't fancy writing JavaScript, we have SDKs for [Java\u2122, Python, and Go](https://cloud.ibm.com/apidocs/cloudant), plus our [HTTP API](https://cloud.ibm.com/apidocs/cloudant). Don't forget. The [IBM Cloudant Dashboard](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-connectingibm-cloudant-dashboard) is a great way to explore your databases, create and modify documents, and refine your index and querying skills.\n\nYou can find more best practice guidance in our [blog](https://blog.cloudant.com/2019/11/21/Best-and-Worst-Practices.html) and [documentation](https://cloud.ibm.com/docs/services/Cloudant/getting-started.html). For a video guide to IBM Cloudant and its capabilities, see the course in our [learning center](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-learning-center).", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-web-based-todo-list"}, {"document_id": "ibmcld_09715-2612-4022", "score": 20.33511, "text": "\n[IBM Cloudant](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-getting-started-with-cloudant) IBM Cloudant is a document-oriented database as a service (DBaaS). It stores data as documents in JSON format. [Platform metrics](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-monitor-ibm-cloud-pm) \n [IBM Cloud Databases for PostgreSQL](https://cloud.ibm.com/docs/databases-for-postgresql?topic=databases-for-postgresql-getting-started) IBM Cloud Databases for PostgreSQL is a managed PostgreSQL service that is hosted in the IBM Cloud and integrated with other IBM Cloud services. [Platform metrics](https://cloud.ibm.com/docs/databases-for-postgresql?topic=databases-for-postgresql-monitoring) \n [IBM Cloud Databases for Redis](https://cloud.ibm.com/docs/databases-for-redis?topic=databases-for-redis-getting-started) IBM Cloud Databases for Redis is a managed service that is hosted in the IBM Cloud and integrated with other IBM Cloud services. [Platform metrics](https://cloud.ibm.com/docs/databases-for-redis?topic=databases-for-redis-monitoring) \n [IBM Cloud Databases for etcd](https://cloud.ibm.com/docs/databases-for-etcd?topic=databases-for-etcd-getting-started) IBM Cloud Databases for etcd is a managed etcd service that is hosted in the IBM Cloud and integrated with other IBM Cloud services. [Platform metrics](https://cloud.ibm.com/docs/databases-for-etcd?topic=databases-for-etcd-monitoring)", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-cloud_services"}, {"document_id": "ibmcld_13159-1443-3030", "score": 20.008821, "text": "\n[Architecture](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution64-serverless-webapp/architecture-serverless-api-webapp.svg)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. The user accesses the application hosted on the bucket in Object Storage\n2. The web application calls a backend API.\n3. The app with the backend API is deployed to Code Engine.\n4. The backend uses IBM Cloudant to store and retrieve guestbook entries.\n\n\n\n\n\n\n\n Step 1: Create the Guestbook database \n\nLet's start by creating a [IBM Cloudant](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-getting-started-with-cloudant) service instance. IBM Cloudant is a fully managed JSON document database. It is built upon and compatible with Apache CouchDB.\n\n\n\n1. In the [Catalog](https://cloud.ibm.com/catalog?category=databasesservices), under Services, go to the Databases category. Click on the IBM Cloudant tile. In the new dialog:\n\n\n\n1. Under Multitenant select a region.\n2. Under Configure Cloudant instance pick a unique name for the service, such as <yourinitials>-guestbook-db.\n3. Select a resource group.\n4. Select IAM as authentication method.\n5. Select the Lite plan. If you already have a Lite plan in your account, select another service plan.\n6. Click Create.\n\n\n\n2. Back in the [IBM Cloud Resource List](https://cloud.ibm.com/resources/), under Services, click on the IBM Cloudant instance you created to open the instance full details page. Note: You may be required to wait until the status of the service changes to Active.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-serverless-webapp"}, {"document_id": "ibmcld_13480-7-2163", "score": 19.913263, "text": "\nGetting started with the catalog \n\nEach instance of IBM Cloud\u00ae Data Engine includes a database catalog that you can use to register and manage table definitions for your data on IBM Cloud\u00ae Object Storage. Catalog syntax is compatible with Hive metastore syntax. See how to [work with the catalog](https://cloud.ibm.com/docs/sql-query?topic=sql-query-getting_started_catalogusage) and refer to the [Catalog management](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referencechapterHiveCatalog) section of the SQL reference.\n\n\n\n Benefits \n\nYou can explore, change, or discover structured data on [Cloud Object Storage](https://cloud.ibm.com/docs/services/cloud-object-storage/getting-started.htmlgetting-started-console) with Data Engine by using SQL syntax. To query data on Object Storage without a table in the catalog, you need to specify the data location (the corresponding Object Storage URI) and the data format in your SELECT statement. During query execution, data and schema are dynamically discovered as part of the SQL compilation process. This process, called inference, derives column names, data types, the list of partitions, and individual objects on Object Storage that together make up the table data.\n\nInferring all this information and doing it repetitively with every query imposes latency to your queries. The inference process can take up a significant amount of time, especially for text formats (for example, CSV and JSON), or when thousands of objects exist in different table partitions. In some cases, the inference process even accounts for the largest part of the overall query execution time. So, if you are either familiar with the schema, or want to repetitively use the data for queries, create a table in the catalog. Such a table improves performance for repeated query executions.\n\nAnother advantage of creating a table in the catalog is that the table name serves as an alias and is decoupled from the data location. Hence, you can separate the tasks of data engineers and SQL authors. Data engineers deal with the data location and publish registered tables in the catalog by using descriptive table names.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-getting_started_catalog"}, {"document_id": "ibmcld_00547-7-1654", "score": 19.606905, "text": "\nGetting started with IBM Cloudant \n\nThe IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Getting started tutorial demonstrates how to use the IBM Cloud\u00ae dashboard to create an IBM Cloudant service instance and obtain service credentials to connect to it. Finally, it guides you through the creation of a simple, locally hosted web application that uses your IBM Cloudant database.\n\n\n\n Objectives \n\n\n\n* Create a service instance.\n* Create an IBM Cloudant service credential.\n\n\n\n\n\n\n\n Step 1: Creating a service instance \n\n\n\n1. Log in to your IBM Cloud account, and click Create resource.\n\nZoom\n\n![IBM Cloud Dashboard, which includes Build tile, Monitor your resources tile, Create and deploy an application tile, API Connect tile, Integrate Watson with anything tile, and Watson starter kits tile.](https://cloud.ibm.com/docs-content/v1/content/522c6f62358b063f921283400a601c3f9bc66f08/Cloudant//tutorials/images/img0001.png)\n\nFigure 1. IBM Cloud Dashboard\n\nThe IBM Cloud Dashboard can be found at: [https://cloud.ibm.com/](https://cloud.ibm.com/). After you authenticate with your username and password, you're presented with the IBM Cloud Dashboard.\n2. Type Cloudant in the Search bar and click to open it.\n3. Select an offering and an environment.\n4. Type an instance name.\n\nZoom\n\n![Create the IBM Cloudant service name and credentials.](https://cloud.ibm.com/docs-content/v1/content/522c6f62358b063f921283400a601c3f9bc66f08/Cloudant/tutorials/images/img0005b.png)\n\nFigure 2. IBM Cloudant service name and credentials\n\n(In this example, the instance name is Cloudant-o7.) Verify that the resource group and authentication methods are correct. Add a tag if you like.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-getting-started-with-cloudant"}, {"document_id": "ibmcld_16725-5135-6404", "score": 19.547102, "text": "\n](https://cloud.ibm.com/docs/virtualization)Virtualization for Classic ServiceContainers[Container Registry](https://cloud.ibm.com/docs/Registry)Container Registry Service[Kubernetes service](https://cloud.ibm.com/docs/containers)Kubernetes service Service[Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift)Red Hat OpenShift on IBM Cloud ServiceDatabases[Cloudant](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-getting-started-with-cloudant)Cloudant Service[Databases For Elasticsearch](https://cloud.ibm.com/docs/databases-for-elasticsearch?topic=databases-for-elasticsearch-getting-started)Databases For Elasticsearch Service[Databases For EnterpriseDB](https://cloud.ibm.com/docs/databases-for-enterprisedb?topic=databases-for-enterprisedb-getting-started)Databases For EnterpriseDB Service[Databases For MongoDB](https://cloud.ibm.com/docs/databases-for-mongodb?topic=databases-for-mongodb-getting-started)Databases For MongoDB Service[Databases For MySQL](https://cloud.ibm.com/docs/databases-for-mysql?topic=databases-for-mysql-getting-started)Databases For MySQL Service[Databases For PostgreSQL](https://cloud.ibm.com/docs/databases-for-postgresql?topic=databases-for-postgresql-getting-started)Databases For PostgreSQL Service[Databases", "title": "", "source": "https://cloud.ibm.com/docs?tab=all-docs"}, {"document_id": "ibmcld_16729-113646-115659", "score": 19.466644, "text": "\nSome are built for high availability and data durability (at the expense of more hardware and extra cost). Others favor speed and can churn out blazingly fast queries (but might lose data in a sudden power failure).\n\nCloudant\n\n\n\n* 2023-03-30\n\n\n\n[Enhance cloud security by applying context-based restrictions](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-cbr-enhanced-security)Enhance cloud security by applying context-based restrictions\n\nThis tutorial walks you through the process of implementing context-based restrictions (CBRs) in your IBM Cloud account. CBRs help you to secure the cloud environment further and move towards a zero trust security model.\n\nKubernetes service Object Storage\n\n+7\n\nActivity Tracker hosted event search,Container Registry,Secrets Manager,App ID,Cloudant,Key Protect,Log Analysis\n\n\n\n* 2 hours\n* 2023-06-28\n\n\n\n[Apply end to end security to a cloud application](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-cloud-e2e-security)Apply end to end security to a cloud application\n\nThis tutorial walks you through key security services available in the IBM Cloud\u00ae catalog and how to use them together. An application that provides file sharing will put security concepts into practice.\n\nKubernetes service Object Storage\n\n+8\n\nActivity Tracker hosted event search,Container Registry,Secrets Manager,App ID,Cloudant,Key Protect,Log Analysis,Cloud Internet Services (CIS)\n\n\n\n* 2 hours\n* 2023-05-05\n\n\n\n[Deploy microservices with Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-openshift-microservices)Deploy microservices with Red Hat OpenShift on IBM Cloud\n\nThis tutorial demonstrates how to deploy applications to Red Hat OpenShift on IBM Cloud. Red Hat OpenShift on IBM Cloud provides a great experience for developers to deploy software applications and for System Administrators to scale and observe the applications in production.\n\nRed Hat OpenShift on IBM Cloud Log Analysis\n\n+3", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00558-1499-3456", "score": 16.479782, "text": "\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-public"}, {"document_id": "ibmcld_00558-20425-22479", "score": 16.384174, "text": "\nThe data storage that is measured for billable purposes for an IBM Cloudant instance is inclusive of both JSON data, indexes, and attachments.\n\n\n\n Data storage included \n\nThis value is the storage capacity that is included in the plan. The Lite plan has a hard limit of 1 GB allowed. The paid Standard plan includes 20 GB for free and any additional data that is stored is metered for billing.\n\n\n\n\n\n Data overage \n\nAll Lite and Standard plans are monitored for disk space used. When you use more data than the plan allocates, you can expect the conditions that are described in the following sections to apply:\n\n\n\n Lite plan \n\n\n\n* Disk usage is capped on the Lite plan at 1 GB.\n* After you reach the cap, you receive a warning on the IBM Cloudant Dashboard and can't write new data. If you try to write new data, a 402: payment required response occurs.\n* To write new data, you must either upgrade to the Standard plan or delete data, and wait until the next check runs for your account to be reactivated.\n\n\n\n\n\n\n\n Standard plan \n\n\n\n* If the account uses more than the 20 GB of storage that is included in the Standard plan, the excess is considered \"disk overage\". Overage causes the account to be billed at the indicated price for each extra GB used beyond the plan allocation.\n* The cost for the amount of disk overage is calculated on an hourly basis.\n\n\n\nFor example, assume your Standard plan increases disk usage to 107 GB for half a day (12 hours). This change means that your instance caused overflow of 87 GB more than the 20 GB plan allocation, for 12 hours. As the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-public"}, {"document_id": "ibmcld_12904-20515-22569", "score": 16.384174, "text": "\nThe data storage that is measured for billable purposes for an IBM Cloudant instance is inclusive of both JSON data, indexes, and attachments.\n\n\n\n Data storage included \n\nThis value is the storage capacity that is included in the plan. The Lite plan has a hard limit of 1 GB allowed. The paid Standard plan includes 20 GB for free and any additional data that is stored is metered for billing.\n\n\n\n\n\n Data overage \n\nAll Lite and Standard plans are monitored for disk space used. When you use more data than the plan allocates, you can expect the conditions that are described in the following sections to apply:\n\n\n\n Lite plan \n\n\n\n* Disk usage is capped on the Lite plan at 1 GB.\n* After you reach the cap, you receive a warning on the IBM Cloudant Dashboard and can't write new data. If you try to write new data, a 402: payment required response occurs.\n* To write new data, you must either upgrade to the Standard plan or delete data, and wait until the next check runs for your account to be reactivated.\n\n\n\n\n\n\n\n Standard plan \n\n\n\n* If the account uses more than the 20 GB of storage that is included in the Standard plan, the excess is considered \"disk overage\". Overage causes the account to be billed at the indicated price for each extra GB used beyond the plan allocation.\n* The cost for the amount of disk overage is calculated on an hourly basis.\n\n\n\nFor example, assume your Standard plan increases disk usage to 107 GB for half a day (12 hours). This change means that your instance caused overflow of 87 GB more than the 20 GB plan allocation, for 12 hours. As the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3.", "title": "", "source": "https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-ibm-cloud-public"}, {"document_id": "ibmcld_12904-1535-3460", "score": 16.27653, "text": "\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message.", "title": "", "source": "https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-ibm-cloud-public"}, {"document_id": "ibmcld_01150-5900-8142", "score": 16.07775, "text": "\nAllow a few minutes for the cached limit of 1 partition for the Lite plan to clear so that you can take advantage of the 100 partition limit for the Standard plan.\n\nHowever, this option does not currently work in the IBM Cloud console for any other combination of plans. For example, if you try a different plan combination, you'll see an error message like the the following:\n\nCould not find VCAP::CloudController::ServicePlan with guid: ibm.eventstreams.standard\n\n\n\n\n\n\n\n What are the differences between the Event Streams Standard and Event Streams Enterprise plans? \n\nTo find out more information about the different Event Streams plans, see [Choosing your plan](https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-plan_choose).\n\n\n\n\n\n How do I handle disaster recovery? \n\nCurrently, it is the responsibility of the user to manage their own Event Streams disaster recovery. Event Streams data can be replicated between an Event Streams instance in one location (region) and another instance in a different location. However, the user is responsible for provisioning a remote Event Streams instance and managing the replication.\n\nWe suggest a tool like Kafka MirrorMaker to replicate data between clusters. For information about how to run MirrorMaker, see [Event Streams kafka-mirrormaker repository](https://github.com/ibm-messaging/event-streams-samples/tree/master/kafka-mirrormaker).\n\nThe user is also responsible for the backup of message payload data. Although this data is replicated across multiple Kafka brokers within a cluster, which protects against the majority of failures, this replication does not cover a location-wide failure.\n\nTopic names are backed up by Event Streams, although it is recommended good practice for users to back up topic names and the configuration data for those topics.\n\nIf you have configured your Event Streams instance in a Multi-Zone Region, a regional disaster is very unlikely. However, we recommend that users do plan for such circumstances. If a user's instance is no longer available because of a disaster (and a remote DR instance is not already set up), the user should consider configuring a new instance in a new region and restoring their topics and data from backup if available.", "title": "", "source": "https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-faqs"}, {"document_id": "ibmcld_02660-1509-3609", "score": 16.07549, "text": "\nCurrently, Dallas (us-south), Washington DC (us-east), London (eu-gb), and Sydney (au-syd) regions are supported.\n4. Select a pricing plan - Based on your business requirements, select a pricing plan: Lite, Standard, and Enterprise.\n\n\n\n* Lite - Includes all App Configuration capabilities for evaluation only. Not to be used for production. Lite plan services are deleted after 30 days of inactivity.\n* Standard - The standard plan includes feature flags and property management capabilities. You can use simple and uniform REST APIs to configure, enable, segment, and monitor features to mobile devices and web applications.\n* Enterprise - The enterprise plan includes targeting segment in addition to the property management and feature flags that are found in the Standard plan. The enterprise plan now supports by using private endpoints.\n\n\n\nFor more information about App Configuration usage and billing, see [Usage and billing](https://cloud.ibm.com/docs/app-configuration?topic=app-configuration-ac-faqs-usage).\n5. Configure your resource by providing a Service name for your instance, or use the preset name.\n6. Select a resource group - The resource group selection helps how you want resources to be organized in your account. The resource group that you select cannot be changed after the service instance is created.\n7. Optionally, define Tags to help you to identify and organize the instance in your account. If your tags are billing related, consider writing tags as key:value pairs to help group-related tags, such as costctr:124.\n8. Optionally, define Access management tags that are needed to apply flexible access policies on specific resources. For example, access:dev, proj:version-1.\n9. If you selected the Enterprise plan, then specify the Service endpoints. The following options are available:\n\n\n\n* Public network - The public network service endpoints are accessible from anywhere on the internet.\n* Both Public & Private network - use of both public and private service endpoint network access.\n\n\n\n10. Accept the licensing agreements and terms by clicking the checkbox.\n11.", "title": "", "source": "https://cloud.ibm.com/docs/app-configuration?topic=app-configuration-ac-create-an-instance"}, {"document_id": "ibmcld_13336-1484-3613", "score": 16.050611, "text": "\n* Use of all available models (same as the Lite plan).\n* Unlimited creation and use of custom language and custom acoustic models at no extra charge.\n* A maximum of one hundred concurrent transcription requests from all interfaces, WebSocket and HTTP, combined.\n\n\n\nThe plan uses a simple tiered pricing model to give high-volume users further discounts as they use the service more heavily. Pricing is based on the aggregate number of minutes of audio that you recognize per month:\n\n\n\n* Users who recognize 1 to 999,999 minutes of audio in a given month pay $0.02 (USD) per minute of audio for that month.\n* Users who recognize at least 1,000,000 minutes of audio in a given month pay $0.01 (USD) per minute of audio for that month.\n\n\n\nThe Plus plan is intended for small businesses. It is also a good choice for large enterprises that want to develop and test larger applications before considering moving to a Premium plan. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https://cloud.ibm.com/catalog/speech-to-text).\n\n\n\n\n\n Can I continue to use the Speech to Text Standard plan? \n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https://cloud.ibm.com/catalog/speech-to-text). They will continue to have access to all of their settings and custom models after upgrading. And, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n\n\n\n\n\n What pricing plan do I need to use the service's customization interface? \n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n\n\n\n\n\n How do I upgrade from the Lite plan to the Plus plan?", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-faq-pricing"}, {"document_id": "ibmcld_16727-1079289-1081125", "score": 15.833505, "text": "\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-1076793-1078629", "score": 15.833505, "text": "\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_07578-1323355-1325090", "score": 15.808303, "text": "\nSelect the \"standard\" plan and hit save.\n\nIn cases where the instance has been locked due to exceeding the maximum allowed size of a Lite instance it may be necessary to use the CLI. The plan ID for a standard Object Storage instance is 744bfc56-d12c-4866-88d5-dac9139e0e5d (if curious, this can be found by issuing the CLI command ic catalog service cloud-object-storage). You'll need to know the name of the instance you are trying to upgrade. For example, to upgrade the instance \"My Object Storage\", you can issue the command:\n\nic resource service-instance-update \"My Object Storage\" --service-plan-id 744bfc56-d12c-4866-88d5- dac9139e0e5d\n* Are bucket names case-sensitive?\n\nBucket names are required to be DNS addressable and are not case-sensitive.\n* What is the maximum number of characters that can be used in a key, or Object name?\n\nKeys have a 1024-character limit.\n* What are some tools unable to render object names?\n\nObject names that contain unicode characters that are not allowed by the XML standard will result in \"Malformed XML\" messages. For more information, see [the XML reference documentation](https://www.w3.org/TR/xml/charsets).\n* Can I create more than one Object Storage service with a Lite account?\n\nIf you already have a Lite plan instance created, you may create other Standard plan instances, but only one Lite plan instance is allowed.\n* What happens if I exceed the maximum usage allowed for a Lite plan?\n\nOnce you exceed the allowed usage, the service instance associated with the Lite plan becomes inaccessible. You will receive a warning notification email with corrective steps. If you do not take action, the instance is removed.\n* How can I find out the total size of my bucket by using the API?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07103-31052-33321", "score": 16.078785, "text": "\nYou cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, and Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 24 September 2021 \n\nNew scoring for NLU enrichments\n: Relevance and confidence scores are displayed for NLU enrichments that are returned by search. For example, when you open the JSON view of the document preview from a query result, you can see confidence scores for Entities mentions and relevance scores for Keyword mentions.\n\n\n\n\n\n 9 September 2021 \n\nNew location for Plus plan\n: The Plus plan is now available from the Sydney location. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product. For more information, see [Getting the most from Discovery](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-version-choose).\n\nChange to Lite and Advanced plans in most locations\n: Lite and Advanced plans are discontinued. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\n\n\n\n\n 26 August 2021 \n\nNew locations for the Plus plan\n: The Plus plan is now available from the London and Washington DC locations, in addition to Dallas, Frankfurt, and Tokyo.\n\nChange to Lite and Advanced plans in some locations\n: You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\nNew answer finding feature\n: Answer finding is now generally available for managed deployments.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-release-notes"}, {"document_id": "ibmcld_07103-29564-31587", "score": 16.05723, "text": "\nPreviously, the list included fields that were not valid choices.\n\n\n\n\n\n 14 October 2021 \n\nNew Discovery home page\n: A new home page is displayed when you start Discovery and gives you quick access to a product overview video, and tours. You can collapse the home page welcome banner to see more projects.\n\nNew plan usage section\n: Stay informed about plan usage and check your usage against the limits for your plan type from the Plan limits and usage page. From the product page header, click the user icon ![User icon](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/user--avatar.svg). The Usage section shows a short summary. Click View all to see usage information for all of the plan limit categories.\n\nChange to spelling settings in Search\n: The spelling correction setting changed from being enabled automatically in new projects to being disabled by default. If you want to alert users when they misspell a term in their query, turn on Spelling suggestions. For more information, see [Customizing the search bar](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-search-bar).\n\nImproved Guided tours availability\n: The Guided tours button is now available from the product page header, which make them accessible from anywhere. Previously, it was available from the My Projects page only.\n\n\n\n\n\n 1 October 2021 \n\nChange to Lite and Advanced plans in all locations\n: Lite and Advanced plans are discontinued. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, and Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 24 September 2021 \n\nNew scoring for NLU enrichments", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-release-notes"}, {"document_id": "ibmcld_11142-7-1829", "score": 14.583178, "text": "\nTry out IBM Cloud, for free \n\nLooking to try out IBM Cloud\u00ae? Create an account and start building proof of concepts (POCs) with the many components available in IBM Cloud. You can try Lite and Free service plans to explore IBM Cloud at no cost while learning how to work in the cloud, use Watson, and more. This quick start guide is intended to help you get up and running on IBM Cloud without having to think about costs until you're ready.\n\n\n\n Before you begin \n\nGo to the [IBM Cloud console](https://cloud.ibm.com) and create an account. You're asked to enter your credit card information to secure your account and verify your identity. There are no costs that are associated with signing up, and you can try out IBM Cloud for free. You pay only for billable services that you choose to use, with no long-term contracts or commitments.\n\nYou're set up with a [Pay-As-You-Go account](https://cloud.ibm.com/docs/account?topic=account-accountspaygo), and you can access the full IBM Cloud catalog, including all Lite and Free plans. You receive a $200 credit to help get you started. You can use the $200 credit on IBM Cloud products that are used in the first 30 days.\n\n\n\n\n\n Step 1: Explore the catalog \n\nExplore the catalog for services that are free to use by filtering for Lite and Free pricing plans. You can work on your projects worry free, without the risk of generating a bill.\n\n\n\n1. Go to the [catalog](https://cloud.ibm.com/catalog).\n2. Select the Lite and Free pricing plan options.\n\n\n\n\n\n\n\n Step 2: Create an instance \n\nCreate an instance of product that includes a free Lite plan or a Free tier pricing plan.\n\n\n\n1. Select the tile from the catalog after reviewing the filtered list of products.\n2. Enter any required information to create the instance.\n3. Click Create.\n\n\n\n\n\n\n\n Step 3: Check out the tutorials", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-tutorial-try-for-free"}, {"document_id": "ibmcld_07103-13283-15511", "score": 14.166313, "text": "\nYou cannot create new service instances that use the Lite plan type in any location, including London. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 22 September 2022 \n\nPlus plan supports more entity extractors\n: The maximum number of entity extractors that you can create with a Plus plan increased from 3 to 6.\n\nYou cannot apply a Smart Document Understanding model to Microsoft Excel files\n: The quality of structural analysis that can be produced for Excel files is not sufficient. Starting on 22 September 2022, you cannot apply an SDU model to Excel files. This change does not impact Excel files in collections where an SDU model was applied before 22 September 2022.\n\n\n\n\n\n 16 September 2022 \n\nIn-context document preview is now available for PDF files that are crawled\n: When you click to view a passage from a search result that is extracted from a PDF document, a document preview page is displayed that shows the returned passage in the context of the original PDF page. The in-context view is available for PDF files to which a Smart Document Understanding model is applied.\n\n\n\n\n\n 15 August 2022 \n\nSDKs were updated to reflect the latest API changes.\n: The following [Discovery v2 API](https://cloud.ibm.com/apidocs/discovery-data) changes are now reflected in the SDKs:\n\n\n\n* Use the new document classifier API to get, add, update, or delete a document classifier.\n* A new document status API is available. You can use it to get a list of the documents in a collection and to get details about a single document.\n* You can now get, add, and remove a stop words or expansion list for a collection.\n* A smart_document_understanding field is returned with the Get collection method. This new field specifies whether an SDU model is enabled for the collection and indicates the model type.\n* A similar parameter is available from the Query method. Use it to find documents that are similar to documents of interest to you.\n* The suggested_refinements parameter of the Query method is deprecated. The suggested_refinements parameter was used to identify dynamic facets from Premium plan data.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-release-notes"}, {"document_id": "ibmcld_07103-32746-34817", "score": 13.370624, "text": "\n: The Plus plan is now available from the London and Washington DC locations, in addition to Dallas, Frankfurt, and Tokyo.\n\nChange to Lite and Advanced plans in some locations\n: You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\nNew answer finding feature\n: Answer finding is now generally available for managed deployments. Use answer finding when you want to return a concise answer to a question. For more information, see [Answer finding](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-parametersanswer-finding).\n\n\n\n\n\n 16 August 2021 \n\nNew locations for the Plus plan\n: The Plus plan is now available from the Frankfurt and Tokyo locations, in addition to Dallas.\n\nChange to Lite and Advanced plans in some locations\n: Lite and Advanced plans are no longer offered. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, or Tokyo locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\n\n\n\n\n 27 July 2021 \n\nImproved document size limit\n: Document size limit is increased. For Premium plan collections, you can now upload files that are up to 50 MB in size instead of 32 MB. For more information, see [Document limits](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-collectionscollections-doc-limits).\n\n\n\n\n\n 23 July 2021 \n\nImproved SharePoint Online connector\n: The Microsoft SharePoint Online data source connector now accepts any valid Azure Active Directory user ID syntax; the format of the user ID doesn't need to match the <admin_user>@.onmicrosoft.com syntax. For more information, see [Microsoft SharePoint Online](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-connector-sharepoint-online-cloud).", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-release-notes"}, {"document_id": "ibmcld_07128-7-1957", "score": 13.360114, "text": "\nAbout Discovery v1 \n\nIBM Watson\u2122 Discovery v1 is deprecated. As of 1 October 2021, you cannot create new v1 instances. Lite or Advanced plan service instances are Discovery v1 instances, as are service instances that you created with a Premium plan before 16 July 2020. Existing v1 service instances are supported until 11 July 2023. Any v1 instances that still exist on that date will be deleted. Migrate your solutions to use Discovery v2 before 11 July 2023. For more information, see the [Discovery v2 documentation](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-version-choose).\n\nDiscovery makes it possible to rapidly build cognitive, cloud-based exploration applications that unlock actionable insights hidden in unstructured data \u2014 including your own proprietary data, as well as public and third-party data.\n\n![Discovery architecture diagram](https://cloud.ibm.com/docs-content/v1/content/ded4adc3ea0bd2a81b113c579f2b1183926da211/discovery/images/about-discovery1.png)\n\nWith Discovery, it only takes a few steps to prepare your unstructured data, create a query that pinpoints the information you need, and then integrate those insights into your new application or existing solution.\n\nHow does Discovery do it? By using data analysis combined with cognitive intuition to take your unstructured data and enrich it so you can discover the information you need.\n\nIBM Watson\u2122 Discovery brings together a functionally rich set of integrated, automated Watson APIs to:\n\n\n\n* Crawl, convert, enrich and normalize data.\n* Securely explore your proprietary content as well as free and licensed public content.\n* Apply additional enrichments such as concepts, relations, and sentiment through Natural Language Understanding (NLU).\n* Simplify development while still providing direct access to APIs.\n\n\n\nTo try out Discovery, see the [IBM Watson\u2122 Discovery Query Demo](https://www.ibm.com/demos/live/watson-discovery/self-service/home).", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-about"}, {"document_id": "ibmcld_16727-1079289-1081125", "score": 13.052542, "text": "\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-1076793-1078629", "score": 13.052542, "text": "\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_13336-1484-3613", "score": 13.015494, "text": "\n* Use of all available models (same as the Lite plan).\n* Unlimited creation and use of custom language and custom acoustic models at no extra charge.\n* A maximum of one hundred concurrent transcription requests from all interfaces, WebSocket and HTTP, combined.\n\n\n\nThe plan uses a simple tiered pricing model to give high-volume users further discounts as they use the service more heavily. Pricing is based on the aggregate number of minutes of audio that you recognize per month:\n\n\n\n* Users who recognize 1 to 999,999 minutes of audio in a given month pay $0.02 (USD) per minute of audio for that month.\n* Users who recognize at least 1,000,000 minutes of audio in a given month pay $0.01 (USD) per minute of audio for that month.\n\n\n\nThe Plus plan is intended for small businesses. It is also a good choice for large enterprises that want to develop and test larger applications before considering moving to a Premium plan. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https://cloud.ibm.com/catalog/speech-to-text).\n\n\n\n\n\n Can I continue to use the Speech to Text Standard plan? \n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https://cloud.ibm.com/catalog/speech-to-text). They will continue to have access to all of their settings and custom models after upgrading. And, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n\n\n\n\n\n What pricing plan do I need to use the service's customization interface? \n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n\n\n\n\n\n How do I upgrade from the Lite plan to the Plus plan?", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-faq-pricing"}, {"document_id": "ibmcld_03729-3519-5413", "score": 12.779987, "text": "\nThese resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings\n* Encrypted data storage limit, for example 1 GB\n* Provisioned throughput capacity\n\n\n\nYou can easily find services for Lite plans in the catalog. By default, all services with a Lite plan are displayed with a Lite tag ![Lite tag](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/Lite.svg). Select a service to view the quota details for the associated Lite plan.\n\n\n\n\n\n Charges for compute resources \n\nYou're charged for the time that your apps run and the memory that's used in GB-hours. GB-hours is the calculation of the number of application instances that are multiplied by the memory per instance and by the hours that the instances run. You can customize the number of instances and the amount of memory per instance based on your needs. You can also add memory or instances to scale for more users. To get the amount charged, take your application instances that are multiplied by memory per instance and by hours running.\n\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_12343-7-1769", "score": 18.810625, "text": "\nPython \n\nGiven its ease of use and adoption for data science applications, [Python](https://www.python.org/) support is imperative to increase adoption of your IBM Cloud service. Supporting Python applications using [Flask](https://github.com/pallets/flask), [Django](https://www.djangoproject.com/), [Jupyter](https://jupyter.org/), and functional programming paradigms introduces special considerations that need to be observed by your SDK.\n\n\n\n Environment support \n\n\n\n* Your Python SDK should be written to support all [Python >=3.5](https://www.python.org/downloads/) releases.\n* Ensure your SDK is compatible with data science usecases, such as [Jupyter Notebooks](https://jupyter.org/).\n\n\n\n\n\n\n\n Publishing \n\nAll Python SDKs should be publicly available on an [IBM GitHub organization](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-distributionopen-source). The releases of these SDKs should be published on [PyPI](https://pypi.org/).\n\nYour SDK should follow the [semantic versioning best practices](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-distributionsemantic-versioning).\n\n\n\n\n\n Community support \n\nAllow your users to find answers to their questions. Users should be able to report problems on GitHub by raising issues on your SDK repository. Having a public Slack channel is a great way to engage with users who have questions specific to their use cases.\n\n\n\n\n\n Style guidelines \n\nYou should follow the [PEP8 style guide for Python](https://www.python.org/dev/peps/pep-0008/), with a few modifications, like four spaces instead of tabs for indentation.\n\nYou should use the standard [development tools](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-developer-tools) for Python to check style and code coverage.", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-python"}, {"document_id": "ibmcld_12341-1239-2954", "score": 17.608286, "text": "\nThe releases of these SDKs should be published on [NPM](https://www.npmjs.com/). Your NPM package should be [scoped](https://docs.npmjs.com/creating-and-publishing-scoped-public-packagescreating-a-scoped-public-package) with [@ibm-cloud](https://www.npmjs.com/search?q=%40ibm-cloud), so that NPM users can find similar packages across NPM.\n\nYour SDK should follow the [semantic versioning best practices](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-distributiondistribution-semver).\n\n\n\n\n\n Community support \n\nAllow your users to find answers to their questions. Users should be able to report problems on GitHub by raising issues on your SDK repository. Having a public Slack channel is a great way to engage with users who have questions specific to their use cases.\n\n\n\n\n\n Style guidelines \n\nYou should follow the [Airbnb conventions](https://github.com/airbnb/javascript), with two spaces for indentation.\n\nYou should use the standard [development tools](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-devtools) for JavaScript to check style and code coverage.\n\n\n\n\n\n Streaming support \n\nIf your API takes fileType parameters, you should accept Node.js streams as an input type.\n\n\n\n\n\n Dependencies \n\nUse a well-defined, well-documented request library that includes browser support, like [axios](https://github.com/axios/axios), [superagent](https://github.com/visionmedia/superagent), or [node-fetch](https://github.com/node-fetch/node-fetch).\n\n\n\n\n\n Objects for arguments \n\nThe methods in your SDK should take a JSON object as an argument. This object will contain the options for the requests, instead of using positional parameters in the function definition.\n\n\n\n\n\n Async architecture", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-node"}, {"document_id": "ibmcld_12343-1428-3200", "score": 17.57392, "text": "\nYou should follow the [PEP8 style guide for Python](https://www.python.org/dev/peps/pep-0008/), with a few modifications, like four spaces instead of tabs for indentation.\n\nYou should use the standard [development tools](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-developer-tools) for Python to check style and code coverage.\n\n\n\n Docstrings \n\nAll non-trivial methods should have docstrings. Docstrings should follow the [PEP257 guidelines](https://www.python.org/dev/peps/pep-0257/). For more examples, see the [Google style guide regarding docstrings](https://google.github.io/styleguide/pyguide.html381-docstrings).\n\n\n\n\n\n\n\n Dependencies \n\nYour Python SDK should use synchronous network calls, using a library like [requests](https://pypi.org/project/requests/).\n\n[PyJWT](https://pyjwt.readthedocs.io/en/latest/) is recommended for encoding and decoding JSON web tokens.\n\nYour SDK should use [logging](https://docs.python.org/3/library/logging.html) to assist users with low-level debugging.\n\n\n\n\n\n Standard features \n\n\n\n\n\n Authentication \n\nYou are not required to use a particular library to provide the authentication for your service.\n\nYour SDK must support all of the authentication methods for your service.\n\n\n\n\n\n Configuration \n\nIn the interests of making your SDK easy to consume and cloud native, you should provide the ability to read in environment variables. Abstracting the application logic from the environment logic allows your users to focus on using your service capabilities their applications.\n\nIf you build this capability into your SDK, you must document this mechanism clearly with examples.\n\n\n\n\n\n Using python-sdk-core \n\n[IBM python-sdk-core](https://github.com/IBM/python-sdk-core) provides configuration and authentication support.", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-python"}, {"document_id": "ibmcld_02602-1716-3243", "score": 16.995333, "text": "\n2. To view summary usage help for all the toolkit commands, enter the following command:\n\napic\n3. To view usage help for any command, use the --help option. For example:\n\napic validate --help\n\n\n\n\n\n\n\n\n\n Installing LoopBack connectors \n\nBefore you can use a LoopBack data source to access data in a backend system such as a database, you must install the data source connector. The In-memory and email connectors are built in to LoopBack, so you don't need to install them.\n\n\n\n Prerequisites \n\nThe Oracle, DB2, and SQLLite connectors require C compiler tools to build and install binary extensions. The exact requirements depend on your operating system as described in the following list.\n\nLinux\n\n\n\n* Python v2.7 (v3.x is not supported)\n* make\n* A C/C++ compiler toolchain, for example GCC version 4.2 or later.\n* On Debian and Debian-derived distributions (Ubuntu, Mint etc), use the command: apt-get install build-essential\n\n\n\nMac OS X\n\n\n\n* [Python Releases for Mac OS X](https://www.python.org/downloads/mac-osx/)\n* [Xcode](https://developer.apple.com/xcode/?cm_mc_uid=46449280653414622613810&cm_mc_sid_50200000=1459433716)\n\n\n\nWindows\n\n\n\n* [Microsoft .NET Framework 4](https://www.microsoft.com/en-us/download/details.aspx?id=17851)\n* [Visual Studio](https://visualstudio.microsoft.com/downloads/)\n* [Python v2.7.10](https://www.python.org/downloads/release/python-2710/)\n* [Microsoft Windows SDK for Windows 10](https://developer.microsoft.com/en-us/windows/downloads/windows-10-sdk)\n* npm version 3: See the following note.", "title": "", "source": "https://cloud.ibm.com/docs/apiconnect?topic=apiconnect-creating_apis"}, {"document_id": "ibmcld_00099-7-1786", "score": 16.770874, "text": "\nUsing the Python SDK \n\nThe IBM Analytics Engine SDK can be installed by installing the library iaesdk from the Python Package Index.\n\nType the following command into a command line:\n\npip install --upgrade \"iaesdk>=1.1.1\"\n\nSource code can be found at [GitHub](https://github.com/IBM/ibm-iae-python-sdk). The iaesdk library provides complete access to the IBM Analytics Engine API.\n\nYou need to provide the service endpoints and the API key when you create a IBM Analytics Engine service resource or a low-level client.\n\nThe service instance ID is also referred to as a instance GUID. You can retrieve the service instance ID when you create service credentials or through the CLI. See [Retrieving service endpoints](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverless).\n\nTo use the iaesdk library, you need the following values:\n\n\n\n* IAM_API_KEY: The API key generated when creating the service credentials. You can retrieve by viewing the service credentials on the [IBM Cloud dashboard](https://cloud.ibm.com/resources).\n* instance_guid: The value in resource_instance_id generated when the service credentials are created. You can retrieve by viewing the service credentials on the [IBM Cloud dashboard](https://cloud.ibm.com/resources).\n* IAE_ENDPOINT_URL: The service endpoint URL including the https:// protocol. See [Service endpoints](https://cloud.ibm.com/apidocs/ibm-analytics-engineservice-endpoints).\n\n\n\n\n\n Code samples using iaesdk \n\nGetting started with the Python SDK after you have installed it, involves sourcing credentials to the IBM Analytics Engine service, invoking the service and then issuing different cluster commands as shown in the following sample code snippets. The code examples are written for Python 3.7.", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-using-python-sdk-serverless"}, {"document_id": "ibmcld_13481-7434-8879", "score": 16.69995, "text": "\nThe SDK simplifies connecting to the Hive metastore and IBM Cloud Object Storage buckets referenced by tables or views.\n\nIn case of using Python download both, the Scala and the Python SDK, and place them in a folder that is in the classpath of your Apache Spark cluster. When using Scala, the Scala SDK is enough.\n\n\n\n* [spark-dataengine-scala](https://us.sql-query.cloud.ibm.com/download/catalog/dataengine-spark-integration-1.4.51.jar)\n* [spark-dataengine-python](https://us.sql-query.cloud.ibm.com/download/catalog/dataengine_spark-1.4.51-py3-none-any.whl)\n\n\n\nAn example of how to use the Python helper can be found in the [Watson Studio Notebooks section](https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastoreusage_watson_notebooks).\n\nUse the following example to get started with IBM\u00ae Analytics Engine (IAE) or Spark runtimes in Watson Studio when using Scala. Submit the following application using a notebook or the spark-submit command:\n\npackage com.ibm.cloud.dataengine\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.SparkSession.{Builder => SessionBuilder}\nimport SparkSessionBuilderAddOn._\nobject SparkSessionBuilderHMSConfigTest {\ndef main(args: Array[String]) = {\nval spark = SparkSession\n.builder()\n.appName(\"Spark DataEngine integration\")\n.enableDataengine(args(0), args(1), \"public\")\n.config(\"fs.cos.impl\", \"com.ibm.stocator.fs.ObjectStoreFileSystem\")\n.config(\"fs.stocator.scheme.list\", \"cos\")", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastore"}, {"document_id": "ibmcld_00462-1307-2903", "score": 16.637629, "text": "\nThe IBM Cloudant SDK for Python library is the official IBM Cloudant library for Python.\n\nInstall the [IBM Cloudant SDK for Python](https://pypi.org/project/ibmcloudant/) library by running pip or easy_install as shown in the following examples:\n\npip install --upgrade \"ibmcloudant>=0.0.27\"\n\nor\n\neasy_install --upgrade \"ibmcloudant>=0.0.27\"\n\nFor more information, see the [python.org](https://www.python.org/about/) website.\n\n\n\n Library for Python \n\n\n\n* [IBM Cloudant SDK for Python](https://github.com/IBM/cloudant-python-sdk)\n\n\n\n\n\n\n\n\n\n Go \n\nThe IBM Cloudant SDK for Go library is the official IBM Cloudant library for Go.\n\nInstall the [IBM Cloudant SDK for Go](https://pkg.go.dev/mod/github.com/IBM/cloudant-go-sdk) library by running the following command:\n\ngo get -u github.com/IBM/cloudant-go-sdk/cloudantv1\n\n\n\n Library for Go \n\n\n\n* [IBM Cloudant SDK for Go](https://github.com/ibm/cloudant-go-sdk)\n\n\n\n\n\n\n\n\n\n Useful tools \n\nYou can use the following tools with IBM Cloudant.\n\n\n\n Supported tools \n\nSupported tools are maintained and supported by IBM Cloudant.\n\n\n\n couchbackup \n\nA tool that you use from the command line to back up an IBM Cloudant or CouchDB database to a text file.\n\nTo install couchbackup, run the following command by using npm:\n\nnpm install -g @cloudant/couchbackup\n\nFor more information, see [couchbackup](https://github.com/cloudant/couchbackup).\n\n\n\n\n\n\n\n Unsupported tools \n\nUnsupported tools are not maintained or supported by IBM Cloudant.\n\n\n\n cURL \n\nA tool that you use from the command line to transfer data.\n\nFor more information, see [curl](https://curl.haxx.se/).", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-client-libraries"}, {"document_id": "ibmcld_12343-2679-4417", "score": 16.606588, "text": "\nIn the interests of making your SDK easy to consume and cloud native, you should provide the ability to read in environment variables. Abstracting the application logic from the environment logic allows your users to focus on using your service capabilities their applications.\n\nIf you build this capability into your SDK, you must document this mechanism clearly with examples.\n\n\n\n\n\n Using python-sdk-core \n\n[IBM python-sdk-core](https://github.com/IBM/python-sdk-core) provides configuration and authentication support. You can use the existing functionality provided by this dependency in your SDK.\n\n\n\n\n\n Documentation \n\nYour SDK is not useful if your audience cannot understand how to consume it in order to do the basic operations for your service. Your SDK needs to contain the following resources to help your users:\n\n\n\n* README.md\n* [Contributor guidelines](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-documentationsdk-contributor-docs)\n* Code Samples\n* [Service documentation](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-documentation)\n\n\n\n\n\n\n\n Samples \n\nFor your Python SDK, you will want some simple code samples and explanations of what each does. Linking out to the API reference documentation for more advanced use is strongly encouraged.\n\nAt minimum, the samples should be included in the README.md file. They should communicate how to install the library, and complete the basic operations provided by your API.\n\nThe samples should include simple installation and initialization instructions for the popular frameworks and data science tools. Additional examples should be available in an /examples directory for more advanced operations which can be copied and pasted in to user applications.", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-python"}, {"document_id": "ibmcld_12370-8009-9582", "score": 16.270712, "text": "\nIf you use Python, review the following steps and examples to migrate to Secrets Manager API v2.\n\n\n\n1. Update your environment to use the latest version (2.0.0) by updating the requirements.txt or running pip install --upgrade \"ibm-secrets-manager-sdk\".\n2. Update your import statements to use v2.\n3. Remove the secret type, and the metadata and resources wrapper from your resource for each operation that you're using.\n\n\n\nResponses don't contain the resources object. They contain only the secret JSON, or a secrets field, in case of a list.\n\n\n\n Comparing v1 and v2 Python examples \n\nCompare the following examples to see the changes between the v1 Python code snippet and how the code must look like in v2.\n\nv1 example\n\nresponse = secretsManager.create_secret(\n'arbitrary'\n{'collection_type: 'application/vnd.ibm.secrets-manager.secret+json', 'collection_total': 1},\n[{'name': 'example-arbirary-secret', 'description': 'Extended description for this secret.', 'payload': 'secret-data'}]\n)\n\nv2 example\n\nsecret_prototype_model = {\n'description': 'Extended description for this secret.',\n'expiration_date': '2023-10-05T11:49:42Z',\n'name': 'example-arbitrary-secret',\n'secret_group_id': 'default'\n'secret_type':'arbitrary'\n'payload': 'secret-data'\n}\nresponse = secretsManager.create_secret(\nsecret_prototype=secret_prototype_model,\n)\n\n\n\n\n\n\n\n Migrating Go applications \n\nIf you use Go, review the following steps and examples to migrate to Secrets Manager API v2.\n\n\n\n1. Update your go.mod file to use the latest version (2.0.0).\n2. Update your import statements to use v2.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-api-migration-v2"}, {"document_id": "ibmcld_05137-892-2529", "score": 16.078697, "text": "\nSpecific instructions for downloading and installing the SDK is available in [Using Python](https://cloud.ibm.com/docs/cloud-object-storage/libraries?topic=cloud-object-storage-python)[Using Node.js](https://cloud.ibm.com/docs/cloud-object-storage/libraries?topic=cloud-object-storage-node)[Using Java](https://cloud.ibm.com/docs/cloud-object-storage/libraries?topic=cloud-object-storage-java)[Using Go](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-using-go).\n\n\n\n\n\n Code Example \n\nThe code examples below provide introductory examples of running the basic operations with Object Storage. For simplicity, the code example can be run multiple times as it uses Universally Unique Identifiers (UUIDs) for bucket/item names to prevent potential conflicts.\n\nIn your code, you must remove the angled brackets or any other excess characters that are provided here as illustration.\n\nTo complete the code example, you need to replace the following values:\n\n\n\n Value Description Example \n\n <endpoint> Regional endpoint for your COS instance s3.us-south.cloud-object-storage.appdomain.cloud \n <api-key> IAM API Key with at least Writer permissions xxxd12V2QHXbjaM99G9tWyYDgF_0gYdlQ8aWALIQxXx4 \n <resource-instance-id> Unique ID for the Service Instance crn:v1:bluemix:public:cloud-object-storage:global:a/xx999cd94a0dda86fd8eff3191349999:9999b05b-x999-4917-xxxx-9d5b326a1111:: \n <storage-class> Storage class for a new bucket us-south-standard \n\n\n\nFor more information about endpoints, see [Endpoints and storage locations](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-endpointsendpoints).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-sdk-gs"}]}
{"task_id": "e1b602e47ded79a35d8df4eefe194e39<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03126-3707-6008", "score": 26.267342, "text": "\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform.\n\n\n\n\n\n What languages does your assistant speak? \n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language).\n\n\n\n\n\n Does your assistant see the glass as half full? \n\nIs your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Choose a personality for your assistant, and then write conversations that reflect that personality. Don't overdo it. Don't sacrifice usability for the sake of keeping your assistant in character. But strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chat bots to identify themselves as chat bots.\n\n\n\n\n\n Who will build your assistant? \n\nAssemble a team with people who understand your customers and their needs, people who know how to interact with customers to reach the best outcomes. These subject matter experts can focus on designing an engaging conversational flow. In fact, the actions skill is designed with this type of expert in mind. The team can simultaneously build a conversational flow by defining discrete actions.\n\nIf you have data scientists or team members with programming skills, you can take advantage of some advanced capabilities that require varying levels of development expertise. This set of users might prefer to build the conversational flow with a dialog skill because there is greater visibility into the individual components that make up the training data.\n\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistants"}, {"document_id": "ibmcld_03120-4813-6717", "score": 25.324118, "text": "\nFor more information, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions. For a dialog skill, add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Phone integration: If you want to deploy an assistant that uses the universal language model with the phone integration, you must connect to custom Speech service language models that can understand the language you're using. For more information about supported language models, see the [Speech to Text](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-modelsmodelsList) and [Text to Speech](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-voiceslanguageVoices) documentation.\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-basicsweb-chat-basics-global).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}, {"document_id": "ibmcld_03120-1659-3917", "score": 24.168016, "text": "\nThe precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\nFor example, use the web chat integration with your French-speaking assistant to deploy to a French-language page on your website. Deploy your German-speaking assistant to the German page of your website. Maybe you have a support phone number for French customers. You can configure your French-speaking assistant to answer those calls, and configure another phone number that German customers can use.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}, {"document_id": "ibmcld_16364-101992-104197", "score": 23.19119, "text": "\n: The new model, which is being offered as a beta feature in English-language dialog and actions skills, is faster and more accurate. It combines traditional machine learning, transfer learning, and deep learning techniques in a cohesive model that is highly responsive at run time. For more information, see [Improved intent recognition](https://cloud.ibm.com/docs/assistant?topic=assistant-intent-detection).\n\n\n\n\n\n 3 November 2020 \n\nSuggestions are now generally available\n: The Suggestions feature that is available for the web chat integration is generally available and is enabled by default when you create a new web chat integration. For more information, see [Showing more suggestions](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nNew languages supported by the dialog analysis notebook\n: The Dialog skill analysis notebook was updated with language support for French, German, Spanish, Czech, Italian, and Portuguese. For more information, see [Analysis notebooks](https://cloud.ibm.com/docs/assistant?topic=assistant-logs-resourceslogs-resources-jupyter-logs).\n\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_03369-16079-18117", "score": 22.686768, "text": "\n: The dialog feature is available in the new Watson Assistant experience. If you have a dialog-based assistant that was built using the classic Watson Assistant, you can now migrate your dialog skill to the new Watson Assistant experience. For more information, see [Migrating to the new experience](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-migrate-overview).\n\n\n\n\n\n 25 March 2022 \n\nImproved irrelevance detection for Dutch\n: Irrelevance detection for Dutch disregards any punctuation in an input sentence. For example, you can now expect the same confidence score for the following two inputs: ik ben een kleine krijger? and ik ben een kleine krijger. In this example, the question mark (?) doesn't affect the confidence score.\n\nImproved enhanced intent detection\n: The exact match in enhanced intent detection now better handles small differences between training examples and runtime utterances when the differences do not change the meaning of a sentence.\n\nFor example, suppose in your training examples, covid-19 is in the covid intent and @doctortype_facilitytype around Palm Beach is in the find_provide_master intent. In this example, the @doctortype_facilitytype direct entity reference contains entity values, including hospital. At run time, covid19 is predicted as 100% confident for the covid intent, and hospital around palm beach is predicted as 100% confident for the find_provide_master intent.\n\nThis update applies to the following languages: English, French, Spanish, Italian, and the universal language model. For more information, see [Accessing intents](https://cloud.ibm.com/docs/assistant?topic=assistant-expression-languageexpression-language-intent).\n\n\n\n\n\n 23 March 2022 \n\nFuzzy matching updates\n: Previously, an update was made so that interactions between the stemming and misspelling fuzzy matching features were not allowed. This change applied to the following languages: English, French, German, and Czech. This was updated so that this change applies only to the English language.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_02839-1790-3940", "score": 22.642424, "text": "\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n3. Create the skill.\n4. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kebab.png), and then select Language preferences.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-language"}, {"document_id": "ibmcld_03126-5596-6966", "score": 21.487408, "text": "\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).\n\n\n\n\n\n Do you have existing content to leverage? \n\nThe answer to many a common question is already documented somewhere in your organization's technical information collateral. If only you could find it!\n\nGive your assistant access to this information by adding a search skill to your assistant. The search skill uses Discovery to return smart answers to natural language questions.\n\n\n\n\n\n Expand your assistant's responsibilities \n\nIf you start small, and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. The built-in metrics of active user conversations help you understand what your customers are asking about and how well your assistant is able to meet their needs.\n\nNothing beats real customer data. It will tell you what areas to tackle next.\n\n\n\n\n\n Ready to start building? \n\nSee [Creating an assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-add) to get started.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistants"}, {"document_id": "ibmcld_03369-64600-66787", "score": 21.27067, "text": "\n: Want a quick way to see how your dialog is doing at responding to customer queries? Enable the new coverage metric to find out. The coverage metric measures the rate at which your dialog is confident that it can address a customer's request per message. For conversations that are not covered, you can review the logs to learn more about what the customer wanted. For the metric to work, you must design your dialog to include an Anything else node that is processed when no other dialog node intents are matched. For more information, see [Graphs and statistics](https://cloud.ibm.com/docs/assistant?topic=assistant-logs-overviewlogs-overview-graphs).\n\nTry out the enhanced intent detection model\n: The new model, which is being offered as a beta feature in English-language dialog and actions skills, is faster and more accurate. It combines traditional machine learning, transfer learning, and deep learning techniques in a cohesive model that is highly responsive at run time.\n\n\n\n\n\n 3 November 2020 \n\nSuggestions are now generally available\n: The Suggestions feature that is available for the web chat integration is generally available and is enabled by default when you create a new web chat integration. For more information, see [Showing more suggestions](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nNew languages supported by the dialog analysis notebook\n: The Dialog skill analysis notebook was updated with language support for French, German, Spanish, Czech, Italian, and Portuguese. For more information, see [Analysis notebooks](https://cloud.ibm.com/docs/assistant?topic=assistant-logs-resourceslogs-resources-jupyter-logs).\n\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_03369-66296-68553", "score": 21.25721, "text": "\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page. This settings page is not displayed in English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills because use of the legacy version of the API is no longer supported for those languages. For more information about the new system entities, see [System entities](https://cloud.ibm.com/docs/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 28 October 2020 \n\nIntroducing the actions skill!\n: The actions skill is the latest step in the continuing evolution of Watson Assistant as a software as a service application. The actions skill is designed to make it simple enough for anyone to build a virtual assistant. We've removed the need to navigate between intents, entities, and dialog to create conversational flows. Building can all now be done in one simple and intuitive interface.\n\nWeb chat integration is created automatically\n: When you create a new assistant, a web chat integration is created for you automatically (in addition to the preview link integration, which was created previously). These integrations are added also to the assistant that is auto-generated (named My first assistant) when you create a new service instance.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_03120-3469-5331", "score": 21.145481, "text": "\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}]}
{"task_id": "e1b602e47ded79a35d8df4eefe194e39<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02839-1790-3940", "score": 21.917751, "text": "\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n3. Create the skill.\n4. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kebab.png), and then select Language preferences.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-language"}, {"document_id": "ibmcld_03120-3469-5331", "score": 20.883953, "text": "\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}, {"document_id": "ibmcld_02839-7-2335", "score": 19.972654, "text": "\nAdding support for global audiences \n\nYour customers come from all around the globe. You need an assistant that can talk to them in their own language and in a familiar style. Choose the approach that best fits your business needs.\n\n\n\n* Quickest solution: The simplest way to add language support is to author the conversational skill in a single language. You can translate each message that is sent to your assistant from the customer's local language to the skill language. Later you can translate each response from the skill language back to the customer's local language.\n\nThis approach simplifies the process of authoring and maintaining the conversational skill. You can build one skill and use it for all languages. However, the intention and meaning of the customer message can be lost in the translation.\n\nFor more information about webhooks you can use for translation, see [Webhook overview](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-webhook-overview).\n* Most precise solution: If you have the time and resources, the best user experience can be achieved when you build multiple conversational skills, one for each language that you want to support. Watson Assistant has built-in support for all languages. Use one of 13 language-specific models or the universal model, which adapts to any other language you want to support.\n\nWhen you build a skill that is dedicated to a language, a language-specific classifier model is used by the skill. The precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-language"}, {"document_id": "ibmcld_03120-1659-3917", "score": 19.583055, "text": "\nThe precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\nFor example, use the web chat integration with your French-speaking assistant to deploy to a French-language page on your website. Deploy your German-speaking assistant to the German page of your website. Maybe you have a support phone number for French customers. You can configure your French-speaking assistant to answer those calls, and configure another phone number that German customers can use.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}, {"document_id": "ibmcld_03126-3707-6008", "score": 19.581097, "text": "\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform.\n\n\n\n\n\n What languages does your assistant speak? \n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language).\n\n\n\n\n\n Does your assistant see the glass as half full? \n\nIs your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Choose a personality for your assistant, and then write conversations that reflect that personality. Don't overdo it. Don't sacrifice usability for the sake of keeping your assistant in character. But strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chat bots to identify themselves as chat bots.\n\n\n\n\n\n Who will build your assistant? \n\nAssemble a team with people who understand your customers and their needs, people who know how to interact with customers to reach the best outcomes. These subject matter experts can focus on designing an engaging conversational flow. In fact, the actions skill is designed with this type of expert in mind. The team can simultaneously build a conversational flow by defining discrete actions.\n\nIf you have data scientists or team members with programming skills, you can take advantage of some advanced capabilities that require varying levels of development expertise. This set of users might prefer to build the conversational flow with a dialog skill because there is greater visibility into the individual components that make up the training data.\n\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistants"}, {"document_id": "ibmcld_03369-52023-54183", "score": 19.383678, "text": "\nSupport for every language!\n: You now can build an assistant in any language you want to support. If a dedicated language model is not available for your target language, create a skill that uses the universal language model. The universal model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from training data written in the target language that you add to it.\n\nThe universal model is available as a beta feature. For more information, see [Understanding the universal language model](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-languageassistant-language-universal).\n\nActions skill improvement\n: Now you can indicate whether or not to ask for a number when you apply a number reply constraint to a step. Test how changes to this setting might help speed up a customer's interaction. Under the right circumstances, it can be useful to let a number mention be recognized and stored without having to explicitly ask the customer for it.\n\n\n\n\n\n 1 March 2021 \n\nIntroducing the Enterprise plan!\n: The Enterprise plan includes all of the market differentiating features of the Plus plan, but with higher capacity limits, additional security features, custom onboarding support to get you going, and a lower overall cost at higher volumes.\n\nTo have a dedicated environment provisioned for your business, request the Enterprise with Data Isolation plan. To submit a request online, go to [http://ibm.biz/contact-wa-enterprise](http://ibm.biz/contact-wa-enterprise).\n\nThe Enterprise plan is replacing the Premium plan. The Premium plan is being retired today. Existing Premium plan users are not impacted. They can continue to work in their Premium instances and create instances up to the 30-instance limit. New users do not see the Premium plan as an option when they create a service instance.\n\nFor more information, see the [Pricing](https://www.ibm.com/cloud/watson-assistant/pricing/) page.\n\nOther plan changes\n: Our pricing has been revised to reflect the features we've added that help you build an assistant that functions as a powerful omnichannel SaaS application.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_03120-4-2233", "score": 18.922373, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Adding support for global audiences \n\nYour customers come from all around the globe. You need an assistant that can talk to them in their own language and in a familiar style. Choose the approach that best fits your business needs.\n\n\n\n* Quickest solution: The simplest way to add language support is to author the conversational skill in a single language. You can translate each message that is sent to your assistant from the customer's local language to the skill language. Later you can translate each response from the skill language back to the customer's local language.\n\nThis approach simplifies the process of authoring and maintaining the conversational skill. You can build one skill and use it for all languages. However, the intention and meaning of the customer message can be lost in the translation.\n\nFor more information about webhooks you can use for translation, see [Webhook overview](https://cloud.ibm.com/docs/assistant?topic=assistant-webhook-overview).\n* Most precise solution: If you have the time and resources, the best user experience can be achieved when you build multiple conversational skills, one for each language that you want to support. Watson Assistant has built-in support for all languages. Use one of 13 language-specific models or the universal model, which adapts to any other language you want to support.\n\nWhen you build a skill that is dedicated to a language, a language-specific classifier model is used by the skill. The precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\nFor example, use the web chat integration with your French-speaking assistant to deploy to a French-language page on your website.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}, {"document_id": "ibmcld_03369-36856-39124", "score": 18.56165, "text": "\nAfter you identify the list of steps, you can then focus on writing engaging content to turn each interaction into a positive experience for your customer.\n\nDate and time response types\n: New to action skills, these response types allow you to collect date and time information from customers as they answer questions or make requests.\n\nNew built-in variables\n: Two kinds of built-in variables are now available for action skills.\n\n\n\n* Set by assistant variables include the common and essential variables Now, Current time, and Current date.\n* Set by integration variables are Timezone and Locale and are available to use when connected to a webhook or integration.\n\n\n\nUniversal language model now generally available\n: You now can build an assistant in any language you want to support. If a dedicated language model is not available for your target language, create a skill that uses the universal language model. The universal model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from training data written in the target language that you add to it. For more information, see [Understanding the universal language model](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-languageassistant-language-universal).\n\n\n\n\n\n 3 June 2021 \n\nLog webhook support for actions and search skills\n: The log webhook now supports messages exchanged with actions skills and search skills, in addition to dialog skills. For more information, see [Logging activity with a webhook](https://cloud.ibm.com/docs/assistant?topic=assistant-webhook-log).\n\n\n\n\n\n 27 May 2021 \n\nChange to conversation skill choices\n: When adding skills to new or existing assistant, the conversation skill choices have been combined, so that you pick from either an actions skill or a dialog skill.\n\nWith this change:\n\n\n\n* New assistants can use up to two skills, either actions and search or dialog and search. Previously, new assistants could use up to three skills: actions, dialog, and search.\n* Existing assistants that already use an actions skill and a dialog skill together can continue to use both.\n* The ability to use actions and dialog skills together in a new assistant is planned for 2H 2021.\n\n\n\n\n\n\n\n 20 May 2021", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_03120-4813-6717", "score": 18.331291, "text": "\nFor more information, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions. For a dialog skill, add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Phone integration: If you want to deploy an assistant that uses the universal language model with the phone integration, you must connect to custom Speech service language models that can understand the language you're using. For more information about supported language models, see the [Speech to Text](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-modelsmodelsList) and [Text to Speech](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-voiceslanguageVoices) documentation.\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-basicsweb-chat-basics-global).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}, {"document_id": "ibmcld_16364-72601-74697", "score": 18.097961, "text": "\nFor more information, see [Actions skill overview](https://cloud.ibm.com/docs/assistant?topic=assistant-actions-overview).\n\nDate and time response types\n: New to action skills, these response types allow you to collect date and time information from customers as they answer questions or make requests. For more information, see [Response types](https://cloud.ibm.com/docs/assistant?topic=assistant-actionsactions-response-types).\n\nNew built-in variables\n: Two kinds of built-in variables are now available for action skills.\n\n\n\n* Set by assistant variables include the common and essential variables Now, Current time, and Current date.\n* Set by integration variables are Timezone and Locale and are available to use when connected to a webhook or integration.\n\n\n\nFor more information, see [Adding and referencing variables](https://cloud.ibm.com/docs/assistant?topic=assistant-actionsactions-variables).\n\nUniversal language model now generally available\n: You now can build an assistant in any language you want to support. If a dedicated language model is not available for your target language, create a skill that uses the universal language model. The universal model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from training data written in the target language that you add to it. For more information, see [Understanding the universal language model](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-languageassistant-language-universal).\n\n\n\n\n\n 3 June 2021 \n\nLog webhook support for actions and search skills\n: The log webhook now supports messages exchanged with actions skills and search skills, in addition to dialog skills. For more information, see [Logging activity with a webhook](https://cloud.ibm.com/docs/assistant?topic=assistant-webhook-log).\n\n\n\n\n\n 27 May 2021 \n\nChange to conversation skill choices\n: When adding skills to new or existing assistant, the conversation skill choices have been combined, so that you pick from either an actions skill or a dialog skill.\n\nWith this change:", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}]}
{"task_id": "e1b602e47ded79a35d8df4eefe194e39<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03119-7-1688", "score": 17.561417, "text": "\nCreating an assistant \n\nCreate an assistant with the skills it needs to address the business goals of your customers.\n\nTo learn more about what an assistant is first, see [Assistants](https://cloud.ibm.com/docs/assistant?topic=assistant-assistants).\n\nFollow these steps to create an assistant:\n\n\n\n1. Click the Assistants icon ![Assistants menu icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/nav-ass-icon.png).\n2. Click Create assistant.\n3. Add details about the new assistant:\n\n\n\n* Name: A name no more than 100 characters in length. A name is required.\n* Description: An optional description no more than 200 characters in length.\n\n\n\n4. Click Create assistant.\n5. Add a skill to the assistant.\n\nNote: You can choose to add an existing skill or create a new one.\n\nSee [Adding a skill to an assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-add).\n\n\n\n\n\n Assistant limits \n\nThe number of assistants you can create depends on your Watson Assistant [plan type](https://www.ibm.com/products/watson-assistant/pricing/). There is also a limit of 100 assistants per service instance.\n\nAfter 30 days of inactivity, an unused assistant in a Lite plan service instance might be deleted to free up space. See [Changing the inactivity timeout setting](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-settings) for more information on the subject.\n\nYou can connect one skill of each type to your assistant. The number of skills you can build differs depending on the plan you have. See [Skill limits](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-addskill-add-limits) for more details.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-add"}, {"document_id": "ibmcld_16364-158662-160553", "score": 17.120207, "text": "\nDialog node limit changes\n: The dialog node limit was temporarily changed from 100,000 to 500 for new Standard plan instances. This limit change was later reversed. If you created a Standard plan instance during the time frame in which the limit was in effect, your dialogs might be impacted. The limit was in effect for skills created between 10 December and 12 December 2018. The lower limits will be removed from all impacted instances in January. If you need to have the lower limit lifted before then, open a support ticket.\n\n\n\n\n\n 1 December 2018 \n\nDetermine the number of dialog nodes\n: To determine the number of dialog nodes in a dialog skill, do one of the following things:\n\n\n\n* From the tool, if it is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant. The trained data section lists the number of dialog nodes.\n* Send a GET request to the /dialog_nodes API endpoint, and include the include_count=true parameter. For example:\n\ncurl -u \"apikey:{apikey}\" \"https://{service-hostname}/assistant/api/v1/workspaces/{workspace_id}/dialog_nodes?version=2018-09-20&include_count=true\"\n\nwhere {service-hostname} is the appropriate URL for your instance. For more details, see [Service endpoint](https://cloud.ibm.com/apidocs/assistant/assistant-v1service-endpoint).\n\nIn the response, the total attribute in the pagination object contains the number of dialog nodes.\n\nSee [Troubleshooting skill import issues](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-dialog-addskill-dialog-add-import-errors) for information about how to edit skills that you want to continue using.\n\n\n\n\n\n\n\n 27 November 2018 \n\nA new service plan, the Plus plan, is available\n: The new plan offers premium-level features at a lower price point. Unlike previous plans, the Plus plan is a user-based billing plan.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_03073-7-1928", "score": 16.717676, "text": "\nCreating skill versions \n\nVersions help you manage the workflow of a dialog skill development project.\n\nCreate a skill version to capture a snapshot of the training data (intents and entities) and dialog in the skill at key points during the development process. Being able to save an in-progress skill at a specific point in time is especially useful as you start to fine tune your assistant. You often need to make a change and see the impact of the change in real time before you can determine whether or not the change improves or lessens the effectiveness of the assistant. Based on your findings from a test environment deployment, you can make an informed decision about whether to deploy a given change to an assistant that is deployed in a production environment.\n\nTo learn more about how versions can improve the workflow you use to build an assistant, [read this blog post](https://medium.com/ibm-watson/watson-assistant-versions-announcement-d60869b1f5f).\n\n\n\n Creating a version \n\nYou can edit only one version of the dialog skill at a time. The in-progress version is called the development version.\n\nWhen you save a version, any skill settings that you applied to the development version are saved also.\n\nTo create a dialog skill version, follow these steps:\n\n\n\n1. From the header of the skill, click Save new version, and then describe the current state of the skill.\n\nAdding a good description will help you to distinguish multiple versions from one another later.\n2. Click Save.\n\n\n\nA snapshot is taken of the current skill and saved as a new version. You remain in the development version of the skill. Any changes you make continue to be applied to the development version, not the version you saved. To access the version you saved, go to the Versions page.\n\n\n\n\n\n Deploying a skill version \n\n\n\n1. From the skill menu, click Versions.\n\nv1.3: Click the Skills tab, and then click Versions.\n2. Click the !", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-versions"}, {"document_id": "ibmcld_03373-7076-8670", "score": 16.491484, "text": "\nYou can then create a collection from a data source and configure your search skill to search this collection for answers to customer queries.\n\nThe following diagram illustrates how user input is processed when both a dialog skill and a search skill are added to an assistant. Any questions that the dialog is not designed to answer are sent to the search skill, which finds a relevant response from a Discovery data collection.\n\n![Diagram of how a question gets routed to the search skill.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/search-skill-diagram.png)\n\n\n\n\n\n Creating a skill \n\nYou can add one conversation skill (actions or dialog) and one search skill to an assistant.\n\n\n\n Conversation \n\n\n\n* [Actions skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-actions-add)\n* [Dialog Skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-dialog-add)\n\n\n\n\n\n\n\n Search \n\n\n\n* [Search Skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-search-add)\n\n\n\n\n\n\n\n\n\n Skill limits \n\nThe number of skills you can create depends on your Watson Assistant plan type. Any sample dialog skills that are available for you to use do not count toward your limit unless you use them. A skill version does not count as a skill.\n\n\n\nPlan details\n\n Plan Maximum number of skills of each type per service instance \n\n Enterprise 100 \n Premium (legacy) 100 \n Plus 50 \n Standard (legacy) 20 \n Lite, Trial 5 \n\n\n\n* After 30 days of inactivity, an unused skill in a Lite plan service instance might be deleted to free up space.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-add"}, {"document_id": "ibmcld_03139-2715-4132", "score": 16.068106, "text": "\n[Skills menu icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/nav-skills-icon.png).\n2. Click Create skill.\n3. Choose to create either an actions or dialog skill, then click Next.\n4. Select the JSON file you want to import.\n\nThe imported JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding. The JSON file cannot contain tabs, newlines, or carriage returns.\n\nThe maximum size for a skill JSON file is 10MB. If you need to import a larger skill, consider using the REST API. For more information, see the [API Reference](https://cloud.ibm.com/apidocs/assistant/assistant-v1createworkspace).\n5. Click Upload.\n\nIf you have trouble uploading a skill, see [Troubleshooting skill import issues](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-dialog-addskill-dialog-add-import-errors).\n6. Specify the details for the skill:\n\n\n\n* Name: A name no more than 100 characters in length. A name is required.\n* Description: An optional description no more than 200 characters in length.\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the skill, it appears as a tile on the Skills page.\n\n\n\n\n\n Re-creating your assistant \n\nYou can now re-create your assistant. You can then link your uploaded skills to the assistant, and configure integrations for it.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-backup"}, {"document_id": "ibmcld_02953-12940-14393", "score": 15.911003, "text": "\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\nYou can see the number of dialog nodes in a dialog skill from the assistant tile. If the skill is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant. The trained data section lists the number of dialog nodes.\n\nIf the total seems larger than you expected, it might be because the dialog that you build from the application is translated into a JSON object. Some fields that appear to be part of a single node are actually structured as separate dialog nodes in the underlying JSON object.\n\n\n\n* Each node and folder is represented as its own node.\n* Each conditional response that is associated with a single dialog node is represented as an individual node.\n* For a node with slots, each slot, slot found response, slot not found response, slot handler, and if set, the prompt for everything response is an individual node. In effect, one node with three slots might be equivalent to eleven dialog nodes.\n\n\n\nPrevious topic:[Controlling the dialog flow](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime)\n\nNext topic:[Dialog building tips](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-tips)", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-tasks"}, {"document_id": "ibmcld_03369-74273-76338", "score": 15.701776, "text": "\n: Try the new autolearning beta feature to empower your skill to improve itself automatically over time. Your skill observes customer choices to understand which choices are most often the best. As its confidence grows, your skill presents better options to get the right answers to your customers with fewer clicks. For more information, see [Empower your skill to learn over time](https://cloud.ibm.com/docs/assistant?topic=assistant-autolearn).\n\nShow more of search results\n: When search results are returned from the search skill, the customer can now click a twistie to expand the search result card to see more of the returned text.\n\n\n\n\n\n 29 July 2020 \n\nThe @sys-location and @sys-person system entities were removed\n: The @sys-location and @sys-person system entities are no longer listed on the System entities page. If your dialog uses one of these entities, a red Entity not created notification is displayed to inform you that the entity is not recognized.\n\nSkill menu actions moved\n: The menu that was displayed in the header of the skill while you were working with a skill was removed. The actions that were available from the menu, such as import and export, are still available. Go to the Skills page, and click the menu on the skill tile.\n\nThe import skill process was updated to support overwriting an existing skill on import. For more information, see [Overwriting a skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-tasksskill-tasks-overwrite).\n\nDialog issues were addressed\n: These dialog issues were addressed:\n\n\n\n* Fixed an issue with adding a jump-to from a conditional response in one node to a conditional response in another node.\n* The page now responds better when you scroll horizontally to see multiple levels of child nodes.\n\n\n\n\n\n\n\n 15 July 2020 \n\nSupport ended for @sys-location and @sys-person\n: The person and location system entities, which were available as a beta feature in English dialog skills only, are no longer supported. You cannot enable them. If your dialog uses them, they are ignored by the service.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_03381-1467-3226", "score": 15.619455, "text": "\nThe uploaded JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding. The JSON cannot contain tabs, newlines, or carriage returns.\n\nThe maximum size for a skill JSON file is 10 MB. If you need to upload a larger skill, consider using the REST API. For more information, see the [API Reference](https://cloud.ibm.com/apidocs/assistant/assistant-v1?curl=createworkspace).\n\nClick Upload.\n\nIf you have trouble uploading a skill, see [Troubleshooting skill upload issues](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-dialog-addskill-dialog-add-import-errors).\n* If you have created a dialog skill already, the Add existing skill tab is displayed, and you can click to add an existing skill.\n\n\n\n3. Specify the details for the skill:\n\n\n\n* Name: A name no more than 64 characters in length. A name is required.\n* Description: An optional description no more than 128 characters in length.\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n4. For Skill type, choose Dialog.\n5. Click Create skill.\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https://cloud.ibm.com/docs/assistant?topic=assistant-catalog).\n* To define your own intents, see [Defining intents](https://cloud.ibm.com/docs/assistant?topic=assistant-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-add).\n\n\n\n Troubleshooting skill upload issues", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-dialog-add"}, {"document_id": "ibmcld_03043-7-2031", "score": 15.58002, "text": "\nAdding a skill to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nYou can create the following types of skills:\n\n\n\n* Dialog skill: Uses Watson natural language processing and machine learning technologies to understand user questions and requests, and respond to them with answers that are authored by you.\n* Search skill: For a given user query, uses the IBM Watson\u00ae Discovery service to search a data source of your self-service content and return an answer.\n\n\n\nTypically, you create a skill of each type first. Then, as you build a dialog for the dialog skill, you decide when to initiate the search skill. For some questions or requests, a hardcoded or programmatically-derived response (that is defined in the dialog skill) is sufficient. For others, you might want to provide a more robust response by returning a full passage of related information (that is extracted from an external data source by using the search skill).\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. In the tool, the name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-add"}, {"document_id": "ibmcld_03273-13172-14845", "score": 15.454623, "text": "\nPlan Dialog nodes per skill \n\n Enterprise 100,000 \n Premium (legacy) 100,000 \n Plus 100,000 \n Trial 25,000 \n Lite 25,000 \n\n\n\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\n\n\n\n\n Finding a dialog node by its node ID \n\nYou can search for a dialog node by its node ID. Enter the full node ID into the search field. You might want to find the dialog node that is associated with a known node ID for any of the following reasons:\n\n\n\n* You are reviewing logs, and the log refers to a section of the dialog by its node ID.\n* You want to map the node IDs listed in the nodes_visited property of the API message output to nodes that you can see in your dialog tree.\n* A dialog runtime error message informs you about a syntax error, and uses a node ID to identify the node you need to fix.\n\n\n\nAnother way to discover a node based on its node ID is by following these steps:\n\n\n\n1. From the Dialog page, select any node in your dialog tree.\n2. Close the edit view if it is open for the current node.\n3. In your web browser's location field, a URL should display that has syntax similar to the following:\n\nhttps://{location}.assistant.watson.cloud.ibm.com/{location}/{instance-id}/skills/{skill-id}/build/dialognode={node-id}\n4. Edit the URL by replacing the current {node-id} value with the ID of the node you want to find, and then submit the new URL.\n5. If necessary, highlight the edited URL again, and resubmit it.\n\n\n\nThe page refreshes, and shifts focus to the dialog node with the node ID that you specified.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-tasks"}]}
{"task_id": "e1b602e47ded79a35d8df4eefe194e39<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03126-3707-6008", "score": 21.846943, "text": "\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform.\n\n\n\n\n\n What languages does your assistant speak? \n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language).\n\n\n\n\n\n Does your assistant see the glass as half full? \n\nIs your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Choose a personality for your assistant, and then write conversations that reflect that personality. Don't overdo it. Don't sacrifice usability for the sake of keeping your assistant in character. But strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chat bots to identify themselves as chat bots.\n\n\n\n\n\n Who will build your assistant? \n\nAssemble a team with people who understand your customers and their needs, people who know how to interact with customers to reach the best outcomes. These subject matter experts can focus on designing an engaging conversational flow. In fact, the actions skill is designed with this type of expert in mind. The team can simultaneously build a conversational flow by defining discrete actions.\n\nIf you have data scientists or team members with programming skills, you can take advantage of some advanced capabilities that require varying levels of development expertise. This set of users might prefer to build the conversational flow with a dialog skill because there is greater visibility into the individual components that make up the training data.\n\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistants"}, {"document_id": "ibmcld_03120-4813-6717", "score": 21.728569, "text": "\nFor more information, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions. For a dialog skill, add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Phone integration: If you want to deploy an assistant that uses the universal language model with the phone integration, you must connect to custom Speech service language models that can understand the language you're using. For more information about supported language models, see the [Speech to Text](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-modelsmodelsList) and [Text to Speech](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-voiceslanguageVoices) documentation.\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-basicsweb-chat-basics-global).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}, {"document_id": "ibmcld_02839-1790-3940", "score": 21.254862, "text": "\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n3. Create the skill.\n4. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kebab.png), and then select Language preferences.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-language"}, {"document_id": "ibmcld_03120-1659-3917", "score": 21.250336, "text": "\nThe precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\nFor example, use the web chat integration with your French-speaking assistant to deploy to a French-language page on your website. Deploy your German-speaking assistant to the German page of your website. Maybe you have a support phone number for French customers. You can configure your French-speaking assistant to answer those calls, and configure another phone number that German customers can use.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}, {"document_id": "ibmcld_03120-3469-5331", "score": 20.510868, "text": "\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}, {"document_id": "ibmcld_02839-3583-5403", "score": 19.887243, "text": "\nIf your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. Add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-basicsweb-chat-basics-global).", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-language"}, {"document_id": "ibmcld_16364-101992-104197", "score": 19.587166, "text": "\n: The new model, which is being offered as a beta feature in English-language dialog and actions skills, is faster and more accurate. It combines traditional machine learning, transfer learning, and deep learning techniques in a cohesive model that is highly responsive at run time. For more information, see [Improved intent recognition](https://cloud.ibm.com/docs/assistant?topic=assistant-intent-detection).\n\n\n\n\n\n 3 November 2020 \n\nSuggestions are now generally available\n: The Suggestions feature that is available for the web chat integration is generally available and is enabled by default when you create a new web chat integration. For more information, see [Showing more suggestions](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nNew languages supported by the dialog analysis notebook\n: The Dialog skill analysis notebook was updated with language support for French, German, Spanish, Czech, Italian, and Portuguese. For more information, see [Analysis notebooks](https://cloud.ibm.com/docs/assistant?topic=assistant-logs-resourceslogs-resources-jupyter-logs).\n\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_03126-5596-6966", "score": 19.328264, "text": "\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).\n\n\n\n\n\n Do you have existing content to leverage? \n\nThe answer to many a common question is already documented somewhere in your organization's technical information collateral. If only you could find it!\n\nGive your assistant access to this information by adding a search skill to your assistant. The search skill uses Discovery to return smart answers to natural language questions.\n\n\n\n\n\n Expand your assistant's responsibilities \n\nIf you start small, and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. The built-in metrics of active user conversations help you understand what your customers are asking about and how well your assistant is able to meet their needs.\n\nNothing beats real customer data. It will tell you what areas to tackle next.\n\n\n\n\n\n Ready to start building? \n\nSee [Creating an assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-add) to get started.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistants"}, {"document_id": "ibmcld_03369-16079-18117", "score": 19.176592, "text": "\n: The dialog feature is available in the new Watson Assistant experience. If you have a dialog-based assistant that was built using the classic Watson Assistant, you can now migrate your dialog skill to the new Watson Assistant experience. For more information, see [Migrating to the new experience](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-migrate-overview).\n\n\n\n\n\n 25 March 2022 \n\nImproved irrelevance detection for Dutch\n: Irrelevance detection for Dutch disregards any punctuation in an input sentence. For example, you can now expect the same confidence score for the following two inputs: ik ben een kleine krijger? and ik ben een kleine krijger. In this example, the question mark (?) doesn't affect the confidence score.\n\nImproved enhanced intent detection\n: The exact match in enhanced intent detection now better handles small differences between training examples and runtime utterances when the differences do not change the meaning of a sentence.\n\nFor example, suppose in your training examples, covid-19 is in the covid intent and @doctortype_facilitytype around Palm Beach is in the find_provide_master intent. In this example, the @doctortype_facilitytype direct entity reference contains entity values, including hospital. At run time, covid19 is predicted as 100% confident for the covid intent, and hospital around palm beach is predicted as 100% confident for the find_provide_master intent.\n\nThis update applies to the following languages: English, French, Spanish, Italian, and the universal language model. For more information, see [Accessing intents](https://cloud.ibm.com/docs/assistant?topic=assistant-expression-languageexpression-language-intent).\n\n\n\n\n\n 23 March 2022 \n\nFuzzy matching updates\n: Previously, an update was made so that interactions between the stemming and misspelling fuzzy matching features were not allowed. This change applied to the following languages: English, French, German, and Czech. This was updated so that this change applies only to the English language.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_02841-1435-2454", "score": 19.131472, "text": "\n[A sample dialog tree with example content](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/dialog-depiction.png) \n\n\n\nThe dialog skill itself is defined in text, but you can integrate it with Watson Speech to Text and Watson Text to Speech services that enable users to interact with your assistant verbally.\n\n![Out-of-the-box training data](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/oob.png) If you want to get started quickly, add prebuilt training data to your dialog skill so your assistant can start helping your customers with the basics.\n\n\n\n\n\n Search skill \n\nA search skill leverages information from existing corporate knowledge bases or other collections of content authored by subject matter experts to address unanticipated or more nuanced customer inquiries.\n\nSee [Creating assistants](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-add) to get started.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistants"}]}
{"task_id": "e1b602e47ded79a35d8df4eefe194e39<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00644-15701-17094", "score": 16.477581, "text": "\nWhen you issue a view request that specifies the keys parameter, the results are returned in the same order as the supplied keys array.\n\nSee the example of using HTTP to request the records in reversed sort order:\n\nGET $SERVICE_URL/$DATABASE/_design/$DDOC/_view/$VIEW_NAME?descending=true HTTP/1.1\nAccept: application/json\n\nSee the example of requesting the records in reverse sort order.\n\nClient libraries use POST method instead of GET because they have a similar behavior.\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl -X GET \"$SERVICE_URL/users/_design/allusers/_view/getVerifiedEmails?descending=true\"\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.PostViewOptions;\nimport com.ibm.cloud.cloudant.v1.model.ViewResult;\n\nCloudant service = Cloudant.newInstance();\n\nPostViewOptions viewOptions = new PostViewOptions.Builder()\n.db(\"users\")\n.ddoc(\"allusers\")\n.view(\"getVerifiedEmails\")\n.descending(true)\n.build();\n\nViewResult response =\nservice.postView(viewOptions).execute()\n.getResult();\n\nSystem.out.println(response);\n\nconst { CloudantV1 } = require('@ibm-cloud/cloudant');\n\nconst service = CloudantV1.newInstance({});\n\nservice.postView({\ndb: 'users',\nddoc: 'allusers',\nview: 'getVerifiedEmails',\ndescending: true\n}).then(response => {\nconsole.log(response.result);\n});\n\nfrom ibmcloudant.cloudant_v1 import CloudantV1\n\nservice = CloudantV1.new_instance()", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-using-views"}, {"document_id": "ibmcld_00539-2548-4016", "score": 15.632468, "text": "\n\"type\": \"json\"\n}\n\n\n\n\n\n Can I sort in reverse order? \n\nYes! IBM Cloudant Query supports sorting the result set in ascending or descending order, but not a combination of the two. For example, a query that sorts some fields in ascending order, and a query where descending is not allowed.\n\nThis query returns documents that match firstname and surname and sorts by surname/firstname/date descending:\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"sort\": [\n{ \"firstname\": \"desc\" },\n{ \"surname\": \"desc\" },\n{ \"date\": \"desc\" }\n],\n\"limit\": 10\n}\n\nA suitable index must be present that contains the selector fields and the sort fields. Otherwise, IBM Cloudant refuses to execute the query. A suitable index definition for the previous query is shown next:\n\n{\n\"index\": {\n\"fields\": [\n\"firstname\",\n\"surname\",\n\"date\"\n]\n},\n\"ddoc\": \"jsonindexes\",\n\"name\": \"byNameAndDate\",\n\"type\": \"json\"\n}\n\nThe previous index is suitable for both ascending and descending sort order.\n\n\n\n\n\n How can I tell if an index is backing a query? \n\nThe [POST /{db}/_explain](https://cloud.ibm.com/apidocs/cloudant?code=javapostexplain) API endpoint when passed a JSON object that is usually sent to the [POST /{db}/_find](https://cloud.ibm.com/apidocs/cloudantpostfind) endpoint, explains how such a query is handled and which indexes, if any, might be used.\n\nIf the index object in the response indicates that \"all_docs\" is being used, a full database scan is required to service the query.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-faq-using-cloudant-query"}, {"document_id": "ibmcld_13429-155971-158020", "score": 15.529749, "text": "\nNew sort parameter for methods that list words for custom language models\n: The GET /v1/customizations/{customization_id}/words method now includes a sort query parameter that controls the order in which the words are to be listed. The parameter accepts two arguments, alphabetical or count, to indicate how the words are to be sorted. You can prepend an optional + or - to an argument to indicate whether the results are to be sorted in ascending or descending order. By default, the method displays the words in ascending alphabetical order. For more information, see [Listing custom words from a custom language model](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-manageWordslistWords).\n\nFor custom models created prior to the introduction of the count field, use of the count argument with the sort parameter is meaningless. Use the default alphabetical argument with such models.\n\nNew error field format for methods that list words for custom language models\n: The error field that can be returned as part of the JSON response from the GET /v1/customizations/{customization_id}/words and GET /v1/customizations/{customization_id}/words/{word_name} methods is now an array. If the service discovered one or more problems with a custom word's definition, the field lists each problem element from the definition and provides a message that describes the problem. For more information, see [Listing custom words from a custom language model](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-manageWordslistWords).\n\nThe keywords_threshold and word_alternatives_threshold parameters no longer accept a null value\n: The keywords_threshold and word_alternatives_threshold parameters of the recognition methods no longer accept a null value. To omit keywords and word alternatives from the response, omit the parameters. A specified value must be a float.\n\n\n\n\n\n 22 September 2016 \n\nNew beta language model customization interface\n: The service now offers a new beta language model customization interface for US English.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-release-notes"}, {"document_id": "ibmcld_16485-5134-7047", "score": 15.151657, "text": "\nFor details about how Knowledge Studio handles Arabic character shaping and numeric shaping, see [Configuring support for Arabic](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_langsupp_ar).\n\n\n\n\n\n\n\n CSV file dictionary \n\nAlso referred to as the standard dictionary format, a dictionary in comma-separated value (CSV) format is a file that you can edit after you upload it. The maximum size of a CSV file that you can upload is 1 MB. If you have a larger dictionary file, then break the large file into multiple files and upload them one at a time into a single dictionary in your Knowledge Studio workspace.\n\nTo summarize the requirements, you must use a text editor to create the CSV file, not software like Microsoft Excel, and the file must use UTF-8 encoding that does not include the byte order mark (BOM) at the start of the text stream. The first row in the file must specify the following column headers:\n\nlemma,poscode,surface\n\nThe remaining lines in the file specify the dictionary entries, where:\n\n\n\n* lemma\n\nSpecifies the most representative word form for the entry.\n* poscode (Arabic, Brazilian Portuguese, English, French, German, Italian, and Spanish)\n\nSpecifies a code that identifies the part of speech. This part of speech information is used by the dictionary annotator to help with sentence tokenization.\n\n\n\n* 0 - Unknown\n\n> Note: This code supports the scenario where you want to upload a large machine-generated dictionary that does not include part of speech information in each entry. You can assign unknown to all entries by default. Avoid using this code, if possible.\n* 1 - Pronoun\n* 2 - Verb\n* 3 - Noun\n* 4 - Adjective\n* 5 - Adverb\n* 6 - Adposition\n* 7 - Interjection\n* 8 - Conjunction\n* 9 - Determiner\n* 10 - Quantifier\n\n\n\nIn English, noun (3), verb (2), and adjective (4) are the most common parts of speech that are used for dictionary entries.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-dictionaries"}, {"document_id": "ibmcld_02914-1593-3315", "score": 14.727815, "text": "\nThe following example shows how the output object is represented in the dialog JSON editor:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"values\":\n{\n\"text\": \"This is my response text.\"\n}\n],\n\"response_type\": \"text\",\n\"selection_policy\": \"sequential\"\n}\n]\n}\n}\n\n\n\nIn the resulting API /message response, the text response is formatted as follows:\n\n{\n\"text\": \"This is my response text.\",\n\"response_type\": \"text\"\n}\n\nThe following output object JSON format is supported for backwards compatibility. With the introduction of rich response types, the output.text structure was augmented with the output.generic structure to facilitate supporting other types of responses in addition to text. Use the new format when you create new nodes to give yourself more flexibility, because you can subsequently change the response type, if needed.\n\n{\n\"output\": {\n\"text\": {\n\"values\": [\n\"This is my response text.\"\n]\n}\n}\n}\n\nThere are response types other than a text response that you can define. See [Responses](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-responses) for more details.\n\nYou can learn more about the /message API call from the [API reference](https://cloud.ibm.com/apidocs/assistant/assistant-v2).\n\n\n\n Retaining information across dialog turns \n\nThe dialog in a dialog skill is stateless, meaning that it does not retain information from one interaction with the user to the next. When you add a dialog skill to an assistant and deploy it, the assistant saves the context from one message call and then re-submits it on the next request throughout the current session. The current session lasts for as long a user interacts with the assistant plus the designated session inactivity time frame.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime-context"}, {"document_id": "ibmcld_02900-30442-32310", "score": 14.6824, "text": "\nChanging the order helps to avoid bias that can be introduced by a percentage of people who always pick the first option without carefully reviewing all of their choices beforehand.<-- </section \"id=\"section-dialog-runtime-choose-nodes\" \"> --><-- <section \"id=\"section-dialog-runtime-handle-none\" \"> --> Handling none of the above When a user clicks the None of the above option, your assistant strips the intents that were recognized in the user input from the message and submits it again. This action typically triggers the anything else node in your dialog tree.To customize the response that is returned in this situation, you can add a root node with a condition that checks for a user input with no recognized intents (the intents are stripped, remember) and contains a suggestion_id property. A suggestion_id property is added by your assistant when disambiguation is triggered.Add a root node with the following condition: intents.size()==0 && input.suggestion_id\nThis condition is met only by input that has triggered a set of disambiguation options of which the user has indicated none match her goal.Add a response that lets users know that you understand that none of the options that were suggested met their needs, and take appropriate action.Again, the placement of nodes in the tree matters. If a node that conditions on an entity type that is mentioned in the user input is higher in the tree than this node, its response is displayed instead.<-- </section \"id=\"section-dialog-runtime-handle-none\" \"> --><-- <section \"id=\"section-dialog-runtime-disambig-test\" \"> --> Testing disambiguation To test disambiguation, complete the following steps:<-- <ol> -->1. From the Try it out pane, enter a test utterance that you think is a good candidate for disambiguation, meaning two or more of your dialog nodes are configured to address utterances like it.2.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime"}, {"document_id": "ibmcld_13673-18705-20148", "score": 14.679797, "text": "\nYou can use the <say-as> element to control how strings are pronounced, including whether they are to be spelled out as individual characters with the letters and digits elements.\n\nFor German, you can also control the pace at which the service pronounces the characters. For more information, see [Specifying how strings are spelled out](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-synthesis-paramsparams-spell-out-mode).\n\n\n\n The interpret-as attribute \n\nAcceptable values for the interpret-as attribute and examples of each value follow. The service supports the following values as arguments to the interpret-as attribute:\n\n\n\n* [cardinal](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-elementssay-as-cardinal)\n* [date](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-elementssay-as-date)\n* [digits](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-elementssay-as-digits)\n* [interjection](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-elementssay-as-interjection)\n* [letters](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-elementssay-as-letters)\n* [number](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-elementssay-as-number)\n* [ordinal](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-elementssay-as-ordinal)\n* [vxml:boolean](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-elementsvxml-boolean)", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-elements"}, {"document_id": "ibmcld_16421-5126-7041", "score": 14.656932, "text": "\nFor details about how Knowledge Studio handles Arabic character shaping and numeric shaping, see [Configuring support for Arabic](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_langsupp_ar).\n\n\n\n\n\n\n\n CSV file dictionary \n\nAlso referred to as the standard dictionary format, a dictionary in comma-separated value (CSV) format is a file that you can edit after you upload it. The maximum size of a CSV file that you can upload is 1 MB. If you have a larger dictionary file, then break the large file into multiple files and upload them one at a time into a single dictionary in your Knowledge Studio workspace.\n\nTo summarize the requirements, you must use a text editor to create the CSV file, not software like Microsoft Excel, and the file must use UTF-8 encoding that does not include the byte order mark (BOM) at the start of the text stream. The first row in the file must specify the following column headers:\n\nlemma,poscode,surface\n\nThe remaining lines in the file specify the dictionary entries, where:\n\n\n\n* lemma\n\nSpecifies the most representative word form for the entry.\n* poscode (Arabic, Brazilian Portuguese, English, French, German, Italian, and Spanish)\n\nSpecifies a code that identifies the part of speech. This part of speech information is used by the dictionary annotator to help with sentence tokenization.\n\n\n\n* 0 - Unknown\n\nThis code supports the scenario where you want to upload a large machine-generated dictionary that does not include part of speech information in each entry. You can assign unknown to all entries by default. Avoid using this code, if possible.\n* 1 - Pronoun\n* 2 - Verb\n* 3 - Noun\n* 4 - Adjective\n* 5 - Adverb\n* 6 - Adposition\n* 7 - Interjection\n* 8 - Conjunction\n* 9 - Determiner\n* 10 - Quantifier\n\n\n\nIn English, noun (3), verb (2), and adjective (4) are the most common parts of speech that are used for dictionary entries.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-dictionaries"}, {"document_id": "ibmcld_16503-13154-14621", "score": 14.458259, "text": "\n4. Specify options for case sensitivity, token range, and special character handling. If, while designing a regular expression, you see false positives, provide more context by extending the pattern in the regular expression or adding context through a sequence pattern. For example, if your postal code expression matches additional terms, incorporate rules for which letters are permitted in specific positions.\n\n\n\n\n\n Regular expression examples \n\nThe following are examples of regular Java expressions that might be used in specific instances. In the pattern descriptions, A represents a character and 9, a digit. For more information about Java syntax, see [Class Pattern](https://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html) Javadoc.\n\n\n\n* To select text that includes any ordinal number of one or more digits followed by th, st, nd, or rd (21st, 2nd, 3rd, and so forth), specify:\n\nd+(st|nd|rd|th)\n* To select text that includes US Social Security numbers formatted as 999-99-9999, specify:\n\nd{3}-d{2}-d{4}\n* To select all text that includes a Canadian postal code formatted as A9A-9A9, A9A 9A9 or A9A9A9 (for example, K1G 3K9, V5g-4X3, and x2H3m5), specify:\n\n[a-zA-Z][a-zA-Z](-|)[0-9][0-9]\n* To select all text that includes a United Kingdom postal code formatted as A9 9AA, A99 9AA, AA99 9AA, A9A 9AA, or a9d AA9A 9AA (for example, M1 1AE, B33 8TH, DN55 1PT, W1A 0AX, CR2 6XH, and SW1A 2AA), specify:\n\n[A-Z]{1,2}[1-9]?[A-Z]?s[0-9]{2,}|GIR 0AA", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-managing-projects-and-extractors"}, {"document_id": "ibmcld_03069-26565-27205", "score": 14.356558, "text": "\n[Close](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/close.png) to close the edit view.\n\n\n\nNow, when you test, you can provide a set of number or a mix of numbers and text as input, and the dialog reminds you of the correct order number format. You have successfully tested your dialog, found a weakness in it, and corrected it.\n\nAnother way you can address this type of scenario is to add a node with slots. See the [Adding a node with slots to a dialog](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-tutorial-slots) tutorial to learn more about using slots.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-tutorial"}]}
{"task_id": "e1b602e47ded79a35d8df4eefe194e39<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03120-4813-6717", "score": 23.704992, "text": "\nFor more information, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions. For a dialog skill, add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Phone integration: If you want to deploy an assistant that uses the universal language model with the phone integration, you must connect to custom Speech service language models that can understand the language you're using. For more information about supported language models, see the [Speech to Text](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-modelsmodelsList) and [Text to Speech](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-voiceslanguageVoices) documentation.\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-basicsweb-chat-basics-global).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}, {"document_id": "ibmcld_03126-3707-6008", "score": 23.60032, "text": "\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform.\n\n\n\n\n\n What languages does your assistant speak? \n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language).\n\n\n\n\n\n Does your assistant see the glass as half full? \n\nIs your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Choose a personality for your assistant, and then write conversations that reflect that personality. Don't overdo it. Don't sacrifice usability for the sake of keeping your assistant in character. But strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chat bots to identify themselves as chat bots.\n\n\n\n\n\n Who will build your assistant? \n\nAssemble a team with people who understand your customers and their needs, people who know how to interact with customers to reach the best outcomes. These subject matter experts can focus on designing an engaging conversational flow. In fact, the actions skill is designed with this type of expert in mind. The team can simultaneously build a conversational flow by defining discrete actions.\n\nIf you have data scientists or team members with programming skills, you can take advantage of some advanced capabilities that require varying levels of development expertise. This set of users might prefer to build the conversational flow with a dialog skill because there is greater visibility into the individual components that make up the training data.\n\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistants"}, {"document_id": "ibmcld_03369-16079-18117", "score": 22.496185, "text": "\n: The dialog feature is available in the new Watson Assistant experience. If you have a dialog-based assistant that was built using the classic Watson Assistant, you can now migrate your dialog skill to the new Watson Assistant experience. For more information, see [Migrating to the new experience](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-migrate-overview).\n\n\n\n\n\n 25 March 2022 \n\nImproved irrelevance detection for Dutch\n: Irrelevance detection for Dutch disregards any punctuation in an input sentence. For example, you can now expect the same confidence score for the following two inputs: ik ben een kleine krijger? and ik ben een kleine krijger. In this example, the question mark (?) doesn't affect the confidence score.\n\nImproved enhanced intent detection\n: The exact match in enhanced intent detection now better handles small differences between training examples and runtime utterances when the differences do not change the meaning of a sentence.\n\nFor example, suppose in your training examples, covid-19 is in the covid intent and @doctortype_facilitytype around Palm Beach is in the find_provide_master intent. In this example, the @doctortype_facilitytype direct entity reference contains entity values, including hospital. At run time, covid19 is predicted as 100% confident for the covid intent, and hospital around palm beach is predicted as 100% confident for the find_provide_master intent.\n\nThis update applies to the following languages: English, French, Spanish, Italian, and the universal language model. For more information, see [Accessing intents](https://cloud.ibm.com/docs/assistant?topic=assistant-expression-languageexpression-language-intent).\n\n\n\n\n\n 23 March 2022 \n\nFuzzy matching updates\n: Previously, an update was made so that interactions between the stemming and misspelling fuzzy matching features were not allowed. This change applied to the following languages: English, French, German, and Czech. This was updated so that this change applies only to the English language.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_02839-1790-3940", "score": 21.02655, "text": "\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n3. Create the skill.\n4. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kebab.png), and then select Language preferences.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-language"}, {"document_id": "ibmcld_16364-101992-104197", "score": 20.960043, "text": "\n: The new model, which is being offered as a beta feature in English-language dialog and actions skills, is faster and more accurate. It combines traditional machine learning, transfer learning, and deep learning techniques in a cohesive model that is highly responsive at run time. For more information, see [Improved intent recognition](https://cloud.ibm.com/docs/assistant?topic=assistant-intent-detection).\n\n\n\n\n\n 3 November 2020 \n\nSuggestions are now generally available\n: The Suggestions feature that is available for the web chat integration is generally available and is enabled by default when you create a new web chat integration. For more information, see [Showing more suggestions](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nNew languages supported by the dialog analysis notebook\n: The Dialog skill analysis notebook was updated with language support for French, German, Spanish, Czech, Italian, and Portuguese. For more information, see [Analysis notebooks](https://cloud.ibm.com/docs/assistant?topic=assistant-logs-resourceslogs-resources-jupyter-logs).\n\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_03120-3469-5331", "score": 20.89019, "text": "\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}, {"document_id": "ibmcld_03049-2703-4536", "score": 20.555763, "text": "\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-catalog).\n* To define your own intents, see [Defining intents](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Troubleshooting skill import issues \n\nIf you receive warnings when you try to upload a skill, take a moment to try to fix the issues.\n\n\n\n1. Make a note of the warning message that are displayed when you try to upload the JSON file.\n2. Edit the skill to address the issues.\n\n\n\n* If you have access to a public service instance, open the skill from there and make edits. Export the edited skill by downloading it.\n* Otherwise, open the JSON file in a text editor and make edits.\n\n\n\nYou might need to remove the @sys-person and @sys-location entities from your training data, and any references to them from dialog nodes, for example.\n3. Try again to import the edited skill.\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon !", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-dialog-add"}, {"document_id": "ibmcld_03120-1659-3917", "score": 20.443497, "text": "\nThe precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\nFor example, use the web chat integration with your French-speaking assistant to deploy to a French-language page on your website. Deploy your German-speaking assistant to the German page of your website. Maybe you have a support phone number for French customers. You can configure your French-speaking assistant to answer those calls, and configure another phone number that German customers can use.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}, {"document_id": "ibmcld_16364-163116-165172", "score": 20.03919, "text": "\nThis version of the tool was evaluated by beta program participants over the past several months.\n\n\n\n* Skills: What you think of as a workspace is now called a skill. A dialog skill is a container for the natural language processing training data and artifacts that enable your assistant to understand user questions, and respond to them.\n\n\n\nWhere are my workspaces? Any workspaces that you created previously are now listed in your service instance as skills. Click the Skills tab to see them. For more information, see [Adding skills to your assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-add).\n\n\n\n* Assistants: You can now publish your skill in just two steps. Add your skill to an assistant, and then set up one or more integrations with which to deploy your skill. The assistant adds a layer of function to your skill that enables Watson Assistant to orchestrate and manage the flow of information for you. See [Assistants](https://cloud.ibm.com/docs/assistant?topic=assistant-assistants).\n* Built-in integrations: Instead of going to the Deploy tab to deploy your workspace, you add your dialog skill to an assistant, and add integrations to the assistant through which the skill is made available to your users. You do not need to build a custom front-end application and manage the conversation state from one call to the next. However, you can still do so if you want to. See [Adding integrations](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-integration-add) for more information.\n* New major API version: A V2 version of the API is available. This version provides access to methods you can use to interact with an assistant at run time. No more passing context with each API call; the session state is managed for you as part of the assistant layer.\n\n\n\nWhat is presented in the tooling as a dialog skill is effectively a wrapper for a V1 workspace. There are currently no API methods for authoring skills and assistants with the V2 API. However, you can continue to use the V1 API for authoring workspaces.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_02932-7-1953", "score": 19.827114, "text": "\nCorrecting user input \n\nAutocorrection fixes misspellings that users make in the utterances that they submit as user input. When autocorrection is enabled, the misspelled words are automatically corrected. And it is the corrected words that are used to evaluate the input. When given more precise input, your assistant can more often recognize entity mentions and understand the user's intent.\n\nAutocorrection is enabled automatically for all new English-language dialog skills. It is available as a beta feature in French-language dialog skills. You must turn it on to use it with French-language skills. For more information about language support, see [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support).\n\nAutocorrection corrects user input in the following way:\n\n\n\n* Orignal input: letme applt for a memberdhip\n* Corrected input: let me apply for a membership\n\n\n\nWhen your assistant evaluates whether to correct the spelling of a word, it does not rely on a simple dictionary lookup process. Instead, it uses a combination of Natural Language Processing and probabalistic models to assess whether a term is, in fact, misspelled and should be corrected.\n\n\n\n Turning autocorrection on or off \n\nAutocorrection helps your assistant understand user input. It is enabled automatically for some languages and available, but disabled in others.\n\nIf you decide to disable it, you must turn it off entirely. You cannot disable autocorrection for a single word or phrase.\n\nIf you find that a domain-specific term is being corrected that shouldn't be, you can prevent the correction from happening by adding the term or phrase to your training data. For more details, see [Autocorrection rules](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime-spell-checkdialog-runtime-spell-check-rules).\n\nTo turn autocorrection on or off, complete the following steps:\n\n\n\n1. Click the Skills icon !", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime-spell-check"}]}
{"task_id": "e1b602e47ded79a35d8df4eefe194e39<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03027-6555-8367", "score": 21.472225, "text": "\nThe language property is set to the original language of the skill. For example, the language property is en for an English skill.\n4. Change the value of this property to the language you want to use instead. For example, change it to fr for French or de for German.\n5. Save the changes to the JSON file, and then upload the edited file, overwriting the existing skill.\n\n\n\n\n\n\n\n Configuring bidirectional languages \n\nFor bidirectional languages, such as Arabic, you can change your skill preferences.\n\n\n\n1. From your skill tile, click the Actions drop-down menu, and then select Language Preferences.\n\nThis option is only available for skills that are configured to use a bidirectional language.\n2. Select from the following options for your skill:\n\n\n\n* GUI Direction: Specifies the layout direction of elements, such as buttons or menus, in the graphical user interface. Choose LTR (left-to-right) or RTL (right-to-left). If not specified, the tool follows the web browser GUI direction setting.\n* Text Direction: Specifies the direction of typed text. Choose LTR (left-to-right), RTL (right-to-left), or Auto (which automatically chooses the text direction based on your system settings). The None option displays left-to-right text.\n* Numeric Shaping: Specifies which form of numerals to use when presenting regular digits. Choose from Nominal, Arabic-Indic, or Arabic-European. The None option will display Western numerals.\n* Calendar Type: Specifies how you choose filtering dates in the skill UI. Choose Islamic-Civil, Islamic-Tabular, Islamic-Umm al-Qura, or Gregorian.\n\n\n\nThis setting is not reflected in the Try it out panel.\n\n![Bidi options](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/bidi-options.png)\n3. Click the X to close the page.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-support"}, {"document_id": "ibmcld_03353-6854-8737", "score": 21.421322, "text": "\nSave the changes to the JSON file, and then upload the edited file, overwriting the existing skill.\n\n\n\n\n\n\n\n Configuring bidirectional languages \n\nFor bidirectional languages, such as Arabic, you can change your skill preferences.\n\n\n\n1. From your skill tile, click the Actions drop-down menu, and then select Language Preferences.\n\nThis option is only available for skills that are configured to use a bidirectional language.\n2. Select from the following options for your skill:\n\n\n\n* GUI Direction: Specifies the layout direction of elements, such as buttons or menus, in the graphical user interface. Choose LTR (left-to-right) or RTL (right-to-left). If not specified, the tool follows the web browser GUI direction setting.\n* Text Direction: Specifies the direction of typed text. Choose LTR (left-to-right) or RTL (right-to-left), or select Auto which will automatically choose the text direction based on your system settings. The None option will display left-to-right text.\n* Numeric Shaping: Specifies which form of numerals to use when presenting regular digits. Choose from Nominal, Arabic-Indic, or Arabic-European. The None option will display Western numerals.\n* Calendar Type: Specifies how you choose filtering dates in the skill UI. Choose Islamic-Civil, Islamic-Tabular, Islamic-Umm al-Qura, or Gregorian.\n\n\n\nThis setting is not reflected in the \"Try it out\" panel.\n\n![Bidi options](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/bidi-options.png)\n3. Click the X to close the page. Your changes are saved automatically.\n\n\n\n\n\n\n\n Working with accented characters \n\nIn a conversational setting, users might or might not use accents while interacting with the Watson Assistant service. As such, both accented and non-accented versions of words might be treated the same for intent detection and entity recognition.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-language-support"}, {"document_id": "ibmcld_02839-3583-5403", "score": 21.06781, "text": "\nIf your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. Add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-basicsweb-chat-basics-global).", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-language"}, {"document_id": "ibmcld_03120-3469-5331", "score": 19.510473, "text": "\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}, {"document_id": "ibmcld_03120-4813-6717", "score": 16.181543, "text": "\nFor more information, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions. For a dialog skill, add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Phone integration: If you want to deploy an assistant that uses the universal language model with the phone integration, you must connect to custom Speech service language models that can understand the language you're using. For more information about supported language models, see the [Speech to Text](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-modelsmodelsList) and [Text to Speech](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-voiceslanguageVoices) documentation.\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-basicsweb-chat-basics-global).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}, {"document_id": "ibmcld_03353-5263-7331", "score": 15.726347, "text": "\nItalian (it) GA Deprecated \n Japanese (ja) GA Deprecated \n Korean (ko) GA Deprecated \n Portuguese (Brazilian) (pt-br) GA Deprecated \n Spanish (es) GA Deprecated \n Universal (xx) GA NA \n\n\n\nThe Watson Assistant service supports multiple languages as noted, but the tool interface itself (descriptions, labels, etc.) is in English. All supported languages can be input and trained through the English interface.\n\nGB18030 compliance: GB18030 is a Chinese standard that specifies an extended code page for use in the Chinese market. This code page standard is important for the software industry because the China National Information Technology Standardization Technical Committee has mandated that any software application that is released for the Chinese market after September 1, 2001, be enabled for GB18030. The Watson Assistant service supports this encoding, and is certified GB18030-compliant\n\n\n\n\n\n\n\n Changing a skill language \n\nOnce a skill has been created, its language cannot be modified. If it is necessary to change the supported language of a skill, you can do so by editing the skill's underlying JSON.\n\nTo change the skill language, take the following steps:\n\n\n\n1. Download the skill that you want to edit.\n2. Open the downloaded skill JSON file in a text editor.\n3. Search for the property named language.\n\nThe language property is set to the original language of the skill. For example, the language property is en for an English skill.\n4. Change the value of this property to the language you want to use instead. For example, change it to fr for French or de for German.\n5. Save the changes to the JSON file, and then upload the edited file, overwriting the existing skill.\n\n\n\n\n\n\n\n Configuring bidirectional languages \n\nFor bidirectional languages, such as Arabic, you can change your skill preferences.\n\n\n\n1. From your skill tile, click the Actions drop-down menu, and then select Language Preferences.\n\nThis option is only available for skills that are configured to use a bidirectional language.\n2. Select from the following options for your skill:", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-language-support"}, {"document_id": "ibmcld_02839-1790-3940", "score": 15.161402, "text": "\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n3. Create the skill.\n4. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kebab.png), and then select Language preferences.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-language"}, {"document_id": "ibmcld_03027-4976-6968", "score": 14.417035, "text": "\nEnglish (en) GA Deprecated \n Arabic (ar) GA Deprecated \n Chinese (Simplified) (zh-cn) GA Deprecated \n Chinese (Traditional) (zh-tw) GA Deprecated \n Czech (cs) GA Deprecated \n Dutch (nl) GA Deprecated \n French (fr) GA Deprecated \n German (de) GA Deprecated \n Italian (it) GA Deprecated \n Japanese (ja) GA Deprecated \n Korean (ko) GA Deprecated \n Portuguese (Brazilian) (pt-br) GA Deprecated \n Spanish (es) GA Deprecated \n Universal (xx) GA NA \n\n\n\nThe Watson Assistant service supports multiple languages as noted, but the tool interface itself (descriptions, labels, etc.) is in English. All supported languages can be input and trained through the English interface.\n\nGB18030 compliance: GB18030 is a Chinese standard that specifies an extended code page for use in the Chinese market. This code page standard is important for the software industry because the China National Information Technology Standardization Technical Committee has mandated that any software application that is released for the Chinese market after September 1, 2001, be enabled for GB18030. The Watson Assistant service supports this encoding, and is certified GB18030-compliant\n\n\n\n\n\n\n\n Changing a skill language \n\nOnce a skill has been created, its language cannot be modified. If it is necessary to change the supported language of a skill, you can do so by editing the skill's underlying JSON.\n\nTo change the skill language, take the following steps:\n\n\n\n1. Download the skill that you want to edit.\n2. Open the downloaded skill JSON file in a text editor.\n3. Search for the property named language.\n\nThe language property is set to the original language of the skill. For example, the language property is en for an English skill.\n4. Change the value of this property to the language you want to use instead. For example, change it to fr for French or de for German.\n5. Save the changes to the JSON file, and then upload the edited file, overwriting the existing skill.\n\n\n\n\n\n\n\n Configuring bidirectional languages", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-support"}, {"document_id": "ibmcld_16364-199341-201521", "score": 13.491331, "text": "\nAnd the links between nodes are represented in a way that makes it easier to understand the relationships between the nodes.\n\n\n\n\n\n 21 June 2017 \n\nArabic support\n: Language support for Arabic is now generally available. For details, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\nLanguage updates\n: The Watson Assistant service algorithms have been updated to improve overall language support. See the [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support) topic for details.\n\n\n\n\n\n 16 June 2017 \n\nRecommendations (Beta - Premium users only)\n: The Improve panel also includes a Recommendations page that recommends ways to improve your system by analyzing the conversations that users have with your chatbot, and taking into account your system's current training data and response certainty.\n\n\n\n\n\n 14 June 2017 \n\nFuzzy matching for additional languages (Beta)\n: Fuzzy matching for entities is now available for additional languages, as noted in the [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support) topic. You can turn on fuzzy matching per entity to improve the ability of your assistant to recognize terms in user input with syntax that is similar to the entity, without requiring an exact match. The feature is able to map user input to the appropriate corresponding entity despite the presence of misspellings or slight syntactical differences. For example, if you define giraffe as a synonym for an animal entity, and the user input contains the terms giraffes or girafe, the fuzzy match is able to map the term to the animal entity correctly. See [Fuzzy matching](https://cloud.ibm.com/docs/assistant?topic=assistant-entitiesentities-fuzzy-matching) for details.\n\n\n\n\n\n 13 June 2017 \n\nUser conversations\n: The Improve panel now includes a User conversations page, which provides a list of user interactions with your chatbot that can be filtered by keyword, intent, entity, or number of days. You can open individual conversations to correct intents, or to add entity values or synonyms.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_03085-14664-15882", "score": 13.073708, "text": "\n[checkmark icon](https://cloud.ibm.com/docs-content/v1/content/icons/checkmark-icon.svg) ![checkmark icon](https://cloud.ibm.com/docs-content/v1/content/icons/checkmark-icon.svg) \n Export a skill or dialog skill version ![checkmark icon](https://cloud.ibm.com/docs-content/v1/content/icons/checkmark-icon.svg) ![checkmark icon](https://cloud.ibm.com/docs-content/v1/content/icons/checkmark-icon.svg) ![checkmark icon](https://cloud.ibm.com/docs-content/v1/content/icons/checkmark-icon.svg) \n Duplicate a skill ![checkmark icon](https://cloud.ibm.com/docs-content/v1/content/icons/checkmark-icon.svg) ![checkmark icon](https://cloud.ibm.com/docs-content/v1/content/icons/checkmark-icon.svg) \n Change bidirectional preferences ![checkmark icon](https://cloud.ibm.com/docs-content/v1/content/icons/checkmark-icon.svg) ![checkmark icon](https://cloud.ibm.com/docs-content/v1/content/icons/checkmark-icon.svg) \n Open and view intents and intent examples ![checkmark icon](https://cloud.ibm.com/docs-content/v1/content/icons/checkmark-icon.svg) ![checkmark icon](https://cloud.ibm.com/docs-content/v1/content/icons/checkmark-icon.svg) ![checkmark icon](https://cloud.ibm.com/docs-content/v1/content/icons/checkmark-icon.svg)", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-access-control"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09149-2959-3768", "score": 19.51357, "text": "\nFor more information about deleting keys, check out [About deleting and purging keys](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-purge-keys).\n\n\n\n\n\n How many key versions do you have? \n\nTo see how many versions you have of each key you have deployed:\n\n\n\n1. [Log in to the IBM Cloud console](https://cloud.ibm.com/login/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the Keys panel, click the \u22ef icon and select Key details. This opens a side panel that shows, among other things, the number of versions of this key you have.\n5. Repeat this process for every key in your instance. Note that because only root keys can be rotated, all of your standard keys only have one version.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-pricing-plan"}, {"document_id": "ibmcld_09061-2799-4588", "score": 19.223, "text": "\n[Log in to the IBM Cloud console](https://cloud.ibm.com/login/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the application details page, use the Keys table to browse the keys in your service.\n5. Click the \u22ef icon to open a list of options for the key that you want to delete.\n6. From the options menu, click Schedule key deletion and review the key's associated resources.\n7. Click the Next button, enter the key name, and click Schedule deletion.\n8. Contact another user to complete the deletion of the key.\n\n\n\nThe other user must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n\n\n Purging a key that holds dual authorization in the console \n\nFour hours after the other user with a Manager access policy has authorized the key for deletion, it can be purged by one of the users as long as they hold [the KeyPurge attribute](https://cloud.ibm.com/docs/key-protect?topic=key-protect-grant-access-keysgrant-access-keys-specific-functions).\n\nThis can be done by clicking the \u22ef icon to open a list of options for the key that you want to purge and then clicking Purge. If you cannot delete the key, make sure it has been at least four hours since the key was authorized for deleting by another user and that you hold the KeyPurge attribute.\n\n\n\n\n\n Authorize deletion for a key with the API \n\n[After you enable dual authorization for an instance or key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps://<region>.kms.cloud.ibm.com/api/v2/keys/<keyID_or_alias>/actions/setKeyForDeletion\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keys"}, {"document_id": "ibmcld_08446-1337-2966", "score": 19.139433, "text": "\nWhen you change the Active key to Deactivated state, the key is detached from all the target keystores, and not accessible to all associated resources and their data. Make sure that you open the confirmation tile to check all the associated resources before you continue. However, you can still reactivate the key so that it is accessible to the resources again.\n4. To destroy a Pre-active or Deactivated key, click the Actions icon ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/icons/action-menu-icon.svg) and choose Destroyed.\n\nWhen you destroy a managed key, the key cannot be restored in Unified Key Orchestrator. However, you can still restore your keys in external keystores depending on the settings of the cloud providers. For more information, see [Azure Key Vault soft-delete overview](https://docs.microsoft.com/en-us/azure/key-vault/general/soft-delete-overview), [Deleting AWS KMS keys](https://docs.aws.amazon.com/kms/latest/developerguide/deleting-keys.html), or [Deleting and purging keys in Key Protect](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-purge-keys).\n5. Click Destroy key to confirm.\n6. To remove the key and the metadata from the vault, click the Actions icon ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/icons/action-menu-icon.svg) and choose Remove from vault.\n\nWhen you remove the managed key from the vault that the key is assigned to, the remaining key metadata is removed permanently.\n\n\n\nThe managed key has been deleted and detached from all target keystores.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-managed-keys"}, {"document_id": "ibmcld_08446-4-1771", "score": 19.111038, "text": "\n* UI\n* API\n\n\n\n\n\n\n\n Deleting managed keys \n\nYou can delete your managed keys in Unified Key Orchestrator with the IBM Cloud\u00ae console, or programmatically with the Unified Key Orchestrator API.\n\nWhen you delete a managed key, the key is to be detached from all target keystores, and all key materials and the metadata are destroyed permanently.\n\n\n\n Deleting managed keys with the IBM Cloud console \n\nTo delete a key in Active state, you need to first deactivate the key, and then destroy the key and remove it from the vault.\n\nTo delete a key in Pre-active or Deactivated state, you only need to destroy the key, and then remove it from the vault.\n\nFor more information about key states and transitions, see [Monitoring the lifecycle of encryption keys in Unified Key Orchestrator](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-uko-key-states).\n\nFollow these steps to complete the process:\n\n\n\n1. [Log in to the Hyper Protect Crypto Services instance](https://cloud.ibm.com/login).\n2. Click Managed keys from the navigation to view all the available keys.\n3. If the managed key that you want to delete is in Active state, click the Actions icon ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/icons/action-menu-icon.svg) and choose Deactivated to deactivate the key first.\n\nWhen you change the Active key to Deactivated state, the key is detached from all the target keystores, and not accessible to all associated resources and their data. Make sure that you open the confirmation tile to check all the associated resources before you continue. However, you can still reactivate the key so that it is accessible to the resources again.\n4. To destroy a Pre-active or Deactivated key, click the Actions icon !", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-managed-keys"}, {"document_id": "ibmcld_09099-5695-7625", "score": 19.024908, "text": "\nBecause a key ring cannot be deleted as long as it contains keys in any state (including the destroyed state keys are moved to after they are deleted but before they are automatically purged 90 days after deletion), if you want to delete a key ring, you might need to transfer keys to a different ring first.\n\nAfter transferring a key to a different key ring, it may take up to a maximum of ten minutes for the change to take effect.\n\n\n\n Transferring a key to a different key ring with the UI \n\nIf you do not see all of the options you expect to see, it might be because you do not have the permission to execute a particular action. Make sure your roles and permissions are sufficient to perform the action. For more information on roles, check out [Managing user access](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-access).\n\nYou must have the service \"Manager\" role of both the key being transferred and the target key ring to transfer a key.\n\nFrom the Keys panel:\n\n\n\n1. Find the key you want to transfer. Note that it can be helpful to specify the key ring where the key is currently located by selecting the ring in the Key ring ID drop down list. You can also click on Key rings in the left navigation, find the appropriate key ring, and click View associated keys inside the setting drop-down list. This will show you all of the keys associated with that key ring.\n2. Click on the \u22ef button, and select Edit key ring from the drop-down list.\n3. In the drop-down list, select the key ring you want to move the key to. Then click Save.\n\n\n\n\n\n\n\n Transferring a key to a different key ring with the API \n\nTransfer a key to a different key ring by making a PATCH call to the following endpoint.\n\nhttps://<region>.kms.cloud.ibm.com/api/v2/keys/<keyID_or_alias>\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https://cloud.ibm.com/docs/key-protect?topic=key-protect-set-up-api).", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-grouping-keys"}, {"document_id": "ibmcld_08580-8441-10004", "score": 18.722555, "text": "\nThe created key is displayed as the first row in the Enterprise PKCS #11 keys table.\n\n\n\n\n\n Deleting EP11 keys \n\nFor default service access roles that support deleting EP11 keys, see [service access roles](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles). If you are to create custom roles, make sure to assign the following actions to the custom role:\n\n\n\n* hs-crypto.keystore.listkeystoresbyids\n* hs-crypto.keystore.listkeysbyids\n* hs-crypto.keystore.deletekey\n\n\n\nFor instructions on creating custom roles, see [Creating custom roles](https://cloud.ibm.com/docs/account?topic=account-custom-roles).\n\nIf you want to delete an EP11 key, complete the following steps:\n\nAfter you delete an EP11 key, you are not able to access the data associated with the key. This action cannot be undone.\n\n\n\n1. Select the EP11 keys tab in the side menu, and find the key that you want to delete in the list.\n2. Click the Actions icon ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/icons/action-menu-icon.svg) in the key row, and click Delete key.\n3. Verify the ID of the key to be deleted, and check the box to confirm the deletion.\n4. Click Delete keystore.\n\n\n\nIf you are performing cryptographic operations using the PKCS #11 API, to delete the key in your PKCS #11 application, reinitialize the PKCS #11 API by using the C_Finalize() and C_Initialize() functions.\n\n\n\n\n\n What's next \n\nYou can use EP11 keys for cryptographic operations with the PKCS #11 API. For more information, see", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-ep11-key-ui"}, {"document_id": "ibmcld_09159-2941-4691", "score": 18.683819, "text": "\nIf the key has been deleted within the last 30 days, it can be restored. If it has been more then 30 days, you will not be able to restore the key. If you attempt to restore a key that is no longer eligible to be restored, you will receive an error when trying to restore the key.\n\n\n\n\n\n\n\n Restoring a deleted key with the console \n\nIf you prefer to restore your key by using a graphical interface, you can use the IBM Cloud console.\n\n[After you import your existing keys into the service](https://cloud.ibm.com/docs/key-protect?topic=key-protect-create-root-keys) and [delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) a key, complete the following steps to restore the key:\n\n\n\n1. [Log in to the IBM Cloud console](https://cloud.ibm.com/login/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. Click Keys to open the keys panel and find the key in the destroyed state you want to restore. One way to achieve this is to click the Key states drop-down list and select the Destroyed state. This will limit the results to only keys that have been deleted.\n5. Click the \u22ef icon to open a list of options for the key that you want to restore. Note that if the key has just been moved to a Destroyed state you must wait 30 seconds before attempting to restore it.\n6. Click the Restore Key button to open the restore side panel.\n7. Click Restore Key button.\n8. Confirm the key was restored in the updated Keys table.\n\n\n\n\n\n\n\n Restoring a deleted key with the API \n\nRestore a previously imported key by making a POST call to the following endpoint:\n\nhttps://<region>.kms.cloud.ibm.com/api/v2/keys/<keyID_or_alias>/restore\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-restore-keys"}, {"document_id": "ibmcld_09064-4-1760", "score": 18.586287, "text": "\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys using a single authorization \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to delete an encryption key and its key material, if you are a manager for your Key Protect instance.\n\nBefore deleting keys, make sure to review the [Considerations before deleting and purging a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Deleting keys in the console \n\nBy default, Key Protect requires one authorization to delete a key. If you prefer to delete your encryption keys by using a graphical interface, you can use the IBM Cloud console.\n\n[After you create or import your existing keys into the service](https://cloud.ibm.com/docs/key-protect?topic=key-protect-create-root-keys), complete the following steps to delete a key:\n\n\n\n1. [Log in to the IBM Cloud console](https://cloud.ibm.com/login/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the application details page, use the Keys table to browse the keys in your service.\n5. Click the \u22ef icon to open a list of options for the key that you want to delete.\n6. From the options menu, click Delete key and confirm the key deletion in the next screen by ensuring the key has no associated resources. Note that you will not be able to delete the key if it is protecting a registered IBM Cloud resource that's non-erasable due to a [retention policy](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutableimmutable-terminology-policy).\n\n\n\nAfter you delete a key, the key transitions to the Destroyed state. Any data encrypted by keys in this state is no longer accessible.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys"}, {"document_id": "ibmcld_09061-1334-3188", "score": 18.545057, "text": "\nWhen the first user authorizes a key for deletion, it remains in the [Active state](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted. When you delete a key, it is \"soft deleted\", meaning that the key and its associated data will be restorable up to 30 days after deletion. You are able to still retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically [purged](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-key-purge), or hard deleted, and its associated data will be permanently removed from the Key Protect service.\n\n\n\n\n\n\n\n Authorize deletion for a key in the console \n\n[After you enable dual authorization for an instance or key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth), you can provide the first authorization to delete a key by using the Key Protect IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https://cloud.ibm.com/login/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the application details page, use the Keys table to browse the keys in your service.\n5. Click the \u22ef icon to open a list of options for the key that you want to delete.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keys"}, {"document_id": "ibmcld_08580-9654-10235", "score": 18.492397, "text": "\nClick Delete keystore.\n\n\n\nIf you are performing cryptographic operations using the PKCS #11 API, to delete the key in your PKCS #11 application, reinitialize the PKCS #11 API by using the C_Finalize() and C_Initialize() functions.\n\n\n\n\n\n What's next \n\nYou can use EP11 keys for cryptographic operations with the PKCS #11 API. For more information, see\n\n[Performing cryptographic operations with the PKCS #11 API](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-up-pkcs-api) and\n\n[PKCS #11 API reference](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-pkcs11-api-ref).", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-ep11-key-ui"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09061-1334-3188", "score": 23.863983, "text": "\nWhen the first user authorizes a key for deletion, it remains in the [Active state](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted. When you delete a key, it is \"soft deleted\", meaning that the key and its associated data will be restorable up to 30 days after deletion. You are able to still retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically [purged](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-key-purge), or hard deleted, and its associated data will be permanently removed from the Key Protect service.\n\n\n\n\n\n\n\n Authorize deletion for a key in the console \n\n[After you enable dual authorization for an instance or key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth), you can provide the first authorization to delete a key by using the Key Protect IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https://cloud.ibm.com/login/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the application details page, use the Keys table to browse the keys in your service.\n5. Click the \u22ef icon to open a list of options for the key that you want to delete.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keys"}, {"document_id": "ibmcld_08435-3634-5079", "score": 23.60512, "text": "\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/icons/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_08776-2908-4519", "score": 22.877493, "text": "\nDual authorization enabled The status of a dual authorization policy on the key.<br><br><br><br> * True: Dual authorization is required to delete the key.<br> * False: No prior authorization is required to delete the key.<br><br><br> \n Set for deletion Indicates whether a delete authorization is issued for a key.<br><br><br><br> * True: An authorization to delete this key is issued by the first user. A second user with a Manager access policy can safely delete the key.<br> * False: The key is not set for deletion. No further action is needed.<br><br><br> \n Deletion expiration The date that an authorization for deletion expires for the key. If this date passes, the authorization is no longer valid. If False is the value for the Dual authorization enabled or Set for deletion column of the key, the Deletion expiration column is left empty. \n\n\n\nNot all key characteristics are displayed by default. To customize how the Keys table is to be presented, click the Settings icon![Settings icon](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/icons/settings.svg) and check the columns to be displayed.\n\nNot seeing the full list of keys that are stored in your service instance? Verify with your administrator that you are assigned the correct role for the applicable service instance or individual key. For more information about roles, see [Roles and permissions](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-accessroles).\n\nYou can also search for a specific key by using the search bar, or filter keys based on your needs by clicking the Filter icon !", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-view-keys"}, {"document_id": "ibmcld_08435-4752-6201", "score": 22.788183, "text": "\nIf no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you enable dual authorization [for an instance](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps://api.<region>.hs-crypto.cloud.ibm.com:<port>/api/v2/keys/<key_ID>/actions/setKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo set a key for deletion, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to set or authorize for deletion.\n3. Provide the first authorization to delete the key.\n\ncurl -X POST \n'https://api.<region>.hs-crypto.cloud.ibm.com:<port>/api/v2/keys/<key_ID>/actions/setKeyForDeletion'", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_08435-1255-3053", "score": 22.639585, "text": "\nTo use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key. During this period, the key remains in the [Active state](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. To complete the deletion, the second user with a Manager access policy can use the IBM Cloud console or API to delete the key.\n* The key and its associated data become inaccessible 90 days after the key is deleted. When you delete a key, the key can be restored within 30 days after the deletion. You are able to retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically purged and its associated data will be permanently removed from your instance.\n\n\n\n\n\n\n\n Authorize deletion for a key with the IBM Cloud console \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you [enable dual authorization for an instance](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by using the IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https://cloud.ibm.com/).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.\n4.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_09055-23127-24436", "score": 22.52601, "text": "\nUser 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",\n\"crn\": \"crn:v1:bluemix:public:kms:us-south:a/ea998d3389c3473aa0987652b46fb146:a192d603-0b8d-452f-aac3-f9e1f95e7411:policy:2427dbde-6cff-41eb-8b5a-ff26b038cafc\",\n\"lastUpdateDate\": \"2020-06-22T21:29:10Z\",\n\"updatedBy\": \"user id ...<redacted>...\",\n\"dualAuthDelete\": {\n\"enabled\": true\n}\n}\n]\n\n cancel a previously scheduled key delete\n$ ibmcloud kp key cancel-delete $KEY_ID\n\nCancelling key for deletion...", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-cli-reference-five-two"}, {"document_id": "ibmcld_09038-20413-22510", "score": 21.957964, "text": "\nA registration with \"preventKeyDeletion\": true indicates that the associated resource has a retention policy. To enable deletion, contact an account owner to remove the retention policy on each resource that is associated with this key.\n\nA delete key event could also receive a reason.reasonCode of 409 due to a dual auth deletion policy on the key. Make a GET request to /api/v2/keys/{id}/policies to see if there is a dual authorization policy associated with your key. If there is a policy set, contact the other authorized user to schedule the key for deletion.\n\n\n\n\n\n Unable to authenticate while make a request \n\nIf the event has a reason.reasonCode of 401, you do not have the correct authorization to perform Key Protect actions in the specified Key Protect instance. Verify with an administrator that you are assigned the correct platform and service access roles in the applicable service instance. For more information about roles, see [Roles and permissions](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-access).\n\nCheck that you are using a valid token that is associated with an account authorized to perform the service action.\n\n\n\n\n\n Unable to view or list keys in a Key Protect instance \n\nIf you make a call to GET api/v2/keys to list the keys that are available in your Key Protect instance and responseData.totalResources is 0, you may need to query for keys in the deleted state using the state parameter or adjust the offset and limit parameters in your request.\n\n\n\n\n\n Lifecycle action on a key with registrations did not complete \n\nThe responseData.reasonForFailure and responseData.resourceCRN fields contain information on why the action wasn't able to be completed.\n\nIf the event has a reason.reasonCode of 409, the action could not be completed due to the adopting service's key state conflicting with the key state that Key Protect has.\n\nIf the event has a reason.reasonCode of 408, the action could not be completed because Key Protect was not notified that all appropriate actions were taken within 4 hours of the action request.\n\n\n\n\n\n\n\n Event Severity", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-at-events"}, {"document_id": "ibmcld_09061-2799-4588", "score": 21.609377, "text": "\n[Log in to the IBM Cloud console](https://cloud.ibm.com/login/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the application details page, use the Keys table to browse the keys in your service.\n5. Click the \u22ef icon to open a list of options for the key that you want to delete.\n6. From the options menu, click Schedule key deletion and review the key's associated resources.\n7. Click the Next button, enter the key name, and click Schedule deletion.\n8. Contact another user to complete the deletion of the key.\n\n\n\nThe other user must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n\n\n Purging a key that holds dual authorization in the console \n\nFour hours after the other user with a Manager access policy has authorized the key for deletion, it can be purged by one of the users as long as they hold [the KeyPurge attribute](https://cloud.ibm.com/docs/key-protect?topic=key-protect-grant-access-keysgrant-access-keys-specific-functions).\n\nThis can be done by clicking the \u22ef icon to open a list of options for the key that you want to purge and then clicking Purge. If you cannot delete the key, make sure it has been at least four hours since the key was authorized for deleting by another user and that you hold the KeyPurge attribute.\n\n\n\n\n\n Authorize deletion for a key with the API \n\n[After you enable dual authorization for an instance or key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps://<region>.kms.cloud.ibm.com/api/v2/keys/<keyID_or_alias>/actions/setKeyForDeletion\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keys"}, {"document_id": "ibmcld_09070-3941-5701", "score": 21.554153, "text": "\nVerify whether a key has a retention policy by checking the preventKeyDeletion field of the [registration details](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resourcesview-protected-resources-api) for the key. Then, you must contact an account owner to remove the retention policy on each resource that is associated with the key before you can delete the key.\n3. Verify the key's deletion authorization policy. By default, keys in Key Protect only require a single deletion authorization by a user with the Manager role However, if a [dual authorization policy has been set](https://cloud.ibm.com/docs/key-protect?topic=key-protect-set-dual-auth-key-policy), two users with the Manager role will have to approve the deletion.\n\n\n\nKey Protect restricts the ability to purge keys after only four hours to users with the [KeyPurge role](https://cloud.ibm.com/docs/key-protect?topic=key-protect-grant-access-keysgrant-access-keys-specific-functions), which must be specifically set for a user as it is not enabled by default, even for the instance owner. This ability is restricted precisely because purged keys cannot be restored. If there is any doubt whether a key should be purged four hours after it has been deleted, do not purge it.\n\n\n\n\n\n API Example \n\nPlease refer to the prerequisites and configuration settings associated with the [API reference](https://cloud.ibm.com/apidocs/key-protectpurgekey), before using this example.\n\ncurl -X DELETE\nhttps://<region>.kms.cloud.ibm.com/api/v2/keys/<keyID_or_alias>/purge\n-H 'accept: application/vnd.ibm.kms.key+json'\n-H 'authorization: Bearer <IAM_token>'\n-H 'bluemix-instance: <instance_ID>'\n\nReplace the variables in the example request according to the following table.\n\n\n\nTable 2.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-purge-keys"}, {"document_id": "ibmcld_08414-28698-30846", "score": 21.484657, "text": "\nIf the delete key event has a reason.reasonCodeof 409, the key cannot be deleted because it is possibly protecting one or more cloud resources that have a retention policy. Make a GET request to /keys/{id}/registrations to learn which resources this key is associated with. A registration with \"preventKeyDeletion\": true indicates that the associated resource has a retention policy. To enable deletion, contact an account owner to remove the retention policy on each resource that is associated with this key.\n\nA delete key event might also receive a reason.reasonCode of 409 due to a dual auth deletion policy on the key. Make a GET request to /api/v2/keys/{id}/policies to see whether a dual authorization policy is associated with your key. If there is a policy set, contact the other authorized user to delete the key.\n\n\n\n\n\n Unable to authenticate while making a request \n\nIf the event has a reason.reasonCode of 401, you might not have the correct authorization to perform Hyper Protect Crypto Services actions in the specified service instance. Verify with an administrator that you are assigned the correct platform and service access roles in the applicable service instance. For more information about roles, see [Roles and permissions](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-access).\n\nCheck that you are using a valid token that is associated with an account that is authorized to perform the service action.\n\n\n\n\n\n Unable to view or list keys in a service instance \n\nYou can call GET api/v2/keys to list the keys that are available in your service instance. If responseData.totalResources is 0, query for keys in the deleted state by using the state parameter or adjust the offset and limit parameters in your request.\n\n\n\n\n\n Lifecycle action on a key with registrations did not complete \n\nThe responseData.reasonForFailure and responseData.resourceCRN fields contain information about why the action wasn't able to be completed.\n\nIf the event has a reason.reasonCode of 409, the action cannot be completed due to the adopting service's key state conflicting with the key state that Hyper Protect Crypto Services has.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-at-events"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03418-8007-9822", "score": 19.616934, "text": "\nAnd you are charged only once when the same anonymous user interacts with your assistant multiple times in a single month.\n\n\n\n\n\n Apple devices \n\nOn Apple devices, the Intelligent Tracking Prevention feature automatically deletes any client-side cookie after 7 days. This means that if an anonymous customer accesses your website and then visits again two weeks later, the two visits are treated as two different MAUs.\n\nTo avoid this problem, use a server-side first-party cookie in your web application. For example, when an anonymous user visits your website for the first time, you can generate a unique user ID and store it in a server-side cookie with any expiration date you choose. Then, your code can use the [updateUserID()](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodsupdateuserid) instance method to set the user ID. You can then use the same cookie to set the same user ID for this customer on any future visits until it expires.\n\n\n\n\n\n More information \n\nFor more information about billing, see [User-based plans explained](https://cloud.ibm.com/docs/assistant?topic=assistant-admin-managing-planadmin-managing-plan-user-based).\n\nFor more information about MAU limits per plan, see [Web chat integration limits](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-limits).\n\nFor more information about deleting a user's data, see [Labeling and deleting data](https://cloud.ibm.com/docs/assistant?topic=assistant-information-securityinformation-security-gdpr-wa).\n\n\n\n\n\n\n\n Human agent service integration \n\nYou can configure the web chat to transfer a customer to a human customer support agent if the customer asks for help from a person. The following service desk integrations are supported:\n\nBuilt-in service desk integrations:", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-basics"}, {"document_id": "ibmcld_08435-8253-9823", "score": 19.517874, "text": "\nDuring this 7-day period, the key remains in the [Active state](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\nTo delete a key and the contents, make a DELETE call to the service endpoint by following instructions in [Deleting keys with the API](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-api).\n\n\n\n\n\n Removing an existing authorization \n\nIf you need to cancel an authorization for a key before the 7-day waiting period expires, you can remove the existing authorization by making a POST call to the following endpoint.\n\nhttps://api.<region>.hs-crypto.cloud.ibm.com:<port>/api/v2/keys/<key_ID>/actions/unsetKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo remove an authorization to delete a key, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to unset or deauthorize for deletion.\n3. Remove an existing authorization to delete the key.\n\ncurl -X POST", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_08435-4752-6201", "score": 19.363956, "text": "\nIf no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you enable dual authorization [for an instance](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps://api.<region>.hs-crypto.cloud.ibm.com:<port>/api/v2/keys/<key_ID>/actions/setKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo set a key for deletion, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to set or authorize for deletion.\n3. Provide the first authorization to delete the key.\n\ncurl -X POST \n'https://api.<region>.hs-crypto.cloud.ibm.com:<port>/api/v2/keys/<key_ID>/actions/setKeyForDeletion'", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_08435-3634-5079", "score": 17.527054, "text": "\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/icons/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_09061-7530-9143", "score": 17.495844, "text": "\nIf no action is taken by another user and the seven-day period expires, you must [restart the dual authorization process](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-set-key-deletion-api) to delete the key.\n\nDelete a key and its contents by making a DELETE call to the following endpoint.\n\nhttps://<region>.kms.cloud.ibm.com/api/v2/keys/<keyID_or_alias>\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https://cloud.ibm.com/docs/key-protect?topic=key-protect-set-up-api).\n2. Retrieve the ID of the key that you would like to delete.\n\nYou can retrieve the ID for a specified key by making a GET /v2/keys request, or by viewing your keys in the Key Protect dashboard.\n3. Run the following curl command to delete the key and its contents.\n\n$ curl -X DELETE \"https://<region>.kms.cloud.ibm.com/api/v2/keys/<keyID_or_alias>\" -H \"authorization: Bearer <IAM_token>\" -H \"bluemix-instance: <instance_ID>\" -H \"prefer: <return_preference>\"\n\nReplace the variables in the example request according to the following table.\n\n\n\n\n\nTable 2. Describes the variables that are needed to delete a key.\n\n Variable Description \n\n region Required. The region abbreviation, such as us-south or eu-gb, that represents the geographic area where your Key Protect instance resides. <br> <br>For more information, see [Regional service endpoints](https://cloud.ibm.com/docs/key-protect?topic=key-protect-regionsservice-endpoints). \n key_ID_or_alias Required. The unique identifier or alias for the key that you would like to delete. \n IAM_token Required.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keys"}, {"document_id": "ibmcld_05202-1322-2876", "score": 16.376701, "text": "\nOnce you have filled in the form details and clicked Next you will be sent a New User Registration verification email with a 7 digit code to the email address that you provided. Find the email in your inbox (if you don\u2019t see if in your inbox check your junk folder), copy the 7-digit code and paste it into the verification token field and click Continue. The code will expire if not used within 30 minutes.\n\nOnce complete the form will redirect you to this page where you can continue to the next step.\n\n\n\n\n\n Step 2. Using your 60-day subscription trial key \n\nAfter signing up for the IBM Cloud Pak for Integration trial an IBM ID will be created for you (if you didn\u2019t already have one) and you will be assigned a container software entitlement key so that you are entitled to use the IBM Cloud Pak for Integration container image.\n\nYou can now follow [Getting started with IBM Cloud Pak for Integration](https://cloud.ibm.com/docs/cloud-pak-integration?topic=cloud-pak-integration-getting-started) to use your trial license with a managed Red Hat OpenShift Cluster on IBM Cloud. Start at the Before you begin step, and because you have already signed up to the IBM Cloud Pak for Integration trial, can skip Step 1. Obtain a license.\n\n> Note: You can find your container software entitlement key here - [https://myibm.ibm.com/products-services/containerlibrary](https://myibm.ibm.com/products-services/containerlibrary). Check out the View library tab on the left-hand side of that page to see details and a full list of the container software you own.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-pak-integration?topic=cloud-pak-integration-trial"}, {"document_id": "ibmcld_03787-5002-7004", "score": 16.34317, "text": "\nA subscription is inactive if its term expires or all of its credit is spent.\n\n\n\nYou can use the spending and usage information on the Subscriptions page to evaluate whether your subscriptions suit your usage needs. For example, if you consistently have overages, you might increase your monthly spending commitment to save money on that usage. To buy new subscriptions or change future subscription amounts, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule).\n\n\n\n\n\n Support subscriptions \n\nTo view support subscription usage, in the console, go to Manage > Billing and usage, and select Support costs. You can view the remaining credit in your active support subscriptions and any upcoming subscriptions that aren't yet valid. For more information, see [Viewing your support costs](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-support).\n\n\n\n\n\n\n\n Subscription credit \n\nAfter you buy a subscription for platform or support credit, you add the credit to your account by applying a subscription code. Applying the code ensures that the credit is added to your account and you don't have unexpected overage charges.\n\nFor more information, see [Applying subscription codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code).\n\n\n\n\n\n Expiring subscriptions \n\nYou are notified by email 60, 30, 14, and 1 day before the expiration date of the last subscription on the account. After the subscription expires, your account is converted to a Pay-As-You Go account, which means you pay only for billable services that you use with no contracts or commitments. The discounts that are associated with the subscription account won't apply to the Pay-As-You-Go account. The IBM Sales team is happy to help extend your subscription before you reach its expiration date. If you extend your subscription within 30 days from the expiration date, you won't get charged at the Pay-As-You-Go account rate. After 30 days, you are invoiced as a Pay-As-You-Go account.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions"}, {"document_id": "ibmcld_03787-6610-7114", "score": 16.036976, "text": "\nThe discounts that are associated with the subscription account won't apply to the Pay-As-You-Go account. The IBM Sales team is happy to help extend your subscription before you reach its expiration date. If you extend your subscription within 30 days from the expiration date, you won't get charged at the Pay-As-You-Go account rate. After 30 days, you are invoiced as a Pay-As-You-Go account.\n\nTo learn more, see [Pay-As-You-Go accounts](https://cloud.ibm.com/docs/account?topic=account-accountspaygo).", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions"}, {"document_id": "ibmcld_16365-15662-16934", "score": 15.9411, "text": "\nOn Apple devices, the Intelligent Tracking Prevention feature automatically deletes any client-side cookie after 7 days. This means that if an anonymous customer accesses your website and then visits again two weeks later, the two visits are treated as two different MAUs. For information about how to avoid this problem, see [Managing user identity information](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-userid).\n\nFor information about how to customize the handling of user identity information for billing purposes, see [Managing user identity information](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-userid).\n\nThe usage is measured differently depending on the plan type. For Lite plans, usage is measured by the number of /message calls (API) are sent to the assistant from the web chat integration. For all other plans, usage is measured by the number of monthly active users (MAU) that the web chat interacts with. The maximum number of allowed MAUs differs depending on your Watson Assistant plan type.\n\n\n\nPlan details\n\n Plan Maximum usage \n\n Enterprise Unlimited MAU \n Premium (legacy) Unlimited MAU \n Plus Unlimited MAU \n Trial 5,000 MAU \n Lite 10,000 API (approximately 1,000 MAU)", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_16382-2411-3972", "score": 15.834435, "text": "\nt.src='https://web-chat.global.assistant.dev.watson.appdomain.cloud/versions/' +\n(window.watsonAssistantChatOptions.clientVersion || 'latest') +\n'/WatsonAssistantChatEntry.js';\ndocument.head.appendChild(t);\n});\n</script>\nShow more\n\n\n\n Apple devices \n\nOn Apple devices, the Intelligent Tracking Prevention feature automatically deletes any client-side cookie after 7 days. This means that if an anonymous customer accesses your website and then visits again two weeks later, the two visits are treated as two different MAUs.\n\nTo avoid this problem, use a server-side first-party cookie in your web application. For example, when an anonymous user visits your website for the first time, you can generate a unique user ID and store it in a server-side cookie with any expiration date you choose. Then, your code can use the [updateUserID()](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodsupdateuserid) instance method to set the user ID. You can then use the same cookie to set the same user ID for this customer on any future visits until it expires.\n\n\n\n\n\n More information \n\nFor more information about billing, see [User-based plans explained](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-managing-plan).\n\nFor more information about MAU limits per plan, see [Pricing](https://www.ibm.com/products/watson-assistant/pricing).\n\nFor more information about deleting a user's data, see [Labeling and deleting data](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-securing).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-userid"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_08211-2628-3483", "score": 25.672558, "text": "\nIf the server has expired, you can remove the entry from the resource list and either:\n\n\n\n* Wait for the target time to trigger deletion for you, or\n* Manually trigger the deletion from the resource reclamations.\n\n\n\nIf an expired server is restored, only the entry within the resource list is restored, not the server itself.\n\n\n\n\n\n Restoring servers that belong to paid plans \n\nServers that belong to a paid plans do not expire, and that's why they can be restored during the reclamation period. If a server is restored, the timeframe for which the server was within the resource reclamations is billed to your account.\n\nAfter the server is deleted, only metadata, which isn't considered to be personal data is kept for 6 months. Make sure you back up important data for future use because you can't recover data after the virtual server has been deleted.", "title": "", "source": "https://cloud.ibm.com/docs/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"}, {"document_id": "ibmcld_08211-1158-3123", "score": 20.077398, "text": "\nibmcloud hpvs instance-delete CRN --force\n\n\n\nWhere CRN is Cloud resource name of the server you want to delete. Use --force to force the deletion of the Hyper Protect Virtual Servers instance without showing a confirmation prompt.\n\nYou can find more information and example output [here](https://cloud.ibm.com/docs/hpvs-cli-pluginhpvs-instance-delete).\n\n\n\n\n\n What happens during the reclamation period \n\nWhen you delete a virtual server from the resource list, the server isn't deleted immediately, it's stopped and marked for deletion, and a reclamation period of seven days starts. The server is deleted after the reclamation period ends. During this seven-day reclamation period, you can restore the virtual server, or manually trigger a deletion from [resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations). Resource reclamations lists the Hyper Protect Virtual Servers that are marked for deletion together with the time (Target time) when the actual deletion is triggered.\n\n\n\n\n\n Deleting servers that belong to the free plan \n\nThe free plan servers expire 30 days after they are created. When a server expires, it's immediately deleted at the backend. The server is also deleted at the backend if it expires during the seven-day reclamation period. Even though the server is deleted at the backend, it's still displayed in the resource list or in the resource reclamations as if it still exists.\n\nIf the server has expired, you can remove the entry from the resource list and either:\n\n\n\n* Wait for the target time to trigger deletion for you, or\n* Manually trigger the deletion from the resource reclamations.\n\n\n\nIf an expired server is restored, only the entry within the resource list is restored, not the server itself.\n\n\n\n\n\n Restoring servers that belong to paid plans \n\nServers that belong to a paid plans do not expire, and that's why they can be restored during the reclamation period.", "title": "", "source": "https://cloud.ibm.com/docs/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"}, {"document_id": "ibmcld_08217-3469-5347", "score": 18.17714, "text": "\nHow to fix it \n\nVirtual servers in paid plans aren't deleted. You can remove the server from the resource list by deleting it from the resource list.\n\n\n\n\n\n Can't create new virtual servers because of exhausted resources or plan limitations \n\nYou can't create new virtual servers because of exhausted resources or plan limitations, although you've less than the described limits.\n\n What\u2019s happening \n\nYou try to create a new server but fail. Instead a message is displayed, which informs you that the maximum number of servers is reached in the selected data center for this account, or that you've reached the maximum number of free plans for this account. When you look in the resource list, you see that you haven't reached the limit.\n\n Why it\u2019s happening \n\nThe resource list is not a complete list of your servers. If you \u201cdelete\u201d a server from the resource list, it's made inaccessible and marked for deletion, but it's still available for you within the [resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) for a limited amount of time, as described in [Deleting a virtual server](https://cloud.ibm.com/docs/services/hp-virtual-servers?topic=hp-virtual-servers-remove_vs).\n\n How to fix it \n\nDepending on your requirements, you must either delete the resource from the resource reclamations, or select a different data center (maximum number of servers is reached), or select the appropriate paid plan that meets your requirements if you reach the maximum number of free plans. For more information, see [resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations).\n\n\n\n\n\n VoiceOver on MacOS does not announce all information on the dashboard in Firefox \n\nVoiceOver on MacOS does not announce information presented on the dashboard in Firefox.", "title": "", "source": "https://cloud.ibm.com/docs/hp-virtual-servers?topic=hp-virtual-servers-troubleshooting"}, {"document_id": "ibmcld_15998-1422-3109", "score": 17.088745, "text": "\nCommon problems \n\nHere are a few difficulties you might encounter.\n\n\n\n Not authorized (401 or 403 error) \n\nYour account might not be authorized for VPC. Make sure that you are using an account that has been onboarded.\n\n\n\n\n\n IAM token expired \n\nThe service is no longer returning any JSON, instead of just giving an HTTP \"401 Unauthorized\" to all requests. This error occurs after about an hour if your IAM token has expired. Refresh your IAM token by rerunning iam_token=$(ibmcloud iam oauth-tokens | awk '/IAM/{ print $4; }').\n\n\n\n\n\n Cannot create resources \n\nIf you cannot create a VPC or other resources, make sure that the owner of the account has granted you the correct [permissions](https://cloud.ibm.com/docs/vpc?topic=vpc-managing-user-permissions-for-vpc-resourcesmanaging-user-permissions-for-vpc-resources).\n\n\n\n\n\n No response from API \n\nIf the API is no longer returning any JSON, it is likely your IAM token has expired and needs to be refreshed. Log in to IBM Cloud again or refresh your token by running iam_token=$(ibmcloud iam oauth-tokens | awk '/IAM/{ print $4; }').\n\n\n\n\n\n\n\n Cannot delete resources \n\nCertain operations--creating and deleting virtual server instances, and creating and deleting subnets, for example--are completed asynchronously through the API. Because of this fact, it is recommended to poll the resources you're deleting, to check for deletion before proceeding.\n\nIt can take several minutes for resources to be deleted from the system, due to these asynchronous operations. To facilitate deletion, the best practice is to do things in this order:\n\n\n\n1. Delete your instances\n2. Delete your public gateways\n3. Delete your subnets\n4. Delete your VPCs", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-troubleshooting-vpc"}, {"document_id": "ibmcld_08399-11378-13200", "score": 17.022846, "text": "\nYou can restore a resource within 7 days after you delete it.\nYou can run the 'ibmcloud resource reclamations' command to check the resources that you can restore.\nTo irrecoverable delete the instance run the 'ibmcloud resource reclamation-delete RECLAMATION_ID' command.\n\nWhen you delete a virtual server from the resource list, the server isn't deleted immediately, it stops and is marked for deletion. It is deleted after a reclamation period of seven days. During this seven-day reclamation period, you can restore the virtual server or manually trigger a deletion thru [resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations).\n\n\n\n\n\n\n\n hpvs registration-key-create \n\nThis command creates a Hyper Protect virtual server gpg registration key. The resulting output files are required as inputs for the hpvs registration-create command, where it is used to sign the registration definition file for the deployment that uses your own image (BYOI). You need to run this command only when you do not have the gpg registration key or you have not already created the key pair, and when you want to use your own image (BYOI).\n\nibmcloud hpvs registration-key-create ID [--gpg-passphrase-path FILE-PATH] [-v VERBOSE]\n\nID\n: The user ID to set for the gpg registration key.\n\n\n\n Command options \n\n--gpg-passphrase-path FILE-PATH\n: Is the path for the file that contains the passphrase that is being used for the registration key. The passphrase must consist of at least 6 characters. To make sure that a new line is not appended, use echo with -n or cat with EOF. If the path is not specified, you are prompted for the passphrase.\n\n-v, --verbose\n: Set to true for verbose output.\n\n\n\n\n\n Example output \n\n$ ibmcloud hpvs registration-key-create abcdefg\nEnter password>", "title": "", "source": "https://cloud.ibm.com/docs/hpvs-cli-plugin?topic=hpvs-cli-plugin-hpvs_cli_plugin"}, {"document_id": "ibmcld_01869-1579-3056", "score": 16.887972, "text": "\nIf you want to delete service instances or check the billing information, you must go back to the Resource list page in the user interface to manage the service instances.\n\n\n\n\n\n Connect a service to an external app by using the API \n\n\n\n1. Create an instance of the service by calling [Resource Controller API](https://cloud.ibm.com/apidocs/resource-controller/resource-controller?code=gocreate-resource-instance) as shown in the following example request:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -X POST https://resource-controller.cloud.ibm.com/v2/resource_instances -H 'Authorization: Bearer <>' -H 'Content-Type: application/json' -d '{\n\"name\": \"my-instance\",\n\"target\": \"bluemix-global\",\n\"resource_group\": \"5g9f447903254bb58972a2f3f5a4c711\",\n\"resource_plan_id\": \"0be5ad401ae913d8ff665d92680664ed\",\n\"tags\": [\n\"my-tag\"\n]\n}'\n\nCreateResourceInstanceOptions createResourceInstanceOptions = new CreateResourceInstanceOptions.Builder()\n.name(resourceInstanceName)\n.target(targetRegion)\n.resourceGroup(resourceGroup)\n.resourcePlanId(resourcePlanId)\n.build();\n\nResponse<ResourceInstance> response = service.createResourceInstance(createResourceInstanceOptions).execute();\nResourceInstance resourceInstance = response.getResult();\n\nSystem.out.printf(\"createResourceInstance() response:n%sn\", resourceInstance.toString());\n\nresource_instance = resource_controller_service.create_resource_instance(\nname=resource_instance_name,\ntarget=target_region,\nresource_group=resource_group,", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-externalapp"}, {"document_id": "ibmcld_09450-13142-13655", "score": 16.588678, "text": "\nTo delete resources, run ./terraform destroy.\n\n\n\n\n\n\n\n What's next? \n\nVerify that the resources are created.\n\n\n\n* [Launch the Observability UI](https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-launch) and check the instance has been created.\n* [Launch Access (IAM)](https://cloud.ibm.com/iam/overview). Select Service IDs and look for the resource key.\n* [Review the user assigned access in the console](https://cloud.ibm.com/docs/account?topic=account-assign-access-resourcesreview-your-access-console).", "title": "", "source": "https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-terraform-setup"}, {"document_id": "ibmcld_07460-4810-5574", "score": 16.32942, "text": "\n$template->data = '127.0.0.1';\n$template->host = 'server01';\n\u00a0\n$result = $client->editObject($template);\nprint_r($result);\n\nIt is also necessary to populate the init params with the resource record ID property. A Boolean is returned by SoftLayer_Dns_Domain_ResourceRecord::editObject\n\n\n\n\n\n Delete records \n\nRemoval of a record is accomplished with SoftLayer_Dns_Domain_ResourceRecord::deleteObject. This method requires only an init parameter to be provided.\n\n$recordId = 1545925;\n\u00a0\n$client = SoftLayer_SoapClient::getClient('SoftLayer_Dns_Domain_ResourceRecord', $recordId, $apiUser, $apiKey);\n\u00a0\n$result = $client->deleteObject();\nprint_r($result);\n\nSoftLayer_Dns_Domain_ResourceRecord::deleteObject Returns a Boolean value: true for successful, false for failed.", "title": "", "source": "https://cloud.ibm.com/docs/dns?topic=dns-getting-started-with-the-dns-api"}, {"document_id": "ibmcld_02166-2413-3883", "score": 16.050371, "text": "\nreclamationsList, response, err := resourceControllerService.ListReclamations(listReclamationsOptions)\nif err != nil {\npanic(err)\n}\nb, _ := json.MarshalIndent(reclamationsList, \"\", \" \")\nfmt.Printf(\"nListReclamations() response:n%sn\", string(b))\n\nconst params = {\naccountId: accountId,\n};\n\nresourceControllerService.listReclamations(params)\n.then(res => {\nvar resources = res.result.resources;\nresources.forEach(reclaim => {\nif (reclaim.resource_instance_id.toString() === instanceGuid) {\nreclamationId = reclaim.id;\n}\n});\nconsole.log('listReclamations() response:n' + JSON.stringify(res.result, null, 2));\n})\n.catch(err => {\nconsole.warn(err)\n});\n\n\n\n\n\n Deleting a reclaimed resource by using the CLI \n\nTo delete a reclaimed resource by using the CLI, run the following command:\n\nibmcloud resource reclamation-delete ID [--comment COMMENT] [--f, --force]\n\nEnter the following command options:\n\n\n\n* ID: The ID of the resource reclamation. This is the reclamation ID and not the resource instance ID. (Required).\n* --comment: Comments about the action.\n* -f, --force: Force deletion without confirmation.\n\n\n\nThe following example shows how to delete a resource reclamation with ID d9fendfwlw:\n\nibmcloud resource reclamation-delete \"d9fendfwlw\"\n\nThe following example shows how to delete a resource reclamation with ID d9fendfwlw and leave a comment of no longer needed without confirmation:\n\nibmcloud resource reclamation-delete \"d9fendfwlw\" --comment \"no longer needed\" -f", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-resource-reclamation&interface=cli"}, {"document_id": "ibmcld_02586-13815-15875", "score": 16.03989, "text": "\n* A request would use an existing resource (for example, to generate a new resource) which has client-mutable state preventing such use.\n* A request would delete a resource that another resource depends on.\n\n\n\nThe following scenarios MUST NOT result in a 409 Conflict:\n\n\n\n* A request has an internal conflict. This SHOULD result in a 400 Bad Request.\n* A request depends on a resource that does not exist. This SHOULD result in a 400 Bad Request.\n* A request would update or create a resource with a binding to an existing resource that the user is unauthorized to bind to. This SHOULD result in a 403 Forbidden unless the user is [not permitted to know about](https://cloud.ibm.com/docs/api-handbook?topic=api-handbook-status-codesinformation-exposure-with-401-and-403) the existing resource.\n* A request would conflict with state that is invisible to clients. This MUST NOT happen by design, but unexpected runtime scenarios MAY result in a 500 Internal Server Error.\n* A request would conflict with state that is immutable for clients. This SHOULD result in a 400 Bad Request.\n* A safe[10] request cannot be made because of the current state of the system. This SHOULD NOT happen by design. Consider modeling the missing functionality as an \"empty\" resource with a 200 OK response or an absent resource with a 404 Not Found response.\n\n\n\nThe following scenarios SHOULD NOT result in a 409 Conflict:\n\n\n\n* A request cannot be processed because of transient resource state and the client is advised to wait for that state to change and retry the request. This SHOULD NOT happen by design, but if it does, it MAY result in a 409 Conflict.\n* A request would update or create a resource with a binding to an existing resource which has irrecoverably failed or expired. This SHOULD result in a 400 Bad Request.\n* A request would use an existing resource (for example, to generate a new resource) which has irrecoverably failed or expired. This SHOULD result in a 400 Bad Request.\n\n\n\n\n\n\n\n\n\n Server errors: 5xx \n\n\n\nServer error status codes\n\n Code Meaning Description", "title": "", "source": "https://cloud.ibm.com/docs/api-handbook?topic=api-handbook-status-codes"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_08446-4-1771", "score": 19.295889, "text": "\n* UI\n* API\n\n\n\n\n\n\n\n Deleting managed keys \n\nYou can delete your managed keys in Unified Key Orchestrator with the IBM Cloud\u00ae console, or programmatically with the Unified Key Orchestrator API.\n\nWhen you delete a managed key, the key is to be detached from all target keystores, and all key materials and the metadata are destroyed permanently.\n\n\n\n Deleting managed keys with the IBM Cloud console \n\nTo delete a key in Active state, you need to first deactivate the key, and then destroy the key and remove it from the vault.\n\nTo delete a key in Pre-active or Deactivated state, you only need to destroy the key, and then remove it from the vault.\n\nFor more information about key states and transitions, see [Monitoring the lifecycle of encryption keys in Unified Key Orchestrator](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-uko-key-states).\n\nFollow these steps to complete the process:\n\n\n\n1. [Log in to the Hyper Protect Crypto Services instance](https://cloud.ibm.com/login).\n2. Click Managed keys from the navigation to view all the available keys.\n3. If the managed key that you want to delete is in Active state, click the Actions icon ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/icons/action-menu-icon.svg) and choose Deactivated to deactivate the key first.\n\nWhen you change the Active key to Deactivated state, the key is detached from all the target keystores, and not accessible to all associated resources and their data. Make sure that you open the confirmation tile to check all the associated resources before you continue. However, you can still reactivate the key so that it is accessible to the resources again.\n4. To destroy a Pre-active or Deactivated key, click the Actions icon !", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-managed-keys"}, {"document_id": "ibmcld_09149-2959-3768", "score": 19.224617, "text": "\nFor more information about deleting keys, check out [About deleting and purging keys](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-purge-keys).\n\n\n\n\n\n How many key versions do you have? \n\nTo see how many versions you have of each key you have deployed:\n\n\n\n1. [Log in to the IBM Cloud console](https://cloud.ibm.com/login/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the Keys panel, click the \u22ef icon and select Key details. This opens a side panel that shows, among other things, the number of versions of this key you have.\n5. Repeat this process for every key in your instance. Note that because only root keys can be rotated, all of your standard keys only have one version.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-pricing-plan"}, {"document_id": "ibmcld_09099-5695-7625", "score": 19.220945, "text": "\nBecause a key ring cannot be deleted as long as it contains keys in any state (including the destroyed state keys are moved to after they are deleted but before they are automatically purged 90 days after deletion), if you want to delete a key ring, you might need to transfer keys to a different ring first.\n\nAfter transferring a key to a different key ring, it may take up to a maximum of ten minutes for the change to take effect.\n\n\n\n Transferring a key to a different key ring with the UI \n\nIf you do not see all of the options you expect to see, it might be because you do not have the permission to execute a particular action. Make sure your roles and permissions are sufficient to perform the action. For more information on roles, check out [Managing user access](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-access).\n\nYou must have the service \"Manager\" role of both the key being transferred and the target key ring to transfer a key.\n\nFrom the Keys panel:\n\n\n\n1. Find the key you want to transfer. Note that it can be helpful to specify the key ring where the key is currently located by selecting the ring in the Key ring ID drop down list. You can also click on Key rings in the left navigation, find the appropriate key ring, and click View associated keys inside the setting drop-down list. This will show you all of the keys associated with that key ring.\n2. Click on the \u22ef button, and select Edit key ring from the drop-down list.\n3. In the drop-down list, select the key ring you want to move the key to. Then click Save.\n\n\n\n\n\n\n\n Transferring a key to a different key ring with the API \n\nTransfer a key to a different key ring by making a PATCH call to the following endpoint.\n\nhttps://<region>.kms.cloud.ibm.com/api/v2/keys/<keyID_or_alias>\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https://cloud.ibm.com/docs/key-protect?topic=key-protect-set-up-api).", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-grouping-keys"}, {"document_id": "ibmcld_08435-3634-5079", "score": 19.166996, "text": "\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/icons/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_08446-1337-2966", "score": 19.029724, "text": "\nWhen you change the Active key to Deactivated state, the key is detached from all the target keystores, and not accessible to all associated resources and their data. Make sure that you open the confirmation tile to check all the associated resources before you continue. However, you can still reactivate the key so that it is accessible to the resources again.\n4. To destroy a Pre-active or Deactivated key, click the Actions icon ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/icons/action-menu-icon.svg) and choose Destroyed.\n\nWhen you destroy a managed key, the key cannot be restored in Unified Key Orchestrator. However, you can still restore your keys in external keystores depending on the settings of the cloud providers. For more information, see [Azure Key Vault soft-delete overview](https://docs.microsoft.com/en-us/azure/key-vault/general/soft-delete-overview), [Deleting AWS KMS keys](https://docs.aws.amazon.com/kms/latest/developerguide/deleting-keys.html), or [Deleting and purging keys in Key Protect](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-purge-keys).\n5. Click Destroy key to confirm.\n6. To remove the key and the metadata from the vault, click the Actions icon ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/icons/action-menu-icon.svg) and choose Remove from vault.\n\nWhen you remove the managed key from the vault that the key is assigned to, the remaining key metadata is removed permanently.\n\n\n\nThe managed key has been deleted and detached from all target keystores.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-managed-keys"}, {"document_id": "ibmcld_09064-4-1760", "score": 18.954445, "text": "\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys using a single authorization \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to delete an encryption key and its key material, if you are a manager for your Key Protect instance.\n\nBefore deleting keys, make sure to review the [Considerations before deleting and purging a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Deleting keys in the console \n\nBy default, Key Protect requires one authorization to delete a key. If you prefer to delete your encryption keys by using a graphical interface, you can use the IBM Cloud console.\n\n[After you create or import your existing keys into the service](https://cloud.ibm.com/docs/key-protect?topic=key-protect-create-root-keys), complete the following steps to delete a key:\n\n\n\n1. [Log in to the IBM Cloud console](https://cloud.ibm.com/login/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the application details page, use the Keys table to browse the keys in your service.\n5. Click the \u22ef icon to open a list of options for the key that you want to delete.\n6. From the options menu, click Delete key and confirm the key deletion in the next screen by ensuring the key has no associated resources. Note that you will not be able to delete the key if it is protecting a registered IBM Cloud resource that's non-erasable due to a [retention policy](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutableimmutable-terminology-policy).\n\n\n\nAfter you delete a key, the key transitions to the Destroyed state. Any data encrypted by keys in this state is no longer accessible.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys"}, {"document_id": "ibmcld_09070-7-2084", "score": 18.949003, "text": "\nAbout deleting and purging keys \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to delete an encryption key and its key material if you are a manager for your Key Protect instance.\n\nBefore you can delete an instance, you must delete every key in that instance. However, if you close your account, any existing instances and keys are automatically hard deleted. Check out [Account cancelation and data deletion](https://cloud.ibm.com/docs/key-protect?topic=key-protect-security-and-complianceaccount-cancelation) for more information.\n\nIn the event that a key is no longer needed or should be removed, Key Protect allows you to delete and ultimately purge keys, an action that shreds the key material and makes any of the data encrypted with it inaccessible.\n\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https://cloud.ibm.com/docs/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n\nThe following table lists the time frames in which you can view, restore, and purge a key after it has been deleted.\n\n\n\nTable 1. Lists how users can interact with keys during certain time intervals after a key has been deleted", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-purge-keys"}, {"document_id": "ibmcld_09064-1360-3081", "score": 18.849108, "text": "\nNote that you will not be able to delete the key if it is protecting a registered IBM Cloud resource that's non-erasable due to a [retention policy](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutableimmutable-terminology-policy).\n\n\n\nAfter you delete a key, the key transitions to the Destroyed state. Any data encrypted by keys in this state is no longer accessible. Metadata that is associated with the key, such as the key's deletion date, is kept in the Key Protect database. Destroyed keys can be recovered after up to 30 days or their expiration date, whichever is sooner. After 30 days, keys can no longer be recovered, and become eligible to be purged after 90 days, a process that shreds the key material and makes its metadata inaccessible.\n\nIf a user [has the KeyPurge attribute](https://cloud.ibm.com/docs/key-protect?topic=key-protect-grant-access-keysgrant-access-keys-specific-functions), they can purge a key after four hours. Check out [Purging keys in the console](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keysdelete-keys-gui-purge) for more information.\n\n\n\n\n\n Purging keys in the console \n\nIf it is important to your use case to purge a key sooner than 90 days (the soonest a key can be purged after a normal deletion), the key can be purged after four hours if a user [has the KeyPurge role](https://cloud.ibm.com/docs/key-protect?topic=key-protect-grant-access-keysgrant-access-keys-specific-functions).\n\nBecause a purged key has its key material permanently shredded and metadata inaccessible, a purged key cannot be restored. It is therefore even more important to ensure that the key has no vital associated resources.\n\nTo purge a key:\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys"}, {"document_id": "ibmcld_09088-9397-11338", "score": 18.77746, "text": "\nIf it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https://cloud.ibm.com/docs/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n\n\n\n\n\n What happens if I try to delete a key that's actively encrypting data? \n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-faqs"}, {"document_id": "ibmcld_08414-28698-30846", "score": 18.753866, "text": "\nIf the delete key event has a reason.reasonCodeof 409, the key cannot be deleted because it is possibly protecting one or more cloud resources that have a retention policy. Make a GET request to /keys/{id}/registrations to learn which resources this key is associated with. A registration with \"preventKeyDeletion\": true indicates that the associated resource has a retention policy. To enable deletion, contact an account owner to remove the retention policy on each resource that is associated with this key.\n\nA delete key event might also receive a reason.reasonCode of 409 due to a dual auth deletion policy on the key. Make a GET request to /api/v2/keys/{id}/policies to see whether a dual authorization policy is associated with your key. If there is a policy set, contact the other authorized user to delete the key.\n\n\n\n\n\n Unable to authenticate while making a request \n\nIf the event has a reason.reasonCode of 401, you might not have the correct authorization to perform Hyper Protect Crypto Services actions in the specified service instance. Verify with an administrator that you are assigned the correct platform and service access roles in the applicable service instance. For more information about roles, see [Roles and permissions](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-access).\n\nCheck that you are using a valid token that is associated with an account that is authorized to perform the service action.\n\n\n\n\n\n Unable to view or list keys in a service instance \n\nYou can call GET api/v2/keys to list the keys that are available in your service instance. If responseData.totalResources is 0, query for keys in the deleted state by using the state parameter or adjust the offset and limit parameters in your request.\n\n\n\n\n\n Lifecycle action on a key with registrations did not complete \n\nThe responseData.reasonForFailure and responseData.resourceCRN fields contain information about why the action wasn't able to be completed.\n\nIf the event has a reason.reasonCode of 409, the action cannot be completed due to the adopting service's key state conflicting with the key state that Hyper Protect Crypto Services has.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-at-events"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09064-8216-9792", "score": 22.024439, "text": "\n\"algorithmMode\": \"Deprecated\",\n\"lastUpdateDate\": \"2020-03-16T20:41:27Z\",\n\"dualAuthDelete\": {\n\"enabled\": false\n},\n\"deleted\": true,\n\"deletionDate\": \"2020-03-16T21:46:53Z\",\n\"deletedBy\": \"...\"\n}\n]\n}\n\nFor a detailed description of the available parameters, see the Key Protect [REST API reference doc](https://cloud.ibm.com/apidocs/key-protect).\n\n\n\n Using the force query parameter \n\nKey Protect blocks the deletion of a key that's protecting a cloud resource, such as a Cloud Object Storage bucket. You can force delete a key and its contents by making a DELETE call to the following endpoint.\n\nhttps://<region>.kms.cloud.ibm.com/api/v2/keys/<keyID_or_alias>?force=true\n\nWhen you delete a key that has registrations associated with it, you immediately deactivate its key material and the data encrypted by the key. Any data that is encrypted by the key becomes inaccessible. Thirty days after a key is deleted, the key can no longer be restored and the key material will be destroyed after 90 days.\n\nForce deletion on a key won't succeed if the key is protecting a registered IBM Cloud resource that's non-erasable due to a [retention policy](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutableimmutable-terminology-policy), which is a Write Once Read Many (WORM) policy set on the your IBM Cloud resource. You can verify whether a key is associated with a non-erasable resource by checking the 'preventKeyDeletion\" field in the [registration details](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) for the key.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys"}, {"document_id": "ibmcld_01019-1608-2449", "score": 21.57575, "text": "\nIf you need to delete the key during the soft-deletion period, you have to force delete the key. After the soft-deletion period, the key can be deleted without the force. You can check the association between the key and your deployment to determine when you can delete the key.\n\n\n\n\n\n Deleting data in your database \n\nThe Db2 database stores data in pages on block storage. When DELETE or TRUNCATE operations are performed, that data is no longer accessible unless you are using TEMPORAL tables. The physical pages that contain the data are not immediately erased and might still exist on the disk, but will be overwritten as needed. There is no ability to recover this data. The database provides the REORG and REDUCE MAX capability to reclaim this space for other activities or it will be reused when the database needs to store more data.", "title": "", "source": "https://cloud.ibm.com/docs/Db2onCloud?topic=Db2onCloud-del_db"}, {"document_id": "ibmcld_09064-9212-10938", "score": 20.968306, "text": "\nForce deletion on a key won't succeed if the key is protecting a registered IBM Cloud resource that's non-erasable due to a [retention policy](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutableimmutable-terminology-policy), which is a Write Once Read Many (WORM) policy set on the your IBM Cloud resource. You can verify whether a key is associated with a non-erasable resource by checking the 'preventKeyDeletion\" field in the [registration details](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) for the key. Then, you must contact an account owner to remove the retention policy on each registered IBM Cloud resource that is associated with the key before you can delete the key.\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https://cloud.ibm.com/docs/key-protect?topic=key-protect-set-up-api).\n2. Retrieve the ID of the key that you want to force delete.\n\nYou can retrieve the ID for a specified key by making a GET /v2/keys/ request, or by viewing your keys in the Key Protect dashboard.\n3. Run the following curl command to force delete the key and its contents.\n\n$ curl -X DELETE \"https://<region>.kms.cloud.ibm.com/api/v2/keys/<keyID_or_alias>?force=true\" -H \"authorization: Bearer <IAM_token>\" -H \"bluemix-instance: <instance_ID>\" -H \"prefer: <return_preference>\"\n\nReplace the variables in the example request according to the following table.\n\n\n\n\n\nTable 2. Describes the variables that are needed to delete keys with the Key Protect API.\n\n Variable Description \n\n region Required. The region abbreviation, such as us-south or eu-gb, that represents the geographic area where your Key Protect instance resides.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys"}, {"document_id": "ibmcld_07578-1211120-1213024", "score": 20.611383, "text": "\nIf needed, you can [force deletion on a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1213753-1215657", "score": 20.611383, "text": "\nIf needed, you can [force deletion on a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_09088-9397-11338", "score": 20.59506, "text": "\nIf it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https://cloud.ibm.com/docs/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n\n\n\n\n\n What happens if I try to delete a key that's actively encrypting data? \n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-faqs"}, {"document_id": "ibmcld_01034-3831-4923", "score": 20.52829, "text": "\nAfter the soft-deletion period, the key can be deleted without the force. You can check the [association between the key and your deployment](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-view-key-details) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.\n\nHyper Protect Crypto Services enables [initiation of a force delete](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-at-events) as hs-crypto.secrets.delete.", "title": "", "source": "https://cloud.ibm.com/docs/Db2onCloud?topic=Db2onCloud-hpcs"}, {"document_id": "ibmcld_16727-1212381-1214315", "score": 20.292355, "text": "\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https://cloud.ibm.com/docs/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n* What happens if I try to delete a key that's actively encrypting data?\n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-1209748-1211682", "score": 20.292355, "text": "\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https://cloud.ibm.com/docs/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n* What happens if I try to delete a key that's actively encrypting data?\n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_01041-3464-4855", "score": 20.25824, "text": "\nAfter the soft-deletion period the key can be deleted without the force. You can check the [association between the key and your deployment](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. Once the key is deleted your data is unrecoverable.\n\nKey Protect or Hyper Protect Crypto Services allows you to initiate a force delete of a key that is in use by IBM Cloud\u00ae services using [Key Protect](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) or [Hyper Protect Crypto Services](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys), including your Db2 on Cloud deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks containing your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data contained within them. Key deletion is sent to the Log Analysis Activity Tracker as kms.secrets.delete using [Key Protect](https://cloud.ibm.com/docs/key-protect?topic=key-protect-at-events) and as hs-crypto.secrets.delete using [Hyper Protect Crypto Services](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-at-events).", "title": "", "source": "https://cloud.ibm.com/docs/Db2onCloud?topic=Db2onCloud-key-management-services"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01034-3831-4923", "score": 26.579151, "text": "\nAfter the soft-deletion period, the key can be deleted without the force. You can check the [association between the key and your deployment](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-view-key-details) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.\n\nHyper Protect Crypto Services enables [initiation of a force delete](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-at-events) as hs-crypto.secrets.delete.", "title": "", "source": "https://cloud.ibm.com/docs/Db2onCloud?topic=Db2onCloud-hpcs"}, {"document_id": "ibmcld_01041-3464-4855", "score": 26.073143, "text": "\nAfter the soft-deletion period the key can be deleted without the force. You can check the [association between the key and your deployment](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. Once the key is deleted your data is unrecoverable.\n\nKey Protect or Hyper Protect Crypto Services allows you to initiate a force delete of a key that is in use by IBM Cloud\u00ae services using [Key Protect](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) or [Hyper Protect Crypto Services](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys), including your Db2 on Cloud deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks containing your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data contained within them. Key deletion is sent to the Log Analysis Activity Tracker as kms.secrets.delete using [Key Protect](https://cloud.ibm.com/docs/key-protect?topic=key-protect-at-events) and as hs-crypto.secrets.delete using [Hyper Protect Crypto Services](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-at-events).", "title": "", "source": "https://cloud.ibm.com/docs/Db2onCloud?topic=Db2onCloud-key-management-services"}, {"document_id": "ibmcld_09559-3849-5260", "score": 24.715572, "text": "\nIf you delete a deployment that is protected with an HPCS key, the deployment remains registered against the key during the soft-deletion period (up to 9 days). If you need to delete the key in the soft-deletion period, you must [force delete](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys) the key. After the soft-deletion period, the key can be deleted without the force. You can check the [association between the key and your deployment](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-view-key-details) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.\n\nHyper Protect Crypto Services enables [initiation of a force delete](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-at-events) as hs-crypto.secrets.delete.", "title": "", "source": "https://cloud.ibm.com/docs/messages-for-rabbitmq?topic=messages-for-rabbitmq-hpcs"}, {"document_id": "ibmcld_06638-4935-6851", "score": 24.596342, "text": "\nKey Protect allows you to [initiate a force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https://cloud.ibm.com/docs/key-protect?topic=key-protect-at-events) as kms.secrets.delete.\n\n\n\n\n\n Bring your own key for backups \n\nIf you use Key Protect, when you provision a database you can also designate a key to encrypt the Cloud Object Storage disk that holds your deployment's backups.\n\nBYOK for backups is available only in US regions us-south and us-east, and eu-de.\n\nOnly keys in the us-south and eu-de are durable to region failures. To ensure that your backups are available even if a region failure occurs, you must use a key from us-south or eu-de, regardless of your deployment's location.\n\n\n\n Granting the delegation authorization \n\nTo enable your deployment to use the Key Protect key, you need to [Enable authorization to be delegated](https://cloud.ibm.com/docs/account?topic=account-serviceauth) when granting the service authorizations. If the delegation authorization is not present before provisioning your deployment with a key, the provision fails.\n\n\n\n\n\n Using the Key at Provision in the CLI \n\nAfter the appropriate authorization and delegation is granted, you supply the [key name or CRN](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-keys) when you provision a deployment.\n\nIn the CLI, use the backup_encryption_key_crn parameter in the parameters JSON object.", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-postgresql?topic=databases-for-postgresql-key-protect"}, {"document_id": "ibmcld_09562-4925-6841", "score": 24.596342, "text": "\nKey Protect allows you to [initiate a force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https://cloud.ibm.com/docs/key-protect?topic=key-protect-at-events) as kms.secrets.delete.\n\n\n\n\n\n Bring your own key for backups \n\nIf you use Key Protect, when you provision a database you can also designate a key to encrypt the Cloud Object Storage disk that holds your deployment's backups.\n\nBYOK for backups is available only in US regions us-south and us-east, and eu-de.\n\nOnly keys in the us-south and eu-de are durable to region failures. To ensure that your backups are available even if a region failure occurs, you must use a key from us-south or eu-de, regardless of your deployment's location.\n\n\n\n Granting the delegation authorization \n\nTo enable your deployment to use the Key Protect key, you need to [Enable authorization to be delegated](https://cloud.ibm.com/docs/account?topic=account-serviceauth) when granting the service authorizations. If the delegation authorization is not present before provisioning your deployment with a key, the provision fails.\n\n\n\n\n\n Using the Key at Provision in the CLI \n\nAfter the appropriate authorization and delegation is granted, you supply the [key name or CRN](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-keys) when you provision a deployment.\n\nIn the CLI, use the backup_encryption_key_crn parameter in the parameters JSON object.", "title": "", "source": "https://cloud.ibm.com/docs/messages-for-rabbitmq?topic=messages-for-rabbitmq-key-protect"}, {"document_id": "ibmcld_06381-2433-3517", "score": 24.243786, "text": "\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-enterprisedb?topic=cloud-databases-deprovisioning"}, {"document_id": "ibmcld_06564-2541-3625", "score": 24.243786, "text": "\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-mysql?topic=databases-for-mysql-deprovisioning"}, {"document_id": "ibmcld_09551-2545-3629", "score": 24.243786, "text": "\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/messages-for-rabbitmq?topic=messages-for-rabbitmq-deprovisioning"}, {"document_id": "ibmcld_01041-2429-3846", "score": 24.210695, "text": "\nAfter you grant your Db2 on Cloud deployments permission to use your keys, you supply the key name or CRN in [Key Protect](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-keys) or [Hyper Protect Crypto Services](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-view-keys) when you provision a deployment. The deployment uses your encryption key to encrypt your data.\n\nIf you provision a deployment through the CLI or API, the key needs to be identified by its full CRN, not just its ID. A CRN is in the format crn:v1:<...>:key:<id>.\n\n\n\n\n\n Deleting the deployment \n\nIf you delete a deployment that is protected with a key, the deployment remains registered against the key for the duration of the soft-deletion period (up to 9 days). If you need to delete the key in the soft-deletion period, you have to force delete the key using [Key Protect](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) or [Hyper Protect Crypto Services](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys). After the soft-deletion period the key can be deleted without the force. You can check the [association between the key and your deployment](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. Once the key is deleted your data is unrecoverable.", "title": "", "source": "https://cloud.ibm.com/docs/Db2onCloud?topic=Db2onCloud-key-management-services"}, {"document_id": "ibmcld_08442-6623-8241", "score": 23.925518, "text": "\nHyper Protect Crypto Services blocks the deletion of a key that's protecting a cloud resource, such as a IBM Cloud Object Storage bucket. You can force-delete a key and the contents by making a DELETE call to the following endpoint.\n\nhttps://api.<region>.hs-crypto.cloud.ibm.com:<port>/api/v2/keys/<key_ID>?force=true\n\nWhen you delete a key with registrations that are associated, you shred the key's contents and associated data. Any data that is encrypted by the key becomes inaccessible.\n\nThis action can't succeed if the key is protecting a resource that's non-erasable due to a retention policy. You can verify whether a key is associated with a non-erasable resource by [checking the registration details](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-view-protected-resources) for the key. Then, you must contact an account owner to remove the retention policy on each resource that is associated with the key before you can delete the key.\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-up-kms-api).\n2. Retrieve the ID of the key that you want to force delete.\n\nYou can retrieve the ID for a specified key by making a GET /v2/keys/request, or by viewing your keys in the IBM Cloud console.\n3. Run the following cURL command to force-delete the key and the contents.\n\ncurl -X DELETE \"https://api.<region>.hs-crypto.cloud.ibm.com:<port>/api/v2/keys/<key_ID>?force=true\" -H 'authorization: Bearer <IAM_token>' -H 'bluemix-instance: <instance_ID>' -H \"x-kms-key-ring: <key_ring_ID>\" -H 'prefer: <return_preference>'", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_06638-4935-6851", "score": 22.23692, "text": "\nKey Protect allows you to [initiate a force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https://cloud.ibm.com/docs/key-protect?topic=key-protect-at-events) as kms.secrets.delete.\n\n\n\n\n\n Bring your own key for backups \n\nIf you use Key Protect, when you provision a database you can also designate a key to encrypt the Cloud Object Storage disk that holds your deployment's backups.\n\nBYOK for backups is available only in US regions us-south and us-east, and eu-de.\n\nOnly keys in the us-south and eu-de are durable to region failures. To ensure that your backups are available even if a region failure occurs, you must use a key from us-south or eu-de, regardless of your deployment's location.\n\n\n\n Granting the delegation authorization \n\nTo enable your deployment to use the Key Protect key, you need to [Enable authorization to be delegated](https://cloud.ibm.com/docs/account?topic=account-serviceauth) when granting the service authorizations. If the delegation authorization is not present before provisioning your deployment with a key, the provision fails.\n\n\n\n\n\n Using the Key at Provision in the CLI \n\nAfter the appropriate authorization and delegation is granted, you supply the [key name or CRN](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-keys) when you provision a deployment.\n\nIn the CLI, use the backup_encryption_key_crn parameter in the parameters JSON object.", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-postgresql?topic=databases-for-postgresql-key-protect"}, {"document_id": "ibmcld_09562-4925-6841", "score": 22.23692, "text": "\nKey Protect allows you to [initiate a force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https://cloud.ibm.com/docs/key-protect?topic=key-protect-at-events) as kms.secrets.delete.\n\n\n\n\n\n Bring your own key for backups \n\nIf you use Key Protect, when you provision a database you can also designate a key to encrypt the Cloud Object Storage disk that holds your deployment's backups.\n\nBYOK for backups is available only in US regions us-south and us-east, and eu-de.\n\nOnly keys in the us-south and eu-de are durable to region failures. To ensure that your backups are available even if a region failure occurs, you must use a key from us-south or eu-de, regardless of your deployment's location.\n\n\n\n Granting the delegation authorization \n\nTo enable your deployment to use the Key Protect key, you need to [Enable authorization to be delegated](https://cloud.ibm.com/docs/account?topic=account-serviceauth) when granting the service authorizations. If the delegation authorization is not present before provisioning your deployment with a key, the provision fails.\n\n\n\n\n\n Using the Key at Provision in the CLI \n\nAfter the appropriate authorization and delegation is granted, you supply the [key name or CRN](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-keys) when you provision a deployment.\n\nIn the CLI, use the backup_encryption_key_crn parameter in the parameters JSON object.", "title": "", "source": "https://cloud.ibm.com/docs/messages-for-rabbitmq?topic=messages-for-rabbitmq-key-protect"}, {"document_id": "ibmcld_06443-2410-3623", "score": 22.14054, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-etcd?topic=databases-for-etcd-deprovisioning"}, {"document_id": "ibmcld_06696-2412-3625", "score": 22.14054, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-redis?topic=databases-for-redis-deprovisioning"}, {"document_id": "ibmcld_06627-2422-3635", "score": 22.14054, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-postgresql?topic=databases-for-postgresql-deprovisioning"}, {"document_id": "ibmcld_06499-2416-3629", "score": 22.14054, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-mongodb?topic=databases-for-mongodb-deprovisioning"}, {"document_id": "ibmcld_06341-2428-3641", "score": 22.14054, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-elasticsearch?topic=databases-for-elasticsearch-deprovisioning"}, {"document_id": "ibmcld_06381-2433-3517", "score": 21.984545, "text": "\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-enterprisedb?topic=cloud-databases-deprovisioning"}, {"document_id": "ibmcld_06564-2541-3625", "score": 21.984545, "text": "\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-mysql?topic=databases-for-mysql-deprovisioning"}, {"document_id": "ibmcld_09551-2545-3629", "score": 21.984545, "text": "\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/messages-for-rabbitmq?topic=messages-for-rabbitmq-deprovisioning"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_08669-6042-7847", "score": 18.802114, "text": "\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events. IBM is responsible for the recovery of Hyper Protect Crypto Services components in case of disaster. You are responsible for the recovery of the workloads that run Hyper Protect Crypto Services and your application data.\n\n\n\nTable 5. Responsibilities for disaster recovery\n\n Task IBM responsibilities Your responsibilities \n\n Instance backups Continuously perform in-region and cross-region backups of key resources and perform continuous testing of backups. Back up your master key; validate the backups and restore data when needed. \n Disaster recovery When an in-region disaster occurs, automatically recover and restart service components. When a regional disaster that affects all available zones occurs, ensure that all data except the master key is replicated to another region. IBM will also make additional crypto units available in a different region and manage routing requests to the new crypto units. When a regional disaster that affects all available zones occurs, load your master key to the new crypto units that IBM provisions in a different region for restoring data. You can also enable and initialize failover crypto units before a disaster occurs, which reduces the downtime. \n Availability Provide high availability capabilities, such as IBM-owned infrastructure in multizone regions, to meet local access and low latency requirements for each supported region. Use the list of [available regions](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-regions) to plan for and create new instances of the service.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-shared-responsibilities"}, {"document_id": "ibmcld_08511-1920-3732", "score": 18.460934, "text": "\nFor more information, see [Disaster recovery](https://cloud.ibm.com/docs/overview?topic=overview-zero-downtimedisaster-recovery).\n\n\n\n\n\n Cross-region disaster recovery \n\nIBM also performs cross-region backup for your key resources. Your data is automatically backed up in another supported region daily. Depending on where you create your instance and your requirements for recovery time, you can restore your data in case of a regional disaster with the following options:\n\n\n\n* If you create your instance in Dallas (us-south) or Washington DC (us-east) and you enable failover crypto units, the failover crypto units back up the operational crypto units and keystores in another region. When a regional disaster occurs, your data is restored automatically with the failover crypto units to reduce the downtime and data loss. For more information about how to use failover crypto units to restore data, see [Restoring your data by using failover crypto units](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-restore-datarestore-data-failover-crypto-units).\n* If you don't enable failover crypto units, you can use the default daily backup to restore your data. In this case, you need to open a support ticket so that IBM can create a new service instance in another supported region to restore your data from the backup. Then, you need to manually load your master key to the new instance again to make it work. In this process, you're the only person who owns the master key. IBM administrators or any third-party users can't access your data or keys in the backup or the restored service instance. For more information about the recovery process, see [Restoring your data by opening an IBM support ticket](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-restore-datarestore-data-open-support-ticket).", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-ha-dr"}, {"document_id": "ibmcld_08622-7-1971", "score": 18.418718, "text": "\nRestoring your data from another region \n\nIf a regional disaster that affects all available zones occurs, you're notified through the [IBM Cloud status](https://cloud.ibm.com/status?selected=status) web page and an email. In this case, depending on your [pricing plan](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-provision), whether you enable failover crypto units, and your requirements for recovery time, you can restore your data with different options.\n\n\n\n Restoring your data by using failover crypto units \n\nIf you are using the standard plan, and create your instance in Dallas (us-south) or Washington DC (us-east) and you enable failover crypto units, your data is restored automatically to reduce the downtime and data loss. In this case, you switch to use the failover crypto units in another region to manage your keys and perform cryptographic operations. The failover crypto units contain a backup of all the encryption keys and other resources in the operational crypto units.\n\nAt the same time, IBM repairs your service instance in the original region. If new operational crypto units are required to complete the repair, you will be notified by IBM and you need to load the master key to the new operational crypto units by [using recovery crypto units or master key parts](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-initialize-instance-mode). After your original service instance is recovered, IBM automatically redirects traffic back to the original region.\n\nTo use failover crypto units to restore data in a regional disaster, make sure that you initialize and configure all the failover crypto units the same as the operational crypto units before the disaster happens. For more information about initialization approaches, see [Introducing service instance initialization approaches](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-initialize-instance-mode).\n\n\n\n\n\n Restoring your data by opening an IBM support ticket", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-restore-data"}, {"document_id": "ibmcld_08622-1505-3356", "score": 18.38414, "text": "\nTo use failover crypto units to restore data in a regional disaster, make sure that you initialize and configure all the failover crypto units the same as the operational crypto units before the disaster happens. For more information about initialization approaches, see [Introducing service instance initialization approaches](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-initialize-instance-mode).\n\n\n\n\n\n Restoring your data by opening an IBM support ticket \n\nIf you don't enable failover crypto units or you are using Hyper Protect Crypto Services with Unified Key Orchestrator, you need to open an IBM support ticket to restore your data. IBM can then provision a new service instance for you in another region by using the same instance ID, and restore all the key resources from the backup. And then, you need to load your\n\nmaster keyto the new service instance in the new region.\n\nIn the process, you're the only person who owns the master key. IBM administrators or any third-party users cannot access your data or keys in the backup or the restored service instance.\n\nTo restore a backup to an existing service instance, follow these steps:\n\n\n\n1. In the IBM Cloud console, click the Help icon ![Help icon](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/icons/help.svg) > Support center from the IBM Cloud console menu barto enter the Support Center. Click View all in the Recent support cases panel and click Create new case. Or, you can directly go to the [Manage cases page](https://cloud.ibm.com/unifiedsupport/cases) and click Create new case.\n2. On the Create a case page displayed, select the offering Hyper Protect Crypto Services, and then specify the following values:\n\n\n\nTable 1. Describes the fields required for creating a case\n\n Field name Action \n\n Subject Enter Disaster recovery.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-restore-data"}, {"document_id": "ibmcld_01020-7-1885", "score": 17.590178, "text": "\nGeo-replicated disaster recovery (DR) \n\nDb2 on Cloud leverages Db2 HADR technology and gives you the ability to add a DR node, on demand, in an offsite data center of your choice. In an unlikely event that the primary data server is affected by external circumstances such as a natural disaster, you can failover to your Geo-Replicated Disaster Recovery node with a few clicks. You can also fail back to your primary site just as easily.\n\nAdmin functionality is not available on the DR node. Any admin functions must be run on the primary instance while it's Active.\n\nDR nodes are currently set up to adopt the KMS instance and disk encrption key of the primary data server in the case that the primary data server uses Hyper Protect Crypto Services for encryption.\n\nDR nodes are currently available for only Enterprise and Standard HADR plans. DR nodes are currently not supported in single node plans or in EU-Cloud.\n\nFailover to the DR site is not automatic. You must initiate the failover.\n\nDeleting a DR configuration is currently not supported on the IBM Cloud dashboard. To delete the DR configuration, you must open a support ticket. Deleting a DR configuration removes both the primary and DR sites.\n\n[Creating a DR node](https://cloud.ibm.com/docs/Db2onCloud?topic=Db2onCloud-dr_gendr_create_dr_node)\n\n[Forcing a failover to the DR site](https://cloud.ibm.com/docs/Db2onCloud?topic=Db2onCloud-dr_gendr_force_failover)\n\n[Forcing a failback to the primary site](https://cloud.ibm.com/docs/Db2onCloud?topic=Db2onCloud-dr_gendr_force_failback)\n\n\n\n High Availability vs. Disaster Recovery \n\nDb2 on Cloud High Availability plan offers Db2 HADR SYNC and ASYNC nodes technology to deliver superior availability and reliability, within the same region. When required, failover to the HA nodes is managed seamlessly and automatically by IBM using automatic client reroute (ACR).", "title": "", "source": "https://cloud.ibm.com/docs/Db2onCloud?topic=Db2onCloud-dr_gen"}, {"document_id": "ibmcld_08511-7-2392", "score": 17.347876, "text": "\nHigh availability and disaster recovery \n\nIBM Cloud\u00ae Hyper Protect Crypto Services is a highly available, regional service with automatic features that help keep your applications secure and operational.\n\nLearn more about availability and disaster recovery strategies of Hyper Protect Crypto Services.\n\n\n\n Locations, tenancy, and availability \n\nYou can create Hyper Protect Crypto Services resources in one of the supported [IBM Cloud regions](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-regions), which represent the geographic area where your Hyper Protect Crypto Services requests are handled and processed. Each IBM Cloud region contains [multiple availability zones](https://www.ibm.com/cloud/data-centers/) to meet local access, low latency, and security requirements for the region.\n\nAs you plan your encryption at rest strategy with IBM Cloud, keep in mind that provisioning Hyper Protect Crypto Services in a region that is nearest to you is more likely to result in faster, more reliable connections when you interact with the Hyper Protect Crypto Services APIs. Choose a specific region if the users, apps, or services that depend on a Hyper Protect Crypto Services resource are geographically concentrated. Users and services who are far away from the region might experience higher latency.\n\nYour encryption keys are confined to the region that you created them in. Hyper Protect Crypto Services does not copy or export encryption keys to other regions.\n\n\n\n\n\n In-region data redundancy and failover \n\nMultiple\n\ncrypto unitsin a service instance are automatically synchronized and load balanced across multiple availability zones. If one available zone that contains your provisioned service instance cannot be accessed, Hyper Protect Crypto Services has automatic in-region data failover in place. The service follows IBM Cloud requirements for planning and recovering from disaster events. For more information, see [Disaster recovery](https://cloud.ibm.com/docs/overview?topic=overview-zero-downtimedisaster-recovery).\n\n\n\n\n\n Cross-region disaster recovery \n\nIBM also performs cross-region backup for your key resources. Your data is automatically backed up in another supported region daily. Depending on where you create your instance and your requirements for recovery time, you can restore your data in case of a regional disaster with the following options:", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-ha-dr"}, {"document_id": "ibmcld_09756-3410-5722", "score": 17.23033, "text": "\nDisaster recovery is about surviving a catastrophic failure or loss of availability in a single location.\n\nIBM Cloud Monitoring follows IBM Cloud requirements for [planning and recovering from disaster events](https://cloud.ibm.com/docs/overview?topic=overview-zero-downtimedisaster-recovery).\n\nIf a regional disaster occurs, consider the following information:\n\n\n\n* The estimated recovery time for rebuilding the regional site and restoring the service at another location is 24 hours.\n* You will have to update the endpoints of applications and monitoring agents to point to the ingestion endpoint in the new location.\n* You will have to restore the service instance's metadata, that is, dashboards and alerts definitions, from your backups.\n\n\n\nHistorical data may be lost during a disaster. If you require historical metrics for auditing purposes, backup the metrics regularly by querying the metrics from the service and storing them at a remote backup site.\n\n\n\n Manual recovery of the service \n\nIf a regional disaster occurs, the recovery time of the service depends on the recovery time for the region. To minimize the downtime of the service and impact to your business, you could implement a manual failover to switch to another region while the region is being restored. To reduce the time to get up and running in a new location, consider using access groups to manage permissions working with the service, and backup the monitoring metadata of each instance. You should backup your alerts, notifications, dashboards and team definitions on a regular basis.\n\nHow to continue working while a DR site is rebuilt?\n\nIf the applications and services that you are monitoring through a monitoring instance are all co-located in the same region, then you must wait for the region to be available again for business.\n\nIf you have deployed monitoring agents on your systems, and those systems are not impacted by the regional failure, you may choose to redirect metrics to other instances of monitoring in a different region. To redirect metric data, complete the following steps:\n\n\n\n1. [Provision a monitoring instance](https://cloud.ibm.com/docs/monitoring?topic=monitoring-provision)\n2. Reconfigure the monitoring agent of each system: Change the access key and ingestion endpoints in the agent configuration.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-ha-dr"}, {"document_id": "ibmcld_08742-4656-6567", "score": 16.599527, "text": "\nRecovery crypto units can also be used as backup crypto units that save a copy of the master key value used by the operational crypto units. If the master key is lost or destroyed, you can [recover the master key from a recovery crypto unit](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-recover-master-key-recovery-crypto-unit) by using signed TKE administrative commands.\n\nIf smart cards are used to load the master key, the recovery crypto units are not applicable and can be ignored. The backup of the master key relies on the backup of the smart cards in that case.\n* Failover crypto unit\n\nFailover crypto units back up the operational crypto units and keystores in another region, and are initialized to provide quick failover in case of disaster. Failover crypto units [charge extra fees](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-faq-pricing) and this option is now available only in regions of us-south and us-east, which means if you create your instance in either of the two regions, the failover crypto units are located in the other region. For more information about using failover crypto units in a regional disaster, see [Restoring your data by using failover crypto units](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-restore-datarestore-data-failover-crypto-units).\n\n\n\n\n\n\n\n Administrators \n\nAdministrators can be added to the target crypto units for issuing commands to the crypto units. You can add up to eight administrators to one crypto unit to increase security. Each administrator owns one private [signature key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-understand-conceptssignature-key-concept) for identity authentication.\n\n\n\n\n\n Signature keys \n\nAn administrator must sign any commands that are issued to the crypto unit with a signature key. The signature keys that are created in Hyper Protect Crypto Services are P521 Elliptic Curve (EC) keys.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-understand-concepts"}, {"document_id": "ibmcld_08738-4699-6619", "score": 16.38092, "text": "\nRecovery crypto units can also be used as backup crypto units that save a copy of the master key value used by the operational crypto units. If the master key is lost or destroyed, you can [recover the master key from a recovery crypto unit](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-uko-recover-master-key-recovery-crypto-unit) using signed TKE administrative commands.\n\nIf smart cards are used to load the master key, the recovery crypto units are not applicable and can be ignored. The backup of the master key relies on the backup of the smart cards in that case.\n* Failover crypto unit\n\nFailover crypto units back up the operational crypto units and keystores in another region, and are initialized to provide quick failover in case of disaster. Failover crypto units [charge extra fees](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-faq-pricing) and this option is now available only in regions of us-south and us-east, which means if you create your instance in either of the two regions, the failover crypto units are located in the other region. For more information about using failover crypto units in a regional disaster, see [Restoring your data by using failover crypto units](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-restore-datarestore-data-failover-crypto-units).\n\n\n\n\n\n\n\n Administrators \n\nAdministrators can be added to the target crypto units for issuing commands to the crypto units. You can add up to eight administrators to one crypto unit to increase security. Each administrator owns one private [signature key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-uko-understand-conceptsuko-signature-key-concept) for identity authentication.\n\n\n\n\n\n Signature keys \n\nAn administrator must sign any commands that are issued to the crypto unit with a signature key. The signature keys that are created in Hyper Protect Crypto Services are P521 Elliptic Curve (EC) keys.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-uko-understand-concepts"}, {"document_id": "ibmcld_08459-7894-9644", "score": 16.378557, "text": "\nIf the service instance has three operational crypto units, you are prompted to enter the number of failover crypto units based on your need. Either 2 or 3 failover crypto units are supported.\n\nFor a service instance with only two operational crypto units, two failover crypto units are assigned automatically. You don't need to take any actions in this case.\n4. Click Yes to confirm the action. The failover crypto units are assigned in the target failover region.\n\nFailover crypto units are now available in us-south and us-east. The two regions are the target failover regions of each other. For example, if your instance is located in us-south, the failover region for your instance is us-east.\n\n\n\n4. Initialize failover crypto units by using the same master key for the operational crypto units initialization and the same initialization approach:\n\n\n\n* [Initializing service instances with smart cards and the Management Utilities](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-initialize-hsm-management-utilities)\n* [Initializing service instances by using key part files](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-initialize-hsm)\n\n\n\nYou need to initialize failover crypto units before you use them for a regional disaster recovery. It is suggested you initialize the failover crypto units right after you enable them for your service instance.\n\n\n\n\n\n\n\n What's next \n\nIf a regional disaster occurs, you can use failover crypto units for automatic data restoration. For more information, see [Cross-region disaster recovery](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-ha-drcross-region-disaster-recovery) and [Restoring your data from another region](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-restore-data).", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-enable-add-failover"}]}
{"task_id": "f3a917e029970190be5ee508ba770d7f<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13139-19107-19978", "score": 21.784166, "text": "\nDelete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https://cloud.ibm.com/docs/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https://cloud.ibm.com/docs/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)\n* [Kubernetes Service](https://cloud.ibm.com/docs/containers)\n* [Building containers from images](https://cloud.ibm.com/docs/containers?topic=containers-images)\n* [Best practice to secure traffic and internet application via CIS](https://cloud.ibm.com/docs/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitybest-practice-configure-security-level-selectively)\n* [Improving App Availability with Multizone Clusters](https://www.ibm.com/cloud/blog/announcements/improving-app-availability-multizone-clusters)", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-multi-region-k8s-cis"}, {"document_id": "ibmcld_13139-17831-19468", "score": 21.783596, "text": "\nIn addition, you can now control what content gets cached by CIS and how long it stays cached. Go to Performance > Caching to define the global caching level and the browser expiration. You can customize the global security and caching rules with Page Rules. Page Rules enable fine-grained configuration using specific domain paths. As example with Page Rules, you could decide to cache all contents under /assets for 3 days:\n\nZoom\n\n![Page Rules](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution32-multi-region-k8s-cis/cis-pagerules.png)\n\nPage Rules\n\n\n\n\n\n\n\n Step 5: Remove resources \n\n\n\n Remove Kubernetes Cluster resources \n\n\n\n1. Remove the Ingress, you can do so by running the following command:\n\nkubectl delete -f glb-ingress.yaml\n2. Remove the service, you can do so by running the following command:\n\nkubectl delete service hello-world-service\n3. Remove the deployment, you can do so by running the following command:\n\nkubectl delete deployment hello-world-deployment\n4. Delete the clusters if you created them specifically for this tutorial.\n\n\n\n\n\n\n\n Remove CIS resources \n\n\n\n1. Remove the GLB.\n2. Remove the origin pools.\n3. Remove the health checks.\n4. Update the DNS for your custom domain.\n5. Delete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https://cloud.ibm.com/docs/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https://cloud.ibm.com/docs/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-multi-region-k8s-cis"}, {"document_id": "ibmcld_04145-1739-3868", "score": 21.641191, "text": "\nThe functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https://cloud.ibm.com/docs/cis?topic=cis-transitioning-next-plan).\n\n\n\n\n\n How do I delete my CIS instance? \n\nTo delete a CIS instance, you must first delete all global load balancers, pools, and health checks. Then delete the associated domain (zone). Go to the Overview page and click the trash can icon next to the domain name located in the Service Details section to start the deletion process.\n\nIf you are moving your domain to a different provider, be sure to migrate your DNS records and other configuration information to the new provider before activating the domain there. Activating the domain before migrating from CIS can cause your domain to changed to a [Moved state](https://cloud.ibm.com/docs/cis?topic=cis-domain-moved-status).\n\n\n\n\n\n I added a user to my account and gave that user permission to manage Internet Services instance(s). Why is that user facing authentication issues? \n\nIt's possible that you did not assign \"service access roles\" to the user. Note that there are two separate sets of roles:\n\n\n\n* Platform access\n* Service access\n\n\n\nYou need platform access roles to create and manage service instances, while service access roles perform service-specific operations on service instances. In the console, these settings can be updated by selecting Manage > Security > Identity and Access.\n\n\n\n\n\n Why is my domain in Pending state? How do I activate it? \n\nWhen you add a domain to CIS, we give you a couple of name servers to configure at your registrar (or at your DNS provider, if you are adding a subdomain). The domain or subdomain remains in pending state until you configure the name servers correctly. Make sure you add both the name servers to your registrar or DNS provider. We periodically scan the public DNS system to check whether the name servers have been configured as instructed. As soon as we are able to verify the name server change (which can take up to 24 hours), we activate your domain.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-faq"}, {"document_id": "ibmcld_04149-3050-4970", "score": 21.377403, "text": "\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https://whois.icann.org/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-getting-started"}, {"document_id": "ibmcld_12492-87895-89178", "score": 20.266493, "text": "\n\"cis_crn\": \"crn:v1:bluemix:public:internet-svcs:global:a/a5ebf2570dcaedf18d7ed78e216c263a:0f4c764e-dc3d-44d1-bd60-a2f7cd91e0c0::\"\n},\n\"name\": \"my-cis-instance\",\n\"type\": \"cis\"\n},\n\"wrap_info\": null,\n\"warnings\": null,\n\"auth\": null\n}\n\n\n\n\n\n\n\n Delete a configuration \n\nRemoves a configuration for a secrets engine that serves as the backend for a specific type of secret. You can delete configurations for the following secret types: public_cert, private_cert\n\n\n\n Example requests \n\nDelete a public certificate authority configuration.\n\ncurl -X DELETE 'https://https://{instance_id}.{region}.secrets-manager.appdomain.cloud/v1/ibmcloud/public_cert/config/certificate_authorities/my-lets-encrypt' -H 'X-Vault-Token: {Vault-Token}'\n\nDelete the DNS provider configuration.\n\ncurl -X DELETE 'https://https://{instance_id}.{region}.secrets-manager.appdomain.cloud/v1/ibmcloud/public_cert/config/dns_providers/my-cis-instance' -H 'X-Vault-Token: {Vault-Token}'\n\nDelete a private certificate authority configuration.\n\ncurl -X DELETE 'https://https://{instance_id}.{region}.secrets-manager.appdomain.cloud/v1/ibmcloud/private_cert/config/root_certificate_authorities/my-root-ca' -H 'X-Vault-Token: {Vault-Token}'\n\n\n\n\n\n Example response \n\nA successful request returns an HTTP 204 No Content response.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-vault-api"}, {"document_id": "ibmcld_04186-18298-19703", "score": 20.019478, "text": "\n[Page Rules](https://cloud.ibm.com/docs-content/v1/content/cb1eb27836421578019401fa7556779109430b29/cis/includes/solution-tutorials/includes/solution-tutorials/images/solution32-multi-region-k8s-cis/cis-pagerules.png)\n\nPage Rules\n\n\n\n\n\n\n\n Step 5: Remove resources \n\n\n\n Remove Kubernetes Cluster resources \n\n\n\n1. Remove the Ingress, you can do so by running the following command:\n\nkubectl delete -f glb-ingress.yaml\n2. Remove the service, you can do so by running the following command:\n\nkubectl delete service hello-world-service\n3. Remove the deployment, you can do so by running the following command:\n\nkubectl delete deployment hello-world-deployment\n4. Delete the clusters if you created them specifically for this tutorial.\n\n\n\n\n\n\n\n Remove CIS resources \n\n\n\n1. Remove the GLB.\n2. Remove the origin pools.\n3. Remove the health checks.\n4. Update the DNS for your custom domain.\n5. Delete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https://cloud.ibm.com/docs/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https://cloud.ibm.com/docs/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)\n* [Kubernetes Service](https://cloud.ibm.com/docs/containers)\n* [Building containers from images](https://cloud.ibm.com/docs/containers?topic=containers-images)", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-multi-region-k8s-cis"}, {"document_id": "ibmcld_04132-3821-5296", "score": 19.764454, "text": "\nDeleting a webhook using the CLI \n\nTo delete a webhook using the CLI, run the following command.\n\nibmcloud cis alert-webhook-delete WEBHOOK_ID [-i, --instance INSTANCE] [-f, --force]\n\nWhere:\n\n\n\n* WEBHOOK_ID is the ID of webhook.\n* i, --instance value is the instance name or ID. If not set, the context instance specified by 'cis instance-set INSTANCE' is used.\n* -f, --force attempts to delete webhook without prompting for confirmation.\n\n\n\n\n\n\n\n\n\n Configuring webhooks using the API \n\nTo call these methods, you must be assigned one or more IAM access roles.\n\n\n\n* internet-svcs.zones.read\n* internet-svcs.zones.update\n\n\n\nYou can check your access by going to Users > name > Access policies.\n\n\n\n Creating a webhook using the API \n\nCreating a webhook alert is a two step process. First, create the webhook, then use the ID in the response that you receive to create the alert.\n\nTo create a webhook by using the API, follow these steps:\n\n\n\n1. Set up your API environment with the correct variables.\n2. Store your the following variable to be used in the API command:\n\n\n\n* crn: the full url-encoded CRN of the service instance.\n* name: the name of the webhook.\n* url: the URL of the webhook.\n* secret: the optional secret or API key needed to use the webhook.\n\n\n\n3. When all variables are initiated, create the webhook:\n\n\n\ncurl -X POST https://api.cis.cloud.ibm.com/v1/:crn/alerting/destinations/webhooks\n-H 'content-type: application/json'\n-H 'x-auth-user-token: Bearer xxxxxx'", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-configuring-webhooks"}, {"document_id": "ibmcld_04183-0-2205", "score": 19.673698, "text": "\n\n\n\n\n\n\n  Securing your data in CIS \n\nTo ensure that you can securely manage your data when you use IBM Cloud\u00ae Internet Services, it is important to know exactly what data is stored and encrypted and how to delete any stored personal data.\n\n\n\n  How your data is stored and encrypted in CIS \n\nCIS interacts with Cloudflare services using a channel that is fully encrypted end-to-end using Transport Layer Security (TLS) 1.2. CIS does not store any customer data. Configuration data about your specific CIS configuration is encrypted in transit and at rest. CIS configuration data is deleted on your request through the UI, CLI, or API.\n\n\n\n\n\n  Protecting your sensitive data in CIS \n\nAll data related to CIS configuration is not considered sensitive data. The configuration data is encrypted at rest. No customer-managed keys are managed by the CIS offering. Therefore, neither Key Protect nor Hyper Protect Crypto Services are used.\n\n\n\n  Working with customer-managed keys for CIS \n\nNo customer-managed keys are managed by the CIS offering.\n\n\n\n\n\n\n\n  Deleting your data in CIS \n\nThe CIS configuration data is deleted on request through the UI, CLI or API.\n\n\n\n  Deleting CIS instances \n\nThe CIS data retention policy describes how long your data is stored after you delete the service. The data retention policy is included in the CIS service description, which you can find in [IBM Cloud Terms](https://cloud.ibm.com/docs/overview?topic=overview-terms). When a CIS instance is deleted by the UI, CLI, or API, the instance data is retained for seven days from deletion.\n\nBefore deleting an instance, all the domains in the instance must be removed.\n\nDeleting the CIS instance removes all data.\n\n\n\n\n\n  Restoring deleted data for CIS \n\nCIS can currently restore the deleted instance. After you delete an instance of CIS, you can restore the deleted service instance within the data retention period of seven days. After the seven-day period expires, the service instance is permanently deleted.\n\nTo view which service instances are available for restoration, use the ibmcloud resource reclamations command. To restore a deleted service instance, use the ibmcloud resource reclamation-restore command.\n\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-mng-data"}, {"document_id": "ibmcld_04132-1248-2869", "score": 19.634981, "text": "\n[overflow icon](https://cloud.ibm.com/docs-content/v1/content/cb1eb27836421578019401fa7556779109430b29/cis//images/horizontal-overflow-icon.png) of the webhook you want to delete, and select Delete. Select Delete in the confirmation box to confirm, or Cancel to close the confirmation box without completing the delete operation.\n\n\n\n\n\n\n\n Configuring webhooks using the CLI \n\n\n\n Creating a webhook using the CLI \n\nTo create a webhook using the CLI, run the following command.\n\nibmcloud cis alert-webhook-create --name NAME --url URL [--secret SECRET] [-i, --instance INSTANCE] [--output FORMAT]\n\nWhere:\n\n\n\n* --name valueis the name of the webhook.\n* --url value is the POST endpoint to call when dispatching an alert.\n* --secret value is the secret that will be passed in the webhook auth header when dispatching a webhook alert.\n* -i, --instance value is the instance name or ID. If not set, the context instance specified by 'cis instance-set INSTANCE' is used.\n* --output value specifies output format; only JSON is supported.\n\n\n\n\n\n\n\n Listing all webhooks using the CLI \n\nTo list a webhook using the CLI, run the following command.\n\nibmcloud cis alert-webhooks [-i, --instance INSTANCE] [--output FORMAT]\n\nWhere:\n\n\n\n* -i, --instance value is the instance name or ID. If not set, the context instance specified by 'cis instance-set INSTANCE' is used.\n* --output value specifies output format; only JSON is supported.\n\n\n\n\n\n\n\n Getting details for a webhook using the CLI \n\nTo get a webhook using the CLI, run the following command.\n\nibmcloud cis alert-webhook WEBHOOK_ID [-i, --instance INSTANCE] [--output FORMAT]\n\nWhere:", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-configuring-webhooks"}, {"document_id": "ibmcld_16727-756469-758485", "score": 19.407627, "text": "\n* What happened to Enterprise Package plans?\n\nStarting on 21 June 2023, you can no longer configure the Enterprise package plan. The functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https://cloud.ibm.com/docs/cis?topic=cis-transitioning-next-plan).\n* How do I delete my CIS instance?\n\nTo delete a CIS instance, you must first delete all global load balancers, pools, and health checks. Then delete the associated domain (zone). Go to the Overview page and click the trash can icon next to the domain name located in the Service Details section to start the deletion process.\n\nIf you are moving your domain to a different provider, be sure to migrate your DNS records and other configuration information to the new provider before activating the domain there. Activating the domain before migrating from CIS can cause your domain to changed to a [Moved state](https://cloud.ibm.com/docs/cis?topic=cis-domain-moved-status).\n* I added a user to my account and gave that user permission to manage Internet Services instance(s). Why is that user facing authentication issues?\n\nIt's possible that you did not assign \"service access roles\" to the user. Note that there are two separate sets of roles:\n\n\n\n* Platform access\n* Service access\n\n\n\nYou need platform access roles to create and manage service instances, while service access roles perform service-specific operations on service instances. In the console, these settings can be updated by selecting Manage > Security > Identity and Access.\n* Why is my domain in Pending state? How do I activate it?\n\nWhen you add a domain to CIS, we give you a couple of name servers to configure at your registrar (or at your DNS provider, if you are adding a subdomain). The domain or subdomain remains in pending state until you configure the name servers correctly. Make sure you add both the name servers to your registrar or DNS provider.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}]}
{"task_id": "f3a917e029970190be5ee508ba770d7f<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04148-0-1895", "score": 22.644318, "text": "\n\n\n\n\n\n\n  Getting CIS running with a new subdomain \n\nFollow these steps to practice using CIS with a subdomain or CNAME. This example uses the GoDaddy domain registrar. Your case might be different, depending on which registrar you use.\n\n\n\n1.  Deploy a CIS instance by using the IBM Cloud console or API.\n\nIt is recommended that you mirror the name of your CIS instance with the domain or subdomain.\n2.  Click Let\u2019s get started.\n3.  Enter the subdomain in the Domain name field and click Connect and continue.\n4.  For new subdomains click Next Step, for existing subdomains click Import records.\n5.  Make note the New NS records for entry into the GoDaddy DNS Management system.\n6.  Log in to GoDaddy domain Registrar.\n7.  Navigate to the DNS Management page for the candidate CIS domain. IBM Cloud\u00ae must be updated through the API.\n8.  Click ADD to create an NS Host record for each name server entry provided from CIS.\n9.  Set up a DNS record with the supplied CIS NS Records\n\n\n\n*  Type Nameserver\n*  Host subdomain (the name of the subdomain, for example, subdomain.example.com)\n*  Points to ns004.name.cloud.ibm.com\n*  TTL \u00bd hour\n\n\n\n10. The DNS Management page now reflects the two new NS records for the subdomain.\n11. Go back to the IBM Cloud Internet Services instance.\n12. After the NS Records are DNS propagated, it is reflected in the DNS tools, and you are ready to proceed.\n13. With completed NS propagation, click Check name servers.\n14. CIS starts checking NS configuration for the subdomain and might be in a Pending State.\n\nAny typographical errors in can produce a \"silent\" failure. If your subdomain is in the pending state for more than 30 minutes, you might have an error.\n\n\n\nUpon successful subdomain name server and NS record confirmation, the CIS instance reports Active. Customers are now ready to start configuring the service and routing traffic to their services.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-get-started-new-subdomain"}, {"document_id": "ibmcld_04149-3050-4970", "score": 20.922018, "text": "\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https://whois.icann.org/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-getting-started"}, {"document_id": "ibmcld_04334-33215-34565", "score": 20.254436, "text": "\nValid values are any, all.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList all dns records in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records-import \n\nImport your BIND config.\n\nibmcloud cis dns-records-import DNS_DOMAIN_ID --file FILE [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: BIND config to import. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nImport BIND config in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records-import 31984fea73a15b45779fa0df4ef62f9b --file bind_config_file.txt -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records-export \n\nExport BIND config.\n\nibmcloud cis dns-records-export DNS_DOMAIN_ID [--file FILE] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: The BIND config file that saves exported DNS records.\n\n-i, --instance\n: Instance name or ID.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_04195-6086-8151", "score": 20.129421, "text": "\nBecause CIS doesn't support email traffic by default, you must set the PTR record to the location of your email server. Contact your email provider for assistance.\n\n\n\n\n\n\n\n Updating DNS records \n\nIn each record row, you can click the Edit record option from the menu, which opens a dialog box that you can use to update the record.\n\nAfter you are finished making your changes, select Update record to save them, or Cancel to abort the changes.\n\n\n\n\n\n Deleting DNS records \n\nIn each record row, you can select the Delete record option from the menu, which opens a dialog box to confirm the delete process.\n\nYou can select the Delete button to confirm your delete action. Select Cancel if you don't want to delete.\n\n\n\n\n\n Importing and exporting DNS records \n\nDNS records can be imported into and exported from CIS. All files are imported and exported as .txt files in BIND format. Learn more about [BIND format](https://en.wikipedia.org/wiki/Zone_file). Click the overflow menu and select to import or export records.\n\nImport records - By default, a total of 3500 DNS records are allowed (imported and created on CIS). You can import multiple files, one at a time, as long as the total number of records is under the max limit. After importing, you are shown a summary with the number of records successfully added and the number that failed, along with the reason why each record failed.\n\nExport records - Use Export records to create a backup of your zone file, or export it to use with another DNS provider. When this menu option is clicked, the records are downloaded to the location specified by your browser settings (typically the Downloads folder). To select another folder location, change your browser's settings to prompt you for a location with each download.\n\n\n\n\n\n Configuring and managing your secure DNS \n\nDNSSec is a technology to digitally sign DNS data so you can be assured it is valid. To eliminate vulnerability from the internet, DNSSec must be deployed at each step in the lookup, from root zone to final domain name (for example, www.icann.org).", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-set-up-your-dns-for-cis"}, {"document_id": "ibmcld_04334-34286-35758", "score": 20.084106, "text": "\nExport BIND config.\n\nibmcloud cis dns-records-export DNS_DOMAIN_ID [--file FILE] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: The BIND config file that saves exported DNS records.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n\n\n\n\n Examples \n\nExport BIND config for domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records-export 31984fea73a15b45779fa0df4ef62f9b --file bind_config_file.txt -i \"cis-demo\"\n\n\n\n\n\n\n\n\n\n Domain \n\nManipulate domains by using the following domain commands.\n\n\n\n ibmcloud cis domain-add \n\nAdd a domain.\n\nibmcloud cis domain-add DNS_DOMAIN_NAME [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\ntype value\n: Specify the domain type setup. Valid values: full, partial (default full).\n\n\n\n* full: A full zone implies that DNS is hosted.\n* partial: A partial zone implies that CNAME setup domain.\n\n\n\njump-start\n: Automatically attempt to fetch existing DNS records.\n\nDNS_DOMAIN_NAME\n: The FQDN of DNS domain. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nAdd a new domain test.com in instance cis-demo.\n\nibmcloud cis domain-add \"test.com\" -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis domain-resume \n\nResume the given domain.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_13877-23871-25303", "score": 19.93228, "text": "\nCreate a DNS entry in the CIS instance using YOUR-CLUSTER Ingress subdomain as the alias.\n\n\n\n1. Open the CIS service instance, you can find it in the [Resource List](https://cloud.ibm.com/resources).\n2. Click the Reliability tab on the left.\n3. Click the DNS tab on the top.\n4. Scroll down to the DNS Records section and click Add to create a new record:\n\n\n\n1. Type: CNAME\n2. Name: secure-file-storage\n3. Alias: The Ingress subdomain of YOUR-CLUSTER. Something like YOUR-CLUSTER-NAME-e012345678901234f61a87aaaaaaaa3a-0000.us-south.containers.appdomain.cloud. In the shell:\n\necho $INGRESS_SUBDOMAIN\n4. Click Add Record\n\n\n\n\n\nConnect Secrets Manager instance to Let's Encrypt.\n\n\n\n1. A Let's Encrypt ACME account and associated .pem file is required. Use an existing one or [create one](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-prepare-order-certificates&interface=uicreate-acme-account):\n\n\n\n1. Install the acme-account-creation-tool. [Creating a Let's Encrypt ACME account](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-prepare-order-certificates&interface=uicreate-acme-account) contains instructions and a link to the creation tool.\n2. Run acme-account-creation-tool to create an accout specifically for this secure-file-storage example. Below is an example session for a Mac.:\n\n$ ./acme-account-creation-tool-darwin-amd64 -e YOUREMAIL -o secure-file-storage.example.com -d letsencrypt-prod", "title": "", "source": "https://cloud.ibm.com/docs/tutorials?topic=solution-tutorials-cloud-e2e-security"}, {"document_id": "ibmcld_04149-1398-3431", "score": 19.35711, "text": "\nSet up your DNS records (optional).\n4. Configure your DNS information with the name servers provided.\n5. Continue getting started with CIS by following a tutorial, or by setting up other features.\n\n\n\n\n\n Step 1: Open the IBM CIS application \n\nOpen the [IBM Cloud catalog](https://cloud.ibm.com/catalog). Then, select the Networking category in the navigation pane. Click the Internet Services tile to open the IBM Cloud Internet Services application.\n\n\n\n The Overview screen \n\nAfter the CIS application starts up, you'll see the CIS Overview screen, and you'll find the tabs for Security, Reliability, and Performance.\n\n\n\n\n\n Which plan do I choose? \n\nThere are several plans to choose from:\n\n\n\n* Enterprise Usage\n* Enterprise Package\n* Enterprise GLB\n* Enterprise Security\n* Standard (Deprecated as of 30 April 2023)\n* Standard Next (Replaces deprecated Standard plan)\n* No-cost Trial\n\n\n\nThe No-cost Trial expires after 30 days, at which point you can upgrade to a plan that best suits your needs. A single Standard or Standard Next instance can manage one domain. You can create as many Standard or Standard Next service instances as you want within a single account, each managing a single domain. The Enterprise Plans allow you to manage multiple domains in a single service instance.\n\nBefore creating a Standard plan, remember that this plan is deprecated and will eventually reach end-of-support.\n\nSelect Create on the Overview screen to begin provisioning your account.\n\nThe No-cost Trial is limited to one instance per account.\n\n\n\n\n\n Begin provisioning \n\nYou'll see the first screen of the CIS application, where you select Add Domain to begin.\n\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-getting-started"}, {"document_id": "ibmcld_12457-6188-7983", "score": 19.33769, "text": "\nYou need the Cloud Resource Name (CRN) of the CIS instance that contains your domains, and an API key with the correct level of access to your instance. The API key must grant Secrets Manager the ability to view the CIS instance, access its domains, and manage TXT records.\n\nIf the CIS instance is located in an account that allows access to only specific IP addresses, you must also update the IP address restrictions in the account to allow incoming requests from Secrets Manager. For more information, see [Managing access with context-based restrictions](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-access-control-cbr).\n\nTo assign access, you can use the Access (IAM) section of the console.\n\n\n\n1. Log in to the account in which your CIS instance is located.\n2. Click Manage > Access (IAM), and select Service IDs.\n3. [Create a service ID API key](https://cloud.ibm.com/docs/account?topic=account-serviceidapikeys) or select an existing one.\n4. Assign the required access to view the CIS instance, access its domains, and manage TXT records.\n\n\n\n1. In the row of the service ID, click the Actions icon ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/991f60ddbe3ab0a9aa69481a07a0a73b359fa329/icons/actions-icon-vertical.svg)> Assign access.\n2. Click the Access policy tile.\n3. From the list of services, select Internet Services and click Next.\n4. Select Resources based on selected attributes.\n5. In the Service instance field, select your CIS instance.\n6. In the Roles and actions section, select the Manager role. If you want to grant the service ID the ability to access the CIS instance from the Resource list in the IBM Cloud console, you can also assign the Viewer platform role.\n7. Click Review > Add > Assign to complete the access assignment.\n\n\n\n5.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-prepare-order-certificates&interface=ui"}, {"document_id": "ibmcld_13877-22396-24231", "score": 19.326662, "text": "\n* [Let's Encrypt](https://letsencrypt.org/) to generate the TLS certificates.\n* IBM Cloud Secrets Manager to integrate with Let's Encrypt to generate the TLS certificate for secure-file-storage.example.com and securely store.\n* Kubernetes [External Secrets Operator](https://external-secrets.io/v0.7.0/) to pull the secret TLS certificate directly from Secrets Manager\n\n\n\n\n\n Provision a CIS and Secrets Manager instance \n\n\n\n* A [IBM Cloud Internet Services](https://cloud.ibm.com/catalog/services/internet-services) instance is required. Use an existing instance or create one from this [catalog entry](https://cloud.ibm.com/catalog/services/internet-services). A number of pricing plans are available, including a free trial. The provisioning process of a new CIS will explain how to configure your existing DNS registrar (perhaps not in IBM Cloud) to use the CIS-provided domain name servers. This tutorial uses example.com for the DNS name. Substitute your domain for example.com in all steps. Also export it in the shell:\n\nexport MYDOMAIN=example.com\n* A Secrets Manager instance is required. Use an existing instance or create a new one described in [Creating a Secrets Manager service instance](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-create-instance&interface=ui). If creating a new instance, name it secure-file-storage-sm. You can enhance the security of your secrets at rest by integrating with the Key Protect instance created earlier.\n\n\n\nCreate a DNS entry in the CIS instance using YOUR-CLUSTER Ingress subdomain as the alias.\n\n\n\n1. Open the CIS service instance, you can find it in the [Resource List](https://cloud.ibm.com/resources).\n2. Click the Reliability tab on the left.\n3. Click the DNS tab on the top.\n4. Scroll down to the DNS Records section and click Add to create a new record:\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/tutorials?topic=solution-tutorials-cloud-e2e-security"}, {"document_id": "ibmcld_04171-7-2143", "score": 19.084131, "text": "\nKnown limitations \n\nThe following information describes some limitations when working with IBM Cloud\u00ae Internet Services (CIS), as well as some suggested courses of action to improve your experience.\n\n\n\n* It is recommended that you use Chrome.\n* The free trial plan is limited to one instance per account. After you create a resource instance and add a domain to it, you are not allowed to add new resource instances for CIS. This restriction is enforced even if you delete a trial domain and then attempt to add a domain again to the same resource instance. You'll encounter an error if you attempt to do so.\n* For this service, we support subdomain delegation only using NS records from another provider. CNAME delegation is not supported.\n* A, AAAA, and CNAME wildcard records (\"*\") cannot be proxied.\n* When you delete a dedicated certificate, it might reappear in the list for a short time before the deletion is complete.\n* To modify your custom dedicated certificate\u2019s hostnames after ordering, you must order a new certificate and then delete the old one.\n* IP rules created with two letter country codes can only be made with the Challenge action. If you want to block visitors from a country, upgrade to the Enterprise plan or place rules on your server to fully block.\n\n\n\n\n\n Global load balancer \n\n\n\n* Cloud Internet Services allows you to use the character _ in load balancer hostnames. However, Kubernetes clusters cannot use _.\n* The Standard plan permits a maximum of 5 load balancers, pools, and health checks. Each pool can have a total of 6 origins, but only 6 unique origins are permitted throughout each CIS instance.\n* Health check events for deleted pools and origins cannot be filtered, but they still appear in the table.\n* If you filter Health check events by Pool Health, Degraded pools are included because they technically are healthy, but might contain 1 or more critical origins.\n* When adding the request header name for a health check, use Host, capitalized. Using a lower-case host for a health check fails.\n\n\n\n\n\n\n\n DNS \n\n\n\n* Exporting DNS records includes Cloudflare CNAME records that should be hidden.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-known-limitations"}]}
{"task_id": "f3a917e029970190be5ee508ba770d7f<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07449-1067-2038", "score": 19.448648, "text": "\n[Sample domains expanded image](https://cloud.ibm.com/docs-content/v1/content/86dadb3996e7fa2b119c2c09bda56dbc01297416/dns/images/custom-name-server-expanded.png)\n\nFigure 2. Domains page with the domain expanded\n7. Select the Add/Edit NS option in the Custom Name Servers section of the page. A dialog appears.\n8. To complete the appropriate action based on the task, refer to one of the following bullets:\n\n\n\n* To add a custom name server, enter the hostname for the name server in the empty field.\n* To delete a custom name server, delete the information from the field for the appropriate name server.\n* To edit a custom name server, edit the details in the corresponding field for the appropriate name server.\n\n\n\n9. Click the Associate button to save the changes, or click Cancel to cancel the action.\n\n\n\n\n\n Next steps \n\nAfter you update the name server details, they appear under the Custom Name Servers section of the domain. You can update the details at any time.", "title": "", "source": "https://cloud.ibm.com/docs/dns?topic=dns-add-edit-or-delete-custom-name-servers-for-a-domain"}, {"document_id": "ibmcld_05980-10127-11813", "score": 18.954689, "text": "\nTo register your custom domain, work with your Domain Name Service (DNS) provider or [IBM Cloud DNS](https://cloud.ibm.com/docs/dns?topic=dns-getting-started). If the apps that you want Ingress to expose are in different namespaces in one cluster, register the custom domain as a wildcard domain, such as .custom_domain.net. Note that domains are limited to 130 characters or fewer in Kubernetes version 1.20 or later.\n2. Define an alias for your custom domain by specifying the IBM-provided subdomain as a Canonical Name record (CNAME). To find the IBM-provided Ingress domain, run ibmcloud ks cluster get --cluster <cluster_name> and look for the Ingress subdomain field.\n\nSpecifying the IBM-provided subdomain as a CNAME is required for automatic health checks to remove any failing IPs from the DNS response, and to ensure that your custom domain updates when you add or remove ALBs.\n\n\n\n\n\n\n\n Creating custom domains for private ALBs \n\nFollow the steps to create a custom domain for private ALBs. Note that custom domains are required to use Ingress with private ALBs.\n\nIf you have a classic cluster with only a private VLAN, you must first configure your own [DNS service that is available on your private network](https://kubernetes.io/docs/tasks/administer-cluster/dns-custom-nameservers/).\n\n\n\n1. Create a custom domain through your DNS service provider. Note that Ingress URLs must be 130 characters or fewer.\n2. Map your custom domain to the private ALBs by adding their IP addresses as A records (classic clusters) or their VPC hostname as a CNAME (VPC clusters). To find the ALB IP addresses (classic) or hostname (VPC), run ibmcloud ks ingress alb ls -c <cluster_name_or_ID>.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-managed-ingress-setup"}, {"document_id": "ibmcld_07449-7-1566", "score": 18.654434, "text": "\nManaging custom name servers for a domain \n\nDomains running on the IBM Cloud\u00ae network can point to a maximum of five (5) custom name servers. Custom name servers can be added, deleted, or changed at any time. Follow these steps to add, edit, or delete custom name servers for a domain.\n\n\n\n1. From your browser, open the [IBM Cloud\u00ae console](https://cloud.ibm.com/) and log in to your account.\n2. Select the Menu icon ![Menu icon](https://cloud.ibm.com/docs-content/v1/content/icons/icon_hamburger.svg), then click Classic Infrastructure.\n3. From the Classic Infrastructure menu, select Services > Domain Registration to open the Domains page.\n4. Select the Domain Name to expand the domain into its snapshot view.\n5. Select Unlocked from the Lock Domain.\n6. Click the > character to expand the domain and configure name servers.\n\nZoom\n\n![Sample domains collapsed image](https://cloud.ibm.com/docs-content/v1/content/86dadb3996e7fa2b119c2c09bda56dbc01297416/dns/images/custom-name-server-collapsed.png)\n\nFigure 1. Domains page with the domain collapsed\n\nZoom\n\n![Sample domains expanded image](https://cloud.ibm.com/docs-content/v1/content/86dadb3996e7fa2b119c2c09bda56dbc01297416/dns/images/custom-name-server-expanded.png)\n\nFigure 2. Domains page with the domain expanded\n7. Select the Add/Edit NS option in the Custom Name Servers section of the page. A dialog appears.\n8. To complete the appropriate action based on the task, refer to one of the following bullets:\n\n\n\n* To add a custom name server, enter the hostname for the name server in the empty field.", "title": "", "source": "https://cloud.ibm.com/docs/dns?topic=dns-add-edit-or-delete-custom-name-servers-for-a-domain"}, {"document_id": "ibmcld_05353-2587-4725", "score": 18.450438, "text": "\n* Code Engine supports custom domain mappings for domains that are protected with a SSL/TLS certificate, which is signed by a public, trusted certificate authority (CA).\n* You can define custom domain mappings that point to public domain names.\n* If your domain name can be resolved only by a nonpublic domain name system (DNS), you must provide a certificate that lists the domain name and is signed by a public, trusted CA.\n* You must provide the entire certificate chain, starting with the certificate that corresponds to the custom domain, followed by all intermediate certificates up to the root certificate.\n* You cannot use self-signed certificates.\n* You cannot use certificates that are signed by an untrusted or a nonpublic enterprise CA.\n\n\n\n\n\n\n\n Preparing to add a custom domain mapping \n\nWhen you want to use a custom domain mapping with Code Engine application, you must take the following actions outside of Code Engine before you can create the custom domain mapping.\n\n\n\n1. From a domain registrar, obtain your custom domain; for example, www.example.com.\n2. From your certificate authority (CA), you must obtain a signed SSL/TLS certificate for your custom domain. This certificate is a type of digital certificate that is used to establish communication privacy between a server and a client. Certificates contain information that is used to create trusted and secure connections between endpoints. You must also obtain a matching private key for the TLS certificate. For security reasons, Code Engine supports only custom domain mappings that are configured with a TLS/SSL certificate that is signed by a public, trusted CA.\n\n\n\n\n\n How can I obtain a certificate for my custom domain? \n\nIn an enterprise environment, work with your corporate domain administrator to obtain the necessary certificates. However, if the custom domain is within your control and you want quickly create a certificate that is not self-certified, then you can optionally use the [Let's Encrypt](https://letsencrypt.org/) service and [Certbot](https://certbot.eff.org/) to obtain a certificate.\n\n\n\n1. Install [Certbot](https://certbot.eff.org/).", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappings"}, {"document_id": "ibmcld_04625-7-1865", "score": 18.36076, "text": "\nAdding and using a custom domain \n\nIBM\u00ae Cloud Foundry is deprecated and no longer supported as of 1 June 2023. For more information, see the [deprecation details](https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-deprecationdep_details).\n\nDomains provide the URL route that is allocated to your organization in IBM Cloud\u00ae. Custom domains direct requests for your apps to a URL that you own. A custom domain can be a shared domain, a shared subdomain, or a shared domain and host. Unless a custom domain is specified, IBM Cloud uses a default shared domain in the route to your app. You can create and use a custom domain by using either the IBM Cloud console or the command-line interface.\n\nThe default shared domain is mybluemix.net, but appdomain.cloud is another domain option that you can use. For more information about migrating to appdomain.cloud, see [Updating your domain](https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-update-domain).\n\nTo use a custom domain, you must register the custom domain on a public DNS server, and then configure the custom domain in IBM Cloud. Next, you must map the custom domain to the IBM Cloud system domain on the public DNS server. After your custom domain is mapped to the system domain, requests for your custom domain are routed to your app in IBM Cloud.\n\n\n\n Adding a custom domain from the IBM Cloud console \n\nComplete these steps to add a custom domain for your org by using the console:\n\n\n\n1. Go to Manage > Account, and select Cloud Foundry orgs.\n2. Click the name of the org for which you're creating a custom domain.\n3. Click the Domains tab to view a list of available domains.\n4. Click Add a domain, enter your domain name, and select the region.\n5. Confirm your updates, and click Add.\n\n\n\n\n\n\n\n Adding the route with the custom domain to an app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-custom-domains"}, {"document_id": "ibmcld_04625-1502-3026", "score": 18.06864, "text": "\nGo to Manage > Account, and select Cloud Foundry orgs.\n2. Click the name of the org for which you're creating a custom domain.\n3. Click the Domains tab to view a list of available domains.\n4. Click Add a domain, enter your domain name, and select the region.\n5. Confirm your updates, and click Add.\n\n\n\n\n\n\n\n Adding the route with the custom domain to an app \n\n\n\n1. From the [IBM Cloud console](https://cloud.ibm.com), click the Menu icon ![Menu icon](https://cloud.ibm.com/docs-content/v1/content/icons/icon_hamburger.svg), and select Resource List.\n2. On the Resource List page, click Cloud Foundry Apps.\n3. Click the app that you want to add the route to. The app's Overview page is displayed.\n4. Select the Routes menu, and select Edit routes.\n5. Click Add route, and specify the route that you want to use for the app.\n6. Confirm your updates by clicking Save.\n\n\n\nAs an example, you can use .mycompany.com to associate the route www.mybluemix.net to your app. You can also use example.mycompany.com to associate the route www.example.bluemix.net to your app.\n\n\n\n\n\n Adding a custom domain from the IBM Cloud command-line interface \n\n\n\n1. For Cloud Foundry apps, connect to your targeted Cloud Foundry API endpoint by typing the following command:\n\nibmcloud target --cf-api <CF_ENDPOINT>\n\nCloud Foundry API endpoints:\n\n\n\n* US-SOUTH - api.us-south.cf.cloud.ibm.com\n* US-EAST - api.us-east.cf.cloud.ibm.com\n* EU-DE - api.eu-de.cf.cloud.ibm.com\n* EU-GB - api.eu-gb.cf.cloud.ibm.com\n* AU-SYD - api.au-syd.cf.cloud.ibm.com\n\n\n\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-custom-domains"}, {"document_id": "ibmcld_02151-2385-4050", "score": 17.757103, "text": "\nThen, click the name of the space.\n\nDepending on how you want to modify the user permissions, select or clear the checkbox for a specific role. The roles that you can assign at the space level are Manager, Developer, and Auditor. For more information, see [Cloud Foundry roles](https://cloud.ibm.com/docs/account?topic=account-mngcfcfroles).\n* To manage your domains, click the Actions icon ![Action icon](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/action-menu-icon.svg) for the respective org, and select Domains.\n\nAs an account owner or organization manager, you can view the system domain and add custom domains for applications that are built within an org and its spaces. If you're a space manager, this page displays read-only list of the domains that are assigned to the space.\n\nIf you add a custom domain, you must configure your DNS server to resolve your custom domain to point to the IBM Cloud system domain. In this way, when IBM Cloud receives a request for your custom domain, it's properly routed to your app. The system domain is always available to a space, and custom domains might also be allocated to a space. Apps that are created in a space might use any of the domains that are listed for that space. For more information about creating and by using custom domains, see [Managing your domains](https://cloud.ibm.com/docs/apps?topic=apps-update-domain).\n* To manage the allocated quota for an org, click the Actions icon ![Action icon](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/action-menu-icon.svg) for the respective org, and select Quotas.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-orgupdates"}, {"document_id": "ibmcld_05353-13236-15010", "score": 17.677662, "text": "\nClick Create to create the custom domain mapping.\n\n\n\nNow you have a domain mapping that is created in Code Engine. However, requests that are sent to your application are not (yet) routed to your custom domain. Next, [complete the custom domain configuration with your domain registrar](https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappingscompleting-custom-domain-registrar).\n\nSuppose that you want to create a custom domain mapping for www.example.com and shop.example.com. In this case, you must create a custom domain mapping for each unique domain or subdomain. However, you can reuse the same TLS secret for multiple custom domain mappings if the TLS secret includes certification for the domain that is specified in the custom domain mapping. The TLS secret can contain certificates that map to specific multiple domains, such as www.example.com and shop.example.com, or a wildcard domain such as .example.com. Note that you cannot use the wildcard domain more than one time within a region.\n\n\n\n\n\n Configuring custom domain mappings with the CLI \n\nTo create a custom domain mapping with the CLI, use the domainmapping create command. This command requires a fully qualified domain name (FQDN), such as www.example.com, a target application, and a TLS secret. For a complete listing of options, see the [ibmcloud ce domainmapping create](https://cloud.ibm.com/docs/codeengine?topic=codeengine-clicli-domainmapping-create) command.\n\nBefore you begin\n\n\n\n* Obtain the registered domain name.\n* Obtain the signed TLS certificate and the private key.\n* Set up your [Code Engine CLI](https://cloud.ibm.com/docs/codeengine?topic=codeengine-install-cli) environment.\n* [Create a project](https://cloud.ibm.com/docs/codeengine?topic=codeengine-manage-project).", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappings"}, {"document_id": "ibmcld_05353-1394-3012", "score": 17.360682, "text": "\n[Prepare to add a custom domain mapping](https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappingsprepare-custom-domain) (outside of Code Engine).\n3. [Configure custom domain mappings](https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappingscustom-domain) (from the Code Engine console or CLI).\n4. [Complete the custom domain configuration with your domain registrar](https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappingscompleting-custom-domain-registrar) (outside of Code Engine).\n\n\n\nAfter the custom domain mapping is created, you can [test](https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappingstest-custom-domain), [update](https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappingsupdate-custom-domain), [view](https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappingsview-domain-mapping), or [delete](https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappingsdelete-custom-domain) your custom domain mappings.\n\n\n\n Considerations before you use custom domain mappings in Code Engine \n\nBefore you implement custom domain mappings in Code Engine, be aware of the following considerations:\n\n\n\n* Code Engine supports custom domain mappings for domains that are protected with a SSL/TLS certificate, which is signed by a public, trusted certificate authority (CA).\n* You can define custom domain mappings that point to public domain names.\n* If your domain name can be resolved only by a nonpublic domain name system (DNS), you must provide a certificate that lists the domain name and is signed by a public, trusted CA.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappings"}, {"document_id": "ibmcld_10414-17181-18854", "score": 17.19115, "text": "\nCustom domain: To specify a custom domain, work with your DNS provider or [IBM Cloud\u00ae Internet Services](https://cloud.ibm.com/catalog/services/internet-services).\n\n\n\n1. Get the public IP address for the public Ingress controller service in each zone in the EXTERNAL-IP column. Note that the Ingress controller service in the first zone where you have workers nodes is always named router-default, and Ingress controller services in zones that you subsequently add to your cluster have names such as router-dal12.\n\noc get svc -n openshift-ingress\n2. Create a custom domain with your DNS provider. If you want to use the same subdomain for multiple services in your cluster, you can register a wildcard subdomain, such as .example.com.\n3. Map your custom domain to the Ingress controller's public IP address by adding the IP address as an A record.\n\n\n\n3. Set up a route that is based on the [type of TLS termination that your app requires](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_routesroute-types). If you don't have a custom domain, don't include the --hostname option. A route hostname is generated for you in the format <service_name>-<project>.<cluster_name>-<random_hash>-0000.<region>.containers.appdomain.cloud. If you registered a wildcard subdomain, specify a unique subdomain in each route that you create. For example, you might specify --hostname svc1.example.com in this route, and --hostname svc2.example.com in another route.\n\n\n\n* Simple:\n\noc expose service <app_service_name> [--hostname <subdomain>]\n* Passthrough:\n\noc create route passthrough --service <app_service_name> [--hostname <subdomain>]\n\nNeed to handle HTTP/2 connections?", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_routes"}]}
{"task_id": "f3a917e029970190be5ee508ba770d7f<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_15141-7808-9997", "score": 10.219545, "text": "\nTransport layer protocols act as liaisons between the application layer protocols and the services that are provided by the network. Client VPN for VPC supports the following protocols:\n\nUDP is recommended for optimal performance; TCP for reliability.\n\n\n\n* User Datagram Protocol (UDP)\n\nThe User Datagram Protocol (UDP) is a simple, lightweight protocol with minimum overhead. If a process wants to send a small message and doesn't care about reliability, it can use UDP. Sending a message by using UDP takes much less time than using TCP. It performs little error checking and does not add any advantages to IP services except to provide process-to-process communication instead of host-to-host communication.\n* Transmission Control Protocol (TCP)\n\nTransmission Control Protocol (TCP) is a reliable but complex transport-layer protocol. TCP adds connection-oriented features and reliability to IP services.\n\nTCP is a stream delivery service that guarantees delivery of data streams sent from one host to another without duplication or lost data. Since packet transfer is not reliable, a technique known as positive acknowledgment with retransmission is used to guarantee reliability of packet transfers. This fundamental technique requires the receiver to respond with an acknowledgment message as it receives the data.\n\nThe sender keeps a record of each packet it sends, and waits for acknowledgment before sending the next packet. The sender also keeps a timer from when the packet was sent, and retransmits a packet if the timer expires. This timer is needed in case a packet becomes lost or corrupted.\n\n\n\n\n\n\n\n Full versus split-tunnel mode \n\nWhen a VPN connection is set up, an encrypted tunnel is created over the internet to the VPN server. The VPN connection appears as a virtual network interface to the computer in addition to the existing LAN interface. You can now use both interfaces simultaneously by sending the private traffic destined to the VPC inside the VPN tunnel and the public traffic (internet traffic) over the other interface (outside the VPN tunnel). When the traffic is split between the VPN interface and other interfaces, split tunneling is said to be in use.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-client-to-site-vpn-planning"}, {"document_id": "ibmcld_04122-7-1660", "score": 9.969434, "text": "\nSetting Transport Layer Security (TLS) options \n\nThe Transport Layer Security (TLS) options let you control whether visitors can browse your website over a secure connection, and when they do, how IBM Cloud\u00ae Internet Services connects to your origin server.\n\nUse the latest version of the TLS protocol (TLS 1.3) for improved security and performance by switching from Off to On.\n\n\n\n TLS encryption modes \n\nSet the TLS mode by selecting one of the following options from the Mode list.\n\nThese options are listed in the order from the least secure (Off) to the most secure (End-to-End CA signed).\n\n\n\n* [Off](https://cloud.ibm.com/docs/cis?topic=cis-cis-tls-optionstls-encryption-modes-off) (not recommended)\n* [Client-to-Edge](https://cloud.ibm.com/docs/cis?topic=cis-cis-tls-optionstls-encryption-modes-client-to-edge) (edge to origin not encrypted, self-signed certificates are not supported)\n* [End-to-End flexible](https://cloud.ibm.com/docs/cis?topic=cis-cis-tls-optionstls-encryption-modes-end-to-end-flexible) (edge to origin certificates can be self-signed)\n* [End-to-End CA signed](https://cloud.ibm.com/docs/cis?topic=cis-cis-tls-optionstls-encryption-modes-end-to-end-ca-signed) (default and recommended)\n* [HTTPS only origin pull](https://cloud.ibm.com/docs/cis?topic=cis-cis-tls-optionstls-encryption-modes-origin-only-pull) (Enterprise only)\n\n\n\n\n\n Off \n\nNo secure connection between your visitor and CIS, and no secure connection between CIS and your web server. Visitors can only view your website over HTTP, and any visitor attempting to connect using HTTPS receives an HTTP 301 Redirect to the plain HTTP version of your website.\n\nZoom\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-cis-tls-options"}, {"document_id": "ibmcld_14602-13828-15860", "score": 9.82446, "text": "\nThe control plane high availability is discussed in another availability pattern.\n\nThe main reason that you need two layers is for physical north-south connectivity in the data centers. Each data center must have their own private and public VLANs and IP addresses for the uplinks. These IP addresses cannot move between the data centers. Therefore, it requires your attention for routing and network address translation if you use public connectivity in this topology.\n\n\n\n\n\n Multisite \u2013 multitenant \n\nMultisite \u2013 single tenant is also a use case and network deployment pattern where tenants require a solution with conflicting IP spaces and complete route table isolation. This topology provides seamless site recovery by using dynamic routing protocols, such as BGP. The vCenter Server automation doesn't deploy multisite topology automatically. However, you can customize the default single-site topology post initial vCenter Server deployment. When you have the compute capacity in the required data center, you can deploy the required extra edge nodes manually. Then, you can create a new edge cluster for the Tier-0 and Tier-1 gateways through NSX-T. This overlay topology is highly scalable and it is possible to automate, for example by using Ansible and Terraform.\n\nThis option is suitable for customers with workloads that run on a multiple data center, single tenant, and have overlapping IP addresses inside their own workloads.\n\nOverlapping IP addresses refers to overlay segments between customer environments that run on the vCenter Server instance.\n\nThe following diagram shows an example of a multisite \u2013 multitenant topology. It consists of a two layer Tier-0 design with three edge clusters. The routing table separation is done at Tier-1 and optionally also at the regional Tier-0 level. For this, consider two edge clusters in the two data centers or zones in a multizone region. And also, one edge cluster deployed across the multizone region with edge nodes in each participating zone or data center.\n\nZoom\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-v2t-example-overlays"}, {"document_id": "ibmcld_14602-12165-14327", "score": 9.106553, "text": "\nAlso, you must create a new edge cluster for your Tier-0 and Tier-1 gateways in the second IBM Cloud data center hosts.\n5. In the second IBM Cloud data center, access to private network is provided though private uplinks, which are attached to a portable subnet on a private primary VLAN on the IBM Cloud private network. If you provision your instance with public interfaces, access to public network is provided though public uplinks, which are attached to a portable subnet on a public VLAN on the IBM Cloud public network. The uplinks have specific IP addresses to this data center and they cannot move between the data centers.\n6. You must deploy two or more edge cluster transport nodes in the regional edge cluster manually. Consider at least one in each zone or data center for high availability. Then, create a new edge cluster by using these edge transport nodes, and create your regional Tier-0 in this cluster. You can select which data center (or edge node) is your preferred Tier-0 path in the regional cluster.\n7. Create an overlay transit and create uplinks in Tier-0 gateways into the transit segment. Establish dynamic routing between the Tier-0 gateways. BGP is the preferred routing protocol.\n8. Create your Tier-1 gateways in the regional edge cluster. You can select which data center (or edge node) is your preferred Tier-1 path in the regional cluster.\n9. You can attach your segments into this level of Tier-1 gateways. You can create multiple segments and advertise them through Tier-1 gateway to north bound Tier-0 gateways.\n\n\n\nThis network topology example doesn't consider the management and control plane (vCenter and NSX Managers). The control plane high availability is discussed in another availability pattern.\n\nThe main reason that you need two layers is for physical north-south connectivity in the data centers. Each data center must have their own private and public VLANs and IP addresses for the uplinks. These IP addresses cannot move between the data centers. Therefore, it requires your attention for routing and network address translation if you use public connectivity in this topology.\n\n\n\n\n\n Multisite \u2013 multitenant", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-v2t-example-overlays"}, {"document_id": "ibmcld_13874-8540-9945", "score": 9.056128, "text": "\nThe following will display help:\n\n./apply.sh\n5. You could apply all of the layers configured by executing ./apply.sh : :. The colons are shorthand for first (or config_tf) and last (vpe_dns_forwarding_rules_tf). The -p prints the layers:\n\n./apply.sh -p : :\n\nIt will look something like:\n\ndirectories: config_tf enterprise_tf transit_tf spokes_tf test_instances_tf transit_spoke_tgw_tf enterprise_link_tf firewall_tf all_firewall_tf spokes_egress_tf all_firewall_asym_tf dns_tf vpe_transit_tf vpe_spokes_tf vpe_dns_forwarding_rules_tf\n6. If you don't already have one, obtain a [Platform API key](https://cloud.ibm.com/iam/apikeys) and export the API key for use by Terraform:\n\nexport IBMCLOUD_API_KEY=YourAPIKEy\n7. In this first step apply in config_tf, enterprise_tf, transit_tf and spokes_tf:\n\n./apply.sh : spokes_tf\n\n\n\n\n\n\n\n Step 2: Create test instances \n\nVPC Virtual Server Instances, VSIs, are provisioned to test the network connectivity. A test instance will be added to each of the worker subnets (one per zone) in the enterprise, transit and each of the spokes. If the default configuration of 3 zones and 2 spokes is used then 12 instances will be provisioned.\n\nZoom\n\n![Test Instances](https://cloud.ibm.com/docs-content/v1/content/6a28e4ae2660b609a18e90e1239ed772f80373d6/transit-gateway/includes/solution-tutorials/includes/solution-tutorials/images/vpc-transit/vpc-transit-test-instances.svg)", "title": "", "source": "https://cloud.ibm.com/docs/transit-gateway?topic=transit-gateway-vpc-transit1"}, {"document_id": "ibmcld_14321-9528-11803", "score": 8.968362, "text": "\nEstablish dynamic routing between the Tier-0 Gateways and BGP is the preferred routing protocol. If you use VRF lite capability in the Tier-0 Gateway, you might use multiple transit segments depending on your design.\n8. Then, create your Tier-1 Gateways in the regional edge cluster. You can select which data center (or edge node) is your preferred Tier-1 path in the regional cluster. You can separate routing tables at this level and decide which routes as advertised to the north bound Tier-0. As in the other multitenant patterns, you can use NAT as well.\n9. You can attach your segments into this level of Tier-1 Gateways. You can create multiple segments and advertise them through Tier-1 Gateway to north bound Tier-0 Gateways.\n\n\n\nThis network topology example does not consider the management and control plane (vCenter and NSX Managers). The control plane high availability is discussed in another availability pattern.\n\nTier-0 Gateways support VRF lite, which can be used if needed to support more complex topologies for isolating routing tables also at Tier-0 level. For more information about capabilities and limitations, see the VMware documentation.\n\nThe main reason that you need two layers is for physical north-south connectivity in the data centers and each data center having their own private and public VLANs and IP addresses for the uplinks. These IP addresses cannot move between the data centers. Therefore, you must consider the routing and network address translation if you use public connectivity in this topology.\n\n\n\n\n\n Considerations for selecting an overlay network topology \n\nVMware NSX-T\u2122 provides many ways to build the network topologies, and the default network topology is useful for many use cases. You can typically start with this, and expand it as your needs grow. Once the initial deployment is done, IBM Cloud automation does use the workload overlay topology and you can change the example topology based on your needs. When changing the configuration, note that the default uplinks provide the basic routed connectivity to IBM Cloud private and public networks. If you change the IP addresses or routing, your overlay workloads might lose connectivity.\n\nIBM Cloud offers a flexible way to build the NSX-T topology to your needs.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-arch-pattern-overlays-multi-site"}, {"document_id": "ibmcld_13245-8381-9781", "score": 8.965678, "text": "\nThe following will display help:\n\n./apply.sh\n5. You could apply all of the layers configured by executing ./apply.sh : :. The colons are shorthand for first (or config_tf) and last (vpe_dns_forwarding_rules_tf). The -p prints the layers:\n\n./apply.sh -p : :\n\nIt will look something like:\n\ndirectories: config_tf enterprise_tf transit_tf spokes_tf test_instances_tf transit_spoke_tgw_tf enterprise_link_tf firewall_tf all_firewall_tf spokes_egress_tf all_firewall_asym_tf dns_tf vpe_transit_tf vpe_spokes_tf vpe_dns_forwarding_rules_tf\n6. If you don't already have one, obtain a [Platform API key](https://cloud.ibm.com/iam/apikeys) and export the API key for use by Terraform:\n\nexport IBMCLOUD_API_KEY=YourAPIKEy\n7. In this first step apply in config_tf, enterprise_tf, transit_tf and spokes_tf:\n\n./apply.sh : spokes_tf\n\n\n\n\n\n\n\n Step 2: Create test instances \n\nVPC Virtual Server Instances, VSIs, are provisioned to test the network connectivity. A test instance will be added to each of the worker subnets (one per zone) in the enterprise, transit and each of the spokes. If the default configuration of 3 zones and 2 spokes is used then 12 instances will be provisioned.\n\nZoom\n\n![Test Instances](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/vpc-transit/vpc-transit-test-instances.svg)\n\nTest Instances\n\n\n\n1. Create the test instances", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vpc-transit1"}, {"document_id": "ibmcld_13875-8974-10530", "score": 8.696965, "text": "\nThe colons are shorthand for first (or config_tf) and last (vpe_dns_forwarding_rules_tf). The -p prints the layers:\n\n./apply.sh -p : :\n7. Apply all of the layers in part one and described above.\n\n./apply.sh : spokes_egress_tf\n\n\n\nIf you were following along in part one some additional ingress routes were added to the transit ingress route table to avoid routing through the firewall-router. In this step these have been removed and the transit ingress route table has just these entries so that all incoming traffic for a zone is routed to the firewall-router in the same zone:\n\n\n\n Zone Destination Next hop \n\n Dallas 1 0.0.0.0/0 10.1.0.196 \n Dallas 2 0.0.0.0/0 10.2.0.196 \n Dallas 3 0.0.0.0/0 10.3.0.196 \n\n\n\nTo observe this:\n\n\n\n1. Open the [VPCs](https://cloud.ibm.com/vpc-ext/network/vpcs) in the IBM Cloud.\n2. Select the transit VPC and notice the Address prefixes displayed.\n3. Find the additional address prefixes for the enterprise CIDR blocks and note the associated zones.\n\n\n\n\n\n\n\n Route Spoke and Transit to the firewall-router \n\nRouting all cloud traffic originating at the spokes through the transit VPC firewall-router in the same zone as the originating instance is accomplished by these routes in the spoke's default egress routing table (shown for Dallas/us-south):\n\n\n\n Zone Destination Next hop \n\n Dallas 1 10.0.0.0/8 10.1.0.196 \n Dallas 2 10.0.0.0/8 10.2.0.196 \n Dallas 3 10.0.0.0/8 10.3.0.196 \n\n\n\nSimilarly in the transit VPC route all enterprise and cloud traffic through the firewall-router in the same zone as the originating instance.", "title": "", "source": "https://cloud.ibm.com/docs/transit-gateway?topic=transit-gateway-vpc-transit2"}, {"document_id": "ibmcld_13246-8709-10265", "score": 8.696965, "text": "\nThe colons are shorthand for first (or config_tf) and last (vpe_dns_forwarding_rules_tf). The -p prints the layers:\n\n./apply.sh -p : :\n7. Apply all of the layers in part one and described above.\n\n./apply.sh : spokes_egress_tf\n\n\n\nIf you were following along in part one some additional ingress routes were added to the transit ingress route table to avoid routing through the firewall-router. In this step these have been removed and the transit ingress route table has just these entries so that all incoming traffic for a zone is routed to the firewall-router in the same zone:\n\n\n\n Zone Destination Next hop \n\n Dallas 1 0.0.0.0/0 10.1.0.196 \n Dallas 2 0.0.0.0/0 10.2.0.196 \n Dallas 3 0.0.0.0/0 10.3.0.196 \n\n\n\nTo observe this:\n\n\n\n1. Open the [VPCs](https://cloud.ibm.com/vpc-ext/network/vpcs) in the IBM Cloud.\n2. Select the transit VPC and notice the Address prefixes displayed.\n3. Find the additional address prefixes for the enterprise CIDR blocks and note the associated zones.\n\n\n\n\n\n\n\n Route Spoke and Transit to the firewall-router \n\nRouting all cloud traffic originating at the spokes through the transit VPC firewall-router in the same zone as the originating instance is accomplished by these routes in the spoke's default egress routing table (shown for Dallas/us-south):\n\n\n\n Zone Destination Next hop \n\n Dallas 1 10.0.0.0/8 10.1.0.196 \n Dallas 2 10.0.0.0/8 10.2.0.196 \n Dallas 3 10.0.0.0/8 10.3.0.196 \n\n\n\nSimilarly in the transit VPC route all enterprise and cloud traffic through the firewall-router in the same zone as the originating instance.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vpc-transit2"}, {"document_id": "ibmcld_13245-2745-4379", "score": 8.606075, "text": "\n* [VPC egress and ingress routing](https://cloud.ibm.com/docs/vpc?topic=vpc-about-custom-routes).\n* Connectivity via [IBM Cloud\u00ae Direct Link](https://www.ibm.com/cloud/direct-link).\n* Connectivity via [IBM Cloud Transit Gateway](https://www.ibm.com/cloud/transit-gateway).\n* [Virtual Network Functions](https://cloud.ibm.com/docs/vpc?topic=vpc-about-vnf-ha).\n\n\n\nA layered architecture will introduce resources and demonstrate connectivity. Each layer will add additional connectivity and resources. A layer may introduce small problems and demonstrate solutions in the context of a larger architecture. The layers are implemented using Infrastructure as Code in the form of Terraform configuration files. It will be possible to change parameters, like number of zones, by changing a Terraform variable.\n\n\n\n Objectives \n\n\n\n* Understand the concepts behind a VPC based hub and spoke model.\n* Understand the implementation of a firewall-router and a transit VPC environment.\n* Understand VPC ingress and egress routing.\n* Identify and optionally resolve asymmetric routing issues.\n* Connect VPCs via a Transit Gateway.\n\n\n\n\n\n\n\n Before you begin \n\nThis tutorial requires:\n\n\n\n* terraform to use Infrastructure as Code to provision resources,\n* python to optionally run the pytest commands,\n* Implementing a firewall-router will require that you [enable IP spoofing checks](https://cloud.ibm.com/docs/vpc?topic=vpc-ip-spoofing-aboutip-spoofing-enable-check),\n* An SSH key to connect to the virtual servers. If you don't have an SSH key, follow [the instructions](https://cloud.ibm.com/docs/vpc?topic=vpc-ssh-keys) for creating a key for VPC.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vpc-transit1"}]}
{"task_id": "f3a917e029970190be5ee508ba770d7f<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04689-4262-6034", "score": 25.041145, "text": "\nWhen an expired or expiring certificate must be renewed, and after the new certificate is ready, delete the existing certificate and then add the new one.\n\nWhen you use a custom domain to serve the SSL certificate, use the following region endpoints to provide the URL route for your organization in IBM Cloud:\n\n\n\nTable 1. Cloud Foundry custom domain region endpoints\n\n Region Endpoint \n\n US-South custom-domain.us-south.cf.cloud.ibm.com \n US-East custom-domain.us-east.cf.cloud.ibm.com \n EU-DE custom-domain.eu-de.cf.cloud.ibm.com \n EU-GB custom-domain.eu-gb.cf.cloud.ibm.com \n AU-SYD custom-domain.au-syd.cf.cloud.ibm.com \n\n\n\nTo upload a certificate for your Cloud Foundry app, complete the following steps:\n\n\n\n1. From the [IBM Cloud console](https://cloud.ibm.com), click Manage, and select Account.\n2. Click Cloud Foundry orgs.\n3. From the Actions column, click the Actions icon ![More Actions icon](https://cloud.ibm.com/docs-content/v1/content/1e0945ee44f87283927af9404a8f2d077786db0c/icons/action-menu-icon.svg), and select Domains.\n4. Click Upload for your custom domain.\n5. Select an option, upload the file, and click Add.\n\n\n\n* Certificate: A digital document that binds a public key to the identity of the certificate owner, which enables the certificate owner to be authenticated. A certificate is issued by a certificate authority and is digitally signed by that authority. A certificate is generally issued and signed by a certificate authority. However, for testing and development purposes, you might use a self-signed certificate.\n* Private key: An algorithmic pattern that is used to encrypt messages that only the corresponding public key can decrypt. The private key is also used to decrypt messages that were encrypted by the corresponding public key.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-ssl_csr"}, {"document_id": "ibmcld_04626-7-2231", "score": 24.886389, "text": "\nCustom Domain update required for Cloud Foundry Applications \n\nIBM\u00ae Cloud Foundry is deprecated and no longer supported as of 1 June 2023. For more information, see the [deprecation details](https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-deprecationdep_details).\n\nIn addition to the [IBM Cloud Foundry deprecation announcement](https://ibm.biz/ibmcf-announce), all IBM Cloud Foundry users that have and are using a custom domain forward pointing to an IBM Cloud Foundry application will need to upload a new application SSL certificate before the deadline of 29 September 2022.\n\n\n\n Custom domain forwarding change needed for applicable IBM Cloud Foundry applications \n\nSecurity changes require IBM Cloud Foundry to store SSL certificates using a different storage technology. This means that any IBM Cloud Foundry application that is being forwarded to as a custom domain, and has an SSL certificate uploaded to properly terminate that forward, needs to upload that SSL certificate again.\n\nThe upload process will put it in the proper place and the forward will keep working like it does today.\n\nSome notes about this process\n\n\n\n* You do not need to regenerate a new SSL certificate if it is still valid, you just need to upload it again\n* Be sure to upload it into the account that hosts your IBM Cloud Foundry application - multiple people can have access to an IBM Cloud account for deployment of applications, so be sure to use the one that holds that certificate currently.\n* If you uploaded certificates for multiple specific IBM Cloud regions, you need to upload them to the same regions again\n* Some users in their DNS forwarding to these custom domains are using only A records, or specific IP addresses, and not CNAME records, like \"custom-domain.us-south.cf.cloud.ibm.com\" like instructions explain. If you use A record IP addresses ONLY in your DNS forwarding, then this change may cause your application to not forward, even if you upload the SSL certificates.\n\n\n\n\n\n\n\n Cloud Foundry domains \n\nYou can examine which domains you currently have set up on your IBM Cloud account that might be served by IBM Cloud Foundry applications, using one of the methods below.\n\n\n\n UI method \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-custom_domain_usage"}, {"document_id": "ibmcld_04689-7442-9480", "score": 24.76358, "text": "\nImporting SSL certificates into IBM Cloud Secrets Manager \n\nYou can apply a security protocol to provide communication privacy for your app to prevent eavesdropping, tampering, and message forgery. If you have a Lite account, you must upgrade your account to upload a certificate.\n\nWhen an expired or expiring certificate must be renewed, and after the new certificate is ready, delete the existing certificate and then add the new one.\n\n\n\n Import your existing credentials into IBM Cloud Secrets Manager \n\nIBM Cloud Foundry uses customer owned IBM Cloud Secrets Manager to manage [SSL certificates.](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificates) permitting customers to have better control of their secrets. If you are using custom domains,IBM Cloud Secrets Manager will be used as storage for your SSL certificates and you will have control of certificates access via IAM service authorizations. We suggest you, to store your custom domains TLS certificates in a dedicated secrets group because will give increased flexibility when configuring [service to service authorization.](https://cloud.ibm.com/docs/account?topic=account-serviceauth)\n\nBefore configuring IBM Cloud Foundry to use IBM Cloud Secrets Manager, you need to [import your existing certificates into IBM Cloud Secrets Manager.](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificatesimport-certificates)\n\n\n\n\n\n Authorizing IBM Cloud Foundry to operate on imported certificates \n\nBefore you can map your SSL certificate to a custom domain, you must authorize IBM Cloud Foundry to use certificates [in IBM Cloud Secrets Manager.](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificatesimport-certificates)\n\n\n\n1. [Log in the IBM Cloud.](https://cloud.ibm.com/)\n2. Click Manage > Access(IAM) > Authorizations.\n3. Click Create.\n4. For Source account select This account.\n5. For Source service select Cloud Foundry for Custom Domain and leave How do you want to scope the access? as All resources.\n6.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-ssl_csr"}, {"document_id": "ibmcld_04689-2895-4699", "score": 24.607216, "text": "\nAfter you create the CSR, you can generate your SSL certificate on a public certificate authority.\n\n\n\n\n\n\n\n Uploading SSL certificates \n\nYou can apply a security protocol to provide communication privacy for your app to prevent eavesdropping, tampering, and message forgery. If you have a Lite account, you must upgrade your account to upload a certificate.\n\nIn order to use TLS certificates in IBM Cloud Foundry custom domains you need to perform few steps:\n\n\n\n1. Obtain, if not already having it, a valid certificate from a Certificate Authority (via CSR creation) [Ref](https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-ssl_csrcreate_csr)\n2. Upload certificates into a IBM Cloud Secrets Manager instance [Ref](https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-ssl_csrssl_import)\n3. Authorise IBM Cloud Foundry service to access uploaded certificates [Ref](https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-ssl_csrssl_cert_auth)\n4. Let custom domain uses the uploaded certificate by mapping its CRN.[Ref](https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-ssl_csrssl_cert_custom_domain)\n\n\n\nSSL certificate mapping is a region specific operation. If you are using the same custom domain and SSL cert across multiple regions, you need to map certificate for each one.\n\nWhen an expired or expiring certificate must be renewed, and after the new certificate is ready, delete the existing certificate and then add the new one.\n\nWhen you use a custom domain to serve the SSL certificate, use the following region endpoints to provide the URL route for your organization in IBM Cloud:\n\n\n\nTable 1. Cloud Foundry custom domain region endpoints\n\n Region Endpoint \n\n US-South custom-domain.us-south.cf.cloud.ibm.com", "title": "", "source": "https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-ssl_csr"}, {"document_id": "ibmcld_07449-7-1566", "score": 24.287775, "text": "\nManaging custom name servers for a domain \n\nDomains running on the IBM Cloud\u00ae network can point to a maximum of five (5) custom name servers. Custom name servers can be added, deleted, or changed at any time. Follow these steps to add, edit, or delete custom name servers for a domain.\n\n\n\n1. From your browser, open the [IBM Cloud\u00ae console](https://cloud.ibm.com/) and log in to your account.\n2. Select the Menu icon ![Menu icon](https://cloud.ibm.com/docs-content/v1/content/icons/icon_hamburger.svg), then click Classic Infrastructure.\n3. From the Classic Infrastructure menu, select Services > Domain Registration to open the Domains page.\n4. Select the Domain Name to expand the domain into its snapshot view.\n5. Select Unlocked from the Lock Domain.\n6. Click the > character to expand the domain and configure name servers.\n\nZoom\n\n![Sample domains collapsed image](https://cloud.ibm.com/docs-content/v1/content/86dadb3996e7fa2b119c2c09bda56dbc01297416/dns/images/custom-name-server-collapsed.png)\n\nFigure 1. Domains page with the domain collapsed\n\nZoom\n\n![Sample domains expanded image](https://cloud.ibm.com/docs-content/v1/content/86dadb3996e7fa2b119c2c09bda56dbc01297416/dns/images/custom-name-server-expanded.png)\n\nFigure 2. Domains page with the domain expanded\n7. Select the Add/Edit NS option in the Custom Name Servers section of the page. A dialog appears.\n8. To complete the appropriate action based on the task, refer to one of the following bullets:\n\n\n\n* To add a custom name server, enter the hostname for the name server in the empty field.", "title": "", "source": "https://cloud.ibm.com/docs/dns?topic=dns-add-edit-or-delete-custom-name-servers-for-a-domain"}, {"document_id": "ibmcld_05980-10127-11813", "score": 24.199007, "text": "\nTo register your custom domain, work with your Domain Name Service (DNS) provider or [IBM Cloud DNS](https://cloud.ibm.com/docs/dns?topic=dns-getting-started). If the apps that you want Ingress to expose are in different namespaces in one cluster, register the custom domain as a wildcard domain, such as .custom_domain.net. Note that domains are limited to 130 characters or fewer in Kubernetes version 1.20 or later.\n2. Define an alias for your custom domain by specifying the IBM-provided subdomain as a Canonical Name record (CNAME). To find the IBM-provided Ingress domain, run ibmcloud ks cluster get --cluster <cluster_name> and look for the Ingress subdomain field.\n\nSpecifying the IBM-provided subdomain as a CNAME is required for automatic health checks to remove any failing IPs from the DNS response, and to ensure that your custom domain updates when you add or remove ALBs.\n\n\n\n\n\n\n\n Creating custom domains for private ALBs \n\nFollow the steps to create a custom domain for private ALBs. Note that custom domains are required to use Ingress with private ALBs.\n\nIf you have a classic cluster with only a private VLAN, you must first configure your own [DNS service that is available on your private network](https://kubernetes.io/docs/tasks/administer-cluster/dns-custom-nameservers/).\n\n\n\n1. Create a custom domain through your DNS service provider. Note that Ingress URLs must be 130 characters or fewer.\n2. Map your custom domain to the private ALBs by adding their IP addresses as A records (classic clusters) or their VPC hostname as a CNAME (VPC clusters). To find the ALB IP addresses (classic) or hostname (VPC), run ibmcloud ks ingress alb ls -c <cluster_name_or_ID>.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-managed-ingress-setup"}, {"document_id": "ibmcld_02151-2385-4050", "score": 24.042034, "text": "\nThen, click the name of the space.\n\nDepending on how you want to modify the user permissions, select or clear the checkbox for a specific role. The roles that you can assign at the space level are Manager, Developer, and Auditor. For more information, see [Cloud Foundry roles](https://cloud.ibm.com/docs/account?topic=account-mngcfcfroles).\n* To manage your domains, click the Actions icon ![Action icon](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/action-menu-icon.svg) for the respective org, and select Domains.\n\nAs an account owner or organization manager, you can view the system domain and add custom domains for applications that are built within an org and its spaces. If you're a space manager, this page displays read-only list of the domains that are assigned to the space.\n\nIf you add a custom domain, you must configure your DNS server to resolve your custom domain to point to the IBM Cloud system domain. In this way, when IBM Cloud receives a request for your custom domain, it's properly routed to your app. The system domain is always available to a space, and custom domains might also be allocated to a space. Apps that are created in a space might use any of the domains that are listed for that space. For more information about creating and by using custom domains, see [Managing your domains](https://cloud.ibm.com/docs/apps?topic=apps-update-domain).\n* To manage the allocated quota for an org, click the Actions icon ![Action icon](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/action-menu-icon.svg) for the respective org, and select Quotas.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-orgupdates"}, {"document_id": "ibmcld_04625-7-1865", "score": 23.992779, "text": "\nAdding and using a custom domain \n\nIBM\u00ae Cloud Foundry is deprecated and no longer supported as of 1 June 2023. For more information, see the [deprecation details](https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-deprecationdep_details).\n\nDomains provide the URL route that is allocated to your organization in IBM Cloud\u00ae. Custom domains direct requests for your apps to a URL that you own. A custom domain can be a shared domain, a shared subdomain, or a shared domain and host. Unless a custom domain is specified, IBM Cloud uses a default shared domain in the route to your app. You can create and use a custom domain by using either the IBM Cloud console or the command-line interface.\n\nThe default shared domain is mybluemix.net, but appdomain.cloud is another domain option that you can use. For more information about migrating to appdomain.cloud, see [Updating your domain](https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-update-domain).\n\nTo use a custom domain, you must register the custom domain on a public DNS server, and then configure the custom domain in IBM Cloud. Next, you must map the custom domain to the IBM Cloud system domain on the public DNS server. After your custom domain is mapped to the system domain, requests for your custom domain are routed to your app in IBM Cloud.\n\n\n\n Adding a custom domain from the IBM Cloud console \n\nComplete these steps to add a custom domain for your org by using the console:\n\n\n\n1. Go to Manage > Account, and select Cloud Foundry orgs.\n2. Click the name of the org for which you're creating a custom domain.\n3. Click the Domains tab to view a list of available domains.\n4. Click Add a domain, enter your domain name, and select the region.\n5. Confirm your updates, and click Add.\n\n\n\n\n\n\n\n Adding the route with the custom domain to an app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-custom-domains"}, {"document_id": "ibmcld_04625-1502-3026", "score": 23.675714, "text": "\nGo to Manage > Account, and select Cloud Foundry orgs.\n2. Click the name of the org for which you're creating a custom domain.\n3. Click the Domains tab to view a list of available domains.\n4. Click Add a domain, enter your domain name, and select the region.\n5. Confirm your updates, and click Add.\n\n\n\n\n\n\n\n Adding the route with the custom domain to an app \n\n\n\n1. From the [IBM Cloud console](https://cloud.ibm.com), click the Menu icon ![Menu icon](https://cloud.ibm.com/docs-content/v1/content/icons/icon_hamburger.svg), and select Resource List.\n2. On the Resource List page, click Cloud Foundry Apps.\n3. Click the app that you want to add the route to. The app's Overview page is displayed.\n4. Select the Routes menu, and select Edit routes.\n5. Click Add route, and specify the route that you want to use for the app.\n6. Confirm your updates by clicking Save.\n\n\n\nAs an example, you can use .mycompany.com to associate the route www.mybluemix.net to your app. You can also use example.mycompany.com to associate the route www.example.bluemix.net to your app.\n\n\n\n\n\n Adding a custom domain from the IBM Cloud command-line interface \n\n\n\n1. For Cloud Foundry apps, connect to your targeted Cloud Foundry API endpoint by typing the following command:\n\nibmcloud target --cf-api <CF_ENDPOINT>\n\nCloud Foundry API endpoints:\n\n\n\n* US-SOUTH - api.us-south.cf.cloud.ibm.com\n* US-EAST - api.us-east.cf.cloud.ibm.com\n* EU-DE - api.eu-de.cf.cloud.ibm.com\n* EU-GB - api.eu-gb.cf.cloud.ibm.com\n* AU-SYD - api.au-syd.cf.cloud.ibm.com\n\n\n\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-custom-domains"}, {"document_id": "ibmcld_02146-1432-3419", "score": 23.631489, "text": "\nA route has a subdomain and a domain. A subdomain is typically the application name. A domain might be a system domain or a custom domain that you registered for your application. If you add a custom domain, you must configure your DNS server to resolve your custom domain to point to the IBM Cloud system domain. In this way, when IBM Cloud receives a request for your custom domain, it can properly route it to your application.\n\nQuota\n: Represents the resources that are available to an org, including the number of services and the amount of memory that can be allocated for use by the org. Quotas are assigned when orgs are created. Any application or service in a space within an org contributes to the usage of the quota. With Pay-As-You-Go or Subscription accounts, you can adjust your quota for Cloud Foundry applications and containers as the needs of your org change.\n\nIn a Subscription account, the quota is a user-defined limit that initiates spending notifications.\n\n\n\n\n\n Managing Cloud Foundry orgs and spaces \n\nYou can manage Cloud Foundry orgs and spaces by going to Manage > Account in the IBM Cloud console, and selecting Account resources > Cloud Foundry orgs.\n\nWhen Cloud Foundry services become IAM-enabled, they are eligible to migrate to a resource group. You're notified when your Cloud Foundry services become eligible, and you're in control of the migration. Your services can't be moved from one org to another.\n\n\n\n\n\n Creating orgs in the console \n\nIf you have a billable account, you can add as many orgs as you need. Lite accounts can have only one org, which is already created in your account. Orgs can't be deleted after you add them.\n\n\n\n1. In the IBM Cloud console, go to Manage > Account, and select Account resources > Cloud Foundry orgs. Click Create.\n2. Enter an org name. The name must be unique in IBM Cloud.\n\nIf the org name is already in use by another IBM Cloud Public, Dedicated, or Local user, you must specify a different name.\n3. Click Add.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-orgsspacesusers"}]}
{"task_id": "f3a917e029970190be5ee508ba770d7f<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07056-7-2167", "score": 21.004103, "text": "\nInformation security \n\nIBM is committed to providing our clients and partners with innovative data privacy, security, and governance solutions.\n\nIBM Cloud\n\nIBM Cloud only\n\nThis information applies only to managed deployments.\n\nNotice: Clients are responsible for ensuring their own compliance with various laws and regulations, including the European Union General Data Protection Regulation. Clients are solely responsible for obtaining advice of competent legal counsel as to the identification and interpretation of any relevant laws and regulations that may affect the clients' business and any actions the clients may need to take to comply with such laws and regulations.\n\nThe products, services, and other capabilities that are described herein are not suitable for all client situations and might have restricted availability. IBM does not provide legal, accounting, or auditing advice or represent or warrant that its services or products ensure that clients are in compliance with any law or regulation.\n\nIf you need to request GDPR support for IBM Cloud\u00ae Watson resources that are created, see [GDPR Subject Access Request](https://cloud.ibm.com/docs/watson?topic=watson-gdpr-sar).\n\n\n\n European Union General Data Protection Regulation (GDPR) \n\nIBM is committed to providing our clients and partners with innovative data privacy, security, and governance solutions to assist them on their journey to GDPR compliance.\n\nLearn more about IBM's own GDPR readiness journey and our GDPR capabilities and offerings to support your compliance journey [here](https://www.ibm.com/data-responsibility/gdpr/).\n\n\n\n\n\n Labeling and deleting data in Discovery \n\nDiscovery includes an API to label data per call. For more information about how to label data by using either the API or from the Discovery product user interface, see [Labeling data](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-information-securitylabeling).\n\nCustomer data can be deleted by using the API. For more information about deleting customer data, see [Deleting labeled data](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-information-securitydeletingdata).", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-information-security"}, {"document_id": "ibmcld_13365-7-2273", "score": 20.689295, "text": "\nInformation security \n\nIBM\u00ae is committed to providing our clients and partners with innovative data privacy, security, and governance solutions.\n\nClients are responsible for ensuring their own compliance with various laws and regulations, including the European Union General Data Protection Regulation. Clients are solely responsible for obtaining advice of competent legal counsel as to the identification and interpretation of any relevant laws and regulations that might affect the clients\u2019 business and any actions the clients might need to take to comply with such laws and regulations.\n\nThe products, services, and other capabilities described herein are not suitable for all client situations and might have restricted availability. IBM does not provide legal, accounting or auditing advice or represent or warrant that its services or products will ensure that clients are in compliance with any law or regulation.\n\nIf you need to request GDPR support for IBM Cloud\u00ae Watson resources that are created\n\n\n\n* In the European Union (EU), see [Requesting support for IBM Cloud Watson resources created in the European Union](https://cloud.ibm.com/docs/watson?topic=watson-gdpr-sarrequest-EU).\n* Outside of the EU, see [Requesting support for resources outside the European Union](https://cloud.ibm.com/docs/watson?topic=watson-gdpr-sarrequest-non-EU).\n\n\n\n\n\n European Union General Data Protection Regulation (GDPR) \n\nIBM is committed to providing our clients and partners with innovative data privacy, security and governance solutions to assist them on their journey to GDPR compliance.\n\nLearn more about IBM's own GDPR readiness journey and our GDPR capabilities and offerings to support your compliance journey [here](http://www.ibm.com/gdpr).\n\n\n\n\n\n Health Insurance Portability and Accountability Act (HIPAA) \n\nIBM Cloud\n\nUS Health Insurance Portability and Accountability Act (HIPAA) support is available for Premium plans that are hosted in the Washington, DC, (us-east) and Dallas (us-south) locations. For more information, see [Enabling EU and HIPAA supported settings](https://cloud.ibm.com/docs/account?topic=account-eu-hipaa-supportedeu-hipaa-supported).\n\nDo not include personal health information (PHI) in data that is to be added to custom models.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-information-security"}, {"document_id": "ibmcld_13712-7-2273", "score": 20.689295, "text": "\nInformation security \n\nIBM\u00ae is committed to providing our clients and partners with innovative data privacy, security, and governance solutions.\n\nClients are responsible for ensuring their own compliance with various laws and regulations, including the European Union General Data Protection Regulation. Clients are solely responsible for obtaining advice of competent legal counsel as to the identification and interpretation of any relevant laws and regulations that might affect the clients\u2019 business and any actions the clients might need to take to comply with such laws and regulations.\n\nThe products, services, and other capabilities described herein are not suitable for all client situations and might have restricted availability. IBM does not provide legal, accounting or auditing advice or represent or warrant that its services or products will ensure that clients are in compliance with any law or regulation.\n\nIf you need to request GDPR support for IBM Cloud\u00ae Watson resources that are created\n\n\n\n* In the European Union (EU), see [Requesting support for IBM Cloud Watson resources created in the European Union](https://cloud.ibm.com/docs/watson?topic=watson-gdpr-sarrequest-EU).\n* Outside of the EU, see [Requesting support for resources outside the European Union](https://cloud.ibm.com/docs/watson?topic=watson-gdpr-sarrequest-non-EU).\n\n\n\n\n\n European Union General Data Protection Regulation (GDPR) \n\nIBM is committed to providing our clients and partners with innovative data privacy, security and governance solutions to assist them on their journey to GDPR compliance.\n\nLearn more about IBM's own GDPR readiness journey and our GDPR capabilities and offerings to support your compliance journey [here](http://www.ibm.com/gdpr).\n\n\n\n\n\n Health Insurance Portability and Accountability Act (HIPAA) \n\nIBM Cloud\n\nUS Health Insurance Portability and Accountability Act (HIPAA) support is available for Premium plans that are hosted in the Washington, DC, (us-east) and Dallas (us-south) locations. For more information, see [Enabling EU and HIPAA supported settings](https://cloud.ibm.com/docs/account?topic=account-eu-hipaa-supportedeu-hipaa-supported).\n\nDo not include personal health information (PHI) in data that is to be added to custom models.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-information-security"}, {"document_id": "ibmcld_03007-7-2204", "score": 20.319603, "text": "\nInformation security \n\nIBM is committed to providing our clients and partners with innovative data privacy, security and governance solutions.\n\nNotice: Clients are responsible for ensuring their own compliance with various laws and regulations, including the European Union General Data Protection Regulation (GDPR). Clients are solely responsible for obtaining advice of competent legal counsel as to the identification and interpretation of any relevant laws and regulations that may affect the clients\u2019 business and any actions the clients may need to take to comply with such laws and regulations.\n\nThe products, services, and other capabilities described herein are not suitable for all client situations and may have restricted availability. IBM does not provide legal, accounting or auditing advice or represent or warrant that its services or products will ensure that clients are in compliance with any law or regulation.\n\nIf you need to request GDPR support for IBM Cloud\u00ae Watson resources that are created\n\n\n\n* In the European Union, see [Requesting support for IBM Cloud Watson resources created in the European Union](https://cloud.ibm.com/docs/watson/getting-started-gdpr-sarrequest-EU).\n* Outside the European Union, see [Requesting support for resources outside the European Union](https://cloud.ibm.com/docs/watson/getting-started-gdpr-sarrequest-non-EU).\n\n\n\n\n\n European Union General Data Protection Regulation (GDPR) \n\nIBM is committed to providing our clients and partners with innovative data privacy, security and governance solutions to assist them on their journey to GDPR compliance.\n\nLearn more about IBM's own GDPR readiness journey and our GDPR capabilities and offerings to support your compliance journey [here](http://www.ibm.com/gdpr).\n\n\n\n\n\n More information \n\nFor more information about data privacy in IBM Cloud Pak for Data, see [IBM Cloud Pak for Data considerations for GDPR readiness](https://www.ibm.com/docs/en/cloud-paks/cp-data/4.0?topic=compliance-considerations-gdpr-readiness).\n\n\n\n\n\n Labeling and deleting data in Watson Assistant \n\n1.5.0 and later Support for deleting data was added when log retention and analytics support were added to the product.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-information-security"}, {"document_id": "ibmcld_00478-7-2275", "score": 20.314983, "text": "\nCompliance \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae provides a trustworthy and secure cloud database system. The service is built on best-in-industry standards, including ISO 27001:2013.\n\n\n\n Tier-1 physical systems \n\nIBM Cloudant DBaaS is physically hosted on Tier-1 cloud infrastructure providers such as IBM Cloud\u00ae and Amazon. Therefore, your data is protected by the network and physical security measures that are employed by these providers.\n\n\n\n\n\n General Data Protection Regulation (GDPR) \n\nThe GDPR seeks to create a harmonized data protection law framework across the EU. It also aims to give citizens back the control of their personal data, while it imposes strict rules on those entities who host and \"process\" this data, anywhere in the world. The Regulation also introduces rules that relate to the free movement of personal data within and outside the EU. For more information, see the [IBM privacy statement](https://www.ibm.com/privacy/).\n\n\n\n\n\n HIPAA \n\nIBM Cloudant, when deployed on dedicated hardware on IBM Cloud, meets the required IBM controls that are commensurate with the Health Insurance Portability and Accountability Act of 1996 (HIPAA) Security and Privacy Rule requirements. These requirements include the appropriate administrative, physical, and technical safeguards required of Business Associates in 45 CFR Part 160 and Subparts A and C of Part 164. HIPAA must be requested at the time of provisioning and applies to the IBM Cloudant Enterprise plan, IBM Cloudant on IBM Cloud Dedicated plan, and IBM Cloudant Dedicated Hardware plan on IBM Cloud. Contact your sales representative to sign a Business Associate Addendum (BAA) agreement with IBM.\n\n\n\n\n\n International Organization for Standardization (ISO) \n\nIBM Cloudant and IBM Cloudant Dedicated Cluster are audited by a third-party security firm and meet ISO 27001, ISO 27017, and ISO 27018 requirements. For more information, see the [IBM Cloudant Compliance page](https://www.ibm.com/cloud/compliance) for links to the certificates. The following descriptions on the IBM Cloudant Compliance page cover the IBM Cloudant service and respective certifications:\n\n\n\n* IBM Cloud Services (PaaS and SaaS) certified cloud product listing\n* IBM Cloud Services (PaaS and SaaS) certificate - ISO 27001", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-compliance"}, {"document_id": "ibmcld_00637-7-2030", "score": 20.257074, "text": "\nSecurity \n\nProtecting application data for large-scale web and mobile apps can be complex, especially with distributed and NoSQL databases.\n\nJust as it reduces the effort of maintaining your databases to keep them running and growing nonstop, IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae also ensures your data stays secure and protected.\n\n\n\n Tier one physical platforms \n\nThe IBM Cloudant DBaaS is physically hosted on Tier-1 cloud infrastructure providers such as IBM Cloud\u00ae and Amazon. Therefore, your data is protected by the network and physical security measures that are employed by those providers, including (but not limited to):\n\n\n\n* Certifications - Compliance with SSAE16, SOC2 Type 1, ISAE 3402, ISO 27001, CSA, and other standards.\n* Access and identity management.\n* General physical security of data centers and network operations center monitoring.\n* Server hardening.\n* IBM Cloudant gives you the flexibility to choose or switch among the different providers as your SLA and cost requirements change.\n\n\n\nMore details about the certifications are available in the [Compliance information](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-compliancecompliance).\n\n\n\n\n\n Secure access control \n\nIBM Cloudant has a multitude of built-in security features for you to control access to data:\n\n\n\nTable 1. IBM Cloudant security features\n\n Feature Description \n\n Authentication IBM Cloudant is accessed by using an HTTPS API. Where the API endpoint requires it, the user is authenticated for every HTTPS request IBM Cloudant receives. IBM Cloudant supports both legacy and IAM access controls. For more information, see the [IAM guide](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-managing-access-for-cloudant) or the legacy [Authentication API document](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-work-with-your-accountauthentication). \n Authorization IBM Cloudant supports both legacy and IAM access controls. The IBM Cloudant team recommends that you use IAM access controls for authentication whenever possible.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-security"}, {"document_id": "ibmcld_09912-7-2171", "score": 20.02055, "text": "\nInformation security \n\nIBM is committed to providing our clients and partners with innovative data privacy, security and governance solutions.\n\nNotice: Clients are responsible for ensuring their own compliance with various laws and regulations, including the European Union General Data Protection Regulation. Clients are solely responsible for obtaining advice of competent legal counsel as to the identification and interpretation of any relevant laws and regulations that may affect the clients\u2019 business and any actions the clients may need to take to comply with such laws and regulations.\n\nThe products, services, and other capabilities described herein are not suitable for all client situations and may have restricted availability. IBM does not provide legal, accounting or auditing advice or represent or warrant that its services or products will ensure that clients are in compliance with any law or regulation.\n\nIf you need to request GDPR support for IBM Cloud\u00ae Watson resources that are created\n\n\n\n* In the European Union (EU), see [Requesting support for IBM Cloud Watson resources created in the European Union](https://cloud.ibm.com/docs/watson?topic=watson-gdpr-sarrequest-EU).\n* Outside of the EU, see [Requesting support for resources outside the European Union](https://cloud.ibm.com/docs/watson/?topic=watson-gdpr-sarrequest-non-EU).\n\n\n\n\n\n European Union General Data Protection Regulation (GDPR) \n\nIBM is committed to providing our clients and partners with innovative data privacy, security and governance solutions to assist them on their journey to GDPR compliance.\n\nLearn more about IBM's own GDPR readiness journey and our GDPR capabilities and offerings to support your compliance journey [here ![External link icon](https://cloud.ibm.com/docs-content/v1/content/icons/launch-glyph.svg)](https://cloud.ibm.com/icons/launch-glyph.svg)]( [http://www.ibm.com/gdpr](http://www.ibm.com/gdpr)){: new_window}.\n\n\n\n\n\n Labeling and deleting data in Natural Language Understanding \n\nUsers should not input any sensitive or personal information when using customization features. Beta releases may not be compatible with legislation such as GDPR.", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-information-security"}, {"document_id": "ibmcld_07170-7-2321", "score": 20.00759, "text": "\nInformation security \n\nIBM is committed to providing our clients and partners with innovative data privacy, security and governance solutions.\n\nNotice: Clients are responsible for ensuring their own compliance with various laws and regulations, including the European Union General Data Protection Regulation. Clients are solely responsible for obtaining advice of competent legal counsel as to the identification and interpretation of any relevant laws and regulations that may affect the clients' business and any actions the clients may need to take to comply with such laws and regulations.\n\nThe products, services, and other capabilities described herein are not suitable for all client situations and might have restricted availability. IBM does not provide legal, accounting, or auditing advice or represent or warrant that its services or products ensure that clients are in compliance with any law or regulation.\n\nIf you need to request GDPR support for IBM Cloud\u00ae Watson resources that are created, see [GDPR Subject Access Request](https://cloud.ibm.com/docs/watson?topic=watson-gdpr-sar).\n\n\n\n European Union General Data Protection Regulation (GDPR) \n\nIBM is committed to providing our clients and partners with innovative data privacy, security and governance solutions to assist them on their journey to GDPR compliance.\n\nLearn more about IBM's own GDPR readiness journey and our GDPR capabilities and offerings to support your compliance journey [here](https://www.ibm.com/data-responsibility/gdpr/).\n\n\n\n\n\n Labeling and deleting data in Discovery \n\nDiscovery includes an API to label data per call.\n\nWith this API you can:\n\n\n\n* Label your data with a customer ID.\n* Delete all data for a specific customer ID, including related notices.\n\n\n\nData is labeled by adding a customer_id of your choice (see restrictions in [How to label data](https://cloud.ibm.com/docs/discovery?topic=discovery-information-securitylabeling)) to the optional X-Watson-Metadata header. Discovery can then delete it by customer_id.\n\nOn any REST call, an optional header X-Watson-Metadata can be sent with semicolon separated field=value pairs, where currently only customer_id is persisted. By adding that customer_id in X-Watson-Metadata header, the request indicates that it contains data that belongs to this customer_id.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-information-security"}, {"document_id": "ibmcld_00636-7-2113", "score": 19.878819, "text": "\nSecuring your data in IBM Cloudant \n\n\n\n IBM Cloudant DBaaS data protection and security \n\nProtecting application data for large-scale web and mobile apps can be complex, especially with distributed and NoSQL databases.\n\nJust as it reduces the effort of maintaining your databases to keep them running and growing nonstop, IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae also ensures that your data stays secure and protected.\n\n\n\n\n\n Tier one physical platforms \n\nThe IBM Cloudant DBaaS is physically hosted on Tier-1 cloud infrastructure providers such as IBM Cloud\u00ae and Amazon. Therefore, your data is protected by the network and physical security measures that are employed by those providers, including (but not limited to):\n\n\n\n* Certifications - Compliance with SSAE16, SOC2 Type 1, ISAE 3402, ISO 27001, CSA, and other standards.\n* Access and identity management.\n* General physical security of data centers and network operations center monitoring.\n* Server hardening.\n* IBM Cloudant gives you the flexibility to choose or switch among the different providers as your SLA and cost requirements change.\n\n\n\nMore details about the certifications are available in the [Compliance information](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-compliancecompliance).\n\n\n\n\n\n Secure access control \n\nIBM Cloudant has a multitude of built-in security features, for you to control access to data:\n\n\n\nTable 1. IBM Cloudant security features\n\n Feature Description \n\n Authentication IBM Cloudant is accessed by using an HTTPS API. Where the API endpoint requires it, the user is authenticated for every HTTPS request IBM Cloudant receives. IBM Cloudant supports both legacy and IAM access controls. For more information, see the [IAM guide](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-managing-access-for-cloudant) or the legacy [Authentication document](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-work-with-your-accountauthentication). \n Authorization IBM Cloudant supports both legacy and IAM access controls. The IBM Cloudant team recommends that you use IAM access controls for authentication whenever possible.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-securing-your-data-in-cloudant"}, {"document_id": "ibmcld_16501-7-2384", "score": 19.850706, "text": "\nInformation security \n\nIBM is committed to providing our clients and partners with innovative data privacy, security and governance solutions.\n\nNotice: Clients are responsible for ensuring their own compliance with various laws and regulations, including the European Union General Data Protection Regulation. Clients are solely responsible for obtaining advice of competent legal counsel as to the identification and interpretation of any relevant laws and regulations that may affect the clients\u2019 business and any actions the clients may need to take to comply with such laws and regulations.\n\nThe products, services, and other capabilities described herein are not suitable for all client situations and may have restricted availability. IBM does not provide legal, accounting or auditing advice or represent or warrant that its services or products will ensure that clients are in compliance with any law or regulation.\n\nIf you need to request GDPR support for IBM Cloud\u00ae Watson resources that are created\n\n\n\n* In the European Union, see [Requesting support for IBM Cloud Watson resources created in the European Union](https://cloud.ibm.com/docs/watson?topic=watson-gdpr-sarrequest-EU).\n* Outside the European Union, see [Requesting support for resources outside the European Union](https://cloud.ibm.com/docs/watson?topic=watson-gdpr-sarrequest-non-EU).\n\n\n\n\n\n European Union General Data Protection Regulation (GDPR) \n\nIBM is committed to providing our clients and partners with innovative data privacy, security and governance solutions to assist them on their journey to GDPR compliance.\n\nLearn more about IBM's own GDPR readiness journey and our GDPR capabilities and offerings to support your compliance journey [here](http://www.ibm.com/gdpr).\n\n\n\n\n\n Health Insurance Portability and Accountability Act (HIPAA) \n\nUS Health Insurance Portability and Accountability Act (HIPAA) support is available for Premium plans in the Washington, DC location created on or after 1 April 2019. See [Enabling EU and HIPAA supported settings](https://cloud.ibm.com/docs/account?topic=account-eu-hipaa-supportedeu-hipaa-supported) for more information.\n\n\n\n\n\n GDPR in Knowledge Studio \n\nIBM Watson\u00ae Knowledge Studio provides a graphical interface through which you can access and delete uploaded artifacts that contain data. The following artifacts can be uploaded to Knowledge Studio:", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-information-security"}]}
{"task_id": "f3a917e029970190be5ee508ba770d7f<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04177-5203-6606", "score": 20.25002, "text": "\n* Turn on WAF using the toggle on the Web Application Firewall page. When you toggle the rules on or off, the changes are applied immediately.\n* Enterprise only - The Rate limiting page allows you to configure rate limiting rules to avoid noisy-neighbor problems and ward off DDoS.\n* On the IP Firewall page, you can configure access rules based on IP, country code, or ASN. You can also configure rules to block user agents. The domain lockdown section of this page allows you to limit access to your domain to certain IP addresses.\n* You can review firewall-related events on the Events page.\n\n\n\n\n\n\n\n Certificates \n\nWhen you configure a domain, IBM CIS automatically deploys a universal certificate for that domain. Thus, you don't need to do anything to have certificate-based protection in that domain. If you want, you can upload your own self-managed certificate. You'll need a separate certificate for each domain, and you'll see an error message if the certificate you are uploading does not match your domain. You can also order custom certificates on this page.\n\nIf you want to upload your own certificate, you must ensure that you replace expiring certificates before they expire, otherwise your visitors might not be able to connect. Enterprise plan users can set up an expiration notice using the [Alerts feature](https://cloud.ibm.com/docs/cis?topic=cis-configuring-policies&interface=ui).", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-manage-your-cis-deployment"}, {"document_id": "ibmcld_04334-69790-71255", "score": 19.601175, "text": "\nibmcloud cis firewall-update e6106d7ec58e47ebb2fa053dedcd7dcb -t lockdowns -d 31984fea73a15b45779fa0df4ef62f9b --json '{\"urls\": [\"api.mysite.com/some/endpoint\"], \"configurations\": [{\"target\": \"ip\", \"value\": \"127.0.0.1\"}, {\"target\": \"ip_range\", \"value\": \"2.2.2.0/24\"}]}' -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis firewalls \n\nList firewall rules.\n\nibmcloud cis firewalls (-t, --type Type) [-d, --domain DNS_DOMAIN_ID] [--page PAGE] [--per-page PER_PAGE ] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\n-t, --type\n: Type of firewall rule to create. Valid values: access-rules, ua-rules, lockdowns. Required.\n\n\n\n* access-rules: Access Rules are a way to allow, challenge, or block requests to your website. You can apply access rules to one domain only or all domains in the same service instance.\n* ua-rules: Perform access control when matching the exact UserAgent reported by the client. The access control mechanisms can be defined within a rule to help manage traffic from particular clients. This enables you to customize the access to your site.\n* lockdowns: Lock access to URLs in this domain to only permitted addresses or address ranges.\n\n\n\n-d, --domain\n: DNS Domain ID. For ua-rules and lockdowns type rule, it is a required parameter.\n\n--page\n: Page number of paginated results. The default value is 0.\n\n--per-page\n: Maximum number of access rules per page. The minimum value is 5. The default value is 20.\n\n-i, --instance\n: Instance name or ID.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_04119-1639-3490", "score": 19.521282, "text": "\nIn general, firewall rules are designed for properties exposed in OSI Layer 7 (HTTP), such as request headers and body content characteristics.\n\n\n\n\n\n Adding an application using the console \n\nFollow these steps to add an application using the UI.\n\nIn the console, UDP applications must be enabled through a Support case. After the functionality is enabled, you can create a UDP application through the CLI or API.\n\n\n\n1. Navigate to Security > Range.\n2. Click Create.\n3. Select a type of application from the list menu. You can choose TCP, UDP, HTTP, HTTPS, RDP, SSH, or Minecraft.\n4. Enter the application name. Your application becomes associated with a DNS name on your CIS domain.\n5. Enter the edge port. CIS listens for incoming connections to these addresses on this port. Connections to these addresses are proxied to your origin. You can enter a port range (for example: 8080-8090), but the origin must have the same quantity of ports specified in a consecutive range.\n6. Select the edge IP connectivity.\n7. In the Origin section, enter the origin IP and port of your TCP application. You can also select an existing load balancer and its port.\n8. Enable IP firewall (optional). When enabled, firewall rules with a \"block\" or \"allowlist\" action are enforced for this application.\n9. Enable edge TLS termination (optional). When enabled, select the type of TLS termination you want to use from the list menu.\n10. Select a [PROXY Protocol](https://cloud.ibm.com/docs/cis?topic=cis-enable-proxy-protocol) if you have a proxy in-line that supports PROXY Protocol (optional). This feature is useful if you are running a service that requires knowledge of the true client IP. In most cases, this setting remains off.\n11. Click Create.\n\n\n\nProvisioning a Range application incurs additional costs, based on the amount of bandwidth used per application.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-cis-range"}, {"document_id": "ibmcld_04109-7-2036", "score": 19.262304, "text": "\nAssigning firewall rule actions \n\nFirewall rule actions tell CIS how to respond to requests that match the criteria you define.\n\nFor lightweight firewall rules, navigate to Security > IP firewall, which contains IP rules, User Agent rules, and Domain Lockdown rules. Firewall rules are based on IP address, IP address range, Autonomous System Number (ASN), or country/region.\n\nDomain lockdown rules specify a list of IP addresses, CIDR ranges, or networks that can access a domain, subdomain, or URL. Anything not on the list is blocked.\n\nFor more robust firewall rules, navigate to Security > Firewall rules, where you can create rules that examine incoming HTTP traffic against a set of filters to block, challenge, log, or allow matching requests.\n\nThe following table describes the actions that you can assign to your rules. The priority column shows what precedence the action receives. If a request matches two different rules that have the same priority, precedence determines the action to take.\n\n\n\nTable 1. Firewall rule actions and priority\n\n Action Available in Description Priority \n\n Log <br><br> * Firewall rules<br><br><br> Logs matching requests on the CIS edge for access with Enterprise Logpush and Logpull. Recommended for testing rule effectiveness you commit to a more severe action. Available to Enterprise customers only. 1 \n Bypass <br><br> * Firewall rules<br><br><br> Allows dynamic disabling of security features for a request. Exempts matching requests from evaluation, based on a user-defined list that contains one or more of the following features: Browser Integrity Check, Domain Lockdown, Hotlink Protection, Rate Limiting, Security Level, User Agent Block, WAF Managed Rules. Matching requests are still subject to evaluation within Firewall Rules, based on order of execution. 2 \n Allow <br><br> * Firewall rules<br> * IP firewall<br><br><br> Allows matching requests to access the site, on condition that no other CIS firewall features block the request, such as IP firewall or access rules. 3", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-actions"}, {"document_id": "ibmcld_04106-7-2045", "score": 19.07848, "text": "\nCreating, editing, and deleting firewall rules \n\nIBM Cloud\u00ae Internet Services firewall rules offer power and flexibility by targeting HTTP traffic and applying custom criteria to block, challenge, log, or allow certain requests.\n\nYou can create many types of firewall rules. However, the number of active rules on your site is limited by your customer plan. See the [Plan comparison](https://cloud.ibm.com/docs/cis?topic=cis-cis-plan-comparison) page for more information on entitlements.\n\nThe number of active rules per plan is fixed. You cannot purchase additional active rules at this time.\n\nBefore getting started, it's a good idea to become familiar with [Using fields, functions, and expressions](https://cloud.ibm.com/docs/cis?topic=cis-fields-and-expressions).\n\n\n\n Creating a firewall rule \n\nTake the following steps to configure a basic firewall rule:\n\n\n\n1. Navigate to Security > Firewall Rules.\n2. Click Create Firewall Rule.\n3. Enter a rule name and optional description.\n4. Optionally, input a priority, if necessary. Note that a priority of zero is a null priority and is evaluated last.\n5. Use the UI builder in the Incoming requests section to add a condition. To build an expression with multiple conditions, click either:\n\n\n\n* And - to evaluate conditions using and logic\n* Or - to evaluate conditions or groups of previously and'ed conditions using or logic\n\n\n\nYou can see that as you build a condition, the Expression Preview shows the expression in plain text.\n\nIn the Expression Preview, you can click to edit your expression manually instead of using the Visual Expression Builder, or switch between the two. However, depending on the complexity of a manually constructed expression, the Visual Expression Builder might be unable to render it.\n6. Pick an action from the Response list menu.\n7. To save your rule, choose the most appropriate option by clicking either:\n\n\n\n* Save as draft to save your rule, but leave it disabled.\n* Save and deploy to save your rule and activate it.\n\n\n\n\n\n\n\n\n\n Editing a firewall rule", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-firewall-rules"}, {"document_id": "ibmcld_08169-0-2277", "score": 18.959787, "text": "\n\n\n\n\n\n\n  Managing permissions \n\nTo view and manage your hardware firewalls, you need the correct permissions. After your account administrator grants your user account permissions and access, you can view your hardware firewall details by using the IBM Cloud\u00ae console, or by using the SoftLayer API. The information or actions that you see depend on your permissions.\n\nThe following permissions are required for viewing and managing various parts of your hardware firewalls:\n\n\n\n*  Manage firewalls - Allows you to view your list of firewalls. It also allows you to view and manage the details of a specific firewall.\n*  View hardware details - Allows you to view your list of hardware firewalls on bare metal servers. It also allows you to view and manage the details of a specific hardware firewall on a bare metal server.\n*  View virtual server details - Allows you to view your list of firewalls on virtual servers. It also allows you to view and manage the details of a specific hardware firewall on a virtual server.\n*  Manage firewall rules - Allows you to manage the rules of a specific hardware firewall.\n*  Cancel services - Allows you to cancel a firewall.\n\n\n\n\n\n  Adding permissions for your users \n\nIf you are the account administrator and you want to grant a user permission to view and manage gateway appliance details, complete the following steps.\n\n\n\n1.  Log in to the [Access (IAM)](https://cloud.ibm.com/iam/users) page in the IBM Cloud\u00ae console.\n2.  Select View: My classic infrastructure users.\n3.  Select a user, click the Classic infrastructure tab, then click the Permissions tab.\n4.  Expand the Devices category and select Manage firewalls.\n5.  Expand the Devices category and select View hardware details.\n6.  Expand the Devices category and select View virtual server details.\n7.  Expand the Devices category and select Manage firewall rules.\n8.  Expand the Account category and select Cancel services.\n9.  Click Apply.\n\n\n\n\n\n\n\n  Next steps \n\nUser permissions are updated immediately after the changes are submitted. If permissions are granted, the user can view or interact with the selected features. If permissions are removed, the user can no longer view or interact with the selected features. Permissions can be updated again at any time.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/hardware-firewall-shared?topic=hardware-firewall-shared-managing-permissions"}, {"document_id": "ibmcld_08150-7-1806", "score": 18.851479, "text": "\nConfiguring the Hardware Firewall \n\nConfiguring your Hardware Firewall is as simple as creating a set of rules to allow access to certain IP addresses/ports from specific internet addresses while denying traffic from other sources.\n\n\n\n Adding a firewall to a server \n\nTo add a firewall to a server, follow the steps in [Getting Started](https://cloud.ibm.com/docs/hardware-firewall-shared?topic=hardware-firewall-shared-getting-startedgetting-started). If you receive an error, see the [Known Limitations](https://cloud.ibm.com/docs/hardware-firewall-shared?topic=hardware-firewall-shared-known-limitations-with-hardware-firewall-shared-known-limitations-with-hardware-firewall-shared-) and [Getting help and support](https://cloud.ibm.com/docs/hardware-firewall-shared?topic=hardware-firewall-shared-getting-help-and-support-for-hardware-firewall-shared-getting-help-and-support-for-hardware-firewall-shared-).\n\n\n\n\n\n Editing rules \n\nWhen a firewall is first added to a server, a set of rules is initially put in place that allows all traffic to reach the server. The rules can then be edited to control the traffic reaching the server.\n\nEnsure the \"status\" indicates that the firewall is \"Processing All Rules.\" Users can choose to bypass the rules in the event that implemented rules have an unintended impact on their environment by clicking Bypass Rules in the Actions drop-down.\n\n\n\n1. From your browser, open the [IBM Cloud catalog](https://cloud.ibm.com) and log into your account.\n2. Select the Menu icon ![Menu icon](https://cloud.ibm.com/docs-content/v1/content/icons/icon_hamburger.svg) from the top left, then click Classic Infrastructure.\n3. Select Devices > Device List and click on the firewall protected device you want to configure.\n4. In the Add-ons section, click Firewall details.", "title": "", "source": "https://cloud.ibm.com/docs/hardware-firewall-shared?topic=hardware-firewall-shared-configuring-the-hardware-firewall-shared-"}, {"document_id": "ibmcld_08150-1495-3332", "score": 18.79107, "text": "\n2. Select the Menu icon ![Menu icon](https://cloud.ibm.com/docs-content/v1/content/icons/icon_hamburger.svg) from the top left, then click Classic Infrastructure.\n3. Select Devices > Device List and click on the firewall protected device you want to configure.\n4. In the Add-ons section, click Firewall details. It will redirect you to the firewall page.\n5. The Firewall Details page shows the current rules in effect for IPv4 and IPv6 addresses. If no rules are implemented, a yellow status icon will show with a \"Bypassing all rules\" message next to the device name on the top of the page.\n\nRules are displayed in the order in which they are processed, with lower numbered rules having precedence over higher number rules (if rule one allows a packet through, rules two and beyond are ignored by the packet).\n\nThe fields are:\n\nPriority - This field contains the rule number. Lower numbered rules have precedence over higher numbered rules.\n\nAction - This select list is used to 'permit' or 'deny' traffic matching this rule.\n\nSource - This field can be either 'any' or a specific IP address or the network address for a specific subnet.\n\nDestination - This field selects the destination IP (see [Known Limitations](https://cloud.ibm.com/docs/hardware-firewall-shared?topic=hardware-firewall-shared-known-limitations-with-hardware-firewall-shared-) if there are issues).\n\nCIDR - This field indicates the standard CIDR notation for the selected source/destination.\n\nPort Range - These two fields indicate the range of ports (between 1 and 65535) that the rule will apply to.\n\nProtocol - This field selects the protocol the rule will apply to (TCP/GRE/ICMP/UDP/PPTP/AH/ESP).\n\nNotes: Freeform field to enter any note about this rule.\n6. Click on the Overflow menu icon at the end of the row of the firewall rule to edit or delete the rule.", "title": "", "source": "https://cloud.ibm.com/docs/hardware-firewall-shared?topic=hardware-firewall-shared-configuring-the-hardware-firewall-shared-"}, {"document_id": "ibmcld_04334-65500-67175", "score": 18.73383, "text": "\n[Deprecated] ibmcloud cis firewall-update FIREWALL_RULE_ID (-t, --type Type) (-s, --json-str JSON_STR | -j, --json-file JSON_FILE) [-d, --domain DNS_DOMAIN_ID] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\n\n\n* FIREWALL_RULE_ID: The ID of firewall rule. Required.\n\n\n\n-t, --type\n: Type of firewall rule to create. Valid values: access-rules, ua-rules, lockdowns. Required.\n\n\n\n* access-rules: Access Rules are a way to allow, challenge, or block requests to your website. You can apply access rules to one domain only or all domains in the same service instance.\n* ua-rules: Perform access control when matching the exact UserAgent reported by the client. The access control mechanisms can be defined within a rule to help manage traffic from particular clients. This enables you to customize the access to your site.\n* lockdowns: Lock access to URLs in this domain to only permitted addresses or address ranges.\n\n\n\n-d, --domain\n: DNS Domain ID. For ua-rules and lockdowns type rule, it is a required parameter.\n\n--json\n: The JSON file or JSON string used to describe a firewall rule. Required.\n\n\n\n* For --type access-rules: The JSON data describing a firewall access rule as follows.\n\n\n\n* Option fields are mode, notes.\n\n\n\n* mode: The type of action to perform. Valid values: block, challenge, whitelist, js_challenge.\n* notes: Some useful information about this rule to help identify the purpose of it.\n\n\n\n\n\n\n\nSample JSON data:\n\n{\n\"mode\": \"challenge\",\n\"notes\": \"This rule is added because of event X that occurred on date xyz\",\n}\n\n\n\n* For --type ua-rules: The JSON data describing a user-agent rule as follows.\n\n\n\n* Required fields are mode, configuration.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_04334-73111-74523", "score": 18.53022, "text": "\nibmcloud cis firewall 4af47b1518be478aa2c8f024af1c0bad -t ua-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall e6106d7ec58e47ebb2fa053dedcd7dcb -t lockdown -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis firewall-delete \n\nDelete a firewall rule by ID.\n\nibmcloud cis firewall-delete FIREWALL_RULE_ID (-t, --type Type) [-d, --domain DNS_DOMAIN_ID] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nFIREWALL_RULE_ID\n: The ID of firewall rule. Required.\n\n-t, --type\n: Type of firewall rule to create. Valid values: access-rules, ua-rules, lockdowns. Required.\n\n\n\n* access-rules: Access Rules are a way to allow, challenge, or block requests to your website. You can apply access rules to one domain only or all domains in the same service instance.\n* ua-rules: Perform access control when matching the exact UserAgent reported by the client. The access control mechanisms can be defined within a rule to help manage traffic from particular clients. This enables you to customize the access to your site.\n* lockdowns: Lock access to URLs in this domain to only permitted addresses or address ranges.\n\n\n\n-d, --domain\n: DNS Domain ID. For ua-rules and lockdowns type rule, it is a required parameter.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n\n\n\n\n Examples \n\nDelete a firewall rule.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}]}
{"task_id": "ddbbbe7ea13560c5768639207e1ca604<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16481-3559-5682", "score": 16.150522, "text": "\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"}, {"document_id": "ibmcld_16417-3559-5683", "score": 16.139776, "text": "\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"}, {"document_id": "ibmcld_16464-13891-15856", "score": 14.862819, "text": "\nIn general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https://cloud.ibm.com/docs-content/v1/content/148d3bd95f946aa1bb53ea1540475f522e6b61c9/watson-knowledge-studio-data/images/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:\n\n\n\n* If the scores are acceptable for an annotation set, select the check box and click Accept. Documents that do not overlap with other document sets are promoted to ground truth. Documents that do overlap must first be reviewed through adjudication so that conflicts can be resolved. For this tutorial, accept both document sets.\n* If the scores are not acceptable for an annotation set, select the check box and click Reject. The document set needs to be revisited by the human annotator to improve the annotations.\n\n\n\n\n\n\n\n\n\n Results \n\nWhen you evaluated the inter-annotator agreement scores, you saw how different pairs of human annotators annotated the same document. If the inter-annotator agreement score was acceptable, you accepted the document set.\n\n\n\n\n\n\n\n Lesson 6: Adjudicating conflicts in annotated documents \n\nIn this lesson, you will learn how to adjudicate conflicts in documents that overlap between document sets in Knowledge Studio.\n\n\n\n About this task \n\nWhen you approve a document set, only the documents that do not overlap with other document sets are promoted to ground truth. If a document is part of the overlap between multiple document sets, you must adjudicate any annotation conflicts before the document can be promoted to ground truth.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}, {"document_id": "ibmcld_16436-9264-11446", "score": 12.406711, "text": "\nAn entity type exists independently and can be uniquely identified.\n\n\n\n\n\n\n\n F \n\n\n\n* F1 score\n\nA measure of a test's accuracy that considers both precision and recall to compute the score. The F1 score can be interpreted as a weighted average of the precision and recall values. An F1 score reaches its best value at 1 and worst value at 0.\n* false negative\n\nAn answer or annotation that is correct, but was predicted to be incorrect.\n* false positive\n\nAn answer or annotation that is incorrect, but was predicted to be correct.\n* feature\n\nA data member or attribute of a type.\n* Fleiss Kappa score\n\nA measure of how consistently the same annotation was applied by multiple human annotators across overlapping documents. The Fleiss Kappa score reaches its best value at 1 and worst value at 0.\n\n\n\n\n\n\n\n G \n\n\n\n* ground truth\n\nThe set of vetted data, consisting of annotations added by human annotators, that is used to adapt a machine learning model to a particular domain. Ground truth is used to train machine learning models, measure model performance (precision and recall), and calculate headroom to decide where to focus development efforts for improving performance. Accuracy of ground truth is essential since inaccuracies in the ground truth will correlate to inaccuracies in the components that use it.\n\n\n\n\n\n\n\n H \n\n\n\n* headroom analysis\n\nThe process of determining how much improvement in accuracy, precision, or recall can be expected by addressing some class of problems that are identified while performing accuracy analysis.\n* human annotator\n\nA subject matter expert who reviews, modifies, and augments the results of pre-annotation by identifying mentions, entity type relationships, and mention coreferences. By examining text in context, a human annotator helps determine ground truth and improve the accuracy of the machine learning model.\n\n\n\n\n\n\n\n I \n\n\n\n* inter-annotator agreement\n\nA measure of how similarly a document in two or more document sets is annotated.\n\n\n\n\n\n\n\n K \n\n\n\n* knowledge graph\n\nA model that consolidates typed entities, their relationships, their properties, and hierarchical taxonomies to represent an organization of concepts for a given domain.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-glossary"}, {"document_id": "ibmcld_16493-8964-11146", "score": 12.406711, "text": "\nAn entity type exists independently and can be uniquely identified.\n\n\n\n\n\n\n\n F \n\n\n\n* F1 score\n\nA measure of a test's accuracy that considers both precision and recall to compute the score. The F1 score can be interpreted as a weighted average of the precision and recall values. An F1 score reaches its best value at 1 and worst value at 0.\n* false negative\n\nAn answer or annotation that is correct, but was predicted to be incorrect.\n* false positive\n\nAn answer or annotation that is incorrect, but was predicted to be correct.\n* feature\n\nA data member or attribute of a type.\n* Fleiss Kappa score\n\nA measure of how consistently the same annotation was applied by multiple human annotators across overlapping documents. The Fleiss Kappa score reaches its best value at 1 and worst value at 0.\n\n\n\n\n\n\n\n G \n\n\n\n* ground truth\n\nThe set of vetted data, consisting of annotations added by human annotators, that is used to adapt a machine learning model to a particular domain. Ground truth is used to train machine learning models, measure model performance (precision and recall), and calculate headroom to decide where to focus development efforts for improving performance. Accuracy of ground truth is essential since inaccuracies in the ground truth will correlate to inaccuracies in the components that use it.\n\n\n\n\n\n\n\n H \n\n\n\n* headroom analysis\n\nThe process of determining how much improvement in accuracy, precision, or recall can be expected by addressing some class of problems that are identified while performing accuracy analysis.\n* human annotator\n\nA subject matter expert who reviews, modifies, and augments the results of pre-annotation by identifying mentions, entity type relationships, and mention coreferences. By examining text in context, a human annotator helps determine ground truth and improve the accuracy of the machine learning model.\n\n\n\n\n\n\n\n I \n\n\n\n* inter-annotator agreement\n\nA measure of how similarly a document in two or more document sets is annotated.\n\n\n\n\n\n\n\n K \n\n\n\n* knowledge graph\n\nA model that consolidates typed entities, their relationships, their properties, and hierarchical taxonomies to represent an organization of concepts for a given domain.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-glossary"}, {"document_id": "ibmcld_16417-5155-7505", "score": 12.35566, "text": "\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"}, {"document_id": "ibmcld_16481-5154-7504", "score": 12.35566, "text": "\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"}, {"document_id": "ibmcld_16563-12333-14196", "score": 12.219032, "text": "\nThe IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.\n\nFor more information about inter-annotator agreement, see [Building the ground truth](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator and select Machine Learning Model > Annotations. Click the Annotation Tasks tab, then click the Test task.\n\nIn the Status column, you can see that the document sets are submitted.\n2. Click Calculate Inter-Annotator Agreement.\n3. View IAA scores for mention, relations, and coreference chains by clicking the first menu. You can also view agreement by pairs of human annotators. You can also view agreement by specific documents. In general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https://cloud.ibm.com/docs-content/v1/content/50eddb8fd81f33092880335ff107a78ff5cd0f65/watson-knowledge-studio/images/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"}, {"document_id": "ibmcld_10916-28690-30835", "score": 11.931901, "text": "\nA measure of a test's accuracy that considers both precision and recall to compute the score. The F1 score can be interpreted as a weighted average of the precision and recall values. An F1 score reaches its best value at 1 and worst value at 0.\n\n\n\n\n\n false negative \n\nAn answer or annotation that is correct, but was predicted to be incorrect.\n\n\n\n\n\n false positive \n\nAn answer or annotation that is incorrect, but was predicted to be correct.\n\n\n\n\n\n feature \n\nA data member or attribute of a type.\n\n\n\n\n\n feature code \n\nA code that is applied to free accounts to unlock extra product resources and capabilities.\n\n\n\n\n\n Federal Risk and Authorization Management Program (FedRAMP) \n\nA United States government program that provides a standardized, risk-based approach for the adoption and use of cloud services by the US federal government. FedRAMP empowers agencies to use modern cloud technologies with an emphasis on security and protection of federal information, and helps accelerate the adoption of secure cloud solutions.\n\n\n\n\n\n federate \n\nTo merge two or more entities. For example, a company's registered domain could be federated with an IBMid.\n\n\n\n\n\n FedRAMP \n\nSee [Federal Risk and Authorization Management Program](https://cloud.ibm.com/docs/overview?topic=overview-glossaryx10109081).\n\n\n\n\n\n feed \n\nA piece of code that configures an external event source to fire trigger events. See also [action](https://cloud.ibm.com/docs/overview?topic=overview-glossaryx2012974).\n\n\n\n\n\n file share \n\nIn the IBM Cloud environment, a persistent storage system where users store and share files. In IBM Cloud Kubernetes Service, users can mount Docker volumes on file shares.\n\n\n\n\n\n fire \n\nTo activate a trigger.\n\n\n\n\n\n Fleiss Kappa score \n\nA measure of how consistently the same annotation was applied by multiple human annotators across overlapping documents. The Fleiss Kappa score reaches its best value at 1 and worst value at 0.\n\n\n\n\n\n floating IP address \n\nA public, routable IP address that makes use of 1-to-1 network address translation (NAT) so that a server can communicate with the public internet and private subnet within a cloud environment.", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-glossary"}, {"document_id": "ibmcld_16410-8324-10312", "score": 11.851344, "text": "\nInter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).\n\n\n\nAn annotation set that you plan to use to train a machine learning model must contain at least 10 annotated documents.\n\n\n\n1. Select a user name from the list of human annotators.\n2. Name the annotation set.\n\nAs a good practice for evaluating a human annotator's work as the workspace progresses, you might want to create annotation set names that identify the human annotator assigned to the set.\n\nYou cannot change the annotation set name after the set is created.\n3. Click Generate.\n\n\n\n6. A list of available annotation sets is displayed under Available Sets, along with the names of the human annotators assigned to them. To add available sets to your annotation task, click Add to task.\n7. Make sure that all of the annotation sets that you want to include in the task appear under Selected Sets, then click Save to create the task.\n\n\n\n\n\n\n\n What to do next \n\nAfter the task is created, you can return to the Annotation Tasks tab on the Machine Learning Model > Annotations page to view the progress of each human annotator. Also, you can complete the following tasks:\n\n\n\n* Check approved documents that overlap between annotation sets to resolve annotation conflicts.\n* Open a task to add annotation sets to it. Ensure that the annotation sets that you add include documents that overlap with documents in the original annotation sets.\n\n\n\nFrom the Settings tab of the main navigation, you can specify the following information:\n\n\n\n* Specify preferences for using colors and keyboard shortcuts in the ground truth editor.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"}]}
{"task_id": "ddbbbe7ea13560c5768639207e1ca604<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16481-3559-5682", "score": 23.118607, "text": "\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"}, {"document_id": "ibmcld_16417-3559-5683", "score": 23.090654, "text": "\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"}, {"document_id": "ibmcld_16410-8324-10312", "score": 23.06059, "text": "\nInter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).\n\n\n\nAn annotation set that you plan to use to train a machine learning model must contain at least 10 annotated documents.\n\n\n\n1. Select a user name from the list of human annotators.\n2. Name the annotation set.\n\nAs a good practice for evaluating a human annotator's work as the workspace progresses, you might want to create annotation set names that identify the human annotator assigned to the set.\n\nYou cannot change the annotation set name after the set is created.\n3. Click Generate.\n\n\n\n6. A list of available annotation sets is displayed under Available Sets, along with the names of the human annotators assigned to them. To add available sets to your annotation task, click Add to task.\n7. Make sure that all of the annotation sets that you want to include in the task appear under Selected Sets, then click Save to create the task.\n\n\n\n\n\n\n\n What to do next \n\nAfter the task is created, you can return to the Annotation Tasks tab on the Machine Learning Model > Annotations page to view the progress of each human annotator. Also, you can complete the following tasks:\n\n\n\n* Check approved documents that overlap between annotation sets to resolve annotation conflicts.\n* Open a task to add annotation sets to it. Ensure that the annotation sets that you add include documents that overlap with documents in the original annotation sets.\n\n\n\nFrom the Settings tab of the main navigation, you can specify the following information:\n\n\n\n* Specify preferences for using colors and keyboard shortcuts in the ground truth editor.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"}, {"document_id": "ibmcld_16417-5155-7505", "score": 22.261143, "text": "\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"}, {"document_id": "ibmcld_16481-5154-7504", "score": 22.261143, "text": "\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"}, {"document_id": "ibmcld_16464-13891-15856", "score": 21.981268, "text": "\nIn general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https://cloud.ibm.com/docs-content/v1/content/148d3bd95f946aa1bb53ea1540475f522e6b61c9/watson-knowledge-studio-data/images/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:\n\n\n\n* If the scores are acceptable for an annotation set, select the check box and click Accept. Documents that do not overlap with other document sets are promoted to ground truth. Documents that do overlap must first be reviewed through adjudication so that conflicts can be resolved. For this tutorial, accept both document sets.\n* If the scores are not acceptable for an annotation set, select the check box and click Reject. The document set needs to be revisited by the human annotator to improve the annotations.\n\n\n\n\n\n\n\n\n\n Results \n\nWhen you evaluated the inter-annotator agreement scores, you saw how different pairs of human annotators annotated the same document. If the inter-annotator agreement score was acceptable, you accepted the document set.\n\n\n\n\n\n\n\n Lesson 6: Adjudicating conflicts in annotated documents \n\nIn this lesson, you will learn how to adjudicate conflicts in documents that overlap between document sets in Knowledge Studio.\n\n\n\n About this task \n\nWhen you approve a document set, only the documents that do not overlap with other document sets are promoted to ground truth. If a document is part of the overlap between multiple document sets, you must adjudicate any annotation conflicts before the document can be promoted to ground truth.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}, {"document_id": "ibmcld_16425-14122-16407", "score": 21.406723, "text": "\nAnother indicator of annotation inconsistency is if you have enough annotations, but the corpus density is low. Density can be impacted when a mention that is significant in the domain literature occurs often, but is annotated as different types across the document set.\n\nLow precision is often an indication that you need to improve annotation consistency. To do so, review the annotation guidelines, better train the human annotators, and ensure that human annotators are working in concert and not in isolation from one another.\n\nCheck the inter-annotator agreement score. This score, which measures the degree of agreement between different annotators' output on the same document, is a valuable number. Not only does this score tell you the quality of the ground truth documents that will be used to train the machine learning model, but it also indicates the upper bound of machine learning model performance. A model that is trained on these documents is unlikely to outperform the best agreement that humans can reach. For example, if performance persists at 75 and does not go higher, take a look at the inter-annotator agreement results. If the inter-annotator agreement score is 80, take actions to better train the human annotators and ensure that conflicts are correctly resolved (according to the annotation guidelines) during adjudication. If humans can't agree on how something should be labeled, then it's unlikely that a machine learning model will apply the correct labels.\n* Enhance human annotator guidelines\n\nClear and comprehensive annotator guidelines are a crucial part of a harmonious and successful annotation development effort. Human annotators have a tough job to do. There can be nuances in assigning entity and relation types that are hard to anticipate until you start to work with the domain documents. The guidelines can provide a sanity check to human annotators as they evaluate documents. The guidelines should be a living and changing document, especially at the beginning of the annotation process. They provide a key feedback loop because a human annotator can capture things she learned while annotating a few documents, then as she or someone else annotates a few more documents, new tips and gotchas can be added to the guideline, and so on.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-ml"}, {"document_id": "ibmcld_16490-14092-16377", "score": 21.406723, "text": "\nAnother indicator of annotation inconsistency is if you have enough annotations, but the corpus density is low. Density can be impacted when a mention that is significant in the domain literature occurs often, but is annotated as different types across the document set.\n\nLow precision is often an indication that you need to improve annotation consistency. To do so, review the annotation guidelines, better train the human annotators, and ensure that human annotators are working in concert and not in isolation from one another.\n\nCheck the inter-annotator agreement score. This score, which measures the degree of agreement between different annotators' output on the same document, is a valuable number. Not only does this score tell you the quality of the ground truth documents that will be used to train the machine learning model, but it also indicates the upper bound of machine learning model performance. A model that is trained on these documents is unlikely to outperform the best agreement that humans can reach. For example, if performance persists at 75 and does not go higher, take a look at the inter-annotator agreement results. If the inter-annotator agreement score is 80, take actions to better train the human annotators and ensure that conflicts are correctly resolved (according to the annotation guidelines) during adjudication. If humans can't agree on how something should be labeled, then it's unlikely that a machine learning model will apply the correct labels.\n* Enhance human annotator guidelines\n\nClear and comprehensive annotator guidelines are a crucial part of a harmonious and successful annotation development effort. Human annotators have a tough job to do. There can be nuances in assigning entity and relation types that are hard to anticipate until you start to work with the domain documents. The guidelines can provide a sanity check to human annotators as they evaluate documents. The guidelines should be a living and changing document, especially at the beginning of the annotation process. They provide a key feedback loop because a human annotator can capture things she learned while annotating a few documents, then as she or someone else annotates a few more documents, new tips and gotchas can be added to the guideline, and so on.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-evaluate-ml"}, {"document_id": "ibmcld_16468-8522-10510", "score": 21.11942, "text": "\nIf no annotation sets are available, click Create Annotation Sets.\n\n\n\n1. For the base set, select the document set or annotation set that you want to divide into annotation sets.\n2. For the overlap value, specify the percentage of documents that you want to include in each annotation set. Inter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).\n\n\n\nAn annotation set that you plan to use to train a machine learning model must contain at least 10 annotated documents.\n\n\n\n1. Select a user name from the list of human annotators.\n2. Name the annotation set.\n\nAs a good practice for evaluating a human annotator's work as the workspace progresses, you might want to create annotation set names that identify the human annotator assigned to the set. You cannot change the annotation set name after the set is created.\n\nThe maximum size of the annotation set name is 256 characters.\n3. Click Generate.\n\n\n\n6. A list of available annotation sets is displayed under Available Sets, along with the names of the human annotators assigned to them. To add available sets to your annotation task, click Add to task.\n7. Make sure that all of the annotation sets that you want to include in the task appear under Selected Sets, then click Save to create the task.\n\n\n\n\n\n\n\n What to do next \n\nAfter the task is created, you can return to the Annotation Tasks tab on the Machine Learning Model > Annotations page to view the progress of each human annotator. Also, you can complete the following tasks:\n\n\n\n* Check approved documents that overlap between annotation sets to resolve annotation conflicts.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents"}, {"document_id": "ibmcld_16417-1764-4158", "score": 20.978994, "text": "\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"}]}
{"task_id": "ddbbbe7ea13560c5768639207e1ca604<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01232-3064-5002", "score": 19.674574, "text": "\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger. The maximum number of inodes that can be configured on a volume is calculated by taking the total allocated volume size in KB and dividing it by 4. Any volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760 \n 80 GB 20,971,520 \n 100 GB 26,214,400 \n 500 GB 131,072,000 \n 1 TB 268,435,456 \n 4 TB 1,073,741,824 \n 8 TB 2,040,109,451 \n 12 TB 2,040,109,451 \n\n\n\n\n\n\n\n I ordered a File Storage for Classic volume in the wrong data center. Is it possible to move or migrate it to another data center? \n\nYou need to order new File Storage for Classic in the right data center, and then cancel the File Storage for Classic device that you ordered in the incorrect location. When the volume is canceled, the request is followed by a 24-hour reclaim wait period. You can still see the volume in the console during those 24 hours. Billing for the volume stops immediately. When the reclaim period expires, the data is destroyed and the volume is removed from the console, too.\n\n\n\n\n\n Measuring IOPS \n\nIOPS is measured based on a load profile of 16-KB blocks with random 50 percent reads and 50 percent writes. Workloads that differ from this profile might experience poor performance.", "title": "", "source": "https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-file-storage-faqs"}, {"document_id": "ibmcld_15092-4396-6100", "score": 18.303736, "text": "\nAll volumes are assigned instance bandwidth proportional to their maximum bandwidth, where the sum of all volume bandwidth equals the overall \"volumes\" bandwidth.\n\nIn our [example](https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-bandwidthvolume-adjust-bandwidth), the remaining bandwidth that is allocated on the instance for data volumes is 1,607 Mbps (2000 Mbps less 393 Mbps for the boot volume). After the data volume is attached to the instance, the volume optimally requires 640 Mbps. If this volume is the only attached volume, it gets the full bandwidth allocation. If you had two more volumes of greater capacity, the bandwidth allocation is less.\n\nUnattached volume bandwidth might not be the same as the actual bandwidth that you see after the volume is attached to an instance. The difference is due to the amount of bandwidth that is dedicated to the boot volume and all other attached data volumes.\n\n\n\n\n\n\n\n Estimating volume bandwidth \n\nThink about the type of data volume that your workloads require and select the right volume profile. Data intensive workloads might require the higher bandwidth performance of a 10 IOPS/GB profile. For more information about the relationship of volume profiles to compute profiles, see [How virtual server profiles relate to storage profiles](https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-profiles&interface=uivsi-profiles-relate-to-storage). For more information about how block size affects performance, see [Block storage capacity and performance](https://cloud.ibm.com/docs/vpc?topic=vpc-capacity-performance&interface=uihow-block-size-affects-performance).\n\n\n\n\n\n Next steps \n\nAllocate total volume bandwidth by using the API or CLI.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-bandwidth"}, {"document_id": "ibmcld_15092-3374-4802", "score": 17.955067, "text": "\nWhen you create a stand-alone (unattached) block storage data volume, the volume bandwidth is assigned based on volume capacity, IOPS, and volume profile. The API response for a GET /volume/{id} call shows the bandwidth for an unattached volume like the following example.\n\n{\n\"active\": true,\n\"bandwidth\": 640,\n\"busy\": false,\n\"capacity\": 500,\n\"created_at\": \"2021-08-08T06:26:17Z\",\n\"crn\": \"crn:[...]\",\n\"encryption\": \"provider_managed\",\n\"href\": \"https://us-south.iaas.cloud.ibm.com/v1/volumes/ccbe6fe1-5680-4865-94d3-687076a38293\",\n\"id\": \"ccbe6fe1-5680-4865-94d3-687076a38293\",\n\"iops\": 5000,\n\"name\": \"my-volume-1\",\n\"profile\": {\n\"href\": \"https://us-south.iaas.cloud.ibm.com/v1/volume/profiles/general-purpose\",\n\"name\": \"custom\"\n.\n.\n.\n\"volume_attachments\": []\nShow more\n\nWhen you attach a secondary volume to a virtual server instance, the primary boot volume gets priority IOPS, and bandwidth allocation to ensure reasonable boot times. Boot volume IOPS and bandwidth are never reduced to be less than 3000 IOPS or 393 Mbps.\n\nAll volumes are assigned instance bandwidth proportional to their maximum bandwidth, where the sum of all volume bandwidth equals the overall \"volumes\" bandwidth.\n\nIn our [example](https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-bandwidthvolume-adjust-bandwidth), the remaining bandwidth that is allocated on the instance for data volumes is 1,607 Mbps (2000 Mbps less 393 Mbps for the boot volume).", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-bandwidth"}, {"document_id": "ibmcld_16727-1272819-1274596", "score": 17.754795, "text": "\nAny volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760 \n 80 GB 20,971,520 \n 100 GB 26,214,400 \n 500 GB 131,072,000 \n 1 TB 268,435,456 \n 4 TB 1,073,741,824 \n 8 TB 2,040,109,451 \n 12 TB 2,040,109,451 \n\n\n\n* I ordered a File Storage for Classic volume in the wrong data center. Is it possible to move or migrate it to another data center?\n\nYou need to order new File Storage for Classic in the right data center, and then cancel the File Storage for Classic device that you ordered in the incorrect location. When the volume is canceled, the request is followed by a 24-hour reclaim wait period. You can still see the volume in the console during those 24 hours. Billing for the volume stops immediately. When the reclaim period expires, the data is destroyed and the volume is removed from the console, too.\n* Measuring IOPS\n\nIOPS is measured based on a load profile of 16-KB blocks with random 50 percent reads and 50 percent writes. Workloads that differ from this profile might experience poor performance. To improve performance, you can try adjusting the host settings or [enabling Jumbo frames](https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-jumboframes).\n* What happens when I use a smaller block size for measuring performance?\n\nMaximum IOPS can be obtained even if you use smaller block sizes. However, the throughput is less in this case. For example, a volume with 6000 IOPS has the following throughput at various block sizes:\n\n\n\n* 16 KB * 6000 IOPS == 93.75 MB/sec", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-1270170-1271947", "score": 17.754795, "text": "\nAny volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760 \n 80 GB 20,971,520 \n 100 GB 26,214,400 \n 500 GB 131,072,000 \n 1 TB 268,435,456 \n 4 TB 1,073,741,824 \n 8 TB 2,040,109,451 \n 12 TB 2,040,109,451 \n\n\n\n* I ordered a File Storage for Classic volume in the wrong data center. Is it possible to move or migrate it to another data center?\n\nYou need to order new File Storage for Classic in the right data center, and then cancel the File Storage for Classic device that you ordered in the incorrect location. When the volume is canceled, the request is followed by a 24-hour reclaim wait period. You can still see the volume in the console during those 24 hours. Billing for the volume stops immediately. When the reclaim period expires, the data is destroyed and the volume is removed from the console, too.\n* Measuring IOPS\n\nIOPS is measured based on a load profile of 16-KB blocks with random 50 percent reads and 50 percent writes. Workloads that differ from this profile might experience poor performance. To improve performance, you can try adjusting the host settings or [enabling Jumbo frames](https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-jumboframes).\n* What happens when I use a smaller block size for measuring performance?\n\nMaximum IOPS can be obtained even if you use smaller block sizes. However, the throughput is less in this case. For example, a volume with 6000 IOPS has the following throughput at various block sizes:\n\n\n\n* 16 KB * 6000 IOPS == 93.75 MB/sec", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_00249-2107-3786", "score": 17.6402, "text": "\nThe API call shows the combined number of Block Storage for Classic and File Storage for Classic.\n\n\n\n\n\n\n\n Requesting volume limit increase \n\nYou can request a provisioning limit increase by submitting a support case in the [console](https://cloud.ibm.com/unifiedsupport/cases/add). When the request is approved, you get a volume limit that is set for a specific data center.\n\nIn the case, provide the following information:\n\n\n\n* Ticket Subject: Request to Increase Data Center Volume Count Storage Limit\n* What is the use case for the additional volumes request?For example, your answer might be something similar to a new VMware\u00ae datastore, a new development and testing (dev/test) environment, an SQL database, or logging.\n* How many extra Block volumes are needed by type, size, IOPS, and location?For example, your answer might be \"25x Endurance 2 TB @ 4 IOPS in DAL09\" or \"25x Performance 4 TB @ 2 IOPS in WDC04\".\n* How many extra File volumes are needed by type, size, IOPS, and location?For example, your answer might be \"25x Performance 20 GB @ 10 IOPS in DAL09\" or \"50x Endurance 2 TB @ 0.25 IOPS in SJC03\".\n* Provide an estimate of when you expect or plan to provision all of the requested volume increase.For example, your answer might be \"90 days\".\n* Provide a 90-day forecast of expected average capacity usage of these volumes.For example, your answer might be \"expect 25 percent to be used in 30 days, 50 percent to be used in 60 days and 75 percent to be used in 90 days\".\n\n\n\nRespond to all questions and statements in your request. They are required for processing and approval.\n\nYou're going to be notified of the update to your limits through the case process.", "title": "", "source": "https://cloud.ibm.com/docs/BlockStorage?topic=BlockStorage-managingstoragelimits"}, {"document_id": "ibmcld_15252-27792-29334", "score": 17.505756, "text": "\nCreate a data volume with a request similar to this example. This procedure shows the volume profiles, crreates a volume, saves the volume ID in a variable, checks the status of the volume, and then creates the volume attachment.\n\nShow a list of volume profiles:\n\ncurl -X GET \"$vpc_api_endpoint/v1/volumes/profiles?version=$api_version&generation=2\" -H \"Authorization: $iam_token\"\n\nProfiles can be general-purpose (3 IOPS/GB), 5iops-tier, 10-iops-tier, and custom. See [Profiles](https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-profilesblock-storage-profiles) for information about volume capacity and IOPS ranges based on the volume profile you select.\n\nCreate the data volume:\n\ncurl -X POST \"$vpc_api_endpoint/v1/volumes?version=$api_version&generation=2\" -H \"Authorization: $iam_token\" -d '{\n\"name\": \"my-volume\",\n\"iops\": 1000,\n\"capacity\": 100,\n\"zone\": {\n\"name\": \"us-south-3\"\n},\n\"profile\": {\n\"name\": \"custom\"\n}\n}'\n\nSave the ID of the volume in a variable:\n\nvolume_id=\"0738-640774d7-2adc-4609-add9-6dfd96167a8f\"\n\nThe status of the volume is pending when it first is created. Before you can proceed, the volume needs to move to available status, which takes a few minutes.\n\nCheck the status of the volume:\n\ncurl -X GET \"$vpc_api_endpoint/v1/volumes/$volume_id?version=$api_version&generation=2\" -H \"Authorization: $iam_token\"\n\nCreate a volume attachment to attach the new data volume to the virtual server instance. Use the instance ID variable that you created earlier in the request. Use the volume ID variable to specify the volume.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-creating-vpc-resources-with-cli-and-api&interface=api"}, {"document_id": "ibmcld_01245-2097-3849", "score": 17.204529, "text": "\nThe API call shows the combined number of Block Storage for Classic and File Storage for Classic.\n\n\n\n\n\n\n\n Requesting limit increase \n\nYou can request a limit increase by submitting a support case in the [portal](https://cloud.ibm.com/unifiedsupport/cases/add). When the request is approved, you get a volume limit that is set for a specific data center.\n\nTo request a limit increase, open a support case and direct it to your sales representative.\n\nIn the ticket, provide the following information:\n\n\n\n* Ticket Subject: Request to Increase Data Center Volume Count Storage Limit\n* What is the use case for the additional volumes request?For example, your answer might be something similar to a new VMware\u00ae datastore, a new development and testing environment, an SQL database, or logging.\n* How many extra Block volumes are needed by type, size, IOPS, and location?For example, your answer might be \"25x Endurance 2 TB @ 4 IOPS in DAL09\" or \"25x Performance 4 TB @ 2 IOPS in WDC04\".\n* How many extra File volumes are needed by type, size, IOPS, and location?For example, your answer might be \"25x Performance 20 GB @ 10 IOPS in DAL09\" or \"50x Endurance 2 TB @ 0.25 IOPS in SJC03\".\n* Provide an estimate of when you expect or plan to provision all of the requested volume increase.For example, your answer might be \"90 days\".\n* Provide a 90-day forecast of expected average capacity usage of these volumes.For example, your answer might be \"expect 25 percent to be used in 30 days, 50 percent to be used in 60 days and 75 percent to be used in 90 days\".\n\n\n\nRespond to all questions and statements in your request. They are required for processing and approval.\n\nYou're going to be notified of the update to your limits through the case handling process.", "title": "", "source": "https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-managinglimits"}, {"document_id": "ibmcld_15271-7332-8240", "score": 17.169155, "text": "\n\"href\": \"https://us-south.iaas.cloud.ibm.com/v1/instances/8f06378c-ed0e-481e-b98c-9a6dfbee1ed5/volume_attachments/4cbb38bc-57d5-4121-a796-d5b10cf0810a\",\n\"id\": \"<4cbb38bc-57d5-4121-a796-d5b10cf0810aAttachment ID>\",\n\"instance\": {\n\"crn\": \"crn:...]\",\n\"href\": \"https://us-south.iaas.cloud.ibm.com/v1/instances/8f06378c-ed0e-481e-b98c-9a6dfbee1ed5\",\n\"id\": \"8f06378c-ed0e-481e-b98c-9a6dfbee1ed5\",\n\"name\": \"my-instance-1\"\n},\n\"name\": \"my-volume-attachment-1\",\n\"type\": \"data\"\n}],\n\"zone\": {\n\"href\": \"https://us-south.iaas.cloud.ibm.com/v1/regions/us-south/zones/us-south-2\",\n\"name\": \"us-south-2\"\n}\n}\n\n\n\n\n\n Expand block storage volumes with Terraform \n\nTo increase the capacity of a volume, use the ibm_is_volume resource. When applied, the following example updates the capacity to 8,000 GB.\n\nresource \"ibm_is_volume\" \"storage\" {\nname = \"demo-volume-update\"\nsize = 8000\nprofile = \"general-purpose\"\nzone = \"us-south-2\"\n}", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-expanding-block-storage-volumes"}, {"document_id": "ibmcld_15275-7345-8253", "score": 17.169155, "text": "\n\"href\": \"https://us-south.iaas.cloud.ibm.com/v1/instances/8f06378c-ed0e-481e-b98c-9a6dfbee1ed5/volume_attachments/4cbb38bc-57d5-4121-a796-d5b10cf0810a\",\n\"id\": \"<4cbb38bc-57d5-4121-a796-d5b10cf0810aAttachment ID>\",\n\"instance\": {\n\"crn\": \"crn:...]\",\n\"href\": \"https://us-south.iaas.cloud.ibm.com/v1/instances/8f06378c-ed0e-481e-b98c-9a6dfbee1ed5\",\n\"id\": \"8f06378c-ed0e-481e-b98c-9a6dfbee1ed5\",\n\"name\": \"my-instance-1\"\n},\n\"name\": \"my-volume-attachment-1\",\n\"type\": \"data\"\n}],\n\"zone\": {\n\"href\": \"https://us-south.iaas.cloud.ibm.com/v1/regions/us-south/zones/us-south-2\",\n\"name\": \"us-south-2\"\n}\n}\n\n\n\n\n\n Expand block storage volumes with Terraform \n\nTo increase the capacity of a volume, use the ibm_is_volume resource. When applied, the following example updates the capacity to 8,000 GB.\n\nresource \"ibm_is_volume\" \"storage\" {\nname = \"demo-volume-update\"\nsize = 8000\nprofile = \"general-purpose\"\nzone = \"us-south-2\"\n}", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-expanding-block-storage-volumes&interface=ui"}]}
{"task_id": "ddbbbe7ea13560c5768639207e1ca604<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16530-3231-5337", "score": 14.624652, "text": "\n* The source document contains a split verb that you want to annotate. How do you annotate noncontiguous text as a single entity type? You can annotate each entity mention, and identify them as being related to each other by using a relation mention.\n\n[EVENT_ANSWER] [EVENT_ANSWER]\n\nAll of the phones were ringing, but he knew he should [pick] the red phone [up] first.\n\n^----splitType-----^\n\n\n\n* Avoid overlapping mentions, which are two different entity type labels that are applied to a single phrase in a document. For example, given the sentence, She donated her father's journals to the JFK Library., you would overlap mentions if you annotate JFK=PERSON and JFK Library=LOCATION for the single phrase JFK Library. The use of the term is more about the library than the person in this sentence, so only the latter annotation should be applied.\n\nDecoding such structures requires multiple parallel invocations of a machine learning model because mention detection only looks for a single label or no label on each word token.\n* Determine how the team will handle lists and plurals in running text. For example, the KLUE type system has PERSON and PEOPLE entity types that distinguish the singular from the plural. You can choose to annotate the list Barack, Michelle, Malia, and Sasha Obama, in one of the following ways:\n\n\n\n* Annotate each item in the list as a singular entity mention (Barack, Michelle, Malia, and Sasha Obama are each a PERSON mention)\n* Annotate the whole phrase as one plural entity mention (Barack, Michelle, Malia, and Sasha Obama is a single PEOPLE mention).\n\n\n\nNo one approach is necessarily better than the other. Just be sure that your team chooses one of them and applies it consistently to any lists that occur in the documents.\n* A coreference is used when mentions refer to the same real-world entity. Relations are used between distinct entities. So, no two mentions should be connected by both coreference and a relation.\n\n\n\n\n\n\n\n Annotation with the ground truth editor \n\nWhen a human annotator annotates a document, the document is opened in the ground truth editor.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-user-guide"}, {"document_id": "ibmcld_16456-3231-5337", "score": 14.624652, "text": "\n* The source document contains a split verb that you want to annotate. How do you annotate noncontiguous text as a single entity type? You can annotate each entity mention, and identify them as being related to each other by using a relation mention.\n\n[EVENT_ANSWER] [EVENT_ANSWER]\n\nAll of the phones were ringing, but he knew he should [pick] the red phone [up] first.\n\n^----splitType-----^\n\n\n\n* Avoid overlapping mentions, which are two different entity type labels that are applied to a single phrase in a document. For example, given the sentence, She donated her father's journals to the JFK Library., you would overlap mentions if you annotate JFK=PERSON and JFK Library=LOCATION for the single phrase JFK Library. The use of the term is more about the library than the person in this sentence, so only the latter annotation should be applied.\n\nDecoding such structures requires multiple parallel invocations of a machine learning model because mention detection only looks for a single label or no label on each word token.\n* Determine how the team will handle lists and plurals in running text. For example, the KLUE type system has PERSON and PEOPLE entity types that distinguish the singular from the plural. You can choose to annotate the list Barack, Michelle, Malia, and Sasha Obama, in one of the following ways:\n\n\n\n* Annotate each item in the list as a singular entity mention (Barack, Michelle, Malia, and Sasha Obama are each a PERSON mention)\n* Annotate the whole phrase as one plural entity mention (Barack, Michelle, Malia, and Sasha Obama is a single PEOPLE mention).\n\n\n\nNo one approach is necessarily better than the other. Just be sure that your team chooses one of them and applies it consistently to any lists that occur in the documents.\n* A coreference is used when mentions refer to the same real-world entity. Relations are used between distinct entities. So, no two mentions should be connected by both coreference and a relation.\n\n\n\n\n\n\n\n Annotation with the ground truth editor \n\nWhen a human annotator annotates a document, the document is opened in the ground truth editor.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-user-guide"}, {"document_id": "ibmcld_16490-12236-14623", "score": 13.609131, "text": "\nHuman annotators can sometimes be thorough about labeling entity type mentions, but be less diligent about annotating relation types and coreferences. For any key types that have a low percentage of corpus density, you might want to focus on finding more annotations of those type in the source documents. But, don't worry too much about coreference and relation accuracy if mention accuracy is deficient. Relation mentions between entities and coreferences of entities cannot be accurate unless entity mentions are accurate to begin with.\n* Fix human annotations\n\nCheck to see whether your training data is consistently and fully annotated. A machine learning model learns from your ground truth annotations. For example, if a sentence contains the phrase Obama family, and you label \"Obama\" as PERSON in one sentence and \"Obama family\" as PEOPLE in another sentence, the inconsistency means that the machine learning model cannot learn the correct annotation. Likewise, if you label \"Obama\" as PERSON in one sentence but do not label his name at all in another sentence, the annotation effort is incomplete and the machine learning model will be improperly trained. This type of inconsistent and partial labeling is sometimes referred to as type confusion. In most cases, just the act of having multiple human annotators review an overlapping set of documents will surface occurrences of type confusion-related mistakes. Pay attention to the issues that surface during document conflict resolution because they can provide insight into deeper issues with the type system itself. If there is no room to further improve or refine the type system, then it might be necessary to update the annotation guidelines and include examples. You can provide illustrations of common mistakes and how to annotate mentions properly under a given set of circumstances.\n\nAnother indicator of annotation inconsistency is if you have enough annotations, but the corpus density is low. Density can be impacted when a mention that is significant in the domain literature occurs often, but is annotated as different types across the document set.\n\nLow precision is often an indication that you need to improve annotation consistency. To do so, review the annotation guidelines, better train the human annotators, and ensure that human annotators are working in concert and not in isolation from one another.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-evaluate-ml"}, {"document_id": "ibmcld_16425-12266-14653", "score": 13.609131, "text": "\nHuman annotators can sometimes be thorough about labeling entity type mentions, but be less diligent about annotating relation types and coreferences. For any key types that have a low percentage of corpus density, you might want to focus on finding more annotations of those type in the source documents. But, don't worry too much about coreference and relation accuracy if mention accuracy is deficient. Relation mentions between entities and coreferences of entities cannot be accurate unless entity mentions are accurate to begin with.\n* Fix human annotations\n\nCheck to see whether your training data is consistently and fully annotated. A machine learning model learns from your ground truth annotations. For example, if a sentence contains the phrase Obama family, and you label \"Obama\" as PERSON in one sentence and \"Obama family\" as PEOPLE in another sentence, the inconsistency means that the machine learning model cannot learn the correct annotation. Likewise, if you label \"Obama\" as PERSON in one sentence but do not label his name at all in another sentence, the annotation effort is incomplete and the machine learning model will be improperly trained. This type of inconsistent and partial labeling is sometimes referred to as type confusion. In most cases, just the act of having multiple human annotators review an overlapping set of documents will surface occurrences of type confusion-related mistakes. Pay attention to the issues that surface during document conflict resolution because they can provide insight into deeper issues with the type system itself. If there is no room to further improve or refine the type system, then it might be necessary to update the annotation guidelines and include examples. You can provide illustrations of common mistakes and how to annotate mentions properly under a given set of circumstances.\n\nAnother indicator of annotation inconsistency is if you have enough annotations, but the corpus density is low. Density can be impacted when a mention that is significant in the domain literature occurs often, but is annotated as different types across the document set.\n\nLow precision is often an indication that you need to improve annotation consistency. To do so, review the annotation guidelines, better train the human annotators, and ensure that human annotators are working in concert and not in isolation from one another.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-ml"}, {"document_id": "ibmcld_16454-13234-15485", "score": 12.900478, "text": "\nAs you get started, define 10 to 40 entity types and relation types. Stay to the lower end of the range if the human annotators who will be working on the workspace are not highly specialized in the field. Do not define more than 50.\n\nPlan to spend a good amount of time defining the type system before your team begins any human annotation tasks. When the team does start to annotate documents, begin with a small set, perhaps no more than 50. Annotate only mentions initially, examine the results, and refine your annotation guidelines and the type system as needed. When you're satisfied with the results of mention annotation, move on to annotate relations and coreferences.\n\nWhile fundamental work is underway to define a set of entity types and mention-annotation guidelines, avoid putting a lot of effort into annotating relation mentions. Mention changes will undo relation annotation work. Do take some time to define a set of relation types and their allowable entity type pairs so that relation type needs are taken into consideration before the entity type inventory is finalized.\n\nExpect the type system to evolve with the experience of people trying to annotate to it. If you revise the type system after you create human annotation tasks, you must decide whether to apply the changes to each task. If you apply the changes, human annotators will have to revisit the documents that they annotated previously.\n\nWhen you test the model, you can review statistics that show how frequently the entity types and relation types occur in your sample documents. Be sure to review these statistics. To ensure that your application receives enough context to accurately annotate large collections of documents, your test data must include a large sampling of the most important entity types and relation types.\n\n> Important: After you train your first model, you will likely need to make modifications based on the performance statistics. However, to create a reliable statistical model for machine annotation, you want the type system to be as close to final as possible before you begin large-scale annotation tasks.\n\n\n\n\n\n When to define roles \n\nUsing roles enables you to define more precise entity types.\n\nEvery entity that you add has a role.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-typesystem"}, {"document_id": "ibmcld_16410-8324-10312", "score": 12.802545, "text": "\nInter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).\n\n\n\nAn annotation set that you plan to use to train a machine learning model must contain at least 10 annotated documents.\n\n\n\n1. Select a user name from the list of human annotators.\n2. Name the annotation set.\n\nAs a good practice for evaluating a human annotator's work as the workspace progresses, you might want to create annotation set names that identify the human annotator assigned to the set.\n\nYou cannot change the annotation set name after the set is created.\n3. Click Generate.\n\n\n\n6. A list of available annotation sets is displayed under Available Sets, along with the names of the human annotators assigned to them. To add available sets to your annotation task, click Add to task.\n7. Make sure that all of the annotation sets that you want to include in the task appear under Selected Sets, then click Save to create the task.\n\n\n\n\n\n\n\n What to do next \n\nAfter the task is created, you can return to the Annotation Tasks tab on the Machine Learning Model > Annotations page to view the progress of each human annotator. Also, you can complete the following tasks:\n\n\n\n* Check approved documents that overlap between annotation sets to resolve annotation conflicts.\n* Open a task to add annotation sets to it. Ensure that the annotation sets that you add include documents that overlap with documents in the original annotation sets.\n\n\n\nFrom the Settings tab of the main navigation, you can specify the following information:\n\n\n\n* Specify preferences for using colors and keyboard shortcuts in the ground truth editor.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"}, {"document_id": "ibmcld_16417-13232-15412", "score": 12.391596, "text": "\nAfter human annotators complete their annotation tasks, they must submit their completed annotation sets for review. When you evaluate the inter-annotator agreement scores, you can see how different pairs of annotators annotated the same document. If the inter-annotator agreement score is acceptable, you approve the annotation set. If a document does not overlap across annotation sets in the task, the annotations in the approved document are promoted to ground truth. If a document overlaps across annotation sets, you should adjudicate the document and resolve any annotation conflicts that exist before promoting the annotations to ground truth.\n\nFor example, when you adjudicate a document, you might see that one annotator annotated the mention Barack Obama with the entity type PeoplePerson. Another annotator annotated the same string of text as two mentions, assigning the entity type Person to Barack and the entity type Person to Obama. To help ensure proper training of the machine learning model, you should resolve this inconsistency.\n\nKnowledge Studio supports the ability to adjudicate between two annotation sets at a time, or between an annotation set and the current ground truth. If a document overlaps across more than two annotation sets, adjudicate the two annotation sets that you have the greatest confidence in (perhaps because you have greater confidence in the human annotators) to determine ground truth for the document. And then adjudicate the rest of the annotation sets based on the results of the initial adjudication.\n\n\n\n\n\n Procedures \n\nTo view overlapping documents and resolve conflicts:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select the Machine Learning Model > Annotations page. Click the Annotation Tasks tab and open the task that you want to evaluate.\n3. Confirm that at least two annotation sets are in In conflict status.\n4. Click Check Overlapping Documents for Conflicts. The documents that are in conflict are listed.\n5. If you want to ignore the conflicts in an overlapping document and promote the annotations to ground truth without adjudicating them, click Accept.\n6.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"}, {"document_id": "ibmcld_16481-13220-15399", "score": 12.384482, "text": "\nAfter human annotators complete their annotation tasks, they must submit their completed annotation sets for review. When you evaluate the inter-annotator agreement scores, you can see how different pairs of annotators annotated the same document. If the inter-annotator agreement score is acceptable, you approve the annotation set. If a document does not overlap across annotation sets in the task, the annotations in the approved document are promoted to ground truth. If a document overlaps across annotation sets, you should adjudicate the document and resolve any annotation conflicts that exist before promoting the annotations to ground truth.\n\nFor example, when you adjudicate a document, you might see that one annotator annotated the mention Barack Obama with the entity type PeoplePerson. Another annotator annotated the same string of text as two mentions, assigning the entity type Person to Barack and the entity type Person to Obama. To help ensure proper training of the machine learning model, you should resolve this inconsistency.\n\nKnowledge Studio supports the ability to adjudicate between two annotation sets at a time, or between an annotation set and the current ground truth. If a document overlaps across more than two annotation sets, adjudicate the two annotation sets that you have the greatest confidence in (perhaps because you have greater confidence in the human annotators) to determine ground truth for the document. And then adjudicate the rest of the annotation sets based on the results of the initial adjudication.\n\n\n\n\n\n Procedure \n\nTo view overlapping documents and resolve conflicts:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select the Machine Learning Model > Annotations page. Click the Annotation Tasks tab and open the task that you want to evaluate.\n3. Confirm that at least two annotation sets are in In conflict status.\n4. Click Check Overlapping Documents for Conflicts. The documents that are in conflict are listed.\n5. If you want to ignore the conflicts in an overlapping document and promote the annotations to ground truth without adjudicating them, click Accept.\n6.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"}, {"document_id": "ibmcld_16468-8522-10510", "score": 12.324977, "text": "\nIf no annotation sets are available, click Create Annotation Sets.\n\n\n\n1. For the base set, select the document set or annotation set that you want to divide into annotation sets.\n2. For the overlap value, specify the percentage of documents that you want to include in each annotation set. Inter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).\n\n\n\nAn annotation set that you plan to use to train a machine learning model must contain at least 10 annotated documents.\n\n\n\n1. Select a user name from the list of human annotators.\n2. Name the annotation set.\n\nAs a good practice for evaluating a human annotator's work as the workspace progresses, you might want to create annotation set names that identify the human annotator assigned to the set. You cannot change the annotation set name after the set is created.\n\nThe maximum size of the annotation set name is 256 characters.\n3. Click Generate.\n\n\n\n6. A list of available annotation sets is displayed under Available Sets, along with the names of the human annotators assigned to them. To add available sets to your annotation task, click Add to task.\n7. Make sure that all of the annotation sets that you want to include in the task appear under Selected Sets, then click Save to create the task.\n\n\n\n\n\n\n\n What to do next \n\nAfter the task is created, you can return to the Annotation Tasks tab on the Machine Learning Model > Annotations page to view the progress of each human annotator. Also, you can complete the following tasks:\n\n\n\n* Check approved documents that overlap between annotation sets to resolve annotation conflicts.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents"}, {"document_id": "ibmcld_16481-16625-18829", "score": 12.20837, "text": "\nIf annotation guidelines were previously connected to the project, and you want help with choosing the correct annotation to apply, click View Guidelines. Depending on the access permissions set up on the site where the guidelines are hosted, you might be able to update the guidelines after you open them, for example, to add clarifications and examples.\n10. To apply a different entity type to a mention, reject the current annotation, select the mention, such as Barack Obama, and then select the correct entity type, such as Person.\n11. Continue accepting, rejecting, and revising other conflicts in the sentence. After you resolve all conflicts in a sentence, click the Select all annotations link and then click Accept.\n12. Click the arrow icon to go to the next sentence. Continue until all mention conflicts in the document are resolved.\n\nTo save your work in progress, or to temporarily suspend the current adjudication session, click Save at any time. If you want to discard all changes that you made, click Discard. If you saved the previous adjudication session, and you are ready to resume adjudication, click Resume to start adjudicating conflicts where you last stopped. If you discarded the previous adjudication session, you must start a new adjudication session.\n13. After resolving mention conflicts, switch the adjudication mode to resolve any conflicts that occur between relation annotations and coreference chain annotations.\n\n\n\n* Resolving conflicts in relation mode is similar to how you resolve conflicts for mentions. You resolve conflicts on a sentence-by-sentence basis.\n* Coreference chains can exist across multiple sentences. When you move to coreference mode, the system lists the coreference chains that were created by each human annotator in a pane on the right. Select the chains that you want to adjudicate and then click Reject Chain or Accept Chain to reject or accept annotations in a chain, or click Merge Chains to merge the two chains. If you want to remove a mention from a coreference chain, click the delete icon (-) in the label above the mention in the document area.\n\n\n\n14. After all conflicts in the document are resolved, click Promote to Ground Truth.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"}]}
{"task_id": "ddbbbe7ea13560c5768639207e1ca604<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16463-4148-5042", "score": 18.793386, "text": "\nAfter the pre-annotation is complete, create a human annotation task that includes the annotation set you created.\n\nFor more information about creating an annotation task, see [Annotation setup](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents).\n7. To view the annotations that were applied by the machine learning model to the new documents, open the annotation task.\n\nBecause the new documents were pre-annotated with the machine learning model, human annotation requires less time. For more information about adding annotations by human annotators, see [Annotating documents](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-user-guide).\n\n\n\n\n\n\n\n Results \n\nBy using your machine learning model to pre-annotate new document sets, you can expedite human annotation tasks for those documents.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutboot_intro"}, {"document_id": "ibmcld_16444-7-2064", "score": 18.23504, "text": "\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"}, {"document_id": "ibmcld_16507-7-2044", "score": 18.130745, "text": "\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Natural Language Understanding\n\nA pre-annotator that you can use to find mentions of entities in your documents automatically. If your source documents have general knowledge subject matter, then this pre-annotator is a good choice for you. If you are working with highly specialized documents that focus on a specific field, such as patent law research, for example, the dictionary pre-annotator or rule-based model might be a better choice.\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}, {"document_id": "ibmcld_16552-4166-4924", "score": 17.957819, "text": "\nFor more information about creating an annotation task, see [Annotation setup](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents).\n6. To view the annotations that were applied by the machine learning model to the new documents, open the annotation task.\n\nBecause the new documents were pre-annotated with the machine learning model, human annotation requires less time. For more information about adding annotations by human annotators, see [Annotating documents](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-user-guide).\n\n\n\n\n\n\n\n Results \n\nBy using your machine learning model to pre-annotate new document sets, you can expedite human annotation tasks for those documents.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutboot_intro"}, {"document_id": "ibmcld_16444-7346-9136", "score": 17.953741, "text": "\nHuman annotations are preserved even if this is selected.\n10. Select the check box for each document set that you want to pre-annotate and click Run.\n\nPre-annotation is applied to individual documents without regard for the various document sets or annotation sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\nRelated information:\n\n[Creating dictionaries](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-dictionaries)\n\n[Getting Started > Adding a dictionary](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutintrowks_tutless4)\n\n\n\n\n\n\n\n Pre-annotating documents with the machine learning model \n\nYou can use an existing machine learning model to pre-annotate documents that you add to your corpus.\n\n\n\n About this task \n\nAfter 10 to 30 documents are annotated, a machine learning model can be trained on the data. Don't use such a minimally trained model in a production. However, you can use the model to pre-annotate documents to help speed up the human annotation of subsequent documents. For example, if you add documents to the corpus after you train a machine learning model, you can use the model to pre-annotate the new document sets. Never run a pre-annotator on the same documents that have been annotated by a person. Pre-annotators remove human annotation.\n\n\n\n\n\n Procedure \n\nTo use an existing machine learning model to pre-annotate documents:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Go to the Machine Learning Model > Pre-annotation page.\n3. Click Run Pre-annotators.\n4. Select Machine Learning Model, and then click Next.\n5.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"}, {"document_id": "ibmcld_16444-1600-3658", "score": 17.745968, "text": "\nHuman annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\nYou can run a pre-annotator on documents that were added to the ground truth as part of the current workspace. Annotations that were added to the documents, reviewed, accepted, and promoted to ground truth within the current workspace are not stripped out.\n\n\n\n\n\n Running multiple pre-annotators \n\nKnowledge Studio allows you to run multiple pre-annotators at once. First, you need to prepare the pre-annotation methods that you want to use. For more information, see the following sections.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"}, {"document_id": "ibmcld_16563-9481-11146", "score": 17.523987, "text": "\nThis pre-annotation is correct, so it does not need to be modified.\n\n![This screen capture shows an open document with an existing pre-annotation for \"IBM\".](images/wks_tut_preannotation.png \"This screen capture shows an open document with an existing pre-annotation for \"IBM\".\")\n6. Annotate a mention:\n\n\n\n1. Click the Entity tab.\n2. In the document body, select the text Thomas Watson.\n3. In the list of entity types, click PERSON. The entity type PERSON is applied to the selected mention.\n\n![This screen capture shows the \"PERSON\" entity type applied to the mention, \"Thomas Watson\".](images/wks_tut_annotatemention3.png \"This screen capture shows the \"PERSON\" entity type applied to the mention, \"Thomas Watson\".\")\n\n\n\n7. Annotate a relation:\n\n\n\n1. Click the Relation tab.\n2. Select the Thomas Watson and IBM mentions (in that order). To select a mention, click the entity type label above the text.\n3. In the list of relation types, click founderOf. The two mentions are connected with a founderOf relationship.\n\n![This screen capture shows two mentions connected by the relation type, \"founderOf\".](images/wks_tut_annotaterelation.png \"This screen capture shows two mentions connected by the relation type, \"founderOf\".\")\n\n\n\n8. From the status menu, select Completed, and then click the Save button.\n9. Click Open document list to return to the list of documents for this task and click Submit All Documents to submit the documents for approval.\n\nIn a realistic situation, you would create many more annotations and complete all the documents in the set before submitting.\n10. Close this annotation set, and then open the other annotation set in the Test task.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"}, {"document_id": "ibmcld_16507-9193-11335", "score": 17.512114, "text": "\nClick Run.\n\nIf you are doing a validation check of the pre-annotator, then open the annotated documents and review the annotations that were added. Make sure a sufficient number of accurate annotations were created. If the annotations are accurate, then you can run the annotator again on more and larger document sets. If the annotations are not accurate, then consider mapping different Natural Language Understanding entity types to your types. If the types do not naturally overlap, then the Natural Language Understanding pre-annotator is not the best pre-annotator for you to use.\n\nPre-annotation is applied to individual documents without regard for the various document sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\n\n\n\n\n Results \n\nGround truth that is produced by documents that were pre-annotated by the Natural Language Understanding service cannot be used directly outside of Knowledge Studio. You can download the ground truth (in non-readable form) to move it from one Knowledge Studio workspace to another. And you can continue to develop the ground truth and use it to build a machine learning model or rule-based model that can be deployed for use in services outside of Knowledge Studio.\n\nDocuments that were pre-annotated with Natural Language Understanding are obscured into a non-readable format when they are downloaded. But, all annotations in those documents are obscured, including annotations that were added to the documents by human annotators.\n\nRelated information:\n\n[Natural Language Understanding](https://www.ibm.com/watson/services/natural-language-understanding/)\n\n\n\n\n\n\n\n Pre-annotating documents with a dictionary \n\nTo help human annotators get started with their annotation tasks, you can create a dictionary and use it to pre-annotate documents that you add to the corpus.\n\n\n\n About this task \n\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}, {"document_id": "ibmcld_16507-1455-3632", "score": 17.471052, "text": "\nThis choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\n\n\n\n\n Running multiple pre-annotators", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}, {"document_id": "ibmcld_16507-12419-14261", "score": 17.28854, "text": "\nAdd entries for the dictionary or upload a file that contains dictionary terms.\n6. Go to the Machine Learning Model > Pre-annotation page.\n7. Click Run Pre-annotators.\n8. Select Dictionaries, and then click Next.\n9. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n10. Select the check box for each document set that you want to pre-annotate and click Run.\n\nPre-annotation is applied to individual documents without regard for the various document sets or annotation sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\nRelated information:\n\n\n\n* [Creating dictionaries](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-dictionaries)\n* [Getting Started > Adding a dictionary](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutintrowks_tutless4)\n\n\n\n\n\n\n\n\n\n Pre-annotating documents with the machine learning model \n\nYou can use an existing machine learning model to pre-annotate documents that you add to your corpus.\n\n\n\n About this task \n\nAfter 10 to 30 documents are annotated, a machine learning model can be trained on the data. Don't use such a minimally trained model in production. However, you can use the model to pre-annotate documents to help speed up the human annotation of subsequent documents. For example, if you add documents to the corpus after you train a machine learning model, you can use the model to pre-annotate the new document sets. Never run a pre-annotator on the same documents that have been annotated by a person. Pre-annotators remove human annotation.\n\n\n\n\n\n Procedure", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}]}
{"task_id": "ddbbbe7ea13560c5768639207e1ca604<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16563-9481-11146", "score": 17.011047, "text": "\nThis pre-annotation is correct, so it does not need to be modified.\n\n![This screen capture shows an open document with an existing pre-annotation for \"IBM\".](images/wks_tut_preannotation.png \"This screen capture shows an open document with an existing pre-annotation for \"IBM\".\")\n6. Annotate a mention:\n\n\n\n1. Click the Entity tab.\n2. In the document body, select the text Thomas Watson.\n3. In the list of entity types, click PERSON. The entity type PERSON is applied to the selected mention.\n\n![This screen capture shows the \"PERSON\" entity type applied to the mention, \"Thomas Watson\".](images/wks_tut_annotatemention3.png \"This screen capture shows the \"PERSON\" entity type applied to the mention, \"Thomas Watson\".\")\n\n\n\n7. Annotate a relation:\n\n\n\n1. Click the Relation tab.\n2. Select the Thomas Watson and IBM mentions (in that order). To select a mention, click the entity type label above the text.\n3. In the list of relation types, click founderOf. The two mentions are connected with a founderOf relationship.\n\n![This screen capture shows two mentions connected by the relation type, \"founderOf\".](images/wks_tut_annotaterelation.png \"This screen capture shows two mentions connected by the relation type, \"founderOf\".\")\n\n\n\n8. From the status menu, select Completed, and then click the Save button.\n9. Click Open document list to return to the list of documents for this task and click Submit All Documents to submit the documents for approval.\n\nIn a realistic situation, you would create many more annotations and complete all the documents in the set before submitting.\n10. Close this annotation set, and then open the other annotation set in the Test task.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"}, {"document_id": "ibmcld_16507-1455-3632", "score": 16.584814, "text": "\nThis choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\n\n\n\n\n Running multiple pre-annotators", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}, {"document_id": "ibmcld_06981-1673-3761", "score": 16.470497, "text": "\nLater, you can limit the search to return content from only the tips field.\n\nOr maybe you have extra large documents that contain subsections. You can teach the SDU model to recognize these subsections, and then split the large document into multiple, smaller, and easier-to-manage documents that begin with one of these subsections.\n* The best way to prepare a collection for use in Conversational Search projects is to identify discrete question-and-answer pairs. You can use the SDU tool to find and annotate them. If you configure the project to contain answers in an answer field, you must update the search configuration in Watson Assistant to get the body of the response from the custom answer field.\n* A pretrained SDU model is applied to Document Retrieval for Contracts projects automatically. The pretrained SDU model knows how to recognize terms and concepts that are significant to contracts. As a result, you cannot apply a user-trained SDU model to this project type, but you also don't need to.\n* The SDU tool is rarely used with Content Mining projects.\n\n\n\nYou can use the SDU tool to annotate the following file types only:\n\n\n\n* Image files (PNG, TIFF, JPG)\n* Microsoft PowerPoint\n* Microsoft Word\n* PDF\n\n\n\nFor a complete list of file types that Discovery supports, see [Supported file types](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-collectionssupportedfiletypes).\n\nThe Smart Document Understanding tool uses optical character recognition (OCR) to extract text from images in the files that it analyzes. Images must meet the minimum quality requirements that are supported by OCR. For more information, see [Optical character recognition](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-collectionsocr).\n\nThe tool cannot read documents with the following characteristics; remove them from your collection before you begin:\n\n\n\n* Documents that appear to have text that overlays other text are considered double overlaid and cannot be annotated.\n* Documents that contain multiple columns of text on a single page cannot be annotated.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-configuring-fields"}, {"document_id": "ibmcld_16507-9193-11335", "score": 16.411684, "text": "\nClick Run.\n\nIf you are doing a validation check of the pre-annotator, then open the annotated documents and review the annotations that were added. Make sure a sufficient number of accurate annotations were created. If the annotations are accurate, then you can run the annotator again on more and larger document sets. If the annotations are not accurate, then consider mapping different Natural Language Understanding entity types to your types. If the types do not naturally overlap, then the Natural Language Understanding pre-annotator is not the best pre-annotator for you to use.\n\nPre-annotation is applied to individual documents without regard for the various document sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\n\n\n\n\n Results \n\nGround truth that is produced by documents that were pre-annotated by the Natural Language Understanding service cannot be used directly outside of Knowledge Studio. You can download the ground truth (in non-readable form) to move it from one Knowledge Studio workspace to another. And you can continue to develop the ground truth and use it to build a machine learning model or rule-based model that can be deployed for use in services outside of Knowledge Studio.\n\nDocuments that were pre-annotated with Natural Language Understanding are obscured into a non-readable format when they are downloaded. But, all annotations in those documents are obscured, including annotations that were added to the documents by human annotators.\n\nRelated information:\n\n[Natural Language Understanding](https://www.ibm.com/watson/services/natural-language-understanding/)\n\n\n\n\n\n\n\n Pre-annotating documents with a dictionary \n\nTo help human annotators get started with their annotation tasks, you can create a dictionary and use it to pre-annotate documents that you add to the corpus.\n\n\n\n About this task \n\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}, {"document_id": "ibmcld_16468-3297-5708", "score": 16.41042, "text": "\n* Involving domain subject matter experts to create the following resources, or to identify existing resources that can be re-used or modified for your domain:\n\n\n\n* Annotation guidelines and examples to help human annotators learn how words and passages in your domain content are to be annotated.\n* Type systems that define the domain-specific types (objects) and features (data classifications) that can be discovered in your domain content through text analysis. The type system controls the types of annotations that a human annotator can add to documents.\n* Dictionaries of terms that are to be treated as equivalent terms in your domain content.\n\n\n\n* Creating a corpus of documents that are representative of your domain content.\n* Pre-annotating documents based on the dictionaries that you add to a Knowledge Studio workspace. After you create a machine learning model, you can use the model to pre-annotate new documents that you add to the corpus. Pre-annotation is a process of machine-annotating a document to the extent possible before a machine learning model is available to do so. Pre-annotation can reduce human-annotation labor by replacing some human annotation creation with mere verification of the correctness of machine annotation.\n* Dividing documents among human annotators, who then use the IBM Watson\u00ae Knowledge Studio ground truth editor tool to manually add annotations to small sets of documents.\n* Comparing the human annotation results and resolving conflicts. Adjudication in this phase is needed to ensure accurate and consistently annotated documents are promoted to ground truth, where they can be used to train and test a machine learning model.\n\n\n\n\n\n\n\n Model development \n\nThis stage refers to the use of Knowledge Studio tools to create a model. After establishing ground truth, the human annotation results can be used to train an algorithm for automatically adding annotations to large collections of documents, such as collections that include millions of documents.\n\n\n\n\n\n Model evaluation \n\nThis stage refers to the use of Knowledge Studio tools to refine the model and improve performance. The results generated by the model are evaluated against a test set of ground truth documents. Accuracy analysis identifies the causes of annotation errors. Headroom analysis helps you assess which errors require focus and where model refinements can yield the greatest impact.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents"}, {"document_id": "ibmcld_16444-1600-3658", "score": 15.977006, "text": "\nHuman annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\nYou can run a pre-annotator on documents that were added to the ground truth as part of the current workspace. Annotations that were added to the documents, reviewed, accepted, and promoted to ground truth within the current workspace are not stripped out.\n\n\n\n\n\n Running multiple pre-annotators \n\nKnowledge Studio allows you to run multiple pre-annotators at once. First, you need to prepare the pre-annotation methods that you want to use. For more information, see the following sections.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"}, {"document_id": "ibmcld_16444-7-2064", "score": 15.638199, "text": "\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"}, {"document_id": "ibmcld_16507-7-2044", "score": 15.551141, "text": "\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Natural Language Understanding\n\nA pre-annotator that you can use to find mentions of entities in your documents automatically. If your source documents have general knowledge subject matter, then this pre-annotator is a good choice for you. If you are working with highly specialized documents that focus on a specific field, such as patent law research, for example, the dictionary pre-annotator or rule-based model might be a better choice.\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}, {"document_id": "ibmcld_16421-12667-13618", "score": 15.498014, "text": "\nEach surface form must be 256 or fewer characters in length. You can change which of the surface forms is used as the lemma. For example, the lemma IBM might have surface forms like IBM Corp. and International Business Machines, Inc..\n5. Select the appropriate part of speech for each lemma and surface form in the dictionary.\n\nThe part of speech information is used by the tokenizer, and during pre-annotation.\n6. Click Save to store your changes.\n\n\n\n\n\n\n\n What to do next \n\nRun the pre-annotator, which uses the dictionaries that you created to do a preliminary pass of the source documents, and adds annotations to them.\n\nRelated tasks:\n\n[Pre-annotating documents with a dictionary](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannot)\n\nRelated reference:\n\n[Language support](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-language-support)", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-dictionaries"}, {"document_id": "ibmcld_16507-13849-15752", "score": 15.477912, "text": "\nHowever, you can use the model to pre-annotate documents to help speed up the human annotation of subsequent documents. For example, if you add documents to the corpus after you train a machine learning model, you can use the model to pre-annotate the new document sets. Never run a pre-annotator on the same documents that have been annotated by a person. Pre-annotators remove human annotation.\n\n\n\n\n\n Procedure \n\nTo use an existing machine learning model to pre-annotate documents:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Go to the Machine Learning Model > Pre-annotation page.\n3. Click Run Pre-annotators.\n4. Select Machine Learning Model, and then click Next.\n5. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n6. Select the check box for each document set that you want to pre-annotate and click Run.\n\nPre-annotation is applied to individual documents without regard for the various document sets or annotation sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\n\n\n\n\n\n\n Pre-annotating documents with the rule-based model \n\nYou can use an existing rule-based model to pre-annotate documents that you add to your corpus.\n\n\n\n Procedure \n\nTo use the rule-based model to pre-annotate documents, complete the following steps:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Go to the Machine Learning Model > Pre-annotation page.\n3. Click the overflow menu button in the Rule-based Model row in the page, then click Map entity types and classes to map entity types that you defined in the Knowledge Studio type system to one or more rule-based model classes.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}]}
{"task_id": "ddbbbe7ea13560c5768639207e1ca604<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13464-7165-8908", "score": 10.3981695, "text": "\nTS_CROSS_CORRELATION(DoubleTimeSeries, DoubleTimeSeries)\n: Output: DoubleArray\n: Use a [cross correlation](https://en.wikipedia.org/wiki/Cross-correlation) algorithm to return a measure of the similarity of two time series.\n\nTS_SEG_CROSS_CORRELATION(DoubleSegmentTimeSeries, DoubleSegmentTimeSeries)\n: Output: DoubleArrayTimeSeries\n: Use a [cross correlation](https://en.wikipedia.org/wiki/Cross-correlation) algorithm to return a measure of the similarity of each pair of corresponding segments in the two input time series. Each timetick in the output time series is the timetick of the corresponding segment.\n\nTS_AVG(DoubleTimeSeries)\n: Output: Double\n: Returns the average of the values of the input time series.\n\nTS_SEG_AVG(DoubleSegmentTimeSeries)\n: Output: DoubleTimeSeries\n: Returns the average of the values of each segment of the input time series. Each timetick in the output time series is the timetick of the corresponding segment.\n\nTS_MIN(DoubleTimeSeries)\n: Output: Double\n: Returns the minimum value of the input time series.\n\nTS_SEG_MIN(DoubleSegmentTimeSeries)\n: Output: DoubleTimeSeries\n: Returns the minimum value of each segment of the input time series. Each timetick in the output time series is the timetick of the corresponding segment.\n\nTS_MAX(DoubleTimeSeries)\n: Output: Double\n: Returns the maximum value of the input time series.\n\nTS_SEG_MAX(DoubleSegmentTimeSeries)\n: Output: DoubleTimeSeries\n: Returns the maximum value of each segment of the input time series. Each timetick in the output time series is the timetick of the corresponding segment.\n\nTS_SUM(DoubleTimeSeries)\n: Output: Double\n: Returns the sum of the values of the input time series.\n\nTS_SEG_SUM(DoubleSegmentTimeSeries)\n: Output: DoubleTimeSeries", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-data_processing_functions"}, {"document_id": "ibmcld_07085-33522-35233", "score": 9.786726, "text": "\nThe trend indicator measures the increase ratio of the frequency of a given facet value for a given time interval compared to the expected average frequency. The excepted average frequency is calculated based on the changes in the past time interval frequencies of the given facet value, using a weighted arithmetic mean.If the standarized residual value is less than -2, the observed frequency is less than the expected frequency. If it is greater than 2, the observed frequency is greater than the expected frequency. If the standardized residual is greater or less than the expected frequency by 3 or more, then something unusual is happening and suggests that there might be an anomaly that is worth investigating.For example, the expected number of feedback submissions for the vanilla flavor in May is calculated from the number of feedback submissions that were received previously (from Jan to Apr). The result is 5.341. The actual number of feedback submissions in May is 10. The results indicate that the vanilla flavor got about twice the number of feedback submissions as expected. The standardized residual value is 2.016, which is greater than expected, but not unusually so. {\n\"aggregations\":\n{\n\"type\": \"trend\",\n\"facet\": \"term(flavor),\",\n\"time_segments\": \"timeslice(date, 1month)\",\n\"show_estimated_matching_results\": true,\n\"show_total_matching_documents\": true,\n\"results\":\n{\n\"aggregations\":\n{\n\"type\": \"term\",\n\"field\": \"flavor\",\n\"results\":\n{\n\"key\": \"vanilla\",\n\"matching_results\": 36,\n\"aggregations\":\n{\n\"type\": \"timeslice\",\n\"field\": \"date\",\n\"results\":\n{\n\"key\": 1577836800000,\n\"key_as_string\": \"2020-01-01T00:00:00.000Z\",\n\"matching_results\": 4,\n\"trend_indicator\": 0.0,\n\"total_matching_documents\": 7,", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-aggregations"}, {"document_id": "ibmcld_03036-7-2061", "score": 9.683983, "text": "\nMetrics overview \n\nThe Overview page provides a summary of the interactions between users and your assistant. You can view the amount of traffic for a given time period, as well as the intents and entities that were recognized most often in user conversations.\n\nThe Analytics page was introduced with version 1.5.0. The Analytics feature is supported only on clusters that are installed on Red Hat OpenShift 4.5 or later.\n\nUse the metrics to answer questions like:\n\n\n\n* What was the average number of conversations per week during the last month?\n* How often did customers need to go elsewhwere for support?\n* Which intents appeared most often last week?\n* Which entity values were recognized the most times during February?\n* Which days had the largest or smallest numbers of conversations in the last month?\n\n\n\nTo see metrics information, select Overview in the navigation bar.\n\n\n\n Controls \n\nYou can use the following controls to filter the information:\n\n\n\n* Time period control - Use this control to choose the period for which data is displayed. This control affects all data shown on the page: not just the number of conversations displayed in the graph, but also the statistics displayed along with the graph, and the lists of top intents and entities.\n\nThe statistics can cover a longer time period than the period for which logs of conversations are retained.\n\n![Time period control](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/oview-time.png)\n\nYou can choose whether to view data for a single day, a week, a month, or a quarter. In each case, the data points on the graph adjust to an appropriate measurement period. For example, when viewing a graph for a day, the data is presented in hourly values, but when viewing a graph for a week, the data is shown by day. A week always runs from Sunday through Saturday.\n\nYou can create custom time periods also, such as a week that runs from Thursday to the following Wednesday, or a month that begins on any date other than the first.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-overview"}, {"document_id": "ibmcld_00324-12617-14618", "score": 9.552653, "text": "\nMetrics with graphical views \n\nMetrics for an individual CDN are provided on the Overview tab of the customer portal for that CDN mapping. Two types of metrics are calculated from the CDN's usage: those that show the metrics over a time period as a graph, and those that are shown as aggregate values.\n\nFor metrics that display the change over a period of time as a graph, you can see three line graphs and a pie chart. The three line graphs are: Bandwidth, Hits by Mapping, and Hits by Type. They display the activity daily over the course of your specified timeframe. The graphs for Bandwidth and Hits by Mapping are single-line graphs, whereas the breakdown of Hits by Type shows a line for each of the hit types provided. The pie chart displays a regional breakdown of the bandwidth for a CDN mapping on a percentage basis.\n\nMetrics that are shown for aggregate values include Bandwidth Usage in GB, Total Hits to the CDN Edge server, and the Hit Ratio. Hit Ratio indicates that the percentage of times content is delivered by the Edge server, not through its origin. Hit ratio currently is shown as a function of all your CDN mappings, not just the one being viewed.\n\nBy default, both the aggregate numbers and the graphs default to show metrics for the last 30 days, but you can change this through the [IBM Cloud console](https://cloud.ibm.com/). Both categories can display metrics for 7-, 15-, 30-, 60-, or 90-day periods.\n\n\n\n\n\n Object storage origin support \n\nIBM Cloud CDN can be configured to serve content from an object storage endpoint by providing the endpoint, the bucket name, protocol, and port. Optionally, you can specify a list of file extensions to allow caching for files only with those extensions. All objects in the bucket must be set with anonymous read or public read access.\n\nFor more information, see [Accelerate delivery of static files using a CDN](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-static-files-cdn).\n\n\n\n\n\n Path-based CDN mappings", "title": "", "source": "https://cloud.ibm.com/docs/CDN?topic=CDN-about-content-delivery-networks-cdn-"}, {"document_id": "ibmcld_13406-6795-8870", "score": 9.529749, "text": "\nThe metrics indicate the progress and complexity of the engine's processing:\n\n\n\n* seen_by_engine is audio that the service has read and passed to the engine at least once.\n* received - seen_by_engine is audio that has been buffered at the service but has not yet been seen or processed by the engine.\n* The relationship between the times is received >= seen_by_engine >= transcription >= speaker_labels.\n\n\n\nThe following relationships can also be helpful in understanding the results:\n\n\n\n* The values of the received and seen_by_engine fields are greater than the values of the transcription and speaker_labels fields during speech recognition processing. The service must receive the audio before it can begin to process results.\n* The values of the received and seen_by_engine fields are identical when the service has finished processing the audio. The final values of the fields can be greater than the values of the transcription and speaker_labels fields by a fractional number of seconds.\n* The value of the speaker_labels field typically trails the value of the transcription field during speech recognition processing. The values of the transcription and speaker_labels fields are identical when the service has finished processing the audio.\n\n\n\n\n\n\n\n Processing metrics example: WebSocket interface \n\nThe following example shows the start message that is passed for a request to the WebSocket interface. The request enables processing metrics and sets the processing metrics interval to 0.25 seconds. It also sets the interim_results and speaker_labels parameters to true. The audio contains the simple message \"hello world long pause stop.\"\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio/flac',\nprocessing_metrics: true,\nprocessing_metrics_interval: 0.25,\ninterim_results: true,\nspeaker_labels: true\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\n}\n\nThe following example output shows the first few processing metrics results that the service returns for the request.\n\n{\n\"processing_metrics\": {\n\"processed_audio\": {", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-metrics"}, {"document_id": "ibmcld_09679-4-2116", "score": 9.410735, "text": "\n--------------------\n\n\n\n Collecting metrics \n\nYou can collect metrics from a number of platforms, orchestrators, and a wide range of applications such as Prometheus, JMX, StatsD, Kubernetes, and other application stacks, that are available in the IBM Cloud\u00ae, outside the IBM Cloud, or on-prem. You can also add more metrics by creating custom metrics and adding integrations.\n\n\n\n Metrics and labels \n\nA metric is a quantitative measure that has one or more labels to define its characteristics.\n\nUse metrics to analyze statistically data that has numerical values.\n\nA metric is represented by time series. A time-series is a unique combination of a metric name and label key-value pairs. For example: website_failedRequest |region='Asia', customer_ID='abc'. A data-point is the value generated for a time-series at a given point in time.\n\nLabels are classified as infrastructure labels and metric descriptor labels. Each metric has a set of pre-defined labels. For custom metrics, you can configure more labels.\n\nYou can use labels to identify and differentiate characteristics of a metric, for example,\n\n\n\n* You can group infrastructure objects into logical hierarchies.\n* You can filter out data.\n* You can split aggregated data into segments.\n\n\n\n\n\n\n\n Collecting default metrics by using the Monitoring agent \n\nWhen you configure a Monitoring agent, data for default metrics is automatically collected. These metrics include metadata that you can use to label, segment, and display metrics when you monitor them. You do not need additional instrumentation or configuration in your hosts to obtain metrics that are collected automatically by the agent to gain insight into what is happening in them.\n\nTo monitor your infrastructure, network, and applications with the IBM Cloud\u00ae Monitoring service, you can deploy Monitoring agents on supported hosts. The host determines the agent type that you can deploy. The agent type determines the metrics that are collected automatically for that host.\n\nTo start collecting default metrics, you must configure a Monitoring agent per environment that you want to monitor.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-about-collect-metrics"}, {"document_id": "ibmcld_00404-5279-6843", "score": 9.400277, "text": "\nAre metrics updated in real time? \n\nThe most recent metrics can be updated every 5 minutes, while other metrics are updated every 24 hours.\n\n\n\n\n\n What is the time interval when you select Most recent from the Time frame list? \n\nThe time range and time interval relationships are shown.\n\n\n\nTable 2: Time range and time interval relationships\n\n Time range Time interval (minutes) \n\n (0, 60] 1 \n (60, 300] 5 \n (300, 600] 10 \n (600, 900] 15 \n (900, 1200] 20 \n (1200, 1500] 25 \n (1500, 1800] 30 \n (1800, 2100] 35 \n (2100, 2400] 40 \n (2400, 2700] 45 \n (2700, 2880] 50 \n\n\n\nMath notation ( means \"does not include\" and ] means \"include\".\n\nExample: Start Date timestamp: 1611244800 End Date timestamp: 1611248400 Time range = (End Date timestamp - Start Date timestamp) / 60 = 300 Referring to the preceding table, the time interval is 5 minutes.\n\n\n\n\n\n Why does the last point sometimes drop suddenly in the Most Recent Metrics Report? \n\nZoom\n\n![Most recent interval](https://cloud.ibm.com/docs-content/v1/content/006fd22ab2811b7d19804c763a00568b3da4c03a/CDN/images/metrics-most-recent-interval.png)\n\nFigure 7: Most recent interval\n\nIn the report, each point is a sum of metric data over a time interval, and the interval is calculated by the preceding table. However, for the last point, the interval might be smaller than others. For example, in the bandwidth \"most recent\" report, the time interval is 5 minutes, and all the points are the sum of bandwidth over 5 minutes, except that the last one is only 1-minute bandwidth (January 21 04:00 PM to January 21 05:00 PM).", "title": "", "source": "https://cloud.ibm.com/docs/CDN?topic=CDN-metrics"}, {"document_id": "ibmcld_00405-0-1479", "score": 9.326812, "text": "\n\n\n\n\n\n\n  Metrics container \n\nThe SoftLayer_Container_Network_CdnMarketplace_Metrics collection contains the attributes that are used by our Metrics APIs. There are three possible values for the type attribute: PIECHART, LINEGRAPH, or TOTALS. The output for the rest of the attributes in this container depend on the type, which is described in further detail. All attributes except type are arrays. Not all attributes are used for all types.\n\nclassSoftLayer_Container_Network_CdnMarketplace_Metrics:\n\n\n\n*  type\n*  names\n*  totals\n*  percentage\n*  time\n*  xaxis\n*  yaxis\n*  yaxis2\n*  yaxis3\n*  yaxis4\n*  yaxis5\n*  yaxis6\n*  yaxis7\n*  yaxis8\n*  yaxis9\n*  yaxis10\n*  yaxis11\n*  yaxis12\n*  yaxis13\n*  yaxis14\n*  yaxis15\n*  yaxis16\n*  yaxis17\n*  yaxis18\n*  yaxis19\n*  yaxis20\n\n\n\nThe PIECHART type is for data that is sent to a pie chart. In this case, the only attributes that are used are: names, xaxis, and yaxis. The names attribute is an array containing the region names. The xaxis attribute contains the usage in GB, and yaxis1 is the test percentage.\n\nThe LINEGRAPH type is for data that will be sent to a line graph. In this case, the names array ontains the names of the metrics that are found in the xaxis, yaxis, yaxis2...yaxis20 attributes, and the actual data is in the corresponding arrays.\n\nIf type is TOTALS, the names array contains the names of the metrics that are found in the corresponding totals array, and the actual data is contained in the totals array.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/CDN?topic=CDN-metrics-container"}, {"document_id": "ibmcld_08582-6197-7807", "score": 9.275227, "text": "\ncorrelation_ID The unique identifier that is used to track and correlate transactions. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you create a key alias. For more examples of PII, see section 2.2 of the [NIST Special Publication 800-122](https://www.nist.gov/publications/guide-protecting-confidentiality-personally-identifiable-information-pii).\n\nA successful POST api/v2/keys/<key_ID>/aliases/<key_alias> response returns the alias for your key, along with other metadata. The alias is a unique name that is assigned to your key and can be used for to retrieve more information about the associated key.\n\n{\n\"metadata\": {\n\"collectionType\": \"application/vnd.ibm.kms.key+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"keyId\": \"02fd6835-6001-4482-a892-13bd2085f75d\",\n\"alias\": \"test-alias\",\n\"creationDate\": \"2020-03-12T03:37:32Z\",\n\"createdBy\": \"...\"\n}\n]\n}\n\nFor a detailed description of the response parameters, see the Hyper Protect Crypto Services [REST API reference doc](https://cloud.ibm.com/apidocs/hs-crypto).\n\n\n\n\n\n\n\n\n\n Deleting key aliases \n\nTo remove a key alias for a key, you can use either the console or the key management service API.\n\n\n\n Deleting key aliases with the console \n\nDelete a key alias with the console by completing the following steps:\n\n\n\n1. [Log in to the IBM Cloud console](https://cloud.ibm.com/login).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-key-alias"}, {"document_id": "ibmcld_09165-3941-4947", "score": 9.109679, "text": "\ncorrelation_ID Optional.The unique identifier that is used to track and correlate transactions. \n\n\n\nA successful GET api/v2/keys/<key_ID_or_alias>/metadata response returns details about your key. The following JSON object shows an example returned value for a standard key.\n\n{\n\"metadata\": {\n\"collectionType\": \"application/vnd.ibm.kms.key+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"type\": \"application/vnd.ibm.kms.key+json\",\n\"id\": \"02fd6835-6001-4482-a892-13bd2085f75d\",\n\"name\": \"test-standard-key\",\n\"aliases\":\n\"alias-1\",\n\"alias-2\"\n],\n\"state\": 1,\n\"expirationDate\": \"2020-03-15T03:50:12Z\",\n\"extractable\": true,\n\"crn\": \"crn:v1:bluemix:public:kms:us-south:a/f047b55a3362ac06afad8a3f2f5586ea:12e8c9c2-a162-472d-b7d6-8b9a86b815a6:key:02fd6835-6001-4482-a892-13bd2085f75d\",\n\"imported\": false,\n\"creationDate\": \"2020-03-12T03:50:12Z\",\n\"createdBy\": \"...\",\n\"algorithmType\": \"Deprecated\",\n\"algorithmMetadata\": {\n\"bitLength\": \"256\",\n\"mode\": \"Deprecated\"\n},\n\"algorithmBitSize\": 256,\n\"algorithmMode\": \"Deprecated\",", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-retrieve-key-metadata"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_06160-11142-12906", "score": 23.85148, "text": "\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https://cloud.ibm.com/unifiedsupport/cases/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-debug_worker_nodes), [Worker node states](https://cloud.ibm.com/docs/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready"}, {"document_id": "ibmcld_10596-11475-13230", "score": 23.417511, "text": "\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https://cloud.ibm.com/unifiedsupport/cases/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-debug_worker_nodes), [Worker node states](https://cloud.ibm.com/docs/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notready"}, {"document_id": "ibmcld_10534-545406-546780", "score": 22.768803, "text": "\n* [If all worker nodes in a single zone, subnet, or VLAN are affected](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-zone)\n* [If all worker nodes in a cluster are affected](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https://cloud.ibm.com/docs/openshift?topic=openshift-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https://cloud.ibm.com/docs/openshift?topic=openshift-bm_machine_idbm_machine_id)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-sitemap"}, {"document_id": "ibmcld_05713-581893-583377", "score": 22.373667, "text": "\n* [If all worker nodes in a cluster are affected](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https://cloud.ibm.com/docs/containers?topic=containers-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https://cloud.ibm.com/docs/containers?topic=containers-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https://cloud.ibm.com/docs/containers?topic=containers-bm_machine_idbm_machine_id)\n\n[After deleting all worker nodes, why don't my pods start on new worker nodes?](https://cloud.ibm.com/docs/containers?topic=containers-zero_nodes_calico_failurezero_nodes_calico_failure)\n\n[After a worker node updates or reloads, why do duplicate nodes and pods appear?]", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_sitemap"}, {"document_id": "ibmcld_06160-5357-7356", "score": 21.65432, "text": "\nIf the previous steps do not solve the issue, [reload](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\nIf some, but not all, of your worker nodes frequently enter a Critical or NotReady state, consider enabling [worker autorecovery](https://cloud.ibm.com/docs/containers?topic=containers-health-monitorautorecovery) to automate these recovery steps.\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready"}, {"document_id": "ibmcld_10596-5350-7330", "score": 21.512589, "text": "\nIf the previous steps do not solve the issue, [reload](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.\n\n\n\n1. Check if there were any recent changes to your cluster, environment, or account that might impact your worker nodes. If so, revert the changes and then check the worker node status to determine if the changes caused the issue.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notready"}, {"document_id": "ibmcld_13144-34858-36660", "score": 21.49379, "text": "\n* stdout and stderr are automatically collected and forwarded from all containers. Log data includes application logs and worker logs.\n* By default, the Log Analysis agent pod that runs on a worker collects logs from all namespaces on that node.\n\n\n\nAfter the agent is configured logs from this cluster will be visible in the Log Analysis web UI covered in the next section. If after a period of time you cannot see logs, check the agent logs.\n\nTo check the logs that are generated by a Log Analysis agent, run the following command:\n\noc logs logdna-agent-<ID> -n ibm-observe\n\nWhere ID is the ID for a Log Analysis agent pod.\n\nFor example,\n\noc logs logdna-agent-mdgdz -n ibm-observe\n\n\n\n\n\n Launch the Log Analysis webUI \n\nLaunch the web UI within the context of a Log Analysis instance, from the IBM Cloud UI.\n\n\n\n1. Navigate to [Red Hat OpenShift on IBM Cloud clusters](https://cloud.ibm.com/kubernetes/clusters?platformType=openshift)\n2. Click on your cluster and verify the Overview tab on the left is selected\n3. Next to Logging, click the Launch button.\n\n\n\nThe Log Analysis UI should open in a new tab.\n\n\n\n\n\n Create a custom view \n\nIn Log Analysis, you can configure custom views to monitor a subset of data. You can also attach an alert to a view to be notified of the presence or absence of log lines.\n\nIn the Log Analysis web UI notice the log entries are displayed with a predefined format. You can modify in the User Preferences section how the information in each log line is displayed. You can also filter logs and modify search settings, then bookmark the result as a view. You can attach and detach one or more alerts to a view. You can define a custom format for how your lines are shown in the view. You can expand a log line and see the data parsed.\n\n\n\n\n\n Simulate Load on the Application", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-openshift-microservices"}, {"document_id": "ibmcld_10596-9883-11854", "score": 21.14265, "text": "\nIf they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n7. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states \n\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https://cloud.ibm.com/docs/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notready"}, {"document_id": "ibmcld_06160-10037-11653", "score": 20.805492, "text": "\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https://cloud.ibm.com/docs/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https://cloud.ibm.com/unifiedsupport/cases/form) and include the worker node information you gathered.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready"}, {"document_id": "ibmcld_10566-1230-2155", "score": 20.723751, "text": "\nRun the px_logcollect.sh script. You can collect logs from all your worker nodes, or you can specify the --workers option and pass the private IP addresses of the worker nodes from where you want to collect logs. If you specify the --workers option, the log files are saved in the /tmp/pxlogs/<worker_node_IP> directory with the private IP address of each worker node as the folder name. To get the private IP addresses of your worker nodes, run the oc get nodes command.\n\n\n\n* Collect the logs from all worker nodes in your cluster.\n\nsudo ./px_logcollect.sh\n* Collect the logs from only certain worker nodes in your cluster.\n\nsudo ./px_logcollect.sh --workers <worker-IP> <worker-IP> <worker-IP>\n\n\n\n4. Review the log files locally. If you can't resolve your issue by reviewing the logs, [open a support ticket](https://cloud.ibm.com/docs/openshift?topic=openshift-get-help) and provide the log information that you collected.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-storage_portworx_support"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10394-7-1848", "score": 28.868387, "text": "\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-storage-update-classic"}, {"document_id": "ibmcld_06209-8154-10055", "score": 28.052052, "text": "\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the classic worker node to the same patch by using the ibmcloud ks worker update command.\n\n\n\nFor more information, see [Update types](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool, or if you have stand-alone worker nodes, apps might be scheduled onto stand-alone worker nodes. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload.\n\nHow can I control how many worker nodes go down at a time during an update or reload?\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-update"}, {"document_id": "ibmcld_10642-7855-9754", "score": 27.596695, "text": "\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.\n\n\n\nFor more information, see [Update types](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool, or if you have stand-alone worker nodes, apps might be scheduled onto stand-alone worker nodes. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload.\n\nHow can I control how many worker nodes go down at a time during an update or reload?\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.\n\nIn addition, you can create a Kubernetes config map that specifies the maximum number of worker nodes that can be unavailable at a time, such as during an update. Worker nodes are identified by the worker node labels. You can use IBM-provided labels or custom labels that you added to the worker node.\n\nThe Kubernetes config map rules are used for updating worker nodes only.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-update"}, {"document_id": "ibmcld_10284-1470-3569", "score": 27.579475, "text": "\n* Image and version updates: Worker node updates, such as security patches to the image or Red Hat OpenShift versions, are provided by IBM for you. However, you choose when to apply the updates to the worker nodes. For more information, see [Updating clusters, worker nodes, and cluster components](https://cloud.ibm.com/docs/containers?topic=containers-update).\n* Temporary modifications: If you log in to a pod or use some other process to modify a worker node setting, the modifications are temporary. Worker node lifecycle operations, such as autorecovery, reloading, updating, or replacing a worker node, change any modifications back to the default settings.\n* Persistent modifications: For modifications to persist across worker node lifecycle operations, create a daemon set that uses an init container. For more information, see [Modifying default worker node settings to optimize performance](https://cloud.ibm.com/docs/openshift?topic=openshift-kernelworker).\n\n\n\nModifications to the operating system are not supported. If you modify the default settings, you are responsible for debugging and resolving the issues that might occur.\n\n\n\n\n\n Hardware changes \n\nTo change the compute hardware, such as the CPU and memory per worker node, choose among the following options.\n\n\n\n* [Create a worker pool](https://cloud.ibm.com/docs/openshift?topic=openshift-add_workers). The instructions vary depending on the type of infrastructure for the cluster, such as classic, VPC, Satellite, or gateway clusters.\n* [Update the flavor](https://cloud.ibm.com/docs/containers?topic=containers-updatemachine_type) in your cluster by creating a worker pool and removing the previous worker pool.\n\n\n\n\n\n\n\n\n\n Modifying worker node settings to optimize performance \n\n\n\n Modifying worker node settings by using the Node Tuning Operator \n\nYou can use the node tuning operator to tune worker node performance by creating custom profiles. For more information, see the Red Hat [Node Tuning Operator](https://docs.openshift.com/container-platform/4.7/scalability_and_performance/using-node-tuning-operator.html) docs.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-kernel"}, {"document_id": "ibmcld_05528-97241-98398", "score": 27.572912, "text": "\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.17.3_1516\n\n Component Previous Current Description \n\n GPU worker node provisioning N/A N/A Fixed bug where new GPU worker nodes could not automatically join clusters that run Kubernetes version 1.16 or 1.17. \n Ubuntu 18.04 packages 4.15.0-76-generic 4.15.0-88-generic Updated worker node images with package updates for [CVE-2019-5108](https://nvd.nist.gov/vuln/detail/CVE-2019-5108), [CVE-2019-20096](https://nvd.nist.gov/vuln/detail/CVE-2019-20096), [CVE-2019-18885](https://nvd.nist.gov/vuln/detail/CVE-2019-18885), [CVE-2019-19082](https://nvd.nist.gov/vuln/detail/CVE-2019-19082), [CVE-2019-19078](https://nvd.nist.gov/vuln/detail/CVE-2019-19078), [CVE-2019-19332](https://nvd.nist.gov/vuln/detail/CVE-2019-19332), [CVE-2016-9840](https://nvd.nist.gov/vuln/detail/CVE-2016-9840), [CVE-2016-9841](https://nvd.nist.gov/vuln/detail/CVE-2016-9841), [CVE-2016-9842](https://nvd.nist.gov/vuln/detail/CVE-2016-9842), and [CVE-2016-9843](https://nvd.nist.gov/vuln/detail/CVE-2016-9843).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-117_changelog"}, {"document_id": "ibmcld_05527-62350-63507", "score": 27.558723, "text": "\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.16.7_1524\n\n Component Previous Current Description \n\n GPU worker node provisioning N/A N/A Fixed bug where new GPU worker nodes could not automatically join clusters that run Kubernetes version 1.16 or 1.17. \n Ubuntu 18.04 packages 4.15.0-76-generic 4.15.0-88-generic Updated worker node images with package updates for [CVE-2019-5108](https://nvd.nist.gov/vuln/detail/CVE-2019-5108), [CVE-2019-20096](https://nvd.nist.gov/vuln/detail/CVE-2019-20096), [CVE-2019-18885](https://nvd.nist.gov/vuln/detail/CVE-2019-18885), [CVE-2019-19082](https://nvd.nist.gov/vuln/detail/CVE-2019-19082), [CVE-2019-19078](https://nvd.nist.gov/vuln/detail/CVE-2019-19078), [CVE-2019-19332](https://nvd.nist.gov/vuln/detail/CVE-2019-19332), [CVE-2016-9840](https://nvd.nist.gov/vuln/detail/CVE-2016-9840), [CVE-2016-9841](https://nvd.nist.gov/vuln/detail/CVE-2016-9841), [CVE-2016-9842](https://nvd.nist.gov/vuln/detail/CVE-2016-9842), and [CVE-2016-9843](https://nvd.nist.gov/vuln/detail/CVE-2016-9843).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-116_changelog"}, {"document_id": "ibmcld_05528-62541-63542", "score": 27.364456, "text": "\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.17.9_1535\n\n Component Previous Current Description \n\n Kubernetes v1.17.9 v1.17.11 See the [Kubernetes change logs](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.17.mdv11711). \n Ubuntu 18.04 packages N/A N/A Updated worker node image with package updates for [CVE-2020-11936](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-11936), [CVE-2020-12400](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-12400), [CVE-2020-12401](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-12401), [CVE-2020-15701](https://nvd.nist.gov/vuln/detail/CVE-2020-15701), [CVE-2020-15702](https://nvd.nist.gov/vuln/detail/CVE-2020-15702), [CVE-2020-15709](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15709), and [CVE-2020-6829](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-6829).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-117_changelog"}, {"document_id": "ibmcld_05527-27905-28908", "score": 27.363722, "text": "\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.16.13_1542\n\n Component Previous Current Description \n\n Kubernetes v1.16.13 v1.16.14 See the [Kubernetes change logs](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.16.mdv11614). \n Ubuntu 18.04 packages N/A N/A Updated worker node image with package updates for [CVE-2020-11936](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-11936), [CVE-2020-12400](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-12400), [CVE-2020-12401](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-12401), [CVE-2020-15701](https://nvd.nist.gov/vuln/detail/CVE-2020-15701), [CVE-2020-15702](https://nvd.nist.gov/vuln/detail/CVE-2020-15702), [CVE-2020-15709](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15709), and [CVE-2020-6829](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-6829).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-116_changelog"}, {"document_id": "ibmcld_05529-82444-83443", "score": 27.350946, "text": "\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.18.6_1523\n\n Component Previous Current Description \n\n Kubernetes v1.18.6 v1.18.8 See the [Kubernetes change logs](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.18.mdv1188). \n Ubuntu 18.04 packages N/A N/A Updated worker node image with package updates for [CVE-2020-11936](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-11936), [CVE-2020-12400](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-12400), [CVE-2020-12401](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-12401), [CVE-2020-15701](https://nvd.nist.gov/vuln/detail/CVE-2020-15701), [CVE-2020-15702](https://nvd.nist.gov/vuln/detail/CVE-2020-15702), [CVE-2020-15709](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15709), and [CVE-2020-6829](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-6829).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-118_changelog"}, {"document_id": "ibmcld_05528-84256-84859", "score": 27.186785, "text": "\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.17.4_1521\n\n Component Previous Current Description \n\n containerd v1.3.3 v1.3.4 See the [containerd release notes](https://github.com/containerd/containerd/releases/tag/v1.3.4). \n HA proxy 1.8.25-30b675 1.8.25-adb65d The update addresses [CVE-2020-1967](https://nvd.nist.gov/vuln/detail/CVE-2020-1967). \n Kubernetes v1.17.4 v1.17.5 See the [Kubernetes release notes](https://github.com/kubernetes/kubernetes/releases/tag/v1.17.5).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-117_changelog"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_05728-3926-5863", "score": 18.674028, "text": "\nUpdate type Examples of version labels Updated by Impact \n\n Major 1.x.x You Operation changes for clusters, including scripts or deployments. \n Minor x.22.x You Operation changes for clusters, including scripts or deployments. \n Patch x.x.4_1510 IBM and you Kubernetes patches, as well as other IBM Cloud Provider component updates such as security and operating system patches. IBM updates masters automatically, but you apply patches to worker nodes. See more about patches in the following section. \n\n\n\nMajor and minor updates (1.x)\n: First, [update your master node](https://cloud.ibm.com/docs/containers?topic=containers-updatemaster) and then [update the worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updateworker_node).\n\n\n\n* You can't update a Kubernetes master two or more minor versions ahead (n+2). For example, if your current master is version 1.22 and you want to update to 1.24, you must update to 1.23 first.\n* Worker nodes can't run a Kubernetes major or minor version that is greater than the masters. Additionally, your worker nodes can be only up to two versions behind the master version (n-2).\n* If you use a kubectl CLI version that does not match at least the major.minor version of your clusters, you might experience unexpected results. Make sure to keep your Kubernetes cluster and [CLI versions](https://cloud.ibm.com/docs/containers?topic=containers-cli-install) up-to-date.\n\n\n\nPatch updates (x.x.4_1510)\n: Changes across patches are documented in the change log of each version. Master patches are applied automatically, but you initiate worker node patches and updates. Worker nodes can also run patch versions that are greater than the masters. As updates become available, you are notified when you view information about the master and worker nodes in the IBM Cloud console or CLI, such as with the following commands: ibmcloud ks cluster ls, cluster get, worker ls, or worker get.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_versions"}, {"document_id": "ibmcld_05597-3924-5861", "score": 18.674028, "text": "\nUpdate type Examples of version labels Updated by Impact \n\n Major 1.x.x You Operation changes for clusters, including scripts or deployments. \n Minor x.22.x You Operation changes for clusters, including scripts or deployments. \n Patch x.x.4_1510 IBM and you Kubernetes patches, as well as other IBM Cloud Provider component updates such as security and operating system patches. IBM updates masters automatically, but you apply patches to worker nodes. See more about patches in the following section. \n\n\n\nMajor and minor updates (1.x)\n: First, [update your master node](https://cloud.ibm.com/docs/containers?topic=containers-updatemaster) and then [update the worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updateworker_node).\n\n\n\n* You can't update a Kubernetes master two or more minor versions ahead (n+2). For example, if your current master is version 1.22 and you want to update to 1.24, you must update to 1.23 first.\n* Worker nodes can't run a Kubernetes major or minor version that is greater than the masters. Additionally, your worker nodes can be only up to two versions behind the master version (n-2).\n* If you use a kubectl CLI version that does not match at least the major.minor version of your clusters, you might experience unexpected results. Make sure to keep your Kubernetes cluster and [CLI versions](https://cloud.ibm.com/docs/containers?topic=containers-cli-install) up-to-date.\n\n\n\nPatch updates (x.x.4_1510)\n: Changes across patches are documented in the change log of each version. Master patches are applied automatically, but you initiate worker node patches and updates. Worker nodes can also run patch versions that are greater than the masters. As updates become available, you are notified when you view information about the master and worker nodes in the IBM Cloud console or CLI, such as with the following commands: ibmcloud ks cluster ls, cluster get, worker ls, or worker get.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-changelog"}, {"document_id": "ibmcld_10642-7855-9754", "score": 17.87977, "text": "\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.\n\n\n\nFor more information, see [Update types](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool, or if you have stand-alone worker nodes, apps might be scheduled onto stand-alone worker nodes. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload.\n\nHow can I control how many worker nodes go down at a time during an update or reload?\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.\n\nIn addition, you can create a Kubernetes config map that specifies the maximum number of worker nodes that can be unavailable at a time, such as during an update. Worker nodes are identified by the worker node labels. You can use IBM-provided labels or custom labels that you added to the worker node.\n\nThe Kubernetes config map rules are used for updating worker nodes only.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-update"}, {"document_id": "ibmcld_10642-20176-22071", "score": 17.213552, "text": "\nFor more information about the latest updates, review the [change log](https://cloud.ibm.com/docs/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https://cloud.ibm.com/docs/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the VPC worker node to the latest patch by using the ibmcloud oc worker replace command.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the VPC worker node to the same patch by using the ibmcloud oc worker replace command with the --update option.\n\n\n\nFor more information, see [Update types](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload, such as by [resizing your worker pools](https://cloud.ibm.com/docs/openshift?topic=openshift-add_workersresize_pool).\n\nWhat happens to my worker node during an update?\n: Your VPC worker node is replaced by removing the old worker node and provisioning a new worker node that runs at the updated patch or major.minor version. The replacement worker node is created in the same zone, same worker pool, and with the same flavor as the deleted worker node.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-update"}, {"document_id": "ibmcld_11770-15918-16546", "score": 16.727991, "text": "\nTo determine the type of update that is available, compare your current worker node versions to the latest worker node fix pack version in the [Red Hat OpenShift version change log](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versions). Major updates are indicated by the first digit in the version label (4.x.x), minor updates are indicated by the second digit (x.7.x) and patch updates are indicated by the trailing digits (x.x.23_1528_openshift). For more information on version updates, see [Version information and update actions](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versions).", "title": "", "source": "https://cloud.ibm.com/docs/satellite?topic=satellite-host-update-workers"}, {"document_id": "ibmcld_10642-6354-8294", "score": 16.407822, "text": "\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https://cloud.ibm.com/docs/openshift?topic=openshift-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https://cloud.ibm.com/docs/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https://cloud.ibm.com/docs/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud oc worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-update"}, {"document_id": "ibmcld_06209-19911-21816", "score": 16.383472, "text": "\nAs security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only VPC clusters. Have a classic cluster? See [Updating classic worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updateworker_node) instead.\n\nIf you have Portworx deployed in your cluster, follow the steps to [update VPC worker nodes with Portworx volumes](https://cloud.ibm.com/docs/containers?topic=containers-storage_portworx_updateportworx_vpc_up).\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https://cloud.ibm.com/docs/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https://cloud.ibm.com/docs/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the VPC worker node to the latest patch by using the ibmcloud ks worker replace command.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the VPC worker node to the same patch by using the ibmcloud ks worker replace command with the --update option.\n\n\n\nFor more information, see [Update types](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionsupdate_types).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-update"}, {"document_id": "ibmcld_10395-7-1827", "score": 16.11989, "text": "\nUpdating VPC worker nodes that use OpenShift Data Foundation \n\nVirtual Private Cloud\n\nFor VPC clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-storage-update-vpc"}, {"document_id": "ibmcld_10394-7-1848", "score": 16.03696, "text": "\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-storage-update-classic"}, {"document_id": "ibmcld_10394-1469-2994", "score": 15.983475, "text": "\nIf you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.\n\n\n\n\n\n\n\n Step 2: Determine which worker nodes you want to update \n\nMajor\n\nMinor\n\n\n\n1. List your worker nodes by using the oc get nodes command and determining which worker nodes you want to update.\n\noc get nodes\n\nExample output\n\nNAME STATUS ROLES AGE VERSION\n10.241.0.4 Ready master,worker 106s v1.21.6+4b61f94\n10.241.128.4 Ready master,worker 22d v1.21.6+bb8d50a\n10.241.64.4 Ready master,worker 22d v1.21.6+bb8d50a\n\n\n\n\n\n\n\n Step 3: Scale down OpenShift Data Foundation \n\nMajor\n\nMinor\n\n\n\n1. For each worker node that you found in the previous step, find the rook-ceph-mon and rook-ceph-osd deployments.\n\noc get pods -n openshift-storage -o wide | grep -i <node_name>\n2. Scale down the deployments that you found in the previous step.\n\noc scale deployment rook-ceph-mon-c --replicas=0 -n openshift-storage\noc scale deployment rook-ceph-osd-2 --replicas=0 -n openshift-storage\noc scale deployment --selector=app=rook-ceph-crashcollector,node_name=NODE-NAME --replicas=0 -n openshift-storage\n\n\n\n\n\n\n\n Step 4: Cordon and drain the worker node \n\nMajor\n\nMinor\n\n\n\n1. Cordon the node. Cordoning the node prevents any pods from being scheduled on this node.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-storage-update-classic"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09410-3448-5457", "score": 13.561476, "text": "\nA tag consists of multiple parts:\n\nX.Y.Z-<date>.[hash]\n\nWhere\n\n\n\n* X represents the major version of an image.\n* Y represents the minor version of an image.\n* Z represents an incremental ID that determines the latest patched minor version.\n* <date> represents the date that the image is built and available. The format is YYYYMMDD.\n* [hash] represents the digest (manifest) of the container image. It is a unique SHA-256 hash.\n\n\n\nThe following table outlines the tagging convention adopted and the agent update behavior:\n\n\n\nTable 1. logging agent tags explained\n\n Tag Logging agent auto-update enabled More info \n\n X YES The logging agent auto-updates when a new minor version releases. <br>The logging agent does not update to a new major version, as these updates may require configuration changes. \n X.Y YES The logging agent auto-updates when a new patch version is released. \n X.Y.Z YES The logging agent auto-updates when a new vulnerability fix is released. The agent code does not change, but the included libraries have vulnerability fixes. \n X.Y.Z-<date>.[hash] NO The logging agent never updates. If you use this tag, make sure you are watching for new agent releases that have vulnerability fixes. \n\n\n\nDepending on the tag that you use, you must consider upgrading the logging agent image in your DevOps maintenance plan, to resolve vulnerabilities and apply agent enhancements and agent bug fixes. For example:\n\n\n\n* In a development environment, you can use a tag X and let auto-updates happen as new minor versions are released.\n* In a staging environment, you might consider using a tag X.Y so auto-updates happen when a new patch is released.\n* In a production environment, you can use the tag X.Y.Z so that auto-updates happen when a new vulnerability fix is released.\n* For highly regulated environments, you should use the tag X.Y.Z-<date>.[hash]. Notice that you will have to check periodically for vulnerability fixes, patches, and minor version releases to keep the agent free of issues.", "title": "", "source": "https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-log_analysis_agent"}, {"document_id": "ibmcld_16493-13844-15872", "score": 13.408509, "text": "\nIn a dictionary, individual lexical items are assigned part of speech (POS) tags. For example, the word 'fly' can be identified as a verb or a noun.\n* performance\n\nThe measurement of a Watson system in terms of accuracy, precision, and recall, for example, when answering questions, discovering relationships, or annotating text.\n* pre-annotation\n\nThe process of annotating a set of documents prior to human annotation. Documents can be pre-annotated by using a rule-based model, a machine-learning model, IBM Watson\u00ae Natural Language Understanding, or a dictionary. Pre-annotation can help human annotators more quickly prepare a set of ground truth documents.\n* precision\n\nA measurement that specifies the proportion of results that are relevant. Precision, which is a positive predictive value, is determined by the number of correct positive results divided by the number of all positive results. Accuracy is best measured by using both precision and recall. See also [accuracy](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-glossarygloss_A) and [recall](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-glossarygloss_R).\n* processing engine archive (PEAR)\n\nA .pear archive file that includes an Unstructured Information Management Architecture (UIMA) analysis engine and all of the resources that are required to use it for custom analysis.\n\n\n\n\n\n\n\n R \n\n\n\n* recall\n\nA measurement that specifies the percentage of relevant results returned, out of all available relevant results. Recall, which is a measure of sensitivity, is determined by the number of correct positive results divided by the number of positive results that should have been returned. Accuracy is best measured by using both precision and recall. See also [accuracy](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-glossarygloss_A) and [precision](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-glossarygloss_P).\n* relation", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-glossary"}, {"document_id": "ibmcld_16471-74601-76664", "score": 13.177041, "text": "\nFor all supported languages, the Multilingual tokenizer uses the part-of-speech tags that are listed in the following table.\n\n\n\n Tag Descriptions \n\n ADJ adjective \n ADP adposition \n ADV adverb \n AUX auxiliary \n CCONJ coordinating conjunction \n DET determiner \n INTJ interjection \n NOUN noun \n NUM numeral \n PART particle \n PRON pronoun \n PROPN proper noun \n PUNCT punctuation \n SCONJ subordinating conjunction \n SYM symbol \n VERB verb \n X other \n\n\n\n\n\n\n\n Examples \n\nExample 1: Using a part of speech tag directly in an extract statement\n\nThe view EnglishNoun extracts English nouns (singular or mass) or proper nouns (singular).\n\ncreate view EnglishNoun\nas extract parts_of_speech 'NOUN' and 'PROPN'\nwith language 'en' on D.text\nas noun from Document D;\n\n\n\n\n\n\n\n Sequence patterns \n\nUse the pattern extraction specification to perform pattern matching across an input document and other spans extracted from the input document.\n\n\n\n Syntax \n\nThe general syntax of a sequence pattern is to first specify the pattern to be matched in the text, and then to specify what is to be returned by the extractor. The final part of the sequence pattern specifies what is the input to the pattern; it might be a column from a previously defined view, or it might be the entire document text.\n\npattern <pattern specification> [return clause] [with inline_match on <viewname.colname>]\n\n\n\n\n\n Description \n\n\n\n* <pattern specification>\n\nA <pattern specification> is composed of multiple Atoms. An individual Atom can be a column from an already-defined view, a fixed string, or a regular expression. You can specify your Atoms to be optional and repeating, and specify token gaps between Atoms.\n\nThe pattern specification is part of a larger AQL statement, which includes an extract clause.\n\nHere is a simple example of how to create a view that contains three adjacent matches from earlier defined views. In this example, the entire combination is returned, which is what group 0 refers to:\n\ncreate view Money as\nextract pattern <C.match> <N.match> <Q.match>\nreturn group 0 as match", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"}, {"document_id": "ibmcld_16436-14174-15978", "score": 12.923121, "text": "\nIn a dictionary, individual lexical items are assigned part of speech (POS) tags. For example, the word 'fly' can be identified as a verb or a noun.\n* performance\n\nThe measurement of a Watson system in terms of accuracy, precision, and recall, for example, when answering questions, discovering relationships, or annotating text.\n* pre-annotation\n\nThe process of annotating a set of documents prior to human annotation. Documents can be pre-annotated by using a rule-based model, a machine-learning model, IBM Watson\u2122 Natural Language Understanding, or a dictionary. Pre-annotation can help human annotators more quickly prepare a set of ground truth documents.\n* precision\n\nA measurement that specifies the proportion of results that are relevant. Precision, which is a positive predictive value, is determined by the number of correct positive results divided by the number of all positive results. Accuracy is best measured by using both precision and recall. See also [accuracy](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-glossarygloss_A) and [recall](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-glossarygloss_R).\n* processing engine archive (PEAR)\n\nA .pear archive file that includes an Unstructured Information Management Architecture (UIMA) analysis engine and all of the resources that are required to use it for custom analysis.\n\n\n\n\n\n\n\n R \n\n\n\n* recall\n\nA measurement that specifies the percentage of relevant results returned, out of all available relevant results. Recall, which is a measure of sensitivity, is determined by the number of correct positive results divided by the number of positive results that should have been returned. Accuracy is best measured by using both precision and recall.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-glossary"}, {"document_id": "ibmcld_16471-73103-74976", "score": 12.150271, "text": "\n* [and mapping from <mapping table name>]\n\nSpecifies the name of an AQL table that maps raw part-of-speech tags such as \"NOUN\" to combinations of high-level parts of speech and flags. While the optional mapping table can have variable names, a part-of-speech mapping table is required to have these column names:\n\n\n\n* tag\n\nThe column that holds a Multilingual tokenizer part-of-speech tag.\n* basetag\n\nThe column that holds the corresponding internal tag.\n* flagstr\n\nThe column that holds a comma-delimited list of flags that are associated with the indicated part of speech.\n\n\n\nThe mapping table must be defined by using the create table statement in the same module as the extract part_of_speech statement that uses it. It cannot be an imported table, and it cannot be an external table.\n\ncreate table POSMapping_EN(tag Text, basetag Text, flagstr Text)\nas values\n('CCONJ','CONJ','coordinating'),\n('SCONJ','CONJ','subordinating');\n* <input column>\n\nSpecifies the column of the input view from which to extract part-of-speech information.\n* <output column>\n\nSpecifies the name of the column where the spans of the tokens with the indicated parts of speech are sent.\n* <input view>\n\nSpecifies the input view from which to extract part-of-speech information.\n\n\n\n\n\n\n\n Usage notes \n\n\n\n* Part of speech extraction works only when is using the Multilingual tokenizer. If the system uses the Standard tokenizer, a part_of_speech extraction generates an error.\n\n\n\n\n\n\n\n Parts of speech tags for languages \n\nFor all supported languages, the Multilingual tokenizer uses the part-of-speech tags that are listed in the following table.\n\n\n\n Tag Descriptions \n\n ADJ adjective \n ADP adposition \n ADV adverb \n AUX auxiliary \n CCONJ coordinating conjunction \n DET determiner \n INTJ interjection \n NOUN noun \n NUM numeral \n PART particle \n PRON pronoun \n PROPN proper noun \n PUNCT punctuation", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"}, {"document_id": "ibmcld_09275-13854-15898", "score": 11.8152685, "text": "\nTags are case-sensitive, and the maximum length of a tag is 128 characters.\n\n\n\n* The characters that are permitted to name tags are A-Z, 0-9, spaces, underscore, hyphen, period, and colon.\n* Colons turn the tag into a string where you can isolate two logical parts, like a key:value pair. You can't use a colon in a tag without creating this pairing.\n* A comma separates tags and can't be used within the tag name itself.\n\n\n\nIf you add PII information in the name, you might be disclosing sensitive data to others in the same account.\n\nWhen you define your tags, do not add sensitive information in the tag name.\n\nTags are visible to all members of an account.\n\nTo control tag visibility, circulate tagging guidelines, and let users know that tags are visible account-wide.\n\n\n\n\n\n\n\n Define the log ingestion strategy \n\nFor non-IBM Cloud enabled services, you must decide the method to collect and forward logs from a log source that you want to monitor to a logging instance.\n\nIn IBM Log Analysis, you can collect and forward data to a logging instance by using any of the following methods:\n\n\n\n* logging agent: Logging agent that automatically collects and forwards logs to 1 logging instance in your account.\n* Syslog: Logging daemon that collects information across multiple devices and system-services, and forwards logs to 1 logging instance in your account.\n* REST API: API that you can use to send log data and custom metadata to 1 logging instance in your account.\n* Code libraries: Libraries that you can use to code ingestion of logs from your apps and services to 1 logging instance. logging offer libraries for Node.JS, Python, Rails, Ruby, Go, iOS, Java, and PHP.\n\n\n\nFor any method that you adopt, you have the flexibility to choose the logging instance where you want to send data per log source. Decide how many instances you might need to collect data from all your log sources based on who can see the data and the type of data that is collected. Avoid sending data to a logging instance that has the platform logs flag enabled.", "title": "", "source": "https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-adoption"}, {"document_id": "ibmcld_16468-20755-22481", "score": 11.6998825, "text": "\nInclude indications of where in the car the part is, or something which just refers to a portion of a car without being a specific part. <br> <br>Can be plural. Can include specification of position in the vehicle, such as \"[driver airbag]\", \"[RF door]\" (meaning right-front), \"[RR] passenger\", \"[LF and RF air bags]\", \"[first row passive/automatic restraints]\", \"[safety system] with EDR capabilities\". <br> <br>Include towed boats, tanks, etc., except semi-trailers, which have a distinct year/model/manufacturer. Cross-section, front plane, tire, steering wheel, airbag, etc. \n PERSON Any person described in an accident scene in a report (could be a driver or a passenger/occupant of a vehicle, pedestrian, or witness). <br> <br>Don't annotate adjectives, so don't annotate \"a [69-year-old] drove\", but do annotate \"a 69-year-old [male] drove\". Can be plural, for example, \"LR and RF [occupants]\". Excludes people who arrive after incident. <br> <br>>In the absence of an \"animal\" entity type, use PERSON to tag wildlife involved in / causing collisions, as their ability to move makes them more like a PERSON than a STRUCTURE. <br> <br>Note: \"passenger airbag\" is a PART_OF_CAR; it does not imply that a person is present. \n STRUCTURE A structure that is on, near, or part of a road. Include specific road adjectives likely to be relevant to the configuration of an accident; omit other adjectives. [two-lane, two-way road], [left lane], eastbound [lane], 2-foot [ditch], [right lane line], [exit ramp], [pole], [tree], steep descending [embankment] \n VEHICLE Any reference to vehicle other than MODEL, MANUFACTURER, and MODEL_YEAR. Can be plural, in which case coreference is very unlikely and no part-of-group relation.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents"}, {"document_id": "ibmcld_16471-71623-73502", "score": 11.32862, "text": "\non CW.word as capswords\nfrom CapitalizedWords CW;\n\nExample 2: Extract blocks of words within a token range\n\nThe following code identifies blocks of exactly two capitalized words within five tokens of each other.\n\ncreate view TwoCapitalizedWords as\nextract blocks\nwith count 2\nand separation between 0 and 5 tokens\non CW.word as capswords\nfrom CapitalizedWords CW;\n\n\n\n\n\n\n\n Part of speech \n\nUse the part-of-speech extraction specification to identify locations of different parts of speech across the input text.\n\n\n\n Syntax \n\npart_of_speech\n'<part of speech spec>'\n[and '<part of speech spec>']\n[with language '<language code>']\n[and mapping from <mapping table name>]\non <input column> as <output column>\nfrom <input view>\n\n\n\n\n\n Description \n\n\n\n* '<part of speech spec>'\n\nIdentifies the parts of speech to extract from the input text. The '<part of speech spec>' is one of the following strings:\n\n\n\n* A string that contains a comma-delimited list of part-of-speech tags that are generated by the Multilingual tokenizer\n* A combination of an internal part-of-speech name and flags, as defined by a mapping table\n\n\n\n* [and '<part of speech spec>']\n\nIdentifies the additional parts of speech tags for extraction.\n* [with language '<language code>']\n\nSpecifies the language to be used in the extraction. The <language code> is a two-letter, lowercase language code, such as 'en' or 'ja'. If this argument is omitted, the language for part-of-speech extraction is assumed to be English\n* [and mapping from <mapping table name>]\n\nSpecifies the name of an AQL table that maps raw part-of-speech tags such as \"NOUN\" to combinations of high-level parts of speech and flags. While the optional mapping table can have variable names, a part-of-speech mapping table is required to have these column names:\n\n\n\n* tag\n\nThe column that holds a Multilingual tokenizer part-of-speech tag.\n* basetag", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"}, {"document_id": "ibmcld_07010-5213-7301", "score": 11.311298, "text": "\nFigure 1. Watson Discovery Content Mining application home page\n\nFrom this starting point, you can determine other ways to filter the data that might be useful.\n\nIf your data consists of traffic reports, for example, the Part of Speech facet might show that high frequency keywords include terms such as engine, brake, fire, smoke, and spark. Given this common terminology, you can create dictionaries to help you categorize and filter the data. The keywords from the example might lead you to create the following dictionaries:\n\n\n\n* component dictionary for terms such as engine and brake\n* phenomenon dictionary for terms such as fire, smoke, and spark\n\n\n\nWhen you apply the dictionary enrichment to your data, it generates annotations. You can think of annotations as tags that you add to words or phrases, where the tag categorizes or identifies the meaning of the word or phrase. The resulting annotations function as new facets that you can use to filter and dissect your data further.\n\nWith your new component and phenomenon facets, for example, you can look for correlations between components and phenomena that are involved in traffic incidents.\n\n[Learn about the ways that you can analyze your data](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-cm-analyze-data).\n\n\n\n\n\n Digging deeper \n\nTo dig even deeper into your data, apply or create AI models that can find different types of information in your documents. You can apply built-in natural language processing models, such as the Entities enrichment that can recognize mentions of commonly known things, such as business or location names and other types of proper nouns. Or you can apply a custom model that recognizes terms and categories that are unique to your data.\n\n[Extend your analysis by adding your own facets](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-cm-add-facets).\n\n\n\n\n\n Getting started \n\nBefore you can use the application, you must create a Discovery Content Mining project. After the project is created and data is uploaded, you can open the Content Mining application.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-contentminerapp"}, {"document_id": "ibmcld_13074-11746-13648", "score": 11.268054, "text": "\nIn the preceding example, you could query the category label by accessing enriched_text.categories.label\n\nThe label is the detected category. The hierarchy levels are separated by forward slashes. The score for that category ranges from 0.0 to 1.0. The higher the score, the greater the confidence in that category.\n\n\n\n\n\n Concept tagging \n\nIdentifies concepts with which the input text is associated, based on other concepts and entities that are present in that text. Concept tagging understands how concepts relate, and can identify concepts that are not directly referenced in the text. For example, if an article mentions CERN and the Higgs boson, the Concepts API functions identifies Large Hadron Collider as a concept even if that term is not mentioned explicitly in the page. Concept tagging enables higher level analysis of input content than just basic keyword identification.\n\nExample portion of a document enriched with Concept Tagging:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"concepts\": [\n{\n\"text\": \"Acme Corporation\",\n\"relevance\": 0.91136,\n\"dbpedia_resource\": \"http://dbpedia.org/resource/Acme_Corporation\"\n},\n{\n\"text\": \"Factory\",\n\"relevance\": 0.886784,\n\"dbpedia_resource\": \"http://dbpedia.org/resource/Factory\"\n}\n]\nShow more\n\nIn the preceding example, you can query the concept text type by accessing enriched_text.concepts.text\n\nThe relevance score ranges from 0.0 to 1.0. The higher the score, the more relevant the concept. Links to the resource(s) are provided, if applicable.\n\n\n\n\n\n Semantic Role extraction \n\nIdentifies subject, action, and object relations within sentences in the input content. Relation information can be used to automatically identify buying signals, key events, and other important actions.\n\nExample portion of a document enriched with Semantic Role Extraction:\n\n{", "title": "", "source": "https://cloud.ibm.com/docs/services/discovery?topic=discovery-configservice"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03970-6841-9069", "score": 21.304298, "text": "\nIf you import a bulk data transfer of nodes and do not also import identities, you will have to perform the separate step of associating identities with the nodes. There are a few ways to procure an identity that can operate a node. For more information about, see [Gathering certificates or credentials](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-import-nodesibp-console-import-start-here). Regardless of the process used to acquire the identity, after the bulk import has been completed you will need to click on each imported node. For peers and ordering nodes, a box on the left of the screen will say Identity not associated with (peer or ordering node), depending on the node in question. After clicking on this box, you will be able to associate the relevant identity by selecting it from your Wallet. Note that this process is distinctly different than the process for importing individual nodes, where you will be asked to associate an identity as part of the import process.\n\nYou will also need to associate an admin identity for the CA. This process is similar to the peer and ordering node process except that after you click on the imported CA you will see a separate screen asking you to associate an identity rather than a box on the left.\n\nFor cases where bulk data transfers are impractical or inadvisable, you can follow the steps below to export and import components and identities one at a time.\n\n\n\n\n\n Gathering certificates or credentials \n\nBecause identities contain private keys, be careful when exporting them to ensure they are handled securely. If a private key is compromised, it can be used to perform malicious actions.\n\nEach IBM Blockchain Platform component is deployed with the signing certificate of an administrator inside. When actions requiring the permission level of an admin are performed against the component, the signing certificate of the entity attempting the action is checked against the signing certificate inside the node. If they don't match, the action is denied. In this way, these certificates, which are also known as \"keys\", allow the administrator to operate their components.\n\nIf you intend to operate an imported node, you have two options:\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-import-nodes"}, {"document_id": "ibmcld_06160-11142-12906", "score": 20.73917, "text": "\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https://cloud.ibm.com/unifiedsupport/cases/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-debug_worker_nodes), [Worker node states](https://cloud.ibm.com/docs/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready"}, {"document_id": "ibmcld_03406-34893-35432", "score": 20.631561, "text": "\nIn this tutorial you tested a node with slots and made changes that optimize how it interacts with real users. For more information about this subject, see [Gathering information with slots](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-slots).\n\n\n\n\n\n\n\n Next steps \n\nDeploy your dialog skill by first connecting it to an assistant, and then deploying the assistant. There are several ways you can do this. See [Adding integrations](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-integration-add) for more details.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-tutorial-slots-complex"}, {"document_id": "ibmcld_10534-545406-546780", "score": 20.35489, "text": "\n* [If all worker nodes in a single zone, subnet, or VLAN are affected](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-zone)\n* [If all worker nodes in a cluster are affected](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https://cloud.ibm.com/docs/openshift?topic=openshift-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https://cloud.ibm.com/docs/openshift?topic=openshift-bm_machine_idbm_machine_id)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-sitemap"}, {"document_id": "ibmcld_10596-11475-13230", "score": 20.332888, "text": "\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https://cloud.ibm.com/unifiedsupport/cases/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-debug_worker_nodes), [Worker node states](https://cloud.ibm.com/docs/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notready"}, {"document_id": "ibmcld_05713-581893-583377", "score": 20.063017, "text": "\n* [If all worker nodes in a cluster are affected](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https://cloud.ibm.com/docs/containers?topic=containers-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https://cloud.ibm.com/docs/containers?topic=containers-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https://cloud.ibm.com/docs/containers?topic=containers-bm_machine_idbm_machine_id)\n\n[After deleting all worker nodes, why don't my pods start on new worker nodes?](https://cloud.ibm.com/docs/containers?topic=containers-zero_nodes_calico_failurezero_nodes_calico_failure)\n\n[After a worker node updates or reloads, why do duplicate nodes and pods appear?]", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_sitemap"}, {"document_id": "ibmcld_02873-7270-8670", "score": 19.997837, "text": "\nThis standard type of node is useful to capture questions about a certain topic and then in the root response ask a follow-up question that is addressed by the child nodes. For example, it might recognize a user question about discounts and ask a follow-up question about whether the user is a member of any associations with which the company has special discount arrangements. And the child nodes provide different responses based on the user's answer to the question about association membership.\n* The second root node is a node with slots. It also conditions on an intent value. It defines a set of slots, one for each piece of information that you want to collect from the user. Each slot asks a question to elicit the answer from the user. It looks for a specific entity value in the user's reply to the prompt, which it then saves in a slot context variable.\n\nThis type of node is useful for collecting details you might need to perform a transaction on the user's behalf. For example, if the user's intent is to book a flight, the slots can collect the origin and destination location information, travel dates, and so on.\n\n\n\n\n\n\n\n Ready to get started? \n\nFor more information, see [Building a dialog](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overview).\n\nNext topic:[Planning the dialog](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-plan)", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-build"}, {"document_id": "ibmcld_03405-3051-4760", "score": 19.885075, "text": "\nClick the System entities tab, and then turn on these entities:\n\n\n\n* @sys-time\n* @sys-date\n* @sys-number\n\n\n\n\n\nYou have successfully enabled the @sys-date, @sys-time, and @sys-number system entities. Now you can use them in your dialog.\n\n\n\n\n\n Step 3: Add a dialog node with slots \n\nA dialog node represents the start of a thread of dialog between your assistant and the user. It contains a condition that must be met for the node to be processed by your assistant. At a minimum, it also contains a response. For example, a node condition might look for the hello intent in user input, and respond with, Hi. How can I help you? This example is the simplest form of a dialog node, one that contains a single condition and a single response. You can define complex dialogs by adding conditional responses to a single node, adding child nodes that prolong the exchange with the user, and much more. (If you want to learn more about complex dialogs, you can complete the [Building a complex dialog](https://cloud.ibm.com/docs/assistant?topic=assistant-tutorial) tutorial.)\n\nThe node that you will add in this step is one that contains slots. Slots provide a structured format through which you can ask for and save multiple pieces of information from a user within a single node. They are most useful when you have a specific task in mind and need key pieces of information from the user before you can perform it. See [Gathering information with slots](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-slots) for more information.\n\nThe node you add will collect the information required to make a reservation at a restaurant.\n\n\n\n1. Click the Dialogs tab to open the dialog tree.\n2. Click the More icon !", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-tutorial-slots"}, {"document_id": "ibmcld_03071-7-2056", "score": 19.564476, "text": "\nTutorial: Adding a node with slots to a dialog \n\nIn this tutorial, you will add slots to a dialog node to collect multiple pieces of information from a user within a single node. The node you create will collect the information that is needed to make a restaurant reservation.\n\n\n\n Learning objectives \n\nBy the time you finish the tutorial, you will understand how to:\n\n\n\n* Define the intents and entities that are needed by your dialog\n* Add slots to a dialog node\n* Test the node with slots\n\n\n\n\n\n Duration \n\nThis tutorial will take approximately 30 minutes to complete.\n\n\n\n\n\n Prerequisite \n\nBefore you begin, complete the [Getting Started tutorial](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-getting-started). You will use the Watson Assistant tutorial skill that you created, and add nodes to the simple dialog that you built as part of the getting started exercise.\n\nYou can also start with a new dialog skill if you want. Just be sure to create the skill before you begin this tutorial.\n\n\n\n\n\n\n\n Step 1: Add intents and examples \n\nAdd an intent on the Intents tab. An intent is the purpose or goal that is expressed in user input. You will add a #reservation intent that recognizes user input that indicates that the user wants to make a restaurant reservation.\n\n\n\n1. From the Intents page of the tutorial skill, click Add intent.\n2. Add the following intent name, and then click Create intent:\n\nreservation\n\nThe #reservation intent is added. A number sign () is prepended to the intent name to label it as an intent. This naming convention helps you and others recognize the intent as an intent. It has no example user utterances associated with it yet.\n3. In the Add user examples field, type the following utterance, and then click Add example:\n\ni'd like to make a reservation\n4. Add these additional examples to help Watson recognize the reservation intent.\n\nI want to reserve a table for dinner\nCan 3 of us get a table for lunch?\ndo you have openings for next Wednesday at 7?\nIs there availability for 4 on Tuesday night?", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-tutorial-slots"}, {"document_id": "ibmcld_03185-6701-8694", "score": 19.52644, "text": "\n[A sample dialog tree with example content](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/dialog-depiction-full.png)\n\nThe dialog tree in this diagram contains two root dialog nodes. A typical dialog tree would likely have many more nodes, but this depiction provides a glimpse of what a subset of nodes might look like.\n\n\n\n* The first root node conditions on an intent value. It has two child nodes that each condition on an entity value. The second child node defines two responses. The first response is returned to the user if the value of the context variable matches the value specified in the condition. Otherwise, the second response is returned.\n\nThis standard type of node is useful to capture questions about a certain topic and then in the root response ask a follow-up question that is addressed by the child nodes. For example, it might recognize a user question about discounts and ask a follow-up question about whether the user is a member of any associations with which the company has special discount arrangements. And the child nodes provide different responses based on the user's answer to the question about association membership.\n* The second root node is a node with slots. It also conditions on an intent value. It defines a set of slots, one for each piece of information that you want to collect from the user. Each slot asks a question to elicit the answer from the user. It looks for a specific entity value in the user's reply to the prompt, which it then saves in a slot context variable.\n\nThis type of node is useful for collecting details you might need to perform a transaction on the user's behalf. For example, if the user's intent is to book a flight, the slots can collect the origin and destination location information, travel dates, and so on.\n\n\n\n\n\n\n\n Ready to get started? \n\nFor more information, see [Creating a dialog](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overview).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-build"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10642-6354-8294", "score": 35.271137, "text": "\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https://cloud.ibm.com/docs/openshift?topic=openshift-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https://cloud.ibm.com/docs/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https://cloud.ibm.com/docs/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud oc worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-update"}, {"document_id": "ibmcld_10394-7-1848", "score": 34.069183, "text": "\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-storage-update-classic"}, {"document_id": "ibmcld_06209-6757-8643", "score": 33.819733, "text": "\n* [Updating classic worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updateworker_node).\n* [Updating VPC worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updatevpc_worker_node).\n\n\n\n\n\n\n\n\n\n Updating classic worker nodes \n\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https://cloud.ibm.com/docs/containers?topic=containers-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https://cloud.ibm.com/docs/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https://cloud.ibm.com/docs/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-update"}, {"document_id": "ibmcld_06209-19911-21816", "score": 33.606834, "text": "\nAs security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only VPC clusters. Have a classic cluster? See [Updating classic worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updateworker_node) instead.\n\nIf you have Portworx deployed in your cluster, follow the steps to [update VPC worker nodes with Portworx volumes](https://cloud.ibm.com/docs/containers?topic=containers-storage_portworx_updateportworx_vpc_up).\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https://cloud.ibm.com/docs/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https://cloud.ibm.com/docs/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the VPC worker node to the latest patch by using the ibmcloud ks worker replace command.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the VPC worker node to the same patch by using the ibmcloud ks worker replace command with the --update option.\n\n\n\nFor more information, see [Update types](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionsupdate_types).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-update"}, {"document_id": "ibmcld_10642-18947-20676", "score": 33.270733, "text": "\nYou notice that an update is available for your worker nodes in a [VPC infrastructure cluster](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providers). What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only VPC clusters. Have a classic cluster? See [Updating classic worker nodes](https://cloud.ibm.com/docs/openshift?topic=openshift-updateworker_node) instead.\n\nIf you have Portworx deployed in your cluster, follow the steps to [update VPC worker nodes with Portworx volumes](https://cloud.ibm.com/docs/openshift?topic=openshift-storage_portworx_updateportworx_vpc_up).\n\nIf you have OpenShift Data Foundation deployed in your cluster, follow the steps to [update VPC worker nodes with OpenShift Data Foundation](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-storage-update-vpc).\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https://cloud.ibm.com/docs/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https://cloud.ibm.com/docs/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the VPC worker node to the latest patch by using the ibmcloud oc worker replace command.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-update"}, {"document_id": "ibmcld_06010-6040-7693", "score": 33.143982, "text": "\nTo update the version of the operating system that a worker node uses, such as from Ubuntu 16 to 18, you can [replace the flavor of the worker pool](https://cloud.ibm.com/docs/containers?topic=containers-updatemachine_type).\n\nYou can also log in to your cluster to check the operating system of the worker nodes.\n\n\n\n1. [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n2. List your worker nodes.\n\nkubectl get nodes\n3. Describe your worker node and check for the operating system label that IBM applies, or the OS Image and Operating System fields in the System Info section.\n\nkubectl describe node <node>\n\nExample output\n\nNAME: 10.xxx.xx.xxx\nRoles: <none>\nLabels: arch=amd64\n...\nibm-cloud.kubernetes.io/os=UBUNTU_18_64\n...\nkubernetes.io/arch=amd64\nkubernetes.io/hostname=10.189.33.198\nkubernetes.io/os=linux\n...\nSystem Info:\nOS Image: Ubuntu 18.04.5 LTS\nOperating System: linux\nArchitecture: amd64\n...\n\n\n\n\n\n\n\n\n\n Virtual machines \n\nWith VMs, you get greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price. You can use VMs for most general-purpose use cases such as testing and development environments, staging, and prod environments, microservices, and business apps. However, there is a tradeoff in performance. If you need high-performance computing for data- or RAM-intensive workloads, consider creating classic clusters with [bare metal](https://cloud.ibm.com/docs/containers?topic=containers-planning_worker_nodesbm) worker nodes.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-planning_worker_nodes"}, {"document_id": "ibmcld_10405-70642-72221", "score": 33.01995, "text": "\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.9.33_1539_openshift\n\n Component Previous Current Description \n\n RHEL 7 Packages N/A N/A Worker node package updates for [CVE-2022-24903](https://nvd.nist.gov/vuln/detail/CVE-2022-24903). \n Red Hat OpenShift on IBM Cloud. 4.9.33 4.9.36 For more information, see the [change log](https://docs.openshift.com/container-platform/4.9/release_notes/ocp-4-9-release-notes.htmlocp-4-9-36). \n\n\n\n\n\n\n\n Change log for master fix pack 4.9.33_1540_openshift, released 3 June 2022 \n\nThe following table shows the changes that are in the master fix pack 4.9.33_1540_openshift. Master patch updates are applied automatically.\n\n\n\nChanges since version 4.9.28_1536_openshift\n\n Component Previous Current Description \n\n Cluster health image v1.3.6 v1.3.7 Updated Go to version 1.17.10 and also updated the dependencies. Update registry base image version to 104 \n IBM Calico extension 954 980 Updated to use Go version 1.17.10. Updated minimal universal base image (UBI) to version 8.5. \n IBM Cloud Block Storage driver and plug-in v2.2.2 v2.2.4 Updated universal base image (UBI) to version 8.6-751 to resolve CVEs. \n IBM Cloud Controller Manager v1.22.8-7 v1.22.10-1 Updated to support the Kubernetes 1.22.10 release. \n IBM Cloud File Storage for Classic plug-in and monitor 408 410 Updated universal base image (UBI) to version 8.6-751 to resolve CVEs. \n IBM Cloud RBAC Operator 8c8c82b 8c96932 Updated Go to version 1.18.1", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_changelog_49"}, {"document_id": "ibmcld_05891-121193-123094", "score": 32.870205, "text": "\nClassic infrastructure\n\nUpdate worker nodes to apply the latest security updates and patches to the operating system, and to update the Kubernetes version to match the version of the Kubernetes master. You can update the master Kubernetes version with the ibmcloud ks cluster master update[command](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_cluster_update). Remember that your worker nodes can be only up to two versions behind the master version (n-2). The worker node IP address remains the same after the update operation.\n\nTo update a worker node in a VPC cluster, use the [ibmcloud ks worker replace command](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clicli_worker_replace) instead.\n\nRunning ibmcloud ks worker update can cause downtime for your apps and services. During the update, all pods are rescheduled onto other worker nodes, the worker node is reimaged, and data is deleted if not stored outside the pod. To avoid downtime, [ensure that you have enough worker nodes to handle your workload while the selected worker nodes are updating](https://cloud.ibm.com/docs/containers?topic=containers-updateworker_node).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https://cloud.ibm.com/docs/satellite?topic=satellite-host-update-workers).\n\nYou might need to change your YAML files for deployments before you update. Review this [release note](https://cloud.ibm.com/docs/containers?topic=containers-cs_versions) for details.\n\nibmcloud ks worker update --cluster CLUSTER --worker WORKER_ID [-f] [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster where you list available worker nodes.\n\n-w, --worker WORKER", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli"}, {"document_id": "ibmcld_06209-18717-20364", "score": 32.811234, "text": "\nComplete the [prerequisite steps](https://cloud.ibm.com/docs/containers?topic=containers-updateworker-up-prereqs) and [set up a config map](https://cloud.ibm.com/docs/containers?topic=containers-updateworker_node) to control how your worker nodes are updated.\n2. From the [IBM Cloud console](https://cloud.ibm.com/) menu ![Menu icon](https://cloud.ibm.com/docs-content/v1/content/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7/icons/icon_hamburger.svg), click Kubernetes.\n3. From the Clusters page, click your cluster.\n4. From the Worker Nodes tab, select the checkbox for each worker node that you want to update. An action bar is displayed over the table header row.\n5. From the action bar, click Update.\n\n\n\nIf you have Portworx installed in your cluster, you must restart the Portworx pods on updated worker nodes. For more information, see [Portworx limitations](https://cloud.ibm.com/docs/containers?topic=containers-storage_portworx_planportworx_limitations).\n\n\n\n\n\n\n\n Updating VPC worker nodes \n\nYou notice that an update is available for your worker nodes in a [VPC infrastructure cluster](https://cloud.ibm.com/docs/containers?topic=containers-infrastructure_providers). What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only VPC clusters. Have a classic cluster? See [Updating classic worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updateworker_node) instead.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-update"}, {"document_id": "ibmcld_10068-145546-146168", "score": 32.57883, "text": "\nThe following table shows the changes that are in the worker node fix pack update 4.3.40_1546_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.3.40_1545_openshift\n\n Component Previous Current Description \n\n Ephemeral storage reservations N/A N/A Local ephemeral storage is reserved on the Kubernetes data disk for system components. For more information, see [Worker node resource reserves](https://cloud.ibm.com/docs/openshift?topic=openshift-planning_worker_nodesresource_limit_node).", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-changelog_archive"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10510-17837-19983", "score": 22.420715, "text": "\nWorker nodes carry the deployments and services that make up your app. When you host workloads in the public cloud, you want to ensure that your app is protected from being accessed, changed, or monitored by an unauthorized user or software.\n\n\n\n Who owns the worker node and am I responsible to secure it? \n\nThe ownership of a worker node depends on the type of cluster that you create and the infrastructure provider that you choose.\n\n\n\n* Classic clusters: Worker nodes are provisioned in to your IBM Cloud account. The worker nodes are dedicated to you and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and IBM Cloud Kubernetes Service components apply the latest security updates and patches.\n* VPC clusters: Worker nodes are provisioned in to an IBM Cloud account that is owned by IBM to enable monitoring of malicious activities and apply security updates. You can't access your worker nodes by using the VPC dashboard. However, you can manage your worker nodes by using the IBM Cloud Kubernetes Service console, CLI, or API. The virtual machines that make up your worker nodes are dedicated to you and you are responsible to request timely updates so that your worker node OS and IBM Cloud Kubernetes Service components apply the latest security updates and patches.\n\n\n\nFor more information, see [Your responsibilities by using Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-responsibilities_iks).\n\nUse the ibmcloud oc worker update[command](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clics_worker_update) regularly (such as monthly) to deploy updates and security patches to the operating system and to update the Red Hat OpenShift version that your worker nodes run. When updates are available, you are notified when you view information about the master and worker nodes in the IBM Cloud console or CLI, such as with the ibmcloud oc clusters ls or ibmcloud oc workers ls --cluster <cluster_name> commands. Worker node updates are provided by IBM as a full worker node image that includes the latest security patches.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-security"}, {"document_id": "ibmcld_06079-10297-12436", "score": 22.300285, "text": "\nWorker node With IBM Cloud Kubernetes Service, the virtual machines that your cluster manages are instances that are called worker nodes. These worker nodes virtual machines and all the worker node components are dedicated to you only and are not shared with other IBM customers. However, the underlying hardware is shared with other IBM customers. For more information, see [Virtual machines](https://cloud.ibm.com/docs/containers?topic=containers-planning_worker_nodesvm). You manage the worker nodes through the automation tools that are provided by IBM Cloud Kubernetes Service, such as the API, CLI, or console. Unlike classic clusters, you don't see VPC compute worker nodes in your infrastructure portal or separate infrastructure bill, but instead manage all maintenance and billing activity for the worker nodes from IBM Cloud Kubernetes Service. Worker nodes include the same [components](https://cloud.ibm.com/docs/containers?topic=containers-service-archworker-components) as described in the Classic architecture. Community Kubernetes worker nodes run on Ubuntu 18.04 x86_64, 16.04 x86_64 (deprecated). \n Cluster networking Your worker nodes are created in a VPC subnet in the zone that you specify. By default, the public and private cloud service endpoints for your cluster are enabled. Communication between the master and worker nodes is over the private network. Authenticated external users can communicate with the master over the public network, such as to run kubectl commands. You can optionally set up your cluster to communicate with on-prem services by setting up a VPC VPN on the private network. \n App networking You can create a Kubernetes LoadBalancer service for your apps in the cluster, which automatically provisions a VPC load balancer in your VPC outside the cluster. The load balancer is multizonal and routes requests for your app through the private NodePorts that are automatically opened on your worker nodes. For more information, see [Exposing apps with VPC load balancers](https://cloud.ibm.com/docs/containers?topic=containers-vpc-lbaas). Calico is used as the cluster networking policy fabric.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-service-arch"}, {"document_id": "ibmcld_06057-8483-10325", "score": 22.06279, "text": "\nWorker nodes <br><br> * Provide worker node patch operating system (OS), version, and security updates.<br> * Fulfill automation requests to update and recover worker nodes.<br><br><br> <br><br> * Use the API, CLI, or console tools to [apply](https://cloud.ibm.com/docs/containers?topic=containers-updateupdate) the provided worker node updates that include operating system patches; or to request that worker nodes are rebooted, reloaded, or replaced.<br><br><br> \n Cluster version <br><br> * Provide a suite of tools to automate cluster management, such as the IBM Cloud Kubernetes Service [API](https://containers.cloud.ibm.com/global/swagger-global-api//), [CLI plug-in](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli), and [console](https://cloud.ibm.com/kubernetes/clusters).<br> * Automatically apply Kubernetes master patch OS, version, and security updates.<br> * Make major and minor updates for master nodes available for you to apply.<br> * Provide worker node major, minor, and patch OS, version, and security updates.<br> * Fulfill automation requests to update cluster master and worker nodes.<br><br><br> <br><br> * Use the API, CLI, or console tools to [apply](https://cloud.ibm.com/docs/containers?topic=containers-updateupdate) the provided major and minor Kubernetes master updates and major, minor, and patch worker node updates.<br><br><br> \n\n\n\n\n\n\n\n Identity and access management \n\nYou and IBM share responsibilities for controlling access to your IBM Cloud Kubernetes Service instances. For IBM Cloud\u00ae Identity and Access Management responsibilities, consult that product's documentation. You are responsible for identity and access management to your application data.\n\n\n\nTable 4. Responsibilities for identity and access management\n\n Resource IBM responsibilities Your responsibilities", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-responsibilities_iks"}, {"document_id": "ibmcld_06010-6040-7693", "score": 22.01851, "text": "\nTo update the version of the operating system that a worker node uses, such as from Ubuntu 16 to 18, you can [replace the flavor of the worker pool](https://cloud.ibm.com/docs/containers?topic=containers-updatemachine_type).\n\nYou can also log in to your cluster to check the operating system of the worker nodes.\n\n\n\n1. [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n2. List your worker nodes.\n\nkubectl get nodes\n3. Describe your worker node and check for the operating system label that IBM applies, or the OS Image and Operating System fields in the System Info section.\n\nkubectl describe node <node>\n\nExample output\n\nNAME: 10.xxx.xx.xxx\nRoles: <none>\nLabels: arch=amd64\n...\nibm-cloud.kubernetes.io/os=UBUNTU_18_64\n...\nkubernetes.io/arch=amd64\nkubernetes.io/hostname=10.189.33.198\nkubernetes.io/os=linux\n...\nSystem Info:\nOS Image: Ubuntu 18.04.5 LTS\nOperating System: linux\nArchitecture: amd64\n...\n\n\n\n\n\n\n\n\n\n Virtual machines \n\nWith VMs, you get greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price. You can use VMs for most general-purpose use cases such as testing and development environments, staging, and prod environments, microservices, and business apps. However, there is a tradeoff in performance. If you need high-performance computing for data- or RAM-intensive workloads, consider creating classic clusters with [bare metal](https://cloud.ibm.com/docs/containers?topic=containers-planning_worker_nodesbm) worker nodes.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-planning_worker_nodes"}, {"document_id": "ibmcld_05891-116023-117972", "score": 21.970617, "text": "\nYou might replace a worker node if you can't reload or update the worker node, such as if it enters a troubled state.\n\nYou can also use this command to update the Kubernetes version of the worker node to match the major and minor version of the Kubernetes master by including the --update option. If you don't include the --update option, patch version updates are applied to your worker node, but not major or minor updates. To see the changes from one major, minor, or patch version to the next, review the [Version change log](https://cloud.ibm.com/docs/containers?topic=containers-changelog) documentation. Remember that your worker nodes can be only up to two versions behind the master version (n-2).\n\nWhen you replace a worker node, keep in mind the following considerations.\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https://cloud.ibm.com/docs/satellite?topic=satellite-host-update-workers).\n\n\n\n* Multiple worker nodes are replaced concurrently: If you replace multiple worker nodes at the same time, they are deleted and replaced concurrently, not one by one. Make sure that you have enough capacity in your cluster to reschedule your workloads before you replace worker nodes.\n* Node-level customizations are not preserved: Any custom labels or taints that you applied at the individual worker node level are not applied to the replacement worker node. Instead, apply [labels](https://cloud.ibm.com/docs/containers?topic=containers-add_workersworker_pool_labels) or [taints](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cliworker_pool_taint) at the worker pool level so that the replacement worker node gets these attributes.\n* Automatic rebalancing: A replacement worker node is not created if the worker pool does not have [automatic rebalancing enabled](https://cloud.ibm.com/docs/containers?topic=containers-auto-rebalance-off).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli"}, {"document_id": "ibmcld_05532-6113-7708", "score": 21.916185, "text": "\nThe worker node can be fixed by using the ibmcloud ks worker reload[command](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_worker_reload) or the ibmcloud ks worker update[command](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_worker_update). \n Worker node runtime components (kubelet, kube-proxy, docker) N/A N/A Removed dependencies of runtime components on the primary disk. This enhancement prevents worker nodes from failing when the primary disk is filled up. \n Root password expiration N/A N/A Root passwords for the worker nodes expire after 90 days for compliance reasons. If your automation tooling needs to log in to the worker node as root or relies on cron jobs that run as root, you can disable the password expiration by logging into the worker node and running chage -M -1 root. Note: If you have security compliance requirements that prevent running as root or removing password expiration, don't disable the expiration. Instead, you can [update](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_worker_update) or [reload](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_worker_reload) your worker nodes at least every 90 days. \n systemd N/A N/A Periodically clean transient mount units to prevent them from becoming unbounded. This action addresses [Kubernetes issue 57345](https://github.com/kubernetes/kubernetes/issues/57345) \n Docker N/A N/A Disabled the default Docker bridge so that the 172.17.0.0/16 IP range is now used for private routes.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-19_changelog"}, {"document_id": "ibmcld_10505-8460-10320", "score": 21.889452, "text": "\nWorker nodes <br><br> * Provide worker node patch operating system (OS), version, and security updates.<br> * Fulfill automation requests to update and recover worker nodes.<br><br><br> <br><br> * Use the API, CLI, or console tools to [apply](https://cloud.ibm.com/docs/containers?topic=containers-updateupdate) the provided worker node updates that include operating system patches; or to request that worker nodes are rebooted, reloaded, or replaced.<br><br><br> \n Cluster version <br><br> * Provide a suite of tools to automate cluster management, such as the Red Hat OpenShift on IBM Cloud [API](https://containers.cloud.ibm.com/global/swagger-global-api//), [CLI plug-in](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli), and [console](https://cloud.ibm.com/kubernetes/clusters).<br> * Automatically apply Red Hat OpenShift master patch OS, version, and security updates.<br> * Make major and minor updates for master nodes available for you to apply.<br> * Provide worker node major, minor, and patch OS, version, and security updates.<br> * Fulfill automation requests to update cluster master and worker nodes.<br><br><br> <br><br> * Use the API, CLI, or console tools to [apply](https://cloud.ibm.com/docs/containers?topic=containers-updateupdate) the provided major and minor Red Hat OpenShift master updates and major, minor, and patch worker node updates.<br><br><br> \n\n\n\n\n\n\n\n Identity and access management \n\nYou and IBM share responsibilities for controlling access to your Red Hat OpenShift on IBM Cloud instances. For IBM Cloud\u00ae Identity and Access Management responsibilities, consult that product's documentation. You are responsible for identity and access management to your application data.\n\n\n\nTable 4. Responsibilities for identity and access management\n\n Resource IBM responsibilities Your responsibilities", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-satellite-responsibilities"}, {"document_id": "ibmcld_05521-21979-23575", "score": 21.875532, "text": "\nThe worker node can be fixed by using the ibmcloud ks worker reload[command](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_worker_reload) or the ibmcloud ks worker update[command](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_worker_update). \n Worker node runtime components (kubelet, kube-proxy, docker) N/A N/A Removed dependencies of runtime components on the primary disk. This enhancement prevents worker nodes from failing when the primary disk is filled up. \n Root password expiration N/A N/A Root passwords for the worker nodes expire after 90 days for compliance reasons. If your automation tooling needs to log in to the worker node as root or relies on cron jobs that run as root, you can disable the password expiration by logging into the worker node and running chage -M -1 root. Note: If you have security compliance requirements that prevent running as root or removing password expiration, don't disable the expiration. Instead, you can [update](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_worker_update) or [reload](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_worker_reload) your worker nodes at least every 90 days. \n systemd N/A N/A Periodically clean transient mount units to prevent them from becoming unbounded. This action addresses [Kubernetes issue 57345](https://github.com/kubernetes/kubernetes/issues/57345). \n Docker N/A N/A Disabled the default Docker bridge so that the 172.17.0.0/16 IP range is now used for private routes.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-110_changelog"}, {"document_id": "ibmcld_04489-116642-118577", "score": 21.85465, "text": "\nYou might replace a worker node if you can't reload or update the worker node, such as if it enters a troubled state.\n\nYou can also use this command to update the Kubernetes version of the worker node to match the major and minor version of the Kubernetes master by including the --update option. If you don't include the --update option, patch version updates are applied to your worker node, but not major or minor updates. To see the changes from one major, minor, or patch version to the next, review the [Version change log](https://cloud.ibm.com/docs/containers?topic=containers-changelog) documentation. Remember that your worker nodes can be only up to two versions behind the master version (n-2).\n\nWhen you replace a worker node, keep in mind the following considerations.\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https://cloud.ibm.com/docs/satellite?topic=satellite-host-update-workers).\n\n\n\n* Multiple worker nodes are replaced concurrently: If you replace multiple worker nodes at the same time, they are deleted and replaced concurrently, not one by one. Make sure that you have enough capacity in your cluster to reschedule your workloads before you replace worker nodes.\n* Node-level customizations are not preserved: Any custom labels or taints that you applied at the individual worker node level are not applied to the replacement worker node. Instead, apply [labels](https://cloud.ibm.com/docs/containers?topic=containers-add_workersworker_pool_labels) or [taints](https://cloud.ibm.com/docs/cli?topic=cli-kubernetes-service-cliworker_pool_taint) at the worker pool level so that the replacement worker node gets these attributes.\n* Automatic rebalancing: A replacement worker node is not created if the worker pool does not have [automatic rebalancing enabled](https://cloud.ibm.com/docs/containers?topic=containers-auto-rebalance-off).", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-kubernetes-service-cli"}, {"document_id": "ibmcld_10488-8451-10309", "score": 21.818499, "text": "\nWorker nodes <br><br> * Provide worker node patch operating system (OS), version, and security updates.<br> * Fulfill automation requests to update and recover worker nodes.<br><br><br> <br><br> * Use the API, CLI, or console tools to [apply](https://cloud.ibm.com/docs/containers?topic=containers-updateupdate) the provided worker node updates that include operating system patches; or to request that worker nodes are rebooted, reloaded, or replaced.<br><br><br> \n Cluster version <br><br> * Provide a suite of tools to automate cluster management, such as the Red Hat OpenShift on IBM Cloud [API](https://containers.cloud.ibm.com/global/swagger-global-api//), [CLI plug-in](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-cli), and [console](https://cloud.ibm.com/kubernetes/clusters).<br> * Automatically apply Red Hat OpenShift master patch OS, version, and security updates.<br> * Make major and minor updates for master nodes available for you to apply.<br> * Provide worker node major, minor, and patch OS, version, and security updates.<br> * Fulfill automation requests to update cluster master and worker nodes.<br><br><br> <br><br> * Use the API, CLI, or console tools to [apply](https://cloud.ibm.com/docs/containers?topic=containers-updateupdate) the provided major and minor Red Hat OpenShift master updates and major, minor, and patch worker node updates.<br><br><br> \n\n\n\n\n\n\n\n Identity and access management \n\nYou and IBM share responsibilities for controlling access to your Red Hat OpenShift on IBM Cloud instances. For IBM Cloud\u00ae Identity and Access Management responsibilities, consult that product's documentation. You are responsible for identity and access management to your application data.\n\n\n\nTable 4. Responsibilities for identity and access management\n\n Resource IBM responsibilities Your responsibilities", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-responsibilities_iks"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10399-36221-37434", "score": 28.600567, "text": "\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.11.13_1533_openshift\n\n Component Previous Current Description \n\n RHEL 8 Packages N/A N/A Worker node package updates for [CVE-2022-42898](https://nvd.nist.gov/vuln/detail/CVE-2022-42898). \n Red Hat OpenShift on IBM Cloud. 4.11.13 4.11.17 For more information, see the [change log](https://docs.openshift.com/container-platform/4.11/release_notes/ocp-4-11-release-notes.htmlocp-4-11-17). \n HAProxy c619f4 508bf6 [CVE-2016-3709](https://nvd.nist.gov/vuln/detail/CVE-2016-3709), [CVE-2022-42898](https://nvd.nist.gov/vuln/detail/CVE-2022-42898), [CVE-2022-1304](https://nvd.nist.gov/vuln/detail/CVE-2022-1304). \n\n\n\n\n\n\n\n Change log for worker node fix pack 4.11.13_1533_openshift, released 21 November 2022 \n\nThe following table shows the changes that are in the worker node fix pack 4.11.13_1533_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.11.12_1530_openshift\n\n Component Previous Current Description", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_changelog_411"}, {"document_id": "ibmcld_10068-170960-171999", "score": 28.576982, "text": "\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.3.29_1533_openshift\n\n Component Previous Current Description \n\n Red Hat OpenShift 4.3.29 4.3.31 See the [Red Hat OpenShift release notes](https://docs.openshift.com/container-platform/4.3/release_notes/ocp-4-3-release-notes.htmlocp-4-3-31). The update resolves CVE-2020-8558 (see the [IBM security bulletin](https://www.ibm.com/support/pages/node/6319989)). \n RHEL 7 packages N/A N/A Updated worker node images with package updates. \n\n\n\n\n\n\n\n Change log for worker node fix pack 4.3.29_1533_openshift, released 3 August 2020 \n\nThe following table shows the changes that are in the worker node fix pack update 4.3.29_1533_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.3.29_1532_openshift\n\n Component Previous Current Description", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-changelog_archive"}, {"document_id": "ibmcld_10405-59853-60989", "score": 28.566414, "text": "\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.9.45_1550_openshift\n\n Component Previous Current Description \n\n RHEL 7 Packages N/A N/A Worker node package updates for [CVE-2022-2526](https://nvd.nist.gov/vuln/detail/CVE-2022-2526). \n Red Hat OpenShift on IBM Cloud. 4.9.45 4.9.46 For more information, see the [change log](https://docs.openshift.com/container-platform/4.9/release_notes/ocp-4-9-release-notes.htmlocp-4-9-46). \n HAProxy 6514a2 c1634f [CVE-2022-32206](https://nvd.nist.gov/vuln/detail/CVE-2022-32206), [CVE-2022-32208](https://nvd.nist.gov/vuln/detail/CVE-2022-32208) \n\n\n\n\n\n\n\n Change log for worker node fix pack 4.9.45_1550_openshift, released 16 August 2022 \n\nThe following table shows the changes that are in the worker node fix pack 4.9.45_1550_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.9.43_1549_openshift\n\n Component Previous Current Description", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_changelog_49"}, {"document_id": "ibmcld_10068-154779-156261", "score": 28.439901, "text": "\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.3.38_1542_openshift\n\n Component Previous Current Description \n\n Red Hat OpenShift 4.3.38 4.3.40 See the [Red Hat OpenShift release notes](https://docs.openshift.com/container-platform/4.3/release_notes/ocp-4-3-release-notes.htmlocp-4-3-40). \n RHEL 7 Packages 3.10.0-1160.2.1.el7 3.10.0-1160.2.2.el7 Updated worker node images with kernel and package updates for [CVE-2020-12351](https://nvd.nist.gov/vuln/detail/CVE-2020-12351) and [CVE-2020-12352](https://nvd.nist.gov/vuln/detail/CVE-2020-12352). \n\n\n\n\n\n\n\n Change log for master fix pack 4.3.38_1544_openshift, released 26 October 2020 \n\nThe following table shows the changes that are in the master fix pack patch update 4.3.38_1544_openshift. Master patch updates are applied automatically.\n\n\n\nChanges since version 4.3.35_1539_openshift\n\n Component Previous Current Description \n\n Cluster health image v1.1.11 v1.1.12 Fixed check for unsupported add-ons. Updated to use Go version 1.15.2. \n Gateway-enabled cluster controller 1082 1105 Updated to use Go version 1.15.2. \n IBM Cloud Block Storage for Classic driver and plug-in 1.17.1 1.17.2 Updated to use Go version 1.13.15. \n IBM Cloud Controller Manager v1.17.12-1 v1.17.13-1 Updated to support the Kubernetes 1.17.13 release. \n IBM Cloud RBAC Operator 4b47693 31c794a Updated to use Go version 1.15.2.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-changelog_archive"}, {"document_id": "ibmcld_10399-3896-5129", "score": 28.373201, "text": "\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.11.42_1558_openshift\n\n Component Previous Current Description \n\n Red Hat OpenShift on IBM Cloud. 4.11.42 4.11.43 see [change logs](https://docs.openshift.com/container-platform/4.11/release_notes/ocp-4-11-release-notes.htmlocp-4-11-43). \n RHEL 8 Packages N/A N/A Worker node package updates for [CVE-2023-32067](https://nvd.nist.gov/vuln/detail/CVE-2023-32067),[CVE-2023-24329](https://nvd.nist.gov/vuln/detail/CVE-2023-24329). \n\n\n\n\n\n\n\n Change log for worker node fix pack 4.11.42_1558_openshift, released 5 June 2023 \n\nThe following table shows the changes that are in the worker node fix pack 4.11.42_1558_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.11.40_1556_openshift\n\n Component Previous Current Description \n\n Red Hat OpenShift on IBM Cloud. 4.11.40 4.11.42 see [change logs](https://docs.openshift.com/container-platform/4.11/release_notes/ocp-4-11-release-notes.htmlocp-4-11-42). \n RHEL 7 Packages N/A N/A N/A", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_changelog_411"}, {"document_id": "ibmcld_10405-6886-7734", "score": 28.315264, "text": "\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.9.59_1588_openshift\n\n Component Previous Current Description \n\n Red Hat OpenShift on IBM Cloud N/A N/A N/A \n RHEL 7 Packages 4.15.0-210-generic 4.15.0-211-generic N/A \n RHEL 8 Packages 4.18.0-425.19.2.el8_7 4.18.0-477.10.1.el8_8 Worker node kernel & package updates for [CVE-2020-10735](https://nvd.nist.gov/vuln/detail/CVE-2020-10735), [CVE-2021-26341](https://nvd.nist.gov/vuln/detail/CVE-2021-26341), [CVE-2021-28861](https://nvd.nist.gov/vuln/detail/CVE-2021-28861), [CVE-2021-33655](https://nvd.nist.gov/vuln/detail/CVE-2021-33655), [CVE-2021-33656](https://nvd.nist.gov/vuln/detail/CVE-2021-33656), [CVE-2022-1462](https://nvd.nist.gov/vuln/detail/CVE-2022-1462), [CVE", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_changelog_49"}, {"document_id": "ibmcld_10284-1470-3569", "score": 28.288996, "text": "\n* Image and version updates: Worker node updates, such as security patches to the image or Red Hat OpenShift versions, are provided by IBM for you. However, you choose when to apply the updates to the worker nodes. For more information, see [Updating clusters, worker nodes, and cluster components](https://cloud.ibm.com/docs/containers?topic=containers-update).\n* Temporary modifications: If you log in to a pod or use some other process to modify a worker node setting, the modifications are temporary. Worker node lifecycle operations, such as autorecovery, reloading, updating, or replacing a worker node, change any modifications back to the default settings.\n* Persistent modifications: For modifications to persist across worker node lifecycle operations, create a daemon set that uses an init container. For more information, see [Modifying default worker node settings to optimize performance](https://cloud.ibm.com/docs/openshift?topic=openshift-kernelworker).\n\n\n\nModifications to the operating system are not supported. If you modify the default settings, you are responsible for debugging and resolving the issues that might occur.\n\n\n\n\n\n Hardware changes \n\nTo change the compute hardware, such as the CPU and memory per worker node, choose among the following options.\n\n\n\n* [Create a worker pool](https://cloud.ibm.com/docs/openshift?topic=openshift-add_workers). The instructions vary depending on the type of infrastructure for the cluster, such as classic, VPC, Satellite, or gateway clusters.\n* [Update the flavor](https://cloud.ibm.com/docs/containers?topic=containers-updatemachine_type) in your cluster by creating a worker pool and removing the previous worker pool.\n\n\n\n\n\n\n\n\n\n Modifying worker node settings to optimize performance \n\n\n\n Modifying worker node settings by using the Node Tuning Operator \n\nYou can use the node tuning operator to tune worker node performance by creating custom profiles. For more information, see the Red Hat [Node Tuning Operator](https://docs.openshift.com/container-platform/4.7/scalability_and_performance/using-node-tuning-operator.html) docs.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-kernel"}, {"document_id": "ibmcld_10400-7104-8022", "score": 28.282808, "text": "\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.12.15_1542_openshift\n\n Component Previous Current Description \n\n Red Hat OpenShift on IBM Cloud. 4.12.15 4.12.16 see [change logs](https://docs.openshift.com/container-platform/4.12/release_notes/ocp-4-12-release-notes.htmlocp-4-12-16). \n RHEL 8 Packages 4.18.0-425.19.2.el8_7 4.18.0-477.10.1.el8_8 Worker node kernel & package updates for [CVE-2020-10735](https://nvd.nist.gov/vuln/detail/CVE-2020-10735), [CVE-2021-26341](https://nvd.nist.gov/vuln/detail/CVE-2021-26341), [CVE-2021-28861](https://nvd.nist.gov/vuln/detail/CVE-2021-28861), [CVE-2021-33655](https://nvd.nist.gov/vuln/detail/CVE-2021-33655), [CVE-2021-33656](https://nvd.nist.gov/vuln/detail/CVE-2021-33656), [CVE-2022-1462](https://nvd.nist.gov/vuln/detail/CVE-2022-1462), [CVE", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_changelog_412"}, {"document_id": "ibmcld_10399-7236-8154", "score": 28.259508, "text": "\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.11.39_1554_openshift\n\n Component Previous Current Description \n\n Red Hat OpenShift on IBM Cloud. 4.11.39 4.11.40 see [change logs](https://docs.openshift.com/container-platform/4.11/release_notes/ocp-4-11-release-notes.htmlocp-4-11-40). \n RHEL 8 Packages 4.18.0-425.19.2.el8_7 4.18.0-477.10.1.el8_8 Worker node kernel & package updates for [CVE-2020-10735](https://nvd.nist.gov/vuln/detail/CVE-2020-10735), [CVE-2021-26341](https://nvd.nist.gov/vuln/detail/CVE-2021-26341), [CVE-2021-28861](https://nvd.nist.gov/vuln/detail/CVE-2021-28861), [CVE-2021-33655](https://nvd.nist.gov/vuln/detail/CVE-2021-33655), [CVE-2021-33656](https://nvd.nist.gov/vuln/detail/CVE-2021-33656), [CVE-2022-1462](https://nvd.nist.gov/vuln/detail/CVE-2022-1462), [CVE", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_changelog_411"}, {"document_id": "ibmcld_10068-125228-126679", "score": 28.187485, "text": "\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.4.18_1516_openshift\n\n Component Previous Current Description \n\n CRI-O 1.17.4 1.17.5 See the [CRI-O release notes](https://github.com/cri-o/cri-o/releases/tag/v1.17.5). \n Red Hat OpenShift 4.4.18 4.4.20 See the [Red Hat OpenShift release notes](https://docs.openshift.com/container-platform/4.3/release_notes/ocp-4-3-release-notes.htmlocp-4-4-20). The update resolves CVE-2020-8557 (see the [IBM security bulletin](https://www.ibm.com/support/pages/node/6343881)). \n RHEL 7 packages N/A N/A Updated worker node image with package updates. \n\n\n\n\n\n\n\n Change log for worker node fix pack 4.4.18_1516_openshift, released 31 August 2020 \n\nThe following table shows the changes that are in the worker node fix pack update 4.4.18_1516_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.4.16_1513_openshift\n\n Component Previous Current Description \n\n Master proxy 1.8.25-384f42 1.8.26-561f1a See the [HAProxy change logs](https://www.haproxy.org/download/1.8/src/CHANGELOG). \n Red Hat OpenShift 4.4.16 4.4.18 See the [Red Hat OpenShift release notes](https://docs.openshift.com/container-platform/4.3/release_notes/ocp-4-3-release-notes.htmlocp-4-4-18).", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-changelog_archive"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_14913-0-1238", "score": 22.586002, "text": "\n\n\n\n\n\n\n  About virtual network functions over VPC \n\nNetwork Function Virtualization (NFV) is the network infrastructure behind virtualizing network services (such as routers, firewalls, and load balancers) that were traditionally run on proprietary hardware. These services, called Virtual Network Functions (VNFs), are packaged as virtual machines (VMs) on commodity hardware, which allows service providers to run their networks on standard servers instead of proprietary ones. This third-party software interacts with the IBM Software-Defined Networking (SDN) controller to offer easy configuration, centralized management, and lower operational costs.\n\nWorking along with IBM Cloud\u00ae Schematics (Infrastructure as Code) and the IBM Content catalog, customers are able to instantiate best-in-network solutions to manage their workload.\n\nBenefits include:\n\n\n\n*  Instantiating virtual network services and modifying configurations without the need to deploy new network hardware.\n*  Rapid service delivery with the agility to scale well above physical hardware.\n*  Centralized policy control.\n*  Using the same routers, firewalls, load balancers, and VPNs in IBM Cloud that were used in physical hardware or other cloud providers.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-about-vnf"}, {"document_id": "ibmcld_16026-0-358", "score": 17.76888, "text": "\n\n\n\n\n\n\n  VNF limitations \n\nHigh Availability (HA) Virtual Network Function (VNF) deployments have the following known limitations.\n\n\n\n*  The Virtual Network Function (VNF) must share one subnet with the Network Load Balancer (NLB).\n*  Routing public internet \"ingress\" traffic to a VNF is not supported.\n*  Auto-scaling with the VNF is not supported.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vnf-limitations"}, {"document_id": "ibmcld_14282-7-2547", "score": 15.52481, "text": "\nVMware vSphere NSX overview \n\nVMware NSX\u00ae is a software networking and security virtualization platform that delivers the operational model of a virtual machine for the network. Virtual networks reproduce the Layer2 - Layer7 network model in software, allowing complex multitier network topologies to be created and provisioned programmatically in seconds, without the need for extra IBM Cloud private networks. NSX also provides a new model for network security. Security profiles are distributed to and enforced by virtual ports and move with virtual machines.\n\nNSX supports the VMware software-defined data center strategy. By extending the virtualization capabilities of abstraction, pooling and automation across all data center resources and services, the software-defined data center architecture simplifies and speeds the provisioning and management of compute, storage, and networking resources through policy-driven automation. By virtualizing the network, NSX delivers a new operational model for networking that breaks through current physical network barriers and enables VMware and IBM Cloud to achieve better speed and agility with reduced costs.\n\nNSX includes a library of logical networking services - logical switches, logical routers, logical firewalls, logical load balancers, logical VPN, and distributed security. You can create custom combinations of these services in isolated software-based virtual networks that support existing applications without modification, or deliver unique requirements for new application workloads. Virtual networks are programmatically provisioned and managed independent of IBM Cloud networking constructs. This decoupling from hardware introduces agility, speed, and operational efficiency that can transform data center operations. Benefits of NSX include the following features:\n\n\n\n* Data center automation\n* Self-service networking services\n* Rapid application deployment with automated network and service provisioning\n* Isolation of development, test, and production environments on the same bare metal infrastructure\n* Single Account multi-tenant clouds\n\n\n\nNSX can be configured through the vSphere Web Client, a command line interface (CLI), and REST API. The core network services that are offered by NSX are:\n\n\n\n Logical switches \n\nA cloud deployment or a virtual data center might have various applications across multiple tenants. These applications and tenants require isolation from each other for security, fault isolation, and avoiding overlapping IP addressing issues.", "title": "", "source": "https://cloud.ibm.com/docs/vmware?topic=vmware-nsx-overview"}, {"document_id": "ibmcld_15151-0-569", "score": 15.440698, "text": "\n\n\n\n\n\n\n  Configuring security groups \n\nThe Virtual Network Function (VNF) data network interface is attached to a VPC security group. Ensure that the security group has inbound rules that allow traffic on the pool health port that is set up between the NLB and the VNF. For example, if the health check is set up for TCP on port 80 (HTTP), then create an inbound rule for that security group. Additionally, you can create rules to allow or restrict data traffic.\n\n\n\n  Next step \n\n[Deploying a supported VNF](https://cloud.ibm.com/docs/vpc?topic=vpc-deploy-vnf)\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-configure-security-groups"}, {"document_id": "ibmcld_11566-3389-5547", "score": 15.414882, "text": "\n* Private network: provides complete control of the secured networking traffic without performance degradation if significant public network traffic occurs at the same time; the private network has three functional areas:\n\n\n\n* Host to and from Host: network traffic in the private VLANs assigned to you. Bandwidth is free and unmetered.\n* Host to and from Backend Services: network traffic to and from the private VLAN to OS update servers, NTP, DNS resolvers, network storage and more. Bandwidth is free and unmetered.\n* VPN and direct connections to and from VLAN: network traffic to and from an existing internal network over direct connection or VPN that uses a distinct stand-alone network to the secure private VLAN. Bandwidth is free and unmetered.\n* Data center to Data center interconnectivity: provides secure connectivity between hosts across IBM Cloud data center locations. Bandwidth is free and unmetered.\n\n\n\n* Management network: provides Out-Of-Band Management (OOBM) accessible through VPN (for example the built-in SSL VPN for administration) or direct connection (for example IBM Cloud Direct Link). Network management allows Remote Console access through the IPMI network interface for Bare Metals hosts on the private network. Bandwidth is free and unmetered.\n\n\n\nThis network-within-a-network topology design provides maximum accessibility, security, and control for your IT infrastructure. The topology provides the ease of a public network with the security of a private network by keeping systems accessible to administrators and safely off-limits to external users.\n\n\n\n Networking VLANs \n\nThe Virtual LAN (VLAN) assigned to you on the Classic Infrastructure network, provides an enterprise-grade private network with full isolation and security. Each VLAN is either public or private, and each VLAN is assigned to a specific data center for a specific IBM Cloud Account.\n\nThe following information is a summary of [Getting started with VLANs on Classic Infrastructure](https://cloud.ibm.com/docs/vlans?topic=vlans-getting-started) and [About VLANs on Classic Infrastructure](https://cloud.ibm.com/docs/vlans?topic=vlans-about-vlans).", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-classic-env-introduction"}, {"document_id": "ibmcld_16030-7-2126", "score": 15.140315, "text": "\nVPC behind the curtain \n\nThe following information presents a detailed conceptual picture of what's happening \"behind the curtain\" in VPC networking. Learn about network isolation, address prefixes, Cloud Service Endpoint source addresses, data packet flows, external IP address lifecycle, and Classic infrastructure access. Readers are expected to have some networking background.\n\n\n\n Network isolation \n\nVPC network isolation takes place at three levels:\n\n\n\n* Hypervisor - The virtual server instances are isolated by the hypervisor. A virtual server instance can't directly reach other virtual server instances that are hosted by the same hypervisor if they are not in the same VPC.\n* Network - Isolation occurs at the network level by using virtual network identifiers (VNIs). These identifiers are assigned to each subnet and scoped to a single zone. A VNI is added to all data packets that enter any zone of the VPC: entering either from the hypervisor, when sent by a virtual server instance, or entering the zone from the cloud, when sent by the implicit routing function.\n\nA packet that leaves a zone has the VNI stripped off. When the packet reaches its destination zone, entering through the implicit routing function, the implicit router always adds the proper VNI for that zone.\n* Router - The implicit router function provides isolation to each VPC by providing a virtual routing function (VRF) and a VPN with MPLS (multi-protocol label switching) in the cloud backbone. Each VPC's VRF has a unique identifier, and this isolation allows each VPC to have access to its own copy of the IPv4 address space. The MPLS VPN allows for federating all edges of the cloud: Classic Infrastructure, Direct Link, and VPC.\n\n\n\n\n\n\n\n Address prefixes \n\nAddress prefixes are the summary information that is used by a VPC's implicit routing function to locate a destination virtual server instance, regardless of the availability zone in which the destination virtual server instance is located. The primary function of address prefixes is to optimize routing over the MPLS VPN, while pathological routing cases are avoided.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-behind-the-curtain"}, {"document_id": "ibmcld_14282-1986-4283", "score": 15.084047, "text": "\n* Isolation of development, test, and production environments on the same bare metal infrastructure\n* Single Account multi-tenant clouds\n\n\n\nNSX can be configured through the vSphere Web Client, a command line interface (CLI), and REST API. The core network services that are offered by NSX are:\n\n\n\n Logical switches \n\nA cloud deployment or a virtual data center might have various applications across multiple tenants. These applications and tenants require isolation from each other for security, fault isolation, and avoiding overlapping IP addressing issues. The NSX logical switch creates logical broadcast domains or segments (VXLAN vWires) to which an application or tenant virtual machine can be logically wired. This feature allows for flexibility and speed of deployment while still providing all the characteristics of a physical network's broadcast domains (VLANs) without physical Layer 2 sprawl. Logical switches allow for thousands of tenant networks to be provisioned onto a single IBM Cloud private network (VLAN). A logical switch is distributed and can span arbitrarily large compute clusters, even across pods within the same data center. This distribution allows for virtual machine mobility within the data center without limitations of physical Layer 2 (VLAN) boundaries across pods.\n\n\n\n\n\n Logical routers \n\nDynamic routing provides the necessary forwarding information between Layer 2 broadcast domains (VXLAN, vWires, Logical Switches). This routing decreases Layer 2 broadcast domains and improve network efficiency and scale. NSX extends this intelligence where the workloads reside for providing East-West routing functions. This extension allows more direct virtual machine to virtual machine communication without the costly or timely need to extend hops. NSX also provides North-South connectivity inbound and outbound of IBM Cloud data centers, thus enabling tenants to access public networks securely and efficiently.\n\n\n\n\n\n Logical firewall \n\nLogical firewall provides security mechanisms for dynamic virtual data centers. The Distributed Firewall component of an NSX Logical Firewall allows users to segment virtual data center entities (virtual servers), vCenter objects (data centers and hosts), and traditional networking attributes like IP addresses and VLANs.", "title": "", "source": "https://cloud.ibm.com/docs/vmware?topic=vmware-nsx-overview"}, {"document_id": "ibmcld_13246-2783-4608", "score": 15.004222, "text": "\n* [Virtual Network Functions](https://cloud.ibm.com/docs/vpc?topic=vpc-about-vnf-ha) in combination with a Network Load Balancers to support a high availability and scalability.\n* Virtual private endpoint gateways.\n* DNS resolution.\n\n\n\nA layered architecture will introduce resources and demonstrate connectivity. Each layer will add additional connectivity and resources. The layers are implemented in Terraform. It will be possible to change parameters, like number of zones, by changing a Terraform variable. A layered approach allows the tutorial to introduce small problems and demonstrate a solution in the context of a complete architecture.\n\n\n\n Objectives \n\n\n\n* Understand the concepts behind a VPC based hub and spoke model for managing all VPC to VPC traffic.\n* Understand VPC ingress and egress routing.\n* Identify and optionally resolve asymmetric routing issues.\n* Understand the use of a Network Load Balancer for a highly available and scalable firewall-router.\n* Utilize the DNS service routing and forwarding rules to build an architecturally sound name resolution system.\n\n\n\n\n\n\n\n Before you begin \n\nThis tutorial requires:\n\n\n\n* terraform to use Infrastructure as Code to provision resources,\n* python to optionally run the pytest commands,\n* Implementing a firewall-router will require that you [enable IP spoofing checks](https://cloud.ibm.com/docs/vpc?topic=vpc-ip-spoofing-aboutip-spoofing-enable-check),\n* An SSH key to connect to the virtual servers. If you don't have an SSH key, follow [the instructions](https://cloud.ibm.com/docs/vpc?topic=vpc-ssh-keys) for creating a key for VPC.\n\n\n\nSee the [prerequisites](https://github.com/IBM-Cloud/vpc-transitprerequisites) for a few options including a Dockerfile to easily create the prerequisite environment.\n\nIn addition:\n\n\n\n* Check for user permissions.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vpc-transit2"}, {"document_id": "ibmcld_13875-2836-4661", "score": 15.004222, "text": "\n* [Virtual Network Functions](https://cloud.ibm.com/docs/vpc?topic=vpc-about-vnf-ha) in combination with a Network Load Balancers to support a high availability and scalability.\n* Virtual private endpoint gateways.\n* DNS resolution.\n\n\n\nA layered architecture will introduce resources and demonstrate connectivity. Each layer will add additional connectivity and resources. The layers are implemented in Terraform. It will be possible to change parameters, like number of zones, by changing a Terraform variable. A layered approach allows the tutorial to introduce small problems and demonstrate a solution in the context of a complete architecture.\n\n\n\n Objectives \n\n\n\n* Understand the concepts behind a VPC based hub and spoke model for managing all VPC to VPC traffic.\n* Understand VPC ingress and egress routing.\n* Identify and optionally resolve asymmetric routing issues.\n* Understand the use of a Network Load Balancer for a highly available and scalable firewall-router.\n* Utilize the DNS service routing and forwarding rules to build an architecturally sound name resolution system.\n\n\n\n\n\n\n\n Before you begin \n\nThis tutorial requires:\n\n\n\n* terraform to use Infrastructure as Code to provision resources,\n* python to optionally run the pytest commands,\n* Implementing a firewall-router will require that you [enable IP spoofing checks](https://cloud.ibm.com/docs/vpc?topic=vpc-ip-spoofing-aboutip-spoofing-enable-check),\n* An SSH key to connect to the virtual servers. If you don't have an SSH key, follow [the instructions](https://cloud.ibm.com/docs/vpc?topic=vpc-ssh-keys) for creating a key for VPC.\n\n\n\nSee the [prerequisites](https://github.com/IBM-Cloud/vpc-transitprerequisites) for a few options including a Dockerfile to easily create the prerequisite environment.\n\nIn addition:\n\n\n\n* Check for user permissions.", "title": "", "source": "https://cloud.ibm.com/docs/transit-gateway?topic=transit-gateway-vpc-transit2"}, {"document_id": "ibmcld_15745-3108-5252", "score": 14.930135, "text": "\nRoute mode for VNFs Yes (see [Setting up high availability for Virtual Network Functions (VNF)](https://cloud.ibm.com/docs/vpc?topic=vpc-about-vnf)) No \n Virtual Servers on VPC Yes Yes \n Member type Virtual server instances Virtual server instances, Bare Metal, Power Systems Virtual Server \n Power Systems Virtual Server instances connected over Direct Link No Yes (No support for instance groups) \n\n\n\n\n\n High Availability mode \n\nThe application load balancer is configured in active-active mode. All compute resources of the load balancer are actively involved in forwarding traffic.\n\nHigh Availability (HA) is achieved by using a Domain Name Service (DNS). The Virtual IP (VIP) of each compute resource is registered to the assigned DNS. If any of the compute resources go down, the other resources continue to forward traffic.\n\nAn NLB is configured in active-standby mode. A single VIP is registered with DNS, and traffic is forwarded through that compute resource. If an active compute resource goes down, the standby takes over and the VIP is transferred to the standby.\n\n\n\n\n\n Multi-zone support \n\nNetwork load balancers can accept members across all three availability zones, but the NLB itself resides in one specific zone. A zone is identified by the subnet that is selected when a load balancer is created. Cloud Internet Services (CIS) Global Load Balancer or Private DNS can be used with multiple zonal network load balancers for multi-zone availability.\n\nThe application load balancer can also be configured to span multiple zones. The back-end servers can be in any zone within a region.\n\n\n\n\n\n Integration with private catalogs \n\nIBM Cloud Application Load Balancer and Network Load Balancer both integrate with private catalogs to centrally manage access to products in the IBM Cloud catalog and your own catalogs. You can customize your private catalogs to allow or disallow load balancer provisioning to specific users in your account. For more information, see [Customizing what's available in your private catalogs](https://cloud.ibm.com/docs/account?topic=account-restrict-by-user).\n\n\n\n\n\n Application load balancer data flow", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-nlb-vs-elb&interface=ui"}]}
{"task_id": "fdee20f7fd677e420742b09989623d68<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16384-7-2422", "score": 20.798252, "text": "\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-overview"}, {"document_id": "ibmcld_16295-7-1721", "score": 20.551758, "text": "\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat"}, {"document_id": "ibmcld_16365-8408-10508", "score": 20.542555, "text": "\nThe code snippet that creates the web chat widget includes a configuration object, which you can modify to change the appearance and behavior of the web chat. The configuration object also specifies details that enable the web chat to connect to your assistant. If you are comfortable writing JavaScript code, you can customize the web chat by modifying the code snippet and using the web chat API.\n\nThe web chat uses the Watson Assistant v2 stateful API to communicate with the assistant. By default, the session ends and the conversation ends after 5 minutes of inactivity. This means that if a user stops interacting with the assistant, after 5 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values. You can change the inactivity timeout setting in the assistant settings (if allowed by your plan).\n\n\n\n Browser support \n\nThe web chat supports a variety of devices and platforms. As a general rule, if the last two versions of a browser account for more than 1% of all desktop or mobile traffic, the web chat supports that browser.\n\nThe following list specifies the minimum required browser software for the web chat (including the two most recent versions, except as noted):\n\n\n\n* Google Chrome\n* Apple Safari\n* Mobile Safari\n* Chrome for Android\n* Microsoft Edge (Chromium and non-Chromium)\n* Mozilla Firefox\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n\n\n\n\n\n Accessibility \n\nIBM strives to provide products with usable access for everyone, regardless of age or ability.\n\nThe web chat integration complies with the [Web Content Accessibility 2.1 Level AA](https://www.w3.org/WAI/standards-guidelines/wcag/new-in-21/) standard. It is tested with both screen readers and automated tools on a continual basis.\n\n\n\n\n\n Language support", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_02855-7-2041", "score": 20.430843, "text": "\nIntegrating the web chat with your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, click the Web chat tile.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n4. Click Create to create a web chat instance.\n5. Optional: Customize the style of the chat window. You can make the following changes:\n\n\n\n* Public assistant name. Name by which the assistant is known to users. This name is displayed in the header of the chat window. The name can be up to 18 characters in length.\n* Primary color. Sets the color of the web chat header.\n\nClick the white dot to open a color switcher where you can choose a color. The color is saved as an HTML color code, such as FF33FC for pink and 329A1D for green. Alternatively, you can add an HTML color code directly to the field to set the color.\n* Secondary color: Sets the color of the user input message bubble.\n* Accent color. Sets the color of interactive elements, including:\n\n\n\n* Chat launcher button that is embedded in your web page\n* Send button associated with the input text field\n* Input text field border when in focus\n* Marker that shows the start of the assistant\u2019s response\n* Border of a button after it is clicked\n* Border of the drop-down list field as the user chooses an option\n* Typing indicator that is shown to repesent a pause response", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat"}, {"document_id": "ibmcld_16280-4696-6712", "score": 20.097395, "text": "\nYou can configure how and where the web chat widget appears, and you can use theming to align it with your branding and website design. If a customer needs help from a person, the web chat integration can transfer the conversation to an agent.\n* [Phone integration](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone): The phone integration enables your assistant to converse with customers on the phone by using the IBM Watson Text to Speech and Speech to Text services. If your customer asks to speak to a person, the phone integration can transfer the call to an agent.\n\n\n\n\n\n\n\n Updating and managing channels \n\nEach channel has specific settings that you can adjust to adapt the end experience for your user. You can edit these settings by selecting the channel in an environment, or in Integrations.\n\nIf you make an update to a channel in the draft environment, the same channel in live environment is not affected in the live environment. Similarly, if you make an update to a channel in the live environment, the same channel in draft environment is not affected. If you select a channel from the Integrations page, you are asked to select which environment you are editing.\n\nFor more information about editing your web chat integration, see [Basic web chat configuration](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-overview).\n\n\n\n\n\n Deleting channels \n\nTo delete a channel, go to the Integrations page and use the overflow menu on the integration:\n\n![GIF of how to delete a channel](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/delete-channel.gif)\n\nIf you deployed your assistant to a channel, then deleting the channel does not remove the assistant from the channel. For example, if you deploy web chat, you paste the JavaScript snippet into the HTML header of your website. Deleting your channel disconnects your content from the customer experience that is shown on your website.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-assistant"}, {"document_id": "ibmcld_03421-1518-3290", "score": 19.741062, "text": "\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config"}, {"document_id": "ibmcld_16368-7-2072", "score": 19.635452, "text": "\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop"}, {"document_id": "ibmcld_03196-30333-32476", "score": 19.38366, "text": "\nIn the Message before link to web chat field, edit the introductory message to display to the user (in the originating channel) before the link that initiates the transfer. By default, this message is OK, click this link for additional help. Chat will continue on a new web page.\n3. In the URL to web chat field, type the URL for your website where the web chat widget is embedded.\n\n\n\nIn the integration that processes the Channel transfer response, the introductory message is displayed, followed by a link to the URL you specify. The user must then click the link to initiate the transfer.\n\nWhen a conversation is transferred from one channel to another, the session history and context are preserved, so the destination channel can continue the conversation from where it left off. Note that the message output that contains the Channel transfer response is processed first by the channel that initiates the transfer, and then by the target channel. If the output contains multiple responses (perhaps using different response types), these will be processed by both channels (before and after the transfer). If you want to target individual responses to specific channels, you can do so by editing the response using the JSON editor. For more information, see [Targeting specific integrations](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-responses-jsondialog-responses-json-target-integrations).\n\n\n\n\n\n Adding an Image response type \n\nSometimes a picture is worth a thousand words. Include images in your response to do things like illustrate a concept, show off merchandise for sale, or maybe to show a map of your store location.\n\nTo add an Image response type, complete the following steps:\n\n\n\n1. Choose Image.\n2. Add the full URL to the hosted image file into the Image source field.\n\nThe image must be in .jpg, .gif, or .png format. The image file must be stored in a location that is publicly addressable by an https: URL.\n\nFor example: https://www.example.com/assets/common/logo.png.\n\nIf you want to display an image title and description above the embedded image in the response, then add them in the fields provided.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overview"}, {"document_id": "ibmcld_16326-3092-4450", "score": 19.30687, "text": "\nYou can visualize how your assistant would look as a web chat widget on your organization's website. You can enter a URL or upload an image.\n\n\n\n Entering a URL \n\nYou can enter a URL of your organization's website. Watson Assistant captures an image of your website to use as the Preview page background.\n\nYour website must be publicly available to all users. Private or intranet sites can\u2019t be accessed. Any login, splash, cookie, or warning screens might be captured in the image.\n\nTo enter a URL:\n\n\n\n1. On the Preview page, click Change background.\n2. Click Enter URL, then click Continue.\n3. Enter the path of your website URL, for example, https://www.example.com or example.com.\n4. Click Continue.\n\n\n\n\n\n\n\n Uploading an image \n\nYou can upload an image of your organization's website. Images are stored for 24 hours. Maximum file size is 1 MB. Supported file types are JPEG and PNG.\n\nTo upload an image:\n\n\n\n1. On the Preview page, click Change background.\n2. Click Upload an image, then click Continue.\n3. Drag a file or click to upload, then click Change background.\n\n\n\nImages are stored for 24 hours. A warning message might appear on the Preview page about the time limit expiration. To clear this message:\n\n\n\n1. On the Preview page, click Change background.\n2. Click Clear background setting, then click Continue.\n3. Click Remove background to finish.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-preview-share"}, {"document_id": "ibmcld_03080-1529-3357", "score": 19.30002, "text": "\nFor a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill. For examples of how to complete common tasks, see [Passing values](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-context).\n* Change the language that is used by the web chat.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-config"}]}
{"task_id": "fdee20f7fd677e420742b09989623d68<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02855-7-2041", "score": 23.896559, "text": "\nIntegrating the web chat with your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, click the Web chat tile.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n4. Click Create to create a web chat instance.\n5. Optional: Customize the style of the chat window. You can make the following changes:\n\n\n\n* Public assistant name. Name by which the assistant is known to users. This name is displayed in the header of the chat window. The name can be up to 18 characters in length.\n* Primary color. Sets the color of the web chat header.\n\nClick the white dot to open a color switcher where you can choose a color. The color is saved as an HTML color code, such as FF33FC for pink and 329A1D for green. Alternatively, you can add an HTML color code directly to the field to set the color.\n* Secondary color: Sets the color of the user input message bubble.\n* Accent color. Sets the color of interactive elements, including:\n\n\n\n* Chat launcher button that is embedded in your web page\n* Send button associated with the input text field\n* Input text field border when in focus\n* Marker that shows the start of the assistant\u2019s response\n* Border of a button after it is clicked\n* Border of the drop-down list field as the user chooses an option\n* Typing indicator that is shown to repesent a pause response", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat"}, {"document_id": "ibmcld_16295-7-1721", "score": 23.314709, "text": "\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat"}, {"document_id": "ibmcld_16389-0-2061", "score": 22.74418, "text": "\n\n\n\n\n\n\n  Configuring style and appearance \n\nOn the Style tab, you can configure the overall appearance of the web chat widget. You can make the following changes:\n\n\n\n*  Set the assistant name. Click Assistant's name as known by customers to specify the name that is displayed in the header of the chat window. The name can be up to 64 characters in length.\n*  Change the colors used in the web chat widget. You can set the following colors:\n\n\n\n*  Primary color: The color of the web chat header.\n*  Secondary color: The color of the customer input message bubble.\n*  Accent color: The color of interactive elements such as the following:\n\n\n\n*  Web chat buttons such as the suggestions button and the \"send message\" button\n*  The border around the input text field (when in focus)\n*  The markers that appear beside the assistant\u2019s messages\n*  The borders that appear around buttons and drop-down lists when customers select from options\n*  The home screen background\n\n\n\n\n\nEach color is specified as an HTML hexadecimal color code, such as FF33FC for pink and 329A1D for green. To change a color, type the HTML color code you want to use, or click the dot next to the field and choose the color from the interactive color picker.\n*  Enable or disable the Built with IBM Watson watermark that is displayed in the web chat widget. To disable the watermark, click to toggle the IBM Watermark switch to the off position. (The watermark cannot be disabled on the Lite plan.)\n*  Provide an avatar image to represent your assistant or organization in the web chat header. Click Add an avatar image to add an image, or Change avatar image to change an image you have previously added.\n\nSpecify the URL for a publicly accessible hosted image, such as a company or brand logo or an assistant avatar. The image file must be between 64 x 64 and 100 x 100 pixels in size.\n\n\n\nStyle changes you make are immediately reflected by the web chat preview that is shown on the page. However, no configuration changes are applied to the environment until you click Save and exit.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-style"}, {"document_id": "ibmcld_16368-7-2072", "score": 22.309456, "text": "\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop"}, {"document_id": "ibmcld_03196-30333-32476", "score": 22.172049, "text": "\nIn the Message before link to web chat field, edit the introductory message to display to the user (in the originating channel) before the link that initiates the transfer. By default, this message is OK, click this link for additional help. Chat will continue on a new web page.\n3. In the URL to web chat field, type the URL for your website where the web chat widget is embedded.\n\n\n\nIn the integration that processes the Channel transfer response, the introductory message is displayed, followed by a link to the URL you specify. The user must then click the link to initiate the transfer.\n\nWhen a conversation is transferred from one channel to another, the session history and context are preserved, so the destination channel can continue the conversation from where it left off. Note that the message output that contains the Channel transfer response is processed first by the channel that initiates the transfer, and then by the target channel. If the output contains multiple responses (perhaps using different response types), these will be processed by both channels (before and after the transfer). If you want to target individual responses to specific channels, you can do so by editing the response using the JSON editor. For more information, see [Targeting specific integrations](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-responses-jsondialog-responses-json-target-integrations).\n\n\n\n\n\n Adding an Image response type \n\nSometimes a picture is worth a thousand words. Include images in your response to do things like illustrate a concept, show off merchandise for sale, or maybe to show a map of your store location.\n\nTo add an Image response type, complete the following steps:\n\n\n\n1. Choose Image.\n2. Add the full URL to the hosted image file into the Image source field.\n\nThe image must be in .jpg, .gif, or .png format. The image file must be stored in a location that is publicly addressable by an https: URL.\n\nFor example: https://www.example.com/assets/common/logo.png.\n\nIf you want to display an image title and description above the embedded image in the response, then add them in the fields provided.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overview"}, {"document_id": "ibmcld_03421-1518-3290", "score": 21.738304, "text": "\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config"}, {"document_id": "ibmcld_03080-1529-3357", "score": 21.641253, "text": "\nFor a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill. For examples of how to complete common tasks, see [Passing values](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-context).\n* Change the language that is used by the web chat.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-config"}, {"document_id": "ibmcld_16365-8408-10508", "score": 20.974518, "text": "\nThe code snippet that creates the web chat widget includes a configuration object, which you can modify to change the appearance and behavior of the web chat. The configuration object also specifies details that enable the web chat to connect to your assistant. If you are comfortable writing JavaScript code, you can customize the web chat by modifying the code snippet and using the web chat API.\n\nThe web chat uses the Watson Assistant v2 stateful API to communicate with the assistant. By default, the session ends and the conversation ends after 5 minutes of inactivity. This means that if a user stops interacting with the assistant, after 5 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values. You can change the inactivity timeout setting in the assistant settings (if allowed by your plan).\n\n\n\n Browser support \n\nThe web chat supports a variety of devices and platforms. As a general rule, if the last two versions of a browser account for more than 1% of all desktop or mobile traffic, the web chat supports that browser.\n\nThe following list specifies the minimum required browser software for the web chat (including the two most recent versions, except as noted):\n\n\n\n* Google Chrome\n* Apple Safari\n* Mobile Safari\n* Chrome for Android\n* Microsoft Edge (Chromium and non-Chromium)\n* Mozilla Firefox\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n\n\n\n\n\n Accessibility \n\nIBM strives to provide products with usable access for everyone, regardless of age or ability.\n\nThe web chat integration complies with the [Web Content Accessibility 2.1 Level AA](https://www.w3.org/WAI/standards-guidelines/wcag/new-in-21/) standard. It is tested with both screen readers and automated tools on a continual basis.\n\n\n\n\n\n Language support", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_03166-4588-6408", "score": 20.86476, "text": "\nIf you don't want to use a home screen, go to the Home screen tab and toggle the switch to Off.\n8. Optional: To configure support for transferring conversations to a service desk agent, click the Live agent tab. For more information, see [Adding service desk support](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-haa).\n9. Optional: The web chat gives your customers a way to reset the conversation if they get stuck by showing them a list of suggestions. Suggestions are enabled automatically. You can control how often suggestions are displayed and what they include. Click the Suggestions tab. For more information, see [Showing more suggestions](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n10. Optional: To secure the web chat, click the Security tab. For more information, see [Securing the web chat](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-security).\n11. Click the Embed tab.\n\nA code snippet is displayed that defines the chat window implementation. You will add this code snippet to your web page. The code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site. The code creates an instance of a widget that communicates with the assistant. The generated code includes a region and unique integration ID. Do not change these parameter values.\n12. Copy the script HTML element. You add this script to your website in the next section, [Deploy your assistant in production](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-snippet).\n13. If you made any customizations, click Save and exit. Otherwise, click Close.\n\nThe web chat instance is created as soon as you click the Create button, and does not need to be saved.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat"}, {"document_id": "ibmcld_16384-7-2422", "score": 20.669476, "text": "\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-overview"}]}
{"task_id": "fdee20f7fd677e420742b09989623d68<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16368-7-2072", "score": 25.273813, "text": "\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop"}, {"document_id": "ibmcld_02855-13982-15842", "score": 22.535627, "text": "\nFor more information about rich response types, see [Rich responses](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia).\n\n\n\n\n\n Extending the web chat \n\nA developer can extend the capabilities of the web chat by using the Watson Assistant web chat toolkit on [GitHub](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html).\n\nIf you choose to use the provided methods, you implement them by editing the code snippet that was generated earlier. You then embed the updated code snippet into your web page.\n\nHere are some common tasks you might want to perform:\n\n\n\n* [Setting and passing context variable values](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-set-context%7D)\n* [Adding user identity information (if you don't enable security)](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-userid)\n\n\n\n\n\n Setting and passing context variable values \n\nA context variable is a variable that you can use to pass information to your assistant before a conversation starts. It can also collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on.\n\nThe following script preserves the context of the conversation. In addition, it adds an $ismember context variable and sets it to true.\n\nThe name that is specified for the skill (main skill) is a hardcoded name that is used to refer to any skill that you create from the product user interface. You do not need to edit your skill name.\n\n<script>\nfunction preSendhandler(event) {\nevent.data.context.skills['main skill'].user_defined.ismember = true;\n}\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat"}, {"document_id": "ibmcld_16384-7-2422", "score": 22.156942, "text": "\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-overview"}, {"document_id": "ibmcld_16384-1889-3334", "score": 21.790155, "text": "\nYou can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.\n\n\n\n* [How the web chat works](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture): Overview of web chat capabilities and architecture\n* [Embedding the web chat on your page](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat): How to embed the web chat widget on your website\n* [Web chat setup](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config): How to configure the web chat using the integration settings\n* [Web chat development](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config): How to customize and extend the web chat by writing code\n* [Adding contact center support](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat-haa): How to integrate the web chat with a contact center platform so you can connect your customers to human agents", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-overview"}, {"document_id": "ibmcld_03166-8640-10452", "score": 20.307123, "text": "\nFor more information, see [Applying advanced customizations](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config).\n4. Click the icon to open the chat window and talk to your assistant.\n\n![Web chat window](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/web-chat-window.png)\n5. Paste the code snippet into each web page where you want the assistant to be available to your customers.\n\nYou can paste the same script tag into as many pages on your website as you want. Add it anywhere where you want users to be able to reach your assistant for help. However, be sure to add it only one time per page.\n6. Submit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf the Connect to agent button is displayed and you don't have human agent support configured, you can hide it by changing the Suggestions configuration. For more information, see [Showing more suggestions](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.\n\n\n\nA developer can use APIs to apply more advanced customizations to the style of the web chat. For more information, see [Applying advanced customizations](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config).\n\n\n\n\n\n Launcher appearance and behavior", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat"}, {"document_id": "ibmcld_02855-6718-8435", "score": 20.144844, "text": "\nSubmit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.\n\n\n\nYou can apply more advanced customizations to the style of the web chat by using the Watson Assistant web chat toolkit on [GitHub](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configuration). For example, the text that is displayed in the chat window uses the fonts: IBMPlexSans, Arial, Helvetica, sans-serif. If you want to use a different font, you can specify it by using the instance.updateCSSVariables() method.\n\n\n\n\n\n Adding a home screen ![Beta](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/beta.png) \n\nCustomers often don't know how to interact with your assistant at first. They aren't sure how to format a question or what types of things they can ask. Don't make them guess. Show them by adding a home screen to the web chat window.\n\n![An example of the home screen](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/home-screen.png)\n\n\n\n1. From the Home screen tab, turn the home screen feature On.\n2. Add a greeting that is engaging and invites the user to interact with your assistant.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat"}, {"document_id": "ibmcld_02855-5574-7284", "score": 19.84053, "text": "\nFor more information, see the [Using a custom launcher tutorial](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Changing the size or position of the chat window that is displayed when users click the launcher button. For more information, see the [Render to a custom element tutorial](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-example-element).\n\n\n\n14. Click the icon to open the chat window and talk to your assistant.\n\n![Web chat window](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/web-chat-window.png)\n\nThe traffic to and from the web chat is sent between the instance that is hosted by your deployed cluster environment and the web page where you embed the web chat.\n15. Paste the code snippet into each web page where you want the assistant to be available to your customers.\n\nYou can paste the same script tag into as many pages on your website as you want. Add it anywhere that you want users to be able to reach your assistant for help. However, be sure to add it only one time per page.\n16. Submit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat"}, {"document_id": "ibmcld_16299-1512-2608", "score": 19.330502, "text": "\n* [Web chat development overview](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop): You can use the web chat API to extensively customize the appearance and behavior of the web chat.\n* Customizing the phone integration: You can use commands and context variables to extensively configure how your assistant interacts with users using the phone integration. (More information coming soon.)\n* Customizing the SMS integration: You can use commands and context variables to customize how your assistant interacts with users using text messages. (More information coming soon.)\n* [Extending your assistant using webhooks](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-webhook-overview): You use webhooks to call external services that extend the capabilities of your assistant or log activity.\n* Developing a custom channel: If none of the built-in channel integrations meet your needs, you can use the Watson Assistant REST API and SDKs to develop a custom client application that interacts with your assistant. (More information coming soon.)", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-develop-overview"}, {"document_id": "ibmcld_16365-8408-10508", "score": 19.084951, "text": "\nThe code snippet that creates the web chat widget includes a configuration object, which you can modify to change the appearance and behavior of the web chat. The configuration object also specifies details that enable the web chat to connect to your assistant. If you are comfortable writing JavaScript code, you can customize the web chat by modifying the code snippet and using the web chat API.\n\nThe web chat uses the Watson Assistant v2 stateful API to communicate with the assistant. By default, the session ends and the conversation ends after 5 minutes of inactivity. This means that if a user stops interacting with the assistant, after 5 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values. You can change the inactivity timeout setting in the assistant settings (if allowed by your plan).\n\n\n\n Browser support \n\nThe web chat supports a variety of devices and platforms. As a general rule, if the last two versions of a browser account for more than 1% of all desktop or mobile traffic, the web chat supports that browser.\n\nThe following list specifies the minimum required browser software for the web chat (including the two most recent versions, except as noted):\n\n\n\n* Google Chrome\n* Apple Safari\n* Mobile Safari\n* Chrome for Android\n* Microsoft Edge (Chromium and non-Chromium)\n* Mozilla Firefox\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n\n\n\n\n\n Accessibility \n\nIBM strives to provide products with usable access for everyone, regardless of age or ability.\n\nThe web chat integration complies with the [Web Content Accessibility 2.1 Level AA](https://www.w3.org/WAI/standards-guidelines/wcag/new-in-21/) standard. It is tested with both screen readers and automated tools on a continual basis.\n\n\n\n\n\n Language support", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_16365-7-1700", "score": 18.936518, "text": "\nHow the web chat works \n\nThe web chat provides an easy-to-use chatbot interface that you can add to your website without writing any code.\n\nAfter you add the web chat script to your website, your customers will see a launcher icon that they can click to open the chat window and start a conversation with the assistant. The appearance of the launcher icon adapts to desktop and mobile browsers.\n\n![web chat launcher in desktop browser](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/web-chat-desktop-highlighted.png)\n\nWhen a customer clicks the launcher, the web chat window opens, initially displaying the home screen. The home screen displays a greeting and an optional set of suggested conversation starters for common questions and problems. The customer can either click a conversation starter or type a message in the input field to start the conversation with the assistant.\n\n![web chat example home screen](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/web-chat-home-screen-lendyr.png)\n\nThe appearance and behavior of the launcher icon, the home screen, and most other aspects of the web chat can be configured and customized to match your website style and branding. For more information, see [Configuring the web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}]}
{"task_id": "fdee20f7fd677e420742b09989623d68<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16298-6367-7794", "score": 25.294645, "text": "\nFor more information see [Securing the web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security).\n2. Encrypt sensitive information that you pass to the web chat.\n\nWhen you enable security in Zendesk, you must provide the name and email address of the current user with each request. Configure the web chat to pass this information in the payload.\n\nSpecify the information by using the following syntax. Use the exact names (name and email) for the two name and value pairs.\n\n{\nuser_payload : {\nname: '{customerName}',\nemail: '{customerEmail}'\n}\n}\n\nFor more information, see [Passing sensitive data](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-securityweb-chat-security-encrypt).\n\nZendesk also expects iat and external_id name and value pairs. However, there's no need for you to provide this information. IBM automatically provides a JWT that contains these values.\n\nFor example:\n\nconst userPayload = {\n\"name\" : \"Cade Jones\",\n\"email\" : \"cade@example.com\",\n}\n\n// Sample NodeJS code on your server.\nconst jwt = require('jsonwebtoken');\nconst RSA = require('node-rsa');\n\nconst rsaKey = new RSA(process.env.PUBLIC_IBM_RSA_KEY);\n\n/\n* Returns a signed JWT. Optionally, adds an encrypted user_payload in stringified JSON.\n/\nfunction mockLogin(userID, userPayload) {\nconst payload = {\nsub: userID, // Required\niss: 'www.ibm.com', // Required\nacr: 'loa1' // Required", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-zendesk"}, {"document_id": "ibmcld_16388-7-1918", "score": 24.211088, "text": "\nEncrypting sensitive data \n\nBy using the public key that is provided by IBM, you can add another level of encryption to hide sensitive data you send from the web chat.\n\nTo use this method for encrypting data, you must first enable the web chat security feature. For more information, see [Enabling web chat security](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security-enable).\n\nUse this method to send sensitive information in messages that come from your website, such as information about a customer's loyalty level, a user ID, or security tokens to use in webhooks that you call from actions. Information passed to your assistant in this way is stored in a private context variable. Private variables cannot be seen by customers and are never sent back to the web chat.\n\nFor example, you might start a business process for a VIP customer that is different from the process you start for a standard customer. You do not want non-VIPs to know that they are categorized as such, but you must pass this information to your action so it can change the flow of the conversation. To do this, you can pass the customer MVP status as an encrypted variable. This private context variable is available for use by the action, but not by anything else.\n\n![development icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/development-icon.png)Tutorial: For a tutorial that shows an example of using web chat security to authenticate users and protect sensitive data, see [Tutorial: Authenticating a user in the middle of a session](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-security).\n\nTo encrypt sensitive data:\n\n\n\n1. On the Security tab of the web chat integration settings, click the Generate key button.\n2. Copy the public key that displays in the IBM-provided public key field.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security-encrypt"}, {"document_id": "ibmcld_03188-4819-6738", "score": 23.6602, "text": "\nFor more information about how to pass data, see [Passing sensitive data](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-securityweb-chat-security-encrypt).\n\nTo access the payload data, you can reference the context.integrations.chat.private.user_payload object from the dialog node condition.\n\nYou must know the structure of the JSON object that is sent in the payload.\n\nFor example, if you passed the value \"mvp:true\" in the JSON payload, you can add a dialog flow that checks for this value to define a response that is meant for VIP customers only. Add a dialog node with a condition like this:\n\n\n\nPrivate variable as node condition\n\n Field Value \n\n If assistant recognizes $integrations.chat.private.user_payload.mvp \n Assistant responds I can help you reserve box seats at the upcoming conference! \n\n\n\n\n\n\n\n Web chat: Accessing web browser information \n\nWhen you use the web chat integration, information about the web browser that your customer is using to access the web chat is automatically collected and stored. The information is stored in the context.integrations.chat.browser_info object.\n\nYou can design your dialog to take advantage of details about the web browser in use. The following properties are taken from the window object that represents the window in which the web chat is running:\n\n\n\n* browser_name: The browser name, such as chrome, edge, or firefox.\n* browser_version: The browser version, such as 80.0.0.\n* browser_OS: The operating system of the customer's computer, such as Mac OS.\n* language: The default locale code of the browser, such as en-US.\n* page_url: Full URL of the web page in which the web chat is embedded. For example: https://www.example.com/products\n* screen_resolution: Specifies the height and width of the browser window in which the web page is displayed. For example: width: 1440, height: 900\n* user_agent: Content from the User-Agent request header.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-integrations"}, {"document_id": "ibmcld_16385-7-2272", "score": 23.044218, "text": "\nOverview: Securing the web chat \n\nIf you enable security, you can configure the web chat to authenticate users, protect private data, and restrict access to your assistant.\n\nAll messages that are sent between the web chat and the assistant are encrypted using Transport Layer Security (TLS), which protects sensitive data as it travels through the network. However, there are still potential security exposures that you might need to protect against. By enabling the web chat security feature and updating your website code appropriately, you can add the following protections:\n\n\n\n* You can prevent unauthorized websites from sending messages to your assistant, even if they copy your web chat embed script. (The unique identifiers in the embed script, such as the integration ID and service instance ID, are visible to anyone who has access to your website.)\n* You can securely authenticate customers in order to control access to features of your assistant that require authorization.\n* You can encrypt sensistive data so that customers cannot see it, while still allowing your assistant to access it.\n\n\n\nWeb chat security uses JSON Web Tokens (JWTs), which are data objects that are sent with each message from your website to the Watson Assistant service. Because a JWT is digitally signed using a private encryption key that only you have, it ensures that each message originates with your website. The JWT payload can also be used to securely authenticate users and carry encrypted private data.\n\nFor detailed information about JSON Web Tokens, see the [JWT specification](https://tools.ietf.org/html/rfc7519)).\n\nEnabling web chat security involves making the following customizations:\n\n\n\n* Implementing web application server code that generates a JWT signed with your private encryption key\n* Customizing the web chat configuration to provide the generated JWT\n* Enabling security in the web chat security settings\n\nAfter you enable web chat security, any message received by the web chat integration that is not accompanied by a properly signed JWT will be rejected.\n\n\n\nFor detailed information about how to complete these steps, see [Enabling web chat security](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security-enable).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security"}, {"document_id": "ibmcld_16387-7-1890", "score": 22.615522, "text": "\nEnabling web chat security \n\nTo enable web chat security, you must make changes to your web application server code and the web chat embed script, as well as the web chat integration settings.\n\n\n\n Before you begin \n\nBefore you enable security, you must create an RS256 public/private key pair. You can use a tool such as OpenSSL or PuTTYgen.\n\nFor example, to create the key pair at a command prompt using OpenSSL, you would use the command openssl genrsa -out key.pem 2048.\n\nSave the generated key pair in a secure location.\n\nMake sure these keys are accessible only by your server code. Never pass them to a client browser through your website.\n\n\n\n\n\n Generating a JWT \n\nTo use web chat security, you must configure the web chat on your website to send a JSON Web Token (JWT) with each message to the assistant. The JWT is used to verify the origin of messages sent from your website, and optionally to carry additional encrypted data. Your website will need to be able to generate a new JWT at the beginning of each session, and also whenever an existing JWT expires.\n\nDo not hardcode a JWT in your website code or share JWTs between users.\n\nOn your server, implement a function that generates and returns a JSON Web Token (JWT) that is signed with your private key. You will use this token to verify the origin of messages sent from your website, and optionally to carry additional encrypted data.\n\nMost programming languages offer JWT libraries that you can use to generate a token. To validate signed JWTs, the web chat integration uses the [jsonwebtoken](https://www.npmjs.com/package/jsonwebtoken) library with the RS256 algorithm.\n\nThe JWT payload must specify the following claims:\n\n\n\n* sub: A unique user ID that identifies the customer who is interacting with the web chat. This can be either a generated unique identifier (for anonymous users) or an authenticated user ID.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security-enable"}, {"document_id": "ibmcld_03180-5630-7213", "score": 22.569519, "text": "\nEnabling visitor authentication also enables support for cross-domain traffic and cross-browser identification. For more information, see the [Zendesk documentation](https://support.zendesk.com/hc/en-us/articles/360022185314-Enabling-authenticated-visitors-in-the-Chat-widget).\n\nBefore you can secure the Zendesk connection, complete the following required tasks:\n\n\n\n1. Secure the web chat. For more information see [Securing the web chat](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-security).\n2. Encrypt sensitive information that you pass to the web chat.\n\nWhen you enable security in Zendesk, you must provide the name and email address of the current user with each request. Configure the web chat to pass this information in the payload.\n\nSpecify the information by using the following syntax. Use the exact names (name and email) for the two name and value pairs.\n\n{\nuser_payload : {\nname: '{customerName}',\nemail: '{customerEmail}'\n}\n}\n\nFor more information, see [Passing sensitive data](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-securityweb-chat-security-encrypt).\n\nZendesk also expects iat and external_id name and value pairs. However, there's no need for you to provide this information. IBM automatically provides a JWT that contains these values.\n\nFor example:\n\nconst userPayload = {\n\"name\" : \"Cade Jones\",\n\"email\" : \"cade@example.com\",\n}\n\n// Sample NodeJS code on your server.\nconst jwt = require('jsonwebtoken');\nconst RSA = require('node-rsa');\n\nconst rsaKey = new RSA(process.env.PUBLIC_IBM_RSA_KEY);\n\n/\n* Returns a signed JWT.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-zendesk"}, {"document_id": "ibmcld_03422-1615-3407", "score": 21.865929, "text": "\nThe process you use to add the web chat to your website is simple. Its simplicity also means it can be misused. That's why it's important to verify that the messages sent to your assistant are coming from authorized users only.\n\nBefore you enable security, complete the following steps:\n\n\n\n1. Create a RS256 private/public key pair.\n\nYou can use a tool such as the OpenSSL command line or PuTTYgen.\n\n\n\n* For example, to create the key pair: openssl genrsa -out key.pem 2048\n\n\n\n2. Use your private key to sign a JSON Web Token (JWT). You will pass the token with the messages that are sent from your website as proof of their origin.\n\nThe JWT payload must specify values for the following claims:\n\n\n\n* iss: Represents the issuer of the JWT. This value is a case-sensitive string.\n* sub: Represents the principal that is the subject of the JWT. This value must either be scoped to be locally unique in the context of the issuer or be globally unique. The value you specify for sub is used as the user_id.\n\nThe user ID that is specified in the sub claim is also sent in the customer_id section of the X-Watson-Metadata HTTP header. The customer_id can be used to make requests to delete user data. Because the ID is sent in a header field, the syntax must meet the requirements for header fields as defined in [RFC 7230](https://tools.ietf.org/html/rfc7230section-3.2) (all visible ASCII characters). For more information about deleting user data, see [Labeling and deleting data](https://cloud.ibm.com/docs/assistant?topic=assistant-information-securityinformation-security-gdpr-wa).\n* exp: Represents the expiration time on or after which the JWT cannot be accepted for processing. Many libraries set this value for you automatically. Set a short-lived exp claim with whatever library you use.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-security"}, {"document_id": "ibmcld_02855-16710-18404", "score": 21.766232, "text": "\nThe next response has a more generic greeting.\n\n![Shows multiple conditioned responses in a dialog node, one of which references the ismember context variable](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/web-chat-use-context-var.png)\n\nIf you enable security, you can encrypt the data that you pass to your dialog. For more information, see [Passing sensitive data](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-encrypt).\n\nRemember that a session ends if there's no interaction with the user after 1 hour (or whatever inactivity timeout setting you specify, which can be up to 7 days). Any contextual information that you pass or collect is reset after the inactivity time period is passed. For more information, see [Changing the inactivity timeout setting](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-settings).\n\n\n\n\n\n Adding user identity information \n\nIf you do not enable security, and you want to perform tasks where you need to know the user who submitted the input, then you must pass the user ID to the web chat integration.\n\nIf you do enable security, you set the user ID in the JSON Web Token instead. For more information, see [Authenticating users](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-authenticate).\n\nChoose a non-human-identifiable ID. For example, do not use a person's email address as the user_id.\n\nUser information is used in the following ways:\n\n\n\n* The user_id is used to measure the number of monthly active users who interact with the web chat integration.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat"}, {"document_id": "ibmcld_02875-7-2073", "score": 21.4057, "text": "\nAdding custom dialog flows for integrations \n\nUse the JSON editor in dialog to access information that is submitted from the web chat integration.\n\nThe context object that is passed as part of the v2 /message API request contains an integrations object. This object makes it possible to pass information that is specific to a single integration type in the context. For more information about context variables, see [Context variables](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-variables).\n\nThe integrations object is available from the v2 API in version 2020-04-01 or later only.\n\n\n\n Web chat: Accessing sensitive data \n\nIf you enable security for the web chat, you can configure your web chat implementation to send encrypted data to the dialog. Payload data that is sent from web chat is stored in a private context variable named context.integrations.chat.private.user_payload. No private variables are sent from the dialog to any integrations. For more information about how to pass data, see [Passing sensitive data](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-encrypt).\n\nTo access the payload data, you can reference the context.integrations.chat.private.user_payload object from the dialog node condition.\n\nYou must know the structure of the JSON object that is sent in the payload.\n\nFor example, if you passed the value \"mvp:true\" in the JSON payload, you can add a dialog flow that checks for this value to define a response that is meant for VIP customers only. Add a dialog node with a condition like this:\n\n\n\nPrivate variable as node condition\n\n Field Value \n\n If assistant recognizes $integrations.chat.private.user_payload.mvp \n Assistant responds I can help you reserve box seats at the upcoming conference! \n\n\n\n\n\n\n\n Web chat: Accessing web browser information \n\nWhen you use the web chat integration, information about the web browser that your customer is using to access the web chat is automatically collected and stored.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-integrations"}, {"document_id": "ibmcld_16385-3291-4480", "score": 21.302382, "text": "\n* You can [prevent unauthorized access](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-securityweb-chat-security-encrypt) to sensitive customer information by encrypting it and including it as part of the JWT user payload.\n\nThe user payload is a part of the JWT you can use to send information you want your assistant to have access to, but that you do not want customers to see. This information is stored only in private variables, which cannot be seen by customers and are never included in logs.\n\nFor more information about using the user payload to protect sensitive information, see [Encrypting sensitive data](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security-encrypt).\n\n\n\n![development icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/development-icon.png)Tutorial: For a developer tutorial that shows an example of using web chat security to authenticate users and protect sensitive data, see [Tutorial: Authenticating a user in the middle of a session](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-security).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security"}]}
{"task_id": "fdee20f7fd677e420742b09989623d68<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16334-18880-20579", "score": 18.954031, "text": "\n* Window open events: The window:pre:open and window:open events now fire any time the chat window is opened, regardless of the reason. In previous releases, these events only fired if the window was opened by the customer clicking on the built-in launcher. Other methods of opening the chat window, such as session history or custom launchers, did not fire these events.\n\nThe event data passed to the listener has a new reason property that indicates the reason the window was opened. If you want to preserve the previous behavior, you can modify your handler to check this property:\n\ninstance.on({ type: \"window:open\", handler: event => {\nif (event.data.reason === 'default_launcher') {\n// Previous code.\n}\n}});\n\nFor more information, see [Window open reasons](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-eventswindowopenreasons).\n* hideCloseButton property renamed: The hideCloseButton property for custom panels has been renamed hideBackButton. The behavior of the property has not changed. For more information, see [customPanel.open()](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodscustompanelopen).\n\n\n\n\n\n\n\n 5.1.2 \n\nRelease date: 11 December 2021\n\n\n\n* Bug fix for Salesforce integration.\n\n\n\n\n\n\n\n 5.1.1 \n\nRelease date: 5 November 2021\n\n\n\n* \"User is typing\" support: The web chat now supports displaying the \"user is typing\" message for service desks. This feature is supported for the Salesforce and Zendesk integrations, as well as any [starter kit](https://github.com/watson-developer-cloud/assistant-web-chat-service-desk-starter) integration that implements it.\n* Bug fixes.\n\n\n\n\n\n\n\n 5.1.0 \n\nRelease date: 28 October 2021", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-release-notes-chat"}, {"document_id": "ibmcld_03166-9980-11726", "score": 18.515043, "text": "\nThis means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.\n\n\n\nA developer can use APIs to apply more advanced customizations to the style of the web chat. For more information, see [Applying advanced customizations](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config).\n\n\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n![An example of the initial launcher](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/web-chat-icon.png)\n\nAfter 15 seconds, the launcher expands to show a greeting message to the user. In this expanded state, a customer can still click the launcher to open the web chat. (If the customer reloads the page or navigates to a different page before the launcher has expanded, the 15-second timer restarts.) There are two slightly different appearances for this expanded state, depending on whether the user is using a desktop browser or a mobile browser.\n\n\n\n* For desktop browsers, the expanded launcher shows two primary buttons the customer can click to open the web chat, and a Close button that closes the launcher:\n\n![An example of the desktop launcher](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/desktop-launcher.png)\n\nThe expanded launcher remains in its expanded state even if the customer reloads the page or navigates to a different page.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat"}, {"document_id": "ibmcld_16365-1312-3051", "score": 18.150698, "text": "\nFor more information, see [Configuring the web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n![An example of the initial launcher](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/web-chat-icon.png)\n\nAfter 15 seconds, the launcher expands to show a greeting message to the user. In this expanded state, a customer can still click the launcher to open the web chat. (If the customer reloads the page or navigates to a different page before the launcher has expanded, the 15-second timer restarts.)\n\nThe appearance of this expanded state differs slightly depending on whether the customer is using a desktop browser or a mobile browser:\n\n\n\n* For desktop browsers, the expanded launcher shows two primary buttons the customer can click to open the web chat, and a Close button that closes the launcher.\n\n![An example of the desktop launcher](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/desktop-launcher.png)\n\nThe expanded launcher remains in its expanded state even if the customer reloads the page or navigates to a different page. It stays in its expanded state until the customer either opens it by clicking on either of the two primary buttons, or closes it, at which point it returns to its initial small state for the rest of the session.\n* For mobile browsers, the launcher shows only a single primary button.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_03166-1557-3458", "score": 17.795252, "text": "\nA preview pane is displayed that shows you what the web chat looks like when it is embedded in a web page. If a message is displayed that starts with, There is an error, it means you haven't added a conversational skill to your assistant yet. After you add a skill, you can test the conversation from the preview pane.\n4. Click Create to create a web chat instance.\n\nYou can skip this step if the web chat integration was created for you automatically.\n\n![Plus or higher plans only](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/plus.png) For environments where private endpoints are in use, keep in mind that the web chat integration sends traffic over the internet. For more information, see [Private network endpoints](https://cloud.ibm.com/docs/assistant?topic=assistant-securitysecurity-private-endpoints).\n5. Optional: Customize the style of the chat window. You can make the following changes:\n\n\n\n* Assistant's name as known by customers: The name by which the assistant is known to users. This name is displayed in the header of the chat window. The name can be up to 64 characters in length.\n* Primary color: The color of the web chat header.\n\nClick the white dot to open a color switcher where you can choose a color. The color is saved as an HTML color code, such as FF33FC for pink and 329A1D for green. Alternatively, you can add an HTML color code directly to the field to set the color.\n* Secondary color: The color of the user input message bubble.\n* Accent color: The color of interactive elements, including:\n\n\n\n* Chat launcher button that is embedded in your web page\n* Send button associated with the input text field\n* Input text field border when in focus\n* Marker that shows the start of the assistant\u2019s response\n* Border of a button after it is clicked\n* Border of the drop-down list field as the user chooses an option", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat"}, {"document_id": "ibmcld_16377-7-1723", "score": 17.572466, "text": "\nTutorial: Displaying a pre-chat or post-chat form \n\nThis tutorial shows how you can display pre-chat form before the web chat opens, or a post-chat form that opens after the web chat closes.\n\nFor a complete, working version of the example described in this tutorial, see [Pre and post-chat forms for Watson Assistant web chat](https://github.com/watson-developer-cloud/assistant-toolkit/tree/master/integrations/webchat/examples/pre-post-chat-forms).\n\nIf you want to gather information from your customers before starting a chat session, you can display a pre-chat form before opening the web chat. Similarly, you might want to display a form after the web chat closes (for example, a customer satisfaction survey). You can use the same approach for either situation.\n\nWhen the web chat is opened or closed, it fires an [event](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-events) that you can subscribe to. In your event handler, you can use the [custom panels](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-rendercustompanel) feature to open a panel with custom content.\n\nBy returning a promise that is resolved when the custom panel closes, you can pause the process of opening or closing the web chat until after the customer completes the form.\n\nThis example shows how to create a pre-chat form. To create a post-chat form, follow the same steps, but subscribe to the window:pre:close event instead of the window:open event.\n\nTo display a pre-chat form, follow these steps:\n\n\n\n1. Create a handler for the [window:open](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-eventswindowpreopen) event, which is fired when the web chat opens.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-pre-chat"}, {"document_id": "ibmcld_16365-7-1700", "score": 17.223528, "text": "\nHow the web chat works \n\nThe web chat provides an easy-to-use chatbot interface that you can add to your website without writing any code.\n\nAfter you add the web chat script to your website, your customers will see a launcher icon that they can click to open the chat window and start a conversation with the assistant. The appearance of the launcher icon adapts to desktop and mobile browsers.\n\n![web chat launcher in desktop browser](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/web-chat-desktop-highlighted.png)\n\nWhen a customer clicks the launcher, the web chat window opens, initially displaying the home screen. The home screen displays a greeting and an optional set of suggested conversation starters for common questions and problems. The customer can either click a conversation starter or type a message in the input field to start the conversation with the assistant.\n\n![web chat example home screen](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/web-chat-home-screen-lendyr.png)\n\nThe appearance and behavior of the launcher icon, the home screen, and most other aspects of the web chat can be configured and customized to match your website style and branding. For more information, see [Configuring the web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_16365-8408-10508", "score": 16.654902, "text": "\nThe code snippet that creates the web chat widget includes a configuration object, which you can modify to change the appearance and behavior of the web chat. The configuration object also specifies details that enable the web chat to connect to your assistant. If you are comfortable writing JavaScript code, you can customize the web chat by modifying the code snippet and using the web chat API.\n\nThe web chat uses the Watson Assistant v2 stateful API to communicate with the assistant. By default, the session ends and the conversation ends after 5 minutes of inactivity. This means that if a user stops interacting with the assistant, after 5 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values. You can change the inactivity timeout setting in the assistant settings (if allowed by your plan).\n\n\n\n Browser support \n\nThe web chat supports a variety of devices and platforms. As a general rule, if the last two versions of a browser account for more than 1% of all desktop or mobile traffic, the web chat supports that browser.\n\nThe following list specifies the minimum required browser software for the web chat (including the two most recent versions, except as noted):\n\n\n\n* Google Chrome\n* Apple Safari\n* Mobile Safari\n* Chrome for Android\n* Microsoft Edge (Chromium and non-Chromium)\n* Mozilla Firefox\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n\n\n\n\n\n Accessibility \n\nIBM strives to provide products with usable access for everyone, regardless of age or ability.\n\nThe web chat integration complies with the [Web Content Accessibility 2.1 Level AA](https://www.w3.org/WAI/standards-guidelines/wcag/new-in-21/) standard. It is tested with both screen readers and automated tools on a continual basis.\n\n\n\n\n\n Language support", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_16315-9405-10024", "score": 16.48773, "text": "\n* Journeys currently do not meet accessibility requirements.\n* Journeys are not supported if you are using the [element configuration option](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationoptionselement) to render the web chat in a custom DOM element.\n* When the customer starts a journey, the web chat window temporarily closes, but will reopen when the journey finishes. If you are using the window:close event to trigger the display of a post-chat form, your code should check the value of the new event.reason parameter of the event and verify that it is not set to open_tour.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-journeys"}, {"document_id": "ibmcld_16334-17373-19365", "score": 16.484747, "text": "\n* Home screen: The web chat home screen has been updated to have a more modern look. For more information about the home screen, see [Configuring the home screen](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-configweb-chat-configure-home-screen).\n* Agent events: New events are now fired by the web chat when interacting with a human agent using a service desk integration. If you are using a custom service desk integration based on the [starter kit](https://github.com/watson-developer-cloud/assistant-web-chat-service-desk-starter), you can use these events to create a pre-chat form before the agent escalation occurs, to create a post-chat form after the agent conversation ends, or to specify what happens if an agent isn\u2019t available (like create a ticket submission form). For more information, see [Agent events summary](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-eventssummary).\n* Markdown support: The web chat now fully supports common Markdown formatting in messages received from an assistant. You might need to review existing assistant output that contains strings that might be recognized as Markdown. (For example, a line of text that begins with a greater-than (>) character is interpreted as a block quote.)\n* Time zone: The time zone set in the context by the web chat no longer overrides any time zone set by the assistant.\n* Locale: Any locale configured for the web chat is now sent to the assistant as part of the context.\n* Window open events: The window:pre:open and window:open events now fire any time the chat window is opened, regardless of the reason. In previous releases, these events only fired if the window was opened by the customer clicking on the built-in launcher. Other methods of opening the chat window, such as session history or custom launchers, did not fire these events.\n\nThe event data passed to the listener has a new reason property that indicates the reason the window was opened.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-release-notes-chat"}, {"document_id": "ibmcld_16334-20193-22029", "score": 16.481438, "text": "\n* \"User is typing\" support: The web chat now supports displaying the \"user is typing\" message for service desks. This feature is supported for the Salesforce and Zendesk integrations, as well as any [starter kit](https://github.com/watson-developer-cloud/assistant-web-chat-service-desk-starter) integration that implements it.\n* Bug fixes.\n\n\n\n\n\n\n\n 5.1.0 \n\nRelease date: 28 October 2021\n\n\n\n* Custom Panels: The web chat now supports customizable panels you can use to display any custom HTML content (for example, a feedback form or a multistep process). Your code can use instance methods to dynamically populate a custom panel, as well as open and close it. For more information, see [Custom Panels](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodscustompanels).\n\n\n\n\n\n\n\n 5.0.2 \n\nRelease date: 4 October 2021\n\n\n\n* A [new tutorial](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-react-portals) is now available that shows how to use Carbon components to customize user-defined responses and writeable elements.\n* Bug fixes.\n\n\n\n\n\n\n\n 5.0.1 \n\nRelease date: 20 September 2021\n\n\n\n* Bug fixes.\n\n\n\n\n\n\n\n 5.0.0 \n\nRelease date: 16 September 2021\n\n\n\n* New response types: The web chat now supports the new video, audio, and iframe response types. For more information about these response types, see [Rich responses](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-multimedia).\n* Link to start web chat: You can now create a set of HTML links that go directly to your web chat and start conversations on specific topics. For example, you might want to send an email inviting customers to update their account information; you can include a link that opens the web chat on your site and sends the initial message I want to update my account.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-release-notes-chat"}]}
{"task_id": "fdee20f7fd677e420742b09989623d68<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16384-7-2422", "score": 17.97827, "text": "\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-overview"}, {"document_id": "ibmcld_16365-7-1700", "score": 17.43395, "text": "\nHow the web chat works \n\nThe web chat provides an easy-to-use chatbot interface that you can add to your website without writing any code.\n\nAfter you add the web chat script to your website, your customers will see a launcher icon that they can click to open the chat window and start a conversation with the assistant. The appearance of the launcher icon adapts to desktop and mobile browsers.\n\n![web chat launcher in desktop browser](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/web-chat-desktop-highlighted.png)\n\nWhen a customer clicks the launcher, the web chat window opens, initially displaying the home screen. The home screen displays a greeting and an optional set of suggested conversation starters for common questions and problems. The customer can either click a conversation starter or type a message in the input field to start the conversation with the assistant.\n\n![web chat example home screen](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/web-chat-home-screen-lendyr.png)\n\nThe appearance and behavior of the launcher icon, the home screen, and most other aspects of the web chat can be configured and customized to match your website style and branding. For more information, see [Configuring the web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_16365-8408-10508", "score": 17.335423, "text": "\nThe code snippet that creates the web chat widget includes a configuration object, which you can modify to change the appearance and behavior of the web chat. The configuration object also specifies details that enable the web chat to connect to your assistant. If you are comfortable writing JavaScript code, you can customize the web chat by modifying the code snippet and using the web chat API.\n\nThe web chat uses the Watson Assistant v2 stateful API to communicate with the assistant. By default, the session ends and the conversation ends after 5 minutes of inactivity. This means that if a user stops interacting with the assistant, after 5 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values. You can change the inactivity timeout setting in the assistant settings (if allowed by your plan).\n\n\n\n Browser support \n\nThe web chat supports a variety of devices and platforms. As a general rule, if the last two versions of a browser account for more than 1% of all desktop or mobile traffic, the web chat supports that browser.\n\nThe following list specifies the minimum required browser software for the web chat (including the two most recent versions, except as noted):\n\n\n\n* Google Chrome\n* Apple Safari\n* Mobile Safari\n* Chrome for Android\n* Microsoft Edge (Chromium and non-Chromium)\n* Mozilla Firefox\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n\n\n\n\n\n Accessibility \n\nIBM strives to provide products with usable access for everyone, regardless of age or ability.\n\nThe web chat integration complies with the [Web Content Accessibility 2.1 Level AA](https://www.w3.org/WAI/standards-guidelines/wcag/new-in-21/) standard. It is tested with both screen readers and automated tools on a continual basis.\n\n\n\n\n\n Language support", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_16375-7-1735", "score": 17.265003, "text": "\nAdding the web chat to your mobile application \n\nIf you have a mobile application built on a mobile framework such as iOS, Android, or React Native, you can use a WebView with a JavaScript bridge to communicate between your app and the Watson Assistant web chat.\n\nUsing WebViews with a JavaScript bridge is a common pattern with a similar implementation for all mobile frameworks.\n\n\n\n Including the web chat as a WebView \n\nYou can include the web chat interface as part of a page of your mobile app, or as a separate panel that your app opens. In either case, you must host an HTML page that includes the web chat embed script, and then include that page as a WebView in your app.\n\nIn the embed script, use the showLauncher option to hide the web chat launcher icon, and the openChatByDefault option to open the web chat automatically when the page loads. In most cases, you will also want to use the hideCloseButton option and use the native controls of your app to control how the web chat page or panel closes. For more information about the configuration options you can specify in the embed script, see the [Web chat API reference](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configuration).\n\nThe following example shows an embed script that includes these configuration options:\n\n<html>\n<head>\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n</head>\n<body>\n<script>\nwindow.watsonAssistantChatOptions = {\n// A UUID like '1d7e34d5-3952-4b86-90eb-7c7232b9b540' included in the embed code provided in Watson Assistant.\nintegrationID: \"YOUR_INTEGRATION_ID\",\n// Your assistants region e.g. 'us-south', 'us-east', 'jp-tok' 'au-syd', 'eu-gb', 'eu-de', etc.\nregion: \"YOUR_REGION\",", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-mobile"}, {"document_id": "ibmcld_03166-4588-6408", "score": 17.068352, "text": "\nIf you don't want to use a home screen, go to the Home screen tab and toggle the switch to Off.\n8. Optional: To configure support for transferring conversations to a service desk agent, click the Live agent tab. For more information, see [Adding service desk support](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-haa).\n9. Optional: The web chat gives your customers a way to reset the conversation if they get stuck by showing them a list of suggestions. Suggestions are enabled automatically. You can control how often suggestions are displayed and what they include. Click the Suggestions tab. For more information, see [Showing more suggestions](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n10. Optional: To secure the web chat, click the Security tab. For more information, see [Securing the web chat](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-security).\n11. Click the Embed tab.\n\nA code snippet is displayed that defines the chat window implementation. You will add this code snippet to your web page. The code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site. The code creates an instance of a widget that communicates with the assistant. The generated code includes a region and unique integration ID. Do not change these parameter values.\n12. Copy the script HTML element. You add this script to your website in the next section, [Deploy your assistant in production](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-snippet).\n13. If you made any customizations, click Save and exit. Otherwise, click Close.\n\nThe web chat instance is created as soon as you click the Create button, and does not need to be saved.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat"}, {"document_id": "ibmcld_16364-80271-82046", "score": 16.853403, "text": "\n* If your web chat integration connects to a Salesforce service desk, then you must edit the API call that is included in the code snippet that you added to the Visualforce Page that you created in Salesforce. From Salesforce, search for Visualforce Pages, and find your page. In the <iframe> snippet that you pasted into the page, make the following change:\n\nReplace: src=\u201chttps://assistant-integrations-{location}.watsonplatform.net/public/salesforceweb\u201d with a url with this syntax:\n\nsrc=\"https://integrations.{location}.assistant.watson.appdomain.cloud/public/salesforceweb/{integration-id}/agent_application?version=2020-09-24\"\n\nFrom the Web chat integration Salesforce live agent setup page, find the Visualforce page markup field. Look for the src parameter in the <iframe> element. It contains the full URL to use, including the appropriate {location} and {integration-id} values for your instance.\n* For a Slack integration that is over 7 months old, make sure the Request URL is using the proper endpoint.\n\n\n\n* Go to the [Slack API](https://api.slack.com/) web page. Click Your Apps to find your assistant app. Click Event Subscriptions from the navigation pane.\n* Edit the Request URL.\n\n\n\nFor example, if the URL has the syntax: https://assistant-slack-{location}.watsonplatform.net/public/message, change it to have this syntax:\n\nhttps://integrations.{location}.assistant.watson.appdomain.cloud/public/slack/{integration-id}/message?version=2020-09-24\n\nCheck the Generated request URL field in the Slack integration setup page for the full URL to use, which includes the appropriate {location} and {integration-id} values for your instance.\n* For a Facebook Messenger integration that is over 7 months old, make sure the Callback URL is using the proper endpoint.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_16368-7-2072", "score": 16.776102, "text": "\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop"}, {"document_id": "ibmcld_03196-33522-35244", "score": 16.749283, "text": "\nIn the web chat, the linked video will render using the embeddable player for the hosting service.\n\nSpecify the URL you would use to view the video in your browser (for example, https://www.youtube.com/watch?v=52bpMKVigGU). You do not need to convert the URL to an embeddable form; the web chat will do this automatically.\n\nYou can embed videos hosted on the following services:\n\n\n\n* [YouTube](https://youtube.com)\n* [Facebook](https://facebook.com)\n* [Vimeo](https://vimeo.com)\n* [Twitch](https://twitch.tv)\n* [Streamable](https://streamable.com)\n* [Wistia](https://wistia.com)\n* [Vidyard](https://vidyard.com)\n\n\n\n\n\nIf you want to display a video title and description above the embedded video in the response, then add them in the fields provided.\n\nSome integration channels ignore titles or descriptions.\n\nIf you want to scale the video to a specific display size, specify a number in the Base height field.\n3. The Video response type is supported in the web chat, Facebook, WhatsApp, Slack, and SMS integrations.\n\n\n\n\n\n\n\n Adding an Audio response type \n\nInclude audio clips in your response to share spoken-word or other audible content. In the web chat, a video response renders as an embedded video player. In the phone integration, an audio response plays over the phone.\n\nTo add an Audio response type, complete the following steps:\n\n\n\n1. Choose Audio.\n2. Add the full URL to the hosted audio clip into the Audio source field:\n\n\n\n* To link directly to an audio file, specify the URL to a file in any standard format such as MP3 or WAV. In the web chat, the linked audio clip will render as an embedded audio player.\n* To link to an audio clip on a supported audio hosting service, specify the URL to the audio clip.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overview"}, {"document_id": "ibmcld_16365-14167-16117", "score": 16.717844, "text": "\n{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https://cloud.ibm.com/docs/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security \n\nThe web chat integration undergoes tests and scans on a regular basis to find and address potential security issues, such as cross-site scripting (XSS) vulnerabilities.\n\nBe sure to run your own security reviews to see how the web chat fits in with your current website structure and policies. The web chat is hosted on your site and can inherit any vulnerabilities that your site has. Only serve content over HTTPS, use a Content Security Policy (CSP), and implement other basic web security precautions.\n\n\n\n\n\n\n\n Billing \n\nWatson Assistant charges based on the number of unique monthly active users (MAU).\n\nBy default, the web chat creates a unique, anonymous ID the first time a new user starts a session. This identifier is stored in a first-party cookie, which remains active for 45 days. If the same user returns to your site and chats with your assistant again while this cookie is still active, the web chat integration recognizes the user and uses the same user ID. This means that you are charged only once per month for the same anonymous user.\n\nOn Apple devices, the Intelligent Tracking Prevention feature automatically deletes any client-side cookie after 7 days. This means that if an anonymous customer accesses your website and then visits again two weeks later, the two visits are treated as two different MAUs. For information about how to avoid this problem, see [Managing user identity information](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-userid).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_16384-1889-3334", "score": 16.69348, "text": "\nYou can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.\n\n\n\n* [How the web chat works](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture): Overview of web chat capabilities and architecture\n* [Embedding the web chat on your page](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat): How to embed the web chat widget on your website\n* [Web chat setup](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config): How to configure the web chat using the integration settings\n* [Web chat development](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config): How to customize and extend the web chat by writing code\n* [Adding contact center support](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat-haa): How to integrate the web chat with a contact center platform so you can connect your customers to human agents", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-overview"}]}
{"task_id": "fdee20f7fd677e420742b09989623d68<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16306-2449-4025", "score": 19.129639, "text": "\nFor more information, see [Managing user identity information](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-userid). \n Slack The Slack member ID (for example, U2147483697). \n Facebook The Facebook sender ID (for example, 4310101122439797). \n Whatsapp The customer's phone number. \n Phone The customer's phone number. \n SMS with Twilio The customer's phone number. \n\n\n\n\n\n\n\n\n\n chat \n\nIncluded only if the web chat integration is in use.\n\n\n\n Properties \n\n\n\nProperties of the chat object\n\n Name Type Description \n\n browser_info.browser_name String The browser name, such as chrome, edge, or firefox. \n browser_info.browser_version String The browser version, such as 109.0.0. \n browser_info.browser_OS String The operating system of the customer's computer, such as Mac OS. \n browser_info.language String The default locale code of the browser, such as en-US. \n browser_info.page_url String The URL of the web page where the web chat is embedded, not including any query parameters or hashes. \n browser_info.screen_resolution String The height and width of the browser window, such as width: 1440, height: 900. \n browser_info.user_agent String The content of the HTTP User-Agent request header. \n browser_info.client_ip_address String The IP address of the customer's computer. \n browser_info.ip_address_list Array Ann array IP addresses specified by HTTP X-Forwarded-For request headers. \n\n\n\n\n\n\n\n Example JSON \n\n\"chat\": {\n\"browser_info\": {\n\"browser_name\": \"chrome\",\n\"browser_version\": \"109.0.0\",\n\"browser_OS\": \"Mac OS\",\n\"language\": \"en-US\",", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-expression-integration-variables"}, {"document_id": "ibmcld_16365-11574-13329", "score": 18.93208, "text": "\nAnyone who has these IDs could use them to send messages to your assistant and receive its replies. However, these IDs cannot be used to log in to your account, make any changes to your assistant, or retrieve logs or analytics information about your assistant.\n\nIf you are concerned about unauthorized access to your assistant, you can enable the web chat security feature for additional security, such as verifying message origin and authenticating users. Enabling the security feature requires additional development work on your website. For more information, see [Web chat security](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n Updating site security policies \n\nIf your website uses a Content Security Policy (CSP), you must update it to grant permission to the web chat.\n\nThe following table lists the values to add to your CSP.\n\n\n\nCSP properties\n\n Property Additional values \n\n default-src 'self' *.watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline' \n connect-src *.watson.appdomain.cloud \n\n\n\nThe following example shows a complete CSP metadata tag:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline';connect-src .watson.appdomain.cloud\" />\n\n\n\n Allowing elements \n\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_02855-25179-26743", "score": 18.81582, "text": "\nfunction mockLogin() {\nconst payload = {\n/\n* Even if this is an unauthenticated user, add a userID in the sub claim that can be used\n* for billing purposes.\n* This ID will help us keep track \"unique users\". For unauthenticated users, drop a\n* cookie in the browser so you can make sure the user is counted uniquely across visits.\n/\nsub: 'some-user-id', // Required\niss: 'yourdomain.com' // Required\n};\n// The \"expiresIn\" option adds an \"exp\" claim to the payload.\nreturn jwt.sign(payload, process.env.YOUR_PRIVATE_RSA_KEY, { algorithm: 'RS256', expiresIn: '10000ms' });\n}\nShow more\n\n\n\nTo enable security, complete the following steps:\n\n\n\n1. From the web chat integration page in Watson Assistant, set the Secure your web chat switch to On.\n2. Add your public key to the Your public key field.\n\nThe public key that you add is used to verify that data which claims to come from your web chat instance is coming from your web chat instance.\n3. To prove that a message is coming from your website, each message that is submitted from your web chat implementation must include the JSON Web Token (JWT) that you created earlier.\n\nAdd the token to the web chat code snippet that you embed in your website page. Specify the token in the identityToken property.\n\nFor example:\n\n<script>\nwindow.watsonAssistantChatOptions = {\nintegrationID: 'YOUR_INTEGRATION_ID',\nregion: 'YOUR_REGION',\nserviceInstanceID: 'YOUR_SERVICE_INSTANCE',\nidentityToken: 'YOUR_JWT',\nonLoad: function(instance) {\ninstance.render();\n}\n};\nsetTimeout(function(){\nconst t=document.createElement('script');", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat"}, {"document_id": "ibmcld_02855-7-2041", "score": 18.453024, "text": "\nIntegrating the web chat with your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, click the Web chat tile.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n4. Click Create to create a web chat instance.\n5. Optional: Customize the style of the chat window. You can make the following changes:\n\n\n\n* Public assistant name. Name by which the assistant is known to users. This name is displayed in the header of the chat window. The name can be up to 18 characters in length.\n* Primary color. Sets the color of the web chat header.\n\nClick the white dot to open a color switcher where you can choose a color. The color is saved as an HTML color code, such as FF33FC for pink and 329A1D for green. Alternatively, you can add an HTML color code directly to the field to set the color.\n* Secondary color: Sets the color of the user input message bubble.\n* Accent color. Sets the color of interactive elements, including:\n\n\n\n* Chat launcher button that is embedded in your web page\n* Send button associated with the input text field\n* Input text field border when in focus\n* Marker that shows the start of the assistant\u2019s response\n* Border of a button after it is clicked\n* Border of the drop-down list field as the user chooses an option\n* Typing indicator that is shown to repesent a pause response", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat"}, {"document_id": "ibmcld_16389-0-2061", "score": 18.284367, "text": "\n\n\n\n\n\n\n  Configuring style and appearance \n\nOn the Style tab, you can configure the overall appearance of the web chat widget. You can make the following changes:\n\n\n\n*  Set the assistant name. Click Assistant's name as known by customers to specify the name that is displayed in the header of the chat window. The name can be up to 64 characters in length.\n*  Change the colors used in the web chat widget. You can set the following colors:\n\n\n\n*  Primary color: The color of the web chat header.\n*  Secondary color: The color of the customer input message bubble.\n*  Accent color: The color of interactive elements such as the following:\n\n\n\n*  Web chat buttons such as the suggestions button and the \"send message\" button\n*  The border around the input text field (when in focus)\n*  The markers that appear beside the assistant\u2019s messages\n*  The borders that appear around buttons and drop-down lists when customers select from options\n*  The home screen background\n\n\n\n\n\nEach color is specified as an HTML hexadecimal color code, such as FF33FC for pink and 329A1D for green. To change a color, type the HTML color code you want to use, or click the dot next to the field and choose the color from the interactive color picker.\n*  Enable or disable the Built with IBM Watson watermark that is displayed in the web chat widget. To disable the watermark, click to toggle the IBM Watermark switch to the off position. (The watermark cannot be disabled on the Lite plan.)\n*  Provide an avatar image to represent your assistant or organization in the web chat header. Click Add an avatar image to add an image, or Change avatar image to change an image you have previously added.\n\nSpecify the URL for a publicly accessible hosted image, such as a company or brand logo or an assistant avatar. The image file must be between 64 x 64 and 100 x 100 pixels in size.\n\n\n\nStyle changes you make are immediately reflected by the web chat preview that is shown on the page. However, no configuration changes are applied to the environment until you click Save and exit.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-style"}, {"document_id": "ibmcld_02774-5358-7120", "score": 18.094822, "text": "\nA user's predefined attributes are empty until their first authentication. Although they're empty, the user is still fully authenticated. You can use their profile ID just as you would someone who has already signed in. For instance, you can modify, search, or delete the profile.\n\n\n\n Before you begin \n\nBefore you get started, you must have the following information:\n\n\n\n* Which identity provider that the user will sign in with.\n* The email of the user that you want to add or their [unique identifier](https://cloud.ibm.com/docs/appid?topic=appid-preregisterpreregister-idp-provide).\n* The [custom attribute](https://cloud.ibm.com/docs/appid?topic=appid-profiles) information that you want to assign.\n\n\n\n\n\n\n\n With the GUI \n\nYou can add a future user and their custom attributes by using the GUI.\n\nThe ability to add future users is disabled for the user name and password configuration of Cloud Directory.\n\n\n\n1. Go to the User Profiles tab of the App ID dashboard.\n2. Click Future users. If you already have future users, you see a table with a list of the user's that you already added. To add another user, click Build a profile. If you don't have any users yet, click Get Started. A screen opens.\n3. Enter your user's email.\n4. Select the identity provider that they sign in with from the Identity Provider drop down.\n5. Add custom attributes by entering the information in a JSON object as shown in the following example.\n\n{\n\"food\": \"Pizza\",\n\"preference\": \"Vegetarian\",\n\"points\": \"37\"\n}\n6. Click Save. The table displays and the user is assigned an identifier.\n\n\n\n\n\n\n\n With the API \n\nYou can add a future user and their custom attributes by using the API.\n\n\n\n1. Log in to IBM Cloud.\n\nibmcloud login\n2. Find your IAM token by running the following command.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-preregister"}, {"document_id": "ibmcld_16295-7-1721", "score": 18.018621, "text": "\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat"}, {"document_id": "ibmcld_02327-1300-2588", "score": 17.876558, "text": "\nIf you log in with a SoftLayer ID, you can also change your profile information from the Profile page.\n\nIf you log in with an ID from an external identity provider (IdP), then your information from your IdP is displayed. However, you can't update it on the Profile page. You must update your user information with your IdP.\n\n\n\n\n\n Changing your cookie settings \n\nThe IBM Cloud console requires cookies to manage your sessions, such as to provide secure login, handle transactions, and save some preferences. Additional cookies are used to build a more personalized experience for you and provide better support. If you change your cookie settings from the IBM standard default, you might not be able to use some features, such as chat communications.\n\nTo change your settings from the IBM standard default, complete the following steps:\n\n\n\n1. In the console, go to the Avatar icon ![Avatar icon](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/i-avatar-icon.svg) > Privacy.\n2. Move the slider to select your level of allowed cookies.\n\nYou can click Advanced settings to view the exact company and domain for the cookies in each level. Then, click Basic settings to return to cookie preference selection.\n3. Click Agree and save custom settings.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-usersettings"}, {"document_id": "ibmcld_03196-30333-32476", "score": 17.874443, "text": "\nIn the Message before link to web chat field, edit the introductory message to display to the user (in the originating channel) before the link that initiates the transfer. By default, this message is OK, click this link for additional help. Chat will continue on a new web page.\n3. In the URL to web chat field, type the URL for your website where the web chat widget is embedded.\n\n\n\nIn the integration that processes the Channel transfer response, the introductory message is displayed, followed by a link to the URL you specify. The user must then click the link to initiate the transfer.\n\nWhen a conversation is transferred from one channel to another, the session history and context are preserved, so the destination channel can continue the conversation from where it left off. Note that the message output that contains the Channel transfer response is processed first by the channel that initiates the transfer, and then by the target channel. If the output contains multiple responses (perhaps using different response types), these will be processed by both channels (before and after the transfer). If you want to target individual responses to specific channels, you can do so by editing the response using the JSON editor. For more information, see [Targeting specific integrations](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-responses-jsondialog-responses-json-target-integrations).\n\n\n\n\n\n Adding an Image response type \n\nSometimes a picture is worth a thousand words. Include images in your response to do things like illustrate a concept, show off merchandise for sale, or maybe to show a map of your store location.\n\nTo add an Image response type, complete the following steps:\n\n\n\n1. Choose Image.\n2. Add the full URL to the hosted image file into the Image source field.\n\nThe image must be in .jpg, .gif, or .png format. The image file must be stored in a location that is publicly addressable by an https: URL.\n\nFor example: https://www.example.com/assets/common/logo.png.\n\nIf you want to display an image title and description above the embedded image in the response, then add them in the fields provided.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overview"}, {"document_id": "ibmcld_16326-3092-4450", "score": 17.82587, "text": "\nYou can visualize how your assistant would look as a web chat widget on your organization's website. You can enter a URL or upload an image.\n\n\n\n Entering a URL \n\nYou can enter a URL of your organization's website. Watson Assistant captures an image of your website to use as the Preview page background.\n\nYour website must be publicly available to all users. Private or intranet sites can\u2019t be accessed. Any login, splash, cookie, or warning screens might be captured in the image.\n\nTo enter a URL:\n\n\n\n1. On the Preview page, click Change background.\n2. Click Enter URL, then click Continue.\n3. Enter the path of your website URL, for example, https://www.example.com or example.com.\n4. Click Continue.\n\n\n\n\n\n\n\n Uploading an image \n\nYou can upload an image of your organization's website. Images are stored for 24 hours. Maximum file size is 1 MB. Supported file types are JPEG and PNG.\n\nTo upload an image:\n\n\n\n1. On the Preview page, click Change background.\n2. Click Upload an image, then click Continue.\n3. Drag a file or click to upload, then click Change background.\n\n\n\nImages are stored for 24 hours. A warning message might appear on the Preview page about the time limit expiration. To clear this message:\n\n\n\n1. On the Preview page, click Change background.\n2. Click Clear background setting, then click Continue.\n3. Click Remove background to finish.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-preview-share"}]}
{"task_id": "fdee20f7fd677e420742b09989623d68<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16365-7-1700", "score": 22.582428, "text": "\nHow the web chat works \n\nThe web chat provides an easy-to-use chatbot interface that you can add to your website without writing any code.\n\nAfter you add the web chat script to your website, your customers will see a launcher icon that they can click to open the chat window and start a conversation with the assistant. The appearance of the launcher icon adapts to desktop and mobile browsers.\n\n![web chat launcher in desktop browser](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/web-chat-desktop-highlighted.png)\n\nWhen a customer clicks the launcher, the web chat window opens, initially displaying the home screen. The home screen displays a greeting and an optional set of suggested conversation starters for common questions and problems. The customer can either click a conversation starter or type a message in the input field to start the conversation with the assistant.\n\n![web chat example home screen](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/web-chat-home-screen-lendyr.png)\n\nThe appearance and behavior of the launcher icon, the home screen, and most other aspects of the web chat can be configured and customized to match your website style and branding. For more information, see [Configuring the web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_16384-7-2422", "score": 20.124044, "text": "\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-overview"}, {"document_id": "ibmcld_16368-7-2072", "score": 19.059576, "text": "\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop"}, {"document_id": "ibmcld_03418-4-2127", "score": 19.024254, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Web chat overview \n\nLearn more about the web chat that you can add to your company website.\n\nWeb chat is a code snippet that you can immediately embed in your website.\n\nWhen you build a custom user interface for your assistant, you spend a lot of time and effort writing code to solve typical UI problems. For example, you must keep up with browser support changes, manage scrolling behavior, validate input, and design the layout and styling. The time you spend designing and maintaing a UI can be better spent building a quality assistant instead. When you use the web chat integration, you can rely on us to manage the user interface, so you can focus on designing conversational exchanges that address the unique business needs of your customers. Cutting-edge functionality from IBM Design and Research is incorporated into the web chat to deliver an exceptional user experience.\n\nFor more information about how to deploy the web chat, see [Integrating the web chat with your website](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat).\n\n\n\n Browser support \n\nThe web chat supports a variety of devices and platforms. As a general rule, if the last two versions of a browser account for more than 1% of all desktop or mobile traffic, the web chat supports that browser.\n\nThe following list specifies the minimum required browser software for the web chat (including the two most recent versions, except as noted):\n\n\n\n* Google Chrome\n* Apple Safari\n* Mobile Safari\n* Chrome for Android\n* Microsoft Edge (Chromium and non-Chromium)\n* Mozilla Firefox\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n\n\n\n\n\n Global audience support", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-basics"}, {"document_id": "ibmcld_16365-8408-10508", "score": 19.019941, "text": "\nThe code snippet that creates the web chat widget includes a configuration object, which you can modify to change the appearance and behavior of the web chat. The configuration object also specifies details that enable the web chat to connect to your assistant. If you are comfortable writing JavaScript code, you can customize the web chat by modifying the code snippet and using the web chat API.\n\nThe web chat uses the Watson Assistant v2 stateful API to communicate with the assistant. By default, the session ends and the conversation ends after 5 minutes of inactivity. This means that if a user stops interacting with the assistant, after 5 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values. You can change the inactivity timeout setting in the assistant settings (if allowed by your plan).\n\n\n\n Browser support \n\nThe web chat supports a variety of devices and platforms. As a general rule, if the last two versions of a browser account for more than 1% of all desktop or mobile traffic, the web chat supports that browser.\n\nThe following list specifies the minimum required browser software for the web chat (including the two most recent versions, except as noted):\n\n\n\n* Google Chrome\n* Apple Safari\n* Mobile Safari\n* Chrome for Android\n* Microsoft Edge (Chromium and non-Chromium)\n* Mozilla Firefox\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n\n\n\n\n\n Accessibility \n\nIBM strives to provide products with usable access for everyone, regardless of age or ability.\n\nThe web chat integration complies with the [Web Content Accessibility 2.1 Level AA](https://www.w3.org/WAI/standards-guidelines/wcag/new-in-21/) standard. It is tested with both screen readers and automated tools on a continual basis.\n\n\n\n\n\n Language support", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_03418-1763-3833", "score": 18.623583, "text": "\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n\n\n\n\n\n Global audience support \n\nThe underlying skills understand customer messages that are written in any of the languages that are supported by the service. For more information, see [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support). The responses from your assistant are defined by you in the underlying skill and can be written in any language you want.\n\nEven if your skill includes responses in a language other than English, some of the phrases that are displayed in the web chat widget are added by the web chat itself and do not come from the underlying skill. These hardcoded phrases are specified in English unless you choose to apply a different language.\n\nThere are language files that contain translations of each English-language phrase that is used by the web chat. You can instruct the web chat to use one of these other languages files by using the instance.updateLanguagePack() method.\n\nLikewise, the web chat applies an American English locale to content that is added by the web chat unless you specify something else. The locale setting affects how values such as dates and times are formatted.\n\nTo configure the web chat for customers outside the US, follow these steps:\n\n\n\n1. To apply the appropriate syntax to dates and times and to use a translation of the English-language phrases, set the locale. Use the instance.updateLocale() method.\n\nFor example, if you apply the Spanish locale (es), the web chat uses Spanish-language phrases that are listed in the es.json file, and uses the DD-MM-YYYY format for dates instead of MM-DD-YYYY.\n\nThe locale you specify for the web chat does not impact the syntax of dates and times that are returned by the underlying skill.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-basics"}, {"document_id": "ibmcld_16381-0-734", "score": 18.607122, "text": "\n\n\n\n\n\n\n  Web chat development tutorials \n\nThe tutorials in this section provide detailed examples, including code snippets, showing customizations that you can implement using the web chat API.\n\nEach tutorial includes links to a [GitHub repository](https://github.com/watson-developer-cloud/assistant-toolkit/tree/master/integrations/webchat/examples/) where you can download complete working code for the example. You can run this code to see the customization in action, adapt it for your own web chat implementation, or use it as a guide for similar customizations of your own.\n\nThe GitHub repository also includes additional tutorials and examples that have not yet been added to this documentation, so feel free to browse.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-tutorials"}, {"document_id": "ibmcld_16374-0-2178", "score": 18.427065, "text": "\n\n\n\n\n\n\n  Supporting global audiences \n\nYou can build an assistant that understands customer messages in any of the languages that are supported by the service. The responses from your assistant are defined by you and can be written in any language you want.\n\nHowever, some of the phrases that are displayed in the web chat widget are part of the web chat itself and do not come from the assistant. By default, these hardcoded phrases are specified in English, but you can apply a different language by adding lines to the embedded web chat script.\n\nThe hardcoded phrases used by the web chat widget are specified in language pack files. The web chat provides language packs that contain translations of each English-language phrase that is used by the web chat. You can instruct the web chat to use one of these other languages files by using the instance.updateLanguagePack() method.\n\nLikewise, the web chat applies an American English locale to content that is added by the web chat unless you specify something else. The locale setting affects how values such as dates and times are formatted.\n\nTo configure the web chat for customers outside the US, follow these steps:\n\n\n\n1.  To apply the appropriate syntax to dates and times and to use a translation of the English-language phrases, set the locale. Use the instance.updateLocale() method.\n\nFor example, if you apply the Spanish locale (es), the web chat uses Spanish-language phrases that are listed in the es.json file, and uses the DD-MM-YYYY format for dates instead of MM-DD-YYYY.\n\nThe locale you specify for the web chat does not impact the syntax of dates and times that are returned by the underlying skill.\n2.  To change only the language of the hardcoded English phrases, use the instance.updateLanguagePack() method.\n\nFor more information, see [Instance methods](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodslanguages).\n3.  To change the text direction of the page from right to left, use the direction method. For more information, see [Configuration](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-global"}, {"document_id": "ibmcld_16334-20193-22029", "score": 18.37049, "text": "\n* \"User is typing\" support: The web chat now supports displaying the \"user is typing\" message for service desks. This feature is supported for the Salesforce and Zendesk integrations, as well as any [starter kit](https://github.com/watson-developer-cloud/assistant-web-chat-service-desk-starter) integration that implements it.\n* Bug fixes.\n\n\n\n\n\n\n\n 5.1.0 \n\nRelease date: 28 October 2021\n\n\n\n* Custom Panels: The web chat now supports customizable panels you can use to display any custom HTML content (for example, a feedback form or a multistep process). Your code can use instance methods to dynamically populate a custom panel, as well as open and close it. For more information, see [Custom Panels](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodscustompanels).\n\n\n\n\n\n\n\n 5.0.2 \n\nRelease date: 4 October 2021\n\n\n\n* A [new tutorial](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-react-portals) is now available that shows how to use Carbon components to customize user-defined responses and writeable elements.\n* Bug fixes.\n\n\n\n\n\n\n\n 5.0.1 \n\nRelease date: 20 September 2021\n\n\n\n* Bug fixes.\n\n\n\n\n\n\n\n 5.0.0 \n\nRelease date: 16 September 2021\n\n\n\n* New response types: The web chat now supports the new video, audio, and iframe response types. For more information about these response types, see [Rich responses](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-multimedia).\n* Link to start web chat: You can now create a set of HTML links that go directly to your web chat and start conversations on specific topics. For example, you might want to send an email inviting customers to update their account information; you can include a link that opens the web chat on your site and sends the initial message I want to update my account.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-release-notes-chat"}, {"document_id": "ibmcld_16375-7-1735", "score": 18.293835, "text": "\nAdding the web chat to your mobile application \n\nIf you have a mobile application built on a mobile framework such as iOS, Android, or React Native, you can use a WebView with a JavaScript bridge to communicate between your app and the Watson Assistant web chat.\n\nUsing WebViews with a JavaScript bridge is a common pattern with a similar implementation for all mobile frameworks.\n\n\n\n Including the web chat as a WebView \n\nYou can include the web chat interface as part of a page of your mobile app, or as a separate panel that your app opens. In either case, you must host an HTML page that includes the web chat embed script, and then include that page as a WebView in your app.\n\nIn the embed script, use the showLauncher option to hide the web chat launcher icon, and the openChatByDefault option to open the web chat automatically when the page loads. In most cases, you will also want to use the hideCloseButton option and use the native controls of your app to control how the web chat page or panel closes. For more information about the configuration options you can specify in the embed script, see the [Web chat API reference](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configuration).\n\nThe following example shows an embed script that includes these configuration options:\n\n<html>\n<head>\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n</head>\n<body>\n<script>\nwindow.watsonAssistantChatOptions = {\n// A UUID like '1d7e34d5-3952-4b86-90eb-7c7232b9b540' included in the embed code provided in Watson Assistant.\nintegrationID: \"YOUR_INTEGRATION_ID\",\n// Your assistants region e.g. 'us-south', 'us-east', 'jp-tok' 'au-syd', 'eu-gb', 'eu-de', etc.\nregion: \"YOUR_REGION\",", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-mobile"}]}
{"task_id": "927077bd895f0c292618f4a34789bef3<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13895-7118-8344", "score": 15.693245, "text": "\n6.7R14S2 \n\nReleased October 10, 2017.\n\n\n\n Issues Resolved \n\n\n\nIssues resolved in 6.7R14S2\n\n Issue Number Priority Summary \n\n VSE-9837 Minor \u201cshow system commit different\u201d showing permission denied after upgrade from 6.7R11S9 to 6.7R13S3 \n\n\n\n\n\n\n\n Security Vulnerabilities Resolved \n\n\n\nSecurity vulnerabilties resolved in 6.7R14S2\n\n Issue Number CVSS score Advisory Summary \n\n VSE-9845 9.8 DLA-1124-1 CVE-2017-14491, CVE-2017-14492, CVE-2017-14494: Debian DLA-1124-1: dnsmasq security update \n\n\n\n\n\n\n\n\n\n 6.7R14S1 \n\nReleased September 22, 2017.\n\n\n\n Issues Resolved \n\n\n\nIssues resolved in 6.7R14S1\n\n Issue Number Priority Summary \n\n VSE-9831 Major MTU setting reverts back to default after reboot on a VIF interface \n\n\n\n\n\n\n\n Security Vulnerabilities Resolved \n\n\n\nSecurity vulnerabilties resolved in 6.7R14S1\n\n Issue Number CVSS score Advisory Summary \n\n VSE-9841 9.8 DLA-1060-1 CVE-2017-0663, CVE-2017-7376: Debian DLA-1060-1: libxml2 security update \n VSE-9840 6.5 DLA-1062-1 CVE-2017-1000100: Debian DLA-1062-1: curl security update \n VSE-9839 7.5 DLA-1059-1 CVE-2017-11185: Debian DLA-1059-1: strongswan security update \n VSE-9835 7.5 DSA-3900-1 CVE-2017-7522, CVE-2017-7521, CVE-2017-7520, CVE-2017-7508 OpenVPN security update", "title": "", "source": "https://cloud.ibm.com/docs/virtual-router-appliance?topic=virtual-router-appliance-at-t-vyatta-5400-vrouter-security-vulnerability-fixes"}, {"document_id": "ibmcld_16173-12945-14297", "score": 14.762256, "text": "\nIBM has since transitioned to a new architecture for its gateways that leverages SR-IOV on the host. This caused the vSRX configuration\u2019s interface mapping to change in many cases. Differences in the interface configuration are also influenced by whether the vSRX is:\n\n\n\n* 10G or 1G\n* Standalone or High Availability\n* Public and Private, or Private Only\n* The vSRX Version\n\n\n\n* All 15.1 based vSRX\u2019s use the legacy architecture\n* Some 18.4 based vSRX\u2019s also use the legacy architecture\n\n\n\n\n\nBoth the legacy and current architecture is detailed in the following sections.\n\n\n\n vSRX High Availability interfaces (current architecture) \n\n\n\nTable 2: vSRX High Availability interfaces (current architecture)\n\n Interface 10G Pub+Priv 10G Priv Only 1G Pub+Priv 1G Priv Only \n\n ge-0/0/0 fab0 fab0 fab0 fab0 \n ge-0/0/1 reth0 reth0 reth0 reth0 \n ge-0/0/2 reth0 reth0 reth0 reth0 \n ge-0/0/3 reth1 reth2 reth1 reth2 \n ge-0/0/4 reth1 reth2 reth1 reth2 \n ge-0/0/5 reth2 fab0 reth2 fab0 \n ge-0/0/6 reth2 Does Not Exist reth2 Does Not Exist \n ge-0/0/7 reth3 Does Not Exist reth3 Does Not Exist \n ge-0/0/8 reth3 Does Not Exist reth3 Does Not Exist \n ge-0/0/9 fab0 Does Not Exist fab0 Does Not Exist \n ge-7/0/0 fab1 fab1 fab1 fab1 \n ge-7/0/1 reth0 reth0 reth0 reth0 \n ge-7/0/2 reth0 reth0 reth0 reth0 \n ge-7/0/3 reth1 reth2 reth1 reth2 \n ge-7/0/4 reth1 reth2 reth1 reth2", "title": "", "source": "https://cloud.ibm.com/docs/vsrx?topic=vsrx-understanding-the-vsrx-default-configuration"}, {"document_id": "ibmcld_12143-11142-12571", "score": 14.3015585, "text": "\nVersions 0.13 through 0.15 require a stepwise upgrade, 0.13 to 0.14, 0.14 to 0.15, 0.15 to 1.0.\n\nThe process is the same for each version step. It is mandatory that a Terraform Apply is run after each version change. This updates the Terraform state file with schema changes related to that version and that version only. After successfully upgrading a single version, the next version update can be performed.\n\n\n\n1. Read the Terraform [upgrade guide](https://developer.hashicorp.com/terraform/language/v1.1.x/upgrade-guides) for the release and implement any required config changes.\n2. Follow the process outlined in [Upgrading the Terraform template version 1.x and above](https://cloud.ibm.com/docs/schematics?topic=schematics-migrating-terraform-versionterraform-version-upgrade1x-process) to upgrade a single version to the target version.\n3. Verify in the Workspace settings page the TF version is now set to the desired version.\n4. Run a Generate Plan operation against the workspace. Validate that the command runs successfully without error and no unexpected messages are logged. The Plan should result in no proposed changes to the resources.\n5. Run a Apply Plan operation against the workspace. This step is mandatory to perform a Terraform state file update. Validate that the command runs successfully without error and no unexpected messages are logged.\n6. You have now successfully upgraded a single version step.", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-migrating-terraform-version"}, {"document_id": "ibmcld_05525-7-1062", "score": 13.793745, "text": "\nVersion 1.14 change log (unsupported 31 May 2020) \n\nVersion 1.14 is unsupported. You can review the following archive of 1.14 change logs.\n\n\n\n Change log for worker node fix pack 1.14.10_1555, released 26 May 2020 \n\nThe following table shows the changes that are in the worker node fix pack 1.14.10_1555. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.14.10_1554\n\n Component Previous Current Description \n\n Ubuntu 18.04 packages 4.15.0-99-generic 4.15.0-101-generic Updated worker node images with kernel and package updates for [CVE-2019-20795](https://nvd.nist.gov/vuln/detail/CVE-2019-20795), [CVE-2020-11494](https://nvd.nist.gov/vuln/detail/CVE-2020-11494), [CVE-2020-12762](https://nvd.nist.gov/vuln/detail/CVE-2020-12762), [CVE-2020-3810](https://nvd.nist.gov/vuln/detail/CVE-2020-3810), [CVE-2020-8616](https://nvd.nist.gov/vuln/detail/CVE-2020-8616), and [CVE-2020-8617](https://nvd.nist.gov/vuln/detail/CVE-2020-8617).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-114_changelog"}, {"document_id": "ibmcld_16034-7-1778", "score": 13.611768, "text": "\nVPC CLI release notes \n\nThe following release notes are for the IBM Cloud\u00ae Virtual Private Cloud (VPC) command line interface (CLI).\n\n\n\n v6.15.0 \n\nVersion 6.15.0 was released on 2023-07-11.\n\n\n\n New commands \n\n\n\n* New commands image-obsolete and image-deprecate are introduced to support image lifecycle management.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for image lifecycle management in image-create, image-update, and images commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v6.14.1 \n\nVersion 6.14.1 was released on 2023-06-30.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed issue with using the SSH key generated from UI in CLI.\n\n\n\n\n\n\n\n\n\n v6.14.0 \n\nVersion 6.14.0 was released on 2023-06-23.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for more algorithms in the SSH key key-create command.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v6.13.0 \n\nVersion 6.13.0 was released on 2023-06-22.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for snapshot and backup cross region copy in snaphot-create, snapshots, backup-policy-plan-create and backup-policy-plan-update commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v6.12.0 \n\nVersion 6.12.0 was released on 2023-06-01.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for fileshare mount targets in share commands (Beta).\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed bare-metal-server-network-interfaces, bare-metal-server-profiles and bare-metal-servers commands to print correct response values.\n\n\n\n\n\n\n\n\n\n v6.11.1 \n\nVersion 6.11.1 was released on 2023-05-03.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-cli-rn"}, {"document_id": "ibmcld_00861-47234-48299", "score": 13.399418, "text": "\nOS name: \"linux\", version: \"5.15.49-linuxkit\", arch: \"amd64\", family: \"unix\"\n\n gradle -version\n\nWelcome to Gradle 7.6!\n\nHere are the highlights of this release:\n- Added support for Java 19.\n- Introduced --rerun flag for individual task rerun.\n- Improved dependency block for test suites to be strongly typed.\n- Added a pluggable system for Java toolchains provisioning.\n\nFor more details see https://docs.gradle.org/7.6/release-notes.html\n\n------------------------------------------------------------\nGradle 7.6\n------------------------------------------------------------\n\nBuild time: 2022-11-25 13:35:10 UTC\nRevision: daece9dbc5b79370cc8e4fd6fe4b2cd400e150a8\n\nKotlin: 1.7.10\nGroovy: 3.0.13\nAnt: Apache Ant(TM) version 1.10.11 compiled on July 10 2021\nJVM: 17.0.5 (Eclipse OpenJ9 openj9-0.35.0)\nOS: Linux 5.15.49-linuxkit amd64\n\n oc version\nClient Version: 4.12.0\nKustomize Version: v4.5.7\n\n zip\nCopyright (c) 1990-2008 Info-ZIP - Type 'zip \"-L\"' for software license.\nThis is Zip 3.0 (July 5th 2008), by Info-ZIP.\n\n unzip\nUnZip 6.00 of 20 April 2009, by Info-ZIP.", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-pipeline_versioned_base_images"}, {"document_id": "ibmcld_00861-261247-262292", "score": 13.341153, "text": "\nTo view the contents of version 2.1, from the running image, type default_versions.sh. This image includes the following tools:\n\n node --version\nv10.16.0\n\n npm --version\n6.9.0\n\n jq --version\njq-1.6\n\n yq --version\nyq version 2.4.0\n\n kubectl version --client\nClient Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.3\", GitCommit:\"5e53fd6bc17c0dec8434817e69b04a25d8ae0ff0\", GitTreeState:\"clean\", BuildDate:\"2019-06-06T01:44:30Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n\n helm version --client\nClient: &version.Version{SemVer:\"v2.14.1\", GitCommit:\"5270352a09c7e8b6e8c9593002a73535276507c0\", GitTreeState:\"clean\"}\n\n ibmcloud -version\nibmcloud version 0.16.2+d1a5f92-2019-06-06T18:32:54+00:00\n\n ibmcloud plugin list\nListing installed plug-ins...\n\nPlugin Name Version Status\ncloud-functions/wsk/functions/fn 1.0.32\ncontainer-registry 0.1.391\ncontainer-service/kubernetes-service 0.3.47\ndoi 0.1.2\n\n java -version\nopenjdk version \"1.8.0_212\"\nOpenJDK Runtime Environment (build 1.8.0_212-8u212-b03-0ubuntu1.16.04.1-b03)", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-pipeline_versioned_base_images"}, {"document_id": "ibmcld_05526-7-1432", "score": 13.289321, "text": "\nVersion 1.15 change log (unsupported 22 September 2020) \n\nVersion 1.15 is unsupported. You can review the following archive of 1.15 change logs.\n\n\n\n Change log for worker node fix pack 1.15.12_1552, released 14 September 2020 \n\nThe following table shows the changes that are in the worker node fix pack 1.15.12_1552. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.15.12_1551\n\n Component Previous Current Description \n\n HAProxy 1.8.25-384f42 1.8.26-561f1a See the [HAProxy change log](https://www.haproxy.org/download/1.8/src/CHANGELOG). \n Ubuntu 18.04 packages 4.15.0-112-generic 4.15.0-117-generic Updated worker node image with kernel and package updates for [CVE-2020-14344](https://nvd.nist.gov/vuln/detail/CVE-2020-14344), [CVE-2020-14363](https://nvd.nist.gov/vuln/detail/CVE-2020-14363), and [CVE-2020-14386](https://nvd.nist.gov/vuln/detail/CVE-2020-14386). \n Ubuntu 16.04 packages 4.4.0-187-generic 4.4.0-189-generic Updated worker node image with kernel and package updates for [CVE-2020-14344](https://nvd.nist.gov/vuln/detail/CVE-2020-14344) and [CVE-2020-14363](https://nvd.nist.gov/vuln/detail/CVE-2020-14363). \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.15.12_1551, released 31 August 2020 \n\nThe following table shows the changes that are in the worker node fix pack 1.15.12_1551.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-115_changelog"}, {"document_id": "ibmcld_00861-131233-132226", "score": 13.175053, "text": "\nJava version: 11.0.19, vendor: IBM Corporation, runtime: /usr/local/jdk11\nDefault locale: en_US, platform encoding: UTF-8\nOS name: \"linux\", version: \"6.2.15-300.fc38.x86_64\", arch: \"amd64\", family: \"unix\"\n\n gradle\n\nWelcome to Gradle 8.1.1!\n\nHere are the highlights of this release:\n- Stable configuration cache\n- Experimental Kotlin DSL assignment syntax\n- Building with Java 20\n\nFor more details see https://docs.gradle.org/8.1.1/release-notes.html\n\n------------------------------------------------------------\nGradle 8.1.1\n------------------------------------------------------------\n\nBuild time: 2023-04-21 12:31:26 UTC\nRevision: 1cf537a851c635c364a4214885f8b9798051175b\n\nKotlin: 1.8.10\nGroovy: 3.0.15\nAnt: Apache Ant(TM) version 1.10.11 compiled on July 10 2021\nJVM: 11.0.19 (Eclipse OpenJ9 openj9-0.38.0)\nOS: Linux 6.2.15-300.fc38.x86_64 amd64\n\n oc\n4.13.0\n\n zip\nCopyright (c) 1990-2008 Info-ZIP - Type 'zip \"-L\"' for software license.\nThis is Zip 3.0 (July 5th 2008), by Info-ZIP.\n\n unzip", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-pipeline_versioned_base_images"}, {"document_id": "ibmcld_05525-47046-47733", "score": 13.154438, "text": "\nThe following table shows the changes that are in the worker node fix pack 1.14.6_1532.\n\n\n\nTable 1. Changes since version 1.14.5_1530\n\n Component Previous Current Description \n\n containerd v1.2.7 v1.2.8 See the [containerd release notes](https://github.com/containerd/containerd/releases/tag/v1.2.8). Update resolves [CVE-2019-9512](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-9512), [CVE-2019-9514](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-9514), and [CVE-2019-14809](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-14809). \n Kubernetes v1.14.5 v1.14.6 See the [Kubernetes release notes](https://github.com/kubernetes/kubernetes/releases/tag/v1.14.6).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-114_changelog"}]}
{"task_id": "927077bd895f0c292618f4a34789bef3<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16034-15398-17327", "score": 16.149397, "text": "\nUpdated commands \n\n\n\n* Update vpn-server-update command to support VPN server upgrade and downgrade.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Note \n\n\n\n* Linux_S390x build support added.\n\n\n\n\n\n\n\n\n\n v2.0.0 \n\nVersion 2.0.0 was released on 2021-11-18.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update instance commands with \"by name\" support. Instance commands include instance-initialization-values, instance-console, instance-create, instance-create-from-template, instance-delete, instance-disk, instance-disk-update, instance-disks, instance-network-interface, instance-network-interface-create, instance-network-interface-delete, instance-network-interface-floating-ip, instance-network-interface-floating-ip-add, instance-network-interface-floating-ip-remove, instance-network-interface-floating-ips, instance-network-interface-update, instance-network-interfaces, instance-reboot, instance-stop, instance-update, instance-volume-attachments, instance-volume-attachment, instance-volume-attachment-add, instance-volume-attachment-detach, instance-volume-attachment-update, instance-template, instance-template-create, instance-template-create-override-source-template, instance-template-update, instance-group, instance-group-create, instance-group-update, instance-group-delete, instance-group-load-balancer-delete, instance-group-managers, instance-group-manager-create, instance-group-manager-update, instance-group-manager-delete, instance-group-manager-actions, instance-group-manager-action-create, instance-group-manager-action-update, instance-group-manager-action-delete, instance-group-manager-policies, instance-group-manager-policy, instance-group-manager-policy-create, instance-group-manager-policy-update, instance-group-membership, instance-group-membership-delete, instance-group-membership-update, instance-group-memberships, instance-group-memberships-delete commands with \"by name\" support.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-cli-rn"}, {"document_id": "ibmcld_16034-9550-11527", "score": 15.931809, "text": "\n* Updated instance-update command to support placement target patch.\n* Updated vpn-server-update command to support client DNS reset option.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v4.0.3 \n\nVersion 4.0.3 was released on 2022-04-25.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated instance-create command to support more data volumes in interactive mode.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Note \n\n\n\n* Fixed bare-metal-server-create command's interactive mode error log for allowed-vlans.\n* Fixed bare-metal-server-console command to display the correct bare metal server VNC console URL.\n\n\n\n\n\n\n\n\n\n v4.0.2 \n\nVersion 4.0.2 was released on 2022-04-08.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Note \n\n\n\n* Fixed the reserved IP not displaying issue when the instance list instances command is run.\n\n\n\n\n\n\n\n\n\n v4.0.1 \n\nVersion 4.0.1 was released on 2022-04-06.\n\n\n\n New commands \n\n\n\n* Added instance-network-interface-reserved-ips and instance-network-interface-reserved-ip commands to list/get reserved IPs that are associated with a network interface.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated instance-create, instance-network-interface-create, instance-create-from-template, instance-template-create, instance-template-create-override-source-template, bare-metal-server-create, bare-metal-server-network-interface-create, subnet-reserved-ip-create commands to support reserved IP.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* Removed security group network interface commands security-group-network-interface, security-group-network-interface-add, security-group-network-interface-remove and security-group-network-interfaces.\n\n\n\n\n\n\n\n Note \n\n\n\n* Support for primary_ipv4_address property in primary-network-interface and network-interface options for the instance-create, instance-create-from-template, instance-template-create and instance-template-create-override-source-template commands were removed.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-cli-rn"}, {"document_id": "ibmcld_16034-17328-19156", "score": 15.5714855, "text": "\nInstance commands can now use an ID or name for the command option values.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v1.7.0 \n\nVersion 1.7.0 was released on 2021-10-07.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update load-balancer, vpc-routing-table-route-create, snapshots, vpn-gateway and vpn-server commands with \"by name\" support. These commands can now use an ID or name for the command option values.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v1.6.0 \n\nVersion 1.6.0 was released on 2021-09-15.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update load-balancer-create/load-balancer-listener-create/load-balancer-update/load-balancer-listener-update commands to support the load-balancer vnf support.\n* Update subnet, public gateway, image, floating IP, key, placement-group, flow-log, security group, virtual private endpoint gateway, dedicated host and volume commands with \"by name\" support. These commands can now use an ID or name for the command option values.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v1.5.0 \n\nVersion 1.5.0 was released on 2021-08-27.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update instance-create/instance-update/instance-template-create commands to support the instance attached block storage bandwidth setting.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v1.4.0 \n\nVersion 1.4.0 was released on 2021-08-26.\n\n\n\n New commands \n\n\n\n* Add client-to-site VPN server commands (Beta).\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update vpc/address-prefix/routing-table/route commands with \"by name\" support. These commands can now use an ID or name for the command option values.\n* Update network ACL and network ACL rule commands with \"by name\" support. These commands can now use an ID or name for the command option values.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-cli-rn"}, {"document_id": "ibmcld_05337-8090-9659", "score": 15.458157, "text": "\nThere are no changes to the commands themselves.<br> * Fixed various bugs.<br><br><br> \n 1.33.1 02 June 2022 <br><br> * Fixed various bugs.<br> * Upgraded to Go 1.18.3.<br><br><br> \n 1.33.0 26 May 2022 <br><br> * Updated the build create command so that the --image and --registry-secret options are no longer required. This update means that you can choose to let Code Engine take care of building the image for you from your source and storing the image in IBM Cloud Container Registry with automatic access, or you can choose to specify registry details with a registry access secret for your build output.<br> * Fixed various bugs.<br><br><br> \n 1.32.0 19 May 2022 <br><br> * Added support for Mac OS M1 for Code Engine CLI.<br> * Fixed various bugs.<br><br><br> \n 1.31.1 12 May 2022 <br><br> * Fixed various bugs.<br> * Updated translations for the CLI.<br> * Upgraded to Go 1.18.2.<br><br><br> \n 1.31.0 05 May 2022 <br><br> * Updated the following commands to support a progress indicator when you create or update an app or job from local or repository source: app create, app update, job create, and job update.<br> * Updated the following commands to support specifying a prefix when you reference a full configmap or secret by using the --env-from-configmap or --env-from-secret option: app create, app update, job create, job update, jobrun submit, and jobrun resubmit.<br> * Updated the app get, job get, and jobrun get commands to indicate whether a full configmap or full secret reference was specified with a prefix.<br> * Fixed various bugs.<br><br><br>", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-cli_versions"}, {"document_id": "ibmcld_16034-25914-27753", "score": 15.366928, "text": "\nVersion 0.7.0 was released on 2020-10-30.\n\n\n\n New commands \n\n\n\n* Add 'create', 'update', 'list', 'get', 'delete' commands for VPC routing-table and routes (custom routes) feature\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Add 'allow-ip-spoofing' flag for network-interface in instance create and network-interface create/update commands\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v0.6.6 \n\nVersion 0.6.6 was released on 2020-10-23.\n\n\n\n New commands \n\n\n\n* Add load-balancer-pool-members-update command to replace the entire pool members\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Remove the DNS service from endpoint-gateway-targets command output\n* Add --members flag to load-balancer-pool-create command to support creating pool with members\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v0.6.4 \n\nVersion 0.6.4 was released on 2020-09-16.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update all deletion commands to support batch deletion.\n* Update vpc-routing-table-create and vpc-routing-table-update to support ingress custom routing feature.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v0.6.3 \n\nVersion 0.6.3 was released on 2020-08-24.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update VPC API version to 2020-08-11\n* Update network load balancer create command with '--family network' instead of the --profile option.\n* Update load-balancer-pool-update command to reset the session-persistence to null with '--session-persistence-type none'.\n* Update \u2018target\u2019 command to support only the accounts that have generation 1 access.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* Hide 'load-balancer-profiles' command and it will be removed in next major release.\n* Hide 'load-balancer-profile' command and it will be removed in next major release.\n* Hide the 'target' command for the account that doesn't have generation 1 access.\n\n\n\n\n\n\n\n\n\n v0.6.2", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-cli-rn"}, {"document_id": "ibmcld_05337-27063-29113", "score": 14.915892, "text": "\nThis support adds the --extensions option to the subscription COS create, subscription COS update, subscription ping create, and subscription ping update commands. Also adds the --extensions-rm option to the subscription COS update and subscription ping update commands to remove CloudEvent extensions.<br> * Updated the project status on the output for the project get and the project list commands. The status of provisioning is changed to creating, and the status of pending reclamation is changed to soft deleted.<br> * Fixed various minor bugs.<br><br><br> \n 1.2.0 13 April 2021 <br><br> * New! Subscription support for jobs as a beta function. Added support for jobs as event destinations. Use the --destination-type option with the subscription ping create, subscription ping update, subscription cos create, and subscription cos update commands to specify the event destination. Valid values for this option are app and job.<br> * Updated the project get command to display project quota information.<br><br><br> \n 1.1.0 07 April 2021 <br><br> * Increased the polling frequency when build runs and job runs are waiting to complete.<br> * Updated the project delete command such that if a project was previously deleted without specifying the --hard option, a subsequent project delete command must use the --hard option.<br> * Updated the project select command such that a project must be in active status before it can be selected.<br> * Updated the output for the project list and project get commands to display projects that are in pending_reclamation status.<br><br><br> \n 1.0.0 30 March 2021 This version is the generally available release of Code Engine CLI.- Important Introduced a breaking change to Code Engine service binding functions. Service bindings that were created with releases of the CLI earlier than release 1.0.0 will no longer work after you update to the CLI 1.0.0 release. Unbind pre-existing service bindings before you update to CLI 1.0.0.<br><br><br><br> * Updated service bindings to use a new naming convention.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-cli_versions"}, {"document_id": "ibmcld_05684-34652-36491", "score": 14.8449545, "text": "\n* Removes the deprecated region get, region set, and region ls commands from help output.\n* Updates command structure to the new spaced format in help output.\n* Adds a warning to the output of legacy cluster config behavior. For more information, see the [version 1.0 plug-in documentation](https://cloud.ibm.com/docs/containers?topic=containers-cs_cli_changelogchangelog_beta).\n* Fixes a bug so that worker reload and messages commands now fail if the command errors.\n* Updates the help text in various languages.\n\n\n\n\n\n\n\n Version 0.4.23 \n\nVersion 0.4.23 of the CLI was released on 16 September 2019.\n\n\n\n* Decreases startup time for the plug-in.\n* Fixes a Go version issue for macOS users.\n* Improves debug tracing.\n* In ibmcloud ks logging filter commands, the syntax of the --logging-config option changes from accepting multiple values in a comma-separated list to requiring repeated options.\n* Minor bug and security fixes.\n* Updates message, warning, and help text.\n\n\n\n\n\n\n\n Version 0.4.3 \n\nVersion 0.4.3 of the CLI was released on 4 September 2019.\n\n\n\n* Adds deprecation warnings for legacy commands to error messages that are sent to stderr.\n\n\n\n\n\n\n\n Version 0.4.1 \n\nVersion 0.4.1 of the CLI was released on 3 April 2019.\n\n\n\n* Sets the IBM Cloud Kubernetes Service plug-in to the redesigned format by default. This redesigned version includes changes such as categorical lists instead of an alphabetical list of commands in the output of ibmcloud ks help, spaced-structured commands instead of hyphenated-structure commands, repeated options instead of multiple values in comma-separated lists, and more. For a full list of the changes between version 0.3 and 0.4, see the comparison table in [Using the beta IBM Cloud Kubernetes Service plug-in](https://cloud.ibm.com/docs/containers?topic=containers-cs_cli_changelogchangelog_beta).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_cli_changelog"}, {"document_id": "ibmcld_16034-18744-20656", "score": 14.803831, "text": "\n* Add client-to-site VPN server commands (Beta).\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update vpc/address-prefix/routing-table/route commands with \"by name\" support. These commands can now use an ID or name for the command option values.\n* Update network ACL and network ACL rule commands with \"by name\" support. These commands can now use an ID or name for the command option values.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v1.3.0 \n\nVersion 1.3.0 was released on 2021-08-19.\n\n\n\n New commands \n\nN/A\n\n\n\n\n\n Updated commands \n\n\n\n* Update ibmcloud is load-balancer-listener-create, ibmcloud is load-balancer-listener-update, ibmcloud is load-balancer-listener-policy-create, ibmcloud is load-balancer-listener-policy-update commands for load balancer https redirect support.\n* Update ibmcloud is volume-update for volume adjustable IOPS feature.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v1.2.0 \n\nVersion 1.2.0 was released on 2021-07-27.\n\n\n\n New commands \n\n\n\n* ibmcloud is placement-groups command to list placement groups.\n* ibmcloud is placement-group command to get placement group.\n* ibmcloud is placement-group-create command to create placement group.\n* ibmcloud is placement-group-update command to update placement group.\n* ibmcloud is placement-group-delete command to delete placement group.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update ibmcloud is instance-create command with new --placement-group option, user can select the instance placement target with the specified placement group.\n* Update ibmcloud is instance command to show the placement group as the placement target if the instance is created with the specific placement group.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v1.1.0 \n\nVersion 1.0.0 was released on 2021-07-16.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update ibmcloud is volume-update command to expand all volume sizes up to 16 TB.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-cli-rn"}, {"document_id": "ibmcld_16034-4138-5877", "score": 14.740066, "text": "\n* Updated instance-create, instance-create-from-template, instance-update, instance-template-create and instance-template-create-override-source-template commands to support instance metadata service.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v6.5.0 \n\nVersion 6.5.0 was released on 2023-02-07.\n\n\n\n New commands \n\n\n\n* Added snapshot-clone, snapshot-clone-create, snapshot-clone-delete and snapshot-clonescommands to support snapshot fast restore.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated snapshot-create, backup-policy-create, backup-policy-plan-create and backup-policy-plan-update commands to support snapshot and backup fast restore.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v6.4.0 \n\nVersion 6.4.0 was released on 2023-01-31.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated bare-metal-server-create, bare-metal-server-update and bare-metal-server commands to support secure boot mode and TPM.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v6.3.0 \n\nVersion 6.3.0 was released on 2023-01-13.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated ike-policy-create, ike-policy-update, ipsec-policy-create and ipsec-policy-update commands to remove the weak ciphers.\n* Updated vpn-server-create, vpn-server-update, load-balancer-listener-create and load-balancer-listener-update commands to remove the certificate manager support.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v6.2.0 \n\nVersion 6.2.0 was released on 2022-12-14.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated volume-create command to support creation of volume from snapshot.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v6.1.0 \n\nVersion 6.1.0 was released on 2022-11-21.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-cli-rn"}, {"document_id": "ibmcld_11163-60797-62856", "score": 14.712274, "text": "\nThe new --output json option provides command output in a parsable JSON format, and the --quiet option suppresses some extra messages such as progress indicators simplify automated processing. The IBM Cloud CLI now also includes the IBM Cloud Developer Tools (ibmcloud dev) commands, so you can work with apps, pipelines, toolchains, and more without needing to install a separate plug-in. The Cloud Foundry CLI (ibmcloud cf) is no longer bundled but can still be installed separately.\n\nFor more information about the IBM Cloud CLI, see [Getting started with the IBM Cloud CLI and Developer Tools](https://cloud.ibm.com/docs/cli?topic=cli-getting-started).\n\n\n\n\n\n 18 March 2020 \n\nCustomizing how access is assigned by using custom roles\n: Until now, you assigned access by using the available platform and service roles that have specific actions that are mapped by individual services. Sometimes, you must assign multiple roles to achieve the required access for your users. With the latest IBM Cloud Identity and Access Management feature, you can now customize how access is assigned within individual services by creating custom roles. You can choose to organize any number of actions available for a specific service into a new role with a name of your choosing. For more information, see [Creating custom roles](https://cloud.ibm.com/docs/account?topic=account-custom-roles).\n\n\n\n\n\n\n\n February 2020 \n\n\n\n 26 February 2020 \n\nUpdated handling of API keys for removed users\n: When you remove a user from your account, IBM Cloud automatically cleans up the API keys associated with that user's identity, so you don't have to. For more information, see the [Updated handling of IBM Cloud API keys for users removed from accounts](https://www.ibm.com/cloud/blog/announcements/updated-handling-of-ibm-cloud-api-keys-for-users-removed-from-accounts) blog post.\n\n\n\n\n\n\n\n January 2020 \n\n\n\n 21 January 2020 \n\nIBM Cloud Shell (Beta) is now available\n: We're introducing a new way to access IBM Cloud from the command line with no installation needed - IBM\u00ae Cloud Shell!", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-whatsnew"}]}
{"task_id": "927077bd895f0c292618f4a34789bef3<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16034-7-1778", "score": 35.496777, "text": "\nVPC CLI release notes \n\nThe following release notes are for the IBM Cloud\u00ae Virtual Private Cloud (VPC) command line interface (CLI).\n\n\n\n v6.15.0 \n\nVersion 6.15.0 was released on 2023-07-11.\n\n\n\n New commands \n\n\n\n* New commands image-obsolete and image-deprecate are introduced to support image lifecycle management.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for image lifecycle management in image-create, image-update, and images commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v6.14.1 \n\nVersion 6.14.1 was released on 2023-06-30.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed issue with using the SSH key generated from UI in CLI.\n\n\n\n\n\n\n\n\n\n v6.14.0 \n\nVersion 6.14.0 was released on 2023-06-23.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for more algorithms in the SSH key key-create command.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v6.13.0 \n\nVersion 6.13.0 was released on 2023-06-22.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for snapshot and backup cross region copy in snaphot-create, snapshots, backup-policy-plan-create and backup-policy-plan-update commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v6.12.0 \n\nVersion 6.12.0 was released on 2023-06-01.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for fileshare mount targets in share commands (Beta).\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed bare-metal-server-network-interfaces, bare-metal-server-profiles and bare-metal-servers commands to print correct response values.\n\n\n\n\n\n\n\n\n\n v6.11.1 \n\nVersion 6.11.1 was released on 2023-05-03.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-cli-rn"}, {"document_id": "ibmcld_15544-7685-9445", "score": 32.886204, "text": "\nUsing the deprecated status can discourage use of the image before the status changes to obsolete.<br> * obsolete: The image is not available to use to provision an instance.<br> * Schedule complete lifecycle: You can schedule both the deprecated and obsolete status changes at the same time.<br><br><br><br>You can move back and forth between the three statuses. Only the statuses you can change to are displayed. You can schedule status changes by using calendar date and time or number of days. The obsolescence date must always be after the deprecation date. \n\n\n\n\n\n\n\n Importing a custom image by using the CLI \n\nMake sure that your compatible custom image is available in IBM Cloud Object Storage. For more information, see [Creating a Linux custom image](https://cloud.ibm.com/docs/vpc?topic=vpc-create-linux-custom-image), [Creating a Windows custom image](https://cloud.ibm.com/docs/vpc?topic=vpc-create-windows-custom-image), [Bring your own license](https://cloud.ibm.com/docs/vpc?topic=vpc-byol-vpc-about) and [Uploading data](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-upload) to IBM Cloud Object Storage.\n\nWhen you have an image available in IBM Cloud Object Storage, you can import it to IBM Cloud VPC infrastructure by using the command-line interface (CLI).\n\nTo import a custom image by using the CLI, use the ibmcloud is image-create command. Specify the name of the custom image to be created by using the IMAGE_NAME variable. You must also specify the source; for example, specify the --file option with the image file location. Specify the --os-name option with the name of the operating system for the image.\n\nibmcloud is image-create IMAGE_NAME [--file IMAGE_FILE_LOCATION] [--os-name OPERATING_SYSTEM_NAME]", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-importing-custom-images-vpc&interface=ui"}, {"document_id": "ibmcld_15758-3961-6028", "score": 32.458447, "text": "\nFor more information, see [Granting access to IBM Cloud Object Storage to import images](https://cloud.ibm.com/docs/vpc?topic=vpc-object-storage-prereq&interface=cli).\n\n\n\n\n\n\n\n Custom image lifecycle \n\nYou can use the UI, CLI, API, and Terraform to manage the lifecycle of your custom images with three statuses. You can move the image back and forth through all the statuses and set dates to automatically change an image status. All status changes are tracked as an Activity Tracker event. You can filter your list of images based on status to aid in clean-up or tracking of your images. For more information about making status changes, see [Managing custom images](https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images&interface=ui).\n\n\n\nTable 1. Image lifecycle status\n\n Image status Description \n\n available You can use the image to create an instance. \n deprecated You can use the image to create an instance. Using the deprecated status can discourage use of the image before changing the status to obsolete. \n obsolete You can't use the image to create an instance. If you try to use an obsolete image to create an instance, you receive a message that states that you can't use the image to create an instance. This status allows a reversible disabling of an image before you delete the image. \n\n\n\nAny image that is in deprecated or obsolete status is still billed. If you don't want to be billed for the image, you must delete it.\n\nIBM Cloud VPC managed images can be managed only this way. Custom images that are published to a private catalog must be in available status and their statuses are maintained in the private catalog. If you try to change or schedule a change to their status in IBM Cloud VPC, the attempt fails. If a custom image is removed from a private catalog, that image retains its original private catalog status until the status is changed in IBM Cloud VPC.\n\n\n\nTable 2. Catalog image lifecycle status and the corresponding VPC status\n\n Private catalog image status Corresponding VPC image status \n\n published/verified available", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-planning-custom-images&interface=ui"}, {"document_id": "ibmcld_15646-2393-4239", "score": 32.370026, "text": "\nSchedule lifecycle Opens the Schedule image lifecycle panel. You can make an immediate status change or schedule a statue change for a future date and time. You can schedule a single status change or schedule the complete lifecycle of the images. The image statuses are:<br><br><br><br> * available: The image can be used to create an instance.<br> * deprecated: The image is still available to use to provision and instance. Using the deprecated status can discourage use of the image before the status changes to obsolete.<br> * obsolete: The image is not available to use to provision an instancce.<br> * Schedule complete lifecycle: You can schedule both the deprecated and obsolete status changes at the same time.<br><br><br><br>You can move back and forth between the three statuses. Only the statuses you can change to are displayed. You can schedule status changes by by using calendar date and time or number of days. The obsolescence dates must always be after the deprecation date. \n Delete Delete the custom image.<br><br>If you want to delete a custom image in a private catalog, see [Deleting a custom image in a private catalog](https://cloud.ibm.com/docs/vpc?topic=vpc-planning-custom-imagesdeleting-private-catalog-custom-image-vpc). \n\n\n\n\n\n\n\n Listing custom images by using the CLI \n\nYou can list all of the IBM Cloud VPC custom images in your region by using the command-line interface (CLI).\n\nTo list all custom images by using the CLI, use the ibmcloud is images command. Custom images are private to the account where they are created, so the --visibility option is private.\n\nibmcloud is images --visibility private\n\nFor more information, see [ibmcloud is images](https://cloud.ibm.com/docs/vpc?topic=vpc-infrastructure-cli-plugin-vpc-referenceimages) in the VPC CLI reference page.\n\n\n\n\n\n Listing all images by using the API", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images"}, {"document_id": "ibmcld_15647-2393-4239", "score": 32.370026, "text": "\nSchedule lifecycle Opens the Schedule image lifecycle panel. You can make an immediate status change or schedule a statue change for a future date and time. You can schedule a single status change or schedule the complete lifecycle of the images. The image statuses are:<br><br><br><br> * available: The image can be used to create an instance.<br> * deprecated: The image is still available to use to provision and instance. Using the deprecated status can discourage use of the image before the status changes to obsolete.<br> * obsolete: The image is not available to use to provision an instancce.<br> * Schedule complete lifecycle: You can schedule both the deprecated and obsolete status changes at the same time.<br><br><br><br>You can move back and forth between the three statuses. Only the statuses you can change to are displayed. You can schedule status changes by by using calendar date and time or number of days. The obsolescence dates must always be after the deprecation date. \n Delete Delete the custom image.<br><br>If you want to delete a custom image in a private catalog, see [Deleting a custom image in a private catalog](https://cloud.ibm.com/docs/vpc?topic=vpc-planning-custom-imagesdeleting-private-catalog-custom-image-vpc). \n\n\n\n\n\n\n\n Listing custom images by using the CLI \n\nYou can list all of the IBM Cloud VPC custom images in your region by using the command-line interface (CLI).\n\nTo list all custom images by using the CLI, use the ibmcloud is images command. Custom images are private to the account where they are created, so the --visibility option is private.\n\nibmcloud is images --visibility private\n\nFor more information, see [ibmcloud is images](https://cloud.ibm.com/docs/vpc?topic=vpc-infrastructure-cli-plugin-vpc-referenceimages) in the VPC CLI reference page.\n\n\n\n\n\n Listing all images by using the API", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images&interface=ui"}, {"document_id": "ibmcld_15507-5434-7003", "score": 32.039516, "text": "\nTo remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc-manageschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc-manage"}, {"document_id": "ibmcld_15647-27849-29558", "score": 31.280344, "text": "\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images&interface=uischedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint/v1/images/$image_id/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint/v1/images/$image_id/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images&interface=ui"}, {"document_id": "ibmcld_14952-4028-5754", "score": 31.257587, "text": "\nFor accounts that have been granted special approval to preview the image lifecycle management feature, the deprecated_at and obsoleted_at properties for [images](https://cloud.ibm.com/apidocs/vpc-betacreate-image) requests have been renamed deprecation_at and obsolescence_at, respectively. Original property names deprecated_at and obsoleted_at will continue to be supported until the feature becomes generally available. Requests that specify the original and revised property names simultaneously will be rejected.\n\nThis feature is now generally available. Support for property names deprecated_at and obsoleted_at has been removed. See the [VPC API change log](https://cloud.ibm.com/docs/vpc?topic=vpc-api-change-log11-july-2023).\n\n\n\n\n\n\n\n 30 May 2023 \n\n\n\n For version 2023-05-30 or later \n\nThis release introduces the following features for users with accounts that have access to file shares.\n\nFile shares property and request path name changes. When making API requests using a version query parameter of 2023-05-30 or later, the shares targets property has been changed to mount_targets. This change applies when [creating](https://cloud.ibm.com/apidocs/vpc-betacreate-share), [updating](https://cloud.ibm.com/apidocs/vpc-betaupdate-share), [listing](https://cloud.ibm.com/apidocs/vpc-betalist-shares), and [retrieving](https://cloud.ibm.com/apidocs/vpc-betaget-share) a file share, and when [listing all mount targets for a file share](https://cloud.ibm.com/apidocs/vpc-betalist-share-mount-targets).\n\nThe name change also applies to the method paths: Requests using a version query parameter of 2023-05-30 or later must use /shares/{share_id}/mount_targets (instead of /shares/{share_id}/targets) in the request URL.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-api-change-log-beta"}, {"document_id": "ibmcld_15500-4519-5783", "score": 30.949268, "text": "\nFor more information about making status changes, see [Managing custom images](https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images&interface=ui).\n\n\n\nTable 1. Image lifecycle status\n\n Image status Description \n\n available You can use the image to create an instance. \n deprecated You can use the image to create an instance. Using the deprecated status can discourage use of the image before changing the status to obsolete. \n obsolete You can't use the image to create an instance. If you try to use an obsolete image to create an instance, you receive a message that states that you can't use the image to create an instance. This status allows a reversible disabling of an image before you delete the image. \n\n\n\nAny image that is in deprecated or obsolete status is still billed. If you don't want to be billed for the image, you must delete it.\n\n\n\n\n\n Next steps \n\n\n\n* Check out the [Creating a custom image from volume and provisioning an instance in the UI](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-and-using-an-image-from-volume) tutorial.\n* [Create an image from a volume](https://cloud.ibm.com/docs/vpc?topic=vpc-create-ifv).\n* [Troubleshooting custom images](https://cloud.ibm.com/docs/vpc?topic=vpc-ifv-troubleshooting-custom-images).", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc"}, {"document_id": "ibmcld_15507-6657-8493", "score": 30.931396, "text": "\nIf you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Removing previously scheduled image from volume lifecycle statuses by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Changing an image from volume lifecycle status by using the API \n\nYou can change the lifecycle status of a IBM Cloud VPC image from volume by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc-manageschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc-manage"}]}
{"task_id": "927077bd895f0c292618f4a34789bef3<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_15507-8094-9618", "score": 21.661282, "text": "\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc-manageschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint/v1/images/$image_id/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint/v1/images/$image_id/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc-manage"}, {"document_id": "ibmcld_15646-29196-30599", "score": 21.420017, "text": "\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecation_at and obsolescence_at dates and times, the obsolescence_at date must be after the deprecation_at date and time.\n\n\n\n* Schedule a status change to deprecated.\n\ncurl -X PATCH \"$vpc_api_endpoint/v1/images/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\"deprecation_at\": \"2023-03-01T06:11:28+05:30\" }'\n* Schedule a status change to obsolete.\n\ncurl -X PATCH \"$vpc_api_endpoint/v1/images/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\u201cobsolescence_at\": \"2023-12-31T06:11:28+05:30\" }'\n\nIf you want to change the deprecation_at and obsolescence_at date and time entries, you can run these commands again.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images"}, {"document_id": "ibmcld_15647-29235-30638", "score": 21.420017, "text": "\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecation_at and obsolescence_at dates and times, the obsolescence_at date must be after the deprecation_at date and time.\n\n\n\n* Schedule a status change to deprecated.\n\ncurl -X PATCH \"$vpc_api_endpoint/v1/images/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\"deprecation_at\": \"2023-03-01T06:11:28+05:30\" }'\n* Schedule a status change to obsolete.\n\ncurl -X PATCH \"$vpc_api_endpoint/v1/images/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\u201cobsolescence_at\": \"2023-12-31T06:11:28+05:30\" }'\n\nIf you want to change the deprecation_at and obsolescence_at date and time entries, you can run these commands again.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images&interface=ui"}, {"document_id": "ibmcld_15647-27849-29558", "score": 20.916151, "text": "\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images&interface=uischedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint/v1/images/$image_id/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint/v1/images/$image_id/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images&interface=ui"}, {"document_id": "ibmcld_15507-1716-3433", "score": 20.860163, "text": "\nFailed Image creation failed. \n Deleting The image is being deleted. \n Deprecated You can use the image to create an instance. Using the deprecated status can discourage use of the image before the status changes to obsolete. \n Obsolete You can't use the image to a create an instance. If you try to use an obsolete image to create an instance, you receive a message that the image can't be used to create an instance. This status allows a reversible disabiling of an image before you delete the image. \n\n\n\n\n\n\n\n Scheduling an image from volume lifecycle status by using the UI \n\nYou can schedule either a single image lifecycle status change or schedule the status changes for the entire lifecycle of the image.\n\nUse the following steps to schedule a single status change:\n\nYou can schedule a single status change for an image.\n\n\n\n1. In [IBM Cloud console](https://cloud.ibm.com/login), go to Menu icon ![Menu icon](https://cloud.ibm.com/docs-content/v1/content/f02b9c9adcbb7328d95a45e105cec371d50f15eb/icons/icon_hamburger.svg) > VPC Infrastructure > Compute > Images.\n2. On the Custom images tab, click the Actions icon ![More Actions icon](https://cloud.ibm.com/docs-content/v1/content/f02b9c9adcbb7328d95a45e105cec371d50f15eb/icons/action-menu-icon.svg) for a specific image and select from the available options.\n3. Select Schedule lifecycle.\n4. In Image status, select the status change for the image.\n5. In Deprecation details, select whether to change status Immediately or to Schedule future date.\n6. If you selected Schedule future date, you need to fill out the following:\n\n\n\n* Select either By calendar date or By number of days.\n\n\n\n* If you selected By calendar date, enter the date and time information.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc-manage"}, {"document_id": "ibmcld_15507-5434-7003", "score": 20.791935, "text": "\nTo remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc-manageschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc-manage"}, {"document_id": "ibmcld_15646-25256-26940", "score": 20.781242, "text": "\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-imagesschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images"}, {"document_id": "ibmcld_15646-27823-29559", "score": 20.583725, "text": "\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-imagesschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint/v1/images/$image_id/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint/v1/images/$image_id/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images"}, {"document_id": "ibmcld_15647-25269-26966", "score": 20.533323, "text": "\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images&interface=uischedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images&interface=ui"}, {"document_id": "ibmcld_15507-9295-10840", "score": 20.067497, "text": "\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecation_at and obsolescence_at dates and times, the obsolescence_at date must be after the deprecation_at date and time.\n\n\n\n* Schedule a status change to deprecated.\n\ncurl -X PATCH \"$vpc_api_endpoint/v1/images/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\"deprecation_at\": \"2023-03-01T06:11:28+05:30\" }'\n* Schedule a status change to obsolete.\n\ncurl -X PATCH \"$vpc_api_endpoint/v1/images/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\u201cobsolescence_at\": \"2023-12-31T06:11:28+05:30\" }'\n\nIf you want to change the deprecation_at and obsolescence_at date and time entries, you can run these commands again. The previous dates and times are replaced with the new dates and times.\n\n\n\n\n\n\n\n Removing previously scheduled image from volume lifecycle statuses by using the API \n\nMake a PATCH /images request to remove any scheduled status change by updating deprecation_at or obsolescence_at to null. This property change removes the date and time from the image and the image is no longer scheduled for that status change.\n\n\n\n* To change an image from deprecated to available, change the deprecation_at property to null.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc-manage"}]}
{"task_id": "927077bd895f0c292618f4a34789bef3<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13770-6649-7831", "score": 5.8029227, "text": "\nThe request specifies the speaker ID for the speaker named speaker_one and the customization ID for the custom model that was created in the first step. The Content-Type header of the request must be multipart/form-data.\n\nIBM Cloud\n\ncurl -X POST -u apikey:{apikey} --header \"Content-Type:multipart/form-data\" --form metadata=\"{\"prompt_text\": \"Thank you and good-bye!\", \"speaker_id\": \"56367f89-546d-4b37-891e-4eb0c13cc833\"}\" --form file=@goodbye-prompt.wav \"{url}/v1/customizations/82f4809a-bf63-89a6-52ca-22731fe467ba/prompts/goodbye\"\n\nIBM Cloud Pak for Data\n\ncurl -X POST --header \"Authorization: Bearer {token}\" --header \"Content-Type:multipart/form-data\" --form metadata=\"{\"prompt_text\": \"Thank you and good-bye!\", \"speaker_id\": \"56367f89-546d-4b37-891e-4eb0c13cc833\"}\" --form file=@goodbye-prompt.wav \"{url}/v1/customizations/82f4809a-bf63-89a6-52ca-22731fe467ba/prompts/goodbye\"\n\nThe service returns the following response with information about the prompt, including its initial status:\n\n{\n\"prompt\": \"Thank you and good-bye!\",\n\"prompt_id\": \"goodbye\",\n\"status\": \"processing\",\n\"speaker_id\": \"823068b2-ed4e-11ea-b6e0-7b6456aa95cc\"\n}\n\nAdding a prompt is an asynchronous operation.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-tbe-create"}, {"document_id": "ibmcld_13770-7534-9182", "score": 5.499141, "text": "\nThe service returns the following response with information about the prompt, including its initial status:\n\n{\n\"prompt\": \"Thank you and good-bye!\",\n\"prompt_id\": \"goodbye\",\n\"status\": \"processing\",\n\"speaker_id\": \"823068b2-ed4e-11ea-b6e0-7b6456aa95cc\"\n}\n\nAdding a prompt is an asynchronous operation. For more information about checking the status of a new prompt, see [Monitoring the add prompt request](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-tbe-createtbe-create-add-prompt-monitor).\n\n\n\n Monitoring the add prompt request \n\nThe service returns a 201 response code if it successfully initiates the request to add the prompt. Although adding a prompt accepts less audio than speaker enrollment, the service must align the audio with the provided text. The time that it takes to process a prompt depends on the length of the audio for the prompt. The processing time generally matches the length of the audio (for example, it takes 20 seconds to process a 20-second prompt).\n\nFor shorter prompts, you can wait for a reasonable amount of time and then check the status of the prompt with the GET /v1/customizations/{customization_id}/prompts/{prompt_id} method. For longer prompts, consider using that method to poll the service every few seconds to determine when the prompt is ready. The following example checks the status of the goodbye prompt:\n\nIBM Cloud\n\ncurl -X GET -u \"apikey:{apikey}\" \"{url}/v1/customizations/82f4809a-bf63-89a6-52ca-22731fe467ba/prompts/goodbye\"\n\nIBM Cloud Pak for Data\n\ncurl -X GET --header \"Authorization: Bearer {token}\" \"{url}/v1/customizations/82f4809a-bf63-89a6-52ca-22731fe467ba/prompts/goodbye\"", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-tbe-create"}, {"document_id": "ibmcld_09892-2841-4583", "score": 4.6203804, "text": "\n> awardedTo\" relation between \"Noble Prize in Physics\" and \"Albert Einstein\n> timeOf\" relation between \"1921\" and \"awarded\n\n\n\n\n\n Semantic Roles \n\nParse sentences into subject-action-object form, and identify entities and keywords that are subjects or objects of an action. For example:\n\nInput\n\n> text: \"In 2011, Watson competed on Jeopardy!\"\n\nResponse\n\n> Subject: Watson\n> Action: competed\n> Object: on Jeopardy\n\n\n\n\n\n Sentiment \n\nAnalyze the sentiment toward specific target phrases and the sentiment of the document as a whole. You can also get sentiment information for detected entities and keywords by enabling the sentiment option for those features. For example:\n\nInput\n\n> text: \"Thank you and have a nice day!\"\n\nResponse\n\n> Positive sentiment (score: 0.91)\n\n\n\n\n\n Syntax \n\nIdentify the sentences and tokens in your text. For example:\n\nInput\n\n> text: \"I love apples! I do not like oranges.\"\n\nResponse\n\n\n\n Sentence Location \n\n I love apples! [0, 14] \n I do not like oranges. [15,37] \n\n\n\n\n\n Token Lemma Part of Speech Location \n\n I I PRON [0, 1] \n love love VERB [2, 6] \n apples apple NOUN [7, 13] \n ! PUNCT [13, 14] \n I I PRON [15, 16] \n do do AUX [17, 19] \n not not PART [20, 23] \n like like VERB [24, 28] \n oranges orange NOUN [29, 36] \n . NOUN [36, 37] \n\n\n\n\n\n\n\n Summarization (Experimental) \n\nSummarization is an experimental feature, and is not intended for use in production deployments. The details of the API, or the behavior of the underlying algorithm, may change with little notice.\n\nIn this Experimental release, Summarization is supported for English only.\n\nIn this Experimental release, Summarization is supported only for instances hosted in the Dallas region/US-South data center.\n\nReturn a summary of input source content.", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-about"}, {"document_id": "ibmcld_02998-6724-7965", "score": 4.5109315, "text": "\nAdd the response text, Good day to you!\n\n\n\n![Adding a general greeting node to the dialog.](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/gs-add-greeting-node.png)\n\n\n\n1. Click ![Close](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/close.png) to close the edit view.\n2. Click the More icon ![More options](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kebab-grey.png) on the #General_Greetings node, and then select Add node below to create a peer node. In the peer node, specify General_Ending in the If assistant recognizes field, and enter OK. See you later. as the response text.\n3. Click ![Close](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/close.png) to close the edit view.\n\n\n\n![An ending node was added to the dialog also.](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/gs-ending-node-added.png)\n\n\n\n\n\n Testing intent recognition \n\nYou built a simple dialog to recognize and respond to both greeting and ending inputs.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-getting-started"}, {"document_id": "ibmcld_03196-12163-14176", "score": 4.2763495, "text": "\nwelcome This condition is evaluated as true during the first dialog turn (when the conversation starts), only if the initial request from the application does not contain any user input. It is evaluated as false in all subsequent dialog turns. The Welcome node is triggered by this condition. Typically, a node with this condition is used to greet the user, for example, to display a message such as Welcome to our Pizza ordering app. This node is never processed during interactions that occur through channels such as Facebook or Slack. \n\n\n\n\n\n\n\n Condition syntax details \n\nUse one of these syntax options to create valid expressions in conditions:\n\n\n\n* Shorthand notations to refer to intents, entities, and context variables. See [Accessing and evaluating objects](https://cloud.ibm.com/docs/assistant?topic=assistant-expression-language).\n* Spring Expression (SpEL) language, which is an expression language that supports querying and manipulating an object graph at run time. See [Spring Expression Language (SpEL) language](https://docs.spring.io/spring/docs/current/spring-framework-reference/core.htmlexpressions) for more information.\n\n\n\nYou can use regular expressions to check for values to condition against. To find a matching string, for example, you can use the String.find method. See [Methods](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-methods) for more details.\n\n\n\n\n\n\n\n Responses \n\nThe dialog response defines how to reply to the user.\n\nYou can reply in the following ways:\n\n\n\n* [Simple text response](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-simple-text)\n* [Rich responses](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-multimedia)\n* [Conditional responses](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-multiple)\n\n\n\n\n\n Simple text response \n\nIf you want to provide a text response, simply enter the text that you want your assistant to display to the user.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overview"}, {"document_id": "ibmcld_13771-3137-4333", "score": 4.260079, "text": "\n\"prompt\": \"Hello and welcome\",\n\"prompt_id\": \"greeting\",\n\"status\": \"available\",\n\"speaker_id\": \"56367f89-546d-4b37-891e-4eb0c13cc833\"\n},\n{\n\"prompt\": \"How can I help you today?\",\n\"prompt_id\": \"help\",\n\"status\": \"processing\",\n\"speaker_id\": \"56367f89-546d-4b37-891e-4eb0c13cc833\"\n},\n{\n\"prompt\": \"I am sorry to hear that.\",\n\"prompt_id\": \"sorry\",\n\"status\": \"available\",\n\"speaker_id\": \"323e4476-63de-9825-7cd7-8120e45f8331\"\n}\n]\n}\nShow more\n\n\n\n\n\n List a specific custom prompt example \n\nThe following example returns information about just the first custom prompt from the previous listing:\n\nIBM Cloud\n\ncurl -X GET -u \"apikey:{apikey}\" \"{url}/v1/customizations/{customization_id}/prompts/greeting\"\n\nIBM Cloud Pak for Data\n\ncurl -X GET --header \"Authorization: Bearer {token}\" \"{url}/v1/customizations/{customization_id}/prompts/greeting\"\n\nThe response duplicates the information from the previous example:\n\n{\n\"prompt\": \"Hello and welcome!\",\n\"prompt_id\": \"greeting\",\n\"status\": \"available\",\n\"speaker_id\": \"56367f89-546d-4b37-891e-4eb0c13cc833\"\n}\n\n\n\n\n\n\n\n Deleting a custom prompt \n\nTo delete a custom prompt from a custom model, use the DELETE /v1/customizations/{customization_id}/prompts/{prompt_id} method.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-tbe-custom-prompts"}, {"document_id": "ibmcld_03329-5673-6894", "score": 4.1625276, "text": "\nNow let's add nodes between the Welcome node and the Anything else node that handle our intents.\n\n\n\n1. Click Add node.\n2. In the node name field, type Greet customers.\n3. In the If assistant recognizes field of this node, start to type General_Greetings. Then, select the General_Greetings option.\n4. Add the response text, Good day to you!\n\n![Editing the general greeting node.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-add-greeting-node.png)\n5. Click ![Close](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/close.png) to close the edit view.\n6. Click Add node to create a peer node.\n7. Name the peer node Say goodbye and specify General_Ending in the If assistant recognizes field.\n8. Add OK. See you later. as the response text.\n\n![Editing the general ending node.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-add-ending-node.png)\n9. Click ![Close](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/close.png) to close the edit view.\n\n\n\n![Dialog after the ending node is added.]", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-gs-dialog"}, {"document_id": "ibmcld_03329-4608-6052", "score": 4.064081, "text": "\n[Editing the welcome node response](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-edit-welcome-node.png)\n4. Click ![Close](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/close.png) to close the edit view.\n\n\n\nYou created a dialog node that is triggered by the welcome condition. (welcome is a special condition that functions like an intent, but does not begin with a .) It is triggered when a new conversation starts. Your node specifies that when a new conversation starts, the system should respond with the welcome message that you add to the response section of this first node.\n\n\n\n\n\n Testing the start node \n\nYou can test your dialog at any time to verify the dialog. Let's test it now.\n\n\n\n* Click the ![Try it](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/try-it.png) icon to open the \"Try it out\" pane. You should see your welcome message.\n\n\n\n\n\n\n\n Adding nodes to handle intents \n\nNow let's add nodes between the Welcome node and the Anything else node that handle our intents.\n\n\n\n1. Click Add node.\n2. In the node name field, type Greet customers.\n3. In the If assistant recognizes field of this node, start to type General_Greetings. Then, select the General_Greetings option.\n4. Add the response text, Good day to you!\n\n![Editing the general greeting node.]", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-gs-dialog"}, {"document_id": "ibmcld_13770-5357-7016", "score": 4.004737, "text": "\nWhen the call returns with a 201 response code to indicate success, the audio is fully processed and the speaker enrollment is complete.\n\n\n\n\n\n Add a custom prompt \n\nTo add a prompt to a custom model, use the POST /v1/customizations/{customization_id}/prompts/{prompt_id} method. You pass a unique identifier for the prompt as a path parameter. You then use that ID to specify the prompt in speech synthesis and other requests to the service.\n\nYou pass the required text of the prompt and the optional speaker ID with the prompt_text and speaker_id fields as a JSON object by using the multipart form parameter named metadata. You pass the audio for the prompt with a multipart form parameter named file. The audio must be in WAV format and must have a sampling rate of no less that 16 kHz. For more information about the rules and guidelines for the prompt ID, text, and audio, see [Rules for creating custom prompts](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-tbe-rulestbe-rules-prompts).\n\nIt is very important that the text and audio of the prompt match exactly. Discrepancies can reduce the quality of the synthesized prompt or even result in failure of the request.\n\nThe following example creates a custom prompt named goodbye that contains a simple farewell message. The request specifies the speaker ID for the speaker named speaker_one and the customization ID for the custom model that was created in the first step. The Content-Type header of the request must be multipart/form-data.\n\nIBM Cloud\n\ncurl -X POST -u apikey:{apikey} --header \"Content-Type:multipart/form-data\" --form metadata=\"{\"prompt_text\": \"Thank you and good-bye!\"", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-tbe-create"}, {"document_id": "ibmcld_02998-5532-6964", "score": 3.9930458, "text": "\nYou created a dialog node that is triggered by the welcome condition. (welcome is a special condition that functions like an intent, but does not begin with a .) It is triggered when a new conversation starts. Your node specifies that when a new conversation starts, the system should respond with the welcome message that you add to the response section of this first node.\n\n\n\n\n\n Testing the start node \n\nYou can test your dialog at any time to verify the dialog. Let's test it now.\n\n\n\n* Click the ![Try it](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/try-it.png) icon to open the Try it out pane. You should see your welcome message.\n\n\n\n\n\n\n\n Adding nodes to handle intents \n\nNow let's add nodes between the Welcome node and the Anything else node that handle our intents.\n\n\n\n1. Click the More icon ![More options](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kebab-grey.png) on the Welcome node, and then select Add node below.\n2. In the If assistant recognizes field of this node, start to type General_Greetings. Then, select the General_Greetings option.\n3. Add the response text, Good day to you!\n\n\n\n![Adding a general greeting node to the dialog.](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/gs-add-greeting-node.png)\n\n\n\n1. Click !", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-getting-started"}]}
{"task_id": "927077bd895f0c292618f4a34789bef3<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_05527-7-700", "score": 18.561365, "text": "\nVersion 1.16 change log (unsupported as of 31 January 2021) \n\nVersion 1.16 is unsupported. You can review the following archive of 1.16 change logs.\n\n\n\n Change log for master fix pack 1.16.15_1557, released 19 January 2021 \n\nThe following table shows the changes that are in the master fix pack patch update 1.16.15_1557. Master patch updates are applied automatically.\n\n\n\nChanges since version 1.16.15_1556\n\n Component Previous Current Description \n\n Cluster health image v1.1.13 v1.1.16 Updated image to implement additional IBM security controls. \n Gateway-enabled cluster controller 1184 1195 Updated image for [CVE-2020-1971](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-1971).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-116_changelog"}, {"document_id": "ibmcld_05527-74434-75732", "score": 18.021378, "text": "\nChange log for 1.16.5_1522, released 20 January 2020 \n\nThe following table shows the changes that are in the master and worker node patch update 1.16.5_1522. Master patch updates are applied automatically. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node. For more information, see [Update types](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionsupdate_types).\n\n\n\nChanges since version 1.16.3_1521\n\n Component Previous Current Description \n\n Calico v3.9.3 v3.9.5 See the [Calico release notes](https://docs.tigera.io/archive/v3.9/release-notes/). \n Cluster master HA Proxy 1.8.21-alpine 1.8.23-alpine See the [HAProxy release notes](https://www.haproxy.org/download/1.8/src/CHANGELOG). Update resolves [CVE-2019-1551](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-1551). \n CoreDNS 1.6.2 1.6.6 See the [CoreDNS release notes](https://coredns.io/2019/12/11/coredns-1.6.6-release/). Update resolves [CVE-2019-19794](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-19794). \n etcd v3.3.17 v3.3.18 See the [etcd release notes](https://github.com/etcd-io/etcd/releases/v3.3.18). Update resolves [CVE-2019-1551](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-1551).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-116_changelog"}, {"document_id": "ibmcld_05528-7-1118", "score": 17.089409, "text": "\nVersion 1.17 change log (unsupported as of 2 July 2021) \n\nVersion 1.17 is unsupported. You can review the following archive of 1.17 change logs.\n\n\n\n Change log for worker node fix pack 1.17.17_1568, released 19 July 2021 \n\nThe following table shows the changes that are in the worker node fix pack 1.17.17_1568. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.17.17_1567\n\n Component Previous Current Description \n\n Ubuntu 16.04 packages N/A N/A Updated worker node images with kernel package updates. \n Ubuntu 18.04 packages N/A N/A Updated worker node images with kernel package updates. \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.17.17_1567, released 6 July 2021 \n\nThe following table shows the changes that are in the worker node fix pack 1.17.17_1567. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.17.17_1566\n\n Component Previous Current Description", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-117_changelog"}, {"document_id": "ibmcld_05527-4063-5172", "score": 16.865467, "text": "\nChange log for master fix pack 1.16.15_1556, released 6 January 2021 \n\nThe following table shows the changes that are in the master fix pack patch update 1.16.15_1556. Master patch updates are applied automatically.\n\n\n\nChanges since version 1.16.15_1554\n\n Component Previous Current Description \n\n IBM Calico extension 544 556 Updated image to include the ip command. \n IBM Cloud File Storage for Classic plug-in N/A N/A Updated to run with a privileged security context. \n Operator Lifecycle Manager 0.14.1-IKS-1 0.14.1-IKS-2 Updated image for [CVE-2020-1971](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-1971) and [CVE-2020-28928](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-28928). \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.16.15_1555, released 21 December 2020 \n\nThe following table shows the changes that are in the worker node fix pack 1.16.15_1555. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.16.15_1554\n\n Component Previous Current Description", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-116_changelog"}, {"document_id": "ibmcld_05588-25161-25965", "score": 16.850601, "text": "\n* Updates the Go version to 1.15.2.\n\n\n\n\n\n\n\n Change log for patch update 1.0.1_124, released 16 October 2020 \n\nReview the changes in version 1.0.1_124 of the cluster autoscaler add-on.\n\n\n\n* Image tags: 1.15.4-4, 1.16.2-6, 1.17.0-7, 1.18.1-6, and 1.19.0-1.\n* Supported cluster versions: 1.15 - 1.19\n* Exposes the --new-pod-scale-up-delay option in the ConfigMap.\n* Adds support for Kubernetes 1.19.\n\n\n\n\n\n\n\n Change log for patch update 1.0.1_114, released 10 September 2020 \n\nReview the changes in version 1.0.1_114 of the cluster autoscaler add-on.\n\n\n\n* Image tags: 1.15.4-4, 1.16.2-5, 1.17.0-6, and 1.18.1-5.\n* Supported cluster versions: 1.15 - 1.18\n* Includes fixes for CVE-5188 and CVE-3180.\n* Unlike the previous Helm chart, you can modify all the add-on configuration settings via a single configmap.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ca_changelog"}, {"document_id": "ibmcld_10111-706-1524", "score": 16.629316, "text": "\n2.2.12 Deprecated Greater than or equal to 4.6 x86 \n\n\n\n\n\n Change log for version 2.2.16, released 3 July 2023 \n\n\n\n* Adds support for auto creation and deletion of user defined bucket names.\n\n\n\n\n\n\n\n Change log for version 2.2.15, released 19 June 2023 \n\n\n\n* Updates UBI image to 8.8-860.\n* Updates Golang to 1.19.10.\n* Resolves the following CVEs: [CVE-2023-29401](https://nvd.nist.gov/vuln/detail/CVE-2023-29401), [CVE-2023-26125](https://nvd.nist.gov/vuln/detail/CVE-2023-26125), [CVE-2022-3172](https://nvd.nist.gov/vuln/detail/CVE-2022-3172),[CVE-2023-29403](https://nvd.nist.gov/vuln/detail/CVE-2023-29403), [CVE-2023-29404](https://nvd.nist.gov/vuln/detail/CVE-2023-29404), [CVE-2023-29405](https://nvd.nist.gov/vuln/detail/CVE-2023-29405), [CVE-2023-29402](https://nvd.nist.gov/vuln/detail/CVE-2023-29402), [CVE-", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cos_plugin_changelog"}, {"document_id": "ibmcld_05525-2381-3163", "score": 16.285692, "text": "\nUbuntu 16.04 packages 4.4.0-177-generic 4.4.0-178-generic Updated worker node images with package and kernel updates for [CVE-2019-19768](https://nvd.nist.gov/vuln/detail/CVE-2019-19768) and [CVE-2020-12243](https://nvd.nist.gov/vuln/detail/CVE-2020-12243). \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.14.10_1553, released 27 April 2020 \n\nThe following table shows the changes that are in the worker node fix pack 1.14.10_1553. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.14.10_1551\n\n Component Previous Current Description \n\n HA proxy 1.8.25-30b675 1.8.25-adb65d The update addresses [CVE-2020-1967](https://nvd.nist.gov/vuln/detail/CVE-2020-1967).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-114_changelog"}, {"document_id": "ibmcld_05526-22901-23683", "score": 16.24712, "text": "\nUbuntu 16.04 packages 4.4.0-177-generic 4.4.0-178-generic Updated worker node images with package and kernel updates for [CVE-2019-19768](https://nvd.nist.gov/vuln/detail/CVE-2019-19768) and [CVE-2020-12243](https://nvd.nist.gov/vuln/detail/CVE-2020-12243). \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.15.11_1537, released 27 April 2020 \n\nThe following table shows the changes that are in the worker node fix pack 1.15.11_1537. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.15.11_1535\n\n Component Previous Current Description \n\n HA proxy 1.8.25-30b675 1.8.25-adb65d The update addresses [CVE-2020-1967](https://nvd.nist.gov/vuln/detail/CVE-2020-1967).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-115_changelog"}, {"document_id": "ibmcld_05527-12288-13107", "score": 16.224785, "text": "\nThe following table shows the changes that are in the master fix pack patch update 1.16.15_1552. Master patch updates are applied automatically.\n\n\n\nChanges since version 1.16.15_1550\n\n Component Previous Current Description \n\n Cluster health image v1.1.12 v1.1.13 Updated image for [DLA-2424-1](https://www.debian.org/lts/security/2020/dla-2424). \n GPU device plug-in and installer edd26a4 c7a8cf7 Updated image for [CVE-2019-20386](https://nvd.nist.gov/vuln/detail/CVE-2019-20386), [CVE-2019-13050](https://nvd.nist.gov/vuln/detail/CVE-2019-13050), [CVE-2020-8177](https://nvd.nist.gov/vuln/detail/CVE-2020-8177), [CVE-2019-14889](https://nvd.nist.gov/vuln/detail/CVE-2019-14889), [CVE-2020-1730](https://nvd.nist.gov/vuln/detail/CVE-2020-1730), [CVE-2020-10029](https://nvd.nist.gov/vuln/detail/CVE-2020-10029), [CVE-", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-116_changelog"}, {"document_id": "ibmcld_05527-34829-35515", "score": 16.192215, "text": "\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.16.11_1537\n\n Component Previous Current Description \n\n HAProxy 2.0.15-afe432 1.8.25-384f42 See the [HAProxy change log](https://www.haproxy.org/download/1.8/src/CHANGELOG). Fixes a connection leak that happens when HAProxy is under high load. \n Kubernetes v1.16.11 v1.16.13 See the [Kubernetes change logs](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.16.mdv11613). The update resolves CVE-2020-8557 (see the [IBM security bulletin](https://www.ibm.com/support/pages/node/6249941)).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-116_changelog"}]}
{"task_id": "674aa142d92a6b4262de254df0c3f7b2<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16233-7-2298", "score": 16.888098, "text": "\nAbout Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant uses industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom-built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search integration with IBM Watson\u00ae Discovery to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how IBM Watson\u00ae Assistant delivers an exceptional, omnichannel customer experience:\n\nZoom\n\n![Flow diagram of the service](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/arch-detail.png)\n\nHow it works\n\nCustomers interact with the assistant through one or more of these channels:", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-about"}, {"document_id": "ibmcld_03330-4-2191", "score": 16.38169, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n About Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant leverages industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search skill to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how the product delivers an exceptional, omnichannel customer experience:\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-index"}, {"document_id": "ibmcld_07578-19989-21995", "score": 15.693864, "text": "\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https://cloud.ibm.com/docs/services/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)\n* What does the \"Only one free environment is allowed per resource group\" error message mean?\n\nIf you have recently deleted a Lite instance and then receive a 400 - Only one free environment is allowed per resource group error message when creating a new environment in a new Lite instance, you need to finish deleting the original Lite instance. See [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) and follow the reclamation-delete instructions.\n* Is there size limitation on the length of Natural Language Queries (NLQ)?\n\nThe maximum query string length for a natural language query is 2048. For more information, see [Natural language query](https://cloud.ibm.com/docs/discovery?topic=discovery-query-parametersnlq).\n* How do you improve query results?\n\nThe relevance of natural language query results can be improved in IBM Watson Discovery with training. You can train your private collections using either the Discovery tooling, or the Discovery APIs. For information, see [Improving result relevance with the tooling](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n* How do you know that relevancy training is complete?\n\nFor answers to common questions about training a collection and explanations of common error and warning messages, see [Relevancy training tips](https://cloud.ibm.com/docs/discovery?topic=discovery-relevancy-tips).", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-19989-21995", "score": 15.693864, "text": "\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https://cloud.ibm.com/docs/services/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)\n* What does the \"Only one free environment is allowed per resource group\" error message mean?\n\nIf you have recently deleted a Lite instance and then receive a 400 - Only one free environment is allowed per resource group error message when creating a new environment in a new Lite instance, you need to finish deleting the original Lite instance. See [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) and follow the reclamation-delete instructions.\n* Is there size limitation on the length of Natural Language Queries (NLQ)?\n\nThe maximum query string length for a natural language query is 2048. For more information, see [Natural language query](https://cloud.ibm.com/docs/discovery?topic=discovery-query-parametersnlq).\n* How do you improve query results?\n\nThe relevance of natural language query results can be improved in IBM Watson Discovery with training. You can train your private collections using either the Discovery tooling, or the Discovery APIs. For information, see [Improving result relevance with the tooling](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n* How do you know that relevancy training is complete?\n\nFor answers to common questions about training a collection and explanations of common error and warning messages, see [Relevancy training tips](https://cloud.ibm.com/docs/discovery?topic=discovery-relevancy-tips).", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_13160-7-1812", "score": 15.429949, "text": "\nBuild a database-driven Slackbot \n\nThis tutorial may incur costs. Use the [Cost Estimator](https://cloud.ibm.com/estimator/review) to generate a cost estimate based on your projected usage.\n\nIn this tutorial, you are going to build a Slackbot which allows to search and create entries in a backend Db2 on Cloud database. The Slackbot is backed by the IBM Watson\u00ae Assistant service. You will integrate Slack and IBM Watson\u00ae Assistant using an Assistant integration. Db2 on Cloud is made available to Watson Assistant as custom extension.\n\nThe Slack integration sends messages between Slack and Watson Assistant. A custom extension, written in Python and deployed as serverless Code Engine app, exposes a REST API against the database backend.\n\nThis tutorial uses the new experience of Watson Assistant and an action skill. A former version was based on the dialog skill and the database was integrated using IBM Cloud\u00ae Functions with code written in Node.js. You can find that version of the tutorial in the [cloud-functions branch of the related code repository](https://github.com/IBM-Cloud/slack-chatbot-database-watson/tree/cloud-functions).\n\n\n\n Objectives \n\n\n\n* Build a chatbot using Watson Assistant which interacts with a database backend\n* Connect Watson Assistant to Slack using an integration\n* Create and deploy a Python database app to Code Engine\n* Access a Db2 on Cloud database via a Watson Assistant custom extension\n\n\n\nZoom\n\n![Architecture](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution19/SlackbotArchitecture.svg)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. The user interacts with [IBM Watson\u00ae Assistant](https://cloud.ibm.com/docs/watson-assistant), either through Slack or using a web chat client\n2.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"}, {"document_id": "ibmcld_13160-1449-3062", "score": 15.395846, "text": "\n[Architecture](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution19/SlackbotArchitecture.svg)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. The user interacts with [IBM Watson\u00ae Assistant](https://cloud.ibm.com/docs/watson-assistant), either through Slack or using a web chat client\n2. The chatbot utilizes a custom extension with REST API deployed as Python app on [Code Engine](https://cloud.ibm.com/docs/codeengine?topic=codeengine-getting-started)\n3. The custom extension app retrieves data from and inserts data into a [Db2 on Cloud](https://cloud.ibm.com/docs/Db2onCloud) database\n\n\n\n\n\n\n\n Before you begin \n\nThis tutorial requires:\n\n\n\n* IBM Cloud CLI,\n\n\n\n* Code Engine plugin,\n\n\n\n* git to clone source code repository,\n* jq to query JSON data.\n\n\n\nTo avoid the installation of these tools you can use the [Cloud Shell](https://cloud.ibm.com/shell) from the IBM Cloud console.\n\nYou will find instructions to download and install these tools for your operating environment in the [Getting started with tutorials](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-tutorials) guide.\n\n\n\n\n\n Step 1: Set up services and deploy backend \n\nIn this section, you are going to set up the needed services and deploy the backend app. All of this can be accomplished from the command line interface (CLI) in a terminal.\n\n\n\n1. Clone the [GitHub repository](https://github.com/IBM-Cloud/slack-chatbot-database-watson) and navigate into the cloned directory:\n\ngit clone https://github.com/IBM-Cloud/slack-chatbot-database-watson", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"}, {"document_id": "ibmcld_07080-6045-7467", "score": 15.153406, "text": "\n[checkbox](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/checkbox.png) Deploy your solution. [Deploying your project](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-deploy) \n\n\n\n\n\n\n\n Enhance your chatbot \n\nDelight your customers by fortifying your chatbot with an answer to every question. Discovery is designed to work seemlessly with Watson Assistant to search and deliver answers from help content that you already own.\n\nZoom\n\n![Shows a chat bot with emphasize the answer enabled.](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/convo-search.png)\n\nFigure 3. Answer finding enabled in the Watson Assistant web chat\n\nIf enhancing your chatbot is your goal, complete the steps that are listed in the following table.\n\n\n\nChecklist for enhancing your chatbot\n\n Step Task Related information \n\n ![checkbox](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/checkbox.png) Create a Conversational Search project. [Creating projects](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-projects) \n ![checkbox](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/checkbox.png) Add a collection that connects to an external data source or contains uploaded files.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-product-overview"}, {"document_id": "ibmcld_13160-6371-8160", "score": 15.004598, "text": "\nReplace projectid, region, and MY_SECRET accordingly.\n\ncurl -X 'POST' 'https://slackbot-backend.projectid.region.codeengine.appdomain.cloud/database/recreate' -H 'accept: application/json' -H 'API_TOKEN: MY_SECRET'\n\nThe above request should return an error message that the confirmation is missing. Now try again with a query parameter:\n\ncurl -X 'POST' 'https://slackbot-backend.projectid.region.codeengine.appdomain.cloud/database/recreate?confirmation=True' -H 'accept: application/json' -H 'API_TOKEN: MY_SECRET'\n\nThe request should succeed and indicate that the database was recreated. Time for another test:\n\ncurl -X 'GET' 'https://slackbot-backend.projectid.region.codeengine.appdomain.cloud/events' -H 'accept: application/json' -H 'API_TOKEN: MY_SECRET'\n\n\n\n\n\n\n\n Step 2: Create an assistant \n\nIn this part of the tutorial you are going to work with the Watson Assistant service. First, you create a new assistant. Then, you create the custom extension and add it to the assistant. Thereafter, you will create actions and test them using the web preview. Finally, you integrate the chatbot with Slack and perform more tests.\n\n\n\n1. In the [IBM Cloud Resource List](https://cloud.ibm.com/resources) open the overview of your services. Locate the instance of the Watson Assistant service under the AI / Machine Learning section. Click on its entry to open the service details.\n2. Click on Launch Watson Assistant to get to the Watson Assistant Tool.\n3. In the welcome dialog, create a new assistant by using slackbot as Assistant name, then click Next to start personalizing.\n4. For the first question on deployment pick Web.\n5. For the other questions answer for your role or with Other / Not sure at this time.\n6. Click Next for the opportunity to customize the chat UI if desired.\n7.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"}, {"document_id": "ibmcld_16364-199341-201521", "score": 14.909996, "text": "\nAnd the links between nodes are represented in a way that makes it easier to understand the relationships between the nodes.\n\n\n\n\n\n 21 June 2017 \n\nArabic support\n: Language support for Arabic is now generally available. For details, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\nLanguage updates\n: The Watson Assistant service algorithms have been updated to improve overall language support. See the [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support) topic for details.\n\n\n\n\n\n 16 June 2017 \n\nRecommendations (Beta - Premium users only)\n: The Improve panel also includes a Recommendations page that recommends ways to improve your system by analyzing the conversations that users have with your chatbot, and taking into account your system's current training data and response certainty.\n\n\n\n\n\n 14 June 2017 \n\nFuzzy matching for additional languages (Beta)\n: Fuzzy matching for entities is now available for additional languages, as noted in the [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support) topic. You can turn on fuzzy matching per entity to improve the ability of your assistant to recognize terms in user input with syntax that is similar to the entity, without requiring an exact match. The feature is able to map user input to the appropriate corresponding entity despite the presence of misspellings or slight syntactical differences. For example, if you define giraffe as a synonym for an animal entity, and the user input contains the terms giraffes or girafe, the fuzzy match is able to map the term to the animal entity correctly. See [Fuzzy matching](https://cloud.ibm.com/docs/assistant?topic=assistant-entitiesentities-fuzzy-matching) for details.\n\n\n\n\n\n 13 June 2017 \n\nUser conversations\n: The Improve panel now includes a User conversations page, which provides a list of user interactions with your chatbot that can be filtered by keyword, intent, entity, or number of days. You can open individual conversations to correct intents, or to add entity values or synonyms.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_03330-3253-5192", "score": 14.837681, "text": "\n* A conversational skill interprets the customer's message further, then directs the flow of the conversation. The skill gathers any information it needs to respond or perform a transaction on the customer's behalf.\n* A search skill leverages existing FAQ or other curated content that you own to find relevant answers to customer questions.\n* If a customer wants more personalized help or wants to discuss a sensitive subject, the assistant can connect the customer with someone from your support team through the web chat integration.\n\n\n\n\n\nFor more information about the architecture, read the [How to Make Chatbot Orchestration Easier](https://medium.com/ibm-watson/how-to-make-chatbot-orchestration-easier-c8ed61620b8d) blog on Medium.com.\n\nTo see how Watson Assistant is helping enterprises cut costs and improve customer satisfaction today, read the [Independent study finds IBM Watson Assistant customers can accrue $23.9 million in benefits](https://www.ibm.com/blogs/watson/2020/03/independent-study-finds-ibm-watson-assistant-customers-accrued-23-9-million-in-benefits/) blog on ibm.com.\n\nThis documentation describes managed instances of Watson Assistant that are offered in IBM Cloud or in Cloud Pak for Data as a Service. If you are interested in on-premises or installed deployments, see [this documentation](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-index).\n\nRead more about these implementation steps by following these links:\n\n\n\n* [Creating an assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-add)\n* [Adding skills to your assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-add)\n* [Deploying your assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-integration-add)\n\n\n\n\n\n\n\n Browser support \n\nThe Watson Assistant application (where you create assistants and skills) requires the same level of browser software as is required by IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-index"}]}
{"task_id": "674aa142d92a6b4262de254df0c3f7b2<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16257-7-2076", "score": 18.661406, "text": "\nUnderstand your most and least successful actions \n\nThe Action completion page of Watson Assistant provides an overview of how all your assistant's actions are doing. The page allows you to:\n\n\n\n* Understand how well users are progressing through the action steps you have created\n* Identify problem areas within actions\n* Investigate why users are having issues where they might escalate to a live agent, start a new action, get stuck on a step, or stop the conversation\n\n\n\n\n\n Definition of completion \n\nCompletion measures how often within a given time period users reach the end step of an action.\n\n\n\n Reasons for completion \n\nAn action is considered complete when:\n\n\n\n* A final (end) step is reached\n* Search reached a final step\n* The action called another action with the End this action after the other action is completed option, and the other action has completed\n* Connect to agent transfer occurs according to the step response and without involving the [Fallback action](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-handle-errorsfallback-action)\n* The last step of the action has been executed and there are no more steps to execute\n\n\n\n\n\n\n\n Reasons for incompletion \n\nAn action is considered incomplete for these reasons:\n\n\n\n Reason Description \n\n Escalated to agent The user explicitly asks to speak to someone, triggering the [Fallback action](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-handle-errorsfallback-action). For more information, see [When your customer asks to speak to a live agent](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-handle-errorswhen-your-customer-asks-to-speak-to-a-human-agent). Or, the user chooses human agent escalation from the list of [suggestions in web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chatdeploy-web-chat-alternate). \n Started a new action The user changes the topic of the conversation, triggering another action, and either doesn't return to the original action or the other action is also incomplete.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-action-completion"}, {"document_id": "ibmcld_16324-3229-5312", "score": 18.2192, "text": "\nChoose a narrow set of user goals first. If you start small and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. After your assistant is live, the built-in metrics of active user conversations help you understand what your customers are asking about, how well your assistant is able to meet their needs, and what to focus on next.\n\n\n\n\n\n 3. Choose the tone and language of your assistant \n\nBefore you build your assistant, it can also be helpful to choose the tone with which your assistant communicates. Is your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Write conversations that reflect your assistant's personality. Don't overdo it by sacrificing usability for the sake of keeping your assistant in character. Strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe that the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chatbots to identify themselves as chatbots.\n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-language-support).\n\n\n\n\n\n 4. Connect to content sources \n\nThe answer to common questions might already be documented somewhere in your organization's technical information. Plan whether you want to connect the assistant to existing content sources by taking an inventory of relevant help content (for example, product information, knowledge articles, FAQs) available to your customers.\n\nYou can give your assistant access to this information by adding a [search integration](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-search-add) to your assistant. The search integration uses IBM Watson\u00ae Discovery to return smart answers to natural language questions.\n\n\n\n\n\n 5. Plan your handoff strategy", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-plan-assistant"}, {"document_id": "ibmcld_03363-4-2165", "score": 18.052933, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Metrics overview \n\nThe overview page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see metrics information, select Overview in the navigation bar. The information in Analytics is not immediately updated after a user interacts with your assistant. Watson Assistant prepares the data for Analytics in the background.\n\nAfter the numbers in metrics hit the 3,000 and above range, the totals are approximated to prevent performance lags in the page.\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period. The total conversations metric and the User conversations page only include conversations in which both the assistant and customer participate. Conversations that only have welcome messages from the assistant, or that only have user messages of zero length, are not included. This metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs-overview"}, {"document_id": "ibmcld_09118-10321-12086", "score": 17.927141, "text": "\n[View docs](https://cloud.ibm.com/docs/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-getting-startedgetting-started) You can use IBM Watson\u00ae Assistant to to build your own branded live chatbot into any device, application, or channel. [View docs](https://cloud.ibm.com/docs/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Natural Language Understanding](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-getting-startedgetting-started) You can use IBM Watson\u00ae Natural Language Understanding to analyze semantic features of text input, including categories, concepts, emotion, entities, keywords, metadata, relations, semantic roles, and sentiment. [View docs](https://cloud.ibm.com/docs/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Personality Insights](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-about) You can use IBM Watson\u00ae Personality Insights to analyze semantic features of text input, including categories, concepts, emotion, entities, keywords, metadata, relations, semantic roles, and sentiment. [View docs](https://cloud.ibm.com/docs/watson?topic=watson-keyservice) \n\n\n\n\n\n\n\n Container service integrations \n\nYou can integrate Key Protect with the following container services.\n\n\n\nTable 4. Supported container services.\n\n Service Description Integration docs \n\n [IBM Cloud Kubernetes Service](https://cloud.ibm.com/docs/containers?topic=containers-getting-started) You can use the IBM Cloud Kubernetes Service service to deploy highly available apps in Docker containers that run in Kubernetes clusters. [View docs](https://cloud.ibm.com/docs/containers?topic=containers-encryptionkeyprotect)", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-integrate-services"}, {"document_id": "ibmcld_02841-7-1807", "score": 17.870628, "text": "\nAssistants \n\nAn assistant is a cognitive bot that you can customize for the unique needs of your business. You teach it about the types of things your customers want to know and do, and then design a script for the assistant to follow as it converses with your customers to help them accomplish their business goals.\n\n![Skills](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/skill-icon.png) An assistant routes your customer queries to a skill, which then provides the appropriate response. Dialog skills return responses that are authored by you to answer common questions, while search skills search for and return passages from existing self-service content to answer more complex inquiries.\n\n\n\n Dialog skill \n\nA dialog skill can understand and address questions or requests that your customers typically need help with. You provide information about the subjects or tasks your users ask about, and how they ask about them, and the product dynamically builds a machine learning model that is tailored to understand the same and similar user requests.\n\n\n\n Dialog tree Graphical user interface \n\n You can use graphical tools to create a dialog for your assistant to read from when interacting with your users, a dialog that simulates a real conversation. The dialog keys off the common customer goals that you teach it to recognize, and provides useful responses. ![A sample dialog tree with example content](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/dialog-depiction.png) \n\n\n\nThe dialog skill itself is defined in text, but you can integrate it with Watson Speech to Text and Watson Text to Speech services that enable users to interact with your assistant verbally.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistants"}, {"document_id": "ibmcld_16233-7-2298", "score": 17.828104, "text": "\nAbout Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant uses industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom-built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search integration with IBM Watson\u00ae Discovery to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how IBM Watson\u00ae Assistant delivers an exceptional, omnichannel customer experience:\n\nZoom\n\n![Flow diagram of the service](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/arch-detail.png)\n\nHow it works\n\nCustomers interact with the assistant through one or more of these channels:", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-about"}, {"document_id": "ibmcld_03379-0-2495", "score": 17.593672, "text": "\n\n\n\n\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n  Automatic retrain of old skills and workspaces \n\nWatson Assistant was released as a service in July 2016. Since then, users have been creating and updating skills to meet their virtual assistant needs. Behind the scenes, Watson Assistant creates machine learning (ML) models to perform a variety of tasks on the user's behalf.\n\nThe primary ML models deal with action recognition, intent classification, and entity detection. For example, the model might detect what a user intends when saying I want to open a checking account, and what type of account the user is talking about.\n\nThese ML models rely on a sophisticated infrastructure. There are many intricate components that are responsible for analyzing what the user has said, breaking down the user's input, and processing it so the ML model can more easily predict what the user is asking.\n\nSince Watson Assistant was first released, the product team has been making continuous updates to the algorithms that generate these sophisticated ML models. Older models have continued to function while running in the context of newer algorithms. Historically, the behavior of these existing ML model did not change unless the skill was updated, at which point the skill was retrained and a new model generated to replace the older one. This meant that many older models never benefited from improvements in our ML algorithms.\n\nWatson Assistant uses continuous retraining. The Watson Assistant service continually monitors all ML models, and automatically retrains those models that have not been retrained in the previous 6 months. Watson Assistant retrains using the selected algorithm version. If the version you had selected is no longer supported, Watson Assistant retrains using the version labeled as Previous. This means that your assistant will automatically have the supported technologies applied. Assistants that have been modified during the previous 6 months will not be affected. For more information, see [Algorithm version](https://cloud.ibm.com/docs/assistant?topic=assistant-algorithm-version).\n\nIn most cases, this retraining will be seamless from an end-user point of view. The same inputs will result in the same actions, intents, and entities being detected. In some cases, the retraining might cause changes in accuracy.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-auto-retrain"}, {"document_id": "ibmcld_03028-7-1945", "score": 17.4986, "text": "\nImprove your skill \n\nThe Analytics page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nThe Analytics page was introduced with version 1.5.0.\n\nTo open a list of individual messages between customers and the assistant that uses this dialog skill, select User conversations in the navigation bar.\n\nWhen you open the User conversations page, the default view lists inputs that were submitted to the assistant for the last day, with the newest results first. The top intent (#intent) and any recognized entity (@entity) values used in a message, and the message text are available. For intents that are not recognized, the value shown is Irrelevant. If an entity is not recognized, or has not been provided, the value shown is No entities found.\n\n![Logs default page](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/logs_page1.png)\n\nThe User conversations page displays the total number of messages between customers and your assistant. A message is a single utterance that a user sends to the assistant. A conversation typically consists of multiple messages. Therefore, the number of results on the User conversations page is different from the number of conversations that are shown on the Overview page.\n\n\n\n Log limits \n\nMessage logs are retained for 90 days.\n\n\n\n\n\n Filtering messages \n\nYou can filter messages by Search user statements, Intents, Entities, and Last n days.\n\nSearch user statements - Type a word in the search bar. This searches the users' inputs, but not your assistant's replies.\n\nIntents - Select the drop-down menu and type an intent in the input field, or choose from the populated list. You can select more than one intent, which filters the results using any of the selected intents, including Irrelevant.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs"}, {"document_id": "ibmcld_09921-1508-2973", "score": 17.489101, "text": "\nsatisfied An affective response to perceived service quality \n sympathetic An affective mode of understanding that involves emotional resonance \n\n\n\n\n\n* Example response:\n\n{\n\"usage\": {\n\"text_units\": 1,\n\"text_characters\": 60,\n\"features\": 1\n},\n\"language\": \"en\",\n\"classifications\": [\n{\n\"confidence\": 0.564849,\n\"class_name\": \"excited\"\n},\n{\n\"confidence\": 0.355816,\n\"class_name\": \"satisfied\"\n},\n{\n\"confidence\": 0.126127,\n\"class_name\": \"polite\"\n},\n{\n\"confidence\": 0.026995,\n\"class_name\": \"sympathetic\"\n},\n{\n\"confidence\": 0.012211,\n\"class_name\": \"frustrated\"\n},\n{\n\"confidence\": 0.011065,\n\"class_name\": \"sad\"\n},\n{\n\"confidence\": 0.000872,\n\"class_name\": \"impolite\"\n}\n]\n}\nShow more\n\n\n\n\n\n\n\n\n\n Migrating from Watson Tone Analyzer Customer Engagement endpoint to Natural Language Understanding \n\nYou can migrate your [Watson Tone Analyzer customer-engagement](https://cloud.ibm.com/docs/tone-analyzer?topic=tone-analyzer-utco) analysis requests to Natural Language Understanding. This can help you better understand your interactions with customers and improve your communications generally, or for specific customers.\n\n\n\n Reformatting your input data \n\nIn Watson Tone Analyzer, you pass the /v3/tone_chat method a JSON ToneChatInput object consisting of utterances, text, and an optional user string fields. For Natural Language Understanding, you pass a JSON object that contains text to be analyzed, and a language-specific model classification ID, to the /v1/analyze method.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-tone_analytics"}, {"document_id": "ibmcld_16313-5159-7337", "score": 17.440031, "text": "\nFor most customer response types, the assistant is able to understand valid responses provided in a variety of formats. For example, for a time value, 2:15 PM and a quarter past two in the afternoon are both acceptable. But if the user provides a value that the assistant cannot interpret as matching the expected response type (for example, a response of purple when asked for a number), a validation error results.\n\nWhen there is a validation error, the assistant asks the customer to try again. By default, the assistant allows three attempts to provide a valid response. After the third attempt, another invalid attempt triggers the Fallback action, which offers other options like connecting to a live agent. For more information about the Fallback action, see [Editing the fallback action](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-handle-errorsfallback-action).\n\n\n\n Customizing validation for a response \n\nWhen you edit a step that expects a customer response, you can customize how validation errors are handled.\n\n\n\n1. Click Edit validation to see the validation options.\n2. For all customer responses except free text, you can customize the following options:\n\n\n\n* In the Response 1 field, specify the text of the message the assistant sends when the customer's response doesn't match the expected response type. For example, the default validation error message for a numeric value is I didn't catch that. Enter a number. You might want to customize this message to be more specific, such as Enter the number of people in your group.\n* If you want to use several validation responses, click Add Response to add more validation messages. The number of validation responses you can enter depends upon the value in the If attempts exceed field.\n* In the If attempts exceed field, click + or -, or directly edit the number, to change how many consecutive attempts the customer can make before the Fallback action is triggered. Or, if you enabled [response modes](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-action-response-modes), you can use the number of step validation attempts from the response mode that you are using.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-handle-errors"}]}
{"task_id": "674aa142d92a6b4262de254df0c3f7b2<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03006-7541-9354", "score": 17.00283, "text": "\nThe minimum required browser software for the product user interface includes the following browsers:\n\n\n\n* Google Chrome\n: Latest version -1 for your operating system\n* Mozilla Firefox\n: Latest regular -1 and Extended Support Release (ESR) version for your operating system\n* Microsoft Edge\n: Latest version -1 for Windows\n* Apple Safari\n: Latest version -1 for Mac\n\n\n\nThe IBM Cloud Pak for Data web client where you create service instances supports the IBM Cloud Pak for Data requirements. For more information, see [Supported web browsers](https://www.ibm.com/docs/en/cloud-paks/cp-data/4.5.x?topic=requirements-softwaresoftware-reqs__web).\n\n\n\n\n\n Language support \n\nLanguage support by feature is detailed in the [Supported languages](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-support) topic.\n\n\n\n\n\n Security \n\nFederal Information Security Management Act (FISMA) support is available for Watson Assistant for IBM Cloud Pak for Data offerings purchased on or after 30 August 2019. Watson Assistant for IBM Cloud Pak for Data is FISMA High Ready.\n\n\n\n\n\n Next steps \n\n\n\n* [Get started](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-getting-started) with the service\n* Try out some [demos](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-sample-apps).\n\n\n\nStill have questions? Contact [IBM Sales](https://www-01.ibm.com/marketing/iwm/dre/signup?source=urx-20970).\n\n\n\n\n\n Trademarks \n\nIBM, the IBM logo, and ibm.com are trademarks or registered trademarks of International Business Machines Corp., registered in many jurisdictions worldwide. Other product and service names might be trademarks of IBM or other companies. A current list of IBM trademarks is available on the web at [Copyright and trademark information](https://www.ibm.com/legal/copytrade).", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-index"}, {"document_id": "ibmcld_07004-12418-14322", "score": 16.211935, "text": "\n* Service: A security identity used by user-created apps, services, and automation tools to access specific Azure resources. It is like a user identity (verified with a certificate) that has a specific role, and tightly-controlled permissions.\n\nSupport for using a service principal was added with version 4.0.3.\n\nIn the Enter your credentials section, complete the following fields:\n\nTenant name\n: The tenant where the data resides. For example, ibm.onmicrosoft.com.\n\nApplication ID\n: The ID of your app. For example, 19ce9f74-cd14-4b68-8dfc-4bcc75ed2fe9.\n\nUpload the following files:\n\nCertification file\n: The certification file that you created in SharePoint. For example, myinfo.crt.\n\nPrivate key file\n: The private key file that you created in SharePoint. For example, private.app.key.\n\nIf a private key password is required, specify the password.\n\nIf this crawler has permissions to access the specified site collection only, set the Azure Access Control Service switch to On, and then provide the following values:\n\n\n\n* Client ID\n* Client secret\n\n\n\n\n\n8. In Specify what you want to crawl section, add values to the following fields:\n\nSite Collection Url\n: The SharePoint web service URL. For example, https://organization_name.com.\n\nUser principal only\n: In the Site Collection Name field, specify the name that the site collection uses. Get the name from the site collection settings.\n9. Optional: If you are using a proxy server to access the data source server, then in the Proxy settings section, set the Enable proxy settings switch to On. Add values to the following fields:\n\nUsername\n: Optional. The proxy server username to authenticate, if the proxy server requires authentication. If you do not know your username, you can obtain it from the administrator of your proxy server.\n\nPassword\n: Optional. The proxy server password to authenticate, if the proxy server requires authentication.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-connector-sharepoint-online-cp4d"}, {"document_id": "ibmcld_02124-4868-6870", "score": 15.986732, "text": "\nClick your name and review your Access for assigned IAM roles and Cloud Foundry to see which orgs you have access to and your assigned Cloud Foundry roles.\n\n\n\n\n\n Required access for App Service apps \n\nAny user who can access an App Service app can migrate it. However, migrating an app doesn't migrate services that are associated with the app. Service instances must be migrated separately.\n\n\n\n\n\n\n\n How does migration work? \n\n\n\n Migrating service instances \n\nWhen you migrate a service instance from a Cloud Foundry org and space to a resource group, a new linked service instance is created in the resource group. The original instance in the Cloud Foundry org and space becomes an [alias](https://cloud.ibm.com/docs/account?topic=account-connect_appwhat_is_alias). The alias counts towards the quota for your organization, but you're billed for your usage of the service instance in the resource group.\n\nYour browser does not support the video tag.\n\nService instances are migrated one at a time when you're notified on the Resource list page by the ![Migrate this service instance to a resource group](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/account/images/migrate.svg) icon that is associated with your Cloud Foundry service instance.\n\nBefore you start the migration process, review your service documentation to see whether any additional, service-specific changes that you might have to make when you migrate your service instance to a resource group. For example, you might need to migrate data from old instances to new instances or update the credentials that are used for your app if you delete the Cloud Foundry alias. Applications that make a direct call to the API of a service that is migrated need to update the API call to use either an IAM API key or access token.\n\n\n\n1. Open the More actions menu.\n2. Select Migrate to a resource group to get started.\n3. Select a resource group.\n4. Click Migrate and the instance is migrated for you.\n5.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-migrate"}, {"document_id": "ibmcld_08197-0-402", "score": 15.700273, "text": "\n\n\n\n\n\n\n  Supported browsers \n\nFor a list of supported browsers, see [Required Browsers for IBM Cloud\u00ae](https://cloud.ibm.com/docs/overview?topic=overview-prereqs-platformbrowsers-platform).\n\nFor Safari, clear the options Prevent cross-site tracking and Block all cookies under Safari > Preferences > Privacy.\n\nIf you encounter problems when you use these browsers, disable your browser plug-ins.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/hp-virtual-servers?topic=hp-virtual-servers-help-support-browsers"}, {"document_id": "ibmcld_16727-779588-781557", "score": 15.4930725, "text": "\n* Click the wanted User.\n* Select the Classic infrastructure tab.\n* From the Permissions tab, expand the Services category.\n* Select Manage CDN Account.\n* Click the Save button.\n\n\n\nFrom the legacy console main page, follow these steps to edit permissions:\n\n\n\n* Select the Account tab.\n* Select Users > User List.\n* Click the wanted Username.\n* Select the Portal Permissions tab.\n* Select the Services tab.\n* Select Manage CDN Account.\n* Click the Edit Portal Permissions button.\n\n\n\n* Why is the Create button not shown or disabled on the Content Delivery Network page?\n\nIf you are the account's Master user, you must upgrade the account for the Create button to appear or be enabled on this page. From the IBM Cloud console page, follow these steps as the account's Master user:\n\n\n\n* Open the navigation pane by clicking the triple bar icon in the upper left of the web page.\n* Select Classic Infrastructure.\n* Click the Upgrade Account button and follow the instructions.\n\n\n\nIf you are one of the account's secondary users, the account's Master user must give you the Add/Upgrade Services permission for the Create button to appear or be enabled on this page. From the IBM Cloud console page, the account's Master user can follow these steps to edit your permissions:\n\n\n\n* Select the Manage tab.\n* Select Access (IAM).\n* Click the Users tab from navigation pane.\n* Click the wanted User.\n* Select the Classic infrastructure tab.\n* From the Permissions tab, expand the Account category.\n* Select Add/Upgrade Services.\n* Click the Save button.\n\n\n\n* Why am I unable to reach my web page through my CDN after configuring Hotlink Protection with protectionType ALLOW?\n\nLet's consider an example in which your website's domain for users is configured to be your CDN's domain/hostname: cdn.example.com. When someone attempts to reach a web page by navigating directly from the browser's navigation bar, the browser typically does not send Referer headers in its HTTP request.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_02776-2010-4574", "score": 15.18413, "text": "\n* Technically Identifiable Personal Information (such as device IDs, usage-based identifiers, static IP address, and so on. - when linked to an individual)\n* Healthcare Information (data related to physical or mental health of an individual, or which otherwise reveals information about his or her health status)\n\n\n\n\n\n\n\n Usage Data \n\nWhen engaging in the Permitted Uses of the Service, Developer may collect certain information automatically, including, but not limited to the following (collectively \"Usage Data\"):\n\n\n\n* The types of devices being used for testing or development\n* IP addresses\n* Operating systems\n* The types of Internet browsers used\n* Unique device identifiers and other diagnostic data\n\n\n\n\n\n\n\n\n\n Use Of Data \n\nDeveloper uses the collected data for various purposes:\n\n\n\n* To perform development and testing of applications\n* To provide analysis or valuable information to improve development and testing\n* To monitor usage in development and testing\n* To detect, prevent, and address technical issues\n\n\n\n\n\n\n\n Transfer Of Data \n\nInformation, including Personal Data, may be transferred to \u2014 and maintained on \u2014 computers located outside of Developer\u2019s state, province, country or other governmental jurisdiction where the data protection laws may differ than those from Developer\u2019s jurisdiction.\n\nDeveloper will take all steps reasonably necessary to ensure that Personal Data is treated securely and in accordance with this Privacy Policy and applicable law. Developer will also ensure no transfer of Personal Data will take place to an organization or a country, unless there are adequate authorizations and controls in place including obtaining consent where necessary and ensuring the security of Personal Data.\n\n\n\n\n\n Disclosure Of Data \n\n\n\n Legal Requirements \n\nDeveloper may disclose Personal Data in the good faith belief that such action is necessary:\n\n\n\n* To comply with a legal obligation\n* To protect and defend the rights or property of Developer\n* To prevent or investigate possible wrongdoing in connection with development and testing activities\n* To protect the safety of Personal Data\n* To protect against legal liability\n\n\n\n\n\n\n\n\n\n Security Of Data \n\nDeveloper will strive to use appropriate means to protect all Personal Data used in performing the Permitted Uses of the Service.\n\n\n\n\n\n Service Providers \n\nDeveloper may employ third-party companies and individuals (\"Service Providers\") to facilitate Permitted Uses of the Service, including to perform development and testing, or to analyze development and testing activities.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-privacy-policy"}, {"document_id": "ibmcld_13167-13903-15855", "score": 15.170994, "text": "\nLeave the field for Service account as is to go with the default.\n* Finish by clicking Continue.\n\n\n\n5. Next, click on Access policy. In the list of services, select All Identity and Access enabled services and click Next. Go with All resources, click Next again, then select Viewer, and again click on Next. In the section Roles and actions, select Reader for Service access and Viewer for Platform access. When done, click Next and finally Add.\n6. Review the Summary on the right side, then Create the trusted profile with the shown trust relationship and the listed access privileges. Leave the browser tab open for later.\n\n\n\n[Utilizing an access group to assign access is best practices](https://cloud.ibm.com/docs/account?topic=account-account_setuplimit-policies). For the sake of simplicity, we opted for assigning read-only access through a direct access policy. The recommendation is to create an access group with assigned privileges, then make the trusted profile a member of it.\n\n\n\n\n\n Step 4: Deploy the app \n\nWith the Kubernetes cluster and the trusted profile in place, it is time to deploy a simple test app. The source code for the app and the configuration is in the [GitHub repository trusted-profile-enterprise-security](https://github.com/IBM-Cloud/trusted-profile-enterprise-security) You don't need it for the deployment, but might be interested in how it works nonetheless.\n\n\n\n1. In the browser tab cluster overview, check that the cluster has been fully deployed. You might want to refresh the browser and check that all checkmarks are green. If this is the case, click on Kubernetes dashboard and a new browser tab opens (Kubernetes dashboard).\n2. In the top left, find the namespace selector and switch to All namespaces.\n3. On the upper right, click on + to create a new resource. Paste the following content into the text form Create from input.\n\napiVersion: v1\nkind: Namespace\nmetadata:\nname: tptest\nlabels:\nname: tptest\n---", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-trusted-profile-for-enterprise-security"}, {"document_id": "ibmcld_03982-8286-10669", "score": 14.990121, "text": "\nThis is why you should click Export to export this identity to your local file system. If you switch browsers, you will need to import the identity from your file system into the Wallet of your new browser.\n3. Then, click Export to download the key pair to your file system and secure them.\n\n\n\n* The Administrators certificate section of the side panel contains the signing certificates keys of your admins. The certificate that you generated by clicking Generate in the section above can be found in the first row of the field. If you want to use multiple admin identities to operate your network, you can paste additional certificates into admin certificate fields.\n\n\n\nBecause your admin certs are passed to your nodes and channels by using the MSP definition, you need to ensure that each of your node and organization admin certificates is stored in the MSP. When you use the console to create an orderer, peer, or channel, you need to Associate one of the identities you exported in your Wallet with the admin certificates that were provided to the MSP definition. When you encounter an Associate identity section or panel, select an identity that you generated and saved to the Wallet when creating the MSP definition.\n\n\n\n* On the Review MSP information panel, review the information that you specified for this MSP.\n\n\n\nAfter you have selected your CA, MSP ID, and either specified or created an admin, click Create MSP definition. It should now be listed as an organization in the Organizations tab. Because an MSP is the representation of an organization in the network, you select the MSP definition when you deploy your nodes (identifying the organization the node belongs to), are joined to the consortium (by an ordering service admin), create a channel, join a channel, edit a channel, or perform any action where you have to specify the organization that is performing the action.\n\n\n\n\n\n Downloading a connection profile \n\nAfter you create an organization MSP definition and create peers with that organization MSP definition, you can download a connection profile that can be used by a client application to connect to your network via one or more gateway peers. The gateway peers are the peers that are specified in the connection profile, and they are used to perform service discovery to find all of the endorsing peers in the network that will endorse transactions.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-organizations"}, {"document_id": "ibmcld_12815-1776-3990", "score": 14.738003, "text": "\nNext, if you want team members to help with the onboarding process, get them set up with access to your account. For example, add a technical team member to create and add your broker. [In the Assign access section, click Assign to create an access group. Then, click Let's go.]\n\nConfirm your legal agreement with IBM. Or, you can upload your own custom agreement. [Go to the My company page to confirm your legal agreement]\n\nGo back to the My products page and click Create. Enter the name of your product, select the product type, and click Add.\n\nFirst, confirm your product's programmatic name, which is automatically generated for you. Your programmatic name must be approved in order to add a pricing plan or register your service broker. [Click Edit to change your programmatic name, save it, and click Confirm.]\n\nAfter your programmatic name is approved, IBM generates a service ID, which is used to identify your service when communicating with other IBM Cloud services. You\u2019ll need to create an API key for authentication as well.\n\nNow you\u2019re ready to customize your product for the catalog. The information that you provide on the Product details tab is displayed in two places: your catalog tile and your detailed product page. For your catalog entry, provide a logo and a description of your product, along with a category and keywords to help users find your product in the catalog. Next, provide the URL to the end user license agreement that users must agree to in order to use your product. Finish your product page by adding a detailed description and features that highlight your service\u2019s attributes and the benefits to users. Finally, provide links to high-quality images or videos, and your official documentation. [Click Product details. Then, click Add logo to add a link to your logo. Then, click the Edit icon for the Short description field to enter a description of your product. Then, click Select category and select Developer tools. Click Provide the end user license agreement URL customers must agree with to use your product and enter the URL to your license agreement. Click the Edit icon for the Detailed description field and provide a more detailed description of your product.", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-get-started"}, {"document_id": "ibmcld_02776-3988-5695", "score": 14.715883, "text": "\n* To prevent or investigate possible wrongdoing in connection with development and testing activities\n* To protect the safety of Personal Data\n* To protect against legal liability\n\n\n\n\n\n\n\n\n\n Security Of Data \n\nDeveloper will strive to use appropriate means to protect all Personal Data used in performing the Permitted Uses of the Service.\n\n\n\n\n\n Service Providers \n\nDeveloper may employ third-party companies and individuals (\"Service Providers\") to facilitate Permitted Uses of the Service, including to perform development and testing, or to analyze development and testing activities.\n\nThese Service Providers have access to Personal Data only to perform these tasks on Developer\u2019s behalf and are obligated not to disclose or use it for any other purpose.\n\n\n\n\n\n Children's Privacy \n\nThe Permitted Use of the Service does not address anyone under the age of 18 (\"Children\").\n\nDeveloper does not knowingly collect Personal Data from anyone under the age of 18. If Developer becomes aware of the collection or processing of Personal Data from Children without verification of parental consent, Developer will take steps to remove that information from the default settings of App ID.\n\n\n\n\n\n Changes To This Privacy Policy \n\nThis Privacy Policy may be updated from time to time and any changes will be reflected by posting the new Privacy Policy on this page. Before the change becomes effective and updated, notification is made via prominent notice on our Service.\n\nThis Privacy Policy should be reviewed periodically for any changes. Changes to this Privacy Policy are effective when they are posted on this page.\n\n\n\n\n\n Contact Us \n\nFor any questions about this Privacy Policy, please contact the Developer.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-privacy-policy"}]}
{"task_id": "674aa142d92a6b4262de254df0c3f7b2<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13074-16820-18514", "score": 16.894712, "text": "\nEmotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,\n\"joy\": 0.626655,\n\"anger\": 0.02303,\n\"fear\": 0.018884,\n\"sadness\": 0.096802\n}\n}\n}\n\nIn the preceding example, you could query the joy Emotion by accessing enriched_text.emotion.document.emotion.joy\n\nEmotion Analysis analyzes your text and calculates a score for each emotion (anger, disgust, fear, joy, sadness) on a scale of 0.0 to 1.0. If the score of any emotion is 0.5 or higher, then that emotion is detected. The higher the score above 0.5, the higher the relevance. In the snippet shown, joy has a score above 0.5, so Watson detected joy.\n\nEmotion Analysis is supported in English only.\n\n\n\n\n\n Element classification \n\nThe Element Classification enrichment is deprecated and will no longer be available, effective 10 July 2020.\n\nParses elements (sentences, lists, tables) in governing documents to classify important types and categories For more information, see [Element classification](https://cloud.ibm.com/docs/discovery?topic=discovery-element-classification).\n\n[Smart Document Understanding](https://cloud.ibm.com/docs/discovery?topic=discovery-sdu) is unavailable if this enrichment is used.\n\n\n\n Enrichment pricing \n\nEnrichment pricing information is available on [IBM Cloud](https://cloud.ibm.com/catalog/services/discovery).\n\n\n\n\n\n Enrichment language support", "title": "", "source": "https://cloud.ibm.com/docs/services/discovery?topic=discovery-configservice"}, {"document_id": "ibmcld_16364-21733-23882", "score": 15.269776, "text": "\n: Use the Trigger word detected action to add words or phrases to two separate groups. The first group connects customers with an agent, when it\u2019s important for a customer to speak with a live agent rather than activate any further actions. The second group shows customers a customizable warning message, used to discourage customers from interacting with your assistant in unacceptable ways, such as using profanity. This action is included with all new assistants created as of this date. This is a beta feature that is available for evaluation and testing purposes. For more information, see [Detecting trigger words](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-trigger-phrases).\n\nChanges to unrecognized requests algorithm\n: In Analyze, the Recognition page lets you view groups of similar unrecognized requests. You can use the requests as example phrases in new or existing actions to address questions and issues that aren't being answered by your assistant. With this release, the criteria for grouping the requests is relaxed for customers with lesser amounts of data. Also, the group names have been improved with better grammar and to be more representative of the requests. For more information, see [Use unrecognized requests to get action recommendations](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-recognition).\n\n\n\n\n\n 1 February 2023 \n\nActions templates updated with new design and new choices\n: The actions template catalog has a new design that lets you select multiple templates at the same time. It also has new and updated templates, including starter kits you can use with external services such as Google and HubSpot. For more information, see [Building actions from a template](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-actions-templates).\n\n\n\n\n\n 26 January 2023 \n\nDisplay formats for variables\n: In Global settings for actions, Display formats lets you specify the display formats for variables that use date, time, numbers, currency, or percentages. You can also choose a default locale to use if one isn't provided by the client application.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_03369-156643-158642", "score": 14.720595, "text": "\nFor example, for the word barri\u00f3, which has an accent and corresponds to the past tense of the verb barrer (to sweep), your assistant can also match the word barrio (neighborhood), but with a slightly lower confidence.\n\nThe system will provide the highest confidence scores in entities with exact matches. For example, barrio will not be detected if barri\u00f3 is in the training set; and barri\u00f3 will not be detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, then you should put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words using, for example, the Spanish letter \u00f1 vs. the letter n, such as u\u00f1a vs. una. In this case the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.\n\nYou can enable fuzzy matching if you think your customers will not use the appropriate accents, or misspell words (including, for example, putting a n instead of a \u00f1), or you can explicitly include them in the training examples.\n\nNote: Accent normalization is enabled for Portuguese, Spanish, French, and Czech.\n\nWorkspace opt-out flag\n: The Watson Assistant REST API now supports an opt-out flag for workspaces. This flag indicates that workspace training data such as intents and entities are not to be used by IBM for general service improvements. For more information, see the [API Reference](https://cloud.ibm.com/apidocs/assistant/assistant-v1?curl=data-collection)\n\n\n\n\n\n 7 August 2017 \n\nNext and last date interpretation\n: The Watson Assistant service treats last and next dates as referring to the most immediate last or next day referenced, which may be in either the same or a previous week. See the [system entities](https://cloud.ibm.com/docs/assistant?topic=assistant-system-entitiessystem-entities-sys-date-time) topic for additional information.\n\n\n\n\n\n 3 August 2017 \n\nFuzzy matching for additional languages (Beta)", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_16251-6430-8753", "score": 14.613107, "text": "\nPortuguese (Brazilian) (pt-br) GA GA GA \n Spanish (es) GA GA GA \n Universal (xx) GA GA GA \n\n\n\nThe Watson Assistant service supports multiple languages as noted, but the user interface itself (such as descriptions and labels) is in English. All supported languages can be input and trained through the English interface.\n\nGB18030 compliance: GB18030 is a Chinese standard that specifies an extended code page for use in the Chinese market. This code page standard is important for the software industry because the China National Information Technology Standardization Technical Committee mandates that any software application that is released for the Chinese market after September 1, 2001, be enabled for GB18030. The Watson Assistant service supports this encoding, and is certified GB18030-compliant\n\n\n\n\n\n\n\n Changing an assistant language \n\nAfter an assistant is created, its language cannot be modified.\n\n\n\n\n\n Working with accented characters \n\nIn a conversational setting, users might or might not use accents with the Watson Assistant service. As such, both accented and nonaccented versions of words might be treated the same for intent detection and entity recognition.\n\nHowever, for some languages like Spanish, some accents can alter the meaning of the entity. Thus, for entity detection, although the original entity might implicitly have an accent, your assistant can also match the nonaccented version of the same entity, but with a slightly lower confidence score.\n\nFor example, for the word \"barri\u00f3\", which has an accent and corresponds to the past tense of the verb \"barrer\" (to sweep), your assistant can also match the word \"barrio\" (neighborhood), but with a slightly lower confidence.\n\nThe system provides the highest confidence scores in entities with exact matches. For example, barrio isn't detected if barri\u00f3 is in the training set; and barri\u00f3 isn't detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words that use the Spanish letter \u00f1 versus the letter n, such as \"u\u00f1a\" versus \"una\". In this case, the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-language-support"}, {"document_id": "ibmcld_03353-8238-10149", "score": 14.447639, "text": "\n[Bidi options](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/bidi-options.png)\n3. Click the X to close the page. Your changes are saved automatically.\n\n\n\n\n\n\n\n Working with accented characters \n\nIn a conversational setting, users might or might not use accents while interacting with the Watson Assistant service. As such, both accented and non-accented versions of words might be treated the same for intent detection and entity recognition.\n\nHowever for some languages, like Spanish, some accents can alter the meaning of the entity. Thus, for entity detection, although the original entity might implicitly have an accent, your assistant can also match the non-accented version of the same entity, but with a slightly lower confidence score.\n\nFor example, for the word \"barri\u00f3\", which has an accent and corresponds to the past tense of the verb \"barrer\" (to sweep), your assistant can also match the word \"barrio\" (neighborhood), but with a slightly lower confidence.\n\nThe system will provide the highest confidence scores in entities with exact matches. For example, barrio will not be detected if barri\u00f3 is in the training set; and barri\u00f3 will not be detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, then you should put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words using, for example, the Spanish letter \u00f1 vs. the letter n, such as \"u\u00f1a\" vs. \"una\". In this case the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.\n\nYou can enable fuzzy matching if you think your customers will not use the appropriate accents, or misspell words (including, for example, putting a n instead of a \u00f1), or you can explicitly include them in the training examples.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-language-support"}, {"document_id": "ibmcld_16313-10077-11045", "score": 14.365276, "text": "\n* Danger word detected: The customer uses words or phrases that match the Connect to agent step in the Trigger word detected action.\n* Profanity detected: The customer repeatedly used words or phrases that match the Show warning step in the Trigger word detected action.\n\n\n\nFor more information about the Trigger word detected action, see [Detecting trigger words](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-trigger-words).\n\nThe Fallback action defines five conditional steps, one for each possible value of the Fallback reason variable. Each step sends a message to the customer, based on the error condition, and then uses the Connect to agent feature to transfer the conversation to a live agent. (For more information about this feature, see [Connecting to a live agent](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-human-agent).) You can modify these steps if you want to handle an error condition in a different way.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-handle-errors"}, {"document_id": "ibmcld_16251-8219-10227", "score": 14.21344, "text": "\nFor example, barrio isn't detected if barri\u00f3 is in the training set; and barri\u00f3 isn't detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words that use the Spanish letter \u00f1 versus the letter n, such as \"u\u00f1a\" versus \"una\". In this case, the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.\n\n\n\n\n\n Using multilingual downloads for translation \n\nYou can enable the download of language data files, in CSV format, so you can translate training examples and assistant responses into other languages and use in other assistants.\n\nEach CSV file includes translatable_string data that you can use with a machine or human translation service.\n\nEach CSV file also includes id, resource_type, and locator data that Watson Assistant can use in another assistant to re-create your source assistant. You don't need to edit this information.\n\nThe overview of the multilingual process is:\n\n\n\n* [Enable multilingual download](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-language-supportadmin-language-support-multilingual-enable): In your source assistant, enable multilingual download\n* [Translate content](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-language-supportadmin-language-support-multilingual-translate): Use the CSV files with a translation service\n* [Upload to language-specific assistants](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-language-supportadmin-language-support-multilingual-upload): In a destination assistant for another language, use the CSV files to upload translated training and responses\n\n\n\n\n\n Enabling multilingual download \n\nTo enable multilingual download:\n\n\n\n1. Open Assistant settings.\n2. In the Download/Upload section, click Enable multilingual download.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-language-support"}, {"document_id": "ibmcld_16364-192793-195089", "score": 14.020913, "text": "\nThe name you specify is saved as a title attribute of the node in the workspace JSON file and the system uses a unique ID that is stored in the name attribute to reference the node.\n\n\n\n\n\n 23 August 2017 \n\nUpdates to Korean, Japanese, and Italian\n: Language support has been enhanced for Korean, Japanese, and Italian. Note that the Watson Assistant service learning models may have been updated as part of this enhancement, and when you retrain your model any changes will be applied.\n\n\n\n\n\n 10 August 2017 \n\nAccent normalization\n: In a conversational setting, users may or may not use accents while interacting with the Watson Assistant service. As such, an update has been made to the algorithm so that accented and non-accented versions of words are treated the same for intent detection and entity recognition.\n\nHowever, for some languages like Spanish, some accents can alter the meaning of the entity. Thus, for entity detection, although the original entity may implicitly have an accent, your assistant can also match the non-accented version of the same entity, but with a slightly lower confidence score.\n\nFor example, for the word barri\u00f3, which has an accent and corresponds to the past tense of the verb barrer (to sweep), your assistant can also match the word barrio (neighborhood), but with a slightly lower confidence.\n\nThe system will provide the highest confidence scores in entities with exact matches. For example, barrio will not be detected if barri\u00f3 is in the training set; and barri\u00f3 will not be detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, then you should put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words using, for example, the Spanish letter \u00f1 vs. the letter n, such as u\u00f1a vs. una. In this case the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.\n\nYou can enable fuzzy matching if you think your customers will not use the appropriate accents, or misspell words (including, for example, putting a n instead of a \u00f1), or you can explicitly include them in the training examples.\n\nNote: Accent normalization is enabled for Portuguese, Spanish, French, and Czech.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_03027-8135-10108", "score": 13.987282, "text": "\nThis setting is not reflected in the Try it out panel.\n\n![Bidi options](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/bidi-options.png)\n3. Click the X to close the page. Your changes are saved automatically.\n\n\n\n\n\n\n\n Working with accented characters \n\nIn a conversational setting, users might or might not use accents while interacting with the Watson Assistant service. As such, both accented and non-accented versions of words might be treated the same for intent detection and entity recognition.\n\nHowever for some languages, like Spanish, some accents can alter the meaning of the entity. Thus, for entity detection, although the original entity might implicitly have an accent, your assistant can also match the non-accented version of the same entity, but with a slightly lower confidence score.\n\nFor example, for the word \"barri\u00f3\", which has an accent and corresponds to the past tense of the verb \"barrer\" (to sweep), your assistant can also match the word \"barrio\" (neighborhood), but with a slightly lower confidence.\n\nThe system will provide the highest confidence scores in entities with exact matches. For example, barrio will not be detected if barri\u00f3 is in the training set; and barri\u00f3 will not be detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, then you should put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words using, for example, the Spanish letter \u00f1 vs. the letter n, such as \"u\u00f1a\" vs. \"una\". In this case the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.\n\nYou can enable fuzzy matching if you think your customers will not use the appropriate accents, or misspell words (including, for example, putting a n instead of a \u00f1), or you can explicitly include them in the training examples.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-support"}, {"document_id": "ibmcld_16356-7-2036", "score": 13.803862, "text": "\nDetecting trigger words \n\nUse the Trigger word detected action to add words or phrases to two separate groups. The first group connects customers with an agent. The second group shows customers a customizable warning message.\n\nBy default, this action has two steps\u2014the Connect to agent step and the Show warning step. To see how this action works, click Set by assistant in the list of actions, and then click Trigger word detected.\n\nThis is a beta feature that is available for evaluation and testing purposes.\n\n\n\n Connect to agent \n\nThe first step of the Trigger word detected action is the Connect to agent step. The Connect to agent step goes to the Fallback action if any trigger words are detected in the customer's input. Use this step to capture any key phrases where it\u2019s important to connect a customer with a live agent rather than activate any further actions.\n\nFor example, you might add hurt and harm as trigger words for the Connect to agent step:\n\nZoom\n\n![Adding trigger words to the Connect to agent step](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/connect-to-agent-phrases.png)\n\nAdding trigger words to the Connect to agent step\n\nIn this example, a customer enters a word or phrase including hurt or harm, which triggers the Fallback action. Step 4 has:\n\n\n\n* Danger word detected as the fallback reason.\n* The default message: It seems this conversation would be best managed by a human agent. Let me connect you to one of our agents. You can customize this message.\n* And then set to Connect to agent (action ends).\n\n\n\nFor more information about the Fallback action, see [Editing the fallback action](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-handle-errorsfallback-action).\n\n\n\n\n\n Show warning \n\nThe second and final step of the Trigger word detected action is the Show warning step. The Show warning step shows a customizable warning message to your customer if any trigger words are detected in the customer's input.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-trigger-phrases"}]}
{"task_id": "674aa142d92a6b4262de254df0c3f7b2<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09118-10321-12086", "score": 18.912676, "text": "\n[View docs](https://cloud.ibm.com/docs/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-getting-startedgetting-started) You can use IBM Watson\u00ae Assistant to to build your own branded live chatbot into any device, application, or channel. [View docs](https://cloud.ibm.com/docs/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Natural Language Understanding](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-getting-startedgetting-started) You can use IBM Watson\u00ae Natural Language Understanding to analyze semantic features of text input, including categories, concepts, emotion, entities, keywords, metadata, relations, semantic roles, and sentiment. [View docs](https://cloud.ibm.com/docs/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Personality Insights](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-about) You can use IBM Watson\u00ae Personality Insights to analyze semantic features of text input, including categories, concepts, emotion, entities, keywords, metadata, relations, semantic roles, and sentiment. [View docs](https://cloud.ibm.com/docs/watson?topic=watson-keyservice) \n\n\n\n\n\n\n\n Container service integrations \n\nYou can integrate Key Protect with the following container services.\n\n\n\nTable 4. Supported container services.\n\n Service Description Integration docs \n\n [IBM Cloud Kubernetes Service](https://cloud.ibm.com/docs/containers?topic=containers-getting-started) You can use the IBM Cloud Kubernetes Service service to deploy highly available apps in Docker containers that run in Kubernetes clusters. [View docs](https://cloud.ibm.com/docs/containers?topic=containers-encryptionkeyprotect)", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-integrate-services"}, {"document_id": "ibmcld_16233-7-2298", "score": 18.547121, "text": "\nAbout Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant uses industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom-built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search integration with IBM Watson\u00ae Discovery to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how IBM Watson\u00ae Assistant delivers an exceptional, omnichannel customer experience:\n\nZoom\n\n![Flow diagram of the service](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/arch-detail.png)\n\nHow it works\n\nCustomers interact with the assistant through one or more of these channels:", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-about"}, {"document_id": "ibmcld_09892-7-1976", "score": 18.33411, "text": "\nAbout \n\nWith IBM Watson\u00ae Natural Language Understanding, developers can analyze semantic features of text input, including categories, concepts, emotion, entities, keywords, metadata, relations, semantic roles, and sentiment.\n\n\n\n Features \n\nSend requests to the API with text, HTML, or a public URL, and specify one or more of the following features to analyze:\n\n\n\n Categories \n\nCategorize your content using a five-level classification hierarchy. View the complete list of categories [here](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-categories-hierarchy). For example:\n\nInput\n\n> url: \"www.cnn.com\"\n\nResponse\n\n> /news\n> /art and entertainment\n> /movies and tv/television\n> /news\n> /international news\n\n\n\n\n\n Concepts \n\nIdentify high-level concepts that aren't necessarily directly referenced in the text. For example:\n\nInput\n\n> text: \"Natural Language Understanding uses natural language processing to analyze text.\"\n\nResponse\n\n> Linguistics\n> Natural language processing\n> Natural language understanding\n\n\n\n\n\n Emotion \n\nAnalyze emotion conveyed by specific target phrases or by the document as a whole. You can also enable emotion analysis for entities and keywords that are automatically detected by the service. For example:\n\nInput\n\n> text: \"I love apples, but I hate oranges.\"\n> targets: \"apples\", and \"oranges\"\n\nResponse\n\n> \"apples\": joy\n> \"oranges\": anger\n\n\n\n\n\n Entities \n\nFind people, places, events, and other types of entities mentioned in your content. View the complete list of entity types and subtypes [here](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-entity-type-systems). For example:\n\nInput\n\n> text: \"IBM is an American multinational technology company headquartered in Armonk, New York, United States, with operations in over 170 countries.\"\n\nResponse\n\n> IBM: Company\n> Armonk: Location\n> New York: Location\n> United States: Location\n\n\n\n\n\n Keywords", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-about"}, {"document_id": "ibmcld_03379-0-2495", "score": 18.039845, "text": "\n\n\n\n\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n  Automatic retrain of old skills and workspaces \n\nWatson Assistant was released as a service in July 2016. Since then, users have been creating and updating skills to meet their virtual assistant needs. Behind the scenes, Watson Assistant creates machine learning (ML) models to perform a variety of tasks on the user's behalf.\n\nThe primary ML models deal with action recognition, intent classification, and entity detection. For example, the model might detect what a user intends when saying I want to open a checking account, and what type of account the user is talking about.\n\nThese ML models rely on a sophisticated infrastructure. There are many intricate components that are responsible for analyzing what the user has said, breaking down the user's input, and processing it so the ML model can more easily predict what the user is asking.\n\nSince Watson Assistant was first released, the product team has been making continuous updates to the algorithms that generate these sophisticated ML models. Older models have continued to function while running in the context of newer algorithms. Historically, the behavior of these existing ML model did not change unless the skill was updated, at which point the skill was retrained and a new model generated to replace the older one. This meant that many older models never benefited from improvements in our ML algorithms.\n\nWatson Assistant uses continuous retraining. The Watson Assistant service continually monitors all ML models, and automatically retrains those models that have not been retrained in the previous 6 months. Watson Assistant retrains using the selected algorithm version. If the version you had selected is no longer supported, Watson Assistant retrains using the version labeled as Previous. This means that your assistant will automatically have the supported technologies applied. Assistants that have been modified during the previous 6 months will not be affected. For more information, see [Algorithm version](https://cloud.ibm.com/docs/assistant?topic=assistant-algorithm-version).\n\nIn most cases, this retraining will be seamless from an end-user point of view. The same inputs will result in the same actions, intents, and entities being detected. In some cases, the retraining might cause changes in accuracy.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-auto-retrain"}, {"document_id": "ibmcld_13074-16820-18514", "score": 17.812244, "text": "\nEmotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,\n\"joy\": 0.626655,\n\"anger\": 0.02303,\n\"fear\": 0.018884,\n\"sadness\": 0.096802\n}\n}\n}\n\nIn the preceding example, you could query the joy Emotion by accessing enriched_text.emotion.document.emotion.joy\n\nEmotion Analysis analyzes your text and calculates a score for each emotion (anger, disgust, fear, joy, sadness) on a scale of 0.0 to 1.0. If the score of any emotion is 0.5 or higher, then that emotion is detected. The higher the score above 0.5, the higher the relevance. In the snippet shown, joy has a score above 0.5, so Watson detected joy.\n\nEmotion Analysis is supported in English only.\n\n\n\n\n\n Element classification \n\nThe Element Classification enrichment is deprecated and will no longer be available, effective 10 July 2020.\n\nParses elements (sentences, lists, tables) in governing documents to classify important types and categories For more information, see [Element classification](https://cloud.ibm.com/docs/discovery?topic=discovery-element-classification).\n\n[Smart Document Understanding](https://cloud.ibm.com/docs/discovery?topic=discovery-sdu) is unavailable if this enrichment is used.\n\n\n\n Enrichment pricing \n\nEnrichment pricing information is available on [IBM Cloud](https://cloud.ibm.com/catalog/services/discovery).\n\n\n\n\n\n Enrichment language support", "title": "", "source": "https://cloud.ibm.com/docs/services/discovery?topic=discovery-configservice"}, {"document_id": "ibmcld_03330-4-2191", "score": 17.571888, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n About Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant leverages industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search skill to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how the product delivers an exceptional, omnichannel customer experience:\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-index"}, {"document_id": "ibmcld_16324-3229-5312", "score": 17.411585, "text": "\nChoose a narrow set of user goals first. If you start small and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. After your assistant is live, the built-in metrics of active user conversations help you understand what your customers are asking about, how well your assistant is able to meet their needs, and what to focus on next.\n\n\n\n\n\n 3. Choose the tone and language of your assistant \n\nBefore you build your assistant, it can also be helpful to choose the tone with which your assistant communicates. Is your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Write conversations that reflect your assistant's personality. Don't overdo it by sacrificing usability for the sake of keeping your assistant in character. Strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe that the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chatbots to identify themselves as chatbots.\n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-language-support).\n\n\n\n\n\n 4. Connect to content sources \n\nThe answer to common questions might already be documented somewhere in your organization's technical information. Plan whether you want to connect the assistant to existing content sources by taking an inventory of relevant help content (for example, product information, knowledge articles, FAQs) available to your customers.\n\nYou can give your assistant access to this information by adding a [search integration](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-search-add) to your assistant. The search integration uses IBM Watson\u00ae Discovery to return smart answers to natural language questions.\n\n\n\n\n\n 5. Plan your handoff strategy", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-plan-assistant"}, {"document_id": "ibmcld_02841-7-1807", "score": 17.214176, "text": "\nAssistants \n\nAn assistant is a cognitive bot that you can customize for the unique needs of your business. You teach it about the types of things your customers want to know and do, and then design a script for the assistant to follow as it converses with your customers to help them accomplish their business goals.\n\n![Skills](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/skill-icon.png) An assistant routes your customer queries to a skill, which then provides the appropriate response. Dialog skills return responses that are authored by you to answer common questions, while search skills search for and return passages from existing self-service content to answer more complex inquiries.\n\n\n\n Dialog skill \n\nA dialog skill can understand and address questions or requests that your customers typically need help with. You provide information about the subjects or tasks your users ask about, and how they ask about them, and the product dynamically builds a machine learning model that is tailored to understand the same and similar user requests.\n\n\n\n Dialog tree Graphical user interface \n\n You can use graphical tools to create a dialog for your assistant to read from when interacting with your users, a dialog that simulates a real conversation. The dialog keys off the common customer goals that you teach it to recognize, and provides useful responses. ![A sample dialog tree with example content](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/dialog-depiction.png) \n\n\n\nThe dialog skill itself is defined in text, but you can integrate it with Watson Speech to Text and Watson Text to Speech services that enable users to interact with your assistant verbally.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistants"}, {"document_id": "ibmcld_09118-9294-10691", "score": 17.086418, "text": "\n[Text to Speech](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-gettingStarted) You can use Text to Speech's speech-synthesis capabilities to convert written text into natural-sounding speech. [View docs](https://cloud.ibm.com/docs/watson?topic=watson-keyservice) \n [Tone Analyzer](https://cloud.ibm.com/docs/tone-analyzer?topic=tone-analyzer-gettingStarted) You can use Tone Analyzer to detect emotional and language tones in your written texts. [View docs](https://cloud.ibm.com/docs/watson?topic=watson-keyservice) \n [Knowledge Studio](https://cloud.ibm.com/docs/tone-analyzer?topic=tone-analyzer-gettingStarted) You can use Knowledge Studio to understand the linguistic nuances, meaning, and relationships specific to your industry. [View docs](https://cloud.ibm.com/docs/watson?topic=watson-keyservice) \n [Watson OpenScale](https://dataplatform.cloud.ibm.com/docs/content/wsj/model/getting-started.html) You can use Watson OpenScale to automate and maintain the AI lifecycle in your business applications. [View docs](https://cloud.ibm.com/docs/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-getting-startedgetting-started) You can use IBM Watson\u00ae Assistant to to build your own branded live chatbot into any device, application, or channel. [View docs](https://cloud.ibm.com/docs/watson?topic=watson-keyservice)", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-integrate-services"}, {"document_id": "ibmcld_09906-1621-3194", "score": 17.003853, "text": "\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application/json\" --data '{\n\"url\": \"http://newsroom.ibm.com/Guerbet-and-IBM-Watson-Health-Announce-Strategic-Partnership-for-Artificial-Intelligence-in-Medical-Imaging-Liver\",\n\"features\": {\n\"sentiment\": {},\n\"categories\": {},\n\"concepts\": {},\n\"entities\": {},\n\"keywords\": {}\n}\n}' \"{url}/v1/analyze?version=2019-07-12\"\n\nWindows users: This command might not run on Windows. Run the following command instead:\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application/json\" --data \"{\"url\":\"http://newsroom.ibm.com/Guerbet-and-IBM-Watson-Health-Announce-Strategic-Partnership-for-Artificial-Intelligence-in-Medical-Imaging-Liver\",\"features\":{\"sentiment\":{},\"categories\":{},\"concepts\":{},\"entities\":{},\"keywords\":{}}}\" \"{url}/v1/analyze?version=2019-07-12\"\n\nThe next step demonstrates how to specify options that customize the analysis for each feature.\n\n\n\n\n\n Step 2: Analyze target phrases and keywords \n\nNatural Language Understanding can analyze target phrases in context of the surrounding text for focused sentiment and emotion results. The targets option for sentiment in the following example tells the service to search for the targets \"apples\", \"oranges\", and \"broccoli\". Since \"apples\" and \"oranges\" are located in the text, sentiment scores are returned for those targets.\n\nYou can also get sentiment and emotion results for entities and keywords that are detected in your text. In the example, the emotion option for keywords tells the service to analyze each detected keyword for emotion results.", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-getting-started"}]}
